2023-01-04 05:36:35,310 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/9b52f48c712e4c9cfbfc342f165d61dd/2023_01_03-225550",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-04 05:36:35,318 INFO: Starting stage: BUILD FEATURIZERS
2023-01-04 05:36:35,321 INFO:   Creating esm representation model
2023-01-04 05:36:35,321 INFO:   Done esm representation model
2023-01-04 05:36:35,321 INFO: Done with stage: BUILD FEATURIZERS
2023-01-04 05:36:35,321 INFO: Starting stage: BUILDING DATASET
2023-01-04 05:36:35,375 INFO: Done with stage: BUILDING DATASET
2023-01-04 05:36:35,375 INFO: Starting stage: FEATURIZING DATA
2023-01-04 05:36:35,376 INFO:   Featurizing proteins
2023-01-04 05:36:35,377 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-04 05:36:35,412 INFO:   Loaded feature cache of size 489
2023-01-04 05:36:35,413 INFO:   Starting to pool ESM Embeddings
2023-01-04 05:36:35,529 INFO:   Featurizing molecules
2023-01-04 05:36:35,531 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-04 05:36:35,533 INFO:   Loaded feature cache of size 498
2023-01-04 05:36:36,881 INFO: Done with stage: FEATURIZING DATA
2023-01-04 05:36:36,882 INFO: Starting stage: RUNNING SPLITS
2023-01-04 05:36:36,890 INFO:   Leaving out SEQ value Fold_0
2023-01-04 05:36:36,904 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 05:36:36,904 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:36:37,562 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:36:37,562 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:36:37,629 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:36:37,630 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:36:37,630 INFO:     No hyperparam tuning for this model
2023-01-04 05:36:37,630 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:36:37,630 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:36:37,630 INFO:     None feature selector for col prot
2023-01-04 05:36:37,631 INFO:     None feature selector for col prot
2023-01-04 05:36:37,631 INFO:     None feature selector for col prot
2023-01-04 05:36:37,631 INFO:     None feature selector for col chem
2023-01-04 05:36:37,631 INFO:     None feature selector for col chem
2023-01-04 05:36:37,631 INFO:     None feature selector for col chem
2023-01-04 05:36:37,631 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:36:37,631 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:36:37,633 INFO:     Number of params in model 70111
2023-01-04 05:36:37,633 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:36:37,633 INFO:   Starting stage: TRAINING
2023-01-04 05:36:39,231 INFO:     Val loss before train {'Reaction outcome loss': 0.933919890721639, 'Total loss': 0.933919890721639}
2023-01-04 05:36:39,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:39,232 INFO:     Epoch: 0
2023-01-04 05:36:40,775 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6781878471374512, 'Total loss': 0.6781878471374512} | train loss {'Reaction outcome loss': 0.8409731558391026, 'Total loss': 0.8409731558391026}
2023-01-04 05:36:40,776 INFO:     Found new best model at epoch 0
2023-01-04 05:36:40,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:40,776 INFO:     Epoch: 1
2023-01-04 05:36:42,312 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5825980881849925, 'Total loss': 0.5825980881849925} | train loss {'Reaction outcome loss': 0.6736329439140502, 'Total loss': 0.6736329439140502}
2023-01-04 05:36:42,312 INFO:     Found new best model at epoch 1
2023-01-04 05:36:42,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:42,313 INFO:     Epoch: 2
2023-01-04 05:36:43,810 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.527492243051529, 'Total loss': 0.527492243051529} | train loss {'Reaction outcome loss': 0.594899405053247, 'Total loss': 0.594899405053247}
2023-01-04 05:36:43,811 INFO:     Found new best model at epoch 2
2023-01-04 05:36:43,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:43,811 INFO:     Epoch: 3
2023-01-04 05:36:45,352 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5103659600019455, 'Total loss': 0.5103659600019455} | train loss {'Reaction outcome loss': 0.5561446428517283, 'Total loss': 0.5561446428517283}
2023-01-04 05:36:45,352 INFO:     Found new best model at epoch 3
2023-01-04 05:36:45,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:45,353 INFO:     Epoch: 4
2023-01-04 05:36:46,858 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5251083552837372, 'Total loss': 0.5251083552837372} | train loss {'Reaction outcome loss': 0.5306857571606234, 'Total loss': 0.5306857571606234}
2023-01-04 05:36:46,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:46,858 INFO:     Epoch: 5
2023-01-04 05:36:48,387 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4903336743513743, 'Total loss': 0.4903336743513743} | train loss {'Reaction outcome loss': 0.5141927708527108, 'Total loss': 0.5141927708527108}
2023-01-04 05:36:48,387 INFO:     Found new best model at epoch 5
2023-01-04 05:36:48,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:48,388 INFO:     Epoch: 6
2023-01-04 05:36:49,907 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4948551098505656, 'Total loss': 0.4948551098505656} | train loss {'Reaction outcome loss': 0.507214075534335, 'Total loss': 0.507214075534335}
2023-01-04 05:36:49,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:49,907 INFO:     Epoch: 7
2023-01-04 05:36:51,432 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48162777225176495, 'Total loss': 0.48162777225176495} | train loss {'Reaction outcome loss': 0.49011682781762694, 'Total loss': 0.49011682781762694}
2023-01-04 05:36:51,432 INFO:     Found new best model at epoch 7
2023-01-04 05:36:51,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:51,432 INFO:     Epoch: 8
2023-01-04 05:36:52,909 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4805131812890371, 'Total loss': 0.4805131812890371} | train loss {'Reaction outcome loss': 0.4867136251904589, 'Total loss': 0.4867136251904589}
2023-01-04 05:36:52,909 INFO:     Found new best model at epoch 8
2023-01-04 05:36:52,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:52,910 INFO:     Epoch: 9
2023-01-04 05:36:54,430 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48301345904668175, 'Total loss': 0.48301345904668175} | train loss {'Reaction outcome loss': 0.47904118507991345, 'Total loss': 0.47904118507991345}
2023-01-04 05:36:54,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:54,431 INFO:     Epoch: 10
2023-01-04 05:36:55,926 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45477246940135957, 'Total loss': 0.45477246940135957} | train loss {'Reaction outcome loss': 0.4692470805767255, 'Total loss': 0.4692470805767255}
2023-01-04 05:36:55,926 INFO:     Found new best model at epoch 10
2023-01-04 05:36:55,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:55,927 INFO:     Epoch: 11
2023-01-04 05:36:57,449 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46825032035509745, 'Total loss': 0.46825032035509745} | train loss {'Reaction outcome loss': 0.4658365651364728, 'Total loss': 0.4658365651364728}
2023-01-04 05:36:57,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:57,450 INFO:     Epoch: 12
2023-01-04 05:36:58,975 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46663789451122284, 'Total loss': 0.46663789451122284} | train loss {'Reaction outcome loss': 0.45499009130038187, 'Total loss': 0.45499009130038187}
2023-01-04 05:36:58,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:58,976 INFO:     Epoch: 13
2023-01-04 05:37:00,509 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4696557531754176, 'Total loss': 0.4696557531754176} | train loss {'Reaction outcome loss': 0.45779728289052246, 'Total loss': 0.45779728289052246}
2023-01-04 05:37:00,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:00,509 INFO:     Epoch: 14
2023-01-04 05:37:02,008 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4578720688819885, 'Total loss': 0.4578720688819885} | train loss {'Reaction outcome loss': 0.4524047882347317, 'Total loss': 0.4524047882347317}
2023-01-04 05:37:02,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:02,008 INFO:     Epoch: 15
2023-01-04 05:37:03,559 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4493681609630585, 'Total loss': 0.4493681609630585} | train loss {'Reaction outcome loss': 0.4455268935406164, 'Total loss': 0.4455268935406164}
2023-01-04 05:37:03,560 INFO:     Found new best model at epoch 15
2023-01-04 05:37:03,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:03,560 INFO:     Epoch: 16
2023-01-04 05:37:05,065 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4410875876744588, 'Total loss': 0.4410875876744588} | train loss {'Reaction outcome loss': 0.44008234760045134, 'Total loss': 0.44008234760045134}
2023-01-04 05:37:05,065 INFO:     Found new best model at epoch 16
2023-01-04 05:37:05,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:05,066 INFO:     Epoch: 17
2023-01-04 05:37:06,593 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4371343791484833, 'Total loss': 0.4371343791484833} | train loss {'Reaction outcome loss': 0.43795750653132415, 'Total loss': 0.43795750653132415}
2023-01-04 05:37:06,593 INFO:     Found new best model at epoch 17
2023-01-04 05:37:06,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:06,595 INFO:     Epoch: 18
2023-01-04 05:37:08,125 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43354108730951946, 'Total loss': 0.43354108730951946} | train loss {'Reaction outcome loss': 0.43333431756321766, 'Total loss': 0.43333431756321766}
2023-01-04 05:37:08,125 INFO:     Found new best model at epoch 18
2023-01-04 05:37:08,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:08,126 INFO:     Epoch: 19
2023-01-04 05:37:09,658 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4491941491762797, 'Total loss': 0.4491941491762797} | train loss {'Reaction outcome loss': 0.43569168470281383, 'Total loss': 0.43569168470281383}
2023-01-04 05:37:09,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:09,659 INFO:     Epoch: 20
2023-01-04 05:37:11,156 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43843979040781655, 'Total loss': 0.43843979040781655} | train loss {'Reaction outcome loss': 0.42617205003679015, 'Total loss': 0.42617205003679015}
2023-01-04 05:37:11,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:11,157 INFO:     Epoch: 21
2023-01-04 05:37:12,695 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.425779531399409, 'Total loss': 0.425779531399409} | train loss {'Reaction outcome loss': 0.4198724324559117, 'Total loss': 0.4198724324559117}
2023-01-04 05:37:12,695 INFO:     Found new best model at epoch 21
2023-01-04 05:37:12,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:12,696 INFO:     Epoch: 22
2023-01-04 05:37:14,207 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4511178910732269, 'Total loss': 0.4511178910732269} | train loss {'Reaction outcome loss': 0.4198265859768504, 'Total loss': 0.4198265859768504}
2023-01-04 05:37:14,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:14,207 INFO:     Epoch: 23
2023-01-04 05:37:15,761 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40158299207687376, 'Total loss': 0.40158299207687376} | train loss {'Reaction outcome loss': 0.41478179755446676, 'Total loss': 0.41478179755446676}
2023-01-04 05:37:15,762 INFO:     Found new best model at epoch 23
2023-01-04 05:37:15,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:15,762 INFO:     Epoch: 24
2023-01-04 05:37:17,314 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4292507509390513, 'Total loss': 0.4292507509390513} | train loss {'Reaction outcome loss': 0.40998899737448047, 'Total loss': 0.40998899737448047}
2023-01-04 05:37:17,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:17,314 INFO:     Epoch: 25
2023-01-04 05:37:18,896 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41806423167387646, 'Total loss': 0.41806423167387646} | train loss {'Reaction outcome loss': 0.40370417214356935, 'Total loss': 0.40370417214356935}
2023-01-04 05:37:18,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:18,896 INFO:     Epoch: 26
2023-01-04 05:37:20,419 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4260232885678609, 'Total loss': 0.4260232885678609} | train loss {'Reaction outcome loss': 0.40469898526375986, 'Total loss': 0.40469898526375986}
2023-01-04 05:37:20,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:20,419 INFO:     Epoch: 27
2023-01-04 05:37:21,980 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4458585441112518, 'Total loss': 0.4458585441112518} | train loss {'Reaction outcome loss': 0.4014717478564371, 'Total loss': 0.4014717478564371}
2023-01-04 05:37:21,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:21,981 INFO:     Epoch: 28
2023-01-04 05:37:23,509 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4165269513924917, 'Total loss': 0.4165269513924917} | train loss {'Reaction outcome loss': 0.3955653816625312, 'Total loss': 0.3955653816625312}
2023-01-04 05:37:23,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:23,509 INFO:     Epoch: 29
2023-01-04 05:37:25,053 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39605348706245425, 'Total loss': 0.39605348706245425} | train loss {'Reaction outcome loss': 0.3890622850684893, 'Total loss': 0.3890622850684893}
2023-01-04 05:37:25,053 INFO:     Found new best model at epoch 29
2023-01-04 05:37:25,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:25,054 INFO:     Epoch: 30
2023-01-04 05:37:26,596 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40382571816444396, 'Total loss': 0.40382571816444396} | train loss {'Reaction outcome loss': 0.38973364042930114, 'Total loss': 0.38973364042930114}
2023-01-04 05:37:26,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:26,596 INFO:     Epoch: 31
2023-01-04 05:37:28,144 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40149917006492614, 'Total loss': 0.40149917006492614} | train loss {'Reaction outcome loss': 0.38192054410993836, 'Total loss': 0.38192054410993836}
2023-01-04 05:37:28,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:28,145 INFO:     Epoch: 32
2023-01-04 05:37:29,650 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38974427382151283, 'Total loss': 0.38974427382151283} | train loss {'Reaction outcome loss': 0.38006490051418873, 'Total loss': 0.38006490051418873}
2023-01-04 05:37:29,650 INFO:     Found new best model at epoch 32
2023-01-04 05:37:29,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:29,651 INFO:     Epoch: 33
2023-01-04 05:37:31,191 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4219267209370931, 'Total loss': 0.4219267209370931} | train loss {'Reaction outcome loss': 0.37775910435578763, 'Total loss': 0.37775910435578763}
2023-01-04 05:37:31,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:31,192 INFO:     Epoch: 34
2023-01-04 05:37:32,697 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38190189003944397, 'Total loss': 0.38190189003944397} | train loss {'Reaction outcome loss': 0.37786200844542883, 'Total loss': 0.37786200844542883}
2023-01-04 05:37:32,698 INFO:     Found new best model at epoch 34
2023-01-04 05:37:32,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:32,698 INFO:     Epoch: 35
2023-01-04 05:37:34,235 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38077360490957896, 'Total loss': 0.38077360490957896} | train loss {'Reaction outcome loss': 0.36990484379695887, 'Total loss': 0.36990484379695887}
2023-01-04 05:37:34,235 INFO:     Found new best model at epoch 35
2023-01-04 05:37:34,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:34,236 INFO:     Epoch: 36
2023-01-04 05:37:35,770 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4182870477437973, 'Total loss': 0.4182870477437973} | train loss {'Reaction outcome loss': 0.370842980050342, 'Total loss': 0.370842980050342}
2023-01-04 05:37:35,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:35,770 INFO:     Epoch: 37
2023-01-04 05:37:37,288 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40803399483362834, 'Total loss': 0.40803399483362834} | train loss {'Reaction outcome loss': 0.365231800374094, 'Total loss': 0.365231800374094}
2023-01-04 05:37:37,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:37,288 INFO:     Epoch: 38
2023-01-04 05:37:38,809 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3899307390054067, 'Total loss': 0.3899307390054067} | train loss {'Reaction outcome loss': 0.3620147076281872, 'Total loss': 0.3620147076281872}
2023-01-04 05:37:38,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:38,809 INFO:     Epoch: 39
2023-01-04 05:37:40,326 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.392140985528628, 'Total loss': 0.392140985528628} | train loss {'Reaction outcome loss': 0.3557030642098123, 'Total loss': 0.3557030642098123}
2023-01-04 05:37:40,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:40,326 INFO:     Epoch: 40
2023-01-04 05:37:41,843 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4071616301933924, 'Total loss': 0.4071616301933924} | train loss {'Reaction outcome loss': 0.3601520998410253, 'Total loss': 0.3601520998410253}
2023-01-04 05:37:41,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:41,844 INFO:     Epoch: 41
2023-01-04 05:37:43,405 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37364391684532167, 'Total loss': 0.37364391684532167} | train loss {'Reaction outcome loss': 0.3545022347580382, 'Total loss': 0.3545022347580382}
2023-01-04 05:37:43,405 INFO:     Found new best model at epoch 41
2023-01-04 05:37:43,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:43,406 INFO:     Epoch: 42
2023-01-04 05:37:44,941 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3994607150554657, 'Total loss': 0.3994607150554657} | train loss {'Reaction outcome loss': 0.35036639811900944, 'Total loss': 0.35036639811900944}
2023-01-04 05:37:44,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:44,942 INFO:     Epoch: 43
2023-01-04 05:37:46,462 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38748568495114644, 'Total loss': 0.38748568495114644} | train loss {'Reaction outcome loss': 0.3479104057336465, 'Total loss': 0.3479104057336465}
2023-01-04 05:37:46,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:46,462 INFO:     Epoch: 44
2023-01-04 05:37:47,989 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4300086895624797, 'Total loss': 0.4300086895624797} | train loss {'Reaction outcome loss': 0.350436158041596, 'Total loss': 0.350436158041596}
2023-01-04 05:37:47,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:47,989 INFO:     Epoch: 45
2023-01-04 05:37:49,492 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3920515149831772, 'Total loss': 0.3920515149831772} | train loss {'Reaction outcome loss': 0.34302891135870756, 'Total loss': 0.34302891135870756}
2023-01-04 05:37:49,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:49,492 INFO:     Epoch: 46
2023-01-04 05:37:51,020 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.388824071486791, 'Total loss': 0.388824071486791} | train loss {'Reaction outcome loss': 0.3329525263536544, 'Total loss': 0.3329525263536544}
2023-01-04 05:37:51,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:51,021 INFO:     Epoch: 47
2023-01-04 05:37:52,541 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3952158451080322, 'Total loss': 0.3952158451080322} | train loss {'Reaction outcome loss': 0.336794083571273, 'Total loss': 0.336794083571273}
2023-01-04 05:37:52,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:52,541 INFO:     Epoch: 48
2023-01-04 05:37:54,086 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.35212202469507853, 'Total loss': 0.35212202469507853} | train loss {'Reaction outcome loss': 0.3349228073934932, 'Total loss': 0.3349228073934932}
2023-01-04 05:37:54,086 INFO:     Found new best model at epoch 48
2023-01-04 05:37:54,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:54,087 INFO:     Epoch: 49
2023-01-04 05:37:55,598 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3657626986503601, 'Total loss': 0.3657626986503601} | train loss {'Reaction outcome loss': 0.3292529963966691, 'Total loss': 0.3292529963966691}
2023-01-04 05:37:55,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:55,599 INFO:     Epoch: 50
2023-01-04 05:37:57,123 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38470057646433514, 'Total loss': 0.38470057646433514} | train loss {'Reaction outcome loss': 0.3297466517531828, 'Total loss': 0.3297466517531828}
2023-01-04 05:37:57,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:57,124 INFO:     Epoch: 51
2023-01-04 05:37:58,639 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.35975280006726584, 'Total loss': 0.35975280006726584} | train loss {'Reaction outcome loss': 0.32753533569775223, 'Total loss': 0.32753533569775223}
2023-01-04 05:37:58,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:37:58,639 INFO:     Epoch: 52
2023-01-04 05:38:00,192 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37851611773173016, 'Total loss': 0.37851611773173016} | train loss {'Reaction outcome loss': 0.3270340591205127, 'Total loss': 0.3270340591205127}
2023-01-04 05:38:00,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:00,193 INFO:     Epoch: 53
2023-01-04 05:38:01,741 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36740226844946544, 'Total loss': 0.36740226844946544} | train loss {'Reaction outcome loss': 0.3227537101878351, 'Total loss': 0.3227537101878351}
2023-01-04 05:38:01,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:01,741 INFO:     Epoch: 54
2023-01-04 05:38:03,260 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39291531244913735, 'Total loss': 0.39291531244913735} | train loss {'Reaction outcome loss': 0.3249107571694004, 'Total loss': 0.3249107571694004}
2023-01-04 05:38:03,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:03,261 INFO:     Epoch: 55
2023-01-04 05:38:04,761 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37656572957833606, 'Total loss': 0.37656572957833606} | train loss {'Reaction outcome loss': 0.3208333420338648, 'Total loss': 0.3208333420338648}
2023-01-04 05:38:04,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:04,762 INFO:     Epoch: 56
2023-01-04 05:38:06,283 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37996624906857807, 'Total loss': 0.37996624906857807} | train loss {'Reaction outcome loss': 0.3202215269917533, 'Total loss': 0.3202215269917533}
2023-01-04 05:38:06,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:06,284 INFO:     Epoch: 57
2023-01-04 05:38:07,781 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36606457432111106, 'Total loss': 0.36606457432111106} | train loss {'Reaction outcome loss': 0.31534649906577644, 'Total loss': 0.31534649906577644}
2023-01-04 05:38:07,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:07,781 INFO:     Epoch: 58
2023-01-04 05:38:09,357 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3900948852300644, 'Total loss': 0.3900948852300644} | train loss {'Reaction outcome loss': 0.31675691066152883, 'Total loss': 0.31675691066152883}
2023-01-04 05:38:09,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:09,357 INFO:     Epoch: 59
2023-01-04 05:38:10,907 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38296243250370027, 'Total loss': 0.38296243250370027} | train loss {'Reaction outcome loss': 0.3134390182329185, 'Total loss': 0.3134390182329185}
2023-01-04 05:38:10,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:10,907 INFO:     Epoch: 60
2023-01-04 05:38:12,431 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37643611629803975, 'Total loss': 0.37643611629803975} | train loss {'Reaction outcome loss': 0.3108971009760986, 'Total loss': 0.3108971009760986}
2023-01-04 05:38:12,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:12,431 INFO:     Epoch: 61
2023-01-04 05:38:13,927 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37863973875840506, 'Total loss': 0.37863973875840506} | train loss {'Reaction outcome loss': 0.30792161975151455, 'Total loss': 0.30792161975151455}
2023-01-04 05:38:13,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:13,928 INFO:     Epoch: 62
2023-01-04 05:38:15,467 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.361778865257899, 'Total loss': 0.361778865257899} | train loss {'Reaction outcome loss': 0.31347829286322926, 'Total loss': 0.31347829286322926}
2023-01-04 05:38:15,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:15,468 INFO:     Epoch: 63
2023-01-04 05:38:16,983 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3628050059080124, 'Total loss': 0.3628050059080124} | train loss {'Reaction outcome loss': 0.30874431223332227, 'Total loss': 0.30874431223332227}
2023-01-04 05:38:16,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:16,983 INFO:     Epoch: 64
2023-01-04 05:38:18,547 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36833869020144144, 'Total loss': 0.36833869020144144} | train loss {'Reaction outcome loss': 0.3095822307270962, 'Total loss': 0.3095822307270962}
2023-01-04 05:38:18,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:18,547 INFO:     Epoch: 65
2023-01-04 05:38:20,098 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37049717207749683, 'Total loss': 0.37049717207749683} | train loss {'Reaction outcome loss': 0.304035484790802, 'Total loss': 0.304035484790802}
2023-01-04 05:38:20,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:20,099 INFO:     Epoch: 66
2023-01-04 05:38:21,666 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3592563301324844, 'Total loss': 0.3592563301324844} | train loss {'Reaction outcome loss': 0.29751675518659443, 'Total loss': 0.29751675518659443}
2023-01-04 05:38:21,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:21,667 INFO:     Epoch: 67
2023-01-04 05:38:23,175 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38043004969755806, 'Total loss': 0.38043004969755806} | train loss {'Reaction outcome loss': 0.3012104129398262, 'Total loss': 0.3012104129398262}
2023-01-04 05:38:23,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:23,176 INFO:     Epoch: 68
2023-01-04 05:38:24,719 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3810887863238653, 'Total loss': 0.3810887863238653} | train loss {'Reaction outcome loss': 0.2953326052580124, 'Total loss': 0.2953326052580124}
2023-01-04 05:38:24,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:24,719 INFO:     Epoch: 69
2023-01-04 05:38:26,247 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37942539552847543, 'Total loss': 0.37942539552847543} | train loss {'Reaction outcome loss': 0.2968093173462393, 'Total loss': 0.2968093173462393}
2023-01-04 05:38:26,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:26,247 INFO:     Epoch: 70
2023-01-04 05:38:27,805 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3950323532025019, 'Total loss': 0.3950323532025019} | train loss {'Reaction outcome loss': 0.2882867854484272, 'Total loss': 0.2882867854484272}
2023-01-04 05:38:27,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:27,805 INFO:     Epoch: 71
2023-01-04 05:38:29,357 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35298954968651136, 'Total loss': 0.35298954968651136} | train loss {'Reaction outcome loss': 0.2918230177827807, 'Total loss': 0.2918230177827807}
2023-01-04 05:38:29,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:29,357 INFO:     Epoch: 72
2023-01-04 05:38:30,911 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38355073233445486, 'Total loss': 0.38355073233445486} | train loss {'Reaction outcome loss': 0.28831056445400355, 'Total loss': 0.28831056445400355}
2023-01-04 05:38:30,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:30,912 INFO:     Epoch: 73
2023-01-04 05:38:32,424 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3737331986427307, 'Total loss': 0.3737331986427307} | train loss {'Reaction outcome loss': 0.288872276415755, 'Total loss': 0.288872276415755}
2023-01-04 05:38:32,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:32,425 INFO:     Epoch: 74
2023-01-04 05:38:33,980 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3830168346563975, 'Total loss': 0.3830168346563975} | train loss {'Reaction outcome loss': 0.2904886205172364, 'Total loss': 0.2904886205172364}
2023-01-04 05:38:33,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:33,981 INFO:     Epoch: 75
2023-01-04 05:38:35,523 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3824781517187754, 'Total loss': 0.3824781517187754} | train loss {'Reaction outcome loss': 0.2870248243922279, 'Total loss': 0.2870248243922279}
2023-01-04 05:38:35,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:35,524 INFO:     Epoch: 76
2023-01-04 05:38:37,069 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3719000617663066, 'Total loss': 0.3719000617663066} | train loss {'Reaction outcome loss': 0.2833928987247385, 'Total loss': 0.2833928987247385}
2023-01-04 05:38:37,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:37,069 INFO:     Epoch: 77
2023-01-04 05:38:38,629 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38536334137121836, 'Total loss': 0.38536334137121836} | train loss {'Reaction outcome loss': 0.2868088087947159, 'Total loss': 0.2868088087947159}
2023-01-04 05:38:38,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:38,629 INFO:     Epoch: 78
2023-01-04 05:38:40,182 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38195599913597106, 'Total loss': 0.38195599913597106} | train loss {'Reaction outcome loss': 0.2800317618709344, 'Total loss': 0.2800317618709344}
2023-01-04 05:38:40,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:40,183 INFO:     Epoch: 79
2023-01-04 05:38:41,700 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.366795622309049, 'Total loss': 0.366795622309049} | train loss {'Reaction outcome loss': 0.2854062503565362, 'Total loss': 0.2854062503565362}
2023-01-04 05:38:41,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:41,700 INFO:     Epoch: 80
2023-01-04 05:38:43,231 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3921324759721756, 'Total loss': 0.3921324759721756} | train loss {'Reaction outcome loss': 0.2837902410945176, 'Total loss': 0.2837902410945176}
2023-01-04 05:38:43,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:43,231 INFO:     Epoch: 81
2023-01-04 05:38:44,747 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38212045828501384, 'Total loss': 0.38212045828501384} | train loss {'Reaction outcome loss': 0.27835396824629755, 'Total loss': 0.27835396824629755}
2023-01-04 05:38:44,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:44,747 INFO:     Epoch: 82
2023-01-04 05:38:46,262 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3754853179057439, 'Total loss': 0.3754853179057439} | train loss {'Reaction outcome loss': 0.27437877806497146, 'Total loss': 0.27437877806497146}
2023-01-04 05:38:46,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:46,263 INFO:     Epoch: 83
2023-01-04 05:38:47,791 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38766707181930543, 'Total loss': 0.38766707181930543} | train loss {'Reaction outcome loss': 0.27421594801403226, 'Total loss': 0.27421594801403226}
2023-01-04 05:38:47,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:47,791 INFO:     Epoch: 84
2023-01-04 05:38:49,311 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.34631694356600445, 'Total loss': 0.34631694356600445} | train loss {'Reaction outcome loss': 0.2756410757755185, 'Total loss': 0.2756410757755185}
2023-01-04 05:38:49,311 INFO:     Found new best model at epoch 84
2023-01-04 05:38:49,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:49,312 INFO:     Epoch: 85
2023-01-04 05:38:50,802 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39392186999320983, 'Total loss': 0.39392186999320983} | train loss {'Reaction outcome loss': 0.2701190731082207, 'Total loss': 0.2701190731082207}
2023-01-04 05:38:50,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:50,803 INFO:     Epoch: 86
2023-01-04 05:38:52,322 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3785907040039698, 'Total loss': 0.3785907040039698} | train loss {'Reaction outcome loss': 0.27178997090666285, 'Total loss': 0.27178997090666285}
2023-01-04 05:38:52,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:52,323 INFO:     Epoch: 87
2023-01-04 05:38:53,809 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3680213501521697, 'Total loss': 0.3680213501521697} | train loss {'Reaction outcome loss': 0.27935447134486924, 'Total loss': 0.27935447134486924}
2023-01-04 05:38:53,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:53,809 INFO:     Epoch: 88
2023-01-04 05:38:55,347 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3694196239113808, 'Total loss': 0.3694196239113808} | train loss {'Reaction outcome loss': 0.2715316564936341, 'Total loss': 0.2715316564936341}
2023-01-04 05:38:55,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:55,347 INFO:     Epoch: 89
2023-01-04 05:38:56,922 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.405205225944519, 'Total loss': 0.405205225944519} | train loss {'Reaction outcome loss': 0.26962631661786046, 'Total loss': 0.26962631661786046}
2023-01-04 05:38:56,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:56,922 INFO:     Epoch: 90
2023-01-04 05:38:58,468 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36483931442101797, 'Total loss': 0.36483931442101797} | train loss {'Reaction outcome loss': 0.265080203803686, 'Total loss': 0.265080203803686}
2023-01-04 05:38:58,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:38:58,469 INFO:     Epoch: 91
2023-01-04 05:39:00,021 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3787961999575297, 'Total loss': 0.3787961999575297} | train loss {'Reaction outcome loss': 0.2670934724556657, 'Total loss': 0.2670934724556657}
2023-01-04 05:39:00,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:00,022 INFO:     Epoch: 92
2023-01-04 05:39:01,619 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35577252904574075, 'Total loss': 0.35577252904574075} | train loss {'Reaction outcome loss': 0.26516669092106293, 'Total loss': 0.26516669092106293}
2023-01-04 05:39:01,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:01,619 INFO:     Epoch: 93
2023-01-04 05:39:03,109 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.369462725520134, 'Total loss': 0.369462725520134} | train loss {'Reaction outcome loss': 0.2605881092476321, 'Total loss': 0.2605881092476321}
2023-01-04 05:39:03,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:03,110 INFO:     Epoch: 94
2023-01-04 05:39:04,646 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43535393675168355, 'Total loss': 0.43535393675168355} | train loss {'Reaction outcome loss': 0.2620351260643957, 'Total loss': 0.2620351260643957}
2023-01-04 05:39:04,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:04,647 INFO:     Epoch: 95
2023-01-04 05:39:06,195 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36815791626771294, 'Total loss': 0.36815791626771294} | train loss {'Reaction outcome loss': 0.2644100014133986, 'Total loss': 0.2644100014133986}
2023-01-04 05:39:06,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:06,195 INFO:     Epoch: 96
2023-01-04 05:39:07,737 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3704011102517446, 'Total loss': 0.3704011102517446} | train loss {'Reaction outcome loss': 0.25708062583819413, 'Total loss': 0.25708062583819413}
2023-01-04 05:39:07,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:07,737 INFO:     Epoch: 97
2023-01-04 05:39:09,258 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3628496160109838, 'Total loss': 0.3628496160109838} | train loss {'Reaction outcome loss': 0.26024408586623465, 'Total loss': 0.26024408586623465}
2023-01-04 05:39:09,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:09,258 INFO:     Epoch: 98
2023-01-04 05:39:10,847 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38594288726647696, 'Total loss': 0.38594288726647696} | train loss {'Reaction outcome loss': 0.2586433558073236, 'Total loss': 0.2586433558073236}
2023-01-04 05:39:10,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:10,847 INFO:     Epoch: 99
2023-01-04 05:39:12,386 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3505815996478001, 'Total loss': 0.3505815996478001} | train loss {'Reaction outcome loss': 0.2618414843284385, 'Total loss': 0.2618414843284385}
2023-01-04 05:39:12,386 INFO:     Best model found after epoch 85 of 100.
2023-01-04 05:39:12,386 INFO:   Done with stage: TRAINING
2023-01-04 05:39:12,386 INFO:   Starting stage: EVALUATION
2023-01-04 05:39:12,527 INFO:   Done with stage: EVALUATION
2023-01-04 05:39:12,527 INFO:   Leaving out SEQ value Fold_1
2023-01-04 05:39:12,540 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 05:39:12,540 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:39:13,203 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:39:13,203 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:39:13,273 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:39:13,273 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:39:13,273 INFO:     No hyperparam tuning for this model
2023-01-04 05:39:13,273 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:39:13,273 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:39:13,274 INFO:     None feature selector for col prot
2023-01-04 05:39:13,274 INFO:     None feature selector for col prot
2023-01-04 05:39:13,274 INFO:     None feature selector for col prot
2023-01-04 05:39:13,275 INFO:     None feature selector for col chem
2023-01-04 05:39:13,275 INFO:     None feature selector for col chem
2023-01-04 05:39:13,275 INFO:     None feature selector for col chem
2023-01-04 05:39:13,275 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:39:13,275 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:39:13,276 INFO:     Number of params in model 70111
2023-01-04 05:39:13,279 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:39:13,279 INFO:   Starting stage: TRAINING
2023-01-04 05:39:13,322 INFO:     Val loss before train {'Reaction outcome loss': 1.0540681958198548, 'Total loss': 1.0540681958198548}
2023-01-04 05:39:13,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:13,322 INFO:     Epoch: 0
2023-01-04 05:39:14,909 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.772853285074234, 'Total loss': 0.772853285074234} | train loss {'Reaction outcome loss': 0.8513838564572127, 'Total loss': 0.8513838564572127}
2023-01-04 05:39:14,909 INFO:     Found new best model at epoch 0
2023-01-04 05:39:14,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:14,910 INFO:     Epoch: 1
2023-01-04 05:39:16,515 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6728868067264557, 'Total loss': 0.6728868067264557} | train loss {'Reaction outcome loss': 0.6890094444337909, 'Total loss': 0.6890094444337909}
2023-01-04 05:39:16,515 INFO:     Found new best model at epoch 1
2023-01-04 05:39:16,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:16,516 INFO:     Epoch: 2
2023-01-04 05:39:18,085 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6375233809153239, 'Total loss': 0.6375233809153239} | train loss {'Reaction outcome loss': 0.6013367529958487, 'Total loss': 0.6013367529958487}
2023-01-04 05:39:18,086 INFO:     Found new best model at epoch 2
2023-01-04 05:39:18,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:18,087 INFO:     Epoch: 3
2023-01-04 05:39:19,696 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6046926498413085, 'Total loss': 0.6046926498413085} | train loss {'Reaction outcome loss': 0.5583373832421891, 'Total loss': 0.5583373832421891}
2023-01-04 05:39:19,696 INFO:     Found new best model at epoch 3
2023-01-04 05:39:19,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:19,697 INFO:     Epoch: 4
2023-01-04 05:39:21,255 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6221696654955546, 'Total loss': 0.6221696654955546} | train loss {'Reaction outcome loss': 0.5274076262401228, 'Total loss': 0.5274076262401228}
2023-01-04 05:39:21,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:21,255 INFO:     Epoch: 5
2023-01-04 05:39:22,857 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5909961938858033, 'Total loss': 0.5909961938858033} | train loss {'Reaction outcome loss': 0.5067907926707488, 'Total loss': 0.5067907926707488}
2023-01-04 05:39:22,857 INFO:     Found new best model at epoch 5
2023-01-04 05:39:22,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:22,858 INFO:     Epoch: 6
2023-01-04 05:39:24,464 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5916870752970378, 'Total loss': 0.5916870752970378} | train loss {'Reaction outcome loss': 0.49166132582425803, 'Total loss': 0.49166132582425803}
2023-01-04 05:39:24,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:24,464 INFO:     Epoch: 7
2023-01-04 05:39:26,064 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5777338922023774, 'Total loss': 0.5777338922023774} | train loss {'Reaction outcome loss': 0.48187837335707084, 'Total loss': 0.48187837335707084}
2023-01-04 05:39:26,064 INFO:     Found new best model at epoch 7
2023-01-04 05:39:26,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:26,065 INFO:     Epoch: 8
2023-01-04 05:39:27,614 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.582910293340683, 'Total loss': 0.582910293340683} | train loss {'Reaction outcome loss': 0.472485159673944, 'Total loss': 0.472485159673944}
2023-01-04 05:39:27,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:27,614 INFO:     Epoch: 9
2023-01-04 05:39:29,185 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.569957822561264, 'Total loss': 0.569957822561264} | train loss {'Reaction outcome loss': 0.4687147664743057, 'Total loss': 0.4687147664743057}
2023-01-04 05:39:29,185 INFO:     Found new best model at epoch 9
2023-01-04 05:39:29,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:29,186 INFO:     Epoch: 10
2023-01-04 05:39:30,764 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5617789149284362, 'Total loss': 0.5617789149284362} | train loss {'Reaction outcome loss': 0.46531625696714374, 'Total loss': 0.46531625696714374}
2023-01-04 05:39:30,764 INFO:     Found new best model at epoch 10
2023-01-04 05:39:30,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:30,765 INFO:     Epoch: 11
2023-01-04 05:39:32,348 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5904366155465444, 'Total loss': 0.5904366155465444} | train loss {'Reaction outcome loss': 0.455595394129109, 'Total loss': 0.455595394129109}
2023-01-04 05:39:32,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:32,349 INFO:     Epoch: 12
2023-01-04 05:39:33,929 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5482284625371298, 'Total loss': 0.5482284625371298} | train loss {'Reaction outcome loss': 0.44589007509521383, 'Total loss': 0.44589007509521383}
2023-01-04 05:39:33,929 INFO:     Found new best model at epoch 12
2023-01-04 05:39:33,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:33,930 INFO:     Epoch: 13
2023-01-04 05:39:35,505 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.598234224319458, 'Total loss': 0.598234224319458} | train loss {'Reaction outcome loss': 0.443656497027563, 'Total loss': 0.443656497027563}
2023-01-04 05:39:35,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:35,505 INFO:     Epoch: 14
2023-01-04 05:39:37,068 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5690015256404877, 'Total loss': 0.5690015256404877} | train loss {'Reaction outcome loss': 0.44827651167693344, 'Total loss': 0.44827651167693344}
2023-01-04 05:39:37,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:37,069 INFO:     Epoch: 15
2023-01-04 05:39:38,606 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5481727103392283, 'Total loss': 0.5481727103392283} | train loss {'Reaction outcome loss': 0.4335161108267156, 'Total loss': 0.4335161108267156}
2023-01-04 05:39:38,606 INFO:     Found new best model at epoch 15
2023-01-04 05:39:38,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:38,607 INFO:     Epoch: 16
2023-01-04 05:39:40,178 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5515936613082886, 'Total loss': 0.5515936613082886} | train loss {'Reaction outcome loss': 0.4279859923366187, 'Total loss': 0.4279859923366187}
2023-01-04 05:39:40,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:40,179 INFO:     Epoch: 17
2023-01-04 05:39:41,751 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5557834664980571, 'Total loss': 0.5557834664980571} | train loss {'Reaction outcome loss': 0.4233988694563184, 'Total loss': 0.4233988694563184}
2023-01-04 05:39:41,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:41,752 INFO:     Epoch: 18
2023-01-04 05:39:43,337 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5385003010431926, 'Total loss': 0.5385003010431926} | train loss {'Reaction outcome loss': 0.41955604485195613, 'Total loss': 0.41955604485195613}
2023-01-04 05:39:43,337 INFO:     Found new best model at epoch 18
2023-01-04 05:39:43,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:43,338 INFO:     Epoch: 19
2023-01-04 05:39:44,868 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.559595376253128, 'Total loss': 0.559595376253128} | train loss {'Reaction outcome loss': 0.42196929351041984, 'Total loss': 0.42196929351041984}
2023-01-04 05:39:44,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:44,868 INFO:     Epoch: 20
2023-01-04 05:39:46,448 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.526670390367508, 'Total loss': 0.526670390367508} | train loss {'Reaction outcome loss': 0.41287045574922493, 'Total loss': 0.41287045574922493}
2023-01-04 05:39:46,449 INFO:     Found new best model at epoch 20
2023-01-04 05:39:46,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:46,449 INFO:     Epoch: 21
2023-01-04 05:39:47,986 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5172553936640422, 'Total loss': 0.5172553936640422} | train loss {'Reaction outcome loss': 0.4093503392943234, 'Total loss': 0.4093503392943234}
2023-01-04 05:39:47,986 INFO:     Found new best model at epoch 21
2023-01-04 05:39:47,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:47,987 INFO:     Epoch: 22
2023-01-04 05:39:49,556 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5301466166973114, 'Total loss': 0.5301466166973114} | train loss {'Reaction outcome loss': 0.4055062654171733, 'Total loss': 0.4055062654171733}
2023-01-04 05:39:49,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:49,557 INFO:     Epoch: 23
2023-01-04 05:39:51,139 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5413252154986063, 'Total loss': 0.5413252154986063} | train loss {'Reaction outcome loss': 0.4099391314962238, 'Total loss': 0.4099391314962238}
2023-01-04 05:39:51,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:51,139 INFO:     Epoch: 24
2023-01-04 05:39:52,716 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5481058895587921, 'Total loss': 0.5481058895587921} | train loss {'Reaction outcome loss': 0.39542773466066294, 'Total loss': 0.39542773466066294}
2023-01-04 05:39:52,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:52,717 INFO:     Epoch: 25
2023-01-04 05:39:54,260 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5122709333896637, 'Total loss': 0.5122709333896637} | train loss {'Reaction outcome loss': 0.39219843292393425, 'Total loss': 0.39219843292393425}
2023-01-04 05:39:54,261 INFO:     Found new best model at epoch 25
2023-01-04 05:39:54,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:54,261 INFO:     Epoch: 26
2023-01-04 05:39:55,832 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49888779123624166, 'Total loss': 0.49888779123624166} | train loss {'Reaction outcome loss': 0.38975902189878214, 'Total loss': 0.38975902189878214}
2023-01-04 05:39:55,832 INFO:     Found new best model at epoch 26
2023-01-04 05:39:55,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:55,833 INFO:     Epoch: 27
2023-01-04 05:39:57,125 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5169834156831106, 'Total loss': 0.5169834156831106} | train loss {'Reaction outcome loss': 0.3846215082136779, 'Total loss': 0.3846215082136779}
2023-01-04 05:39:57,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:57,125 INFO:     Epoch: 28
2023-01-04 05:39:58,157 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5125735481580098, 'Total loss': 0.5125735481580098} | train loss {'Reaction outcome loss': 0.37988005592605856, 'Total loss': 0.37988005592605856}
2023-01-04 05:39:58,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:58,158 INFO:     Epoch: 29
2023-01-04 05:39:59,184 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5057275662819545, 'Total loss': 0.5057275662819545} | train loss {'Reaction outcome loss': 0.3759882511415829, 'Total loss': 0.3759882511415829}
2023-01-04 05:39:59,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:39:59,185 INFO:     Epoch: 30
2023-01-04 05:40:00,212 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5278027971585592, 'Total loss': 0.5278027971585592} | train loss {'Reaction outcome loss': 0.37140363044686703, 'Total loss': 0.37140363044686703}
2023-01-04 05:40:00,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:00,212 INFO:     Epoch: 31
2023-01-04 05:40:01,500 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5055067976315816, 'Total loss': 0.5055067976315816} | train loss {'Reaction outcome loss': 0.37117823569670966, 'Total loss': 0.37117823569670966}
2023-01-04 05:40:01,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:01,500 INFO:     Epoch: 32
2023-01-04 05:40:03,044 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5138010263442994, 'Total loss': 0.5138010263442994} | train loss {'Reaction outcome loss': 0.3713869322631238, 'Total loss': 0.3713869322631238}
2023-01-04 05:40:03,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:03,044 INFO:     Epoch: 33
2023-01-04 05:40:04,595 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5246242403984069, 'Total loss': 0.5246242403984069} | train loss {'Reaction outcome loss': 0.37313104679228476, 'Total loss': 0.37313104679228476}
2023-01-04 05:40:04,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:04,595 INFO:     Epoch: 34
2023-01-04 05:40:06,159 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4814431389172872, 'Total loss': 0.4814431389172872} | train loss {'Reaction outcome loss': 0.3610910530766452, 'Total loss': 0.3610910530766452}
2023-01-04 05:40:06,159 INFO:     Found new best model at epoch 34
2023-01-04 05:40:06,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:06,160 INFO:     Epoch: 35
2023-01-04 05:40:07,718 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5011503199736277, 'Total loss': 0.5011503199736277} | train loss {'Reaction outcome loss': 0.3543233833312853, 'Total loss': 0.3543233833312853}
2023-01-04 05:40:07,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:07,718 INFO:     Epoch: 36
2023-01-04 05:40:09,274 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47651800165573754, 'Total loss': 0.47651800165573754} | train loss {'Reaction outcome loss': 0.3533724897548856, 'Total loss': 0.3533724897548856}
2023-01-04 05:40:09,274 INFO:     Found new best model at epoch 36
2023-01-04 05:40:09,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:09,275 INFO:     Epoch: 37
2023-01-04 05:40:10,759 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.506906924645106, 'Total loss': 0.506906924645106} | train loss {'Reaction outcome loss': 0.351290721893378, 'Total loss': 0.351290721893378}
2023-01-04 05:40:10,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:10,760 INFO:     Epoch: 38
2023-01-04 05:40:12,316 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4951476852099101, 'Total loss': 0.4951476852099101} | train loss {'Reaction outcome loss': 0.3498589683617668, 'Total loss': 0.3498589683617668}
2023-01-04 05:40:12,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:12,316 INFO:     Epoch: 39
2023-01-04 05:40:13,879 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5005327979723613, 'Total loss': 0.5005327979723613} | train loss {'Reaction outcome loss': 0.3444528921196858, 'Total loss': 0.3444528921196858}
2023-01-04 05:40:13,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:13,880 INFO:     Epoch: 40
2023-01-04 05:40:15,446 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5079867124557496, 'Total loss': 0.5079867124557496} | train loss {'Reaction outcome loss': 0.34213918007478333, 'Total loss': 0.34213918007478333}
2023-01-04 05:40:15,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:15,446 INFO:     Epoch: 41
2023-01-04 05:40:17,019 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5350777645905812, 'Total loss': 0.5350777645905812} | train loss {'Reaction outcome loss': 0.3554246747677309, 'Total loss': 0.3554246747677309}
2023-01-04 05:40:17,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:17,019 INFO:     Epoch: 42
2023-01-04 05:40:18,553 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4948265631993612, 'Total loss': 0.4948265631993612} | train loss {'Reaction outcome loss': 0.3841471895204344, 'Total loss': 0.3841471895204344}
2023-01-04 05:40:18,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:18,553 INFO:     Epoch: 43
2023-01-04 05:40:20,083 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4959232230981191, 'Total loss': 0.4959232230981191} | train loss {'Reaction outcome loss': 0.34701339973379736, 'Total loss': 0.34701339973379736}
2023-01-04 05:40:20,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:20,083 INFO:     Epoch: 44
2023-01-04 05:40:21,653 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47145928839842477, 'Total loss': 0.47145928839842477} | train loss {'Reaction outcome loss': 0.34798995991223963, 'Total loss': 0.34798995991223963}
2023-01-04 05:40:21,653 INFO:     Found new best model at epoch 44
2023-01-04 05:40:21,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:21,654 INFO:     Epoch: 45
2023-01-04 05:40:23,235 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49677169919013975, 'Total loss': 0.49677169919013975} | train loss {'Reaction outcome loss': 0.3480503627881948, 'Total loss': 0.3480503627881948}
2023-01-04 05:40:23,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:23,235 INFO:     Epoch: 46
2023-01-04 05:40:24,813 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4899563272794088, 'Total loss': 0.4899563272794088} | train loss {'Reaction outcome loss': 0.338080665393584, 'Total loss': 0.338080665393584}
2023-01-04 05:40:24,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:24,813 INFO:     Epoch: 47
2023-01-04 05:40:26,378 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48217800358931223, 'Total loss': 0.48217800358931223} | train loss {'Reaction outcome loss': 0.33833866533857054, 'Total loss': 0.33833866533857054}
2023-01-04 05:40:26,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:26,378 INFO:     Epoch: 48
2023-01-04 05:40:27,918 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5005703330039978, 'Total loss': 0.5005703330039978} | train loss {'Reaction outcome loss': 0.32761241425422655, 'Total loss': 0.32761241425422655}
2023-01-04 05:40:27,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:27,918 INFO:     Epoch: 49
2023-01-04 05:40:29,440 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4607482314109802, 'Total loss': 0.4607482314109802} | train loss {'Reaction outcome loss': 0.3272822427721964, 'Total loss': 0.3272822427721964}
2023-01-04 05:40:29,441 INFO:     Found new best model at epoch 49
2023-01-04 05:40:29,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:29,442 INFO:     Epoch: 50
2023-01-04 05:40:31,017 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4931536724170049, 'Total loss': 0.4931536724170049} | train loss {'Reaction outcome loss': 0.3204900324344635, 'Total loss': 0.3204900324344635}
2023-01-04 05:40:31,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:31,017 INFO:     Epoch: 51
2023-01-04 05:40:32,576 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47218047579129535, 'Total loss': 0.47218047579129535} | train loss {'Reaction outcome loss': 0.32955359855913086, 'Total loss': 0.32955359855913086}
2023-01-04 05:40:32,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:32,576 INFO:     Epoch: 52
2023-01-04 05:40:34,154 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47665180762608844, 'Total loss': 0.47665180762608844} | train loss {'Reaction outcome loss': 0.3162146677327194, 'Total loss': 0.3162146677327194}
2023-01-04 05:40:34,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:34,154 INFO:     Epoch: 53
2023-01-04 05:40:35,725 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4629101266463598, 'Total loss': 0.4629101266463598} | train loss {'Reaction outcome loss': 0.31698051542575145, 'Total loss': 0.31698051542575145}
2023-01-04 05:40:35,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:35,726 INFO:     Epoch: 54
2023-01-04 05:40:37,220 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47396693428357445, 'Total loss': 0.47396693428357445} | train loss {'Reaction outcome loss': 0.3132703674795187, 'Total loss': 0.3132703674795187}
2023-01-04 05:40:37,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:37,220 INFO:     Epoch: 55
2023-01-04 05:40:38,787 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49054590066274006, 'Total loss': 0.49054590066274006} | train loss {'Reaction outcome loss': 0.31059736592452164, 'Total loss': 0.31059736592452164}
2023-01-04 05:40:38,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:38,787 INFO:     Epoch: 56
2023-01-04 05:40:40,337 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4705531656742096, 'Total loss': 0.4705531656742096} | train loss {'Reaction outcome loss': 0.30857887233547, 'Total loss': 0.30857887233547}
2023-01-04 05:40:40,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:40,337 INFO:     Epoch: 57
2023-01-04 05:40:41,888 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4592672367890676, 'Total loss': 0.4592672367890676} | train loss {'Reaction outcome loss': 0.3070314906105615, 'Total loss': 0.3070314906105615}
2023-01-04 05:40:41,888 INFO:     Found new best model at epoch 57
2023-01-04 05:40:41,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:41,889 INFO:     Epoch: 58
2023-01-04 05:40:43,435 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46942151387532555, 'Total loss': 0.46942151387532555} | train loss {'Reaction outcome loss': 0.3034220095293637, 'Total loss': 0.3034220095293637}
2023-01-04 05:40:43,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:43,435 INFO:     Epoch: 59
2023-01-04 05:40:44,967 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.462215135494868, 'Total loss': 0.462215135494868} | train loss {'Reaction outcome loss': 0.3025209392164496, 'Total loss': 0.3025209392164496}
2023-01-04 05:40:44,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:44,967 INFO:     Epoch: 60
2023-01-04 05:40:46,447 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4821161071459452, 'Total loss': 0.4821161071459452} | train loss {'Reaction outcome loss': 0.30610300227999687, 'Total loss': 0.30610300227999687}
2023-01-04 05:40:46,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:46,447 INFO:     Epoch: 61
2023-01-04 05:40:47,994 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47738422056039176, 'Total loss': 0.47738422056039176} | train loss {'Reaction outcome loss': 0.3091468030343885, 'Total loss': 0.3091468030343885}
2023-01-04 05:40:47,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:47,995 INFO:     Epoch: 62
2023-01-04 05:40:49,541 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4905917108058929, 'Total loss': 0.4905917108058929} | train loss {'Reaction outcome loss': 0.33418639169320924, 'Total loss': 0.33418639169320924}
2023-01-04 05:40:49,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:49,541 INFO:     Epoch: 63
2023-01-04 05:40:51,092 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4924395193656286, 'Total loss': 0.4924395193656286} | train loss {'Reaction outcome loss': 0.3001450676524985, 'Total loss': 0.3001450676524985}
2023-01-04 05:40:51,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:51,092 INFO:     Epoch: 64
2023-01-04 05:40:52,635 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5003540178140005, 'Total loss': 0.5003540178140005} | train loss {'Reaction outcome loss': 0.2960392231660713, 'Total loss': 0.2960392231660713}
2023-01-04 05:40:52,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:52,635 INFO:     Epoch: 65
2023-01-04 05:40:54,200 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45033607482910154, 'Total loss': 0.45033607482910154} | train loss {'Reaction outcome loss': 0.29105852855375985, 'Total loss': 0.29105852855375985}
2023-01-04 05:40:54,201 INFO:     Found new best model at epoch 65
2023-01-04 05:40:54,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:54,201 INFO:     Epoch: 66
2023-01-04 05:40:55,692 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4808044691880544, 'Total loss': 0.4808044691880544} | train loss {'Reaction outcome loss': 0.2881635076963626, 'Total loss': 0.2881635076963626}
2023-01-04 05:40:55,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:55,692 INFO:     Epoch: 67
2023-01-04 05:40:57,246 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48411920070648196, 'Total loss': 0.48411920070648196} | train loss {'Reaction outcome loss': 0.2879839409277707, 'Total loss': 0.2879839409277707}
2023-01-04 05:40:57,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:57,246 INFO:     Epoch: 68
2023-01-04 05:40:58,823 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4685331076383591, 'Total loss': 0.4685331076383591} | train loss {'Reaction outcome loss': 0.2931260685233966, 'Total loss': 0.2931260685233966}
2023-01-04 05:40:58,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:40:58,823 INFO:     Epoch: 69
2023-01-04 05:41:00,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4688238203525543, 'Total loss': 0.4688238203525543} | train loss {'Reaction outcome loss': 0.28989500320260075, 'Total loss': 0.28989500320260075}
2023-01-04 05:41:00,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:00,382 INFO:     Epoch: 70
2023-01-04 05:41:01,921 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4786236067612966, 'Total loss': 0.4786236067612966} | train loss {'Reaction outcome loss': 0.30446189982256433, 'Total loss': 0.30446189982256433}
2023-01-04 05:41:01,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:01,921 INFO:     Epoch: 71
2023-01-04 05:41:03,481 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49433887799580895, 'Total loss': 0.49433887799580895} | train loss {'Reaction outcome loss': 0.2885846941853347, 'Total loss': 0.2885846941853347}
2023-01-04 05:41:03,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:03,481 INFO:     Epoch: 72
2023-01-04 05:41:04,974 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46067990859349567, 'Total loss': 0.46067990859349567} | train loss {'Reaction outcome loss': 0.28432415745497774, 'Total loss': 0.28432415745497774}
2023-01-04 05:41:04,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:04,975 INFO:     Epoch: 73
2023-01-04 05:41:06,518 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4484261612097422, 'Total loss': 0.4484261612097422} | train loss {'Reaction outcome loss': 0.28616623356398463, 'Total loss': 0.28616623356398463}
2023-01-04 05:41:06,518 INFO:     Found new best model at epoch 73
2023-01-04 05:41:06,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:06,519 INFO:     Epoch: 74
2023-01-04 05:41:08,067 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4347854971885681, 'Total loss': 0.4347854971885681} | train loss {'Reaction outcome loss': 0.28146768987948156, 'Total loss': 0.28146768987948156}
2023-01-04 05:41:08,067 INFO:     Found new best model at epoch 74
2023-01-04 05:41:08,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:08,068 INFO:     Epoch: 75
2023-01-04 05:41:09,615 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44904700517654417, 'Total loss': 0.44904700517654417} | train loss {'Reaction outcome loss': 0.28829009266759176, 'Total loss': 0.28829009266759176}
2023-01-04 05:41:09,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:09,616 INFO:     Epoch: 76
2023-01-04 05:41:11,177 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.490020485719045, 'Total loss': 0.490020485719045} | train loss {'Reaction outcome loss': 0.30945106549863366, 'Total loss': 0.30945106549863366}
2023-01-04 05:41:11,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:11,178 INFO:     Epoch: 77
2023-01-04 05:41:12,734 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4245557924111684, 'Total loss': 0.4245557924111684} | train loss {'Reaction outcome loss': 0.28465779023531795, 'Total loss': 0.28465779023531795}
2023-01-04 05:41:12,734 INFO:     Found new best model at epoch 77
2023-01-04 05:41:12,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:12,735 INFO:     Epoch: 78
2023-01-04 05:41:14,228 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.447396261493365, 'Total loss': 0.447396261493365} | train loss {'Reaction outcome loss': 0.28018883701588493, 'Total loss': 0.28018883701588493}
2023-01-04 05:41:14,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:14,228 INFO:     Epoch: 79
2023-01-04 05:41:15,826 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48722772002220155, 'Total loss': 0.48722772002220155} | train loss {'Reaction outcome loss': 0.27588329288730584, 'Total loss': 0.27588329288730584}
2023-01-04 05:41:15,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:15,826 INFO:     Epoch: 80
2023-01-04 05:41:17,375 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5245711535215378, 'Total loss': 0.5245711535215378} | train loss {'Reaction outcome loss': 0.2857310113267622, 'Total loss': 0.2857310113267622}
2023-01-04 05:41:17,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:17,375 INFO:     Epoch: 81
2023-01-04 05:41:18,926 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4696320414543152, 'Total loss': 0.4696320414543152} | train loss {'Reaction outcome loss': 0.3496544047257107, 'Total loss': 0.3496544047257107}
2023-01-04 05:41:18,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:18,927 INFO:     Epoch: 82
2023-01-04 05:41:20,492 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4485557119051615, 'Total loss': 0.4485557119051615} | train loss {'Reaction outcome loss': 0.2804050883181238, 'Total loss': 0.2804050883181238}
2023-01-04 05:41:20,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:20,492 INFO:     Epoch: 83
2023-01-04 05:41:22,031 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46338822642962135, 'Total loss': 0.46338822642962135} | train loss {'Reaction outcome loss': 0.2769320614946385, 'Total loss': 0.2769320614946385}
2023-01-04 05:41:22,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:22,031 INFO:     Epoch: 84
2023-01-04 05:41:23,526 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4493559127052625, 'Total loss': 0.4493559127052625} | train loss {'Reaction outcome loss': 0.2760655388937912, 'Total loss': 0.2760655388937912}
2023-01-04 05:41:23,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:23,526 INFO:     Epoch: 85
2023-01-04 05:41:25,079 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47135966767867404, 'Total loss': 0.47135966767867404} | train loss {'Reaction outcome loss': 0.27207448235814174, 'Total loss': 0.27207448235814174}
2023-01-04 05:41:25,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:25,079 INFO:     Epoch: 86
2023-01-04 05:41:26,654 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45768733819325763, 'Total loss': 0.45768733819325763} | train loss {'Reaction outcome loss': 0.27162910383734584, 'Total loss': 0.27162910383734584}
2023-01-04 05:41:26,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:26,655 INFO:     Epoch: 87
2023-01-04 05:41:28,198 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45870108107725777, 'Total loss': 0.45870108107725777} | train loss {'Reaction outcome loss': 0.30819763559038227, 'Total loss': 0.30819763559038227}
2023-01-04 05:41:28,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:28,198 INFO:     Epoch: 88
2023-01-04 05:41:29,738 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4620286444822947, 'Total loss': 0.4620286444822947} | train loss {'Reaction outcome loss': 0.2922500742348822, 'Total loss': 0.2922500742348822}
2023-01-04 05:41:29,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:29,738 INFO:     Epoch: 89
2023-01-04 05:41:31,253 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46758535703023274, 'Total loss': 0.46758535703023274} | train loss {'Reaction outcome loss': 0.26901170071484387, 'Total loss': 0.26901170071484387}
2023-01-04 05:41:31,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:31,254 INFO:     Epoch: 90
2023-01-04 05:41:32,777 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4557177245616913, 'Total loss': 0.4557177245616913} | train loss {'Reaction outcome loss': 0.2696682522326465, 'Total loss': 0.2696682522326465}
2023-01-04 05:41:32,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:32,778 INFO:     Epoch: 91
2023-01-04 05:41:34,322 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46782300372918445, 'Total loss': 0.46782300372918445} | train loss {'Reaction outcome loss': 0.2692393431435956, 'Total loss': 0.2692393431435956}
2023-01-04 05:41:34,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:34,323 INFO:     Epoch: 92
2023-01-04 05:41:35,862 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.457391756772995, 'Total loss': 0.457391756772995} | train loss {'Reaction outcome loss': 0.2611178844387684, 'Total loss': 0.2611178844387684}
2023-01-04 05:41:35,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:35,863 INFO:     Epoch: 93
2023-01-04 05:41:37,415 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47928595542907715, 'Total loss': 0.47928595542907715} | train loss {'Reaction outcome loss': 0.26462060493645695, 'Total loss': 0.26462060493645695}
2023-01-04 05:41:37,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:37,415 INFO:     Epoch: 94
2023-01-04 05:41:38,966 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5110341360171636, 'Total loss': 0.5110341360171636} | train loss {'Reaction outcome loss': 0.267631934415819, 'Total loss': 0.267631934415819}
2023-01-04 05:41:38,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:38,966 INFO:     Epoch: 95
2023-01-04 05:41:40,494 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46847096880277, 'Total loss': 0.46847096880277} | train loss {'Reaction outcome loss': 0.2810829375913549, 'Total loss': 0.2810829375913549}
2023-01-04 05:41:40,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:40,494 INFO:     Epoch: 96
2023-01-04 05:41:42,009 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4559271593888601, 'Total loss': 0.4559271593888601} | train loss {'Reaction outcome loss': 0.26487580032182345, 'Total loss': 0.26487580032182345}
2023-01-04 05:41:42,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:42,010 INFO:     Epoch: 97
2023-01-04 05:41:43,557 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4751424898703893, 'Total loss': 0.4751424898703893} | train loss {'Reaction outcome loss': 0.2601537801986168, 'Total loss': 0.2601537801986168}
2023-01-04 05:41:43,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:43,557 INFO:     Epoch: 98
2023-01-04 05:41:45,094 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45625646114349366, 'Total loss': 0.45625646114349366} | train loss {'Reaction outcome loss': 0.26346367788410396, 'Total loss': 0.26346367788410396}
2023-01-04 05:41:45,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:45,094 INFO:     Epoch: 99
2023-01-04 05:41:46,647 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48913434743881223, 'Total loss': 0.48913434743881223} | train loss {'Reaction outcome loss': 0.2617701012206743, 'Total loss': 0.2617701012206743}
2023-01-04 05:41:46,647 INFO:     Best model found after epoch 78 of 100.
2023-01-04 05:41:46,647 INFO:   Done with stage: TRAINING
2023-01-04 05:41:46,647 INFO:   Starting stage: EVALUATION
2023-01-04 05:41:46,774 INFO:   Done with stage: EVALUATION
2023-01-04 05:41:46,774 INFO:   Leaving out SEQ value Fold_2
2023-01-04 05:41:46,787 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 05:41:46,787 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:41:47,436 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:41:47,436 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:41:47,506 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:41:47,507 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:41:47,507 INFO:     No hyperparam tuning for this model
2023-01-04 05:41:47,507 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:41:47,507 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:41:47,507 INFO:     None feature selector for col prot
2023-01-04 05:41:47,508 INFO:     None feature selector for col prot
2023-01-04 05:41:47,508 INFO:     None feature selector for col prot
2023-01-04 05:41:47,508 INFO:     None feature selector for col chem
2023-01-04 05:41:47,508 INFO:     None feature selector for col chem
2023-01-04 05:41:47,508 INFO:     None feature selector for col chem
2023-01-04 05:41:47,508 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:41:47,508 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:41:47,509 INFO:     Number of params in model 70111
2023-01-04 05:41:47,512 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:41:47,513 INFO:   Starting stage: TRAINING
2023-01-04 05:41:47,555 INFO:     Val loss before train {'Reaction outcome loss': 0.934474770228068, 'Total loss': 0.934474770228068}
2023-01-04 05:41:47,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:47,555 INFO:     Epoch: 0
2023-01-04 05:41:49,064 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6634881575902303, 'Total loss': 0.6634881575902303} | train loss {'Reaction outcome loss': 0.8407163364391257, 'Total loss': 0.8407163364391257}
2023-01-04 05:41:49,064 INFO:     Found new best model at epoch 0
2023-01-04 05:41:49,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:49,065 INFO:     Epoch: 1
2023-01-04 05:41:50,570 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5608906745910645, 'Total loss': 0.5608906745910645} | train loss {'Reaction outcome loss': 0.6806052231440579, 'Total loss': 0.6806052231440579}
2023-01-04 05:41:50,571 INFO:     Found new best model at epoch 1
2023-01-04 05:41:50,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:50,571 INFO:     Epoch: 2
2023-01-04 05:41:52,106 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5045334080855052, 'Total loss': 0.5045334080855052} | train loss {'Reaction outcome loss': 0.5839591188913714, 'Total loss': 0.5839591188913714}
2023-01-04 05:41:52,106 INFO:     Found new best model at epoch 2
2023-01-04 05:41:52,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:52,107 INFO:     Epoch: 3
2023-01-04 05:41:53,640 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47090586721897126, 'Total loss': 0.47090586721897126} | train loss {'Reaction outcome loss': 0.5384518787482359, 'Total loss': 0.5384518787482359}
2023-01-04 05:41:53,640 INFO:     Found new best model at epoch 3
2023-01-04 05:41:53,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:53,641 INFO:     Epoch: 4
2023-01-04 05:41:55,179 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47763328154881796, 'Total loss': 0.47763328154881796} | train loss {'Reaction outcome loss': 0.5160143015375973, 'Total loss': 0.5160143015375973}
2023-01-04 05:41:55,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:55,180 INFO:     Epoch: 5
2023-01-04 05:41:56,713 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45184644460678103, 'Total loss': 0.45184644460678103} | train loss {'Reaction outcome loss': 0.5004706510009557, 'Total loss': 0.5004706510009557}
2023-01-04 05:41:56,713 INFO:     Found new best model at epoch 5
2023-01-04 05:41:56,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:56,714 INFO:     Epoch: 6
2023-01-04 05:41:58,213 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46025427083174386, 'Total loss': 0.46025427083174386} | train loss {'Reaction outcome loss': 0.4917130105904419, 'Total loss': 0.4917130105904419}
2023-01-04 05:41:58,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:58,213 INFO:     Epoch: 7
2023-01-04 05:41:59,744 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4125029742717743, 'Total loss': 0.4125029742717743} | train loss {'Reaction outcome loss': 0.47912395680255265, 'Total loss': 0.47912395680255265}
2023-01-04 05:41:59,744 INFO:     Found new best model at epoch 7
2023-01-04 05:41:59,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:41:59,744 INFO:     Epoch: 8
2023-01-04 05:42:01,281 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4256738394498825, 'Total loss': 0.4256738394498825} | train loss {'Reaction outcome loss': 0.4691596890453005, 'Total loss': 0.4691596890453005}
2023-01-04 05:42:01,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:01,281 INFO:     Epoch: 9
2023-01-04 05:42:02,824 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4353253602981567, 'Total loss': 0.4353253602981567} | train loss {'Reaction outcome loss': 0.46469326975354314, 'Total loss': 0.46469326975354314}
2023-01-04 05:42:02,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:02,825 INFO:     Epoch: 10
2023-01-04 05:42:04,384 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44355720082918804, 'Total loss': 0.44355720082918804} | train loss {'Reaction outcome loss': 0.45705056614684364, 'Total loss': 0.45705056614684364}
2023-01-04 05:42:04,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:04,384 INFO:     Epoch: 11
2023-01-04 05:42:05,960 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4077745219071706, 'Total loss': 0.4077745219071706} | train loss {'Reaction outcome loss': 0.45308559839307827, 'Total loss': 0.45308559839307827}
2023-01-04 05:42:05,961 INFO:     Found new best model at epoch 11
2023-01-04 05:42:05,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:05,962 INFO:     Epoch: 12
2023-01-04 05:42:07,465 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3913075308005015, 'Total loss': 0.3913075308005015} | train loss {'Reaction outcome loss': 0.44588754804682557, 'Total loss': 0.44588754804682557}
2023-01-04 05:42:07,465 INFO:     Found new best model at epoch 12
2023-01-04 05:42:07,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:07,466 INFO:     Epoch: 13
2023-01-04 05:42:09,027 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39778760969638827, 'Total loss': 0.39778760969638827} | train loss {'Reaction outcome loss': 0.44168518606002316, 'Total loss': 0.44168518606002316}
2023-01-04 05:42:09,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:09,027 INFO:     Epoch: 14
2023-01-04 05:42:10,575 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39436489542325337, 'Total loss': 0.39436489542325337} | train loss {'Reaction outcome loss': 0.4376527982471633, 'Total loss': 0.4376527982471633}
2023-01-04 05:42:10,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:10,576 INFO:     Epoch: 15
2023-01-04 05:42:12,137 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40857035319010415, 'Total loss': 0.40857035319010415} | train loss {'Reaction outcome loss': 0.4323275125701062, 'Total loss': 0.4323275125701062}
2023-01-04 05:42:12,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:12,138 INFO:     Epoch: 16
2023-01-04 05:42:13,669 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39028255740801493, 'Total loss': 0.39028255740801493} | train loss {'Reaction outcome loss': 0.42860576923746263, 'Total loss': 0.42860576923746263}
2023-01-04 05:42:13,669 INFO:     Found new best model at epoch 16
2023-01-04 05:42:13,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:13,670 INFO:     Epoch: 17
2023-01-04 05:42:15,211 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39983123938242593, 'Total loss': 0.39983123938242593} | train loss {'Reaction outcome loss': 0.4235847071357017, 'Total loss': 0.4235847071357017}
2023-01-04 05:42:15,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:15,211 INFO:     Epoch: 18
2023-01-04 05:42:16,685 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3913997828960419, 'Total loss': 0.3913997828960419} | train loss {'Reaction outcome loss': 0.41772623757158756, 'Total loss': 0.41772623757158756}
2023-01-04 05:42:16,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:16,685 INFO:     Epoch: 19
2023-01-04 05:42:18,255 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4118253211180369, 'Total loss': 0.4118253211180369} | train loss {'Reaction outcome loss': 0.41293245553970337, 'Total loss': 0.41293245553970337}
2023-01-04 05:42:18,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:18,256 INFO:     Epoch: 20
2023-01-04 05:42:19,839 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.396975843111674, 'Total loss': 0.396975843111674} | train loss {'Reaction outcome loss': 0.4093616524860807, 'Total loss': 0.4093616524860807}
2023-01-04 05:42:19,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:19,839 INFO:     Epoch: 21
2023-01-04 05:42:21,394 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.395332407951355, 'Total loss': 0.395332407951355} | train loss {'Reaction outcome loss': 0.40590323545854456, 'Total loss': 0.40590323545854456}
2023-01-04 05:42:21,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:21,395 INFO:     Epoch: 22
2023-01-04 05:42:22,959 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3910526971022288, 'Total loss': 0.3910526971022288} | train loss {'Reaction outcome loss': 0.4037783617412087, 'Total loss': 0.4037783617412087}
2023-01-04 05:42:22,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:22,959 INFO:     Epoch: 23
2023-01-04 05:42:24,512 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37752043704191846, 'Total loss': 0.37752043704191846} | train loss {'Reaction outcome loss': 0.40061644638759375, 'Total loss': 0.40061644638759375}
2023-01-04 05:42:24,513 INFO:     Found new best model at epoch 23
2023-01-04 05:42:24,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:24,514 INFO:     Epoch: 24
2023-01-04 05:42:25,983 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40646450916926063, 'Total loss': 0.40646450916926063} | train loss {'Reaction outcome loss': 0.3970792311223319, 'Total loss': 0.3970792311223319}
2023-01-04 05:42:25,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:25,984 INFO:     Epoch: 25
2023-01-04 05:42:27,542 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3903970638910929, 'Total loss': 0.3903970638910929} | train loss {'Reaction outcome loss': 0.3882664562522495, 'Total loss': 0.3882664562522495}
2023-01-04 05:42:27,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:27,543 INFO:     Epoch: 26
2023-01-04 05:42:29,102 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39148806234200795, 'Total loss': 0.39148806234200795} | train loss {'Reaction outcome loss': 0.38803840102287973, 'Total loss': 0.38803840102287973}
2023-01-04 05:42:29,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:29,102 INFO:     Epoch: 27
2023-01-04 05:42:30,663 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3569050908088684, 'Total loss': 0.3569050908088684} | train loss {'Reaction outcome loss': 0.38571425326114156, 'Total loss': 0.38571425326114156}
2023-01-04 05:42:30,663 INFO:     Found new best model at epoch 27
2023-01-04 05:42:30,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:30,664 INFO:     Epoch: 28
2023-01-04 05:42:32,218 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37590310672918953, 'Total loss': 0.37590310672918953} | train loss {'Reaction outcome loss': 0.3811039404712454, 'Total loss': 0.3811039404712454}
2023-01-04 05:42:32,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:32,218 INFO:     Epoch: 29
2023-01-04 05:42:33,751 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37163910071055095, 'Total loss': 0.37163910071055095} | train loss {'Reaction outcome loss': 0.3776540687701998, 'Total loss': 0.3776540687701998}
2023-01-04 05:42:33,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:33,751 INFO:     Epoch: 30
2023-01-04 05:42:35,200 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3712590754032135, 'Total loss': 0.3712590754032135} | train loss {'Reaction outcome loss': 0.3745991268949787, 'Total loss': 0.3745991268949787}
2023-01-04 05:42:35,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:35,201 INFO:     Epoch: 31
2023-01-04 05:42:36,722 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.36646157304445903, 'Total loss': 0.36646157304445903} | train loss {'Reaction outcome loss': 0.36659890829320374, 'Total loss': 0.36659890829320374}
2023-01-04 05:42:36,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:36,723 INFO:     Epoch: 32
2023-01-04 05:42:38,253 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3874805529912313, 'Total loss': 0.3874805529912313} | train loss {'Reaction outcome loss': 0.36459648715209786, 'Total loss': 0.36459648715209786}
2023-01-04 05:42:38,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:38,253 INFO:     Epoch: 33
2023-01-04 05:42:39,784 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3752754886945089, 'Total loss': 0.3752754886945089} | train loss {'Reaction outcome loss': 0.3637422310718655, 'Total loss': 0.3637422310718655}
2023-01-04 05:42:39,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:39,785 INFO:     Epoch: 34
2023-01-04 05:42:41,331 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3455097069342931, 'Total loss': 0.3455097069342931} | train loss {'Reaction outcome loss': 0.36362578072687135, 'Total loss': 0.36362578072687135}
2023-01-04 05:42:41,331 INFO:     Found new best model at epoch 34
2023-01-04 05:42:41,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:41,332 INFO:     Epoch: 35
2023-01-04 05:42:42,883 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.34473467071851094, 'Total loss': 0.34473467071851094} | train loss {'Reaction outcome loss': 0.3581239423938911, 'Total loss': 0.3581239423938911}
2023-01-04 05:42:42,884 INFO:     Found new best model at epoch 35
2023-01-04 05:42:42,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:42,885 INFO:     Epoch: 36
2023-01-04 05:42:44,357 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.378020275135835, 'Total loss': 0.378020275135835} | train loss {'Reaction outcome loss': 0.3579256761084943, 'Total loss': 0.3579256761084943}
2023-01-04 05:42:44,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:44,357 INFO:     Epoch: 37
2023-01-04 05:42:45,906 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36797332564989726, 'Total loss': 0.36797332564989726} | train loss {'Reaction outcome loss': 0.3488887922063361, 'Total loss': 0.3488887922063361}
2023-01-04 05:42:45,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:45,907 INFO:     Epoch: 38
2023-01-04 05:42:47,455 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3468639517823855, 'Total loss': 0.3468639517823855} | train loss {'Reaction outcome loss': 0.34787118250001087, 'Total loss': 0.34787118250001087}
2023-01-04 05:42:47,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:47,455 INFO:     Epoch: 39
2023-01-04 05:42:49,000 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3529036472241084, 'Total loss': 0.3529036472241084} | train loss {'Reaction outcome loss': 0.34568476595365216, 'Total loss': 0.34568476595365216}
2023-01-04 05:42:49,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:49,000 INFO:     Epoch: 40
2023-01-04 05:42:50,549 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.34387257794539133, 'Total loss': 0.34387257794539133} | train loss {'Reaction outcome loss': 0.34140560185931024, 'Total loss': 0.34140560185931024}
2023-01-04 05:42:50,549 INFO:     Found new best model at epoch 40
2023-01-04 05:42:50,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:50,549 INFO:     Epoch: 41
2023-01-04 05:42:52,086 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3498359223206838, 'Total loss': 0.3498359223206838} | train loss {'Reaction outcome loss': 0.3370671280435402, 'Total loss': 0.3370671280435402}
2023-01-04 05:42:52,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:52,087 INFO:     Epoch: 42
2023-01-04 05:42:53,577 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3768069763978322, 'Total loss': 0.3768069763978322} | train loss {'Reaction outcome loss': 0.3348908261226041, 'Total loss': 0.3348908261226041}
2023-01-04 05:42:53,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:53,577 INFO:     Epoch: 43
2023-01-04 05:42:55,136 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3333391805489858, 'Total loss': 0.3333391805489858} | train loss {'Reaction outcome loss': 0.33003752088568505, 'Total loss': 0.33003752088568505}
2023-01-04 05:42:55,137 INFO:     Found new best model at epoch 43
2023-01-04 05:42:55,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:55,138 INFO:     Epoch: 44
2023-01-04 05:42:56,679 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.33620752294858297, 'Total loss': 0.33620752294858297} | train loss {'Reaction outcome loss': 0.32955486786952853, 'Total loss': 0.32955486786952853}
2023-01-04 05:42:56,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:56,679 INFO:     Epoch: 45
2023-01-04 05:42:58,243 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.33641175081332525, 'Total loss': 0.33641175081332525} | train loss {'Reaction outcome loss': 0.3244549774558005, 'Total loss': 0.3244549774558005}
2023-01-04 05:42:58,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:58,244 INFO:     Epoch: 46
2023-01-04 05:42:59,782 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.33078796168168384, 'Total loss': 0.33078796168168384} | train loss {'Reaction outcome loss': 0.3248768676425854, 'Total loss': 0.3248768676425854}
2023-01-04 05:42:59,782 INFO:     Found new best model at epoch 46
2023-01-04 05:42:59,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:42:59,783 INFO:     Epoch: 47
2023-01-04 05:43:01,329 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.347244397799174, 'Total loss': 0.347244397799174} | train loss {'Reaction outcome loss': 0.31979581001248675, 'Total loss': 0.31979581001248675}
2023-01-04 05:43:01,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:01,329 INFO:     Epoch: 48
2023-01-04 05:43:02,810 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3389978716770808, 'Total loss': 0.3389978716770808} | train loss {'Reaction outcome loss': 0.3221761655524699, 'Total loss': 0.3221761655524699}
2023-01-04 05:43:02,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:02,811 INFO:     Epoch: 49
2023-01-04 05:43:04,379 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3153259346882502, 'Total loss': 0.3153259346882502} | train loss {'Reaction outcome loss': 0.3195556757332635, 'Total loss': 0.3195556757332635}
2023-01-04 05:43:04,380 INFO:     Found new best model at epoch 49
2023-01-04 05:43:04,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:04,380 INFO:     Epoch: 50
2023-01-04 05:43:05,936 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.32083717385927835, 'Total loss': 0.32083717385927835} | train loss {'Reaction outcome loss': 0.31193795291720516, 'Total loss': 0.31193795291720516}
2023-01-04 05:43:05,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:05,936 INFO:     Epoch: 51
2023-01-04 05:43:07,491 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3297467827796936, 'Total loss': 0.3297467827796936} | train loss {'Reaction outcome loss': 0.31219858918203053, 'Total loss': 0.31219858918203053}
2023-01-04 05:43:07,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:07,492 INFO:     Epoch: 52
2023-01-04 05:43:09,060 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.32993637919425967, 'Total loss': 0.32993637919425967} | train loss {'Reaction outcome loss': 0.31565282126739075, 'Total loss': 0.31565282126739075}
2023-01-04 05:43:09,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:09,060 INFO:     Epoch: 53
2023-01-04 05:43:10,609 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.31882573465506236, 'Total loss': 0.31882573465506236} | train loss {'Reaction outcome loss': 0.31028777828616816, 'Total loss': 0.31028777828616816}
2023-01-04 05:43:10,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:10,609 INFO:     Epoch: 54
2023-01-04 05:43:12,110 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.34082936545213066, 'Total loss': 0.34082936545213066} | train loss {'Reaction outcome loss': 0.3099869717537922, 'Total loss': 0.3099869717537922}
2023-01-04 05:43:12,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:12,110 INFO:     Epoch: 55
2023-01-04 05:43:13,672 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.34128164052963256, 'Total loss': 0.34128164052963256} | train loss {'Reaction outcome loss': 0.3041930683093132, 'Total loss': 0.3041930683093132}
2023-01-04 05:43:13,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:13,673 INFO:     Epoch: 56
2023-01-04 05:43:15,222 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3243803044160207, 'Total loss': 0.3243803044160207} | train loss {'Reaction outcome loss': 0.30420248259375565, 'Total loss': 0.30420248259375565}
2023-01-04 05:43:15,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:15,222 INFO:     Epoch: 57
2023-01-04 05:43:16,765 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.33012729783852895, 'Total loss': 0.33012729783852895} | train loss {'Reaction outcome loss': 0.3025674272845261, 'Total loss': 0.3025674272845261}
2023-01-04 05:43:16,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:16,765 INFO:     Epoch: 58
2023-01-04 05:43:18,297 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3317014217376709, 'Total loss': 0.3317014217376709} | train loss {'Reaction outcome loss': 0.30306483236868886, 'Total loss': 0.30306483236868886}
2023-01-04 05:43:18,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:18,297 INFO:     Epoch: 59
2023-01-04 05:43:19,798 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33765009144941965, 'Total loss': 0.33765009144941965} | train loss {'Reaction outcome loss': 0.29928725911644255, 'Total loss': 0.29928725911644255}
2023-01-04 05:43:19,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:19,798 INFO:     Epoch: 60
2023-01-04 05:43:21,299 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.34480324685573577, 'Total loss': 0.34480324685573577} | train loss {'Reaction outcome loss': 0.2965187110605031, 'Total loss': 0.2965187110605031}
2023-01-04 05:43:21,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:21,300 INFO:     Epoch: 61
2023-01-04 05:43:22,833 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3243443965911865, 'Total loss': 0.3243443965911865} | train loss {'Reaction outcome loss': 0.2969960663059767, 'Total loss': 0.2969960663059767}
2023-01-04 05:43:22,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:22,834 INFO:     Epoch: 62
2023-01-04 05:43:24,374 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3288171450297038, 'Total loss': 0.3288171450297038} | train loss {'Reaction outcome loss': 0.2910165860161294, 'Total loss': 0.2910165860161294}
2023-01-04 05:43:24,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:24,374 INFO:     Epoch: 63
2023-01-04 05:43:25,905 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.31182537575562796, 'Total loss': 0.31182537575562796} | train loss {'Reaction outcome loss': 0.2954198226169513, 'Total loss': 0.2954198226169513}
2023-01-04 05:43:25,906 INFO:     Found new best model at epoch 63
2023-01-04 05:43:25,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:25,907 INFO:     Epoch: 64
2023-01-04 05:43:27,439 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3463247388601303, 'Total loss': 0.3463247388601303} | train loss {'Reaction outcome loss': 0.2935270554705584, 'Total loss': 0.2935270554705584}
2023-01-04 05:43:27,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:27,439 INFO:     Epoch: 65
2023-01-04 05:43:28,944 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.30191000998020173, 'Total loss': 0.30191000998020173} | train loss {'Reaction outcome loss': 0.29154416149223805, 'Total loss': 0.29154416149223805}
2023-01-04 05:43:28,944 INFO:     Found new best model at epoch 65
2023-01-04 05:43:28,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:28,945 INFO:     Epoch: 66
2023-01-04 05:43:30,437 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.31122135718663535, 'Total loss': 0.31122135718663535} | train loss {'Reaction outcome loss': 0.28536410871757206, 'Total loss': 0.28536410871757206}
2023-01-04 05:43:30,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:30,437 INFO:     Epoch: 67
2023-01-04 05:43:31,971 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3148668333888054, 'Total loss': 0.3148668333888054} | train loss {'Reaction outcome loss': 0.28994590941354303, 'Total loss': 0.28994590941354303}
2023-01-04 05:43:31,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:31,972 INFO:     Epoch: 68
2023-01-04 05:43:33,503 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3244299521048864, 'Total loss': 0.3244299521048864} | train loss {'Reaction outcome loss': 0.2843408714504029, 'Total loss': 0.2843408714504029}
2023-01-04 05:43:33,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:33,503 INFO:     Epoch: 69
2023-01-04 05:43:35,044 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34963482022285464, 'Total loss': 0.34963482022285464} | train loss {'Reaction outcome loss': 0.28929802041201697, 'Total loss': 0.28929802041201697}
2023-01-04 05:43:35,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:35,044 INFO:     Epoch: 70
2023-01-04 05:43:36,576 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34727866351604464, 'Total loss': 0.34727866351604464} | train loss {'Reaction outcome loss': 0.2818193776247493, 'Total loss': 0.2818193776247493}
2023-01-04 05:43:36,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:36,577 INFO:     Epoch: 71
2023-01-04 05:43:38,080 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34865456918875376, 'Total loss': 0.34865456918875376} | train loss {'Reaction outcome loss': 0.2817566999553764, 'Total loss': 0.2817566999553764}
2023-01-04 05:43:38,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:38,081 INFO:     Epoch: 72
2023-01-04 05:43:39,577 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.310483463605245, 'Total loss': 0.310483463605245} | train loss {'Reaction outcome loss': 0.2781421737541465, 'Total loss': 0.2781421737541465}
2023-01-04 05:43:39,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:39,578 INFO:     Epoch: 73
2023-01-04 05:43:41,099 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36314287086327873, 'Total loss': 0.36314287086327873} | train loss {'Reaction outcome loss': 0.28243113572906403, 'Total loss': 0.28243113572906403}
2023-01-04 05:43:41,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:41,099 INFO:     Epoch: 74
2023-01-04 05:43:42,637 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.2978578587373098, 'Total loss': 0.2978578587373098} | train loss {'Reaction outcome loss': 0.28050681796387167, 'Total loss': 0.28050681796387167}
2023-01-04 05:43:42,637 INFO:     Found new best model at epoch 74
2023-01-04 05:43:42,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:42,638 INFO:     Epoch: 75
2023-01-04 05:43:44,163 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35489753683408104, 'Total loss': 0.35489753683408104} | train loss {'Reaction outcome loss': 0.2764228939955687, 'Total loss': 0.2764228939955687}
2023-01-04 05:43:44,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:44,164 INFO:     Epoch: 76
2023-01-04 05:43:45,681 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3091640214125315, 'Total loss': 0.3091640214125315} | train loss {'Reaction outcome loss': 0.27573129257363993, 'Total loss': 0.27573129257363993}
2023-01-04 05:43:45,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:45,682 INFO:     Epoch: 77
2023-01-04 05:43:47,201 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3220271130402883, 'Total loss': 0.3220271130402883} | train loss {'Reaction outcome loss': 0.2782190669681469, 'Total loss': 0.2782190669681469}
2023-01-04 05:43:47,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:47,201 INFO:     Epoch: 78
2023-01-04 05:43:48,733 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.31257063696781795, 'Total loss': 0.31257063696781795} | train loss {'Reaction outcome loss': 0.2731567057678952, 'Total loss': 0.2731567057678952}
2023-01-04 05:43:48,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:48,733 INFO:     Epoch: 79
2023-01-04 05:43:50,257 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.304269681374232, 'Total loss': 0.304269681374232} | train loss {'Reaction outcome loss': 0.2728920547142081, 'Total loss': 0.2728920547142081}
2023-01-04 05:43:50,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:50,258 INFO:     Epoch: 80
2023-01-04 05:43:51,806 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.309950386484464, 'Total loss': 0.309950386484464} | train loss {'Reaction outcome loss': 0.27290819783824205, 'Total loss': 0.27290819783824205}
2023-01-04 05:43:51,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:51,807 INFO:     Epoch: 81
2023-01-04 05:43:53,351 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3255954583485921, 'Total loss': 0.3255954583485921} | train loss {'Reaction outcome loss': 0.2694230076931689, 'Total loss': 0.2694230076931689}
2023-01-04 05:43:53,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:53,352 INFO:     Epoch: 82
2023-01-04 05:43:54,894 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.32391410966714224, 'Total loss': 0.32391410966714224} | train loss {'Reaction outcome loss': 0.27131695494762736, 'Total loss': 0.27131695494762736}
2023-01-04 05:43:54,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:54,895 INFO:     Epoch: 83
2023-01-04 05:43:56,391 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3135941962401072, 'Total loss': 0.3135941962401072} | train loss {'Reaction outcome loss': 0.27221893984144624, 'Total loss': 0.27221893984144624}
2023-01-04 05:43:56,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:56,392 INFO:     Epoch: 84
2023-01-04 05:43:57,955 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3195187677939733, 'Total loss': 0.3195187677939733} | train loss {'Reaction outcome loss': 0.2687755183581888, 'Total loss': 0.2687755183581888}
2023-01-04 05:43:57,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:57,956 INFO:     Epoch: 85
2023-01-04 05:43:59,487 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3613237659136454, 'Total loss': 0.3613237659136454} | train loss {'Reaction outcome loss': 0.2683200683227203, 'Total loss': 0.2683200683227203}
2023-01-04 05:43:59,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:43:59,487 INFO:     Epoch: 86
2023-01-04 05:44:01,026 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3240188807249069, 'Total loss': 0.3240188807249069} | train loss {'Reaction outcome loss': 0.2734848002556467, 'Total loss': 0.2734848002556467}
2023-01-04 05:44:01,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:01,026 INFO:     Epoch: 87
2023-01-04 05:44:02,573 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.292373471458753, 'Total loss': 0.292373471458753} | train loss {'Reaction outcome loss': 0.26073628644982394, 'Total loss': 0.26073628644982394}
2023-01-04 05:44:02,573 INFO:     Found new best model at epoch 87
2023-01-04 05:44:02,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:02,574 INFO:     Epoch: 88
2023-01-04 05:44:04,104 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.28639885832866036, 'Total loss': 0.28639885832866036} | train loss {'Reaction outcome loss': 0.2671441244926766, 'Total loss': 0.2671441244926766}
2023-01-04 05:44:04,104 INFO:     Found new best model at epoch 88
2023-01-04 05:44:04,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:04,105 INFO:     Epoch: 89
2023-01-04 05:44:05,582 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.31752936268846194, 'Total loss': 0.31752936268846194} | train loss {'Reaction outcome loss': 0.26053340448895945, 'Total loss': 0.26053340448895945}
2023-01-04 05:44:05,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:05,583 INFO:     Epoch: 90
2023-01-04 05:44:07,118 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3210006150727471, 'Total loss': 0.3210006150727471} | train loss {'Reaction outcome loss': 0.2623510585866705, 'Total loss': 0.2623510585866705}
2023-01-04 05:44:07,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:07,118 INFO:     Epoch: 91
2023-01-04 05:44:08,649 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.31587533056735995, 'Total loss': 0.31587533056735995} | train loss {'Reaction outcome loss': 0.26462953483318763, 'Total loss': 0.26462953483318763}
2023-01-04 05:44:08,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:08,649 INFO:     Epoch: 92
2023-01-04 05:44:10,178 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.310600671172142, 'Total loss': 0.310600671172142} | train loss {'Reaction outcome loss': 0.25797045544931924, 'Total loss': 0.25797045544931924}
2023-01-04 05:44:10,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:10,179 INFO:     Epoch: 93
2023-01-04 05:44:11,725 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.32889138559500375, 'Total loss': 0.32889138559500375} | train loss {'Reaction outcome loss': 0.26140800399882513, 'Total loss': 0.26140800399882513}
2023-01-04 05:44:11,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:11,725 INFO:     Epoch: 94
2023-01-04 05:44:13,265 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33885359366734824, 'Total loss': 0.33885359366734824} | train loss {'Reaction outcome loss': 0.2618849449892984, 'Total loss': 0.2618849449892984}
2023-01-04 05:44:13,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:13,265 INFO:     Epoch: 95
2023-01-04 05:44:14,746 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.33507955571015674, 'Total loss': 0.33507955571015674} | train loss {'Reaction outcome loss': 0.2603964405066341, 'Total loss': 0.2603964405066341}
2023-01-04 05:44:14,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:14,746 INFO:     Epoch: 96
2023-01-04 05:44:16,282 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.2916354114810626, 'Total loss': 0.2916354114810626} | train loss {'Reaction outcome loss': 0.26158048356645297, 'Total loss': 0.26158048356645297}
2023-01-04 05:44:16,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:16,282 INFO:     Epoch: 97
2023-01-04 05:44:17,825 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.32005576392014823, 'Total loss': 0.32005576392014823} | train loss {'Reaction outcome loss': 0.25644723079881093, 'Total loss': 0.25644723079881093}
2023-01-04 05:44:17,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:17,825 INFO:     Epoch: 98
2023-01-04 05:44:19,364 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3483330845832825, 'Total loss': 0.3483330845832825} | train loss {'Reaction outcome loss': 0.25790851098233764, 'Total loss': 0.25790851098233764}
2023-01-04 05:44:19,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:19,364 INFO:     Epoch: 99
2023-01-04 05:44:20,924 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3183749054869016, 'Total loss': 0.3183749054869016} | train loss {'Reaction outcome loss': 0.2582734313650723, 'Total loss': 0.2582734313650723}
2023-01-04 05:44:20,924 INFO:     Best model found after epoch 89 of 100.
2023-01-04 05:44:20,924 INFO:   Done with stage: TRAINING
2023-01-04 05:44:20,924 INFO:   Starting stage: EVALUATION
2023-01-04 05:44:21,055 INFO:   Done with stage: EVALUATION
2023-01-04 05:44:21,055 INFO:   Leaving out SEQ value Fold_3
2023-01-04 05:44:21,068 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 05:44:21,068 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:44:21,716 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:44:21,716 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:44:21,786 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:44:21,786 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:44:21,786 INFO:     No hyperparam tuning for this model
2023-01-04 05:44:21,786 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:44:21,786 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:44:21,787 INFO:     None feature selector for col prot
2023-01-04 05:44:21,787 INFO:     None feature selector for col prot
2023-01-04 05:44:21,787 INFO:     None feature selector for col prot
2023-01-04 05:44:21,787 INFO:     None feature selector for col chem
2023-01-04 05:44:21,788 INFO:     None feature selector for col chem
2023-01-04 05:44:21,788 INFO:     None feature selector for col chem
2023-01-04 05:44:21,788 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:44:21,788 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:44:21,789 INFO:     Number of params in model 70111
2023-01-04 05:44:21,792 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:44:21,792 INFO:   Starting stage: TRAINING
2023-01-04 05:44:21,835 INFO:     Val loss before train {'Reaction outcome loss': 0.9808064301808676, 'Total loss': 0.9808064301808676}
2023-01-04 05:44:21,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:21,835 INFO:     Epoch: 0
2023-01-04 05:44:23,335 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7528324743111928, 'Total loss': 0.7528324743111928} | train loss {'Reaction outcome loss': 0.8713505984875407, 'Total loss': 0.8713505984875407}
2023-01-04 05:44:23,335 INFO:     Found new best model at epoch 0
2023-01-04 05:44:23,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:23,336 INFO:     Epoch: 1
2023-01-04 05:44:24,874 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6418768167495728, 'Total loss': 0.6418768167495728} | train loss {'Reaction outcome loss': 0.725151035037354, 'Total loss': 0.725151035037354}
2023-01-04 05:44:24,874 INFO:     Found new best model at epoch 1
2023-01-04 05:44:24,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:24,875 INFO:     Epoch: 2
2023-01-04 05:44:26,412 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.567350955804189, 'Total loss': 0.567350955804189} | train loss {'Reaction outcome loss': 0.6305469812920493, 'Total loss': 0.6305469812920493}
2023-01-04 05:44:26,412 INFO:     Found new best model at epoch 2
2023-01-04 05:44:26,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:26,413 INFO:     Epoch: 3
2023-01-04 05:44:27,966 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5243762354056041, 'Total loss': 0.5243762354056041} | train loss {'Reaction outcome loss': 0.5762969334847736, 'Total loss': 0.5762969334847736}
2023-01-04 05:44:27,966 INFO:     Found new best model at epoch 3
2023-01-04 05:44:27,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:27,967 INFO:     Epoch: 4
2023-01-04 05:44:29,506 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5228327959775925, 'Total loss': 0.5228327959775925} | train loss {'Reaction outcome loss': 0.5431489943370332, 'Total loss': 0.5431489943370332}
2023-01-04 05:44:29,507 INFO:     Found new best model at epoch 4
2023-01-04 05:44:29,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:29,508 INFO:     Epoch: 5
2023-01-04 05:44:31,062 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4930639902750651, 'Total loss': 0.4930639902750651} | train loss {'Reaction outcome loss': 0.5279282492986561, 'Total loss': 0.5279282492986561}
2023-01-04 05:44:31,063 INFO:     Found new best model at epoch 5
2023-01-04 05:44:31,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:31,063 INFO:     Epoch: 6
2023-01-04 05:44:32,559 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.522571611404419, 'Total loss': 0.522571611404419} | train loss {'Reaction outcome loss': 0.5048673528171804, 'Total loss': 0.5048673528171804}
2023-01-04 05:44:32,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:32,559 INFO:     Epoch: 7
2023-01-04 05:44:34,101 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48314014871915184, 'Total loss': 0.48314014871915184} | train loss {'Reaction outcome loss': 0.4974760058043647, 'Total loss': 0.4974760058043647}
2023-01-04 05:44:34,102 INFO:     Found new best model at epoch 7
2023-01-04 05:44:34,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:34,102 INFO:     Epoch: 8
2023-01-04 05:44:35,642 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47348926464716595, 'Total loss': 0.47348926464716595} | train loss {'Reaction outcome loss': 0.48747753863134524, 'Total loss': 0.48747753863134524}
2023-01-04 05:44:35,642 INFO:     Found new best model at epoch 8
2023-01-04 05:44:35,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:35,643 INFO:     Epoch: 9
2023-01-04 05:44:37,202 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4657665063937505, 'Total loss': 0.4657665063937505} | train loss {'Reaction outcome loss': 0.4804502519486594, 'Total loss': 0.4804502519486594}
2023-01-04 05:44:37,202 INFO:     Found new best model at epoch 9
2023-01-04 05:44:37,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:37,203 INFO:     Epoch: 10
2023-01-04 05:44:38,766 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4890329003334045, 'Total loss': 0.4890329003334045} | train loss {'Reaction outcome loss': 0.4708668552067158, 'Total loss': 0.4708668552067158}
2023-01-04 05:44:38,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:38,766 INFO:     Epoch: 11
2023-01-04 05:44:40,314 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46504825552304585, 'Total loss': 0.46504825552304585} | train loss {'Reaction outcome loss': 0.46506520621750475, 'Total loss': 0.46506520621750475}
2023-01-04 05:44:40,314 INFO:     Found new best model at epoch 11
2023-01-04 05:44:40,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:40,315 INFO:     Epoch: 12
2023-01-04 05:44:41,832 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43884504536787666, 'Total loss': 0.43884504536787666} | train loss {'Reaction outcome loss': 0.4576034711225189, 'Total loss': 0.4576034711225189}
2023-01-04 05:44:41,832 INFO:     Found new best model at epoch 12
2023-01-04 05:44:41,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:41,833 INFO:     Epoch: 13
2023-01-04 05:44:43,413 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45157914559046425, 'Total loss': 0.45157914559046425} | train loss {'Reaction outcome loss': 0.45437513123246004, 'Total loss': 0.45437513123246004}
2023-01-04 05:44:43,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:43,413 INFO:     Epoch: 14
2023-01-04 05:44:44,994 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45079194704691566, 'Total loss': 0.45079194704691566} | train loss {'Reaction outcome loss': 0.4529147995160009, 'Total loss': 0.4529147995160009}
2023-01-04 05:44:44,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:44,996 INFO:     Epoch: 15
2023-01-04 05:44:46,559 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43857895930608115, 'Total loss': 0.43857895930608115} | train loss {'Reaction outcome loss': 0.44297603713552447, 'Total loss': 0.44297603713552447}
2023-01-04 05:44:46,560 INFO:     Found new best model at epoch 15
2023-01-04 05:44:46,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:46,560 INFO:     Epoch: 16
2023-01-04 05:44:48,110 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46363198359807334, 'Total loss': 0.46363198359807334} | train loss {'Reaction outcome loss': 0.43868177305281597, 'Total loss': 0.43868177305281597}
2023-01-04 05:44:48,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:48,110 INFO:     Epoch: 17
2023-01-04 05:44:49,662 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4427897254625956, 'Total loss': 0.4427897254625956} | train loss {'Reaction outcome loss': 0.43499031404617927, 'Total loss': 0.43499031404617927}
2023-01-04 05:44:49,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:49,662 INFO:     Epoch: 18
2023-01-04 05:44:51,133 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42880744536717735, 'Total loss': 0.42880744536717735} | train loss {'Reaction outcome loss': 0.42604381868439, 'Total loss': 0.42604381868439}
2023-01-04 05:44:51,134 INFO:     Found new best model at epoch 18
2023-01-04 05:44:51,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:51,134 INFO:     Epoch: 19
2023-01-04 05:44:52,702 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4311003863811493, 'Total loss': 0.4311003863811493} | train loss {'Reaction outcome loss': 0.4244055542415076, 'Total loss': 0.4244055542415076}
2023-01-04 05:44:52,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:52,702 INFO:     Epoch: 20
2023-01-04 05:44:54,255 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4511207610368729, 'Total loss': 0.4511207610368729} | train loss {'Reaction outcome loss': 0.4205888984792859, 'Total loss': 0.4205888984792859}
2023-01-04 05:44:54,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:54,256 INFO:     Epoch: 21
2023-01-04 05:44:55,828 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4420665502548218, 'Total loss': 0.4420665502548218} | train loss {'Reaction outcome loss': 0.41409974409280903, 'Total loss': 0.41409974409280903}
2023-01-04 05:44:55,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:55,828 INFO:     Epoch: 22
2023-01-04 05:44:57,408 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4306351254383723, 'Total loss': 0.4306351254383723} | train loss {'Reaction outcome loss': 0.40923580418538, 'Total loss': 0.40923580418538}
2023-01-04 05:44:57,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:57,408 INFO:     Epoch: 23
2023-01-04 05:44:58,979 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43633828560511273, 'Total loss': 0.43633828560511273} | train loss {'Reaction outcome loss': 0.4063453119057808, 'Total loss': 0.4063453119057808}
2023-01-04 05:44:58,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:44:58,979 INFO:     Epoch: 24
2023-01-04 05:45:00,517 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4466939359903336, 'Total loss': 0.4466939359903336} | train loss {'Reaction outcome loss': 0.4056501694730599, 'Total loss': 0.4056501694730599}
2023-01-04 05:45:00,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:00,517 INFO:     Epoch: 25
2023-01-04 05:45:02,121 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44367976784706115, 'Total loss': 0.44367976784706115} | train loss {'Reaction outcome loss': 0.3989439702925891, 'Total loss': 0.3989439702925891}
2023-01-04 05:45:02,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:02,122 INFO:     Epoch: 26
2023-01-04 05:45:03,715 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4379130095243454, 'Total loss': 0.4379130095243454} | train loss {'Reaction outcome loss': 0.3985077218308936, 'Total loss': 0.3985077218308936}
2023-01-04 05:45:03,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:03,715 INFO:     Epoch: 27
2023-01-04 05:45:05,319 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4021406888961792, 'Total loss': 0.4021406888961792} | train loss {'Reaction outcome loss': 0.3915144617050669, 'Total loss': 0.3915144617050669}
2023-01-04 05:45:05,319 INFO:     Found new best model at epoch 27
2023-01-04 05:45:05,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:05,320 INFO:     Epoch: 28
2023-01-04 05:45:06,918 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4092747246225675, 'Total loss': 0.4092747246225675} | train loss {'Reaction outcome loss': 0.38797745250002313, 'Total loss': 0.38797745250002313}
2023-01-04 05:45:06,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:06,918 INFO:     Epoch: 29
2023-01-04 05:45:08,458 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4392557124296824, 'Total loss': 0.4392557124296824} | train loss {'Reaction outcome loss': 0.3896243920019508, 'Total loss': 0.3896243920019508}
2023-01-04 05:45:08,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:08,458 INFO:     Epoch: 30
2023-01-04 05:45:09,996 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43822240630785625, 'Total loss': 0.43822240630785625} | train loss {'Reaction outcome loss': 0.37993353877189384, 'Total loss': 0.37993353877189384}
2023-01-04 05:45:09,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:09,996 INFO:     Epoch: 31
2023-01-04 05:45:11,585 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4011155794064204, 'Total loss': 0.4011155794064204} | train loss {'Reaction outcome loss': 0.3801731336725889, 'Total loss': 0.3801731336725889}
2023-01-04 05:45:11,585 INFO:     Found new best model at epoch 31
2023-01-04 05:45:11,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:11,586 INFO:     Epoch: 32
2023-01-04 05:45:13,134 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4325604279836019, 'Total loss': 0.4325604279836019} | train loss {'Reaction outcome loss': 0.37387259652579785, 'Total loss': 0.37387259652579785}
2023-01-04 05:45:13,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:13,134 INFO:     Epoch: 33
2023-01-04 05:45:14,702 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4615049421787262, 'Total loss': 0.4615049421787262} | train loss {'Reaction outcome loss': 0.37048707320524826, 'Total loss': 0.37048707320524826}
2023-01-04 05:45:14,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:14,702 INFO:     Epoch: 34
2023-01-04 05:45:16,272 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39468594988187156, 'Total loss': 0.39468594988187156} | train loss {'Reaction outcome loss': 0.37414485694718186, 'Total loss': 0.37414485694718186}
2023-01-04 05:45:16,273 INFO:     Found new best model at epoch 34
2023-01-04 05:45:16,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:16,274 INFO:     Epoch: 35
2023-01-04 05:45:17,768 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41053297817707063, 'Total loss': 0.41053297817707063} | train loss {'Reaction outcome loss': 0.36688948887651857, 'Total loss': 0.36688948887651857}
2023-01-04 05:45:17,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:17,768 INFO:     Epoch: 36
2023-01-04 05:45:19,329 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42604110240936277, 'Total loss': 0.42604110240936277} | train loss {'Reaction outcome loss': 0.36415858822364877, 'Total loss': 0.36415858822364877}
2023-01-04 05:45:19,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:19,330 INFO:     Epoch: 37
2023-01-04 05:45:20,881 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43356291254361473, 'Total loss': 0.43356291254361473} | train loss {'Reaction outcome loss': 0.36101065622302736, 'Total loss': 0.36101065622302736}
2023-01-04 05:45:20,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:20,881 INFO:     Epoch: 38
2023-01-04 05:45:22,483 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38455492158730825, 'Total loss': 0.38455492158730825} | train loss {'Reaction outcome loss': 0.3582613607664613, 'Total loss': 0.3582613607664613}
2023-01-04 05:45:22,483 INFO:     Found new best model at epoch 38
2023-01-04 05:45:22,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:22,484 INFO:     Epoch: 39
2023-01-04 05:45:24,093 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39972147742907205, 'Total loss': 0.39972147742907205} | train loss {'Reaction outcome loss': 0.3568193789326797, 'Total loss': 0.3568193789326797}
2023-01-04 05:45:24,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:24,093 INFO:     Epoch: 40
2023-01-04 05:45:25,687 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4010363519191742, 'Total loss': 0.4010363519191742} | train loss {'Reaction outcome loss': 0.3525068821099988, 'Total loss': 0.3525068821099988}
2023-01-04 05:45:25,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:25,687 INFO:     Epoch: 41
2023-01-04 05:45:27,188 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40590295791625974, 'Total loss': 0.40590295791625974} | train loss {'Reaction outcome loss': 0.34862791513004443, 'Total loss': 0.34862791513004443}
2023-01-04 05:45:27,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:27,188 INFO:     Epoch: 42
2023-01-04 05:45:28,744 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4104426811138789, 'Total loss': 0.4104426811138789} | train loss {'Reaction outcome loss': 0.3483034908825899, 'Total loss': 0.3483034908825899}
2023-01-04 05:45:28,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:28,744 INFO:     Epoch: 43
2023-01-04 05:45:30,298 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41167158385117847, 'Total loss': 0.41167158385117847} | train loss {'Reaction outcome loss': 0.3433820605821853, 'Total loss': 0.3433820605821853}
2023-01-04 05:45:30,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:30,299 INFO:     Epoch: 44
2023-01-04 05:45:31,855 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.424569050470988, 'Total loss': 0.424569050470988} | train loss {'Reaction outcome loss': 0.34249438456919074, 'Total loss': 0.34249438456919074}
2023-01-04 05:45:31,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:31,855 INFO:     Epoch: 45
2023-01-04 05:45:33,408 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4005017141501109, 'Total loss': 0.4005017141501109} | train loss {'Reaction outcome loss': 0.33898516534997597, 'Total loss': 0.33898516534997597}
2023-01-04 05:45:33,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:33,409 INFO:     Epoch: 46
2023-01-04 05:45:34,951 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42920954525470734, 'Total loss': 0.42920954525470734} | train loss {'Reaction outcome loss': 0.33861766005084465, 'Total loss': 0.33861766005084465}
2023-01-04 05:45:34,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:34,952 INFO:     Epoch: 47
2023-01-04 05:45:36,445 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42587873339653015, 'Total loss': 0.42587873339653015} | train loss {'Reaction outcome loss': 0.33274959354069983, 'Total loss': 0.33274959354069983}
2023-01-04 05:45:36,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:36,445 INFO:     Epoch: 48
2023-01-04 05:45:38,000 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41408419410387676, 'Total loss': 0.41408419410387676} | train loss {'Reaction outcome loss': 0.3342354752286507, 'Total loss': 0.3342354752286507}
2023-01-04 05:45:38,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:38,000 INFO:     Epoch: 49
2023-01-04 05:45:39,548 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44763938784599305, 'Total loss': 0.44763938784599305} | train loss {'Reaction outcome loss': 0.32878851499000605, 'Total loss': 0.32878851499000605}
2023-01-04 05:45:39,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:39,549 INFO:     Epoch: 50
2023-01-04 05:45:41,091 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40170390407244366, 'Total loss': 0.40170390407244366} | train loss {'Reaction outcome loss': 0.3311193514424954, 'Total loss': 0.3311193514424954}
2023-01-04 05:45:41,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:41,091 INFO:     Epoch: 51
2023-01-04 05:45:42,631 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39975019892056785, 'Total loss': 0.39975019892056785} | train loss {'Reaction outcome loss': 0.32701344464490884, 'Total loss': 0.32701344464490884}
2023-01-04 05:45:42,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:42,631 INFO:     Epoch: 52
2023-01-04 05:45:44,189 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3882642755905787, 'Total loss': 0.3882642755905787} | train loss {'Reaction outcome loss': 0.3263572543913866, 'Total loss': 0.3263572543913866}
2023-01-04 05:45:44,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:44,189 INFO:     Epoch: 53
2023-01-04 05:45:45,667 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3877665599187215, 'Total loss': 0.3877665599187215} | train loss {'Reaction outcome loss': 0.3251994880065866, 'Total loss': 0.3251994880065866}
2023-01-04 05:45:45,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:45,668 INFO:     Epoch: 54
2023-01-04 05:45:47,237 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.392048978805542, 'Total loss': 0.392048978805542} | train loss {'Reaction outcome loss': 0.31881607905791626, 'Total loss': 0.31881607905791626}
2023-01-04 05:45:47,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:47,238 INFO:     Epoch: 55
2023-01-04 05:45:48,797 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4154651244481405, 'Total loss': 0.4154651244481405} | train loss {'Reaction outcome loss': 0.3181642619689016, 'Total loss': 0.3181642619689016}
2023-01-04 05:45:48,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:48,798 INFO:     Epoch: 56
2023-01-04 05:45:50,348 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3876069714625677, 'Total loss': 0.3876069714625677} | train loss {'Reaction outcome loss': 0.31580429369189444, 'Total loss': 0.31580429369189444}
2023-01-04 05:45:50,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:50,348 INFO:     Epoch: 57
2023-01-04 05:45:51,903 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3925523420174917, 'Total loss': 0.3925523420174917} | train loss {'Reaction outcome loss': 0.3160547920278389, 'Total loss': 0.3160547920278389}
2023-01-04 05:45:51,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:51,905 INFO:     Epoch: 58
2023-01-04 05:45:53,462 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.414583162466685, 'Total loss': 0.414583162466685} | train loss {'Reaction outcome loss': 0.31453054417332593, 'Total loss': 0.31453054417332593}
2023-01-04 05:45:53,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:53,462 INFO:     Epoch: 59
2023-01-04 05:45:54,959 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4297132154305776, 'Total loss': 0.4297132154305776} | train loss {'Reaction outcome loss': 0.3116251738456479, 'Total loss': 0.3116251738456479}
2023-01-04 05:45:54,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:54,959 INFO:     Epoch: 60
2023-01-04 05:45:56,534 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39454880555470784, 'Total loss': 0.39454880555470784} | train loss {'Reaction outcome loss': 0.304907692963407, 'Total loss': 0.304907692963407}
2023-01-04 05:45:56,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:56,534 INFO:     Epoch: 61
2023-01-04 05:45:58,081 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3894861439863841, 'Total loss': 0.3894861439863841} | train loss {'Reaction outcome loss': 0.30377256489583176, 'Total loss': 0.30377256489583176}
2023-01-04 05:45:58,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:58,082 INFO:     Epoch: 62
2023-01-04 05:45:59,695 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42006646394729613, 'Total loss': 0.42006646394729613} | train loss {'Reaction outcome loss': 0.3077107185538668, 'Total loss': 0.3077107185538668}
2023-01-04 05:45:59,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:45:59,695 INFO:     Epoch: 63
2023-01-04 05:46:01,309 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3811444769303004, 'Total loss': 0.3811444769303004} | train loss {'Reaction outcome loss': 0.3024404675964891, 'Total loss': 0.3024404675964891}
2023-01-04 05:46:01,309 INFO:     Found new best model at epoch 63
2023-01-04 05:46:01,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:01,310 INFO:     Epoch: 64
2023-01-04 05:46:02,880 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3903541127840678, 'Total loss': 0.3903541127840678} | train loss {'Reaction outcome loss': 0.29745005639473887, 'Total loss': 0.29745005639473887}
2023-01-04 05:46:02,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:02,881 INFO:     Epoch: 65
2023-01-04 05:46:04,393 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3824545125166575, 'Total loss': 0.3824545125166575} | train loss {'Reaction outcome loss': 0.29841796025960116, 'Total loss': 0.29841796025960116}
2023-01-04 05:46:04,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:04,393 INFO:     Epoch: 66
2023-01-04 05:46:05,952 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3884211679299672, 'Total loss': 0.3884211679299672} | train loss {'Reaction outcome loss': 0.297995943983976, 'Total loss': 0.297995943983976}
2023-01-04 05:46:05,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:05,952 INFO:     Epoch: 67
2023-01-04 05:46:07,494 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41927830974260966, 'Total loss': 0.41927830974260966} | train loss {'Reaction outcome loss': 0.29605257398292534, 'Total loss': 0.29605257398292534}
2023-01-04 05:46:07,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:07,494 INFO:     Epoch: 68
2023-01-04 05:46:09,038 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40019130110740664, 'Total loss': 0.40019130110740664} | train loss {'Reaction outcome loss': 0.2962450633083817, 'Total loss': 0.2962450633083817}
2023-01-04 05:46:09,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:09,038 INFO:     Epoch: 69
2023-01-04 05:46:10,568 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3999773303667704, 'Total loss': 0.3999773303667704} | train loss {'Reaction outcome loss': 0.2962429757726236, 'Total loss': 0.2962429757726236}
2023-01-04 05:46:10,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:10,569 INFO:     Epoch: 70
2023-01-04 05:46:12,109 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4027589112520218, 'Total loss': 0.4027589112520218} | train loss {'Reaction outcome loss': 0.2917114510098948, 'Total loss': 0.2917114510098948}
2023-01-04 05:46:12,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:12,109 INFO:     Epoch: 71
2023-01-04 05:46:13,670 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3782924205064774, 'Total loss': 0.3782924205064774} | train loss {'Reaction outcome loss': 0.28948276957673746, 'Total loss': 0.28948276957673746}
2023-01-04 05:46:13,670 INFO:     Found new best model at epoch 71
2023-01-04 05:46:13,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:13,671 INFO:     Epoch: 72
2023-01-04 05:46:15,212 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4243276556332906, 'Total loss': 0.4243276556332906} | train loss {'Reaction outcome loss': 0.2894549369268174, 'Total loss': 0.2894549369268174}
2023-01-04 05:46:15,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:15,212 INFO:     Epoch: 73
2023-01-04 05:46:16,759 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36837612887223564, 'Total loss': 0.36837612887223564} | train loss {'Reaction outcome loss': 0.29233748484810773, 'Total loss': 0.29233748484810773}
2023-01-04 05:46:16,759 INFO:     Found new best model at epoch 73
2023-01-04 05:46:16,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:16,760 INFO:     Epoch: 74
2023-01-04 05:46:18,300 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37068324685096743, 'Total loss': 0.37068324685096743} | train loss {'Reaction outcome loss': 0.28395787702642217, 'Total loss': 0.28395787702642217}
2023-01-04 05:46:18,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:18,301 INFO:     Epoch: 75
2023-01-04 05:46:19,838 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38073759774367016, 'Total loss': 0.38073759774367016} | train loss {'Reaction outcome loss': 0.2856047397384243, 'Total loss': 0.2856047397384243}
2023-01-04 05:46:19,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:19,838 INFO:     Epoch: 76
2023-01-04 05:46:21,323 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3831734468539556, 'Total loss': 0.3831734468539556} | train loss {'Reaction outcome loss': 0.2822200388368899, 'Total loss': 0.2822200388368899}
2023-01-04 05:46:21,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:21,324 INFO:     Epoch: 77
2023-01-04 05:46:22,862 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3537895252307256, 'Total loss': 0.3537895252307256} | train loss {'Reaction outcome loss': 0.28457501302235316, 'Total loss': 0.28457501302235316}
2023-01-04 05:46:22,863 INFO:     Found new best model at epoch 77
2023-01-04 05:46:22,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:22,863 INFO:     Epoch: 78
2023-01-04 05:46:24,410 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3688887407382329, 'Total loss': 0.3688887407382329} | train loss {'Reaction outcome loss': 0.280924057098527, 'Total loss': 0.280924057098527}
2023-01-04 05:46:24,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:24,410 INFO:     Epoch: 79
2023-01-04 05:46:25,949 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4122726281483968, 'Total loss': 0.4122726281483968} | train loss {'Reaction outcome loss': 0.28236741700420415, 'Total loss': 0.28236741700420415}
2023-01-04 05:46:25,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:25,949 INFO:     Epoch: 80
2023-01-04 05:46:27,481 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3790920754273733, 'Total loss': 0.3790920754273733} | train loss {'Reaction outcome loss': 0.2818443963888788, 'Total loss': 0.2818443963888788}
2023-01-04 05:46:27,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:27,483 INFO:     Epoch: 81
2023-01-04 05:46:29,017 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37648682594299315, 'Total loss': 0.37648682594299315} | train loss {'Reaction outcome loss': 0.283559867690732, 'Total loss': 0.283559867690732}
2023-01-04 05:46:29,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:29,017 INFO:     Epoch: 82
2023-01-04 05:46:30,509 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3905476003885269, 'Total loss': 0.3905476003885269} | train loss {'Reaction outcome loss': 0.27815591307343357, 'Total loss': 0.27815591307343357}
2023-01-04 05:46:30,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:30,509 INFO:     Epoch: 83
2023-01-04 05:46:32,079 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39680753548940023, 'Total loss': 0.39680753548940023} | train loss {'Reaction outcome loss': 0.2798634649927381, 'Total loss': 0.2798634649927381}
2023-01-04 05:46:32,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:32,080 INFO:     Epoch: 84
2023-01-04 05:46:33,700 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3808686787883441, 'Total loss': 0.3808686787883441} | train loss {'Reaction outcome loss': 0.27635299914727246, 'Total loss': 0.27635299914727246}
2023-01-04 05:46:33,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:33,701 INFO:     Epoch: 85
2023-01-04 05:46:35,314 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38194828828175864, 'Total loss': 0.38194828828175864} | train loss {'Reaction outcome loss': 0.27650066939638046, 'Total loss': 0.27650066939638046}
2023-01-04 05:46:35,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:35,314 INFO:     Epoch: 86
2023-01-04 05:46:36,898 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39563764333724977, 'Total loss': 0.39563764333724977} | train loss {'Reaction outcome loss': 0.274022257064272, 'Total loss': 0.274022257064272}
2023-01-04 05:46:36,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:36,898 INFO:     Epoch: 87
2023-01-04 05:46:38,442 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3852094441652298, 'Total loss': 0.3852094441652298} | train loss {'Reaction outcome loss': 0.2726700638631617, 'Total loss': 0.2726700638631617}
2023-01-04 05:46:38,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:38,442 INFO:     Epoch: 88
2023-01-04 05:46:39,928 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4078110734621684, 'Total loss': 0.4078110734621684} | train loss {'Reaction outcome loss': 0.2700292911978751, 'Total loss': 0.2700292911978751}
2023-01-04 05:46:39,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:39,928 INFO:     Epoch: 89
2023-01-04 05:46:41,470 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3897520969311396, 'Total loss': 0.3897520969311396} | train loss {'Reaction outcome loss': 0.2705131209027158, 'Total loss': 0.2705131209027158}
2023-01-04 05:46:41,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:41,470 INFO:     Epoch: 90
2023-01-04 05:46:43,011 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41383538047472634, 'Total loss': 0.41383538047472634} | train loss {'Reaction outcome loss': 0.2690093381887805, 'Total loss': 0.2690093381887805}
2023-01-04 05:46:43,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:43,011 INFO:     Epoch: 91
2023-01-04 05:46:44,591 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39553758800029754, 'Total loss': 0.39553758800029754} | train loss {'Reaction outcome loss': 0.27106089979736475, 'Total loss': 0.27106089979736475}
2023-01-04 05:46:44,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:44,591 INFO:     Epoch: 92
2023-01-04 05:46:46,128 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44250004092852274, 'Total loss': 0.44250004092852274} | train loss {'Reaction outcome loss': 0.2676109762821537, 'Total loss': 0.2676109762821537}
2023-01-04 05:46:46,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:46,129 INFO:     Epoch: 93
2023-01-04 05:46:47,657 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.368184561530749, 'Total loss': 0.368184561530749} | train loss {'Reaction outcome loss': 0.26879093233142454, 'Total loss': 0.26879093233142454}
2023-01-04 05:46:47,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:47,657 INFO:     Epoch: 94
2023-01-04 05:46:49,133 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39234223067760465, 'Total loss': 0.39234223067760465} | train loss {'Reaction outcome loss': 0.26870611777705866, 'Total loss': 0.26870611777705866}
2023-01-04 05:46:49,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:49,133 INFO:     Epoch: 95
2023-01-04 05:46:50,692 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3666324670116107, 'Total loss': 0.3666324670116107} | train loss {'Reaction outcome loss': 0.26696521443498394, 'Total loss': 0.26696521443498394}
2023-01-04 05:46:50,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:50,692 INFO:     Epoch: 96
2023-01-04 05:46:52,264 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40299963653087617, 'Total loss': 0.40299963653087617} | train loss {'Reaction outcome loss': 0.2642420015304628, 'Total loss': 0.2642420015304628}
2023-01-04 05:46:52,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:52,264 INFO:     Epoch: 97
2023-01-04 05:46:53,815 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4046822319428126, 'Total loss': 0.4046822319428126} | train loss {'Reaction outcome loss': 0.2656444100676662, 'Total loss': 0.2656444100676662}
2023-01-04 05:46:53,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:53,815 INFO:     Epoch: 98
2023-01-04 05:46:55,343 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4113818764686584, 'Total loss': 0.4113818764686584} | train loss {'Reaction outcome loss': 0.2682101011520972, 'Total loss': 0.2682101011520972}
2023-01-04 05:46:55,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:55,344 INFO:     Epoch: 99
2023-01-04 05:46:56,886 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.376719568669796, 'Total loss': 0.376719568669796} | train loss {'Reaction outcome loss': 0.263964107518431, 'Total loss': 0.263964107518431}
2023-01-04 05:46:56,886 INFO:     Best model found after epoch 78 of 100.
2023-01-04 05:46:56,886 INFO:   Done with stage: TRAINING
2023-01-04 05:46:56,886 INFO:   Starting stage: EVALUATION
2023-01-04 05:46:57,019 INFO:   Done with stage: EVALUATION
2023-01-04 05:46:57,019 INFO:   Leaving out SEQ value Fold_4
2023-01-04 05:46:57,031 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 05:46:57,031 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:46:57,672 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:46:57,674 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:46:57,743 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:46:57,743 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:46:57,743 INFO:     No hyperparam tuning for this model
2023-01-04 05:46:57,743 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:46:57,743 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:46:57,744 INFO:     None feature selector for col prot
2023-01-04 05:46:57,744 INFO:     None feature selector for col prot
2023-01-04 05:46:57,744 INFO:     None feature selector for col prot
2023-01-04 05:46:57,745 INFO:     None feature selector for col chem
2023-01-04 05:46:57,745 INFO:     None feature selector for col chem
2023-01-04 05:46:57,745 INFO:     None feature selector for col chem
2023-01-04 05:46:57,745 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:46:57,745 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:46:57,746 INFO:     Number of params in model 70111
2023-01-04 05:46:57,749 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:46:57,749 INFO:   Starting stage: TRAINING
2023-01-04 05:46:57,793 INFO:     Val loss before train {'Reaction outcome loss': 1.0205517133076987, 'Total loss': 1.0205517133076987}
2023-01-04 05:46:57,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:57,793 INFO:     Epoch: 0
2023-01-04 05:46:59,346 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6479754487673441, 'Total loss': 0.6479754487673441} | train loss {'Reaction outcome loss': 0.8284458314632848, 'Total loss': 0.8284458314632848}
2023-01-04 05:46:59,346 INFO:     Found new best model at epoch 0
2023-01-04 05:46:59,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:46:59,347 INFO:     Epoch: 1
2023-01-04 05:47:00,898 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5841069380442302, 'Total loss': 0.5841069380442302} | train loss {'Reaction outcome loss': 0.6627897560378931, 'Total loss': 0.6627897560378931}
2023-01-04 05:47:00,898 INFO:     Found new best model at epoch 1
2023-01-04 05:47:00,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:00,899 INFO:     Epoch: 2
2023-01-04 05:47:02,428 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5240221510330836, 'Total loss': 0.5240221510330836} | train loss {'Reaction outcome loss': 0.579719205026644, 'Total loss': 0.579719205026644}
2023-01-04 05:47:02,429 INFO:     Found new best model at epoch 2
2023-01-04 05:47:02,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:02,429 INFO:     Epoch: 3
2023-01-04 05:47:03,971 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5435544113318126, 'Total loss': 0.5435544113318126} | train loss {'Reaction outcome loss': 0.5368839902599363, 'Total loss': 0.5368839902599363}
2023-01-04 05:47:03,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:03,972 INFO:     Epoch: 4
2023-01-04 05:47:05,518 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5236761331558227, 'Total loss': 0.5236761331558227} | train loss {'Reaction outcome loss': 0.510436556308809, 'Total loss': 0.510436556308809}
2023-01-04 05:47:05,518 INFO:     Found new best model at epoch 4
2023-01-04 05:47:05,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:05,519 INFO:     Epoch: 5
2023-01-04 05:47:07,005 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5077271521091461, 'Total loss': 0.5077271521091461} | train loss {'Reaction outcome loss': 0.4960499944260521, 'Total loss': 0.4960499944260521}
2023-01-04 05:47:07,005 INFO:     Found new best model at epoch 5
2023-01-04 05:47:07,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:07,006 INFO:     Epoch: 6
2023-01-04 05:47:08,561 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48703826665878297, 'Total loss': 0.48703826665878297} | train loss {'Reaction outcome loss': 0.4804694728150855, 'Total loss': 0.4804694728150855}
2023-01-04 05:47:08,562 INFO:     Found new best model at epoch 6
2023-01-04 05:47:08,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:08,562 INFO:     Epoch: 7
2023-01-04 05:47:10,124 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4772170901298523, 'Total loss': 0.4772170901298523} | train loss {'Reaction outcome loss': 0.47140177426329494, 'Total loss': 0.47140177426329494}
2023-01-04 05:47:10,125 INFO:     Found new best model at epoch 7
2023-01-04 05:47:10,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:10,125 INFO:     Epoch: 8
2023-01-04 05:47:11,674 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4960987706979116, 'Total loss': 0.4960987706979116} | train loss {'Reaction outcome loss': 0.4609222714483303, 'Total loss': 0.4609222714483303}
2023-01-04 05:47:11,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:11,675 INFO:     Epoch: 9
2023-01-04 05:47:13,219 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46905396481355033, 'Total loss': 0.46905396481355033} | train loss {'Reaction outcome loss': 0.449554029009203, 'Total loss': 0.449554029009203}
2023-01-04 05:47:13,219 INFO:     Found new best model at epoch 9
2023-01-04 05:47:13,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:13,220 INFO:     Epoch: 10
2023-01-04 05:47:14,755 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4841492553551992, 'Total loss': 0.4841492553551992} | train loss {'Reaction outcome loss': 0.44721540563950574, 'Total loss': 0.44721540563950574}
2023-01-04 05:47:14,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:14,755 INFO:     Epoch: 11
2023-01-04 05:47:16,219 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45047709743181863, 'Total loss': 0.45047709743181863} | train loss {'Reaction outcome loss': 0.44099369949667994, 'Total loss': 0.44099369949667994}
2023-01-04 05:47:16,220 INFO:     Found new best model at epoch 11
2023-01-04 05:47:16,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:16,220 INFO:     Epoch: 12
2023-01-04 05:47:17,777 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4736606995264689, 'Total loss': 0.4736606995264689} | train loss {'Reaction outcome loss': 0.4376383312862285, 'Total loss': 0.4376383312862285}
2023-01-04 05:47:17,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:17,777 INFO:     Epoch: 13
2023-01-04 05:47:19,332 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4376005987326304, 'Total loss': 0.4376005987326304} | train loss {'Reaction outcome loss': 0.4330590261812628, 'Total loss': 0.4330590261812628}
2023-01-04 05:47:19,332 INFO:     Found new best model at epoch 13
2023-01-04 05:47:19,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:19,333 INFO:     Epoch: 14
2023-01-04 05:47:20,915 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4744879961013794, 'Total loss': 0.4744879961013794} | train loss {'Reaction outcome loss': 0.4248396067941276, 'Total loss': 0.4248396067941276}
2023-01-04 05:47:20,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:20,916 INFO:     Epoch: 15
2023-01-04 05:47:22,489 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44314063191413877, 'Total loss': 0.44314063191413877} | train loss {'Reaction outcome loss': 0.42092494413691717, 'Total loss': 0.42092494413691717}
2023-01-04 05:47:22,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:22,489 INFO:     Epoch: 16
2023-01-04 05:47:24,063 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45330689549446107, 'Total loss': 0.45330689549446107} | train loss {'Reaction outcome loss': 0.41851331720495744, 'Total loss': 0.41851331720495744}
2023-01-04 05:47:24,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:24,063 INFO:     Epoch: 17
2023-01-04 05:47:25,545 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4370027979214986, 'Total loss': 0.4370027979214986} | train loss {'Reaction outcome loss': 0.4157796766962448, 'Total loss': 0.4157796766962448}
2023-01-04 05:47:25,545 INFO:     Found new best model at epoch 17
2023-01-04 05:47:25,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:25,546 INFO:     Epoch: 18
2023-01-04 05:47:27,080 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4682598869005839, 'Total loss': 0.4682598869005839} | train loss {'Reaction outcome loss': 0.40369732030769334, 'Total loss': 0.40369732030769334}
2023-01-04 05:47:27,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:27,080 INFO:     Epoch: 19
2023-01-04 05:47:28,644 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4814475804567337, 'Total loss': 0.4814475804567337} | train loss {'Reaction outcome loss': 0.40343492915921836, 'Total loss': 0.40343492915921836}
2023-01-04 05:47:28,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:28,645 INFO:     Epoch: 20
2023-01-04 05:47:30,205 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44449856082598366, 'Total loss': 0.44449856082598366} | train loss {'Reaction outcome loss': 0.3996446707496678, 'Total loss': 0.3996446707496678}
2023-01-04 05:47:30,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:30,205 INFO:     Epoch: 21
2023-01-04 05:47:31,769 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46665830810864767, 'Total loss': 0.46665830810864767} | train loss {'Reaction outcome loss': 0.3952169093119837, 'Total loss': 0.3952169093119837}
2023-01-04 05:47:31,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:31,769 INFO:     Epoch: 22
2023-01-04 05:47:33,300 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4306399087111155, 'Total loss': 0.4306399087111155} | train loss {'Reaction outcome loss': 0.3956121961402632, 'Total loss': 0.3956121961402632}
2023-01-04 05:47:33,300 INFO:     Found new best model at epoch 22
2023-01-04 05:47:33,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:33,301 INFO:     Epoch: 23
2023-01-04 05:47:34,809 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42742495735486347, 'Total loss': 0.42742495735486347} | train loss {'Reaction outcome loss': 0.38948214219978256, 'Total loss': 0.38948214219978256}
2023-01-04 05:47:34,809 INFO:     Found new best model at epoch 23
2023-01-04 05:47:34,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:34,810 INFO:     Epoch: 24
2023-01-04 05:47:36,358 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41781323750813804, 'Total loss': 0.41781323750813804} | train loss {'Reaction outcome loss': 0.38593967220861547, 'Total loss': 0.38593967220861547}
2023-01-04 05:47:36,358 INFO:     Found new best model at epoch 24
2023-01-04 05:47:36,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:36,359 INFO:     Epoch: 25
2023-01-04 05:47:37,894 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44205279300610223, 'Total loss': 0.44205279300610223} | train loss {'Reaction outcome loss': 0.37925761206632985, 'Total loss': 0.37925761206632985}
2023-01-04 05:47:37,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:37,895 INFO:     Epoch: 26
2023-01-04 05:47:39,437 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45081562797228497, 'Total loss': 0.45081562797228497} | train loss {'Reaction outcome loss': 0.37771542663991886, 'Total loss': 0.37771542663991886}
2023-01-04 05:47:39,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:39,437 INFO:     Epoch: 27
2023-01-04 05:47:40,972 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44034622808297474, 'Total loss': 0.44034622808297474} | train loss {'Reaction outcome loss': 0.37374558734850294, 'Total loss': 0.37374558734850294}
2023-01-04 05:47:40,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:40,972 INFO:     Epoch: 28
2023-01-04 05:47:42,500 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4086370348930359, 'Total loss': 0.4086370348930359} | train loss {'Reaction outcome loss': 0.37221984249831985, 'Total loss': 0.37221984249831985}
2023-01-04 05:47:42,501 INFO:     Found new best model at epoch 28
2023-01-04 05:47:42,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:42,501 INFO:     Epoch: 29
2023-01-04 05:47:44,006 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4119728962580363, 'Total loss': 0.4119728962580363} | train loss {'Reaction outcome loss': 0.36429118171986874, 'Total loss': 0.36429118171986874}
2023-01-04 05:47:44,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:44,007 INFO:     Epoch: 30
2023-01-04 05:47:45,560 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4192367772261302, 'Total loss': 0.4192367772261302} | train loss {'Reaction outcome loss': 0.3606037453741488, 'Total loss': 0.3606037453741488}
2023-01-04 05:47:45,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:45,560 INFO:     Epoch: 31
2023-01-04 05:47:47,100 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39467434386412303, 'Total loss': 0.39467434386412303} | train loss {'Reaction outcome loss': 0.3632726619822265, 'Total loss': 0.3632726619822265}
2023-01-04 05:47:47,100 INFO:     Found new best model at epoch 31
2023-01-04 05:47:47,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:47,101 INFO:     Epoch: 32
2023-01-04 05:47:48,620 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4245181659857432, 'Total loss': 0.4245181659857432} | train loss {'Reaction outcome loss': 0.3591025685415651, 'Total loss': 0.3591025685415651}
2023-01-04 05:47:48,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:48,621 INFO:     Epoch: 33
2023-01-04 05:47:50,171 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4301063855489095, 'Total loss': 0.4301063855489095} | train loss {'Reaction outcome loss': 0.355696228217252, 'Total loss': 0.355696228217252}
2023-01-04 05:47:50,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:50,171 INFO:     Epoch: 34
2023-01-04 05:47:51,689 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4028472373882929, 'Total loss': 0.4028472373882929} | train loss {'Reaction outcome loss': 0.3504865814517014, 'Total loss': 0.3504865814517014}
2023-01-04 05:47:51,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:51,689 INFO:     Epoch: 35
2023-01-04 05:47:53,199 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40547904272874197, 'Total loss': 0.40547904272874197} | train loss {'Reaction outcome loss': 0.3499656641570321, 'Total loss': 0.3499656641570321}
2023-01-04 05:47:53,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:53,200 INFO:     Epoch: 36
2023-01-04 05:47:54,738 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.413887956738472, 'Total loss': 0.413887956738472} | train loss {'Reaction outcome loss': 0.3447253862871741, 'Total loss': 0.3447253862871741}
2023-01-04 05:47:54,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:54,738 INFO:     Epoch: 37
2023-01-04 05:47:56,276 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40233761866887413, 'Total loss': 0.40233761866887413} | train loss {'Reaction outcome loss': 0.34136034167596024, 'Total loss': 0.34136034167596024}
2023-01-04 05:47:56,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:56,277 INFO:     Epoch: 38
2023-01-04 05:47:57,837 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42084042529265087, 'Total loss': 0.42084042529265087} | train loss {'Reaction outcome loss': 0.3389706947861144, 'Total loss': 0.3389706947861144}
2023-01-04 05:47:57,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:57,837 INFO:     Epoch: 39
2023-01-04 05:47:59,382 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40038742621739704, 'Total loss': 0.40038742621739704} | train loss {'Reaction outcome loss': 0.3410182484989836, 'Total loss': 0.3410182484989836}
2023-01-04 05:47:59,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:47:59,383 INFO:     Epoch: 40
2023-01-04 05:48:00,904 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3804986298084259, 'Total loss': 0.3804986298084259} | train loss {'Reaction outcome loss': 0.3345276889030951, 'Total loss': 0.3345276889030951}
2023-01-04 05:48:00,904 INFO:     Found new best model at epoch 40
2023-01-04 05:48:00,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:00,904 INFO:     Epoch: 41
2023-01-04 05:48:02,427 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3948832703133424, 'Total loss': 0.3948832703133424} | train loss {'Reaction outcome loss': 0.33371709504701796, 'Total loss': 0.33371709504701796}
2023-01-04 05:48:02,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:02,427 INFO:     Epoch: 42
2023-01-04 05:48:03,967 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38808615108331046, 'Total loss': 0.38808615108331046} | train loss {'Reaction outcome loss': 0.33242376178611804, 'Total loss': 0.33242376178611804}
2023-01-04 05:48:03,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:03,967 INFO:     Epoch: 43
2023-01-04 05:48:05,516 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41796892484029136, 'Total loss': 0.41796892484029136} | train loss {'Reaction outcome loss': 0.3245280594666944, 'Total loss': 0.3245280594666944}
2023-01-04 05:48:05,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:05,517 INFO:     Epoch: 44
2023-01-04 05:48:07,054 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40571296215057373, 'Total loss': 0.40571296215057373} | train loss {'Reaction outcome loss': 0.32495069106782437, 'Total loss': 0.32495069106782437}
2023-01-04 05:48:07,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:07,054 INFO:     Epoch: 45
2023-01-04 05:48:08,600 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3895191381374995, 'Total loss': 0.3895191381374995} | train loss {'Reaction outcome loss': 0.32110562103453777, 'Total loss': 0.32110562103453777}
2023-01-04 05:48:08,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:08,600 INFO:     Epoch: 46
2023-01-04 05:48:10,125 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4066295479734739, 'Total loss': 0.4066295479734739} | train loss {'Reaction outcome loss': 0.32331584733876867, 'Total loss': 0.32331584733876867}
2023-01-04 05:48:10,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:10,125 INFO:     Epoch: 47
2023-01-04 05:48:11,637 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3757336914539337, 'Total loss': 0.3757336914539337} | train loss {'Reaction outcome loss': 0.31864764272187746, 'Total loss': 0.31864764272187746}
2023-01-04 05:48:11,637 INFO:     Found new best model at epoch 47
2023-01-04 05:48:11,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:11,638 INFO:     Epoch: 48
2023-01-04 05:48:13,160 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38744514584541323, 'Total loss': 0.38744514584541323} | train loss {'Reaction outcome loss': 0.3165971642754374, 'Total loss': 0.3165971642754374}
2023-01-04 05:48:13,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:13,161 INFO:     Epoch: 49
2023-01-04 05:48:14,678 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37482992112636565, 'Total loss': 0.37482992112636565} | train loss {'Reaction outcome loss': 0.3128832010076429, 'Total loss': 0.3128832010076429}
2023-01-04 05:48:14,678 INFO:     Found new best model at epoch 49
2023-01-04 05:48:14,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:14,679 INFO:     Epoch: 50
2023-01-04 05:48:16,205 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3641686568657557, 'Total loss': 0.3641686568657557} | train loss {'Reaction outcome loss': 0.3107434654621965, 'Total loss': 0.3107434654621965}
2023-01-04 05:48:16,205 INFO:     Found new best model at epoch 50
2023-01-04 05:48:16,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:16,206 INFO:     Epoch: 51
2023-01-04 05:48:17,731 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39944156209627785, 'Total loss': 0.39944156209627785} | train loss {'Reaction outcome loss': 0.3110570925811346, 'Total loss': 0.3110570925811346}
2023-01-04 05:48:17,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:17,732 INFO:     Epoch: 52
2023-01-04 05:48:19,218 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4128482530514399, 'Total loss': 0.4128482530514399} | train loss {'Reaction outcome loss': 0.30663154557020994, 'Total loss': 0.30663154557020994}
2023-01-04 05:48:19,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:19,219 INFO:     Epoch: 53
2023-01-04 05:48:20,737 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38869387010733286, 'Total loss': 0.38869387010733286} | train loss {'Reaction outcome loss': 0.3088757406893003, 'Total loss': 0.3088757406893003}
2023-01-04 05:48:20,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:20,737 INFO:     Epoch: 54
2023-01-04 05:48:22,267 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38319311837355297, 'Total loss': 0.38319311837355297} | train loss {'Reaction outcome loss': 0.3042872103515768, 'Total loss': 0.3042872103515768}
2023-01-04 05:48:22,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:22,267 INFO:     Epoch: 55
2023-01-04 05:48:23,817 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36915604074796043, 'Total loss': 0.36915604074796043} | train loss {'Reaction outcome loss': 0.30807874237533905, 'Total loss': 0.30807874237533905}
2023-01-04 05:48:23,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:23,817 INFO:     Epoch: 56
2023-01-04 05:48:25,346 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4129820386568705, 'Total loss': 0.4129820386568705} | train loss {'Reaction outcome loss': 0.30077142885675395, 'Total loss': 0.30077142885675395}
2023-01-04 05:48:25,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:25,347 INFO:     Epoch: 57
2023-01-04 05:48:26,890 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3937025050322215, 'Total loss': 0.3937025050322215} | train loss {'Reaction outcome loss': 0.2992912515127746, 'Total loss': 0.2992912515127746}
2023-01-04 05:48:26,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:26,891 INFO:     Epoch: 58
2023-01-04 05:48:28,380 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.379716361562411, 'Total loss': 0.379716361562411} | train loss {'Reaction outcome loss': 0.29814915742426024, 'Total loss': 0.29814915742426024}
2023-01-04 05:48:28,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:28,380 INFO:     Epoch: 59
2023-01-04 05:48:29,924 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.378955148657163, 'Total loss': 0.378955148657163} | train loss {'Reaction outcome loss': 0.2965102879344112, 'Total loss': 0.2965102879344112}
2023-01-04 05:48:29,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:29,925 INFO:     Epoch: 60
2023-01-04 05:48:31,464 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37982009202241895, 'Total loss': 0.37982009202241895} | train loss {'Reaction outcome loss': 0.29908497925222355, 'Total loss': 0.29908497925222355}
2023-01-04 05:48:31,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:31,464 INFO:     Epoch: 61
2023-01-04 05:48:32,993 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.35414575835069023, 'Total loss': 0.35414575835069023} | train loss {'Reaction outcome loss': 0.2920827772604288, 'Total loss': 0.2920827772604288}
2023-01-04 05:48:32,993 INFO:     Found new best model at epoch 61
2023-01-04 05:48:32,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:32,994 INFO:     Epoch: 62
2023-01-04 05:48:34,522 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3861088703076045, 'Total loss': 0.3861088703076045} | train loss {'Reaction outcome loss': 0.289726647963054, 'Total loss': 0.289726647963054}
2023-01-04 05:48:34,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:34,522 INFO:     Epoch: 63
2023-01-04 05:48:36,054 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3696372240781784, 'Total loss': 0.3696372240781784} | train loss {'Reaction outcome loss': 0.2884240436238529, 'Total loss': 0.2884240436238529}
2023-01-04 05:48:36,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:36,055 INFO:     Epoch: 64
2023-01-04 05:48:37,533 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35614230632781985, 'Total loss': 0.35614230632781985} | train loss {'Reaction outcome loss': 0.2899449260592678, 'Total loss': 0.2899449260592678}
2023-01-04 05:48:37,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:37,533 INFO:     Epoch: 65
2023-01-04 05:48:39,074 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35872221291065215, 'Total loss': 0.35872221291065215} | train loss {'Reaction outcome loss': 0.28776093997931396, 'Total loss': 0.28776093997931396}
2023-01-04 05:48:39,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:39,074 INFO:     Epoch: 66
2023-01-04 05:48:40,621 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.34680569370587666, 'Total loss': 0.34680569370587666} | train loss {'Reaction outcome loss': 0.28763501400495095, 'Total loss': 0.28763501400495095}
2023-01-04 05:48:40,621 INFO:     Found new best model at epoch 66
2023-01-04 05:48:40,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:40,622 INFO:     Epoch: 67
2023-01-04 05:48:42,161 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3507718503475189, 'Total loss': 0.3507718503475189} | train loss {'Reaction outcome loss': 0.2812950347081153, 'Total loss': 0.2812950347081153}
2023-01-04 05:48:42,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:42,161 INFO:     Epoch: 68
2023-01-04 05:48:43,697 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3940686682860057, 'Total loss': 0.3940686682860057} | train loss {'Reaction outcome loss': 0.2863553338378233, 'Total loss': 0.2863553338378233}
2023-01-04 05:48:43,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:43,698 INFO:     Epoch: 69
2023-01-04 05:48:45,233 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3695071925719579, 'Total loss': 0.3695071925719579} | train loss {'Reaction outcome loss': 0.2804575466081826, 'Total loss': 0.2804575466081826}
2023-01-04 05:48:45,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:45,233 INFO:     Epoch: 70
2023-01-04 05:48:46,700 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39551831980546315, 'Total loss': 0.39551831980546315} | train loss {'Reaction outcome loss': 0.27964193828023265, 'Total loss': 0.27964193828023265}
2023-01-04 05:48:46,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:46,700 INFO:     Epoch: 71
2023-01-04 05:48:48,229 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.33312618335088096, 'Total loss': 0.33312618335088096} | train loss {'Reaction outcome loss': 0.277605079957386, 'Total loss': 0.277605079957386}
2023-01-04 05:48:48,230 INFO:     Found new best model at epoch 71
2023-01-04 05:48:48,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:48,231 INFO:     Epoch: 72
2023-01-04 05:48:49,769 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41177761753400166, 'Total loss': 0.41177761753400166} | train loss {'Reaction outcome loss': 0.27525264756196605, 'Total loss': 0.27525264756196605}
2023-01-04 05:48:49,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:49,770 INFO:     Epoch: 73
2023-01-04 05:48:51,304 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40291398465633393, 'Total loss': 0.40291398465633393} | train loss {'Reaction outcome loss': 0.2769662098224907, 'Total loss': 0.2769662098224907}
2023-01-04 05:48:51,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:51,304 INFO:     Epoch: 74
2023-01-04 05:48:52,854 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4045387049516042, 'Total loss': 0.4045387049516042} | train loss {'Reaction outcome loss': 0.2748388444501771, 'Total loss': 0.2748388444501771}
2023-01-04 05:48:52,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:52,854 INFO:     Epoch: 75
2023-01-04 05:48:54,409 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3693755090236664, 'Total loss': 0.3693755090236664} | train loss {'Reaction outcome loss': 0.27110456512139663, 'Total loss': 0.27110456512139663}
2023-01-04 05:48:54,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:54,409 INFO:     Epoch: 76
2023-01-04 05:48:55,892 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36325758894284566, 'Total loss': 0.36325758894284566} | train loss {'Reaction outcome loss': 0.27370969953871993, 'Total loss': 0.27370969953871993}
2023-01-04 05:48:55,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:55,892 INFO:     Epoch: 77
2023-01-04 05:48:57,454 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36451934774716693, 'Total loss': 0.36451934774716693} | train loss {'Reaction outcome loss': 0.27316857704444086, 'Total loss': 0.27316857704444086}
2023-01-04 05:48:57,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:57,455 INFO:     Epoch: 78
2023-01-04 05:48:58,994 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36400731007258097, 'Total loss': 0.36400731007258097} | train loss {'Reaction outcome loss': 0.27282260502450656, 'Total loss': 0.27282260502450656}
2023-01-04 05:48:58,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:48:58,994 INFO:     Epoch: 79
2023-01-04 05:49:00,530 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.375641659895579, 'Total loss': 0.375641659895579} | train loss {'Reaction outcome loss': 0.273398295044899, 'Total loss': 0.273398295044899}
2023-01-04 05:49:00,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:00,532 INFO:     Epoch: 80
2023-01-04 05:49:02,082 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3637688547372818, 'Total loss': 0.3637688547372818} | train loss {'Reaction outcome loss': 0.26858182429560346, 'Total loss': 0.26858182429560346}
2023-01-04 05:49:02,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:02,083 INFO:     Epoch: 81
2023-01-04 05:49:03,637 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3609626690546672, 'Total loss': 0.3609626690546672} | train loss {'Reaction outcome loss': 0.2679051632591843, 'Total loss': 0.2679051632591843}
2023-01-04 05:49:03,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:03,638 INFO:     Epoch: 82
2023-01-04 05:49:05,121 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.384701939423879, 'Total loss': 0.384701939423879} | train loss {'Reaction outcome loss': 0.2658786370697683, 'Total loss': 0.2658786370697683}
2023-01-04 05:49:05,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:05,121 INFO:     Epoch: 83
2023-01-04 05:49:06,684 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3616215229034424, 'Total loss': 0.3616215229034424} | train loss {'Reaction outcome loss': 0.2612443151509892, 'Total loss': 0.2612443151509892}
2023-01-04 05:49:06,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:06,684 INFO:     Epoch: 84
2023-01-04 05:49:08,264 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3581686168909073, 'Total loss': 0.3581686168909073} | train loss {'Reaction outcome loss': 0.2638676690522337, 'Total loss': 0.2638676690522337}
2023-01-04 05:49:08,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:08,264 INFO:     Epoch: 85
2023-01-04 05:49:09,820 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3634164144595464, 'Total loss': 0.3634164144595464} | train loss {'Reaction outcome loss': 0.26636276595348857, 'Total loss': 0.26636276595348857}
2023-01-04 05:49:09,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:09,820 INFO:     Epoch: 86
2023-01-04 05:49:11,385 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3739735593398412, 'Total loss': 0.3739735593398412} | train loss {'Reaction outcome loss': 0.2685034518014558, 'Total loss': 0.2685034518014558}
2023-01-04 05:49:11,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:11,386 INFO:     Epoch: 87
2023-01-04 05:49:12,983 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3734310920039813, 'Total loss': 0.3734310920039813} | train loss {'Reaction outcome loss': 0.2643211440040465, 'Total loss': 0.2643211440040465}
2023-01-04 05:49:12,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:12,983 INFO:     Epoch: 88
2023-01-04 05:49:14,480 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3535458887616793, 'Total loss': 0.3535458887616793} | train loss {'Reaction outcome loss': 0.2603343618204341, 'Total loss': 0.2603343618204341}
2023-01-04 05:49:14,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:14,480 INFO:     Epoch: 89
2023-01-04 05:49:16,049 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35956025421619414, 'Total loss': 0.35956025421619414} | train loss {'Reaction outcome loss': 0.2585152999300809, 'Total loss': 0.2585152999300809}
2023-01-04 05:49:16,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:16,049 INFO:     Epoch: 90
2023-01-04 05:49:17,629 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3462179064750671, 'Total loss': 0.3462179064750671} | train loss {'Reaction outcome loss': 0.25925945860408517, 'Total loss': 0.25925945860408517}
2023-01-04 05:49:17,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:17,629 INFO:     Epoch: 91
2023-01-04 05:49:19,236 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3799454386035601, 'Total loss': 0.3799454386035601} | train loss {'Reaction outcome loss': 0.26190195357712515, 'Total loss': 0.26190195357712515}
2023-01-04 05:49:19,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:19,237 INFO:     Epoch: 92
2023-01-04 05:49:20,811 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35978005031744636, 'Total loss': 0.35978005031744636} | train loss {'Reaction outcome loss': 0.258139317297805, 'Total loss': 0.258139317297805}
2023-01-04 05:49:20,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:20,811 INFO:     Epoch: 93
2023-01-04 05:49:22,363 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37007843653361, 'Total loss': 0.37007843653361} | train loss {'Reaction outcome loss': 0.2559309203830296, 'Total loss': 0.2559309203830296}
2023-01-04 05:49:22,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:22,363 INFO:     Epoch: 94
2023-01-04 05:49:23,874 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3696034421523412, 'Total loss': 0.3696034421523412} | train loss {'Reaction outcome loss': 0.2574658105489764, 'Total loss': 0.2574658105489764}
2023-01-04 05:49:23,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:23,874 INFO:     Epoch: 95
2023-01-04 05:49:25,429 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39011410375436145, 'Total loss': 0.39011410375436145} | train loss {'Reaction outcome loss': 0.25366004817459703, 'Total loss': 0.25366004817459703}
2023-01-04 05:49:25,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:25,429 INFO:     Epoch: 96
2023-01-04 05:49:26,992 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38822297354539237, 'Total loss': 0.38822297354539237} | train loss {'Reaction outcome loss': 0.2591677638600125, 'Total loss': 0.2591677638600125}
2023-01-04 05:49:26,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:26,992 INFO:     Epoch: 97
2023-01-04 05:49:28,553 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.376715221007665, 'Total loss': 0.376715221007665} | train loss {'Reaction outcome loss': 0.2538028768379323, 'Total loss': 0.2538028768379323}
2023-01-04 05:49:28,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:28,553 INFO:     Epoch: 98
2023-01-04 05:49:30,107 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.35750416020552317, 'Total loss': 0.35750416020552317} | train loss {'Reaction outcome loss': 0.25347918504509176, 'Total loss': 0.25347918504509176}
2023-01-04 05:49:30,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:30,107 INFO:     Epoch: 99
2023-01-04 05:49:31,638 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3902762909730276, 'Total loss': 0.3902762909730276} | train loss {'Reaction outcome loss': 0.2523143734769338, 'Total loss': 0.2523143734769338}
2023-01-04 05:49:31,638 INFO:     Best model found after epoch 72 of 100.
2023-01-04 05:49:31,638 INFO:   Done with stage: TRAINING
2023-01-04 05:49:31,638 INFO:   Starting stage: EVALUATION
2023-01-04 05:49:31,767 INFO:   Done with stage: EVALUATION
2023-01-04 05:49:31,768 INFO:   Leaving out SEQ value Fold_5
2023-01-04 05:49:31,780 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 05:49:31,780 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:49:32,429 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:49:32,429 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:49:32,500 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:49:32,500 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:49:32,500 INFO:     No hyperparam tuning for this model
2023-01-04 05:49:32,500 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:49:32,500 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:49:32,501 INFO:     None feature selector for col prot
2023-01-04 05:49:32,501 INFO:     None feature selector for col prot
2023-01-04 05:49:32,501 INFO:     None feature selector for col prot
2023-01-04 05:49:32,501 INFO:     None feature selector for col chem
2023-01-04 05:49:32,501 INFO:     None feature selector for col chem
2023-01-04 05:49:32,502 INFO:     None feature selector for col chem
2023-01-04 05:49:32,502 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:49:32,502 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:49:32,503 INFO:     Number of params in model 70111
2023-01-04 05:49:32,506 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:49:32,506 INFO:   Starting stage: TRAINING
2023-01-04 05:49:32,548 INFO:     Val loss before train {'Reaction outcome loss': 1.0444004972775778, 'Total loss': 1.0444004972775778}
2023-01-04 05:49:32,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:32,548 INFO:     Epoch: 0
2023-01-04 05:49:34,122 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7935445566972097, 'Total loss': 0.7935445566972097} | train loss {'Reaction outcome loss': 0.8517157055869482, 'Total loss': 0.8517157055869482}
2023-01-04 05:49:34,122 INFO:     Found new best model at epoch 0
2023-01-04 05:49:34,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:34,123 INFO:     Epoch: 1
2023-01-04 05:49:35,698 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6422129809856415, 'Total loss': 0.6422129809856415} | train loss {'Reaction outcome loss': 0.7036649943261907, 'Total loss': 0.7036649943261907}
2023-01-04 05:49:35,698 INFO:     Found new best model at epoch 1
2023-01-04 05:49:35,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:35,699 INFO:     Epoch: 2
2023-01-04 05:49:37,251 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5733832478523254, 'Total loss': 0.5733832478523254} | train loss {'Reaction outcome loss': 0.6106569754040759, 'Total loss': 0.6106569754040759}
2023-01-04 05:49:37,252 INFO:     Found new best model at epoch 2
2023-01-04 05:49:37,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:37,253 INFO:     Epoch: 3
2023-01-04 05:49:38,821 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5321850995222728, 'Total loss': 0.5321850995222728} | train loss {'Reaction outcome loss': 0.5534133837107852, 'Total loss': 0.5534133837107852}
2023-01-04 05:49:38,821 INFO:     Found new best model at epoch 3
2023-01-04 05:49:38,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:38,822 INFO:     Epoch: 4
2023-01-04 05:49:40,300 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5085647225379943, 'Total loss': 0.5085647225379943} | train loss {'Reaction outcome loss': 0.5216989541878465, 'Total loss': 0.5216989541878465}
2023-01-04 05:49:40,300 INFO:     Found new best model at epoch 4
2023-01-04 05:49:40,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:40,301 INFO:     Epoch: 5
2023-01-04 05:49:41,328 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.520206888516744, 'Total loss': 0.520206888516744} | train loss {'Reaction outcome loss': 0.5052406238931892, 'Total loss': 0.5052406238931892}
2023-01-04 05:49:41,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:41,328 INFO:     Epoch: 6
2023-01-04 05:49:42,346 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5092720150947571, 'Total loss': 0.5092720150947571} | train loss {'Reaction outcome loss': 0.49453906687921373, 'Total loss': 0.49453906687921373}
2023-01-04 05:49:42,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:42,346 INFO:     Epoch: 7
2023-01-04 05:49:43,362 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5199077705542247, 'Total loss': 0.5199077705542247} | train loss {'Reaction outcome loss': 0.48577054984111717, 'Total loss': 0.48577054984111717}
2023-01-04 05:49:43,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:43,363 INFO:     Epoch: 8
2023-01-04 05:49:44,378 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48339682519435884, 'Total loss': 0.48339682519435884} | train loss {'Reaction outcome loss': 0.49846153312187264, 'Total loss': 0.49846153312187264}
2023-01-04 05:49:44,378 INFO:     Found new best model at epoch 8
2023-01-04 05:49:44,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:44,379 INFO:     Epoch: 9
2023-01-04 05:49:45,832 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48256305456161497, 'Total loss': 0.48256305456161497} | train loss {'Reaction outcome loss': 0.489356204111507, 'Total loss': 0.489356204111507}
2023-01-04 05:49:45,832 INFO:     Found new best model at epoch 9
2023-01-04 05:49:45,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:45,833 INFO:     Epoch: 10
2023-01-04 05:49:47,416 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48472560743490856, 'Total loss': 0.48472560743490856} | train loss {'Reaction outcome loss': 0.46841569944028405, 'Total loss': 0.46841569944028405}
2023-01-04 05:49:47,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:47,416 INFO:     Epoch: 11
2023-01-04 05:49:48,974 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49360723892847697, 'Total loss': 0.49360723892847697} | train loss {'Reaction outcome loss': 0.45185256072558777, 'Total loss': 0.45185256072558777}
2023-01-04 05:49:48,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:48,974 INFO:     Epoch: 12
2023-01-04 05:49:50,535 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47476856112480165, 'Total loss': 0.47476856112480165} | train loss {'Reaction outcome loss': 0.44752231095850037, 'Total loss': 0.44752231095850037}
2023-01-04 05:49:50,535 INFO:     Found new best model at epoch 12
2023-01-04 05:49:50,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:50,536 INFO:     Epoch: 13
2023-01-04 05:49:52,093 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47418695092201235, 'Total loss': 0.47418695092201235} | train loss {'Reaction outcome loss': 0.4420634184734545, 'Total loss': 0.4420634184734545}
2023-01-04 05:49:52,093 INFO:     Found new best model at epoch 13
2023-01-04 05:49:52,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:52,093 INFO:     Epoch: 14
2023-01-04 05:49:53,668 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47725009322166445, 'Total loss': 0.47725009322166445} | train loss {'Reaction outcome loss': 0.4400162717607547, 'Total loss': 0.4400162717607547}
2023-01-04 05:49:53,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:53,668 INFO:     Epoch: 15
2023-01-04 05:49:55,192 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4655453403790792, 'Total loss': 0.4655453403790792} | train loss {'Reaction outcome loss': 0.4348491817162003, 'Total loss': 0.4348491817162003}
2023-01-04 05:49:55,192 INFO:     Found new best model at epoch 15
2023-01-04 05:49:55,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:55,193 INFO:     Epoch: 16
2023-01-04 05:49:56,733 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44087883035341896, 'Total loss': 0.44087883035341896} | train loss {'Reaction outcome loss': 0.4311994370984156, 'Total loss': 0.4311994370984156}
2023-01-04 05:49:56,733 INFO:     Found new best model at epoch 16
2023-01-04 05:49:56,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:56,734 INFO:     Epoch: 17
2023-01-04 05:49:58,299 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4501159975926081, 'Total loss': 0.4501159975926081} | train loss {'Reaction outcome loss': 0.425581966139388, 'Total loss': 0.425581966139388}
2023-01-04 05:49:58,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:58,299 INFO:     Epoch: 18
2023-01-04 05:49:59,873 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4596260368824005, 'Total loss': 0.4596260368824005} | train loss {'Reaction outcome loss': 0.4262949941997404, 'Total loss': 0.4262949941997404}
2023-01-04 05:49:59,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:49:59,873 INFO:     Epoch: 19
2023-01-04 05:50:01,434 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4521945804357529, 'Total loss': 0.4521945804357529} | train loss {'Reaction outcome loss': 0.4209048138067558, 'Total loss': 0.4209048138067558}
2023-01-04 05:50:01,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:01,434 INFO:     Epoch: 20
2023-01-04 05:50:02,986 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4471190889676412, 'Total loss': 0.4471190889676412} | train loss {'Reaction outcome loss': 0.4144217402643045, 'Total loss': 0.4144217402643045}
2023-01-04 05:50:02,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:02,986 INFO:     Epoch: 21
2023-01-04 05:50:04,542 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4404007226228714, 'Total loss': 0.4404007226228714} | train loss {'Reaction outcome loss': 0.41269123079415504, 'Total loss': 0.41269123079415504}
2023-01-04 05:50:04,542 INFO:     Found new best model at epoch 21
2023-01-04 05:50:04,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:04,543 INFO:     Epoch: 22
2023-01-04 05:50:06,063 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4403628607590993, 'Total loss': 0.4403628607590993} | train loss {'Reaction outcome loss': 0.40745735360816476, 'Total loss': 0.40745735360816476}
2023-01-04 05:50:06,063 INFO:     Found new best model at epoch 22
2023-01-04 05:50:06,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:06,064 INFO:     Epoch: 23
2023-01-04 05:50:07,602 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4483058472474416, 'Total loss': 0.4483058472474416} | train loss {'Reaction outcome loss': 0.40825360527505045, 'Total loss': 0.40825360527505045}
2023-01-04 05:50:07,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:07,602 INFO:     Epoch: 24
2023-01-04 05:50:09,131 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4404350201288859, 'Total loss': 0.4404350201288859} | train loss {'Reaction outcome loss': 0.4064155092489892, 'Total loss': 0.4064155092489892}
2023-01-04 05:50:09,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:09,131 INFO:     Epoch: 25
2023-01-04 05:50:10,672 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46717482606569927, 'Total loss': 0.46717482606569927} | train loss {'Reaction outcome loss': 0.4060601404719595, 'Total loss': 0.4060601404719595}
2023-01-04 05:50:10,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:10,672 INFO:     Epoch: 26
2023-01-04 05:50:12,176 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45990607937177025, 'Total loss': 0.45990607937177025} | train loss {'Reaction outcome loss': 0.39937986581977725, 'Total loss': 0.39937986581977725}
2023-01-04 05:50:12,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:12,176 INFO:     Epoch: 27
2023-01-04 05:50:13,727 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4568485995133718, 'Total loss': 0.4568485995133718} | train loss {'Reaction outcome loss': 0.40817837881437247, 'Total loss': 0.40817837881437247}
2023-01-04 05:50:13,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:13,728 INFO:     Epoch: 28
2023-01-04 05:50:15,254 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42660247087478637, 'Total loss': 0.42660247087478637} | train loss {'Reaction outcome loss': 0.41677309146177943, 'Total loss': 0.41677309146177943}
2023-01-04 05:50:15,254 INFO:     Found new best model at epoch 28
2023-01-04 05:50:15,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:15,255 INFO:     Epoch: 29
2023-01-04 05:50:16,806 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41385780870914457, 'Total loss': 0.41385780870914457} | train loss {'Reaction outcome loss': 0.3997681589284237, 'Total loss': 0.3997681589284237}
2023-01-04 05:50:16,806 INFO:     Found new best model at epoch 29
2023-01-04 05:50:16,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:16,807 INFO:     Epoch: 30
2023-01-04 05:50:18,355 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4306011279424032, 'Total loss': 0.4306011279424032} | train loss {'Reaction outcome loss': 0.38329229884497495, 'Total loss': 0.38329229884497495}
2023-01-04 05:50:18,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:18,355 INFO:     Epoch: 31
2023-01-04 05:50:19,915 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.427250208457311, 'Total loss': 0.427250208457311} | train loss {'Reaction outcome loss': 0.38207521716780635, 'Total loss': 0.38207521716780635}
2023-01-04 05:50:19,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:19,916 INFO:     Epoch: 32
2023-01-04 05:50:21,458 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4105589807033539, 'Total loss': 0.4105589807033539} | train loss {'Reaction outcome loss': 0.37370982533995656, 'Total loss': 0.37370982533995656}
2023-01-04 05:50:21,458 INFO:     Found new best model at epoch 32
2023-01-04 05:50:21,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:21,459 INFO:     Epoch: 33
2023-01-04 05:50:23,015 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41697186827659605, 'Total loss': 0.41697186827659605} | train loss {'Reaction outcome loss': 0.3751951133751351, 'Total loss': 0.3751951133751351}
2023-01-04 05:50:23,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:23,015 INFO:     Epoch: 34
2023-01-04 05:50:24,529 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4025861362616221, 'Total loss': 0.4025861362616221} | train loss {'Reaction outcome loss': 0.3827155358765436, 'Total loss': 0.3827155358765436}
2023-01-04 05:50:24,530 INFO:     Found new best model at epoch 34
2023-01-04 05:50:24,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:24,530 INFO:     Epoch: 35
2023-01-04 05:50:26,081 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41279109915097556, 'Total loss': 0.41279109915097556} | train loss {'Reaction outcome loss': 0.3724158326180048, 'Total loss': 0.3724158326180048}
2023-01-04 05:50:26,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:26,081 INFO:     Epoch: 36
2023-01-04 05:50:27,639 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40185948411623634, 'Total loss': 0.40185948411623634} | train loss {'Reaction outcome loss': 0.37466421199665556, 'Total loss': 0.37466421199665556}
2023-01-04 05:50:27,639 INFO:     Found new best model at epoch 36
2023-01-04 05:50:27,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:27,640 INFO:     Epoch: 37
2023-01-04 05:50:29,206 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4216019451618195, 'Total loss': 0.4216019451618195} | train loss {'Reaction outcome loss': 0.3802640679346371, 'Total loss': 0.3802640679346371}
2023-01-04 05:50:29,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:29,206 INFO:     Epoch: 38
2023-01-04 05:50:30,722 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39271167119344075, 'Total loss': 0.39271167119344075} | train loss {'Reaction outcome loss': 0.3772212516894375, 'Total loss': 0.3772212516894375}
2023-01-04 05:50:30,722 INFO:     Found new best model at epoch 38
2023-01-04 05:50:30,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:30,723 INFO:     Epoch: 39
2023-01-04 05:50:32,263 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4396734098593394, 'Total loss': 0.4396734098593394} | train loss {'Reaction outcome loss': 0.3851703210207431, 'Total loss': 0.3851703210207431}
2023-01-04 05:50:32,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:32,264 INFO:     Epoch: 40
2023-01-04 05:50:33,815 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40678402185440066, 'Total loss': 0.40678402185440066} | train loss {'Reaction outcome loss': 0.36596258818779304, 'Total loss': 0.36596258818779304}
2023-01-04 05:50:33,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:33,816 INFO:     Epoch: 41
2023-01-04 05:50:35,366 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39443095326423644, 'Total loss': 0.39443095326423644} | train loss {'Reaction outcome loss': 0.37515499291644583, 'Total loss': 0.37515499291644583}
2023-01-04 05:50:35,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:35,367 INFO:     Epoch: 42
2023-01-04 05:50:36,927 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44727856715520226, 'Total loss': 0.44727856715520226} | train loss {'Reaction outcome loss': 0.38060201987948106, 'Total loss': 0.38060201987948106}
2023-01-04 05:50:36,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:36,927 INFO:     Epoch: 43
2023-01-04 05:50:38,498 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40734776854515076, 'Total loss': 0.40734776854515076} | train loss {'Reaction outcome loss': 0.39091780684564426, 'Total loss': 0.39091780684564426}
2023-01-04 05:50:38,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:38,499 INFO:     Epoch: 44
2023-01-04 05:50:40,022 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4090234180291494, 'Total loss': 0.4090234180291494} | train loss {'Reaction outcome loss': 0.38462179189250956, 'Total loss': 0.38462179189250956}
2023-01-04 05:50:40,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:40,022 INFO:     Epoch: 45
2023-01-04 05:50:41,552 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38437546888987223, 'Total loss': 0.38437546888987223} | train loss {'Reaction outcome loss': 0.35911878356136434, 'Total loss': 0.35911878356136434}
2023-01-04 05:50:41,552 INFO:     Found new best model at epoch 45
2023-01-04 05:50:41,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:41,553 INFO:     Epoch: 46
2023-01-04 05:50:43,101 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38755645751953127, 'Total loss': 0.38755645751953127} | train loss {'Reaction outcome loss': 0.3489836554373682, 'Total loss': 0.3489836554373682}
2023-01-04 05:50:43,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:43,101 INFO:     Epoch: 47
2023-01-04 05:50:44,660 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41683565576871234, 'Total loss': 0.41683565576871234} | train loss {'Reaction outcome loss': 0.3466893209969503, 'Total loss': 0.3466893209969503}
2023-01-04 05:50:44,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:44,660 INFO:     Epoch: 48
2023-01-04 05:50:46,217 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3971259633700053, 'Total loss': 0.3971259633700053} | train loss {'Reaction outcome loss': 0.3531616417880076, 'Total loss': 0.3531616417880076}
2023-01-04 05:50:46,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:46,218 INFO:     Epoch: 49
2023-01-04 05:50:47,798 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38181607723236083, 'Total loss': 0.38181607723236083} | train loss {'Reaction outcome loss': 0.3780795753464454, 'Total loss': 0.3780795753464454}
2023-01-04 05:50:47,798 INFO:     Found new best model at epoch 49
2023-01-04 05:50:47,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:47,799 INFO:     Epoch: 50
2023-01-04 05:50:49,317 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37999357432127, 'Total loss': 0.37999357432127} | train loss {'Reaction outcome loss': 0.3474907386019144, 'Total loss': 0.3474907386019144}
2023-01-04 05:50:49,318 INFO:     Found new best model at epoch 50
2023-01-04 05:50:49,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:49,319 INFO:     Epoch: 51
2023-01-04 05:50:50,831 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39495914181073505, 'Total loss': 0.39495914181073505} | train loss {'Reaction outcome loss': 0.33933342863578664, 'Total loss': 0.33933342863578664}
2023-01-04 05:50:50,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:50,831 INFO:     Epoch: 52
2023-01-04 05:50:52,382 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39167218108971913, 'Total loss': 0.39167218108971913} | train loss {'Reaction outcome loss': 0.33780822940710664, 'Total loss': 0.33780822940710664}
2023-01-04 05:50:52,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:52,382 INFO:     Epoch: 53
2023-01-04 05:50:53,933 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38628685275713603, 'Total loss': 0.38628685275713603} | train loss {'Reaction outcome loss': 0.3410341766459591, 'Total loss': 0.3410341766459591}
2023-01-04 05:50:53,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:53,933 INFO:     Epoch: 54
2023-01-04 05:50:55,468 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41757556597391765, 'Total loss': 0.41757556597391765} | train loss {'Reaction outcome loss': 0.33324375102107506, 'Total loss': 0.33324375102107506}
2023-01-04 05:50:55,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:55,469 INFO:     Epoch: 55
2023-01-04 05:50:57,015 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3804564863443375, 'Total loss': 0.3804564863443375} | train loss {'Reaction outcome loss': 0.33498708149328077, 'Total loss': 0.33498708149328077}
2023-01-04 05:50:57,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:57,016 INFO:     Epoch: 56
2023-01-04 05:50:58,552 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38206844925880434, 'Total loss': 0.38206844925880434} | train loss {'Reaction outcome loss': 0.3313112837680872, 'Total loss': 0.3313112837680872}
2023-01-04 05:50:58,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:50:58,553 INFO:     Epoch: 57
2023-01-04 05:51:00,088 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3926970660686493, 'Total loss': 0.3926970660686493} | train loss {'Reaction outcome loss': 0.3288290737954663, 'Total loss': 0.3288290737954663}
2023-01-04 05:51:00,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:00,089 INFO:     Epoch: 58
2023-01-04 05:51:01,659 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3777781277894974, 'Total loss': 0.3777781277894974} | train loss {'Reaction outcome loss': 0.3285780313272762, 'Total loss': 0.3285780313272762}
2023-01-04 05:51:01,659 INFO:     Found new best model at epoch 58
2023-01-04 05:51:01,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:01,660 INFO:     Epoch: 59
2023-01-04 05:51:03,224 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43039073745409645, 'Total loss': 0.43039073745409645} | train loss {'Reaction outcome loss': 0.34332718179169774, 'Total loss': 0.34332718179169774}
2023-01-04 05:51:03,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:03,224 INFO:     Epoch: 60
2023-01-04 05:51:04,825 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38661775390307107, 'Total loss': 0.38661775390307107} | train loss {'Reaction outcome loss': 0.3371472989101017, 'Total loss': 0.3371472989101017}
2023-01-04 05:51:04,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:04,825 INFO:     Epoch: 61
2023-01-04 05:51:06,371 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40259609520435335, 'Total loss': 0.40259609520435335} | train loss {'Reaction outcome loss': 0.32444123754702153, 'Total loss': 0.32444123754702153}
2023-01-04 05:51:06,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:06,372 INFO:     Epoch: 62
2023-01-04 05:51:07,949 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38646284143129983, 'Total loss': 0.38646284143129983} | train loss {'Reaction outcome loss': 0.31933137299357983, 'Total loss': 0.31933137299357983}
2023-01-04 05:51:07,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:07,950 INFO:     Epoch: 63
2023-01-04 05:51:09,533 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38709666530291237, 'Total loss': 0.38709666530291237} | train loss {'Reaction outcome loss': 0.3204961827520848, 'Total loss': 0.3204961827520848}
2023-01-04 05:51:09,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:09,533 INFO:     Epoch: 64
2023-01-04 05:51:11,119 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3691703875859578, 'Total loss': 0.3691703875859578} | train loss {'Reaction outcome loss': 0.3170933206025781, 'Total loss': 0.3170933206025781}
2023-01-04 05:51:11,120 INFO:     Found new best model at epoch 64
2023-01-04 05:51:11,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:11,120 INFO:     Epoch: 65
2023-01-04 05:51:12,698 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3692275663216909, 'Total loss': 0.3692275663216909} | train loss {'Reaction outcome loss': 0.31510374825987697, 'Total loss': 0.31510374825987697}
2023-01-04 05:51:12,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:12,698 INFO:     Epoch: 66
2023-01-04 05:51:14,280 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3678137222925822, 'Total loss': 0.3678137222925822} | train loss {'Reaction outcome loss': 0.3141487359673416, 'Total loss': 0.3141487359673416}
2023-01-04 05:51:14,280 INFO:     Found new best model at epoch 66
2023-01-04 05:51:14,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:14,281 INFO:     Epoch: 67
2023-01-04 05:51:15,851 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3708240419626236, 'Total loss': 0.3708240419626236} | train loss {'Reaction outcome loss': 0.3080448839936635, 'Total loss': 0.3080448839936635}
2023-01-04 05:51:15,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:15,851 INFO:     Epoch: 68
2023-01-04 05:51:17,432 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41722000340620674, 'Total loss': 0.41722000340620674} | train loss {'Reaction outcome loss': 0.31520501678080665, 'Total loss': 0.31520501678080665}
2023-01-04 05:51:17,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:17,432 INFO:     Epoch: 69
2023-01-04 05:51:18,993 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3960937738418579, 'Total loss': 0.3960937738418579} | train loss {'Reaction outcome loss': 0.33930170030014223, 'Total loss': 0.33930170030014223}
2023-01-04 05:51:18,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:18,993 INFO:     Epoch: 70
2023-01-04 05:51:20,579 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3853057806690534, 'Total loss': 0.3853057806690534} | train loss {'Reaction outcome loss': 0.30663438789011654, 'Total loss': 0.30663438789011654}
2023-01-04 05:51:20,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:20,579 INFO:     Epoch: 71
2023-01-04 05:51:22,166 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4038868725299835, 'Total loss': 0.4038868725299835} | train loss {'Reaction outcome loss': 0.3049621208422426, 'Total loss': 0.3049621208422426}
2023-01-04 05:51:22,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:22,166 INFO:     Epoch: 72
2023-01-04 05:51:23,762 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36608567933241526, 'Total loss': 0.36608567933241526} | train loss {'Reaction outcome loss': 0.3066727216692938, 'Total loss': 0.3066727216692938}
2023-01-04 05:51:23,762 INFO:     Found new best model at epoch 72
2023-01-04 05:51:23,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:23,763 INFO:     Epoch: 73
2023-01-04 05:51:25,342 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3836850831906001, 'Total loss': 0.3836850831906001} | train loss {'Reaction outcome loss': 0.3160417056309782, 'Total loss': 0.3160417056309782}
2023-01-04 05:51:25,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:25,343 INFO:     Epoch: 74
2023-01-04 05:51:26,896 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3859425693750381, 'Total loss': 0.3859425693750381} | train loss {'Reaction outcome loss': 0.2973320743581955, 'Total loss': 0.2973320743581955}
2023-01-04 05:51:26,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:26,896 INFO:     Epoch: 75
2023-01-04 05:51:28,489 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39347947438557945, 'Total loss': 0.39347947438557945} | train loss {'Reaction outcome loss': 0.29883157851957326, 'Total loss': 0.29883157851957326}
2023-01-04 05:51:28,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:28,489 INFO:     Epoch: 76
2023-01-04 05:51:30,076 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3776679039001465, 'Total loss': 0.3776679039001465} | train loss {'Reaction outcome loss': 0.2949371968992426, 'Total loss': 0.2949371968992426}
2023-01-04 05:51:30,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:30,076 INFO:     Epoch: 77
2023-01-04 05:51:31,672 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41058196624120075, 'Total loss': 0.41058196624120075} | train loss {'Reaction outcome loss': 0.2908224968199173, 'Total loss': 0.2908224968199173}
2023-01-04 05:51:31,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:31,673 INFO:     Epoch: 78
2023-01-04 05:51:33,279 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3602587660153707, 'Total loss': 0.3602587660153707} | train loss {'Reaction outcome loss': 0.2953360883867733, 'Total loss': 0.2953360883867733}
2023-01-04 05:51:33,279 INFO:     Found new best model at epoch 78
2023-01-04 05:51:33,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:33,280 INFO:     Epoch: 79
2023-01-04 05:51:34,868 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3715957144896189, 'Total loss': 0.3715957144896189} | train loss {'Reaction outcome loss': 0.2892766510792527, 'Total loss': 0.2892766510792527}
2023-01-04 05:51:34,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:34,868 INFO:     Epoch: 80
2023-01-04 05:51:36,425 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39463329017162324, 'Total loss': 0.39463329017162324} | train loss {'Reaction outcome loss': 0.28835098180148844, 'Total loss': 0.28835098180148844}
2023-01-04 05:51:36,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:36,426 INFO:     Epoch: 81
2023-01-04 05:51:38,015 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3827407071987788, 'Total loss': 0.3827407071987788} | train loss {'Reaction outcome loss': 0.29050178363568324, 'Total loss': 0.29050178363568324}
2023-01-04 05:51:38,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:38,016 INFO:     Epoch: 82
2023-01-04 05:51:39,607 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39605743686358136, 'Total loss': 0.39605743686358136} | train loss {'Reaction outcome loss': 0.28919179070794926, 'Total loss': 0.28919179070794926}
2023-01-04 05:51:39,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:39,607 INFO:     Epoch: 83
2023-01-04 05:51:41,185 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38163610100746154, 'Total loss': 0.38163610100746154} | train loss {'Reaction outcome loss': 0.28364800889226055, 'Total loss': 0.28364800889226055}
2023-01-04 05:51:41,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:41,186 INFO:     Epoch: 84
2023-01-04 05:51:42,772 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40210299293200175, 'Total loss': 0.40210299293200175} | train loss {'Reaction outcome loss': 0.2825238915148488, 'Total loss': 0.2825238915148488}
2023-01-04 05:51:42,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:42,772 INFO:     Epoch: 85
2023-01-04 05:51:44,316 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3967406749725342, 'Total loss': 0.3967406749725342} | train loss {'Reaction outcome loss': 0.28689399242579966, 'Total loss': 0.28689399242579966}
2023-01-04 05:51:44,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:44,316 INFO:     Epoch: 86
2023-01-04 05:51:45,863 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37904450446367266, 'Total loss': 0.37904450446367266} | train loss {'Reaction outcome loss': 0.28000894631259143, 'Total loss': 0.28000894631259143}
2023-01-04 05:51:45,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:45,863 INFO:     Epoch: 87
2023-01-04 05:51:47,463 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3958544115225474, 'Total loss': 0.3958544115225474} | train loss {'Reaction outcome loss': 0.2809445658054176, 'Total loss': 0.2809445658054176}
2023-01-04 05:51:47,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:47,463 INFO:     Epoch: 88
2023-01-04 05:51:49,048 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37557749152183534, 'Total loss': 0.37557749152183534} | train loss {'Reaction outcome loss': 0.27712110919621435, 'Total loss': 0.27712110919621435}
2023-01-04 05:51:49,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:49,049 INFO:     Epoch: 89
2023-01-04 05:51:50,622 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38173031707604727, 'Total loss': 0.38173031707604727} | train loss {'Reaction outcome loss': 0.2766248007385951, 'Total loss': 0.2766248007385951}
2023-01-04 05:51:50,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:50,622 INFO:     Epoch: 90
2023-01-04 05:51:52,214 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37561501065889996, 'Total loss': 0.37561501065889996} | train loss {'Reaction outcome loss': 0.2810422710237512, 'Total loss': 0.2810422710237512}
2023-01-04 05:51:52,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:52,214 INFO:     Epoch: 91
2023-01-04 05:51:53,752 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39690707524617513, 'Total loss': 0.39690707524617513} | train loss {'Reaction outcome loss': 0.2995776037088312, 'Total loss': 0.2995776037088312}
2023-01-04 05:51:53,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:53,752 INFO:     Epoch: 92
2023-01-04 05:51:55,313 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37533050576845806, 'Total loss': 0.37533050576845806} | train loss {'Reaction outcome loss': 0.27682071007734194, 'Total loss': 0.27682071007734194}
2023-01-04 05:51:55,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:55,314 INFO:     Epoch: 93
2023-01-04 05:51:56,925 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3672547399997711, 'Total loss': 0.3672547399997711} | train loss {'Reaction outcome loss': 0.2869188450889508, 'Total loss': 0.2869188450889508}
2023-01-04 05:51:56,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:56,925 INFO:     Epoch: 94
2023-01-04 05:51:58,532 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3638600712021192, 'Total loss': 0.3638600712021192} | train loss {'Reaction outcome loss': 0.27014942067245906, 'Total loss': 0.27014942067245906}
2023-01-04 05:51:58,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:51:58,533 INFO:     Epoch: 95
2023-01-04 05:52:00,115 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37778733174006146, 'Total loss': 0.37778733174006146} | train loss {'Reaction outcome loss': 0.26904065492999507, 'Total loss': 0.26904065492999507}
2023-01-04 05:52:00,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:00,116 INFO:     Epoch: 96
2023-01-04 05:52:01,678 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36527672012646994, 'Total loss': 0.36527672012646994} | train loss {'Reaction outcome loss': 0.2669215131689376, 'Total loss': 0.2669215131689376}
2023-01-04 05:52:01,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:01,678 INFO:     Epoch: 97
2023-01-04 05:52:03,184 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36422442893187207, 'Total loss': 0.36422442893187207} | train loss {'Reaction outcome loss': 0.26718594190458755, 'Total loss': 0.26718594190458755}
2023-01-04 05:52:03,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:03,184 INFO:     Epoch: 98
2023-01-04 05:52:04,759 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34955100814501444, 'Total loss': 0.34955100814501444} | train loss {'Reaction outcome loss': 0.2682679730764442, 'Total loss': 0.2682679730764442}
2023-01-04 05:52:04,759 INFO:     Found new best model at epoch 98
2023-01-04 05:52:04,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:04,760 INFO:     Epoch: 99
2023-01-04 05:52:06,357 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3646121645967166, 'Total loss': 0.3646121645967166} | train loss {'Reaction outcome loss': 0.26435266274189495, 'Total loss': 0.26435266274189495}
2023-01-04 05:52:06,358 INFO:     Best model found after epoch 99 of 100.
2023-01-04 05:52:06,358 INFO:   Done with stage: TRAINING
2023-01-04 05:52:06,358 INFO:   Starting stage: EVALUATION
2023-01-04 05:52:06,485 INFO:   Done with stage: EVALUATION
2023-01-04 05:52:06,485 INFO:   Leaving out SEQ value Fold_6
2023-01-04 05:52:06,497 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 05:52:06,498 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:52:07,151 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:52:07,151 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:52:07,222 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:52:07,222 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:52:07,222 INFO:     No hyperparam tuning for this model
2023-01-04 05:52:07,222 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:52:07,222 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:52:07,223 INFO:     None feature selector for col prot
2023-01-04 05:52:07,223 INFO:     None feature selector for col prot
2023-01-04 05:52:07,223 INFO:     None feature selector for col prot
2023-01-04 05:52:07,223 INFO:     None feature selector for col chem
2023-01-04 05:52:07,223 INFO:     None feature selector for col chem
2023-01-04 05:52:07,224 INFO:     None feature selector for col chem
2023-01-04 05:52:07,224 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:52:07,224 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:52:07,225 INFO:     Number of params in model 70111
2023-01-04 05:52:07,228 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:52:07,228 INFO:   Starting stage: TRAINING
2023-01-04 05:52:07,270 INFO:     Val loss before train {'Reaction outcome loss': 1.0382478753725688, 'Total loss': 1.0382478753725688}
2023-01-04 05:52:07,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:07,271 INFO:     Epoch: 0
2023-01-04 05:52:08,851 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7266405721505483, 'Total loss': 0.7266405721505483} | train loss {'Reaction outcome loss': 0.8369374040662166, 'Total loss': 0.8369374040662166}
2023-01-04 05:52:08,851 INFO:     Found new best model at epoch 0
2023-01-04 05:52:08,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:08,851 INFO:     Epoch: 1
2023-01-04 05:52:10,456 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6023257712523142, 'Total loss': 0.6023257712523142} | train loss {'Reaction outcome loss': 0.674349940533242, 'Total loss': 0.674349940533242}
2023-01-04 05:52:10,456 INFO:     Found new best model at epoch 1
2023-01-04 05:52:10,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:10,457 INFO:     Epoch: 2
2023-01-04 05:52:12,007 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5190375487009684, 'Total loss': 0.5190375487009684} | train loss {'Reaction outcome loss': 0.572936670229323, 'Total loss': 0.572936670229323}
2023-01-04 05:52:12,007 INFO:     Found new best model at epoch 2
2023-01-04 05:52:12,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:12,008 INFO:     Epoch: 3
2023-01-04 05:52:13,625 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5295960962772369, 'Total loss': 0.5295960962772369} | train loss {'Reaction outcome loss': 0.5353164711583822, 'Total loss': 0.5353164711583822}
2023-01-04 05:52:13,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:13,625 INFO:     Epoch: 4
2023-01-04 05:52:15,221 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5048014342784881, 'Total loss': 0.5048014342784881} | train loss {'Reaction outcome loss': 0.5141243967984127, 'Total loss': 0.5141243967984127}
2023-01-04 05:52:15,221 INFO:     Found new best model at epoch 4
2023-01-04 05:52:15,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:15,222 INFO:     Epoch: 5
2023-01-04 05:52:16,824 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.491624108950297, 'Total loss': 0.491624108950297} | train loss {'Reaction outcome loss': 0.49983943875085574, 'Total loss': 0.49983943875085574}
2023-01-04 05:52:16,824 INFO:     Found new best model at epoch 5
2023-01-04 05:52:16,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:16,825 INFO:     Epoch: 6
2023-01-04 05:52:18,442 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46983028054237364, 'Total loss': 0.46983028054237364} | train loss {'Reaction outcome loss': 0.49026924586898585, 'Total loss': 0.49026924586898585}
2023-01-04 05:52:18,443 INFO:     Found new best model at epoch 6
2023-01-04 05:52:18,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:18,444 INFO:     Epoch: 7
2023-01-04 05:52:19,973 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4733153720696767, 'Total loss': 0.4733153720696767} | train loss {'Reaction outcome loss': 0.4784959766085828, 'Total loss': 0.4784959766085828}
2023-01-04 05:52:19,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:19,974 INFO:     Epoch: 8
2023-01-04 05:52:21,530 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4777163465817769, 'Total loss': 0.4777163465817769} | train loss {'Reaction outcome loss': 0.4728668231772602, 'Total loss': 0.4728668231772602}
2023-01-04 05:52:21,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:21,530 INFO:     Epoch: 9
2023-01-04 05:52:23,134 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4854144394397736, 'Total loss': 0.4854144394397736} | train loss {'Reaction outcome loss': 0.4623063660162881, 'Total loss': 0.4623063660162881}
2023-01-04 05:52:23,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:23,134 INFO:     Epoch: 10
2023-01-04 05:52:24,711 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47217041353384653, 'Total loss': 0.47217041353384653} | train loss {'Reaction outcome loss': 0.46292621499794917, 'Total loss': 0.46292621499794917}
2023-01-04 05:52:24,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:24,711 INFO:     Epoch: 11
2023-01-04 05:52:26,265 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46828579107920326, 'Total loss': 0.46828579107920326} | train loss {'Reaction outcome loss': 0.4542386325526754, 'Total loss': 0.4542386325526754}
2023-01-04 05:52:26,265 INFO:     Found new best model at epoch 11
2023-01-04 05:52:26,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:26,266 INFO:     Epoch: 12
2023-01-04 05:52:27,826 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.453524390856425, 'Total loss': 0.453524390856425} | train loss {'Reaction outcome loss': 0.44372392308625935, 'Total loss': 0.44372392308625935}
2023-01-04 05:52:27,826 INFO:     Found new best model at epoch 12
2023-01-04 05:52:27,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:27,827 INFO:     Epoch: 13
2023-01-04 05:52:29,386 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4693213721116384, 'Total loss': 0.4693213721116384} | train loss {'Reaction outcome loss': 0.4443099857560134, 'Total loss': 0.4443099857560134}
2023-01-04 05:52:29,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:29,387 INFO:     Epoch: 14
2023-01-04 05:52:30,951 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44796241720517477, 'Total loss': 0.44796241720517477} | train loss {'Reaction outcome loss': 0.4375042303159349, 'Total loss': 0.4375042303159349}
2023-01-04 05:52:30,952 INFO:     Found new best model at epoch 14
2023-01-04 05:52:30,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:30,953 INFO:     Epoch: 15
2023-01-04 05:52:32,521 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.445038569966952, 'Total loss': 0.445038569966952} | train loss {'Reaction outcome loss': 0.4345583332574755, 'Total loss': 0.4345583332574755}
2023-01-04 05:52:32,521 INFO:     Found new best model at epoch 15
2023-01-04 05:52:32,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:32,522 INFO:     Epoch: 16
2023-01-04 05:52:34,109 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44196243286132814, 'Total loss': 0.44196243286132814} | train loss {'Reaction outcome loss': 0.4292561840871181, 'Total loss': 0.4292561840871181}
2023-01-04 05:52:34,109 INFO:     Found new best model at epoch 16
2023-01-04 05:52:34,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:34,110 INFO:     Epoch: 17
2023-01-04 05:52:35,685 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46862971782684326, 'Total loss': 0.46862971782684326} | train loss {'Reaction outcome loss': 0.42321379471987164, 'Total loss': 0.42321379471987164}
2023-01-04 05:52:35,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:35,686 INFO:     Epoch: 18
2023-01-04 05:52:37,270 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43342973391215006, 'Total loss': 0.43342973391215006} | train loss {'Reaction outcome loss': 0.41788373279657604, 'Total loss': 0.41788373279657604}
2023-01-04 05:52:37,271 INFO:     Found new best model at epoch 18
2023-01-04 05:52:37,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:37,272 INFO:     Epoch: 19
2023-01-04 05:52:38,834 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42685358921686806, 'Total loss': 0.42685358921686806} | train loss {'Reaction outcome loss': 0.4135603081125645, 'Total loss': 0.4135603081125645}
2023-01-04 05:52:38,834 INFO:     Found new best model at epoch 19
2023-01-04 05:52:38,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:38,835 INFO:     Epoch: 20
2023-01-04 05:52:40,398 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4363081932067871, 'Total loss': 0.4363081932067871} | train loss {'Reaction outcome loss': 0.41092155282032616, 'Total loss': 0.41092155282032616}
2023-01-04 05:52:40,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:40,399 INFO:     Epoch: 21
2023-01-04 05:52:41,998 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46247660120328266, 'Total loss': 0.46247660120328266} | train loss {'Reaction outcome loss': 0.4083013042054452, 'Total loss': 0.4083013042054452}
2023-01-04 05:52:41,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:41,999 INFO:     Epoch: 22
2023-01-04 05:52:43,581 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4368557592233022, 'Total loss': 0.4368557592233022} | train loss {'Reaction outcome loss': 0.4028407194338981, 'Total loss': 0.4028407194338981}
2023-01-04 05:52:43,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:43,581 INFO:     Epoch: 23
2023-01-04 05:52:45,177 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42984347144762675, 'Total loss': 0.42984347144762675} | train loss {'Reaction outcome loss': 0.3985136793892736, 'Total loss': 0.3985136793892736}
2023-01-04 05:52:45,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:45,177 INFO:     Epoch: 24
2023-01-04 05:52:46,748 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4256844053665797, 'Total loss': 0.4256844053665797} | train loss {'Reaction outcome loss': 0.3948987763280903, 'Total loss': 0.3948987763280903}
2023-01-04 05:52:46,749 INFO:     Found new best model at epoch 24
2023-01-04 05:52:46,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:46,749 INFO:     Epoch: 25
2023-01-04 05:52:48,257 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41760488152503966, 'Total loss': 0.41760488152503966} | train loss {'Reaction outcome loss': 0.3918864132856634, 'Total loss': 0.3918864132856634}
2023-01-04 05:52:48,257 INFO:     Found new best model at epoch 25
2023-01-04 05:52:48,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:48,258 INFO:     Epoch: 26
2023-01-04 05:52:49,819 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43797000249226886, 'Total loss': 0.43797000249226886} | train loss {'Reaction outcome loss': 0.3873433576701781, 'Total loss': 0.3873433576701781}
2023-01-04 05:52:49,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:49,820 INFO:     Epoch: 27
2023-01-04 05:52:51,408 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4130248775084813, 'Total loss': 0.4130248775084813} | train loss {'Reaction outcome loss': 0.3843927816740012, 'Total loss': 0.3843927816740012}
2023-01-04 05:52:51,408 INFO:     Found new best model at epoch 27
2023-01-04 05:52:51,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:51,409 INFO:     Epoch: 28
2023-01-04 05:52:52,986 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4385737786690394, 'Total loss': 0.4385737786690394} | train loss {'Reaction outcome loss': 0.3798183501304702, 'Total loss': 0.3798183501304702}
2023-01-04 05:52:52,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:52,986 INFO:     Epoch: 29
2023-01-04 05:52:54,594 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4055573344230652, 'Total loss': 0.4055573344230652} | train loss {'Reaction outcome loss': 0.3793295586367376, 'Total loss': 0.3793295586367376}
2023-01-04 05:52:54,594 INFO:     Found new best model at epoch 29
2023-01-04 05:52:54,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:54,594 INFO:     Epoch: 30
2023-01-04 05:52:56,145 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42175379892190296, 'Total loss': 0.42175379892190296} | train loss {'Reaction outcome loss': 0.3717401414195123, 'Total loss': 0.3717401414195123}
2023-01-04 05:52:56,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:56,145 INFO:     Epoch: 31
2023-01-04 05:52:57,717 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4354767858982086, 'Total loss': 0.4354767858982086} | train loss {'Reaction outcome loss': 0.37149812009467975, 'Total loss': 0.37149812009467975}
2023-01-04 05:52:57,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:57,717 INFO:     Epoch: 32
2023-01-04 05:52:59,307 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4358168105284373, 'Total loss': 0.4358168105284373} | train loss {'Reaction outcome loss': 0.3666432780156497, 'Total loss': 0.3666432780156497}
2023-01-04 05:52:59,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:52:59,307 INFO:     Epoch: 33
2023-01-04 05:53:00,864 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42032540440559385, 'Total loss': 0.42032540440559385} | train loss {'Reaction outcome loss': 0.3609121539478698, 'Total loss': 0.3609121539478698}
2023-01-04 05:53:00,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:00,865 INFO:     Epoch: 34
2023-01-04 05:53:02,448 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40429464280605315, 'Total loss': 0.40429464280605315} | train loss {'Reaction outcome loss': 0.36014344898264333, 'Total loss': 0.36014344898264333}
2023-01-04 05:53:02,449 INFO:     Found new best model at epoch 34
2023-01-04 05:53:02,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:02,450 INFO:     Epoch: 35
2023-01-04 05:53:04,035 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4070913871129354, 'Total loss': 0.4070913871129354} | train loss {'Reaction outcome loss': 0.3618632582981234, 'Total loss': 0.3618632582981234}
2023-01-04 05:53:04,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:04,035 INFO:     Epoch: 36
2023-01-04 05:53:05,586 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40685702363650006, 'Total loss': 0.40685702363650006} | train loss {'Reaction outcome loss': 0.3566109556637516, 'Total loss': 0.3566109556637516}
2023-01-04 05:53:05,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:05,586 INFO:     Epoch: 37
2023-01-04 05:53:07,114 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3939522643884023, 'Total loss': 0.3939522643884023} | train loss {'Reaction outcome loss': 0.35413802628966873, 'Total loss': 0.35413802628966873}
2023-01-04 05:53:07,115 INFO:     Found new best model at epoch 37
2023-01-04 05:53:07,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:07,115 INFO:     Epoch: 38
2023-01-04 05:53:08,675 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4085090200106303, 'Total loss': 0.4085090200106303} | train loss {'Reaction outcome loss': 0.35305283665119097, 'Total loss': 0.35305283665119097}
2023-01-04 05:53:08,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:08,676 INFO:     Epoch: 39
2023-01-04 05:53:10,249 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4165774047374725, 'Total loss': 0.4165774047374725} | train loss {'Reaction outcome loss': 0.35041852787621186, 'Total loss': 0.35041852787621186}
2023-01-04 05:53:10,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:10,249 INFO:     Epoch: 40
2023-01-04 05:53:11,836 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37968631039063133, 'Total loss': 0.37968631039063133} | train loss {'Reaction outcome loss': 0.346060138155407, 'Total loss': 0.346060138155407}
2023-01-04 05:53:11,836 INFO:     Found new best model at epoch 40
2023-01-04 05:53:11,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:11,837 INFO:     Epoch: 41
2023-01-04 05:53:13,412 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3876666714747747, 'Total loss': 0.3876666714747747} | train loss {'Reaction outcome loss': 0.3442427174655539, 'Total loss': 0.3442427174655539}
2023-01-04 05:53:13,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:13,412 INFO:     Epoch: 42
2023-01-04 05:53:14,964 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38901856243610383, 'Total loss': 0.38901856243610383} | train loss {'Reaction outcome loss': 0.3411006981016066, 'Total loss': 0.3411006981016066}
2023-01-04 05:53:14,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:14,964 INFO:     Epoch: 43
2023-01-04 05:53:16,499 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3971446136633555, 'Total loss': 0.3971446136633555} | train loss {'Reaction outcome loss': 0.3402289188187906, 'Total loss': 0.3402289188187906}
2023-01-04 05:53:16,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:16,499 INFO:     Epoch: 44
2023-01-04 05:53:18,064 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39244898955027263, 'Total loss': 0.39244898955027263} | train loss {'Reaction outcome loss': 0.3355129493487871, 'Total loss': 0.3355129493487871}
2023-01-04 05:53:18,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:18,065 INFO:     Epoch: 45
2023-01-04 05:53:19,659 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38922284146149955, 'Total loss': 0.38922284146149955} | train loss {'Reaction outcome loss': 0.336307934717366, 'Total loss': 0.336307934717366}
2023-01-04 05:53:19,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:19,659 INFO:     Epoch: 46
2023-01-04 05:53:21,228 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39312273065249126, 'Total loss': 0.39312273065249126} | train loss {'Reaction outcome loss': 0.33102706424380896, 'Total loss': 0.33102706424380896}
2023-01-04 05:53:21,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:21,229 INFO:     Epoch: 47
2023-01-04 05:53:22,814 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4127837677796682, 'Total loss': 0.4127837677796682} | train loss {'Reaction outcome loss': 0.32822311742211074, 'Total loss': 0.32822311742211074}
2023-01-04 05:53:22,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:22,814 INFO:     Epoch: 48
2023-01-04 05:53:24,353 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37816870013872783, 'Total loss': 0.37816870013872783} | train loss {'Reaction outcome loss': 0.32908112752093305, 'Total loss': 0.32908112752093305}
2023-01-04 05:53:24,353 INFO:     Found new best model at epoch 48
2023-01-04 05:53:24,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:24,354 INFO:     Epoch: 49
2023-01-04 05:53:25,920 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38221743404865266, 'Total loss': 0.38221743404865266} | train loss {'Reaction outcome loss': 0.3241761154915452, 'Total loss': 0.3241761154915452}
2023-01-04 05:53:25,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:25,920 INFO:     Epoch: 50
2023-01-04 05:53:27,495 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3820868204037348, 'Total loss': 0.3820868204037348} | train loss {'Reaction outcome loss': 0.3201683688411213, 'Total loss': 0.3201683688411213}
2023-01-04 05:53:27,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:27,495 INFO:     Epoch: 51
2023-01-04 05:53:29,072 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3696928640206655, 'Total loss': 0.3696928640206655} | train loss {'Reaction outcome loss': 0.3236815464222259, 'Total loss': 0.3236815464222259}
2023-01-04 05:53:29,072 INFO:     Found new best model at epoch 51
2023-01-04 05:53:29,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:29,073 INFO:     Epoch: 52
2023-01-04 05:53:30,645 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3769228915373484, 'Total loss': 0.3769228915373484} | train loss {'Reaction outcome loss': 0.3226577409741465, 'Total loss': 0.3226577409741465}
2023-01-04 05:53:30,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:30,646 INFO:     Epoch: 53
2023-01-04 05:53:32,183 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39598604242006935, 'Total loss': 0.39598604242006935} | train loss {'Reaction outcome loss': 0.314044223526755, 'Total loss': 0.314044223526755}
2023-01-04 05:53:32,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:32,184 INFO:     Epoch: 54
2023-01-04 05:53:33,714 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3815947582324346, 'Total loss': 0.3815947582324346} | train loss {'Reaction outcome loss': 0.3162539313523778, 'Total loss': 0.3162539313523778}
2023-01-04 05:53:33,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:33,715 INFO:     Epoch: 55
2023-01-04 05:53:35,262 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4128435452779134, 'Total loss': 0.4128435452779134} | train loss {'Reaction outcome loss': 0.31259843903435697, 'Total loss': 0.31259843903435697}
2023-01-04 05:53:35,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:35,262 INFO:     Epoch: 56
2023-01-04 05:53:36,826 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36719609002272285, 'Total loss': 0.36719609002272285} | train loss {'Reaction outcome loss': 0.3152106923289893, 'Total loss': 0.3152106923289893}
2023-01-04 05:53:36,826 INFO:     Found new best model at epoch 56
2023-01-04 05:53:36,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:36,827 INFO:     Epoch: 57
2023-01-04 05:53:38,380 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3731303423643112, 'Total loss': 0.3731303423643112} | train loss {'Reaction outcome loss': 0.30929005371964796, 'Total loss': 0.30929005371964796}
2023-01-04 05:53:38,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:38,382 INFO:     Epoch: 58
2023-01-04 05:53:39,928 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4018957098325094, 'Total loss': 0.4018957098325094} | train loss {'Reaction outcome loss': 0.3084773656370838, 'Total loss': 0.3084773656370838}
2023-01-04 05:53:39,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:39,928 INFO:     Epoch: 59
2023-01-04 05:53:41,455 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36189093788464866, 'Total loss': 0.36189093788464866} | train loss {'Reaction outcome loss': 0.3054386461254492, 'Total loss': 0.3054386461254492}
2023-01-04 05:53:41,455 INFO:     Found new best model at epoch 59
2023-01-04 05:53:41,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:41,456 INFO:     Epoch: 60
2023-01-04 05:53:42,990 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3729399691025416, 'Total loss': 0.3729399691025416} | train loss {'Reaction outcome loss': 0.30402324730631247, 'Total loss': 0.30402324730631247}
2023-01-04 05:53:42,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:42,991 INFO:     Epoch: 61
2023-01-04 05:53:44,560 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3880877435207367, 'Total loss': 0.3880877435207367} | train loss {'Reaction outcome loss': 0.3005665716604205, 'Total loss': 0.3005665716604205}
2023-01-04 05:53:44,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:44,561 INFO:     Epoch: 62
2023-01-04 05:53:46,119 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38418764223655066, 'Total loss': 0.38418764223655066} | train loss {'Reaction outcome loss': 0.29917914588475053, 'Total loss': 0.29917914588475053}
2023-01-04 05:53:46,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:46,120 INFO:     Epoch: 63
2023-01-04 05:53:47,678 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35529857178529106, 'Total loss': 0.35529857178529106} | train loss {'Reaction outcome loss': 0.2981147466745187, 'Total loss': 0.2981147466745187}
2023-01-04 05:53:47,678 INFO:     Found new best model at epoch 63
2023-01-04 05:53:47,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:47,679 INFO:     Epoch: 64
2023-01-04 05:53:49,226 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3674748549858729, 'Total loss': 0.3674748549858729} | train loss {'Reaction outcome loss': 0.2973989669892547, 'Total loss': 0.2973989669892547}
2023-01-04 05:53:49,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:49,226 INFO:     Epoch: 65
2023-01-04 05:53:50,758 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3768988013267517, 'Total loss': 0.3768988013267517} | train loss {'Reaction outcome loss': 0.29455847122339995, 'Total loss': 0.29455847122339995}
2023-01-04 05:53:50,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:50,759 INFO:     Epoch: 66
2023-01-04 05:53:52,284 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3843534866968791, 'Total loss': 0.3843534866968791} | train loss {'Reaction outcome loss': 0.29594600216791517, 'Total loss': 0.29594600216791517}
2023-01-04 05:53:52,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:52,284 INFO:     Epoch: 67
2023-01-04 05:53:53,835 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38527438541253406, 'Total loss': 0.38527438541253406} | train loss {'Reaction outcome loss': 0.2929376818051407, 'Total loss': 0.2929376818051407}
2023-01-04 05:53:53,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:53,835 INFO:     Epoch: 68
2023-01-04 05:53:55,386 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35639049460490546, 'Total loss': 0.35639049460490546} | train loss {'Reaction outcome loss': 0.2943911625052187, 'Total loss': 0.2943911625052187}
2023-01-04 05:53:55,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:55,386 INFO:     Epoch: 69
2023-01-04 05:53:56,940 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3864496131738027, 'Total loss': 0.3864496131738027} | train loss {'Reaction outcome loss': 0.2926003625246592, 'Total loss': 0.2926003625246592}
2023-01-04 05:53:56,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:56,941 INFO:     Epoch: 70
2023-01-04 05:53:58,501 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3796316425005595, 'Total loss': 0.3796316425005595} | train loss {'Reaction outcome loss': 0.2873687728271157, 'Total loss': 0.2873687728271157}
2023-01-04 05:53:58,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:53:58,501 INFO:     Epoch: 71
2023-01-04 05:54:00,046 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37054192970196403, 'Total loss': 0.37054192970196403} | train loss {'Reaction outcome loss': 0.2848043623060956, 'Total loss': 0.2848043623060956}
2023-01-04 05:54:00,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:00,047 INFO:     Epoch: 72
2023-01-04 05:54:01,594 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38163222968578336, 'Total loss': 0.38163222968578336} | train loss {'Reaction outcome loss': 0.2900439925787681, 'Total loss': 0.2900439925787681}
2023-01-04 05:54:01,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:01,594 INFO:     Epoch: 73
2023-01-04 05:54:03,157 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3663490762313207, 'Total loss': 0.3663490762313207} | train loss {'Reaction outcome loss': 0.2909622375285152, 'Total loss': 0.2909622375285152}
2023-01-04 05:54:03,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:03,157 INFO:     Epoch: 74
2023-01-04 05:54:04,728 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3653852085272471, 'Total loss': 0.3653852085272471} | train loss {'Reaction outcome loss': 0.2867549638724499, 'Total loss': 0.2867549638724499}
2023-01-04 05:54:04,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:04,728 INFO:     Epoch: 75
2023-01-04 05:54:06,294 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3767937242984772, 'Total loss': 0.3767937242984772} | train loss {'Reaction outcome loss': 0.28371148134181645, 'Total loss': 0.28371148134181645}
2023-01-04 05:54:06,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:06,295 INFO:     Epoch: 76
2023-01-04 05:54:07,878 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3689244826634725, 'Total loss': 0.3689244826634725} | train loss {'Reaction outcome loss': 0.2805156751875413, 'Total loss': 0.2805156751875413}
2023-01-04 05:54:07,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:07,879 INFO:     Epoch: 77
2023-01-04 05:54:09,435 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36677989264329275, 'Total loss': 0.36677989264329275} | train loss {'Reaction outcome loss': 0.2879449624151314, 'Total loss': 0.2879449624151314}
2023-01-04 05:54:09,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:09,436 INFO:     Epoch: 78
2023-01-04 05:54:11,014 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35395870010058084, 'Total loss': 0.35395870010058084} | train loss {'Reaction outcome loss': 0.28143651683945947, 'Total loss': 0.28143651683945947}
2023-01-04 05:54:11,014 INFO:     Found new best model at epoch 78
2023-01-04 05:54:11,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:11,015 INFO:     Epoch: 79
2023-01-04 05:54:12,610 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3615888237953186, 'Total loss': 0.3615888237953186} | train loss {'Reaction outcome loss': 0.2782772926593515, 'Total loss': 0.2782772926593515}
2023-01-04 05:54:12,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:12,610 INFO:     Epoch: 80
2023-01-04 05:54:14,134 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.34864666908979414, 'Total loss': 0.34864666908979414} | train loss {'Reaction outcome loss': 0.27506668142140556, 'Total loss': 0.27506668142140556}
2023-01-04 05:54:14,135 INFO:     Found new best model at epoch 80
2023-01-04 05:54:14,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:14,136 INFO:     Epoch: 81
2023-01-04 05:54:15,676 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3518005987008413, 'Total loss': 0.3518005987008413} | train loss {'Reaction outcome loss': 0.27534513772609864, 'Total loss': 0.27534513772609864}
2023-01-04 05:54:15,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:15,677 INFO:     Epoch: 82
2023-01-04 05:54:17,211 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3721069246530533, 'Total loss': 0.3721069246530533} | train loss {'Reaction outcome loss': 0.27562785249485866, 'Total loss': 0.27562785249485866}
2023-01-04 05:54:17,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:17,211 INFO:     Epoch: 83
2023-01-04 05:54:18,725 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.353872482975324, 'Total loss': 0.353872482975324} | train loss {'Reaction outcome loss': 0.2746407307200268, 'Total loss': 0.2746407307200268}
2023-01-04 05:54:18,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:18,725 INFO:     Epoch: 84
2023-01-04 05:54:20,260 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36092462738355, 'Total loss': 0.36092462738355} | train loss {'Reaction outcome loss': 0.2745128138938966, 'Total loss': 0.2745128138938966}
2023-01-04 05:54:20,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:20,261 INFO:     Epoch: 85
2023-01-04 05:54:21,862 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35925858666499455, 'Total loss': 0.35925858666499455} | train loss {'Reaction outcome loss': 0.2745673794312813, 'Total loss': 0.2745673794312813}
2023-01-04 05:54:21,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:21,862 INFO:     Epoch: 86
2023-01-04 05:54:23,429 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37246391773223875, 'Total loss': 0.37246391773223875} | train loss {'Reaction outcome loss': 0.27104728367677233, 'Total loss': 0.27104728367677233}
2023-01-04 05:54:23,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:23,429 INFO:     Epoch: 87
2023-01-04 05:54:25,014 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3665387213230133, 'Total loss': 0.3665387213230133} | train loss {'Reaction outcome loss': 0.272625594927731, 'Total loss': 0.272625594927731}
2023-01-04 05:54:25,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:25,015 INFO:     Epoch: 88
2023-01-04 05:54:26,639 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3617107222477595, 'Total loss': 0.3617107222477595} | train loss {'Reaction outcome loss': 0.2695275853902424, 'Total loss': 0.2695275853902424}
2023-01-04 05:54:26,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:26,640 INFO:     Epoch: 89
2023-01-04 05:54:28,198 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36103004912535347, 'Total loss': 0.36103004912535347} | train loss {'Reaction outcome loss': 0.26639337724726986, 'Total loss': 0.26639337724726986}
2023-01-04 05:54:28,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:28,199 INFO:     Epoch: 90
2023-01-04 05:54:29,822 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3536904444297155, 'Total loss': 0.3536904444297155} | train loss {'Reaction outcome loss': 0.2651245218536914, 'Total loss': 0.2651245218536914}
2023-01-04 05:54:29,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:29,822 INFO:     Epoch: 91
2023-01-04 05:54:31,460 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34207040270169575, 'Total loss': 0.34207040270169575} | train loss {'Reaction outcome loss': 0.26598036886337434, 'Total loss': 0.26598036886337434}
2023-01-04 05:54:31,460 INFO:     Found new best model at epoch 91
2023-01-04 05:54:31,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:31,461 INFO:     Epoch: 92
2023-01-04 05:54:33,030 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35545571024219197, 'Total loss': 0.35545571024219197} | train loss {'Reaction outcome loss': 0.26699595010775523, 'Total loss': 0.26699595010775523}
2023-01-04 05:54:33,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:33,030 INFO:     Epoch: 93
2023-01-04 05:54:34,613 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34133777817090355, 'Total loss': 0.34133777817090355} | train loss {'Reaction outcome loss': 0.2599256966357197, 'Total loss': 0.2599256966357197}
2023-01-04 05:54:34,614 INFO:     Found new best model at epoch 93
2023-01-04 05:54:34,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:34,614 INFO:     Epoch: 94
2023-01-04 05:54:36,170 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3582258631785711, 'Total loss': 0.3582258631785711} | train loss {'Reaction outcome loss': 0.26661195194463005, 'Total loss': 0.26661195194463005}
2023-01-04 05:54:36,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:36,170 INFO:     Epoch: 95
2023-01-04 05:54:37,700 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3659424195686976, 'Total loss': 0.3659424195686976} | train loss {'Reaction outcome loss': 0.2580516305264583, 'Total loss': 0.2580516305264583}
2023-01-04 05:54:37,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:37,700 INFO:     Epoch: 96
2023-01-04 05:54:39,260 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35693074266115826, 'Total loss': 0.35693074266115826} | train loss {'Reaction outcome loss': 0.261850082285245, 'Total loss': 0.261850082285245}
2023-01-04 05:54:39,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:39,260 INFO:     Epoch: 97
2023-01-04 05:54:40,817 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.35357512931029, 'Total loss': 0.35357512931029} | train loss {'Reaction outcome loss': 0.26150347082623504, 'Total loss': 0.26150347082623504}
2023-01-04 05:54:40,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:40,817 INFO:     Epoch: 98
2023-01-04 05:54:42,386 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3507462481657664, 'Total loss': 0.3507462481657664} | train loss {'Reaction outcome loss': 0.2640079853901579, 'Total loss': 0.2640079853901579}
2023-01-04 05:54:42,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:42,386 INFO:     Epoch: 99
2023-01-04 05:54:43,944 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35246141254901886, 'Total loss': 0.35246141254901886} | train loss {'Reaction outcome loss': 0.26248499234660866, 'Total loss': 0.26248499234660866}
2023-01-04 05:54:43,944 INFO:     Best model found after epoch 94 of 100.
2023-01-04 05:54:43,944 INFO:   Done with stage: TRAINING
2023-01-04 05:54:43,944 INFO:   Starting stage: EVALUATION
2023-01-04 05:54:44,067 INFO:   Done with stage: EVALUATION
2023-01-04 05:54:44,067 INFO:   Leaving out SEQ value Fold_7
2023-01-04 05:54:44,080 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 05:54:44,080 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:54:44,727 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:54:44,727 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:54:44,796 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:54:44,796 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:54:44,796 INFO:     No hyperparam tuning for this model
2023-01-04 05:54:44,796 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:54:44,797 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:54:44,797 INFO:     None feature selector for col prot
2023-01-04 05:54:44,797 INFO:     None feature selector for col prot
2023-01-04 05:54:44,797 INFO:     None feature selector for col prot
2023-01-04 05:54:44,798 INFO:     None feature selector for col chem
2023-01-04 05:54:44,798 INFO:     None feature selector for col chem
2023-01-04 05:54:44,798 INFO:     None feature selector for col chem
2023-01-04 05:54:44,798 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:54:44,798 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:54:44,799 INFO:     Number of params in model 70111
2023-01-04 05:54:44,802 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:54:44,803 INFO:   Starting stage: TRAINING
2023-01-04 05:54:44,844 INFO:     Val loss before train {'Reaction outcome loss': 0.9942735274632771, 'Total loss': 0.9942735274632771}
2023-01-04 05:54:44,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:44,844 INFO:     Epoch: 0
2023-01-04 05:54:46,365 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7349323550860087, 'Total loss': 0.7349323550860087} | train loss {'Reaction outcome loss': 0.8341287816062728, 'Total loss': 0.8341287816062728}
2023-01-04 05:54:46,365 INFO:     Found new best model at epoch 0
2023-01-04 05:54:46,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:46,366 INFO:     Epoch: 1
2023-01-04 05:54:47,916 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6016330262025197, 'Total loss': 0.6016330262025197} | train loss {'Reaction outcome loss': 0.6698475808539577, 'Total loss': 0.6698475808539577}
2023-01-04 05:54:47,916 INFO:     Found new best model at epoch 1
2023-01-04 05:54:47,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:47,917 INFO:     Epoch: 2
2023-01-04 05:54:49,465 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5450980762640635, 'Total loss': 0.5450980762640635} | train loss {'Reaction outcome loss': 0.5749857948816287, 'Total loss': 0.5749857948816287}
2023-01-04 05:54:49,466 INFO:     Found new best model at epoch 2
2023-01-04 05:54:49,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:49,467 INFO:     Epoch: 3
2023-01-04 05:54:51,037 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5753213147322337, 'Total loss': 0.5753213147322337} | train loss {'Reaction outcome loss': 0.5411195785239122, 'Total loss': 0.5411195785239122}
2023-01-04 05:54:51,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:51,037 INFO:     Epoch: 4
2023-01-04 05:54:52,610 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5076569656531016, 'Total loss': 0.5076569656531016} | train loss {'Reaction outcome loss': 0.5301631583791712, 'Total loss': 0.5301631583791712}
2023-01-04 05:54:52,610 INFO:     Found new best model at epoch 4
2023-01-04 05:54:52,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:52,611 INFO:     Epoch: 5
2023-01-04 05:54:54,142 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5110615889231364, 'Total loss': 0.5110615889231364} | train loss {'Reaction outcome loss': 0.4993233978051306, 'Total loss': 0.4993233978051306}
2023-01-04 05:54:54,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:54,142 INFO:     Epoch: 6
2023-01-04 05:54:55,661 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4910433491071065, 'Total loss': 0.4910433491071065} | train loss {'Reaction outcome loss': 0.4848895321627134, 'Total loss': 0.4848895321627134}
2023-01-04 05:54:55,662 INFO:     Found new best model at epoch 6
2023-01-04 05:54:55,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:55,663 INFO:     Epoch: 7
2023-01-04 05:54:57,209 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4996825943390528, 'Total loss': 0.4996825943390528} | train loss {'Reaction outcome loss': 0.4748971698277603, 'Total loss': 0.4748971698277603}
2023-01-04 05:54:57,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:57,209 INFO:     Epoch: 8
2023-01-04 05:54:58,788 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5480242550373078, 'Total loss': 0.5480242550373078} | train loss {'Reaction outcome loss': 0.4735419725378354, 'Total loss': 0.4735419725378354}
2023-01-04 05:54:58,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:54:58,788 INFO:     Epoch: 9
2023-01-04 05:55:00,338 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5273780802885691, 'Total loss': 0.5273780802885691} | train loss {'Reaction outcome loss': 0.49391962228801806, 'Total loss': 0.49391962228801806}
2023-01-04 05:55:00,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:00,339 INFO:     Epoch: 10
2023-01-04 05:55:01,887 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4927859365940094, 'Total loss': 0.4927859365940094} | train loss {'Reaction outcome loss': 0.45598692626763426, 'Total loss': 0.45598692626763426}
2023-01-04 05:55:01,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:01,887 INFO:     Epoch: 11
2023-01-04 05:55:03,421 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49449116786321007, 'Total loss': 0.49449116786321007} | train loss {'Reaction outcome loss': 0.45186117401454545, 'Total loss': 0.45186117401454545}
2023-01-04 05:55:03,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:03,422 INFO:     Epoch: 12
2023-01-04 05:55:04,685 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47129927972952523, 'Total loss': 0.47129927972952523} | train loss {'Reaction outcome loss': 0.44673935426534084, 'Total loss': 0.44673935426534084}
2023-01-04 05:55:04,686 INFO:     Found new best model at epoch 12
2023-01-04 05:55:04,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:04,686 INFO:     Epoch: 13
2023-01-04 05:55:05,713 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4808176706234614, 'Total loss': 0.4808176706234614} | train loss {'Reaction outcome loss': 0.4451601419975792, 'Total loss': 0.4451601419975792}
2023-01-04 05:55:05,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:05,713 INFO:     Epoch: 14
2023-01-04 05:55:06,725 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5126547753810883, 'Total loss': 0.5126547753810883} | train loss {'Reaction outcome loss': 0.4380144147553306, 'Total loss': 0.4380144147553306}
2023-01-04 05:55:06,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:06,725 INFO:     Epoch: 15
2023-01-04 05:55:07,742 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49288108150164284, 'Total loss': 0.49288108150164284} | train loss {'Reaction outcome loss': 0.4371874265750681, 'Total loss': 0.4371874265750681}
2023-01-04 05:55:07,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:07,743 INFO:     Epoch: 16
2023-01-04 05:55:08,988 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4911413073539734, 'Total loss': 0.4911413073539734} | train loss {'Reaction outcome loss': 0.42939411962161894, 'Total loss': 0.42939411962161894}
2023-01-04 05:55:08,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:08,988 INFO:     Epoch: 17
2023-01-04 05:55:10,523 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47235873341560364, 'Total loss': 0.47235873341560364} | train loss {'Reaction outcome loss': 0.42803165172496677, 'Total loss': 0.42803165172496677}
2023-01-04 05:55:10,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:10,523 INFO:     Epoch: 18
2023-01-04 05:55:12,071 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4712432523568471, 'Total loss': 0.4712432523568471} | train loss {'Reaction outcome loss': 0.4213571622427823, 'Total loss': 0.4213571622427823}
2023-01-04 05:55:12,071 INFO:     Found new best model at epoch 18
2023-01-04 05:55:12,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:12,072 INFO:     Epoch: 19
2023-01-04 05:55:13,621 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4888142536083857, 'Total loss': 0.4888142536083857} | train loss {'Reaction outcome loss': 0.4180927885750282, 'Total loss': 0.4180927885750282}
2023-01-04 05:55:13,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:13,622 INFO:     Epoch: 20
2023-01-04 05:55:15,178 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5083712597688039, 'Total loss': 0.5083712597688039} | train loss {'Reaction outcome loss': 0.4100322709823756, 'Total loss': 0.4100322709823756}
2023-01-04 05:55:15,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:15,178 INFO:     Epoch: 21
2023-01-04 05:55:16,731 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46941384275754294, 'Total loss': 0.46941384275754294} | train loss {'Reaction outcome loss': 0.4087747724699801, 'Total loss': 0.4087747724699801}
2023-01-04 05:55:16,731 INFO:     Found new best model at epoch 21
2023-01-04 05:55:16,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:16,731 INFO:     Epoch: 22
2023-01-04 05:55:18,248 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4898142139116923, 'Total loss': 0.4898142139116923} | train loss {'Reaction outcome loss': 0.4069696243960356, 'Total loss': 0.4069696243960356}
2023-01-04 05:55:18,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:18,248 INFO:     Epoch: 23
2023-01-04 05:55:19,761 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4556466301282247, 'Total loss': 0.4556466301282247} | train loss {'Reaction outcome loss': 0.4058429985374644, 'Total loss': 0.4058429985374644}
2023-01-04 05:55:19,763 INFO:     Found new best model at epoch 23
2023-01-04 05:55:19,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:19,763 INFO:     Epoch: 24
2023-01-04 05:55:21,312 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4474923541148504, 'Total loss': 0.4474923541148504} | train loss {'Reaction outcome loss': 0.40013616977839905, 'Total loss': 0.40013616977839905}
2023-01-04 05:55:21,312 INFO:     Found new best model at epoch 24
2023-01-04 05:55:21,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:21,313 INFO:     Epoch: 25
2023-01-04 05:55:22,876 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4974185804526011, 'Total loss': 0.4974185804526011} | train loss {'Reaction outcome loss': 0.39419191440675355, 'Total loss': 0.39419191440675355}
2023-01-04 05:55:22,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:22,876 INFO:     Epoch: 26
2023-01-04 05:55:24,430 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4712339609861374, 'Total loss': 0.4712339609861374} | train loss {'Reaction outcome loss': 0.3916248681826814, 'Total loss': 0.3916248681826814}
2023-01-04 05:55:24,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:24,430 INFO:     Epoch: 27
2023-01-04 05:55:25,982 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47411971489588417, 'Total loss': 0.47411971489588417} | train loss {'Reaction outcome loss': 0.38876767533593404, 'Total loss': 0.38876767533593404}
2023-01-04 05:55:25,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:25,983 INFO:     Epoch: 28
2023-01-04 05:55:27,500 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4411307613054911, 'Total loss': 0.4411307613054911} | train loss {'Reaction outcome loss': 0.386442762846802, 'Total loss': 0.386442762846802}
2023-01-04 05:55:27,501 INFO:     Found new best model at epoch 28
2023-01-04 05:55:27,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:27,501 INFO:     Epoch: 29
2023-01-04 05:55:29,032 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4567979673544566, 'Total loss': 0.4567979673544566} | train loss {'Reaction outcome loss': 0.3806270486646732, 'Total loss': 0.3806270486646732}
2023-01-04 05:55:29,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:29,032 INFO:     Epoch: 30
2023-01-04 05:55:30,588 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.461978550752004, 'Total loss': 0.461978550752004} | train loss {'Reaction outcome loss': 0.38957360915947653, 'Total loss': 0.38957360915947653}
2023-01-04 05:55:30,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:30,588 INFO:     Epoch: 31
2023-01-04 05:55:32,139 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4421908895174662, 'Total loss': 0.4421908895174662} | train loss {'Reaction outcome loss': 0.39411439121687325, 'Total loss': 0.39411439121687325}
2023-01-04 05:55:32,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:32,139 INFO:     Epoch: 32
2023-01-04 05:55:33,691 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43992902437845866, 'Total loss': 0.43992902437845866} | train loss {'Reaction outcome loss': 0.36726601365481276, 'Total loss': 0.36726601365481276}
2023-01-04 05:55:33,691 INFO:     Found new best model at epoch 32
2023-01-04 05:55:33,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:33,692 INFO:     Epoch: 33
2023-01-04 05:55:35,242 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44727337261041006, 'Total loss': 0.44727337261041006} | train loss {'Reaction outcome loss': 0.3807189292611851, 'Total loss': 0.3807189292611851}
2023-01-04 05:55:35,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:35,242 INFO:     Epoch: 34
2023-01-04 05:55:36,744 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4259120762348175, 'Total loss': 0.4259120762348175} | train loss {'Reaction outcome loss': 0.4109799898443811, 'Total loss': 0.4109799898443811}
2023-01-04 05:55:36,745 INFO:     Found new best model at epoch 34
2023-01-04 05:55:36,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:36,745 INFO:     Epoch: 35
2023-01-04 05:55:38,310 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4805015683174133, 'Total loss': 0.4805015683174133} | train loss {'Reaction outcome loss': 0.3672877848148346, 'Total loss': 0.3672877848148346}
2023-01-04 05:55:38,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:38,311 INFO:     Epoch: 36
2023-01-04 05:55:39,847 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43500654101371766, 'Total loss': 0.43500654101371766} | train loss {'Reaction outcome loss': 0.36494465621755173, 'Total loss': 0.36494465621755173}
2023-01-04 05:55:39,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:39,847 INFO:     Epoch: 37
2023-01-04 05:55:41,405 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4355082551638285, 'Total loss': 0.4355082551638285} | train loss {'Reaction outcome loss': 0.35731560119387246, 'Total loss': 0.35731560119387246}
2023-01-04 05:55:41,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:41,406 INFO:     Epoch: 38
2023-01-04 05:55:42,961 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43419731855392457, 'Total loss': 0.43419731855392457} | train loss {'Reaction outcome loss': 0.3596008468311334, 'Total loss': 0.3596008468311334}
2023-01-04 05:55:42,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:42,962 INFO:     Epoch: 39
2023-01-04 05:55:44,510 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43005109031995137, 'Total loss': 0.43005109031995137} | train loss {'Reaction outcome loss': 0.3735322282064126, 'Total loss': 0.3735322282064126}
2023-01-04 05:55:44,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:44,510 INFO:     Epoch: 40
2023-01-04 05:55:46,016 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45220041275024414, 'Total loss': 0.45220041275024414} | train loss {'Reaction outcome loss': 0.35013012331572996, 'Total loss': 0.35013012331572996}
2023-01-04 05:55:46,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:46,016 INFO:     Epoch: 41
2023-01-04 05:55:47,570 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4431589037179947, 'Total loss': 0.4431589037179947} | train loss {'Reaction outcome loss': 0.3551488602938859, 'Total loss': 0.3551488602938859}
2023-01-04 05:55:47,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:47,571 INFO:     Epoch: 42
2023-01-04 05:55:49,122 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46167226831118263, 'Total loss': 0.46167226831118263} | train loss {'Reaction outcome loss': 0.37908829602858296, 'Total loss': 0.37908829602858296}
2023-01-04 05:55:49,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:49,122 INFO:     Epoch: 43
2023-01-04 05:55:50,672 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.450979682803154, 'Total loss': 0.450979682803154} | train loss {'Reaction outcome loss': 0.36627555537321, 'Total loss': 0.36627555537321}
2023-01-04 05:55:50,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:50,674 INFO:     Epoch: 44
2023-01-04 05:55:52,225 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4165727694829305, 'Total loss': 0.4165727694829305} | train loss {'Reaction outcome loss': 0.3424701170752878, 'Total loss': 0.3424701170752878}
2023-01-04 05:55:52,225 INFO:     Found new best model at epoch 44
2023-01-04 05:55:52,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:52,226 INFO:     Epoch: 45
2023-01-04 05:55:53,766 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4330377260843913, 'Total loss': 0.4330377260843913} | train loss {'Reaction outcome loss': 0.3351780574336864, 'Total loss': 0.3351780574336864}
2023-01-04 05:55:53,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:53,766 INFO:     Epoch: 46
2023-01-04 05:55:55,310 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4258179128170013, 'Total loss': 0.4258179128170013} | train loss {'Reaction outcome loss': 0.33373309470767126, 'Total loss': 0.33373309470767126}
2023-01-04 05:55:55,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:55,310 INFO:     Epoch: 47
2023-01-04 05:55:56,893 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4208259453376134, 'Total loss': 0.4208259453376134} | train loss {'Reaction outcome loss': 0.33103385845880845, 'Total loss': 0.33103385845880845}
2023-01-04 05:55:56,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:56,894 INFO:     Epoch: 48
2023-01-04 05:55:58,469 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4202898581822713, 'Total loss': 0.4202898581822713} | train loss {'Reaction outcome loss': 0.33730799845163373, 'Total loss': 0.33730799845163373}
2023-01-04 05:55:58,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:55:58,469 INFO:     Epoch: 49
2023-01-04 05:56:00,021 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41974086364110313, 'Total loss': 0.41974086364110313} | train loss {'Reaction outcome loss': 0.3426009816437305, 'Total loss': 0.3426009816437305}
2023-01-04 05:56:00,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:00,021 INFO:     Epoch: 50
2023-01-04 05:56:01,586 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4636840720971425, 'Total loss': 0.4636840720971425} | train loss {'Reaction outcome loss': 0.325066334383218, 'Total loss': 0.325066334383218}
2023-01-04 05:56:01,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:01,586 INFO:     Epoch: 51
2023-01-04 05:56:03,126 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4184542735417684, 'Total loss': 0.4184542735417684} | train loss {'Reaction outcome loss': 0.32705644876377715, 'Total loss': 0.32705644876377715}
2023-01-04 05:56:03,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:03,126 INFO:     Epoch: 52
2023-01-04 05:56:04,639 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40247470512986183, 'Total loss': 0.40247470512986183} | train loss {'Reaction outcome loss': 0.32065902784105066, 'Total loss': 0.32065902784105066}
2023-01-04 05:56:04,639 INFO:     Found new best model at epoch 52
2023-01-04 05:56:04,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:04,640 INFO:     Epoch: 53
2023-01-04 05:56:06,194 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3893378590544065, 'Total loss': 0.3893378590544065} | train loss {'Reaction outcome loss': 0.3181813136283038, 'Total loss': 0.3181813136283038}
2023-01-04 05:56:06,194 INFO:     Found new best model at epoch 53
2023-01-04 05:56:06,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:06,195 INFO:     Epoch: 54
2023-01-04 05:56:07,755 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44357011318206785, 'Total loss': 0.44357011318206785} | train loss {'Reaction outcome loss': 0.3183017545597977, 'Total loss': 0.3183017545597977}
2023-01-04 05:56:07,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:07,755 INFO:     Epoch: 55
2023-01-04 05:56:09,321 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42991893986860913, 'Total loss': 0.42991893986860913} | train loss {'Reaction outcome loss': 0.3205435355328887, 'Total loss': 0.3205435355328887}
2023-01-04 05:56:09,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:09,322 INFO:     Epoch: 56
2023-01-04 05:56:10,883 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4260576605796814, 'Total loss': 0.4260576605796814} | train loss {'Reaction outcome loss': 0.3310962294268867, 'Total loss': 0.3310962294268867}
2023-01-04 05:56:10,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:10,884 INFO:     Epoch: 57
2023-01-04 05:56:12,433 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39956083993117014, 'Total loss': 0.39956083993117014} | train loss {'Reaction outcome loss': 0.3638691035355779, 'Total loss': 0.3638691035355779}
2023-01-04 05:56:12,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:12,433 INFO:     Epoch: 58
2023-01-04 05:56:13,958 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4079703986644745, 'Total loss': 0.4079703986644745} | train loss {'Reaction outcome loss': 0.3168237404661604, 'Total loss': 0.3168237404661604}
2023-01-04 05:56:13,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:13,958 INFO:     Epoch: 59
2023-01-04 05:56:15,517 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43596360385417937, 'Total loss': 0.43596360385417937} | train loss {'Reaction outcome loss': 0.30873187686315295, 'Total loss': 0.30873187686315295}
2023-01-04 05:56:15,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:15,517 INFO:     Epoch: 60
2023-01-04 05:56:17,061 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4026366462310155, 'Total loss': 0.4026366462310155} | train loss {'Reaction outcome loss': 0.3075317988253158, 'Total loss': 0.3075317988253158}
2023-01-04 05:56:17,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:17,062 INFO:     Epoch: 61
2023-01-04 05:56:18,628 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4003362397352854, 'Total loss': 0.4003362397352854} | train loss {'Reaction outcome loss': 0.3037116816571063, 'Total loss': 0.3037116816571063}
2023-01-04 05:56:18,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:18,628 INFO:     Epoch: 62
2023-01-04 05:56:20,177 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41926274796326957, 'Total loss': 0.41926274796326957} | train loss {'Reaction outcome loss': 0.3007487547988801, 'Total loss': 0.3007487547988801}
2023-01-04 05:56:20,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:20,177 INFO:     Epoch: 63
2023-01-04 05:56:21,701 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4249653150637945, 'Total loss': 0.4249653150637945} | train loss {'Reaction outcome loss': 0.3007252656224528, 'Total loss': 0.3007252656224528}
2023-01-04 05:56:21,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:21,702 INFO:     Epoch: 64
2023-01-04 05:56:23,222 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4042695035537084, 'Total loss': 0.4042695035537084} | train loss {'Reaction outcome loss': 0.29578739040796104, 'Total loss': 0.29578739040796104}
2023-01-04 05:56:23,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:23,222 INFO:     Epoch: 65
2023-01-04 05:56:24,774 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40223773618539177, 'Total loss': 0.40223773618539177} | train loss {'Reaction outcome loss': 0.2958261159559091, 'Total loss': 0.2958261159559091}
2023-01-04 05:56:24,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:24,774 INFO:     Epoch: 66
2023-01-04 05:56:26,320 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4094653089841207, 'Total loss': 0.4094653089841207} | train loss {'Reaction outcome loss': 0.30407070442932943, 'Total loss': 0.30407070442932943}
2023-01-04 05:56:26,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:26,320 INFO:     Epoch: 67
2023-01-04 05:56:27,871 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41426685253779094, 'Total loss': 0.41426685253779094} | train loss {'Reaction outcome loss': 0.29654058222861396, 'Total loss': 0.29654058222861396}
2023-01-04 05:56:27,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:27,872 INFO:     Epoch: 68
2023-01-04 05:56:29,404 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3783861756324768, 'Total loss': 0.3783861756324768} | train loss {'Reaction outcome loss': 0.2951726259636706, 'Total loss': 0.2951726259636706}
2023-01-04 05:56:29,404 INFO:     Found new best model at epoch 68
2023-01-04 05:56:29,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:29,405 INFO:     Epoch: 69
2023-01-04 05:56:30,933 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4408833329876264, 'Total loss': 0.4408833329876264} | train loss {'Reaction outcome loss': 0.2928734493536362, 'Total loss': 0.2928734493536362}
2023-01-04 05:56:30,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:30,933 INFO:     Epoch: 70
2023-01-04 05:56:32,456 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4057284454504649, 'Total loss': 0.4057284454504649} | train loss {'Reaction outcome loss': 0.3174214931069941, 'Total loss': 0.3174214931069941}
2023-01-04 05:56:32,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:32,456 INFO:     Epoch: 71
2023-01-04 05:56:34,017 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39398603439331054, 'Total loss': 0.39398603439331054} | train loss {'Reaction outcome loss': 0.3141590393404814, 'Total loss': 0.3141590393404814}
2023-01-04 05:56:34,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:34,017 INFO:     Epoch: 72
2023-01-04 05:56:35,579 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41176539262135825, 'Total loss': 0.41176539262135825} | train loss {'Reaction outcome loss': 0.2865038247900489, 'Total loss': 0.2865038247900489}
2023-01-04 05:56:35,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:35,579 INFO:     Epoch: 73
2023-01-04 05:56:37,141 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3970373531182607, 'Total loss': 0.3970373531182607} | train loss {'Reaction outcome loss': 0.28880611017845786, 'Total loss': 0.28880611017845786}
2023-01-04 05:56:37,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:37,141 INFO:     Epoch: 74
2023-01-04 05:56:38,696 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39988783597946165, 'Total loss': 0.39988783597946165} | train loss {'Reaction outcome loss': 0.2859582062540711, 'Total loss': 0.2859582062540711}
2023-01-04 05:56:38,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:38,696 INFO:     Epoch: 75
2023-01-04 05:56:40,182 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39997168083985646, 'Total loss': 0.39997168083985646} | train loss {'Reaction outcome loss': 0.28686569906447246, 'Total loss': 0.28686569906447246}
2023-01-04 05:56:40,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:40,183 INFO:     Epoch: 76
2023-01-04 05:56:41,737 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40151272614796957, 'Total loss': 0.40151272614796957} | train loss {'Reaction outcome loss': 0.28138720384205057, 'Total loss': 0.28138720384205057}
2023-01-04 05:56:41,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:41,737 INFO:     Epoch: 77
2023-01-04 05:56:43,334 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42361806432406107, 'Total loss': 0.42361806432406107} | train loss {'Reaction outcome loss': 0.2785077742368415, 'Total loss': 0.2785077742368415}
2023-01-04 05:56:43,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:43,335 INFO:     Epoch: 78
2023-01-04 05:56:44,921 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43005412245790164, 'Total loss': 0.43005412245790164} | train loss {'Reaction outcome loss': 0.28333007245311054, 'Total loss': 0.28333007245311054}
2023-01-04 05:56:44,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:44,921 INFO:     Epoch: 79
2023-01-04 05:56:46,482 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39443179269631706, 'Total loss': 0.39443179269631706} | train loss {'Reaction outcome loss': 0.27592411338759965, 'Total loss': 0.27592411338759965}
2023-01-04 05:56:46,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:46,483 INFO:     Epoch: 80
2023-01-04 05:56:48,061 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.414725528160731, 'Total loss': 0.414725528160731} | train loss {'Reaction outcome loss': 0.2777098858917969, 'Total loss': 0.2777098858917969}
2023-01-04 05:56:48,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:48,061 INFO:     Epoch: 81
2023-01-04 05:56:49,578 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3803765416145325, 'Total loss': 0.3803765416145325} | train loss {'Reaction outcome loss': 0.2818682912089255, 'Total loss': 0.2818682912089255}
2023-01-04 05:56:49,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:49,578 INFO:     Epoch: 82
2023-01-04 05:56:51,169 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38831803103288015, 'Total loss': 0.38831803103288015} | train loss {'Reaction outcome loss': 0.2887431592882975, 'Total loss': 0.2887431592882975}
2023-01-04 05:56:51,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:51,169 INFO:     Epoch: 83
2023-01-04 05:56:52,759 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39910644888877866, 'Total loss': 0.39910644888877866} | train loss {'Reaction outcome loss': 0.2755136259197109, 'Total loss': 0.2755136259197109}
2023-01-04 05:56:52,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:52,760 INFO:     Epoch: 84
2023-01-04 05:56:54,335 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4129258344570796, 'Total loss': 0.4129258344570796} | train loss {'Reaction outcome loss': 0.28353685712900717, 'Total loss': 0.28353685712900717}
2023-01-04 05:56:54,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:54,335 INFO:     Epoch: 85
2023-01-04 05:56:55,915 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3853089441855749, 'Total loss': 0.3853089441855749} | train loss {'Reaction outcome loss': 0.26846899720165285, 'Total loss': 0.26846899720165285}
2023-01-04 05:56:55,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:55,915 INFO:     Epoch: 86
2023-01-04 05:56:57,465 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3988857885201772, 'Total loss': 0.3988857885201772} | train loss {'Reaction outcome loss': 0.2673196559974357, 'Total loss': 0.2673196559974357}
2023-01-04 05:56:57,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:57,465 INFO:     Epoch: 87
2023-01-04 05:56:59,019 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38610864281654356, 'Total loss': 0.38610864281654356} | train loss {'Reaction outcome loss': 0.26476197309144167, 'Total loss': 0.26476197309144167}
2023-01-04 05:56:59,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:56:59,020 INFO:     Epoch: 88
2023-01-04 05:57:00,609 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38455258011817933, 'Total loss': 0.38455258011817933} | train loss {'Reaction outcome loss': 0.26849500872059795, 'Total loss': 0.26849500872059795}
2023-01-04 05:57:00,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:00,610 INFO:     Epoch: 89
2023-01-04 05:57:02,187 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38371222217877704, 'Total loss': 0.38371222217877704} | train loss {'Reaction outcome loss': 0.2704098649910125, 'Total loss': 0.2704098649910125}
2023-01-04 05:57:02,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:02,188 INFO:     Epoch: 90
2023-01-04 05:57:03,754 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3755456705888112, 'Total loss': 0.3755456705888112} | train loss {'Reaction outcome loss': 0.27054116635353886, 'Total loss': 0.27054116635353886}
2023-01-04 05:57:03,755 INFO:     Found new best model at epoch 90
2023-01-04 05:57:03,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:03,755 INFO:     Epoch: 91
2023-01-04 05:57:05,308 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4206743737061818, 'Total loss': 0.4206743737061818} | train loss {'Reaction outcome loss': 0.2645250781020824, 'Total loss': 0.2645250781020824}
2023-01-04 05:57:05,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:05,308 INFO:     Epoch: 92
2023-01-04 05:57:06,848 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4047750512758891, 'Total loss': 0.4047750512758891} | train loss {'Reaction outcome loss': 0.2587517530873547, 'Total loss': 0.2587517530873547}
2023-01-04 05:57:06,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:06,849 INFO:     Epoch: 93
2023-01-04 05:57:08,374 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39168959359327954, 'Total loss': 0.39168959359327954} | train loss {'Reaction outcome loss': 0.25707150835786824, 'Total loss': 0.25707150835786824}
2023-01-04 05:57:08,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:08,374 INFO:     Epoch: 94
2023-01-04 05:57:09,947 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3893363684415817, 'Total loss': 0.3893363684415817} | train loss {'Reaction outcome loss': 0.25821358176957193, 'Total loss': 0.25821358176957193}
2023-01-04 05:57:09,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:09,947 INFO:     Epoch: 95
2023-01-04 05:57:11,524 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4115236272414525, 'Total loss': 0.4115236272414525} | train loss {'Reaction outcome loss': 0.2620986605491624, 'Total loss': 0.2620986605491624}
2023-01-04 05:57:11,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:11,525 INFO:     Epoch: 96
2023-01-04 05:57:13,126 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3928246269623438, 'Total loss': 0.3928246269623438} | train loss {'Reaction outcome loss': 0.2603748935411652, 'Total loss': 0.2603748935411652}
2023-01-04 05:57:13,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:13,126 INFO:     Epoch: 97
2023-01-04 05:57:14,718 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4569175084431966, 'Total loss': 0.4569175084431966} | train loss {'Reaction outcome loss': 0.26587813879376737, 'Total loss': 0.26587813879376737}
2023-01-04 05:57:14,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:14,718 INFO:     Epoch: 98
2023-01-04 05:57:16,259 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3712320655584335, 'Total loss': 0.3712320655584335} | train loss {'Reaction outcome loss': 0.29155240846676345, 'Total loss': 0.29155240846676345}
2023-01-04 05:57:16,260 INFO:     Found new best model at epoch 98
2023-01-04 05:57:16,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:16,260 INFO:     Epoch: 99
2023-01-04 05:57:17,798 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39510606477657956, 'Total loss': 0.39510606477657956} | train loss {'Reaction outcome loss': 0.2610501772205285, 'Total loss': 0.2610501772205285}
2023-01-04 05:57:17,799 INFO:     Best model found after epoch 99 of 100.
2023-01-04 05:57:17,799 INFO:   Done with stage: TRAINING
2023-01-04 05:57:17,799 INFO:   Starting stage: EVALUATION
2023-01-04 05:57:17,926 INFO:   Done with stage: EVALUATION
2023-01-04 05:57:17,927 INFO:   Leaving out SEQ value Fold_8
2023-01-04 05:57:17,939 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 05:57:17,939 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:57:18,586 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:57:18,586 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:57:18,655 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:57:18,656 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:57:18,656 INFO:     No hyperparam tuning for this model
2023-01-04 05:57:18,656 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:57:18,656 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:57:18,656 INFO:     None feature selector for col prot
2023-01-04 05:57:18,657 INFO:     None feature selector for col prot
2023-01-04 05:57:18,657 INFO:     None feature selector for col prot
2023-01-04 05:57:18,657 INFO:     None feature selector for col chem
2023-01-04 05:57:18,657 INFO:     None feature selector for col chem
2023-01-04 05:57:18,657 INFO:     None feature selector for col chem
2023-01-04 05:57:18,657 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:57:18,657 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:57:18,658 INFO:     Number of params in model 70111
2023-01-04 05:57:18,662 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:57:18,662 INFO:   Starting stage: TRAINING
2023-01-04 05:57:18,704 INFO:     Val loss before train {'Reaction outcome loss': 0.9412374377250672, 'Total loss': 0.9412374377250672}
2023-01-04 05:57:18,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:18,704 INFO:     Epoch: 0
2023-01-04 05:57:20,262 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7052729447682698, 'Total loss': 0.7052729447682698} | train loss {'Reaction outcome loss': 0.856572475662266, 'Total loss': 0.856572475662266}
2023-01-04 05:57:20,262 INFO:     Found new best model at epoch 0
2023-01-04 05:57:20,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:20,263 INFO:     Epoch: 1
2023-01-04 05:57:21,809 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5768271803855896, 'Total loss': 0.5768271803855896} | train loss {'Reaction outcome loss': 0.6986645989632909, 'Total loss': 0.6986645989632909}
2023-01-04 05:57:21,810 INFO:     Found new best model at epoch 1
2023-01-04 05:57:21,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:21,810 INFO:     Epoch: 2
2023-01-04 05:57:23,344 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5531826059023539, 'Total loss': 0.5531826059023539} | train loss {'Reaction outcome loss': 0.5985979951675171, 'Total loss': 0.5985979951675171}
2023-01-04 05:57:23,345 INFO:     Found new best model at epoch 2
2023-01-04 05:57:23,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:23,346 INFO:     Epoch: 3
2023-01-04 05:57:24,878 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5268712282180786, 'Total loss': 0.5268712282180786} | train loss {'Reaction outcome loss': 0.5521610148682974, 'Total loss': 0.5521610148682974}
2023-01-04 05:57:24,878 INFO:     Found new best model at epoch 3
2023-01-04 05:57:24,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:24,878 INFO:     Epoch: 4
2023-01-04 05:57:26,399 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4974871555964152, 'Total loss': 0.4974871555964152} | train loss {'Reaction outcome loss': 0.5308694229615735, 'Total loss': 0.5308694229615735}
2023-01-04 05:57:26,399 INFO:     Found new best model at epoch 4
2023-01-04 05:57:26,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:26,400 INFO:     Epoch: 5
2023-01-04 05:57:27,963 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.508046277364095, 'Total loss': 0.508046277364095} | train loss {'Reaction outcome loss': 0.5186699145082114, 'Total loss': 0.5186699145082114}
2023-01-04 05:57:27,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:27,963 INFO:     Epoch: 6
2023-01-04 05:57:29,523 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4823187917470932, 'Total loss': 0.4823187917470932} | train loss {'Reaction outcome loss': 0.5075585482426096, 'Total loss': 0.5075585482426096}
2023-01-04 05:57:29,524 INFO:     Found new best model at epoch 6
2023-01-04 05:57:29,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:29,524 INFO:     Epoch: 7
2023-01-04 05:57:31,081 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4865122745434443, 'Total loss': 0.4865122745434443} | train loss {'Reaction outcome loss': 0.49413021626895753, 'Total loss': 0.49413021626895753}
2023-01-04 05:57:31,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:31,082 INFO:     Epoch: 8
2023-01-04 05:57:32,674 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48441936274369557, 'Total loss': 0.48441936274369557} | train loss {'Reaction outcome loss': 0.4860279466607028, 'Total loss': 0.4860279466607028}
2023-01-04 05:57:32,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:32,674 INFO:     Epoch: 9
2023-01-04 05:57:34,207 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.475608229637146, 'Total loss': 0.475608229637146} | train loss {'Reaction outcome loss': 0.4789460523566906, 'Total loss': 0.4789460523566906}
2023-01-04 05:57:34,207 INFO:     Found new best model at epoch 9
2023-01-04 05:57:34,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:34,208 INFO:     Epoch: 10
2023-01-04 05:57:35,752 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4692743549744288, 'Total loss': 0.4692743549744288} | train loss {'Reaction outcome loss': 0.475078710935254, 'Total loss': 0.475078710935254}
2023-01-04 05:57:35,753 INFO:     Found new best model at epoch 10
2023-01-04 05:57:35,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:35,754 INFO:     Epoch: 11
2023-01-04 05:57:37,317 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4658902664979299, 'Total loss': 0.4658902664979299} | train loss {'Reaction outcome loss': 0.4819112490656772, 'Total loss': 0.4819112490656772}
2023-01-04 05:57:37,317 INFO:     Found new best model at epoch 11
2023-01-04 05:57:37,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:37,318 INFO:     Epoch: 12
2023-01-04 05:57:38,878 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47427496314048767, 'Total loss': 0.47427496314048767} | train loss {'Reaction outcome loss': 0.4643977956822736, 'Total loss': 0.4643977956822736}
2023-01-04 05:57:38,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:38,878 INFO:     Epoch: 13
2023-01-04 05:57:40,460 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4609694242477417, 'Total loss': 0.4609694242477417} | train loss {'Reaction outcome loss': 0.4626215999757034, 'Total loss': 0.4626215999757034}
2023-01-04 05:57:40,460 INFO:     Found new best model at epoch 13
2023-01-04 05:57:40,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:40,461 INFO:     Epoch: 14
2023-01-04 05:57:42,037 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49109361370404564, 'Total loss': 0.49109361370404564} | train loss {'Reaction outcome loss': 0.45997139530769293, 'Total loss': 0.45997139530769293}
2023-01-04 05:57:42,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:42,039 INFO:     Epoch: 15
2023-01-04 05:57:43,537 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45435351729393003, 'Total loss': 0.45435351729393003} | train loss {'Reaction outcome loss': 0.4661181764272244, 'Total loss': 0.4661181764272244}
2023-01-04 05:57:43,537 INFO:     Found new best model at epoch 15
2023-01-04 05:57:43,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:43,538 INFO:     Epoch: 16
2023-01-04 05:57:45,106 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46861198047796887, 'Total loss': 0.46861198047796887} | train loss {'Reaction outcome loss': 0.448707546579881, 'Total loss': 0.448707546579881}
2023-01-04 05:57:45,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:45,107 INFO:     Epoch: 17
2023-01-04 05:57:46,662 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46685424049695334, 'Total loss': 0.46685424049695334} | train loss {'Reaction outcome loss': 0.44674570939463115, 'Total loss': 0.44674570939463115}
2023-01-04 05:57:46,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:46,662 INFO:     Epoch: 18
2023-01-04 05:57:48,238 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44245118896166485, 'Total loss': 0.44245118896166485} | train loss {'Reaction outcome loss': 0.4479169813676508, 'Total loss': 0.4479169813676508}
2023-01-04 05:57:48,239 INFO:     Found new best model at epoch 18
2023-01-04 05:57:48,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:48,240 INFO:     Epoch: 19
2023-01-04 05:57:49,812 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45478838086128237, 'Total loss': 0.45478838086128237} | train loss {'Reaction outcome loss': 0.44097113919417386, 'Total loss': 0.44097113919417386}
2023-01-04 05:57:49,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:49,812 INFO:     Epoch: 20
2023-01-04 05:57:51,334 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4573068598906199, 'Total loss': 0.4573068598906199} | train loss {'Reaction outcome loss': 0.43738985832686117, 'Total loss': 0.43738985832686117}
2023-01-04 05:57:51,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:51,334 INFO:     Epoch: 21
2023-01-04 05:57:52,865 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4435544451077779, 'Total loss': 0.4435544451077779} | train loss {'Reaction outcome loss': 0.43555649418545805, 'Total loss': 0.43555649418545805}
2023-01-04 05:57:52,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:52,866 INFO:     Epoch: 22
2023-01-04 05:57:54,413 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43359951774279276, 'Total loss': 0.43359951774279276} | train loss {'Reaction outcome loss': 0.4317031872160969, 'Total loss': 0.4317031872160969}
2023-01-04 05:57:54,414 INFO:     Found new best model at epoch 22
2023-01-04 05:57:54,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:54,414 INFO:     Epoch: 23
2023-01-04 05:57:55,978 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4538100977738698, 'Total loss': 0.4538100977738698} | train loss {'Reaction outcome loss': 0.42761734785323124, 'Total loss': 0.42761734785323124}
2023-01-04 05:57:55,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:55,978 INFO:     Epoch: 24
2023-01-04 05:57:57,554 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44214741985003153, 'Total loss': 0.44214741985003153} | train loss {'Reaction outcome loss': 0.4226982381356799, 'Total loss': 0.4226982381356799}
2023-01-04 05:57:57,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:57,555 INFO:     Epoch: 25
2023-01-04 05:57:59,112 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4706969698270162, 'Total loss': 0.4706969698270162} | train loss {'Reaction outcome loss': 0.41887536981527734, 'Total loss': 0.41887536981527734}
2023-01-04 05:57:59,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:57:59,112 INFO:     Epoch: 26
2023-01-04 05:58:00,636 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42940251231193544, 'Total loss': 0.42940251231193544} | train loss {'Reaction outcome loss': 0.41778347296707763, 'Total loss': 0.41778347296707763}
2023-01-04 05:58:00,637 INFO:     Found new best model at epoch 26
2023-01-04 05:58:00,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:00,638 INFO:     Epoch: 27
2023-01-04 05:58:02,154 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4297572771708171, 'Total loss': 0.4297572771708171} | train loss {'Reaction outcome loss': 0.41439781652129104, 'Total loss': 0.41439781652129104}
2023-01-04 05:58:02,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:02,154 INFO:     Epoch: 28
2023-01-04 05:58:03,713 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42772395809491476, 'Total loss': 0.42772395809491476} | train loss {'Reaction outcome loss': 0.4137353548017479, 'Total loss': 0.4137353548017479}
2023-01-04 05:58:03,713 INFO:     Found new best model at epoch 28
2023-01-04 05:58:03,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:03,714 INFO:     Epoch: 29
2023-01-04 05:58:05,275 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4538228869438171, 'Total loss': 0.4538228869438171} | train loss {'Reaction outcome loss': 0.40765064997949463, 'Total loss': 0.40765064997949463}
2023-01-04 05:58:05,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:05,275 INFO:     Epoch: 30
2023-01-04 05:58:06,839 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45426960388819376, 'Total loss': 0.45426960388819376} | train loss {'Reaction outcome loss': 0.40589721818906727, 'Total loss': 0.40589721818906727}
2023-01-04 05:58:06,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:06,840 INFO:     Epoch: 31
2023-01-04 05:58:08,415 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4194799095392227, 'Total loss': 0.4194799095392227} | train loss {'Reaction outcome loss': 0.42498707579637784, 'Total loss': 0.42498707579637784}
2023-01-04 05:58:08,416 INFO:     Found new best model at epoch 31
2023-01-04 05:58:08,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:08,416 INFO:     Epoch: 32
2023-01-04 05:58:09,955 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42255522509415944, 'Total loss': 0.42255522509415944} | train loss {'Reaction outcome loss': 0.4046015789111455, 'Total loss': 0.4046015789111455}
2023-01-04 05:58:09,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:09,956 INFO:     Epoch: 33
2023-01-04 05:58:11,505 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41337081491947175, 'Total loss': 0.41337081491947175} | train loss {'Reaction outcome loss': 0.3998406069231746, 'Total loss': 0.3998406069231746}
2023-01-04 05:58:11,506 INFO:     Found new best model at epoch 33
2023-01-04 05:58:11,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:11,506 INFO:     Epoch: 34
2023-01-04 05:58:13,093 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42653472622235616, 'Total loss': 0.42653472622235616} | train loss {'Reaction outcome loss': 0.3909993841991071, 'Total loss': 0.3909993841991071}
2023-01-04 05:58:13,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:13,094 INFO:     Epoch: 35
2023-01-04 05:58:14,684 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41735950807730354, 'Total loss': 0.41735950807730354} | train loss {'Reaction outcome loss': 0.39061204875195166, 'Total loss': 0.39061204875195166}
2023-01-04 05:58:14,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:14,684 INFO:     Epoch: 36
2023-01-04 05:58:16,279 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4266335745652517, 'Total loss': 0.4266335745652517} | train loss {'Reaction outcome loss': 0.38714622803946847, 'Total loss': 0.38714622803946847}
2023-01-04 05:58:16,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:16,279 INFO:     Epoch: 37
2023-01-04 05:58:17,832 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4135113189617793, 'Total loss': 0.4135113189617793} | train loss {'Reaction outcome loss': 0.38121790193912125, 'Total loss': 0.38121790193912125}
2023-01-04 05:58:17,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:17,833 INFO:     Epoch: 38
2023-01-04 05:58:19,357 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4119070609410604, 'Total loss': 0.4119070609410604} | train loss {'Reaction outcome loss': 0.3836377662086886, 'Total loss': 0.3836377662086886}
2023-01-04 05:58:19,358 INFO:     Found new best model at epoch 38
2023-01-04 05:58:19,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:19,358 INFO:     Epoch: 39
2023-01-04 05:58:20,876 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41930798689524335, 'Total loss': 0.41930798689524335} | train loss {'Reaction outcome loss': 0.37867477643506037, 'Total loss': 0.37867477643506037}
2023-01-04 05:58:20,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:20,876 INFO:     Epoch: 40
2023-01-04 05:58:22,422 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43383126457532245, 'Total loss': 0.43383126457532245} | train loss {'Reaction outcome loss': 0.3766462835019279, 'Total loss': 0.3766462835019279}
2023-01-04 05:58:22,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:22,422 INFO:     Epoch: 41
2023-01-04 05:58:23,964 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4447073598702749, 'Total loss': 0.4447073598702749} | train loss {'Reaction outcome loss': 0.3696065185071927, 'Total loss': 0.3696065185071927}
2023-01-04 05:58:23,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:23,965 INFO:     Epoch: 42
2023-01-04 05:58:25,513 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.397550364335378, 'Total loss': 0.397550364335378} | train loss {'Reaction outcome loss': 0.3714450742995393, 'Total loss': 0.3714450742995393}
2023-01-04 05:58:25,513 INFO:     Found new best model at epoch 42
2023-01-04 05:58:25,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:25,514 INFO:     Epoch: 43
2023-01-04 05:58:27,072 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43296326994895934, 'Total loss': 0.43296326994895934} | train loss {'Reaction outcome loss': 0.36664034442409227, 'Total loss': 0.36664034442409227}
2023-01-04 05:58:27,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:27,072 INFO:     Epoch: 44
2023-01-04 05:58:28,598 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3864476601282755, 'Total loss': 0.3864476601282755} | train loss {'Reaction outcome loss': 0.3857174905698638, 'Total loss': 0.3857174905698638}
2023-01-04 05:58:28,598 INFO:     Found new best model at epoch 44
2023-01-04 05:58:28,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:28,599 INFO:     Epoch: 45
2023-01-04 05:58:30,142 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4285855074723562, 'Total loss': 0.4285855074723562} | train loss {'Reaction outcome loss': 0.3634653924154523, 'Total loss': 0.3634653924154523}
2023-01-04 05:58:30,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:30,143 INFO:     Epoch: 46
2023-01-04 05:58:31,697 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39373910427093506, 'Total loss': 0.39373910427093506} | train loss {'Reaction outcome loss': 0.36522809075920476, 'Total loss': 0.36522809075920476}
2023-01-04 05:58:31,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:31,697 INFO:     Epoch: 47
2023-01-04 05:58:33,271 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3972804720203082, 'Total loss': 0.3972804720203082} | train loss {'Reaction outcome loss': 0.3929245689937818, 'Total loss': 0.3929245689937818}
2023-01-04 05:58:33,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:33,271 INFO:     Epoch: 48
2023-01-04 05:58:34,849 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3844312965869904, 'Total loss': 0.3844312965869904} | train loss {'Reaction outcome loss': 0.3570518379059175, 'Total loss': 0.3570518379059175}
2023-01-04 05:58:34,849 INFO:     Found new best model at epoch 48
2023-01-04 05:58:34,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:34,850 INFO:     Epoch: 49
2023-01-04 05:58:36,443 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4109485497077306, 'Total loss': 0.4109485497077306} | train loss {'Reaction outcome loss': 0.3530563183425777, 'Total loss': 0.3530563183425777}
2023-01-04 05:58:36,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:36,444 INFO:     Epoch: 50
2023-01-04 05:58:37,956 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40546599427858987, 'Total loss': 0.40546599427858987} | train loss {'Reaction outcome loss': 0.3510453905640305, 'Total loss': 0.3510453905640305}
2023-01-04 05:58:37,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:37,957 INFO:     Epoch: 51
2023-01-04 05:58:39,573 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3938755303621292, 'Total loss': 0.3938755303621292} | train loss {'Reaction outcome loss': 0.346343314978699, 'Total loss': 0.346343314978699}
2023-01-04 05:58:39,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:39,573 INFO:     Epoch: 52
2023-01-04 05:58:41,203 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39690870145956675, 'Total loss': 0.39690870145956675} | train loss {'Reaction outcome loss': 0.34465757938290853, 'Total loss': 0.34465757938290853}
2023-01-04 05:58:41,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:41,203 INFO:     Epoch: 53
2023-01-04 05:58:42,785 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41664641002813974, 'Total loss': 0.41664641002813974} | train loss {'Reaction outcome loss': 0.35906983002601867, 'Total loss': 0.35906983002601867}
2023-01-04 05:58:42,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:42,786 INFO:     Epoch: 54
2023-01-04 05:58:44,334 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4115989794333776, 'Total loss': 0.4115989794333776} | train loss {'Reaction outcome loss': 0.3397826217144451, 'Total loss': 0.3397826217144451}
2023-01-04 05:58:44,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:44,334 INFO:     Epoch: 55
2023-01-04 05:58:45,845 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41015218396981556, 'Total loss': 0.41015218396981556} | train loss {'Reaction outcome loss': 0.3362290507209474, 'Total loss': 0.3362290507209474}
2023-01-04 05:58:45,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:45,846 INFO:     Epoch: 56
2023-01-04 05:58:47,373 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3762382835149765, 'Total loss': 0.3762382835149765} | train loss {'Reaction outcome loss': 0.3325790020660835, 'Total loss': 0.3325790020660835}
2023-01-04 05:58:47,373 INFO:     Found new best model at epoch 56
2023-01-04 05:58:47,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:47,374 INFO:     Epoch: 57
2023-01-04 05:58:48,918 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43473623394966127, 'Total loss': 0.43473623394966127} | train loss {'Reaction outcome loss': 0.3360813806454341, 'Total loss': 0.3360813806454341}
2023-01-04 05:58:48,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:48,919 INFO:     Epoch: 58
2023-01-04 05:58:50,477 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3952891657749812, 'Total loss': 0.3952891657749812} | train loss {'Reaction outcome loss': 0.3333961205469255, 'Total loss': 0.3333961205469255}
2023-01-04 05:58:50,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:50,477 INFO:     Epoch: 59
2023-01-04 05:58:52,016 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40711638232072195, 'Total loss': 0.40711638232072195} | train loss {'Reaction outcome loss': 0.32757706189717073, 'Total loss': 0.32757706189717073}
2023-01-04 05:58:52,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:52,016 INFO:     Epoch: 60
2023-01-04 05:58:53,570 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3827393007775148, 'Total loss': 0.3827393007775148} | train loss {'Reaction outcome loss': 0.3353862740399748, 'Total loss': 0.3353862740399748}
2023-01-04 05:58:53,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:53,570 INFO:     Epoch: 61
2023-01-04 05:58:55,088 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40012661516666415, 'Total loss': 0.40012661516666415} | train loss {'Reaction outcome loss': 0.3272204120066422, 'Total loss': 0.3272204120066422}
2023-01-04 05:58:55,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:55,089 INFO:     Epoch: 62
2023-01-04 05:58:56,611 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.394610999027888, 'Total loss': 0.394610999027888} | train loss {'Reaction outcome loss': 0.31989264139986556, 'Total loss': 0.31989264139986556}
2023-01-04 05:58:56,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:56,611 INFO:     Epoch: 63
2023-01-04 05:58:58,166 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4000786870718002, 'Total loss': 0.4000786870718002} | train loss {'Reaction outcome loss': 0.327134409946376, 'Total loss': 0.327134409946376}
2023-01-04 05:58:58,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:58,166 INFO:     Epoch: 64
2023-01-04 05:58:59,733 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.395849468310674, 'Total loss': 0.395849468310674} | train loss {'Reaction outcome loss': 0.3173638248476166, 'Total loss': 0.3173638248476166}
2023-01-04 05:58:59,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:58:59,733 INFO:     Epoch: 65
2023-01-04 05:59:01,301 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43467959662278494, 'Total loss': 0.43467959662278494} | train loss {'Reaction outcome loss': 0.31661527971922676, 'Total loss': 0.31661527971922676}
2023-01-04 05:59:01,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:01,302 INFO:     Epoch: 66
2023-01-04 05:59:02,837 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3860815366109212, 'Total loss': 0.3860815366109212} | train loss {'Reaction outcome loss': 0.31465381498455297, 'Total loss': 0.31465381498455297}
2023-01-04 05:59:02,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:02,838 INFO:     Epoch: 67
2023-01-04 05:59:04,363 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41005290150642393, 'Total loss': 0.41005290150642393} | train loss {'Reaction outcome loss': 0.31990477456238825, 'Total loss': 0.31990477456238825}
2023-01-04 05:59:04,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:04,364 INFO:     Epoch: 68
2023-01-04 05:59:05,892 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3842717170715332, 'Total loss': 0.3842717170715332} | train loss {'Reaction outcome loss': 0.33417747717327945, 'Total loss': 0.33417747717327945}
2023-01-04 05:59:05,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:05,892 INFO:     Epoch: 69
2023-01-04 05:59:07,431 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.413463768362999, 'Total loss': 0.413463768362999} | train loss {'Reaction outcome loss': 0.3175357205998254, 'Total loss': 0.3175357205998254}
2023-01-04 05:59:07,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:07,431 INFO:     Epoch: 70
2023-01-04 05:59:08,977 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.376427107055982, 'Total loss': 0.376427107055982} | train loss {'Reaction outcome loss': 0.3089611052899905, 'Total loss': 0.3089611052899905}
2023-01-04 05:59:08,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:08,977 INFO:     Epoch: 71
2023-01-04 05:59:10,536 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.449381086230278, 'Total loss': 0.449381086230278} | train loss {'Reaction outcome loss': 0.3124816452787406, 'Total loss': 0.3124816452787406}
2023-01-04 05:59:10,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:10,536 INFO:     Epoch: 72
2023-01-04 05:59:12,094 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38343349695205686, 'Total loss': 0.38343349695205686} | train loss {'Reaction outcome loss': 0.3122791701833299, 'Total loss': 0.3122791701833299}
2023-01-04 05:59:12,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:12,094 INFO:     Epoch: 73
2023-01-04 05:59:13,617 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4147893557945887, 'Total loss': 0.4147893557945887} | train loss {'Reaction outcome loss': 0.3069502935623345, 'Total loss': 0.3069502935623345}
2023-01-04 05:59:13,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:13,618 INFO:     Epoch: 74
2023-01-04 05:59:15,123 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3911048829555511, 'Total loss': 0.3911048829555511} | train loss {'Reaction outcome loss': 0.32345484113118245, 'Total loss': 0.32345484113118245}
2023-01-04 05:59:15,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:15,123 INFO:     Epoch: 75
2023-01-04 05:59:16,665 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3881166974703471, 'Total loss': 0.3881166974703471} | train loss {'Reaction outcome loss': 0.30566315861601057, 'Total loss': 0.30566315861601057}
2023-01-04 05:59:16,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:16,665 INFO:     Epoch: 76
2023-01-04 05:59:18,220 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41205746730168663, 'Total loss': 0.41205746730168663} | train loss {'Reaction outcome loss': 0.31201101310443186, 'Total loss': 0.31201101310443186}
2023-01-04 05:59:18,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:18,220 INFO:     Epoch: 77
2023-01-04 05:59:19,775 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42660049597422284, 'Total loss': 0.42660049597422284} | train loss {'Reaction outcome loss': 0.36054288834313175, 'Total loss': 0.36054288834313175}
2023-01-04 05:59:19,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:19,775 INFO:     Epoch: 78
2023-01-04 05:59:21,334 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39262231489022575, 'Total loss': 0.39262231489022575} | train loss {'Reaction outcome loss': 0.3081877069898706, 'Total loss': 0.3081877069898706}
2023-01-04 05:59:21,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:21,334 INFO:     Epoch: 79
2023-01-04 05:59:22,845 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4002218554417292, 'Total loss': 0.4002218554417292} | train loss {'Reaction outcome loss': 0.3027125294590234, 'Total loss': 0.3027125294590234}
2023-01-04 05:59:22,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:22,845 INFO:     Epoch: 80
2023-01-04 05:59:24,367 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41354136566321054, 'Total loss': 0.41354136566321054} | train loss {'Reaction outcome loss': 0.2965995659753284, 'Total loss': 0.2965995659753284}
2023-01-04 05:59:24,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:24,367 INFO:     Epoch: 81
2023-01-04 05:59:25,912 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40897939999898275, 'Total loss': 0.40897939999898275} | train loss {'Reaction outcome loss': 0.2989988324360625, 'Total loss': 0.2989988324360625}
2023-01-04 05:59:25,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:25,913 INFO:     Epoch: 82
2023-01-04 05:59:27,480 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38900245328744254, 'Total loss': 0.38900245328744254} | train loss {'Reaction outcome loss': 0.29624481739533687, 'Total loss': 0.29624481739533687}
2023-01-04 05:59:27,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:27,480 INFO:     Epoch: 83
2023-01-04 05:59:29,028 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4120091825723648, 'Total loss': 0.4120091825723648} | train loss {'Reaction outcome loss': 0.29411854884254857, 'Total loss': 0.29411854884254857}
2023-01-04 05:59:29,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:29,029 INFO:     Epoch: 84
2023-01-04 05:59:30,577 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41605398456255593, 'Total loss': 0.41605398456255593} | train loss {'Reaction outcome loss': 0.2923353297662908, 'Total loss': 0.2923353297662908}
2023-01-04 05:59:30,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:30,577 INFO:     Epoch: 85
2023-01-04 05:59:32,092 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37615175942579904, 'Total loss': 0.37615175942579904} | train loss {'Reaction outcome loss': 0.2929084636086465, 'Total loss': 0.2929084636086465}
2023-01-04 05:59:32,093 INFO:     Found new best model at epoch 85
2023-01-04 05:59:32,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:32,094 INFO:     Epoch: 86
2023-01-04 05:59:33,610 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4125652402639389, 'Total loss': 0.4125652402639389} | train loss {'Reaction outcome loss': 0.29330711460847786, 'Total loss': 0.29330711460847786}
2023-01-04 05:59:33,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:33,610 INFO:     Epoch: 87
2023-01-04 05:59:35,149 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39050749440987903, 'Total loss': 0.39050749440987903} | train loss {'Reaction outcome loss': 0.2905141583144449, 'Total loss': 0.2905141583144449}
2023-01-04 05:59:35,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:35,149 INFO:     Epoch: 88
2023-01-04 05:59:36,687 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39051347176233925, 'Total loss': 0.39051347176233925} | train loss {'Reaction outcome loss': 0.28694719236396404, 'Total loss': 0.28694719236396404}
2023-01-04 05:59:36,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:36,687 INFO:     Epoch: 89
2023-01-04 05:59:38,237 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39250482320785524, 'Total loss': 0.39250482320785524} | train loss {'Reaction outcome loss': 0.28412997739834955, 'Total loss': 0.28412997739834955}
2023-01-04 05:59:38,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:38,237 INFO:     Epoch: 90
2023-01-04 05:59:39,796 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39034342567125957, 'Total loss': 0.39034342567125957} | train loss {'Reaction outcome loss': 0.2866636048091333, 'Total loss': 0.2866636048091333}
2023-01-04 05:59:39,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:39,796 INFO:     Epoch: 91
2023-01-04 05:59:41,300 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39452573359012605, 'Total loss': 0.39452573359012605} | train loss {'Reaction outcome loss': 0.29095213560630445, 'Total loss': 0.29095213560630445}
2023-01-04 05:59:41,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:41,300 INFO:     Epoch: 92
2023-01-04 05:59:42,832 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3977437635262807, 'Total loss': 0.3977437635262807} | train loss {'Reaction outcome loss': 0.3233182636845479, 'Total loss': 0.3233182636845479}
2023-01-04 05:59:42,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:42,832 INFO:     Epoch: 93
2023-01-04 05:59:44,377 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4308648327986399, 'Total loss': 0.4308648327986399} | train loss {'Reaction outcome loss': 0.3006171344819924, 'Total loss': 0.3006171344819924}
2023-01-04 05:59:44,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:44,378 INFO:     Epoch: 94
2023-01-04 05:59:45,937 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4084467311700185, 'Total loss': 0.4084467311700185} | train loss {'Reaction outcome loss': 0.33621140918694437, 'Total loss': 0.33621140918694437}
2023-01-04 05:59:45,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:45,938 INFO:     Epoch: 95
2023-01-04 05:59:47,503 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3931990578770638, 'Total loss': 0.3931990578770638} | train loss {'Reaction outcome loss': 0.2888303384525647, 'Total loss': 0.2888303384525647}
2023-01-04 05:59:47,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:47,503 INFO:     Epoch: 96
2023-01-04 05:59:49,077 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4092443605264028, 'Total loss': 0.4092443605264028} | train loss {'Reaction outcome loss': 0.2789221570187626, 'Total loss': 0.2789221570187626}
2023-01-04 05:59:49,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:49,077 INFO:     Epoch: 97
2023-01-04 05:59:50,563 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3978071550528208, 'Total loss': 0.3978071550528208} | train loss {'Reaction outcome loss': 0.27719130635639466, 'Total loss': 0.27719130635639466}
2023-01-04 05:59:50,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:50,563 INFO:     Epoch: 98
2023-01-04 05:59:52,123 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3820697252949079, 'Total loss': 0.3820697252949079} | train loss {'Reaction outcome loss': 0.2782084777514894, 'Total loss': 0.2782084777514894}
2023-01-04 05:59:52,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:52,123 INFO:     Epoch: 99
2023-01-04 05:59:53,703 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41348514556884763, 'Total loss': 0.41348514556884763} | train loss {'Reaction outcome loss': 0.27614358619557344, 'Total loss': 0.27614358619557344}
2023-01-04 05:59:53,703 INFO:     Best model found after epoch 86 of 100.
2023-01-04 05:59:53,703 INFO:   Done with stage: TRAINING
2023-01-04 05:59:53,703 INFO:   Starting stage: EVALUATION
2023-01-04 05:59:53,829 INFO:   Done with stage: EVALUATION
2023-01-04 05:59:53,829 INFO:   Leaving out SEQ value Fold_9
2023-01-04 05:59:53,841 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 05:59:53,841 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:59:54,482 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:59:54,482 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:59:54,551 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:59:54,552 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:59:54,552 INFO:     No hyperparam tuning for this model
2023-01-04 05:59:54,552 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:59:54,552 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:59:54,552 INFO:     None feature selector for col prot
2023-01-04 05:59:54,553 INFO:     None feature selector for col prot
2023-01-04 05:59:54,553 INFO:     None feature selector for col prot
2023-01-04 05:59:54,553 INFO:     None feature selector for col chem
2023-01-04 05:59:54,553 INFO:     None feature selector for col chem
2023-01-04 05:59:54,553 INFO:     None feature selector for col chem
2023-01-04 05:59:54,553 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:59:54,554 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:59:54,554 INFO:     Number of params in model 70111
2023-01-04 05:59:54,558 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:59:54,558 INFO:   Starting stage: TRAINING
2023-01-04 05:59:54,600 INFO:     Val loss before train {'Reaction outcome loss': 1.0313879410425821, 'Total loss': 1.0313879410425821}
2023-01-04 05:59:54,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:54,600 INFO:     Epoch: 0
2023-01-04 05:59:56,147 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7697190920511882, 'Total loss': 0.7697190920511882} | train loss {'Reaction outcome loss': 0.8378650409479936, 'Total loss': 0.8378650409479936}
2023-01-04 05:59:56,148 INFO:     Found new best model at epoch 0
2023-01-04 05:59:56,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:56,148 INFO:     Epoch: 1
2023-01-04 05:59:57,707 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6380368868509928, 'Total loss': 0.6380368868509928} | train loss {'Reaction outcome loss': 0.6813099746578846, 'Total loss': 0.6813099746578846}
2023-01-04 05:59:57,708 INFO:     Found new best model at epoch 1
2023-01-04 05:59:57,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:57,709 INFO:     Epoch: 2
2023-01-04 05:59:59,215 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5771031777064005, 'Total loss': 0.5771031777064005} | train loss {'Reaction outcome loss': 0.5847592337623887, 'Total loss': 0.5847592337623887}
2023-01-04 05:59:59,216 INFO:     Found new best model at epoch 2
2023-01-04 05:59:59,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:59:59,216 INFO:     Epoch: 3
2023-01-04 06:00:00,747 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5465948263804118, 'Total loss': 0.5465948263804118} | train loss {'Reaction outcome loss': 0.5439495918125022, 'Total loss': 0.5439495918125022}
2023-01-04 06:00:00,747 INFO:     Found new best model at epoch 3
2023-01-04 06:00:00,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:00,748 INFO:     Epoch: 4
2023-01-04 06:00:02,313 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5372333268324534, 'Total loss': 0.5372333268324534} | train loss {'Reaction outcome loss': 0.5147201931239038, 'Total loss': 0.5147201931239038}
2023-01-04 06:00:02,313 INFO:     Found new best model at epoch 4
2023-01-04 06:00:02,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:02,314 INFO:     Epoch: 5
2023-01-04 06:00:03,851 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5342047115166982, 'Total loss': 0.5342047115166982} | train loss {'Reaction outcome loss': 0.5044774947067102, 'Total loss': 0.5044774947067102}
2023-01-04 06:00:03,852 INFO:     Found new best model at epoch 5
2023-01-04 06:00:03,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:03,853 INFO:     Epoch: 6
2023-01-04 06:00:05,394 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5234994947910309, 'Total loss': 0.5234994947910309} | train loss {'Reaction outcome loss': 0.4900093424451146, 'Total loss': 0.4900093424451146}
2023-01-04 06:00:05,394 INFO:     Found new best model at epoch 6
2023-01-04 06:00:05,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:05,395 INFO:     Epoch: 7
2023-01-04 06:00:06,930 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5125808835029602, 'Total loss': 0.5125808835029602} | train loss {'Reaction outcome loss': 0.4829821550908188, 'Total loss': 0.4829821550908188}
2023-01-04 06:00:06,931 INFO:     Found new best model at epoch 7
2023-01-04 06:00:06,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:06,931 INFO:     Epoch: 8
2023-01-04 06:00:08,413 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5026176969210306, 'Total loss': 0.5026176969210306} | train loss {'Reaction outcome loss': 0.47218046787716245, 'Total loss': 0.47218046787716245}
2023-01-04 06:00:08,414 INFO:     Found new best model at epoch 8
2023-01-04 06:00:08,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:08,414 INFO:     Epoch: 9
2023-01-04 06:00:09,956 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5082558890183767, 'Total loss': 0.5082558890183767} | train loss {'Reaction outcome loss': 0.46793578548080195, 'Total loss': 0.46793578548080195}
2023-01-04 06:00:09,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:09,956 INFO:     Epoch: 10
2023-01-04 06:00:11,508 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5195213854312897, 'Total loss': 0.5195213854312897} | train loss {'Reaction outcome loss': 0.47221568097238953, 'Total loss': 0.47221568097238953}
2023-01-04 06:00:11,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:11,508 INFO:     Epoch: 11
2023-01-04 06:00:13,053 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4897715071837107, 'Total loss': 0.4897715071837107} | train loss {'Reaction outcome loss': 0.46932107240528514, 'Total loss': 0.46932107240528514}
2023-01-04 06:00:13,053 INFO:     Found new best model at epoch 11
2023-01-04 06:00:13,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:13,054 INFO:     Epoch: 12
2023-01-04 06:00:14,604 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4895746966203054, 'Total loss': 0.4895746966203054} | train loss {'Reaction outcome loss': 0.45381638503538957, 'Total loss': 0.45381638503538957}
2023-01-04 06:00:14,604 INFO:     Found new best model at epoch 12
2023-01-04 06:00:14,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:14,605 INFO:     Epoch: 13
2023-01-04 06:00:16,133 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4924841741720835, 'Total loss': 0.4924841741720835} | train loss {'Reaction outcome loss': 0.45215154154752585, 'Total loss': 0.45215154154752585}
2023-01-04 06:00:16,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:16,134 INFO:     Epoch: 14
2023-01-04 06:00:17,631 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4966498831907908, 'Total loss': 0.4966498831907908} | train loss {'Reaction outcome loss': 0.4443481823807393, 'Total loss': 0.4443481823807393}
2023-01-04 06:00:17,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:17,631 INFO:     Epoch: 15
2023-01-04 06:00:19,181 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4966542998949687, 'Total loss': 0.4966542998949687} | train loss {'Reaction outcome loss': 0.44053880954026314, 'Total loss': 0.44053880954026314}
2023-01-04 06:00:19,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:19,181 INFO:     Epoch: 16
2023-01-04 06:00:20,735 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4804390788078308, 'Total loss': 0.4804390788078308} | train loss {'Reaction outcome loss': 0.43949906333633093, 'Total loss': 0.43949906333633093}
2023-01-04 06:00:20,736 INFO:     Found new best model at epoch 16
2023-01-04 06:00:20,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:20,736 INFO:     Epoch: 17
2023-01-04 06:00:22,287 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4712743699550629, 'Total loss': 0.4712743699550629} | train loss {'Reaction outcome loss': 0.43880100101249403, 'Total loss': 0.43880100101249403}
2023-01-04 06:00:22,287 INFO:     Found new best model at epoch 17
2023-01-04 06:00:22,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:22,288 INFO:     Epoch: 18
2023-01-04 06:00:23,837 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49314970076084136, 'Total loss': 0.49314970076084136} | train loss {'Reaction outcome loss': 0.42957877287889185, 'Total loss': 0.42957877287889185}
2023-01-04 06:00:23,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:23,837 INFO:     Epoch: 19
2023-01-04 06:00:25,356 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49707778294881183, 'Total loss': 0.49707778294881183} | train loss {'Reaction outcome loss': 0.4276245620938531, 'Total loss': 0.4276245620938531}
2023-01-04 06:00:25,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:25,356 INFO:     Epoch: 20
2023-01-04 06:00:26,894 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4732139567534129, 'Total loss': 0.4732139567534129} | train loss {'Reaction outcome loss': 0.4259145878309357, 'Total loss': 0.4259145878309357}
2023-01-04 06:00:26,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:26,895 INFO:     Epoch: 21
2023-01-04 06:00:28,458 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4678304001688957, 'Total loss': 0.4678304001688957} | train loss {'Reaction outcome loss': 0.41884703761425573, 'Total loss': 0.41884703761425573}
2023-01-04 06:00:28,459 INFO:     Found new best model at epoch 21
2023-01-04 06:00:28,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:28,460 INFO:     Epoch: 22
2023-01-04 06:00:30,032 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47427660822868345, 'Total loss': 0.47427660822868345} | train loss {'Reaction outcome loss': 0.4162160981166222, 'Total loss': 0.4162160981166222}
2023-01-04 06:00:30,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:30,032 INFO:     Epoch: 23
2023-01-04 06:00:31,622 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48437702655792236, 'Total loss': 0.48437702655792236} | train loss {'Reaction outcome loss': 0.41198433456483524, 'Total loss': 0.41198433456483524}
2023-01-04 06:00:31,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:31,623 INFO:     Epoch: 24
2023-01-04 06:00:33,202 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4872406909863154, 'Total loss': 0.4872406909863154} | train loss {'Reaction outcome loss': 0.40965748372241084, 'Total loss': 0.40965748372241084}
2023-01-04 06:00:33,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:33,202 INFO:     Epoch: 25
2023-01-04 06:00:34,762 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4918999085823695, 'Total loss': 0.4918999085823695} | train loss {'Reaction outcome loss': 0.4125454546208831, 'Total loss': 0.4125454546208831}
2023-01-04 06:00:34,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:34,763 INFO:     Epoch: 26
2023-01-04 06:00:36,336 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46220486164093016, 'Total loss': 0.46220486164093016} | train loss {'Reaction outcome loss': 0.4125448773755098, 'Total loss': 0.4125448773755098}
2023-01-04 06:00:36,336 INFO:     Found new best model at epoch 26
2023-01-04 06:00:36,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:36,337 INFO:     Epoch: 27
2023-01-04 06:00:37,933 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4902604262034098, 'Total loss': 0.4902604262034098} | train loss {'Reaction outcome loss': 0.39658411966967466, 'Total loss': 0.39658411966967466}
2023-01-04 06:00:37,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:37,933 INFO:     Epoch: 28
2023-01-04 06:00:39,545 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46966855724652606, 'Total loss': 0.46966855724652606} | train loss {'Reaction outcome loss': 0.38993612135612016, 'Total loss': 0.38993612135612016}
2023-01-04 06:00:39,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:39,545 INFO:     Epoch: 29
2023-01-04 06:00:41,110 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4764353593190511, 'Total loss': 0.4764353593190511} | train loss {'Reaction outcome loss': 0.3975876837874344, 'Total loss': 0.3975876837874344}
2023-01-04 06:00:41,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:41,110 INFO:     Epoch: 30
2023-01-04 06:00:42,685 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4730454583962758, 'Total loss': 0.4730454583962758} | train loss {'Reaction outcome loss': 0.39038925443647726, 'Total loss': 0.39038925443647726}
2023-01-04 06:00:42,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:42,685 INFO:     Epoch: 31
2023-01-04 06:00:44,235 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4727501432100932, 'Total loss': 0.4727501432100932} | train loss {'Reaction outcome loss': 0.3806840394475106, 'Total loss': 0.3806840394475106}
2023-01-04 06:00:44,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:44,236 INFO:     Epoch: 32
2023-01-04 06:00:45,766 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4686804453531901, 'Total loss': 0.4686804453531901} | train loss {'Reaction outcome loss': 0.3792868987167848, 'Total loss': 0.3792868987167848}
2023-01-04 06:00:45,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:45,766 INFO:     Epoch: 33
2023-01-04 06:00:47,322 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4643636514743169, 'Total loss': 0.4643636514743169} | train loss {'Reaction outcome loss': 0.38124647431760567, 'Total loss': 0.38124647431760567}
2023-01-04 06:00:47,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:47,323 INFO:     Epoch: 34
2023-01-04 06:00:48,877 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4471781522035599, 'Total loss': 0.4471781522035599} | train loss {'Reaction outcome loss': 0.3739671325699116, 'Total loss': 0.3739671325699116}
2023-01-04 06:00:48,877 INFO:     Found new best model at epoch 34
2023-01-04 06:00:48,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:48,878 INFO:     Epoch: 35
2023-01-04 06:00:50,435 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4407126466433207, 'Total loss': 0.4407126466433207} | train loss {'Reaction outcome loss': 0.3674957131008631, 'Total loss': 0.3674957131008631}
2023-01-04 06:00:50,435 INFO:     Found new best model at epoch 35
2023-01-04 06:00:50,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:50,436 INFO:     Epoch: 36
2023-01-04 06:00:52,013 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4469689836104711, 'Total loss': 0.4469689836104711} | train loss {'Reaction outcome loss': 0.3649141694835673, 'Total loss': 0.3649141694835673}
2023-01-04 06:00:52,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:52,013 INFO:     Epoch: 37
2023-01-04 06:00:53,571 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4470786025126775, 'Total loss': 0.4470786025126775} | train loss {'Reaction outcome loss': 0.36359965634883207, 'Total loss': 0.36359965634883207}
2023-01-04 06:00:53,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:53,571 INFO:     Epoch: 38
2023-01-04 06:00:55,178 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44876720011234283, 'Total loss': 0.44876720011234283} | train loss {'Reaction outcome loss': 0.3566592295984805, 'Total loss': 0.3566592295984805}
2023-01-04 06:00:55,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:55,178 INFO:     Epoch: 39
2023-01-04 06:00:56,784 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4470266113678614, 'Total loss': 0.4470266113678614} | train loss {'Reaction outcome loss': 0.35737468187521765, 'Total loss': 0.35737468187521765}
2023-01-04 06:00:56,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:56,784 INFO:     Epoch: 40
2023-01-04 06:00:58,377 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4566556721925735, 'Total loss': 0.4566556721925735} | train loss {'Reaction outcome loss': 0.35493463047179463, 'Total loss': 0.35493463047179463}
2023-01-04 06:00:58,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:58,377 INFO:     Epoch: 41
2023-01-04 06:00:59,934 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47826138039429983, 'Total loss': 0.47826138039429983} | train loss {'Reaction outcome loss': 0.3515821613640899, 'Total loss': 0.3515821613640899}
2023-01-04 06:00:59,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:00:59,945 INFO:     Epoch: 42
2023-01-04 06:01:01,500 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4454890032609304, 'Total loss': 0.4454890032609304} | train loss {'Reaction outcome loss': 0.34807726334648853, 'Total loss': 0.34807726334648853}
2023-01-04 06:01:01,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:01,501 INFO:     Epoch: 43
2023-01-04 06:01:03,035 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45247889558474225, 'Total loss': 0.45247889558474225} | train loss {'Reaction outcome loss': 0.3597958277694989, 'Total loss': 0.3597958277694989}
2023-01-04 06:01:03,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:03,036 INFO:     Epoch: 44
2023-01-04 06:01:04,605 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44045207301775613, 'Total loss': 0.44045207301775613} | train loss {'Reaction outcome loss': 0.3879867601815773, 'Total loss': 0.3879867601815773}
2023-01-04 06:01:04,605 INFO:     Found new best model at epoch 44
2023-01-04 06:01:04,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:04,606 INFO:     Epoch: 45
2023-01-04 06:01:06,174 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43695574104785917, 'Total loss': 0.43695574104785917} | train loss {'Reaction outcome loss': 0.3434511281118013, 'Total loss': 0.3434511281118013}
2023-01-04 06:01:06,174 INFO:     Found new best model at epoch 45
2023-01-04 06:01:06,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:06,175 INFO:     Epoch: 46
2023-01-04 06:01:07,740 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45931252936522166, 'Total loss': 0.45931252936522166} | train loss {'Reaction outcome loss': 0.33768117454504437, 'Total loss': 0.33768117454504437}
2023-01-04 06:01:07,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:07,740 INFO:     Epoch: 47
2023-01-04 06:01:09,319 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45787343581517537, 'Total loss': 0.45787343581517537} | train loss {'Reaction outcome loss': 0.3314676726155955, 'Total loss': 0.3314676726155955}
2023-01-04 06:01:09,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:09,320 INFO:     Epoch: 48
2023-01-04 06:01:10,849 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4478563835223516, 'Total loss': 0.4478563835223516} | train loss {'Reaction outcome loss': 0.33937632219622965, 'Total loss': 0.33937632219622965}
2023-01-04 06:01:10,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:10,850 INFO:     Epoch: 49
2023-01-04 06:01:12,381 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46820888519287107, 'Total loss': 0.46820888519287107} | train loss {'Reaction outcome loss': 0.3413641700872045, 'Total loss': 0.3413641700872045}
2023-01-04 06:01:12,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:12,381 INFO:     Epoch: 50
2023-01-04 06:01:13,942 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43970660169919334, 'Total loss': 0.43970660169919334} | train loss {'Reaction outcome loss': 0.3754768743242164, 'Total loss': 0.3754768743242164}
2023-01-04 06:01:13,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:13,943 INFO:     Epoch: 51
2023-01-04 06:01:15,512 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46310580770174664, 'Total loss': 0.46310580770174664} | train loss {'Reaction outcome loss': 0.32864272209775186, 'Total loss': 0.32864272209775186}
2023-01-04 06:01:15,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:15,512 INFO:     Epoch: 52
2023-01-04 06:01:17,087 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43678407470385233, 'Total loss': 0.43678407470385233} | train loss {'Reaction outcome loss': 0.3223342938159687, 'Total loss': 0.3223342938159687}
2023-01-04 06:01:17,087 INFO:     Found new best model at epoch 52
2023-01-04 06:01:17,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:17,088 INFO:     Epoch: 53
2023-01-04 06:01:18,659 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4448168714841207, 'Total loss': 0.4448168714841207} | train loss {'Reaction outcome loss': 0.3256606459617615, 'Total loss': 0.3256606459617615}
2023-01-04 06:01:18,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:18,659 INFO:     Epoch: 54
2023-01-04 06:01:20,180 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4204156011343002, 'Total loss': 0.4204156011343002} | train loss {'Reaction outcome loss': 0.3344069146213756, 'Total loss': 0.3344069146213756}
2023-01-04 06:01:20,180 INFO:     Found new best model at epoch 54
2023-01-04 06:01:20,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:20,181 INFO:     Epoch: 55
2023-01-04 06:01:21,719 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43375805219014485, 'Total loss': 0.43375805219014485} | train loss {'Reaction outcome loss': 0.3150630787089197, 'Total loss': 0.3150630787089197}
2023-01-04 06:01:21,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:21,720 INFO:     Epoch: 56
2023-01-04 06:01:23,288 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4824874887863795, 'Total loss': 0.4824874887863795} | train loss {'Reaction outcome loss': 0.31421149017262284, 'Total loss': 0.31421149017262284}
2023-01-04 06:01:23,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:23,288 INFO:     Epoch: 57
2023-01-04 06:01:24,842 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41901025275389353, 'Total loss': 0.41901025275389353} | train loss {'Reaction outcome loss': 0.3211964044611955, 'Total loss': 0.3211964044611955}
2023-01-04 06:01:24,843 INFO:     Found new best model at epoch 57
2023-01-04 06:01:24,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:24,843 INFO:     Epoch: 58
2023-01-04 06:01:26,399 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4225842917958895, 'Total loss': 0.4225842917958895} | train loss {'Reaction outcome loss': 0.3183114050220668, 'Total loss': 0.3183114050220668}
2023-01-04 06:01:26,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:26,399 INFO:     Epoch: 59
2023-01-04 06:01:27,979 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45299506982167564, 'Total loss': 0.45299506982167564} | train loss {'Reaction outcome loss': 0.3085974756176111, 'Total loss': 0.3085974756176111}
2023-01-04 06:01:27,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:27,980 INFO:     Epoch: 60
2023-01-04 06:01:29,532 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.414488485455513, 'Total loss': 0.414488485455513} | train loss {'Reaction outcome loss': 0.3041956637395703, 'Total loss': 0.3041956637395703}
2023-01-04 06:01:29,532 INFO:     Found new best model at epoch 60
2023-01-04 06:01:29,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:29,533 INFO:     Epoch: 61
2023-01-04 06:01:31,066 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42881938914457957, 'Total loss': 0.42881938914457957} | train loss {'Reaction outcome loss': 0.3066059424804141, 'Total loss': 0.3066059424804141}
2023-01-04 06:01:31,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:31,066 INFO:     Epoch: 62
2023-01-04 06:01:32,643 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4351951003074646, 'Total loss': 0.4351951003074646} | train loss {'Reaction outcome loss': 0.30844197073357477, 'Total loss': 0.30844197073357477}
2023-01-04 06:01:32,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:32,643 INFO:     Epoch: 63
2023-01-04 06:01:34,202 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42942588329315184, 'Total loss': 0.42942588329315184} | train loss {'Reaction outcome loss': 0.30492320554195973, 'Total loss': 0.30492320554195973}
2023-01-04 06:01:34,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:34,204 INFO:     Epoch: 64
2023-01-04 06:01:35,782 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4281694491704305, 'Total loss': 0.4281694491704305} | train loss {'Reaction outcome loss': 0.3148079249580458, 'Total loss': 0.3148079249580458}
2023-01-04 06:01:35,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:35,783 INFO:     Epoch: 65
2023-01-04 06:01:37,350 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4219403291742007, 'Total loss': 0.4219403291742007} | train loss {'Reaction outcome loss': 0.3024993782008465, 'Total loss': 0.3024993782008465}
2023-01-04 06:01:37,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:37,350 INFO:     Epoch: 66
2023-01-04 06:01:38,892 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43796860973040264, 'Total loss': 0.43796860973040264} | train loss {'Reaction outcome loss': 0.29850017905960685, 'Total loss': 0.29850017905960685}
2023-01-04 06:01:38,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:38,892 INFO:     Epoch: 67
2023-01-04 06:01:40,437 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43238126834233603, 'Total loss': 0.43238126834233603} | train loss {'Reaction outcome loss': 0.29885855412947526, 'Total loss': 0.29885855412947526}
2023-01-04 06:01:40,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:40,438 INFO:     Epoch: 68
2023-01-04 06:01:42,008 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4618516743183136, 'Total loss': 0.4618516743183136} | train loss {'Reaction outcome loss': 0.2930564838529065, 'Total loss': 0.2930564838529065}
2023-01-04 06:01:42,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:42,008 INFO:     Epoch: 69
2023-01-04 06:01:43,597 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4246434768040975, 'Total loss': 0.4246434768040975} | train loss {'Reaction outcome loss': 0.3018245870463442, 'Total loss': 0.3018245870463442}
2023-01-04 06:01:43,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:43,597 INFO:     Epoch: 70
2023-01-04 06:01:45,190 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42800816694895427, 'Total loss': 0.42800816694895427} | train loss {'Reaction outcome loss': 0.2906671241252449, 'Total loss': 0.2906671241252449}
2023-01-04 06:01:45,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:45,190 INFO:     Epoch: 71
2023-01-04 06:01:46,779 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4455855071544647, 'Total loss': 0.4455855071544647} | train loss {'Reaction outcome loss': 0.2916702053881254, 'Total loss': 0.2916702053881254}
2023-01-04 06:01:46,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:46,779 INFO:     Epoch: 72
2023-01-04 06:01:48,310 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4214282214641571, 'Total loss': 0.4214282214641571} | train loss {'Reaction outcome loss': 0.29003160214726476, 'Total loss': 0.29003160214726476}
2023-01-04 06:01:48,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:48,310 INFO:     Epoch: 73
2023-01-04 06:01:49,896 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4438047021627426, 'Total loss': 0.4438047021627426} | train loss {'Reaction outcome loss': 0.28375414653725084, 'Total loss': 0.28375414653725084}
2023-01-04 06:01:49,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:49,896 INFO:     Epoch: 74
2023-01-04 06:01:51,487 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4242421845595042, 'Total loss': 0.4242421845595042} | train loss {'Reaction outcome loss': 0.2847526810499772, 'Total loss': 0.2847526810499772}
2023-01-04 06:01:51,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:51,487 INFO:     Epoch: 75
2023-01-04 06:01:53,051 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4473678072293599, 'Total loss': 0.4473678072293599} | train loss {'Reaction outcome loss': 0.28672579802873044, 'Total loss': 0.28672579802873044}
2023-01-04 06:01:53,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:53,052 INFO:     Epoch: 76
2023-01-04 06:01:54,641 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4630009820063909, 'Total loss': 0.4630009820063909} | train loss {'Reaction outcome loss': 0.28946710831445194, 'Total loss': 0.28946710831445194}
2023-01-04 06:01:54,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:54,642 INFO:     Epoch: 77
2023-01-04 06:01:56,192 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4755875110626221, 'Total loss': 0.4755875110626221} | train loss {'Reaction outcome loss': 0.33002657173336414, 'Total loss': 0.33002657173336414}
2023-01-04 06:01:56,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:56,192 INFO:     Epoch: 78
2023-01-04 06:01:57,740 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43180768489837645, 'Total loss': 0.43180768489837645} | train loss {'Reaction outcome loss': 0.3275339055074163, 'Total loss': 0.3275339055074163}
2023-01-04 06:01:57,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:57,741 INFO:     Epoch: 79
2023-01-04 06:01:59,302 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41698938409487407, 'Total loss': 0.41698938409487407} | train loss {'Reaction outcome loss': 0.2829508190330091, 'Total loss': 0.2829508190330091}
2023-01-04 06:01:59,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:01:59,302 INFO:     Epoch: 80
2023-01-04 06:02:00,859 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45738675793011985, 'Total loss': 0.45738675793011985} | train loss {'Reaction outcome loss': 0.28177860492597456, 'Total loss': 0.28177860492597456}
2023-01-04 06:02:00,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:00,860 INFO:     Epoch: 81
2023-01-04 06:02:02,411 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43570205370585124, 'Total loss': 0.43570205370585124} | train loss {'Reaction outcome loss': 0.2901914733141419, 'Total loss': 0.2901914733141419}
2023-01-04 06:02:02,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:02,411 INFO:     Epoch: 82
2023-01-04 06:02:03,992 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4416886895895004, 'Total loss': 0.4416886895895004} | train loss {'Reaction outcome loss': 0.27847804901176604, 'Total loss': 0.27847804901176604}
2023-01-04 06:02:03,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:03,993 INFO:     Epoch: 83
2023-01-04 06:02:05,538 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41817078391710916, 'Total loss': 0.41817078391710916} | train loss {'Reaction outcome loss': 0.2931964607787845, 'Total loss': 0.2931964607787845}
2023-01-04 06:02:05,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:05,539 INFO:     Epoch: 84
2023-01-04 06:02:07,059 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42672329346338905, 'Total loss': 0.42672329346338905} | train loss {'Reaction outcome loss': 0.2706055690642392, 'Total loss': 0.2706055690642392}
2023-01-04 06:02:07,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:07,059 INFO:     Epoch: 85
2023-01-04 06:02:08,637 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42147806386152903, 'Total loss': 0.42147806386152903} | train loss {'Reaction outcome loss': 0.268997595888441, 'Total loss': 0.268997595888441}
2023-01-04 06:02:08,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:08,637 INFO:     Epoch: 86
2023-01-04 06:02:10,198 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42655840814113616, 'Total loss': 0.42655840814113616} | train loss {'Reaction outcome loss': 0.2691086138926777, 'Total loss': 0.2691086138926777}
2023-01-04 06:02:10,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:10,198 INFO:     Epoch: 87
2023-01-04 06:02:11,765 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4211791982253393, 'Total loss': 0.4211791982253393} | train loss {'Reaction outcome loss': 0.2661611000345885, 'Total loss': 0.2661611000345885}
2023-01-04 06:02:11,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:11,766 INFO:     Epoch: 88
2023-01-04 06:02:13,323 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40254353483517963, 'Total loss': 0.40254353483517963} | train loss {'Reaction outcome loss': 0.2722429665669367, 'Total loss': 0.2722429665669367}
2023-01-04 06:02:13,323 INFO:     Found new best model at epoch 88
2023-01-04 06:02:13,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:13,324 INFO:     Epoch: 89
2023-01-04 06:02:14,844 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4305386374394099, 'Total loss': 0.4305386374394099} | train loss {'Reaction outcome loss': 0.2693237262850533, 'Total loss': 0.2693237262850533}
2023-01-04 06:02:14,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:14,845 INFO:     Epoch: 90
2023-01-04 06:02:16,374 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42868693470954894, 'Total loss': 0.42868693470954894} | train loss {'Reaction outcome loss': 0.2681510041828902, 'Total loss': 0.2681510041828902}
2023-01-04 06:02:16,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:16,374 INFO:     Epoch: 91
2023-01-04 06:02:17,923 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4028201371431351, 'Total loss': 0.4028201371431351} | train loss {'Reaction outcome loss': 0.2754389680652083, 'Total loss': 0.2754389680652083}
2023-01-04 06:02:17,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:17,924 INFO:     Epoch: 92
2023-01-04 06:02:19,468 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4114123503367106, 'Total loss': 0.4114123503367106} | train loss {'Reaction outcome loss': 0.3042895449190468, 'Total loss': 0.3042895449190468}
2023-01-04 06:02:19,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:19,468 INFO:     Epoch: 93
2023-01-04 06:02:21,018 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42464651465415953, 'Total loss': 0.42464651465415953} | train loss {'Reaction outcome loss': 0.2811777750165134, 'Total loss': 0.2811777750165134}
2023-01-04 06:02:21,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:21,018 INFO:     Epoch: 94
2023-01-04 06:02:22,565 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4153021226326625, 'Total loss': 0.4153021226326625} | train loss {'Reaction outcome loss': 0.2699102361381148, 'Total loss': 0.2699102361381148}
2023-01-04 06:02:22,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:22,565 INFO:     Epoch: 95
2023-01-04 06:02:24,079 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42164686719576516, 'Total loss': 0.42164686719576516} | train loss {'Reaction outcome loss': 0.2665214704727565, 'Total loss': 0.2665214704727565}
2023-01-04 06:02:24,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:24,080 INFO:     Epoch: 96
2023-01-04 06:02:25,609 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4365532249212265, 'Total loss': 0.4365532249212265} | train loss {'Reaction outcome loss': 0.27129076540038205, 'Total loss': 0.27129076540038205}
2023-01-04 06:02:25,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:25,610 INFO:     Epoch: 97
2023-01-04 06:02:27,189 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42979128460089366, 'Total loss': 0.42979128460089366} | train loss {'Reaction outcome loss': 0.2683543777380112, 'Total loss': 0.2683543777380112}
2023-01-04 06:02:27,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:27,189 INFO:     Epoch: 98
2023-01-04 06:02:28,767 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45571463108062743, 'Total loss': 0.45571463108062743} | train loss {'Reaction outcome loss': 0.26517731692318036, 'Total loss': 0.26517731692318036}
2023-01-04 06:02:28,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:28,767 INFO:     Epoch: 99
2023-01-04 06:02:30,324 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4114699234565099, 'Total loss': 0.4114699234565099} | train loss {'Reaction outcome loss': 0.2978935019068624, 'Total loss': 0.2978935019068624}
2023-01-04 06:02:30,324 INFO:     Best model found after epoch 89 of 100.
2023-01-04 06:02:30,324 INFO:   Done with stage: TRAINING
2023-01-04 06:02:30,324 INFO:   Starting stage: EVALUATION
2023-01-04 06:02:30,452 INFO:   Done with stage: EVALUATION
2023-01-04 06:02:30,460 INFO:   Leaving out SEQ value Fold_0
2023-01-04 06:02:30,473 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 06:02:30,473 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:02:31,113 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:02:31,114 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:02:31,182 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:02:31,183 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:02:31,183 INFO:     No hyperparam tuning for this model
2023-01-04 06:02:31,183 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:02:31,183 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:02:31,183 INFO:     None feature selector for col prot
2023-01-04 06:02:31,184 INFO:     None feature selector for col prot
2023-01-04 06:02:31,184 INFO:     None feature selector for col prot
2023-01-04 06:02:31,184 INFO:     None feature selector for col chem
2023-01-04 06:02:31,184 INFO:     None feature selector for col chem
2023-01-04 06:02:31,184 INFO:     None feature selector for col chem
2023-01-04 06:02:31,184 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:02:31,184 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:02:31,185 INFO:     Number of params in model 70111
2023-01-04 06:02:31,188 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:02:31,189 INFO:   Starting stage: TRAINING
2023-01-04 06:02:31,231 INFO:     Val loss before train {'Reaction outcome loss': 0.999262269337972, 'Total loss': 0.999262269337972}
2023-01-04 06:02:31,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:31,231 INFO:     Epoch: 0
2023-01-04 06:02:32,748 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7810864627361298, 'Total loss': 0.7810864627361298} | train loss {'Reaction outcome loss': 0.8445698221891129, 'Total loss': 0.8445698221891129}
2023-01-04 06:02:32,748 INFO:     Found new best model at epoch 0
2023-01-04 06:02:32,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:32,749 INFO:     Epoch: 1
2023-01-04 06:02:34,257 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6018998016913731, 'Total loss': 0.6018998016913731} | train loss {'Reaction outcome loss': 0.705597687086496, 'Total loss': 0.705597687086496}
2023-01-04 06:02:34,257 INFO:     Found new best model at epoch 1
2023-01-04 06:02:34,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:34,258 INFO:     Epoch: 2
2023-01-04 06:02:35,800 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5672384897867838, 'Total loss': 0.5672384897867838} | train loss {'Reaction outcome loss': 0.6104339748291072, 'Total loss': 0.6104339748291072}
2023-01-04 06:02:35,800 INFO:     Found new best model at epoch 2
2023-01-04 06:02:35,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:35,801 INFO:     Epoch: 3
2023-01-04 06:02:37,348 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5553030788898468, 'Total loss': 0.5553030788898468} | train loss {'Reaction outcome loss': 0.5594526289024037, 'Total loss': 0.5594526289024037}
2023-01-04 06:02:37,348 INFO:     Found new best model at epoch 3
2023-01-04 06:02:37,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:37,349 INFO:     Epoch: 4
2023-01-04 06:02:38,918 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5012953658898671, 'Total loss': 0.5012953658898671} | train loss {'Reaction outcome loss': 0.5329075797127621, 'Total loss': 0.5329075797127621}
2023-01-04 06:02:38,918 INFO:     Found new best model at epoch 4
2023-01-04 06:02:38,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:38,919 INFO:     Epoch: 5
2023-01-04 06:02:40,495 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.490434260169665, 'Total loss': 0.490434260169665} | train loss {'Reaction outcome loss': 0.5108722081043624, 'Total loss': 0.5108722081043624}
2023-01-04 06:02:40,496 INFO:     Found new best model at epoch 5
2023-01-04 06:02:40,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:40,497 INFO:     Epoch: 6
2023-01-04 06:02:42,037 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.497955987850825, 'Total loss': 0.497955987850825} | train loss {'Reaction outcome loss': 0.4929953786059939, 'Total loss': 0.4929953786059939}
2023-01-04 06:02:42,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:42,038 INFO:     Epoch: 7
2023-01-04 06:02:43,562 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49753669699033104, 'Total loss': 0.49753669699033104} | train loss {'Reaction outcome loss': 0.4873809525227635, 'Total loss': 0.4873809525227635}
2023-01-04 06:02:43,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:43,562 INFO:     Epoch: 8
2023-01-04 06:02:45,091 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46939436395963036, 'Total loss': 0.46939436395963036} | train loss {'Reaction outcome loss': 0.4746050890191455, 'Total loss': 0.4746050890191455}
2023-01-04 06:02:45,091 INFO:     Found new best model at epoch 8
2023-01-04 06:02:45,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:45,092 INFO:     Epoch: 9
2023-01-04 06:02:46,644 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4500168045361837, 'Total loss': 0.4500168045361837} | train loss {'Reaction outcome loss': 0.46671134541395404, 'Total loss': 0.46671134541395404}
2023-01-04 06:02:46,645 INFO:     Found new best model at epoch 9
2023-01-04 06:02:46,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:46,646 INFO:     Epoch: 10
2023-01-04 06:02:48,193 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.483515328168869, 'Total loss': 0.483515328168869} | train loss {'Reaction outcome loss': 0.45628009241665424, 'Total loss': 0.45628009241665424}
2023-01-04 06:02:48,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:48,194 INFO:     Epoch: 11
2023-01-04 06:02:49,722 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.439347272614638, 'Total loss': 0.439347272614638} | train loss {'Reaction outcome loss': 0.44968401912833494, 'Total loss': 0.44968401912833494}
2023-01-04 06:02:49,722 INFO:     Found new best model at epoch 11
2023-01-04 06:02:49,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:49,723 INFO:     Epoch: 12
2023-01-04 06:02:51,218 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4499451299508413, 'Total loss': 0.4499451299508413} | train loss {'Reaction outcome loss': 0.44402403640131227, 'Total loss': 0.44402403640131227}
2023-01-04 06:02:51,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:51,219 INFO:     Epoch: 13
2023-01-04 06:02:52,749 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43874282439549767, 'Total loss': 0.43874282439549767} | train loss {'Reaction outcome loss': 0.44338856667720083, 'Total loss': 0.44338856667720083}
2023-01-04 06:02:52,749 INFO:     Found new best model at epoch 13
2023-01-04 06:02:52,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:52,750 INFO:     Epoch: 14
2023-01-04 06:02:54,334 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4695647060871124, 'Total loss': 0.4695647060871124} | train loss {'Reaction outcome loss': 0.43360113575229786, 'Total loss': 0.43360113575229786}
2023-01-04 06:02:54,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:54,334 INFO:     Epoch: 15
2023-01-04 06:02:55,902 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4429940422375997, 'Total loss': 0.4429940422375997} | train loss {'Reaction outcome loss': 0.43046987722060776, 'Total loss': 0.43046987722060776}
2023-01-04 06:02:55,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:55,903 INFO:     Epoch: 16
2023-01-04 06:02:57,460 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4330625881751378, 'Total loss': 0.4330625881751378} | train loss {'Reaction outcome loss': 0.4256968810549521, 'Total loss': 0.4256968810549521}
2023-01-04 06:02:57,460 INFO:     Found new best model at epoch 16
2023-01-04 06:02:57,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:57,461 INFO:     Epoch: 17
2023-01-04 06:02:58,990 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44999813437461855, 'Total loss': 0.44999813437461855} | train loss {'Reaction outcome loss': 0.4224313227562887, 'Total loss': 0.4224313227562887}
2023-01-04 06:02:58,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:02:58,991 INFO:     Epoch: 18
2023-01-04 06:03:00,467 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4677964349587758, 'Total loss': 0.4677964349587758} | train loss {'Reaction outcome loss': 0.4166526735048892, 'Total loss': 0.4166526735048892}
2023-01-04 06:03:00,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:00,467 INFO:     Epoch: 19
2023-01-04 06:03:01,971 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45118177533149717, 'Total loss': 0.45118177533149717} | train loss {'Reaction outcome loss': 0.4142689976525043, 'Total loss': 0.4142689976525043}
2023-01-04 06:03:01,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:01,972 INFO:     Epoch: 20
2023-01-04 06:03:03,498 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47059718569119774, 'Total loss': 0.47059718569119774} | train loss {'Reaction outcome loss': 0.4118067538606285, 'Total loss': 0.4118067538606285}
2023-01-04 06:03:03,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:03,498 INFO:     Epoch: 21
2023-01-04 06:03:05,026 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43707146445910133, 'Total loss': 0.43707146445910133} | train loss {'Reaction outcome loss': 0.40665602475074825, 'Total loss': 0.40665602475074825}
2023-01-04 06:03:05,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:05,026 INFO:     Epoch: 22
2023-01-04 06:03:06,558 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4518109122912089, 'Total loss': 0.4518109122912089} | train loss {'Reaction outcome loss': 0.3985459224434356, 'Total loss': 0.3985459224434356}
2023-01-04 06:03:06,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:06,559 INFO:     Epoch: 23
2023-01-04 06:03:08,107 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4405190348625183, 'Total loss': 0.4405190348625183} | train loss {'Reaction outcome loss': 0.39712855841180933, 'Total loss': 0.39712855841180933}
2023-01-04 06:03:08,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:08,107 INFO:     Epoch: 24
2023-01-04 06:03:09,588 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4441073695818583, 'Total loss': 0.4441073695818583} | train loss {'Reaction outcome loss': 0.3898319721881754, 'Total loss': 0.3898319721881754}
2023-01-04 06:03:09,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:09,588 INFO:     Epoch: 25
2023-01-04 06:03:11,125 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4364701986312866, 'Total loss': 0.4364701986312866} | train loss {'Reaction outcome loss': 0.3904080782979177, 'Total loss': 0.3904080782979177}
2023-01-04 06:03:11,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:11,126 INFO:     Epoch: 26
2023-01-04 06:03:12,654 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43296358386675515, 'Total loss': 0.43296358386675515} | train loss {'Reaction outcome loss': 0.3849746478219754, 'Total loss': 0.3849746478219754}
2023-01-04 06:03:12,654 INFO:     Found new best model at epoch 26
2023-01-04 06:03:12,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:12,655 INFO:     Epoch: 27
2023-01-04 06:03:14,216 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4170197824637095, 'Total loss': 0.4170197824637095} | train loss {'Reaction outcome loss': 0.3863315795070571, 'Total loss': 0.3863315795070571}
2023-01-04 06:03:14,216 INFO:     Found new best model at epoch 27
2023-01-04 06:03:14,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:14,217 INFO:     Epoch: 28
2023-01-04 06:03:15,730 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43101465900739033, 'Total loss': 0.43101465900739033} | train loss {'Reaction outcome loss': 0.37882421052983767, 'Total loss': 0.37882421052983767}
2023-01-04 06:03:15,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:15,730 INFO:     Epoch: 29
2023-01-04 06:03:17,283 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45544654031594595, 'Total loss': 0.45544654031594595} | train loss {'Reaction outcome loss': 0.3796929680773253, 'Total loss': 0.3796929680773253}
2023-01-04 06:03:17,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:17,284 INFO:     Epoch: 30
2023-01-04 06:03:18,746 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4427630126476288, 'Total loss': 0.4427630126476288} | train loss {'Reaction outcome loss': 0.3697658757167109, 'Total loss': 0.3697658757167109}
2023-01-04 06:03:18,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:18,746 INFO:     Epoch: 31
2023-01-04 06:03:20,287 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4159413158893585, 'Total loss': 0.4159413158893585} | train loss {'Reaction outcome loss': 0.3699315173544567, 'Total loss': 0.3699315173544567}
2023-01-04 06:03:20,288 INFO:     Found new best model at epoch 31
2023-01-04 06:03:20,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:20,288 INFO:     Epoch: 32
2023-01-04 06:03:21,819 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43930443525314333, 'Total loss': 0.43930443525314333} | train loss {'Reaction outcome loss': 0.36491385932558135, 'Total loss': 0.36491385932558135}
2023-01-04 06:03:21,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:21,819 INFO:     Epoch: 33
2023-01-04 06:03:23,367 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4085166662931442, 'Total loss': 0.4085166662931442} | train loss {'Reaction outcome loss': 0.36329579177377846, 'Total loss': 0.36329579177377846}
2023-01-04 06:03:23,367 INFO:     Found new best model at epoch 33
2023-01-04 06:03:23,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:23,368 INFO:     Epoch: 34
2023-01-04 06:03:24,904 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4678375065326691, 'Total loss': 0.4678375065326691} | train loss {'Reaction outcome loss': 0.3592730323436955, 'Total loss': 0.3592730323436955}
2023-01-04 06:03:24,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:24,905 INFO:     Epoch: 35
2023-01-04 06:03:26,432 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3872889161109924, 'Total loss': 0.3872889161109924} | train loss {'Reaction outcome loss': 0.35853724379601076, 'Total loss': 0.35853724379601076}
2023-01-04 06:03:26,432 INFO:     Found new best model at epoch 35
2023-01-04 06:03:26,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:26,433 INFO:     Epoch: 36
2023-01-04 06:03:27,932 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4051632304986318, 'Total loss': 0.4051632304986318} | train loss {'Reaction outcome loss': 0.3522610396586661, 'Total loss': 0.3522610396586661}
2023-01-04 06:03:27,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:27,933 INFO:     Epoch: 37
2023-01-04 06:03:29,485 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41497526864210765, 'Total loss': 0.41497526864210765} | train loss {'Reaction outcome loss': 0.3496539402491932, 'Total loss': 0.3496539402491932}
2023-01-04 06:03:29,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:29,486 INFO:     Epoch: 38
2023-01-04 06:03:31,073 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3913198192914327, 'Total loss': 0.3913198192914327} | train loss {'Reaction outcome loss': 0.3474090434748308, 'Total loss': 0.3474090434748308}
2023-01-04 06:03:31,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:31,073 INFO:     Epoch: 39
2023-01-04 06:03:32,633 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3914832631746928, 'Total loss': 0.3914832631746928} | train loss {'Reaction outcome loss': 0.3448922444148697, 'Total loss': 0.3448922444148697}
2023-01-04 06:03:32,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:32,633 INFO:     Epoch: 40
2023-01-04 06:03:34,198 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40298870503902434, 'Total loss': 0.40298870503902434} | train loss {'Reaction outcome loss': 0.3386219166136756, 'Total loss': 0.3386219166136756}
2023-01-04 06:03:34,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:34,198 INFO:     Epoch: 41
2023-01-04 06:03:35,727 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3984860340754191, 'Total loss': 0.3984860340754191} | train loss {'Reaction outcome loss': 0.33794446492986924, 'Total loss': 0.33794446492986924}
2023-01-04 06:03:35,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:35,727 INFO:     Epoch: 42
2023-01-04 06:03:37,245 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4061204731464386, 'Total loss': 0.4061204731464386} | train loss {'Reaction outcome loss': 0.33804300980044466, 'Total loss': 0.33804300980044466}
2023-01-04 06:03:37,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:37,246 INFO:     Epoch: 43
2023-01-04 06:03:38,785 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39774394830067955, 'Total loss': 0.39774394830067955} | train loss {'Reaction outcome loss': 0.33516214867689514, 'Total loss': 0.33516214867689514}
2023-01-04 06:03:38,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:38,785 INFO:     Epoch: 44
2023-01-04 06:03:40,342 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4187152663866679, 'Total loss': 0.4187152663866679} | train loss {'Reaction outcome loss': 0.3330335179928044, 'Total loss': 0.3330335179928044}
2023-01-04 06:03:40,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:40,342 INFO:     Epoch: 45
2023-01-04 06:03:41,870 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39878742893536884, 'Total loss': 0.39878742893536884} | train loss {'Reaction outcome loss': 0.3280118421214973, 'Total loss': 0.3280118421214973}
2023-01-04 06:03:41,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:41,870 INFO:     Epoch: 46
2023-01-04 06:03:43,409 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40786746044953665, 'Total loss': 0.40786746044953665} | train loss {'Reaction outcome loss': 0.32934189659313085, 'Total loss': 0.32934189659313085}
2023-01-04 06:03:43,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:43,410 INFO:     Epoch: 47
2023-01-04 06:03:44,904 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3946499129136403, 'Total loss': 0.3946499129136403} | train loss {'Reaction outcome loss': 0.32637676585644376, 'Total loss': 0.32637676585644376}
2023-01-04 06:03:44,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:44,904 INFO:     Epoch: 48
2023-01-04 06:03:46,397 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4164196203152339, 'Total loss': 0.4164196203152339} | train loss {'Reaction outcome loss': 0.32371938822454194, 'Total loss': 0.32371938822454194}
2023-01-04 06:03:46,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:46,397 INFO:     Epoch: 49
2023-01-04 06:03:47,916 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4160840670267741, 'Total loss': 0.4160840670267741} | train loss {'Reaction outcome loss': 0.31889995927080456, 'Total loss': 0.31889995927080456}
2023-01-04 06:03:47,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:47,916 INFO:     Epoch: 50
2023-01-04 06:03:49,477 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41230592926343285, 'Total loss': 0.41230592926343285} | train loss {'Reaction outcome loss': 0.31822440220641035, 'Total loss': 0.31822440220641035}
2023-01-04 06:03:49,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:49,478 INFO:     Epoch: 51
2023-01-04 06:03:51,014 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4047206511100133, 'Total loss': 0.4047206511100133} | train loss {'Reaction outcome loss': 0.3203819867814599, 'Total loss': 0.3203819867814599}
2023-01-04 06:03:51,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:51,014 INFO:     Epoch: 52
2023-01-04 06:03:52,550 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36704524103552105, 'Total loss': 0.36704524103552105} | train loss {'Reaction outcome loss': 0.311023715869747, 'Total loss': 0.311023715869747}
2023-01-04 06:03:52,550 INFO:     Found new best model at epoch 52
2023-01-04 06:03:52,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:52,551 INFO:     Epoch: 53
2023-01-04 06:03:54,066 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38730110228061676, 'Total loss': 0.38730110228061676} | train loss {'Reaction outcome loss': 0.311188326976726, 'Total loss': 0.311188326976726}
2023-01-04 06:03:54,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:54,066 INFO:     Epoch: 54
2023-01-04 06:03:55,593 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40900480349858603, 'Total loss': 0.40900480349858603} | train loss {'Reaction outcome loss': 0.3089430322561317, 'Total loss': 0.3089430322561317}
2023-01-04 06:03:55,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:55,593 INFO:     Epoch: 55
2023-01-04 06:03:57,148 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3752363950014114, 'Total loss': 0.3752363950014114} | train loss {'Reaction outcome loss': 0.3135234164245894, 'Total loss': 0.3135234164245894}
2023-01-04 06:03:57,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:57,148 INFO:     Epoch: 56
2023-01-04 06:03:58,674 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39875337183475495, 'Total loss': 0.39875337183475495} | train loss {'Reaction outcome loss': 0.3083237711876301, 'Total loss': 0.3083237711876301}
2023-01-04 06:03:58,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:03:58,675 INFO:     Epoch: 57
2023-01-04 06:04:00,215 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38915603955586753, 'Total loss': 0.38915603955586753} | train loss {'Reaction outcome loss': 0.30394736091809077, 'Total loss': 0.30394736091809077}
2023-01-04 06:04:00,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:00,215 INFO:     Epoch: 58
2023-01-04 06:04:01,755 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4110622972249985, 'Total loss': 0.4110622972249985} | train loss {'Reaction outcome loss': 0.29808569039695815, 'Total loss': 0.29808569039695815}
2023-01-04 06:04:01,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:01,756 INFO:     Epoch: 59
2023-01-04 06:04:03,258 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3929843043287595, 'Total loss': 0.3929843043287595} | train loss {'Reaction outcome loss': 0.3012063737779966, 'Total loss': 0.3012063737779966}
2023-01-04 06:04:03,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:03,258 INFO:     Epoch: 60
2023-01-04 06:04:04,765 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40002477218707405, 'Total loss': 0.40002477218707405} | train loss {'Reaction outcome loss': 0.3025967897744196, 'Total loss': 0.3025967897744196}
2023-01-04 06:04:04,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:04,765 INFO:     Epoch: 61
2023-01-04 06:04:06,296 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4136795878410339, 'Total loss': 0.4136795878410339} | train loss {'Reaction outcome loss': 0.29969941568990477, 'Total loss': 0.29969941568990477}
2023-01-04 06:04:06,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:06,297 INFO:     Epoch: 62
2023-01-04 06:04:07,834 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4172390003999074, 'Total loss': 0.4172390003999074} | train loss {'Reaction outcome loss': 0.29440688212639293, 'Total loss': 0.29440688212639293}
2023-01-04 06:04:07,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:07,835 INFO:     Epoch: 63
2023-01-04 06:04:09,390 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.418560779094696, 'Total loss': 0.418560779094696} | train loss {'Reaction outcome loss': 0.2961236323707658, 'Total loss': 0.2961236323707658}
2023-01-04 06:04:09,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:09,390 INFO:     Epoch: 64
2023-01-04 06:04:10,930 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3852539598941803, 'Total loss': 0.3852539598941803} | train loss {'Reaction outcome loss': 0.2965672845880044, 'Total loss': 0.2965672845880044}
2023-01-04 06:04:10,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:10,930 INFO:     Epoch: 65
2023-01-04 06:04:12,435 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3833423842986425, 'Total loss': 0.3833423842986425} | train loss {'Reaction outcome loss': 0.2939694774271817, 'Total loss': 0.2939694774271817}
2023-01-04 06:04:12,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:12,436 INFO:     Epoch: 66
2023-01-04 06:04:13,943 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4086846033732096, 'Total loss': 0.4086846033732096} | train loss {'Reaction outcome loss': 0.2922408283581593, 'Total loss': 0.2922408283581593}
2023-01-04 06:04:13,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:13,943 INFO:     Epoch: 67
2023-01-04 06:04:15,483 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39865714609622954, 'Total loss': 0.39865714609622954} | train loss {'Reaction outcome loss': 0.2889510774194534, 'Total loss': 0.2889510774194534}
2023-01-04 06:04:15,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:15,483 INFO:     Epoch: 68
2023-01-04 06:04:17,041 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4222496718168259, 'Total loss': 0.4222496718168259} | train loss {'Reaction outcome loss': 0.28791417329953606, 'Total loss': 0.28791417329953606}
2023-01-04 06:04:17,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:17,041 INFO:     Epoch: 69
2023-01-04 06:04:18,603 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3881311058998108, 'Total loss': 0.3881311058998108} | train loss {'Reaction outcome loss': 0.2835059716362795, 'Total loss': 0.2835059716362795}
2023-01-04 06:04:18,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:18,604 INFO:     Epoch: 70
2023-01-04 06:04:20,147 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3826866333683332, 'Total loss': 0.3826866333683332} | train loss {'Reaction outcome loss': 0.28613035463319053, 'Total loss': 0.28613035463319053}
2023-01-04 06:04:20,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:20,148 INFO:     Epoch: 71
2023-01-04 06:04:21,642 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40062383910020194, 'Total loss': 0.40062383910020194} | train loss {'Reaction outcome loss': 0.28160624074100127, 'Total loss': 0.28160624074100127}
2023-01-04 06:04:21,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:21,642 INFO:     Epoch: 72
2023-01-04 06:04:23,148 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39848706821600594, 'Total loss': 0.39848706821600594} | train loss {'Reaction outcome loss': 0.2831954473279059, 'Total loss': 0.2831954473279059}
2023-01-04 06:04:23,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:23,148 INFO:     Epoch: 73
2023-01-04 06:04:24,695 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4134694496790568, 'Total loss': 0.4134694496790568} | train loss {'Reaction outcome loss': 0.27945618174722714, 'Total loss': 0.27945618174722714}
2023-01-04 06:04:24,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:24,696 INFO:     Epoch: 74
2023-01-04 06:04:26,226 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4299292519688606, 'Total loss': 0.4299292519688606} | train loss {'Reaction outcome loss': 0.27986820993388273, 'Total loss': 0.27986820993388273}
2023-01-04 06:04:26,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:26,227 INFO:     Epoch: 75
2023-01-04 06:04:27,778 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3979094550013542, 'Total loss': 0.3979094550013542} | train loss {'Reaction outcome loss': 0.2811621076176527, 'Total loss': 0.2811621076176527}
2023-01-04 06:04:27,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:27,779 INFO:     Epoch: 76
2023-01-04 06:04:29,330 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3865246117115021, 'Total loss': 0.3865246117115021} | train loss {'Reaction outcome loss': 0.27990144961324565, 'Total loss': 0.27990144961324565}
2023-01-04 06:04:29,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:29,331 INFO:     Epoch: 77
2023-01-04 06:04:30,835 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4284731169541677, 'Total loss': 0.4284731169541677} | train loss {'Reaction outcome loss': 0.27819536477877205, 'Total loss': 0.27819536477877205}
2023-01-04 06:04:30,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:30,836 INFO:     Epoch: 78
2023-01-04 06:04:32,324 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4136669099330902, 'Total loss': 0.4136669099330902} | train loss {'Reaction outcome loss': 0.2764452021170366, 'Total loss': 0.2764452021170366}
2023-01-04 06:04:32,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:32,324 INFO:     Epoch: 79
2023-01-04 06:04:33,840 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3986215353012085, 'Total loss': 0.3986215353012085} | train loss {'Reaction outcome loss': 0.27552463856570397, 'Total loss': 0.27552463856570397}
2023-01-04 06:04:33,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:33,840 INFO:     Epoch: 80
2023-01-04 06:04:35,368 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3980973800023397, 'Total loss': 0.3980973800023397} | train loss {'Reaction outcome loss': 0.2761647322411027, 'Total loss': 0.2761647322411027}
2023-01-04 06:04:35,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:35,369 INFO:     Epoch: 81
2023-01-04 06:04:36,889 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40339412689208987, 'Total loss': 0.40339412689208987} | train loss {'Reaction outcome loss': 0.27830693253566857, 'Total loss': 0.27830693253566857}
2023-01-04 06:04:36,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:36,890 INFO:     Epoch: 82
2023-01-04 06:04:38,419 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3921829695502917, 'Total loss': 0.3921829695502917} | train loss {'Reaction outcome loss': 0.26921664777717025, 'Total loss': 0.26921664777717025}
2023-01-04 06:04:38,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:38,419 INFO:     Epoch: 83
2023-01-04 06:04:39,912 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37663000226020815, 'Total loss': 0.37663000226020815} | train loss {'Reaction outcome loss': 0.27033126636019933, 'Total loss': 0.27033126636019933}
2023-01-04 06:04:39,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:39,913 INFO:     Epoch: 84
2023-01-04 06:04:41,404 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40671929518381755, 'Total loss': 0.40671929518381755} | train loss {'Reaction outcome loss': 0.26608544102839, 'Total loss': 0.26608544102839}
2023-01-04 06:04:41,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:41,404 INFO:     Epoch: 85
2023-01-04 06:04:42,931 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.423367710908254, 'Total loss': 0.423367710908254} | train loss {'Reaction outcome loss': 0.2692005659051487, 'Total loss': 0.2692005659051487}
2023-01-04 06:04:42,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:42,931 INFO:     Epoch: 86
2023-01-04 06:04:44,454 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4094790865977605, 'Total loss': 0.4094790865977605} | train loss {'Reaction outcome loss': 0.26407891720863286, 'Total loss': 0.26407891720863286}
2023-01-04 06:04:44,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:44,454 INFO:     Epoch: 87
2023-01-04 06:04:45,977 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41957439879576364, 'Total loss': 0.41957439879576364} | train loss {'Reaction outcome loss': 0.26270992649767233, 'Total loss': 0.26270992649767233}
2023-01-04 06:04:45,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:45,977 INFO:     Epoch: 88
2023-01-04 06:04:47,503 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39417281150817873, 'Total loss': 0.39417281150817873} | train loss {'Reaction outcome loss': 0.263770659292646, 'Total loss': 0.263770659292646}
2023-01-04 06:04:47,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:47,503 INFO:     Epoch: 89
2023-01-04 06:04:49,013 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39088981052239735, 'Total loss': 0.39088981052239735} | train loss {'Reaction outcome loss': 0.26148341789951624, 'Total loss': 0.26148341789951624}
2023-01-04 06:04:49,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:49,013 INFO:     Epoch: 90
2023-01-04 06:04:50,221 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4180125157038371, 'Total loss': 0.4180125157038371} | train loss {'Reaction outcome loss': 0.2680946927503906, 'Total loss': 0.2680946927503906}
2023-01-04 06:04:50,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:50,221 INFO:     Epoch: 91
2023-01-04 06:04:51,229 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3944057027498881, 'Total loss': 0.3944057027498881} | train loss {'Reaction outcome loss': 0.25513490667477307, 'Total loss': 0.25513490667477307}
2023-01-04 06:04:51,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:51,230 INFO:     Epoch: 92
2023-01-04 06:04:52,234 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3753504325946172, 'Total loss': 0.3753504325946172} | train loss {'Reaction outcome loss': 0.26370952402093756, 'Total loss': 0.26370952402093756}
2023-01-04 06:04:52,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:52,234 INFO:     Epoch: 93
2023-01-04 06:04:53,239 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4171085059642792, 'Total loss': 0.4171085059642792} | train loss {'Reaction outcome loss': 0.25923257931462074, 'Total loss': 0.25923257931462074}
2023-01-04 06:04:53,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:53,240 INFO:     Epoch: 94
2023-01-04 06:04:54,294 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42305823663870495, 'Total loss': 0.42305823663870495} | train loss {'Reaction outcome loss': 0.2588068202440369, 'Total loss': 0.2588068202440369}
2023-01-04 06:04:54,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:54,296 INFO:     Epoch: 95
2023-01-04 06:04:55,804 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4274701575438182, 'Total loss': 0.4274701575438182} | train loss {'Reaction outcome loss': 0.2586486892726588, 'Total loss': 0.2586486892726588}
2023-01-04 06:04:55,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:55,804 INFO:     Epoch: 96
2023-01-04 06:04:57,333 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3924272815386454, 'Total loss': 0.3924272815386454} | train loss {'Reaction outcome loss': 0.2614976761663312, 'Total loss': 0.2614976761663312}
2023-01-04 06:04:57,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:57,333 INFO:     Epoch: 97
2023-01-04 06:04:58,836 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4011659393707911, 'Total loss': 0.4011659393707911} | train loss {'Reaction outcome loss': 0.25844174672976633, 'Total loss': 0.25844174672976633}
2023-01-04 06:04:58,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:04:58,837 INFO:     Epoch: 98
2023-01-04 06:05:00,388 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4060905863841375, 'Total loss': 0.4060905863841375} | train loss {'Reaction outcome loss': 0.2517650874255988, 'Total loss': 0.2517650874255988}
2023-01-04 06:05:00,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:00,389 INFO:     Epoch: 99
2023-01-04 06:05:01,907 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42507899900277457, 'Total loss': 0.42507899900277457} | train loss {'Reaction outcome loss': 0.25759090318231126, 'Total loss': 0.25759090318231126}
2023-01-04 06:05:01,907 INFO:     Best model found after epoch 53 of 100.
2023-01-04 06:05:01,907 INFO:   Done with stage: TRAINING
2023-01-04 06:05:01,907 INFO:   Starting stage: EVALUATION
2023-01-04 06:05:02,051 INFO:   Done with stage: EVALUATION
2023-01-04 06:05:02,051 INFO:   Leaving out SEQ value Fold_1
2023-01-04 06:05:02,064 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 06:05:02,064 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:05:02,704 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:05:02,704 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:05:02,773 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:05:02,773 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:05:02,774 INFO:     No hyperparam tuning for this model
2023-01-04 06:05:02,774 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:05:02,774 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:05:02,774 INFO:     None feature selector for col prot
2023-01-04 06:05:02,775 INFO:     None feature selector for col prot
2023-01-04 06:05:02,775 INFO:     None feature selector for col prot
2023-01-04 06:05:02,775 INFO:     None feature selector for col chem
2023-01-04 06:05:02,775 INFO:     None feature selector for col chem
2023-01-04 06:05:02,775 INFO:     None feature selector for col chem
2023-01-04 06:05:02,775 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:05:02,775 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:05:02,776 INFO:     Number of params in model 70111
2023-01-04 06:05:02,779 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:05:02,780 INFO:   Starting stage: TRAINING
2023-01-04 06:05:02,821 INFO:     Val loss before train {'Reaction outcome loss': 1.0890403588612874, 'Total loss': 1.0890403588612874}
2023-01-04 06:05:02,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:02,821 INFO:     Epoch: 0
2023-01-04 06:05:04,353 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7878188490867615, 'Total loss': 0.7878188490867615} | train loss {'Reaction outcome loss': 0.8451516847463622, 'Total loss': 0.8451516847463622}
2023-01-04 06:05:04,353 INFO:     Found new best model at epoch 0
2023-01-04 06:05:04,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:04,354 INFO:     Epoch: 1
2023-01-04 06:05:05,954 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6383504271507263, 'Total loss': 0.6383504271507263} | train loss {'Reaction outcome loss': 0.6826672973229374, 'Total loss': 0.6826672973229374}
2023-01-04 06:05:05,954 INFO:     Found new best model at epoch 1
2023-01-04 06:05:05,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:05,955 INFO:     Epoch: 2
2023-01-04 06:05:07,547 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5694817841053009, 'Total loss': 0.5694817841053009} | train loss {'Reaction outcome loss': 0.5814530708755584, 'Total loss': 0.5814530708755584}
2023-01-04 06:05:07,547 INFO:     Found new best model at epoch 2
2023-01-04 06:05:07,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:07,548 INFO:     Epoch: 3
2023-01-04 06:05:09,136 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5214213232199351, 'Total loss': 0.5214213232199351} | train loss {'Reaction outcome loss': 0.5425174808048684, 'Total loss': 0.5425174808048684}
2023-01-04 06:05:09,136 INFO:     Found new best model at epoch 3
2023-01-04 06:05:09,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:09,137 INFO:     Epoch: 4
2023-01-04 06:05:10,700 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5167559862136841, 'Total loss': 0.5167559862136841} | train loss {'Reaction outcome loss': 0.5321434818316197, 'Total loss': 0.5321434818316197}
2023-01-04 06:05:10,700 INFO:     Found new best model at epoch 4
2023-01-04 06:05:10,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:10,701 INFO:     Epoch: 5
2023-01-04 06:05:12,244 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49808934728304544, 'Total loss': 0.49808934728304544} | train loss {'Reaction outcome loss': 0.5141126191162545, 'Total loss': 0.5141126191162545}
2023-01-04 06:05:12,244 INFO:     Found new best model at epoch 5
2023-01-04 06:05:12,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:12,245 INFO:     Epoch: 6
2023-01-04 06:05:13,785 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4937481900056203, 'Total loss': 0.4937481900056203} | train loss {'Reaction outcome loss': 0.50036861066558, 'Total loss': 0.50036861066558}
2023-01-04 06:05:13,786 INFO:     Found new best model at epoch 6
2023-01-04 06:05:13,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:13,787 INFO:     Epoch: 7
2023-01-04 06:05:15,371 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5133368511994679, 'Total loss': 0.5133368511994679} | train loss {'Reaction outcome loss': 0.4806673159380781, 'Total loss': 0.4806673159380781}
2023-01-04 06:05:15,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:15,371 INFO:     Epoch: 8
2023-01-04 06:05:16,943 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4824303468068441, 'Total loss': 0.4824303468068441} | train loss {'Reaction outcome loss': 0.47521003918803256, 'Total loss': 0.47521003918803256}
2023-01-04 06:05:16,944 INFO:     Found new best model at epoch 8
2023-01-04 06:05:16,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:16,944 INFO:     Epoch: 9
2023-01-04 06:05:18,507 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5261716465155284, 'Total loss': 0.5261716465155284} | train loss {'Reaction outcome loss': 0.4708077972501759, 'Total loss': 0.4708077972501759}
2023-01-04 06:05:18,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:18,507 INFO:     Epoch: 10
2023-01-04 06:05:20,067 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5136272847652436, 'Total loss': 0.5136272847652436} | train loss {'Reaction outcome loss': 0.4646831542469453, 'Total loss': 0.4646831542469453}
2023-01-04 06:05:20,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:20,067 INFO:     Epoch: 11
2023-01-04 06:05:21,575 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4784495453039805, 'Total loss': 0.4784495453039805} | train loss {'Reaction outcome loss': 0.4675704311653596, 'Total loss': 0.4675704311653596}
2023-01-04 06:05:21,575 INFO:     Found new best model at epoch 11
2023-01-04 06:05:21,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:21,576 INFO:     Epoch: 12
2023-01-04 06:05:23,124 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4922641118367513, 'Total loss': 0.4922641118367513} | train loss {'Reaction outcome loss': 0.4519849616318833, 'Total loss': 0.4519849616318833}
2023-01-04 06:05:23,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:23,124 INFO:     Epoch: 13
2023-01-04 06:05:24,675 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4603233595689138, 'Total loss': 0.4603233595689138} | train loss {'Reaction outcome loss': 0.44505817828821426, 'Total loss': 0.44505817828821426}
2023-01-04 06:05:24,676 INFO:     Found new best model at epoch 13
2023-01-04 06:05:24,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:24,677 INFO:     Epoch: 14
2023-01-04 06:05:26,232 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49249075452486674, 'Total loss': 0.49249075452486674} | train loss {'Reaction outcome loss': 0.438220290239374, 'Total loss': 0.438220290239374}
2023-01-04 06:05:26,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:26,233 INFO:     Epoch: 15
2023-01-04 06:05:27,788 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4672218422094981, 'Total loss': 0.4672218422094981} | train loss {'Reaction outcome loss': 0.43703507769859623, 'Total loss': 0.43703507769859623}
2023-01-04 06:05:27,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:27,788 INFO:     Epoch: 16
2023-01-04 06:05:29,353 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4619579871495565, 'Total loss': 0.4619579871495565} | train loss {'Reaction outcome loss': 0.42955746289437124, 'Total loss': 0.42955746289437124}
2023-01-04 06:05:29,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:29,354 INFO:     Epoch: 17
2023-01-04 06:05:30,858 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4693266789118449, 'Total loss': 0.4693266789118449} | train loss {'Reaction outcome loss': 0.4255153962910391, 'Total loss': 0.4255153962910391}
2023-01-04 06:05:30,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:30,859 INFO:     Epoch: 18
2023-01-04 06:05:32,407 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4394008715947469, 'Total loss': 0.4394008715947469} | train loss {'Reaction outcome loss': 0.4236223831955441, 'Total loss': 0.4236223831955441}
2023-01-04 06:05:32,407 INFO:     Found new best model at epoch 18
2023-01-04 06:05:32,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:32,408 INFO:     Epoch: 19
2023-01-04 06:05:33,961 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45931391219298046, 'Total loss': 0.45931391219298046} | train loss {'Reaction outcome loss': 0.41709496037008753, 'Total loss': 0.41709496037008753}
2023-01-04 06:05:33,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:33,961 INFO:     Epoch: 20
2023-01-04 06:05:35,509 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4741994023323059, 'Total loss': 0.4741994023323059} | train loss {'Reaction outcome loss': 0.4128290852835483, 'Total loss': 0.4128290852835483}
2023-01-04 06:05:35,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:35,509 INFO:     Epoch: 21
2023-01-04 06:05:37,064 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44402589499950407, 'Total loss': 0.44402589499950407} | train loss {'Reaction outcome loss': 0.4085501468591932, 'Total loss': 0.4085501468591932}
2023-01-04 06:05:37,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:37,064 INFO:     Epoch: 22
2023-01-04 06:05:38,603 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42845884362856546, 'Total loss': 0.42845884362856546} | train loss {'Reaction outcome loss': 0.4153469775354598, 'Total loss': 0.4153469775354598}
2023-01-04 06:05:38,603 INFO:     Found new best model at epoch 22
2023-01-04 06:05:38,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:38,603 INFO:     Epoch: 23
2023-01-04 06:05:40,101 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48248151938120526, 'Total loss': 0.48248151938120526} | train loss {'Reaction outcome loss': 0.3977724085178098, 'Total loss': 0.3977724085178098}
2023-01-04 06:05:40,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:40,102 INFO:     Epoch: 24
2023-01-04 06:05:41,665 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4896245539188385, 'Total loss': 0.4896245539188385} | train loss {'Reaction outcome loss': 0.4149819162498782, 'Total loss': 0.4149819162498782}
2023-01-04 06:05:41,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:41,665 INFO:     Epoch: 25
2023-01-04 06:05:43,235 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45594693620999655, 'Total loss': 0.45594693620999655} | train loss {'Reaction outcome loss': 0.43854832055344095, 'Total loss': 0.43854832055344095}
2023-01-04 06:05:43,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:43,236 INFO:     Epoch: 26
2023-01-04 06:05:44,798 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45151813626289367, 'Total loss': 0.45151813626289367} | train loss {'Reaction outcome loss': 0.40948080491596, 'Total loss': 0.40948080491596}
2023-01-04 06:05:44,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:44,799 INFO:     Epoch: 27
2023-01-04 06:05:46,355 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45684581995010376, 'Total loss': 0.45684581995010376} | train loss {'Reaction outcome loss': 0.3906426254012015, 'Total loss': 0.3906426254012015}
2023-01-04 06:05:46,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:46,355 INFO:     Epoch: 28
2023-01-04 06:05:47,913 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4407694359620412, 'Total loss': 0.4407694359620412} | train loss {'Reaction outcome loss': 0.39725992642343044, 'Total loss': 0.39725992642343044}
2023-01-04 06:05:47,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:47,913 INFO:     Epoch: 29
2023-01-04 06:05:49,412 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44189220865567524, 'Total loss': 0.44189220865567524} | train loss {'Reaction outcome loss': 0.39253905346698087, 'Total loss': 0.39253905346698087}
2023-01-04 06:05:49,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:49,412 INFO:     Epoch: 30
2023-01-04 06:05:51,026 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4227030644814173, 'Total loss': 0.4227030644814173} | train loss {'Reaction outcome loss': 0.3726424319885563, 'Total loss': 0.3726424319885563}
2023-01-04 06:05:51,026 INFO:     Found new best model at epoch 30
2023-01-04 06:05:51,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:51,027 INFO:     Epoch: 31
2023-01-04 06:05:52,637 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4434170027573903, 'Total loss': 0.4434170027573903} | train loss {'Reaction outcome loss': 0.3717783592334287, 'Total loss': 0.3717783592334287}
2023-01-04 06:05:52,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:52,637 INFO:     Epoch: 32
2023-01-04 06:05:54,230 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4310034602880478, 'Total loss': 0.4310034602880478} | train loss {'Reaction outcome loss': 0.36712744267846364, 'Total loss': 0.36712744267846364}
2023-01-04 06:05:54,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:54,231 INFO:     Epoch: 33
2023-01-04 06:05:55,849 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44891157746315, 'Total loss': 0.44891157746315} | train loss {'Reaction outcome loss': 0.3692641960038547, 'Total loss': 0.3692641960038547}
2023-01-04 06:05:55,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:55,850 INFO:     Epoch: 34
2023-01-04 06:05:57,418 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40568719108899437, 'Total loss': 0.40568719108899437} | train loss {'Reaction outcome loss': 0.35994732458198414, 'Total loss': 0.35994732458198414}
2023-01-04 06:05:57,418 INFO:     Found new best model at epoch 34
2023-01-04 06:05:57,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:57,419 INFO:     Epoch: 35
2023-01-04 06:05:58,984 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43410841226577757, 'Total loss': 0.43410841226577757} | train loss {'Reaction outcome loss': 0.3556351140478923, 'Total loss': 0.3556351140478923}
2023-01-04 06:05:58,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:05:58,984 INFO:     Epoch: 36
2023-01-04 06:06:00,567 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42576518257459006, 'Total loss': 0.42576518257459006} | train loss {'Reaction outcome loss': 0.3544296443030454, 'Total loss': 0.3544296443030454}
2023-01-04 06:06:00,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:00,567 INFO:     Epoch: 37
2023-01-04 06:06:02,136 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4376499275366465, 'Total loss': 0.4376499275366465} | train loss {'Reaction outcome loss': 0.35522168056796427, 'Total loss': 0.35522168056796427}
2023-01-04 06:06:02,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:02,137 INFO:     Epoch: 38
2023-01-04 06:06:03,703 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44021662573019665, 'Total loss': 0.44021662573019665} | train loss {'Reaction outcome loss': 0.36958152058777277, 'Total loss': 0.36958152058777277}
2023-01-04 06:06:03,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:03,703 INFO:     Epoch: 39
2023-01-04 06:06:05,260 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4472138206164042, 'Total loss': 0.4472138206164042} | train loss {'Reaction outcome loss': 0.3489824766537809, 'Total loss': 0.3489824766537809}
2023-01-04 06:06:05,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:05,260 INFO:     Epoch: 40
2023-01-04 06:06:06,797 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4811383128166199, 'Total loss': 0.4811383128166199} | train loss {'Reaction outcome loss': 0.34623820450750814, 'Total loss': 0.34623820450750814}
2023-01-04 06:06:06,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:06,797 INFO:     Epoch: 41
2023-01-04 06:06:08,351 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40683630406856536, 'Total loss': 0.40683630406856536} | train loss {'Reaction outcome loss': 0.3398221531930123, 'Total loss': 0.3398221531930123}
2023-01-04 06:06:08,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:08,351 INFO:     Epoch: 42
2023-01-04 06:06:09,940 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4209603408972422, 'Total loss': 0.4209603408972422} | train loss {'Reaction outcome loss': 0.3350447669640997, 'Total loss': 0.3350447669640997}
2023-01-04 06:06:09,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:09,940 INFO:     Epoch: 43
2023-01-04 06:06:11,534 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40911715229352313, 'Total loss': 0.40911715229352313} | train loss {'Reaction outcome loss': 0.3364503022432104, 'Total loss': 0.3364503022432104}
2023-01-04 06:06:11,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:11,535 INFO:     Epoch: 44
2023-01-04 06:06:13,136 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45547607938448587, 'Total loss': 0.45547607938448587} | train loss {'Reaction outcome loss': 0.33440908990746393, 'Total loss': 0.33440908990746393}
2023-01-04 06:06:13,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:13,136 INFO:     Epoch: 45
2023-01-04 06:06:14,737 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4082076887289683, 'Total loss': 0.4082076887289683} | train loss {'Reaction outcome loss': 0.3334486529069102, 'Total loss': 0.3334486529069102}
2023-01-04 06:06:14,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:14,737 INFO:     Epoch: 46
2023-01-04 06:06:16,248 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4314310073852539, 'Total loss': 0.4314310073852539} | train loss {'Reaction outcome loss': 0.33866383185913024, 'Total loss': 0.33866383185913024}
2023-01-04 06:06:16,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:16,248 INFO:     Epoch: 47
2023-01-04 06:06:17,817 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4411981721719106, 'Total loss': 0.4411981721719106} | train loss {'Reaction outcome loss': 0.32314177353755047, 'Total loss': 0.32314177353755047}
2023-01-04 06:06:17,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:17,817 INFO:     Epoch: 48
2023-01-04 06:06:19,397 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42770950496196747, 'Total loss': 0.42770950496196747} | train loss {'Reaction outcome loss': 0.3330203357382097, 'Total loss': 0.3330203357382097}
2023-01-04 06:06:19,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:19,397 INFO:     Epoch: 49
2023-01-04 06:06:20,966 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3946514179309209, 'Total loss': 0.3946514179309209} | train loss {'Reaction outcome loss': 0.34596590209158434, 'Total loss': 0.34596590209158434}
2023-01-04 06:06:20,966 INFO:     Found new best model at epoch 49
2023-01-04 06:06:20,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:20,967 INFO:     Epoch: 50
2023-01-04 06:06:22,532 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4234691361586253, 'Total loss': 0.4234691361586253} | train loss {'Reaction outcome loss': 0.32192258099498955, 'Total loss': 0.32192258099498955}
2023-01-04 06:06:22,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:22,532 INFO:     Epoch: 51
2023-01-04 06:06:24,102 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4049735168615977, 'Total loss': 0.4049735168615977} | train loss {'Reaction outcome loss': 0.32022534558585164, 'Total loss': 0.32022534558585164}
2023-01-04 06:06:24,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:24,102 INFO:     Epoch: 52
2023-01-04 06:06:25,600 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4188739001750946, 'Total loss': 0.4188739001750946} | train loss {'Reaction outcome loss': 0.3153529855679127, 'Total loss': 0.3153529855679127}
2023-01-04 06:06:25,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:25,600 INFO:     Epoch: 53
2023-01-04 06:06:27,157 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40118843416372935, 'Total loss': 0.40118843416372935} | train loss {'Reaction outcome loss': 0.3077294392970161, 'Total loss': 0.3077294392970161}
2023-01-04 06:06:27,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:27,158 INFO:     Epoch: 54
2023-01-04 06:06:28,723 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42717829247315725, 'Total loss': 0.42717829247315725} | train loss {'Reaction outcome loss': 0.30636186957016814, 'Total loss': 0.30636186957016814}
2023-01-04 06:06:28,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:28,724 INFO:     Epoch: 55
2023-01-04 06:06:30,288 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4225208173195521, 'Total loss': 0.4225208173195521} | train loss {'Reaction outcome loss': 0.30790877326702076, 'Total loss': 0.30790877326702076}
2023-01-04 06:06:30,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:30,288 INFO:     Epoch: 56
2023-01-04 06:06:31,868 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37457898259162903, 'Total loss': 0.37457898259162903} | train loss {'Reaction outcome loss': 0.3129707050064336, 'Total loss': 0.3129707050064336}
2023-01-04 06:06:31,868 INFO:     Found new best model at epoch 56
2023-01-04 06:06:31,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:31,869 INFO:     Epoch: 57
2023-01-04 06:06:33,446 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46109399100144705, 'Total loss': 0.46109399100144705} | train loss {'Reaction outcome loss': 0.3131908165236962, 'Total loss': 0.3131908165236962}
2023-01-04 06:06:33,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:33,446 INFO:     Epoch: 58
2023-01-04 06:06:34,943 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43079491357008615, 'Total loss': 0.43079491357008615} | train loss {'Reaction outcome loss': 0.31011893046156, 'Total loss': 0.31011893046156}
2023-01-04 06:06:34,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:34,943 INFO:     Epoch: 59
2023-01-04 06:06:36,497 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40832293530305225, 'Total loss': 0.40832293530305225} | train loss {'Reaction outcome loss': 0.30761462976321735, 'Total loss': 0.30761462976321735}
2023-01-04 06:06:36,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:36,497 INFO:     Epoch: 60
2023-01-04 06:06:38,058 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4282906154791514, 'Total loss': 0.4282906154791514} | train loss {'Reaction outcome loss': 0.307900731430087, 'Total loss': 0.307900731430087}
2023-01-04 06:06:38,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:38,058 INFO:     Epoch: 61
2023-01-04 06:06:39,620 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4157762328783671, 'Total loss': 0.4157762328783671} | train loss {'Reaction outcome loss': 0.301153653240982, 'Total loss': 0.301153653240982}
2023-01-04 06:06:39,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:39,620 INFO:     Epoch: 62
2023-01-04 06:06:41,185 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43506423433621727, 'Total loss': 0.43506423433621727} | train loss {'Reaction outcome loss': 0.29885289160048834, 'Total loss': 0.29885289160048834}
2023-01-04 06:06:41,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:41,186 INFO:     Epoch: 63
2023-01-04 06:06:42,729 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39436195890108744, 'Total loss': 0.39436195890108744} | train loss {'Reaction outcome loss': 0.3019238802173303, 'Total loss': 0.3019238802173303}
2023-01-04 06:06:42,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:42,729 INFO:     Epoch: 64
2023-01-04 06:06:44,267 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4075410783290863, 'Total loss': 0.4075410783290863} | train loss {'Reaction outcome loss': 0.31270191508034867, 'Total loss': 0.31270191508034867}
2023-01-04 06:06:44,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:44,267 INFO:     Epoch: 65
2023-01-04 06:06:45,828 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4756553788979848, 'Total loss': 0.4756553788979848} | train loss {'Reaction outcome loss': 0.3354784683516577, 'Total loss': 0.3354784683516577}
2023-01-04 06:06:45,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:45,828 INFO:     Epoch: 66
2023-01-04 06:06:47,396 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43824563721815746, 'Total loss': 0.43824563721815746} | train loss {'Reaction outcome loss': 0.3080660018013736, 'Total loss': 0.3080660018013736}
2023-01-04 06:06:47,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:47,397 INFO:     Epoch: 67
2023-01-04 06:06:48,968 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4396221141020457, 'Total loss': 0.4396221141020457} | train loss {'Reaction outcome loss': 0.29787824999969587, 'Total loss': 0.29787824999969587}
2023-01-04 06:06:48,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:48,968 INFO:     Epoch: 68
2023-01-04 06:06:50,538 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4351049453020096, 'Total loss': 0.4351049453020096} | train loss {'Reaction outcome loss': 0.2920569319453468, 'Total loss': 0.2920569319453468}
2023-01-04 06:06:50,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:50,538 INFO:     Epoch: 69
2023-01-04 06:06:52,067 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46418965657552086, 'Total loss': 0.46418965657552086} | train loss {'Reaction outcome loss': 0.306896488411703, 'Total loss': 0.306896488411703}
2023-01-04 06:06:52,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:52,068 INFO:     Epoch: 70
2023-01-04 06:06:53,620 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4156025936206182, 'Total loss': 0.4156025936206182} | train loss {'Reaction outcome loss': 0.33932184591406217, 'Total loss': 0.33932184591406217}
2023-01-04 06:06:53,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:53,621 INFO:     Epoch: 71
2023-01-04 06:06:55,207 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4151178459326426, 'Total loss': 0.4151178459326426} | train loss {'Reaction outcome loss': 0.2861035632296884, 'Total loss': 0.2861035632296884}
2023-01-04 06:06:55,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:55,208 INFO:     Epoch: 72
2023-01-04 06:06:56,769 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4022345552841822, 'Total loss': 0.4022345552841822} | train loss {'Reaction outcome loss': 0.28459599664590013, 'Total loss': 0.28459599664590013}
2023-01-04 06:06:56,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:56,769 INFO:     Epoch: 73
2023-01-04 06:06:58,341 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4101132387916247, 'Total loss': 0.4101132387916247} | train loss {'Reaction outcome loss': 0.29708413449048565, 'Total loss': 0.29708413449048565}
2023-01-04 06:06:58,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:58,341 INFO:     Epoch: 74
2023-01-04 06:06:59,937 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4185256212949753, 'Total loss': 0.4185256212949753} | train loss {'Reaction outcome loss': 0.2933515543523042, 'Total loss': 0.2933515543523042}
2023-01-04 06:06:59,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:06:59,937 INFO:     Epoch: 75
2023-01-04 06:07:01,454 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4137935628493627, 'Total loss': 0.4137935628493627} | train loss {'Reaction outcome loss': 0.29197540003266453, 'Total loss': 0.29197540003266453}
2023-01-04 06:07:01,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:01,454 INFO:     Epoch: 76
2023-01-04 06:07:03,048 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4050922085841497, 'Total loss': 0.4050922085841497} | train loss {'Reaction outcome loss': 0.28201445221518795, 'Total loss': 0.28201445221518795}
2023-01-04 06:07:03,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:03,049 INFO:     Epoch: 77
2023-01-04 06:07:04,615 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4313046395778656, 'Total loss': 0.4313046395778656} | train loss {'Reaction outcome loss': 0.2779329509568819, 'Total loss': 0.2779329509568819}
2023-01-04 06:07:04,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:04,616 INFO:     Epoch: 78
2023-01-04 06:07:06,179 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3998994280894597, 'Total loss': 0.3998994280894597} | train loss {'Reaction outcome loss': 0.27807473772596836, 'Total loss': 0.27807473772596836}
2023-01-04 06:07:06,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:06,179 INFO:     Epoch: 79
2023-01-04 06:07:07,768 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41779781381289166, 'Total loss': 0.41779781381289166} | train loss {'Reaction outcome loss': 0.2792281543480003, 'Total loss': 0.2792281543480003}
2023-01-04 06:07:07,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:07,768 INFO:     Epoch: 80
2023-01-04 06:07:09,337 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4284266511599223, 'Total loss': 0.4284266511599223} | train loss {'Reaction outcome loss': 0.28128349050488055, 'Total loss': 0.28128349050488055}
2023-01-04 06:07:09,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:09,338 INFO:     Epoch: 81
2023-01-04 06:07:10,853 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39915625353654227, 'Total loss': 0.39915625353654227} | train loss {'Reaction outcome loss': 0.27745916363715695, 'Total loss': 0.27745916363715695}
2023-01-04 06:07:10,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:10,854 INFO:     Epoch: 82
2023-01-04 06:07:12,431 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40156547526518505, 'Total loss': 0.40156547526518505} | train loss {'Reaction outcome loss': 0.27652970609673555, 'Total loss': 0.27652970609673555}
2023-01-04 06:07:12,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:12,432 INFO:     Epoch: 83
2023-01-04 06:07:14,005 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41767916480700173, 'Total loss': 0.41767916480700173} | train loss {'Reaction outcome loss': 0.2722017422547915, 'Total loss': 0.2722017422547915}
2023-01-04 06:07:14,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:14,005 INFO:     Epoch: 84
2023-01-04 06:07:15,575 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40770242164532344, 'Total loss': 0.40770242164532344} | train loss {'Reaction outcome loss': 0.2700945818628036, 'Total loss': 0.2700945818628036}
2023-01-04 06:07:15,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:15,575 INFO:     Epoch: 85
2023-01-04 06:07:17,128 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4066694756348928, 'Total loss': 0.4066694756348928} | train loss {'Reaction outcome loss': 0.2687139484923387, 'Total loss': 0.2687139484923387}
2023-01-04 06:07:17,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:17,128 INFO:     Epoch: 86
2023-01-04 06:07:18,666 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42501526574293774, 'Total loss': 0.42501526574293774} | train loss {'Reaction outcome loss': 0.27056137226737925, 'Total loss': 0.27056137226737925}
2023-01-04 06:07:18,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:18,666 INFO:     Epoch: 87
2023-01-04 06:07:20,149 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4239837408065796, 'Total loss': 0.4239837408065796} | train loss {'Reaction outcome loss': 0.26967030707411416, 'Total loss': 0.26967030707411416}
2023-01-04 06:07:20,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:20,149 INFO:     Epoch: 88
2023-01-04 06:07:21,699 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43072346250216165, 'Total loss': 0.43072346250216165} | train loss {'Reaction outcome loss': 0.2676715737991575, 'Total loss': 0.2676715737991575}
2023-01-04 06:07:21,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:21,700 INFO:     Epoch: 89
2023-01-04 06:07:23,266 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40345943967501324, 'Total loss': 0.40345943967501324} | train loss {'Reaction outcome loss': 0.27709734912259854, 'Total loss': 0.27709734912259854}
2023-01-04 06:07:23,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:23,267 INFO:     Epoch: 90
2023-01-04 06:07:24,828 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4215000609556834, 'Total loss': 0.4215000609556834} | train loss {'Reaction outcome loss': 0.27417803801717644, 'Total loss': 0.27417803801717644}
2023-01-04 06:07:24,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:24,828 INFO:     Epoch: 91
2023-01-04 06:07:26,388 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4314158360163371, 'Total loss': 0.4314158360163371} | train loss {'Reaction outcome loss': 0.27239366921771696, 'Total loss': 0.27239366921771696}
2023-01-04 06:07:26,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:26,388 INFO:     Epoch: 92
2023-01-04 06:07:27,935 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4152676860491435, 'Total loss': 0.4152676860491435} | train loss {'Reaction outcome loss': 0.27413763101820066, 'Total loss': 0.27413763101820066}
2023-01-04 06:07:27,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:27,935 INFO:     Epoch: 93
2023-01-04 06:07:29,446 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42074501017729443, 'Total loss': 0.42074501017729443} | train loss {'Reaction outcome loss': 0.26368324970151635, 'Total loss': 0.26368324970151635}
2023-01-04 06:07:29,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:29,447 INFO:     Epoch: 94
2023-01-04 06:07:30,987 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4419881840546926, 'Total loss': 0.4419881840546926} | train loss {'Reaction outcome loss': 0.2792619356334384, 'Total loss': 0.2792619356334384}
2023-01-04 06:07:30,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:30,988 INFO:     Epoch: 95
2023-01-04 06:07:32,549 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42362837692101796, 'Total loss': 0.42362837692101796} | train loss {'Reaction outcome loss': 0.2595041197795502, 'Total loss': 0.2595041197795502}
2023-01-04 06:07:32,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:32,549 INFO:     Epoch: 96
2023-01-04 06:07:34,094 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3988583703835805, 'Total loss': 0.3988583703835805} | train loss {'Reaction outcome loss': 0.2640909047500379, 'Total loss': 0.2640909047500379}
2023-01-04 06:07:34,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:34,095 INFO:     Epoch: 97
2023-01-04 06:07:35,641 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4201035956541697, 'Total loss': 0.4201035956541697} | train loss {'Reaction outcome loss': 0.30085786685779475, 'Total loss': 0.30085786685779475}
2023-01-04 06:07:35,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:35,642 INFO:     Epoch: 98
2023-01-04 06:07:37,166 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41266213754812875, 'Total loss': 0.41266213754812875} | train loss {'Reaction outcome loss': 0.28168489733104873, 'Total loss': 0.28168489733104873}
2023-01-04 06:07:37,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:37,166 INFO:     Epoch: 99
2023-01-04 06:07:38,691 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46410312652587893, 'Total loss': 0.46410312652587893} | train loss {'Reaction outcome loss': 0.27020666597114096, 'Total loss': 0.27020666597114096}
2023-01-04 06:07:38,692 INFO:     Best model found after epoch 57 of 100.
2023-01-04 06:07:38,692 INFO:   Done with stage: TRAINING
2023-01-04 06:07:38,692 INFO:   Starting stage: EVALUATION
2023-01-04 06:07:38,820 INFO:   Done with stage: EVALUATION
2023-01-04 06:07:38,820 INFO:   Leaving out SEQ value Fold_2
2023-01-04 06:07:38,833 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 06:07:38,833 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:07:39,474 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:07:39,474 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:07:39,542 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:07:39,542 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:07:39,542 INFO:     No hyperparam tuning for this model
2023-01-04 06:07:39,542 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:07:39,543 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:07:39,543 INFO:     None feature selector for col prot
2023-01-04 06:07:39,543 INFO:     None feature selector for col prot
2023-01-04 06:07:39,544 INFO:     None feature selector for col prot
2023-01-04 06:07:39,544 INFO:     None feature selector for col chem
2023-01-04 06:07:39,544 INFO:     None feature selector for col chem
2023-01-04 06:07:39,544 INFO:     None feature selector for col chem
2023-01-04 06:07:39,544 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:07:39,545 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:07:39,546 INFO:     Number of params in model 70111
2023-01-04 06:07:39,549 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:07:39,549 INFO:   Starting stage: TRAINING
2023-01-04 06:07:39,592 INFO:     Val loss before train {'Reaction outcome loss': 1.1049402077992758, 'Total loss': 1.1049402077992758}
2023-01-04 06:07:39,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:39,592 INFO:     Epoch: 0
2023-01-04 06:07:41,143 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9119403084119161, 'Total loss': 0.9119403084119161} | train loss {'Reaction outcome loss': 0.8757291365496433, 'Total loss': 0.8757291365496433}
2023-01-04 06:07:41,143 INFO:     Found new best model at epoch 0
2023-01-04 06:07:41,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:41,144 INFO:     Epoch: 1
2023-01-04 06:07:42,694 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7783120334148407, 'Total loss': 0.7783120334148407} | train loss {'Reaction outcome loss': 0.7122181005721545, 'Total loss': 0.7122181005721545}
2023-01-04 06:07:42,694 INFO:     Found new best model at epoch 1
2023-01-04 06:07:42,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:42,695 INFO:     Epoch: 2
2023-01-04 06:07:44,258 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6436877111593883, 'Total loss': 0.6436877111593883} | train loss {'Reaction outcome loss': 0.5949495394517036, 'Total loss': 0.5949495394517036}
2023-01-04 06:07:44,258 INFO:     Found new best model at epoch 2
2023-01-04 06:07:44,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:44,259 INFO:     Epoch: 3
2023-01-04 06:07:45,773 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6078929563363393, 'Total loss': 0.6078929563363393} | train loss {'Reaction outcome loss': 0.5463230192226215, 'Total loss': 0.5463230192226215}
2023-01-04 06:07:45,773 INFO:     Found new best model at epoch 3
2023-01-04 06:07:45,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:45,774 INFO:     Epoch: 4
2023-01-04 06:07:47,287 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5989780644575755, 'Total loss': 0.5989780644575755} | train loss {'Reaction outcome loss': 0.5208443365719196, 'Total loss': 0.5208443365719196}
2023-01-04 06:07:47,287 INFO:     Found new best model at epoch 4
2023-01-04 06:07:47,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:47,287 INFO:     Epoch: 5
2023-01-04 06:07:48,841 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5579424858093261, 'Total loss': 0.5579424858093261} | train loss {'Reaction outcome loss': 0.5051246811873722, 'Total loss': 0.5051246811873722}
2023-01-04 06:07:48,841 INFO:     Found new best model at epoch 5
2023-01-04 06:07:48,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:48,842 INFO:     Epoch: 6
2023-01-04 06:07:50,396 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5557034512360891, 'Total loss': 0.5557034512360891} | train loss {'Reaction outcome loss': 0.4938980887514831, 'Total loss': 0.4938980887514831}
2023-01-04 06:07:50,396 INFO:     Found new best model at epoch 6
2023-01-04 06:07:50,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:50,397 INFO:     Epoch: 7
2023-01-04 06:07:51,949 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5935363670190176, 'Total loss': 0.5935363670190176} | train loss {'Reaction outcome loss': 0.48029282379106886, 'Total loss': 0.48029282379106886}
2023-01-04 06:07:51,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:51,950 INFO:     Epoch: 8
2023-01-04 06:07:53,496 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5438323636849721, 'Total loss': 0.5438323636849721} | train loss {'Reaction outcome loss': 0.4795126795877505, 'Total loss': 0.4795126795877505}
2023-01-04 06:07:53,496 INFO:     Found new best model at epoch 8
2023-01-04 06:07:53,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:53,497 INFO:     Epoch: 9
2023-01-04 06:07:55,003 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5386712352434794, 'Total loss': 0.5386712352434794} | train loss {'Reaction outcome loss': 0.4691685596956824, 'Total loss': 0.4691685596956824}
2023-01-04 06:07:55,003 INFO:     Found new best model at epoch 9
2023-01-04 06:07:55,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:55,004 INFO:     Epoch: 10
2023-01-04 06:07:56,527 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5482535024483999, 'Total loss': 0.5482535024483999} | train loss {'Reaction outcome loss': 0.46424977541187384, 'Total loss': 0.46424977541187384}
2023-01-04 06:07:56,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:56,527 INFO:     Epoch: 11
2023-01-04 06:07:58,061 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5412001579999923, 'Total loss': 0.5412001579999923} | train loss {'Reaction outcome loss': 0.455442810906981, 'Total loss': 0.455442810906981}
2023-01-04 06:07:58,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:58,062 INFO:     Epoch: 12
2023-01-04 06:07:59,606 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5329444249471028, 'Total loss': 0.5329444249471028} | train loss {'Reaction outcome loss': 0.4531044106740151, 'Total loss': 0.4531044106740151}
2023-01-04 06:07:59,607 INFO:     Found new best model at epoch 12
2023-01-04 06:07:59,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:07:59,607 INFO:     Epoch: 13
2023-01-04 06:08:01,148 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5345350007216135, 'Total loss': 0.5345350007216135} | train loss {'Reaction outcome loss': 0.44675820717846393, 'Total loss': 0.44675820717846393}
2023-01-04 06:08:01,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:01,149 INFO:     Epoch: 14
2023-01-04 06:08:02,686 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5489116966724396, 'Total loss': 0.5489116966724396} | train loss {'Reaction outcome loss': 0.43911464196922134, 'Total loss': 0.43911464196922134}
2023-01-04 06:08:02,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:02,687 INFO:     Epoch: 15
2023-01-04 06:08:04,186 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5634873072306316, 'Total loss': 0.5634873072306316} | train loss {'Reaction outcome loss': 0.4389994478900067, 'Total loss': 0.4389994478900067}
2023-01-04 06:08:04,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:04,187 INFO:     Epoch: 16
2023-01-04 06:08:05,723 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5340197424093882, 'Total loss': 0.5340197424093882} | train loss {'Reaction outcome loss': 0.43258998102515284, 'Total loss': 0.43258998102515284}
2023-01-04 06:08:05,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:05,723 INFO:     Epoch: 17
2023-01-04 06:08:07,249 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5548895319302877, 'Total loss': 0.5548895319302877} | train loss {'Reaction outcome loss': 0.42659615785101035, 'Total loss': 0.42659615785101035}
2023-01-04 06:08:07,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:07,249 INFO:     Epoch: 18
2023-01-04 06:08:08,788 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5195175111293793, 'Total loss': 0.5195175111293793} | train loss {'Reaction outcome loss': 0.42514345011789434, 'Total loss': 0.42514345011789434}
2023-01-04 06:08:08,788 INFO:     Found new best model at epoch 18
2023-01-04 06:08:08,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:08,789 INFO:     Epoch: 19
2023-01-04 06:08:10,335 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5331648051738739, 'Total loss': 0.5331648051738739} | train loss {'Reaction outcome loss': 0.4222378360148329, 'Total loss': 0.4222378360148329}
2023-01-04 06:08:10,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:10,335 INFO:     Epoch: 20
2023-01-04 06:08:11,887 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5258286992708842, 'Total loss': 0.5258286992708842} | train loss {'Reaction outcome loss': 0.4177916404539651, 'Total loss': 0.4177916404539651}
2023-01-04 06:08:11,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:11,887 INFO:     Epoch: 21
2023-01-04 06:08:13,369 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49748142858346306, 'Total loss': 0.49748142858346306} | train loss {'Reaction outcome loss': 0.4137512870731145, 'Total loss': 0.4137512870731145}
2023-01-04 06:08:13,370 INFO:     Found new best model at epoch 21
2023-01-04 06:08:13,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:13,371 INFO:     Epoch: 22
2023-01-04 06:08:14,939 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5295421520868937, 'Total loss': 0.5295421520868937} | train loss {'Reaction outcome loss': 0.4075894007173768, 'Total loss': 0.4075894007173768}
2023-01-04 06:08:14,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:14,939 INFO:     Epoch: 23
2023-01-04 06:08:16,516 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5180652101834615, 'Total loss': 0.5180652101834615} | train loss {'Reaction outcome loss': 0.4037925451993942, 'Total loss': 0.4037925451993942}
2023-01-04 06:08:16,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:16,516 INFO:     Epoch: 24
2023-01-04 06:08:18,077 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5141307810942332, 'Total loss': 0.5141307810942332} | train loss {'Reaction outcome loss': 0.4004385548840909, 'Total loss': 0.4004385548840909}
2023-01-04 06:08:18,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:18,077 INFO:     Epoch: 25
2023-01-04 06:08:19,636 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5297364513079326, 'Total loss': 0.5297364513079326} | train loss {'Reaction outcome loss': 0.4023495481832184, 'Total loss': 0.4023495481832184}
2023-01-04 06:08:19,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:19,637 INFO:     Epoch: 26
2023-01-04 06:08:21,180 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5250686903794607, 'Total loss': 0.5250686903794607} | train loss {'Reaction outcome loss': 0.3961727487290428, 'Total loss': 0.3961727487290428}
2023-01-04 06:08:21,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:21,180 INFO:     Epoch: 27
2023-01-04 06:08:22,679 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5042078197002411, 'Total loss': 0.5042078197002411} | train loss {'Reaction outcome loss': 0.3914138568687613, 'Total loss': 0.3914138568687613}
2023-01-04 06:08:22,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:22,679 INFO:     Epoch: 28
2023-01-04 06:08:24,230 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5366420328617096, 'Total loss': 0.5366420328617096} | train loss {'Reaction outcome loss': 0.3901848008271551, 'Total loss': 0.3901848008271551}
2023-01-04 06:08:24,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:24,230 INFO:     Epoch: 29
2023-01-04 06:08:25,785 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5139092286427815, 'Total loss': 0.5139092286427815} | train loss {'Reaction outcome loss': 0.3828108928499431, 'Total loss': 0.3828108928499431}
2023-01-04 06:08:25,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:25,786 INFO:     Epoch: 30
2023-01-04 06:08:27,353 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5050223489602407, 'Total loss': 0.5050223489602407} | train loss {'Reaction outcome loss': 0.3822283165624542, 'Total loss': 0.3822283165624542}
2023-01-04 06:08:27,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:27,353 INFO:     Epoch: 31
2023-01-04 06:08:28,911 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49419199824333193, 'Total loss': 0.49419199824333193} | train loss {'Reaction outcome loss': 0.3816625327687629, 'Total loss': 0.3816625327687629}
2023-01-04 06:08:28,911 INFO:     Found new best model at epoch 31
2023-01-04 06:08:28,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:28,912 INFO:     Epoch: 32
2023-01-04 06:08:30,457 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5021256645520528, 'Total loss': 0.5021256645520528} | train loss {'Reaction outcome loss': 0.3769473417723266, 'Total loss': 0.3769473417723266}
2023-01-04 06:08:30,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:30,457 INFO:     Epoch: 33
2023-01-04 06:08:31,952 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.513670152425766, 'Total loss': 0.513670152425766} | train loss {'Reaction outcome loss': 0.37482014651933726, 'Total loss': 0.37482014651933726}
2023-01-04 06:08:31,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:31,952 INFO:     Epoch: 34
2023-01-04 06:08:33,494 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.518631511926651, 'Total loss': 0.518631511926651} | train loss {'Reaction outcome loss': 0.3693343026658697, 'Total loss': 0.3693343026658697}
2023-01-04 06:08:33,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:33,495 INFO:     Epoch: 35
2023-01-04 06:08:35,057 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48471206923325855, 'Total loss': 0.48471206923325855} | train loss {'Reaction outcome loss': 0.37148866560446087, 'Total loss': 0.37148866560446087}
2023-01-04 06:08:35,057 INFO:     Found new best model at epoch 35
2023-01-04 06:08:35,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:35,058 INFO:     Epoch: 36
2023-01-04 06:08:36,613 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4746803343296051, 'Total loss': 0.4746803343296051} | train loss {'Reaction outcome loss': 0.3615739893739241, 'Total loss': 0.3615739893739241}
2023-01-04 06:08:36,613 INFO:     Found new best model at epoch 36
2023-01-04 06:08:36,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:36,614 INFO:     Epoch: 37
2023-01-04 06:08:38,158 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5027833958466847, 'Total loss': 0.5027833958466847} | train loss {'Reaction outcome loss': 0.36136701276158767, 'Total loss': 0.36136701276158767}
2023-01-04 06:08:38,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:38,159 INFO:     Epoch: 38
2023-01-04 06:08:39,691 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5020800749460856, 'Total loss': 0.5020800749460856} | train loss {'Reaction outcome loss': 0.356734438153514, 'Total loss': 0.356734438153514}
2023-01-04 06:08:39,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:39,692 INFO:     Epoch: 39
2023-01-04 06:08:41,171 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5024945835272471, 'Total loss': 0.5024945835272471} | train loss {'Reaction outcome loss': 0.35492493981753825, 'Total loss': 0.35492493981753825}
2023-01-04 06:08:41,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:41,171 INFO:     Epoch: 40
2023-01-04 06:08:42,722 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4989983558654785, 'Total loss': 0.4989983558654785} | train loss {'Reaction outcome loss': 0.3529736092925942, 'Total loss': 0.3529736092925942}
2023-01-04 06:08:42,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:42,722 INFO:     Epoch: 41
2023-01-04 06:08:44,263 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.52429239153862, 'Total loss': 0.52429239153862} | train loss {'Reaction outcome loss': 0.3509941111815019, 'Total loss': 0.3509941111815019}
2023-01-04 06:08:44,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:44,264 INFO:     Epoch: 42
2023-01-04 06:08:45,813 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5160890529553096, 'Total loss': 0.5160890529553096} | train loss {'Reaction outcome loss': 0.34809593766601415, 'Total loss': 0.34809593766601415}
2023-01-04 06:08:45,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:45,813 INFO:     Epoch: 43
2023-01-04 06:08:47,358 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5069639186064402, 'Total loss': 0.5069639186064402} | train loss {'Reaction outcome loss': 0.3460211022111186, 'Total loss': 0.3460211022111186}
2023-01-04 06:08:47,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:47,359 INFO:     Epoch: 44
2023-01-04 06:08:48,909 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49744156499703723, 'Total loss': 0.49744156499703723} | train loss {'Reaction outcome loss': 0.33994074579137956, 'Total loss': 0.33994074579137956}
2023-01-04 06:08:48,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:48,909 INFO:     Epoch: 45
2023-01-04 06:08:50,396 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5127369264761606, 'Total loss': 0.5127369264761606} | train loss {'Reaction outcome loss': 0.3354353040565539, 'Total loss': 0.3354353040565539}
2023-01-04 06:08:50,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:50,397 INFO:     Epoch: 46
2023-01-04 06:08:51,958 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4970928361018499, 'Total loss': 0.4970928361018499} | train loss {'Reaction outcome loss': 0.3353286235436906, 'Total loss': 0.3353286235436906}
2023-01-04 06:08:51,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:51,959 INFO:     Epoch: 47
2023-01-04 06:08:53,512 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5156993548075358, 'Total loss': 0.5156993548075358} | train loss {'Reaction outcome loss': 0.33397627551190173, 'Total loss': 0.33397627551190173}
2023-01-04 06:08:53,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:53,512 INFO:     Epoch: 48
2023-01-04 06:08:55,067 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5065396308898926, 'Total loss': 0.5065396308898926} | train loss {'Reaction outcome loss': 0.32912414773863596, 'Total loss': 0.32912414773863596}
2023-01-04 06:08:55,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:55,068 INFO:     Epoch: 49
2023-01-04 06:08:56,611 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4999538342158, 'Total loss': 0.4999538342158} | train loss {'Reaction outcome loss': 0.3296325456106315, 'Total loss': 0.3296325456106315}
2023-01-04 06:08:56,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:56,612 INFO:     Epoch: 50
2023-01-04 06:08:58,144 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49486106634140015, 'Total loss': 0.49486106634140015} | train loss {'Reaction outcome loss': 0.32799853587074435, 'Total loss': 0.32799853587074435}
2023-01-04 06:08:58,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:58,144 INFO:     Epoch: 51
2023-01-04 06:08:59,656 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4668583462635676, 'Total loss': 0.4668583462635676} | train loss {'Reaction outcome loss': 0.32478068461709647, 'Total loss': 0.32478068461709647}
2023-01-04 06:08:59,656 INFO:     Found new best model at epoch 51
2023-01-04 06:08:59,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:08:59,657 INFO:     Epoch: 52
2023-01-04 06:09:01,198 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5057018806536993, 'Total loss': 0.5057018806536993} | train loss {'Reaction outcome loss': 0.32146937386506663, 'Total loss': 0.32146937386506663}
2023-01-04 06:09:01,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:01,198 INFO:     Epoch: 53
2023-01-04 06:09:02,736 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5268351614475251, 'Total loss': 0.5268351614475251} | train loss {'Reaction outcome loss': 0.31962183963534607, 'Total loss': 0.31962183963534607}
2023-01-04 06:09:02,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:02,737 INFO:     Epoch: 54
2023-01-04 06:09:04,270 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4662347634633382, 'Total loss': 0.4662347634633382} | train loss {'Reaction outcome loss': 0.3189277616295501, 'Total loss': 0.3189277616295501}
2023-01-04 06:09:04,271 INFO:     Found new best model at epoch 54
2023-01-04 06:09:04,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:04,271 INFO:     Epoch: 55
2023-01-04 06:09:05,821 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5278643310070038, 'Total loss': 0.5278643310070038} | train loss {'Reaction outcome loss': 0.31684636085355367, 'Total loss': 0.31684636085355367}
2023-01-04 06:09:05,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:05,821 INFO:     Epoch: 56
2023-01-04 06:09:07,349 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4992780109246572, 'Total loss': 0.4992780109246572} | train loss {'Reaction outcome loss': 0.31364212098130345, 'Total loss': 0.31364212098130345}
2023-01-04 06:09:07,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:07,349 INFO:     Epoch: 57
2023-01-04 06:09:08,866 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4957061469554901, 'Total loss': 0.4957061469554901} | train loss {'Reaction outcome loss': 0.3165159901998339, 'Total loss': 0.3165159901998339}
2023-01-04 06:09:08,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:08,867 INFO:     Epoch: 58
2023-01-04 06:09:10,401 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5042660534381866, 'Total loss': 0.5042660534381866} | train loss {'Reaction outcome loss': 0.30488422629933287, 'Total loss': 0.30488422629933287}
2023-01-04 06:09:10,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:10,401 INFO:     Epoch: 59
2023-01-04 06:09:11,937 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4911539067824682, 'Total loss': 0.4911539067824682} | train loss {'Reaction outcome loss': 0.3050401947141564, 'Total loss': 0.3050401947141564}
2023-01-04 06:09:11,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:11,938 INFO:     Epoch: 60
2023-01-04 06:09:13,465 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47064120372136437, 'Total loss': 0.47064120372136437} | train loss {'Reaction outcome loss': 0.3039245064893778, 'Total loss': 0.3039245064893778}
2023-01-04 06:09:13,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:13,465 INFO:     Epoch: 61
2023-01-04 06:09:14,989 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5140871206919352, 'Total loss': 0.5140871206919352} | train loss {'Reaction outcome loss': 0.30450624404271154, 'Total loss': 0.30450624404271154}
2023-01-04 06:09:14,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:14,991 INFO:     Epoch: 62
2023-01-04 06:09:16,488 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48778987328211465, 'Total loss': 0.48778987328211465} | train loss {'Reaction outcome loss': 0.30383016870622215, 'Total loss': 0.30383016870622215}
2023-01-04 06:09:16,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:16,488 INFO:     Epoch: 63
2023-01-04 06:09:17,982 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4970982432365417, 'Total loss': 0.4970982432365417} | train loss {'Reaction outcome loss': 0.3025145007256609, 'Total loss': 0.3025145007256609}
2023-01-04 06:09:17,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:17,983 INFO:     Epoch: 64
2023-01-04 06:09:19,523 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4801257054011027, 'Total loss': 0.4801257054011027} | train loss {'Reaction outcome loss': 0.30169475413043134, 'Total loss': 0.30169475413043134}
2023-01-04 06:09:19,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:19,524 INFO:     Epoch: 65
2023-01-04 06:09:21,055 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47932536800702413, 'Total loss': 0.47932536800702413} | train loss {'Reaction outcome loss': 0.29796743099271816, 'Total loss': 0.29796743099271816}
2023-01-04 06:09:21,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:21,056 INFO:     Epoch: 66
2023-01-04 06:09:22,598 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47224749326705934, 'Total loss': 0.47224749326705934} | train loss {'Reaction outcome loss': 0.2969762315552165, 'Total loss': 0.2969762315552165}
2023-01-04 06:09:22,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:22,598 INFO:     Epoch: 67
2023-01-04 06:09:24,127 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4856068720420202, 'Total loss': 0.4856068720420202} | train loss {'Reaction outcome loss': 0.2925270477404995, 'Total loss': 0.2925270477404995}
2023-01-04 06:09:24,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:24,127 INFO:     Epoch: 68
2023-01-04 06:09:25,634 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5116491248210271, 'Total loss': 0.5116491248210271} | train loss {'Reaction outcome loss': 0.29029015977832956, 'Total loss': 0.29029015977832956}
2023-01-04 06:09:25,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:25,634 INFO:     Epoch: 69
2023-01-04 06:09:27,156 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4867609123388926, 'Total loss': 0.4867609123388926} | train loss {'Reaction outcome loss': 0.29214560795221883, 'Total loss': 0.29214560795221883}
2023-01-04 06:09:27,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:27,156 INFO:     Epoch: 70
2023-01-04 06:09:28,699 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4805506701270739, 'Total loss': 0.4805506701270739} | train loss {'Reaction outcome loss': 0.29029659157360554, 'Total loss': 0.29029659157360554}
2023-01-04 06:09:28,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:28,699 INFO:     Epoch: 71
2023-01-04 06:09:30,267 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.473821884393692, 'Total loss': 0.473821884393692} | train loss {'Reaction outcome loss': 0.28973108747579757, 'Total loss': 0.28973108747579757}
2023-01-04 06:09:30,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:30,268 INFO:     Epoch: 72
2023-01-04 06:09:31,811 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44732957482337954, 'Total loss': 0.44732957482337954} | train loss {'Reaction outcome loss': 0.2870212523062734, 'Total loss': 0.2870212523062734}
2023-01-04 06:09:31,811 INFO:     Found new best model at epoch 72
2023-01-04 06:09:31,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:31,812 INFO:     Epoch: 73
2023-01-04 06:09:33,370 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.467764280239741, 'Total loss': 0.467764280239741} | train loss {'Reaction outcome loss': 0.28442449359236843, 'Total loss': 0.28442449359236843}
2023-01-04 06:09:33,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:33,371 INFO:     Epoch: 74
2023-01-04 06:09:34,871 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4714004427194595, 'Total loss': 0.4714004427194595} | train loss {'Reaction outcome loss': 0.2833973201413224, 'Total loss': 0.2833973201413224}
2023-01-04 06:09:34,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:34,872 INFO:     Epoch: 75
2023-01-04 06:09:36,424 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4671139637629191, 'Total loss': 0.4671139637629191} | train loss {'Reaction outcome loss': 0.2835947380122477, 'Total loss': 0.2835947380122477}
2023-01-04 06:09:36,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:36,424 INFO:     Epoch: 76
2023-01-04 06:09:37,979 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4365364223718643, 'Total loss': 0.4365364223718643} | train loss {'Reaction outcome loss': 0.2784288442374146, 'Total loss': 0.2784288442374146}
2023-01-04 06:09:37,979 INFO:     Found new best model at epoch 76
2023-01-04 06:09:37,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:37,980 INFO:     Epoch: 77
2023-01-04 06:09:39,528 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4573586980501811, 'Total loss': 0.4573586980501811} | train loss {'Reaction outcome loss': 0.28388328309150507, 'Total loss': 0.28388328309150507}
2023-01-04 06:09:39,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:39,528 INFO:     Epoch: 78
2023-01-04 06:09:41,096 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45964719653129577, 'Total loss': 0.45964719653129577} | train loss {'Reaction outcome loss': 0.2833041665586133, 'Total loss': 0.2833041665586133}
2023-01-04 06:09:41,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:41,097 INFO:     Epoch: 79
2023-01-04 06:09:42,651 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47967126270135246, 'Total loss': 0.47967126270135246} | train loss {'Reaction outcome loss': 0.27640470690399843, 'Total loss': 0.27640470690399843}
2023-01-04 06:09:42,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:42,652 INFO:     Epoch: 80
2023-01-04 06:09:44,144 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4998340447743734, 'Total loss': 0.4998340447743734} | train loss {'Reaction outcome loss': 0.2698494810882929, 'Total loss': 0.2698494810882929}
2023-01-04 06:09:44,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:44,144 INFO:     Epoch: 81
2023-01-04 06:09:45,672 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47910548051198326, 'Total loss': 0.47910548051198326} | train loss {'Reaction outcome loss': 0.2766465710435253, 'Total loss': 0.2766465710435253}
2023-01-04 06:09:45,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:45,672 INFO:     Epoch: 82
2023-01-04 06:09:47,208 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44925023913383483, 'Total loss': 0.44925023913383483} | train loss {'Reaction outcome loss': 0.27715856560172825, 'Total loss': 0.27715856560172825}
2023-01-04 06:09:47,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:47,210 INFO:     Epoch: 83
2023-01-04 06:09:48,751 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4754518687725067, 'Total loss': 0.4754518687725067} | train loss {'Reaction outcome loss': 0.26853463630171587, 'Total loss': 0.26853463630171587}
2023-01-04 06:09:48,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:48,751 INFO:     Epoch: 84
2023-01-04 06:09:50,296 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4439819395542145, 'Total loss': 0.4439819395542145} | train loss {'Reaction outcome loss': 0.2705186713949172, 'Total loss': 0.2705186713949172}
2023-01-04 06:09:50,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:50,296 INFO:     Epoch: 85
2023-01-04 06:09:51,831 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46044907371203103, 'Total loss': 0.46044907371203103} | train loss {'Reaction outcome loss': 0.2708956519699227, 'Total loss': 0.2708956519699227}
2023-01-04 06:09:51,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:51,831 INFO:     Epoch: 86
2023-01-04 06:09:53,309 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49322167138258616, 'Total loss': 0.49322167138258616} | train loss {'Reaction outcome loss': 0.26510450903353466, 'Total loss': 0.26510450903353466}
2023-01-04 06:09:53,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:53,310 INFO:     Epoch: 87
2023-01-04 06:09:54,879 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4524799923102061, 'Total loss': 0.4524799923102061} | train loss {'Reaction outcome loss': 0.2690013186176763, 'Total loss': 0.2690013186176763}
2023-01-04 06:09:54,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:54,879 INFO:     Epoch: 88
2023-01-04 06:09:56,452 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4406599268317223, 'Total loss': 0.4406599268317223} | train loss {'Reaction outcome loss': 0.26555332651592956, 'Total loss': 0.26555332651592956}
2023-01-04 06:09:56,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:56,452 INFO:     Epoch: 89
2023-01-04 06:09:58,022 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4396121879418691, 'Total loss': 0.4396121879418691} | train loss {'Reaction outcome loss': 0.26173742406450917, 'Total loss': 0.26173742406450917}
2023-01-04 06:09:58,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:58,022 INFO:     Epoch: 90
2023-01-04 06:09:59,594 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4651772608359655, 'Total loss': 0.4651772608359655} | train loss {'Reaction outcome loss': 0.2639690583204701, 'Total loss': 0.2639690583204701}
2023-01-04 06:09:59,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:09:59,594 INFO:     Epoch: 91
2023-01-04 06:10:01,161 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4668003102143606, 'Total loss': 0.4668003102143606} | train loss {'Reaction outcome loss': 0.26675461227223823, 'Total loss': 0.26675461227223823}
2023-01-04 06:10:01,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:01,161 INFO:     Epoch: 92
2023-01-04 06:10:02,657 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4546942333380381, 'Total loss': 0.4546942333380381} | train loss {'Reaction outcome loss': 0.2651236346331391, 'Total loss': 0.2651236346331391}
2023-01-04 06:10:02,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:02,657 INFO:     Epoch: 93
2023-01-04 06:10:04,235 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4280818293491999, 'Total loss': 0.4280818293491999} | train loss {'Reaction outcome loss': 0.26428206893105577, 'Total loss': 0.26428206893105577}
2023-01-04 06:10:04,235 INFO:     Found new best model at epoch 93
2023-01-04 06:10:04,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:04,236 INFO:     Epoch: 94
2023-01-04 06:10:05,825 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4927815238634745, 'Total loss': 0.4927815238634745} | train loss {'Reaction outcome loss': 0.2595474368409954, 'Total loss': 0.2595474368409954}
2023-01-04 06:10:05,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:05,826 INFO:     Epoch: 95
2023-01-04 06:10:07,394 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43714930514494577, 'Total loss': 0.43714930514494577} | train loss {'Reaction outcome loss': 0.2620167178203807, 'Total loss': 0.2620167178203807}
2023-01-04 06:10:07,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:07,394 INFO:     Epoch: 96
2023-01-04 06:10:08,977 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44229348997275036, 'Total loss': 0.44229348997275036} | train loss {'Reaction outcome loss': 0.26233940340415407, 'Total loss': 0.26233940340415407}
2023-01-04 06:10:08,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:08,978 INFO:     Epoch: 97
2023-01-04 06:10:10,533 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46136978367964426, 'Total loss': 0.46136978367964426} | train loss {'Reaction outcome loss': 0.25564631202468907, 'Total loss': 0.25564631202468907}
2023-01-04 06:10:10,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:10,533 INFO:     Epoch: 98
2023-01-04 06:10:11,802 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4435628910859426, 'Total loss': 0.4435628910859426} | train loss {'Reaction outcome loss': 0.2568138608314695, 'Total loss': 0.2568138608314695}
2023-01-04 06:10:11,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:11,803 INFO:     Epoch: 99
2023-01-04 06:10:12,821 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4389273256063461, 'Total loss': 0.4389273256063461} | train loss {'Reaction outcome loss': 0.2569044372678673, 'Total loss': 0.2569044372678673}
2023-01-04 06:10:12,821 INFO:     Best model found after epoch 94 of 100.
2023-01-04 06:10:12,822 INFO:   Done with stage: TRAINING
2023-01-04 06:10:12,822 INFO:   Starting stage: EVALUATION
2023-01-04 06:10:12,952 INFO:   Done with stage: EVALUATION
2023-01-04 06:10:12,952 INFO:   Leaving out SEQ value Fold_3
2023-01-04 06:10:12,964 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 06:10:12,965 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:10:13,607 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:10:13,607 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:10:13,676 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:10:13,676 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:10:13,676 INFO:     No hyperparam tuning for this model
2023-01-04 06:10:13,676 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:10:13,676 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:10:13,677 INFO:     None feature selector for col prot
2023-01-04 06:10:13,677 INFO:     None feature selector for col prot
2023-01-04 06:10:13,677 INFO:     None feature selector for col prot
2023-01-04 06:10:13,678 INFO:     None feature selector for col chem
2023-01-04 06:10:13,678 INFO:     None feature selector for col chem
2023-01-04 06:10:13,678 INFO:     None feature selector for col chem
2023-01-04 06:10:13,678 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:10:13,678 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:10:13,679 INFO:     Number of params in model 70111
2023-01-04 06:10:13,682 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:10:13,682 INFO:   Starting stage: TRAINING
2023-01-04 06:10:13,715 INFO:     Val loss before train {'Reaction outcome loss': 0.9509315013885498, 'Total loss': 0.9509315013885498}
2023-01-04 06:10:13,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:13,715 INFO:     Epoch: 0
2023-01-04 06:10:14,726 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.736499410867691, 'Total loss': 0.736499410867691} | train loss {'Reaction outcome loss': 0.8308113247920306, 'Total loss': 0.8308113247920306}
2023-01-04 06:10:14,726 INFO:     Found new best model at epoch 0
2023-01-04 06:10:14,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:14,727 INFO:     Epoch: 1
2023-01-04 06:10:15,822 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6122892002264658, 'Total loss': 0.6122892002264658} | train loss {'Reaction outcome loss': 0.6573433773967373, 'Total loss': 0.6573433773967373}
2023-01-04 06:10:15,822 INFO:     Found new best model at epoch 1
2023-01-04 06:10:15,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:15,823 INFO:     Epoch: 2
2023-01-04 06:10:17,334 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5637479891379674, 'Total loss': 0.5637479891379674} | train loss {'Reaction outcome loss': 0.5605870751125035, 'Total loss': 0.5605870751125035}
2023-01-04 06:10:17,335 INFO:     Found new best model at epoch 2
2023-01-04 06:10:17,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:17,335 INFO:     Epoch: 3
2023-01-04 06:10:18,847 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5374888281027476, 'Total loss': 0.5374888281027476} | train loss {'Reaction outcome loss': 0.5233643559854982, 'Total loss': 0.5233643559854982}
2023-01-04 06:10:18,847 INFO:     Found new best model at epoch 3
2023-01-04 06:10:18,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:18,848 INFO:     Epoch: 4
2023-01-04 06:10:20,378 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5340068936347961, 'Total loss': 0.5340068936347961} | train loss {'Reaction outcome loss': 0.5041832455294036, 'Total loss': 0.5041832455294036}
2023-01-04 06:10:20,378 INFO:     Found new best model at epoch 4
2023-01-04 06:10:20,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:20,379 INFO:     Epoch: 5
2023-01-04 06:10:21,905 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5382056117057801, 'Total loss': 0.5382056117057801} | train loss {'Reaction outcome loss': 0.49203792967639126, 'Total loss': 0.49203792967639126}
2023-01-04 06:10:21,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:21,906 INFO:     Epoch: 6
2023-01-04 06:10:23,426 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5413551946481069, 'Total loss': 0.5413551946481069} | train loss {'Reaction outcome loss': 0.4822601589200261, 'Total loss': 0.4822601589200261}
2023-01-04 06:10:23,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:23,427 INFO:     Epoch: 7
2023-01-04 06:10:24,920 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5477087398370107, 'Total loss': 0.5477087398370107} | train loss {'Reaction outcome loss': 0.4732859485642814, 'Total loss': 0.4732859485642814}
2023-01-04 06:10:24,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:24,921 INFO:     Epoch: 8
2023-01-04 06:10:26,431 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4955132861932119, 'Total loss': 0.4955132861932119} | train loss {'Reaction outcome loss': 0.46127706607837815, 'Total loss': 0.46127706607837815}
2023-01-04 06:10:26,431 INFO:     Found new best model at epoch 8
2023-01-04 06:10:26,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:26,432 INFO:     Epoch: 9
2023-01-04 06:10:27,950 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5306214074293772, 'Total loss': 0.5306214074293772} | train loss {'Reaction outcome loss': 0.45575764157123616, 'Total loss': 0.45575764157123616}
2023-01-04 06:10:27,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:27,951 INFO:     Epoch: 10
2023-01-04 06:10:29,469 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5477634648482005, 'Total loss': 0.5477634648482005} | train loss {'Reaction outcome loss': 0.45127540264592503, 'Total loss': 0.45127540264592503}
2023-01-04 06:10:29,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:29,469 INFO:     Epoch: 11
2023-01-04 06:10:31,001 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5333156883716583, 'Total loss': 0.5333156883716583} | train loss {'Reaction outcome loss': 0.4470800823453582, 'Total loss': 0.4470800823453582}
2023-01-04 06:10:31,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:31,002 INFO:     Epoch: 12
2023-01-04 06:10:32,531 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5238192995389302, 'Total loss': 0.5238192995389302} | train loss {'Reaction outcome loss': 0.43778222253471066, 'Total loss': 0.43778222253471066}
2023-01-04 06:10:32,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:32,531 INFO:     Epoch: 13
2023-01-04 06:10:34,030 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5129928708076477, 'Total loss': 0.5129928708076477} | train loss {'Reaction outcome loss': 0.43657672498034034, 'Total loss': 0.43657672498034034}
2023-01-04 06:10:34,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:34,030 INFO:     Epoch: 14
2023-01-04 06:10:35,537 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5207865595817566, 'Total loss': 0.5207865595817566} | train loss {'Reaction outcome loss': 0.4327272118338735, 'Total loss': 0.4327272118338735}
2023-01-04 06:10:35,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:35,537 INFO:     Epoch: 15
2023-01-04 06:10:37,070 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5349516371885935, 'Total loss': 0.5349516371885935} | train loss {'Reaction outcome loss': 0.4232884443504906, 'Total loss': 0.4232884443504906}
2023-01-04 06:10:37,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:37,070 INFO:     Epoch: 16
2023-01-04 06:10:38,609 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48854517539342246, 'Total loss': 0.48854517539342246} | train loss {'Reaction outcome loss': 0.42436873754520554, 'Total loss': 0.42436873754520554}
2023-01-04 06:10:38,609 INFO:     Found new best model at epoch 16
2023-01-04 06:10:38,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:38,610 INFO:     Epoch: 17
2023-01-04 06:10:40,149 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.526262636979421, 'Total loss': 0.526262636979421} | train loss {'Reaction outcome loss': 0.4140307538129471, 'Total loss': 0.4140307538129471}
2023-01-04 06:10:40,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:40,150 INFO:     Epoch: 18
2023-01-04 06:10:41,698 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4911309043566386, 'Total loss': 0.4911309043566386} | train loss {'Reaction outcome loss': 0.4132488100949825, 'Total loss': 0.4132488100949825}
2023-01-04 06:10:41,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:41,698 INFO:     Epoch: 19
2023-01-04 06:10:43,203 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.505109828710556, 'Total loss': 0.505109828710556} | train loss {'Reaction outcome loss': 0.40775535940687296, 'Total loss': 0.40775535940687296}
2023-01-04 06:10:43,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:43,203 INFO:     Epoch: 20
2023-01-04 06:10:44,691 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5104435563087464, 'Total loss': 0.5104435563087464} | train loss {'Reaction outcome loss': 0.40834198630118107, 'Total loss': 0.40834198630118107}
2023-01-04 06:10:44,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:44,691 INFO:     Epoch: 21
2023-01-04 06:10:46,225 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5026460150877635, 'Total loss': 0.5026460150877635} | train loss {'Reaction outcome loss': 0.4022761176684837, 'Total loss': 0.4022761176684837}
2023-01-04 06:10:46,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:46,225 INFO:     Epoch: 22
2023-01-04 06:10:47,778 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4811310306191444, 'Total loss': 0.4811310306191444} | train loss {'Reaction outcome loss': 0.4011396802825369, 'Total loss': 0.4011396802825369}
2023-01-04 06:10:47,778 INFO:     Found new best model at epoch 22
2023-01-04 06:10:47,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:47,779 INFO:     Epoch: 23
2023-01-04 06:10:49,335 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4733191758394241, 'Total loss': 0.4733191758394241} | train loss {'Reaction outcome loss': 0.39610545746572723, 'Total loss': 0.39610545746572723}
2023-01-04 06:10:49,335 INFO:     Found new best model at epoch 23
2023-01-04 06:10:49,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:49,336 INFO:     Epoch: 24
2023-01-04 06:10:50,879 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4856307029724121, 'Total loss': 0.4856307029724121} | train loss {'Reaction outcome loss': 0.38658083219340433, 'Total loss': 0.38658083219340433}
2023-01-04 06:10:50,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:50,880 INFO:     Epoch: 25
2023-01-04 06:10:52,402 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4983660320440928, 'Total loss': 0.4983660320440928} | train loss {'Reaction outcome loss': 0.3899651630457504, 'Total loss': 0.3899651630457504}
2023-01-04 06:10:52,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:52,403 INFO:     Epoch: 26
2023-01-04 06:10:53,916 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4708483835061391, 'Total loss': 0.4708483835061391} | train loss {'Reaction outcome loss': 0.38544067241005847, 'Total loss': 0.38544067241005847}
2023-01-04 06:10:53,916 INFO:     Found new best model at epoch 26
2023-01-04 06:10:53,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:53,916 INFO:     Epoch: 27
2023-01-04 06:10:55,498 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48485349416732787, 'Total loss': 0.48485349416732787} | train loss {'Reaction outcome loss': 0.3823038277390239, 'Total loss': 0.3823038277390239}
2023-01-04 06:10:55,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:55,498 INFO:     Epoch: 28
2023-01-04 06:10:57,057 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4927820126215617, 'Total loss': 0.4927820126215617} | train loss {'Reaction outcome loss': 0.37710841873408235, 'Total loss': 0.37710841873408235}
2023-01-04 06:10:57,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:57,058 INFO:     Epoch: 29
2023-01-04 06:10:58,606 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4639336903889974, 'Total loss': 0.4639336903889974} | train loss {'Reaction outcome loss': 0.37278263412770773, 'Total loss': 0.37278263412770773}
2023-01-04 06:10:58,607 INFO:     Found new best model at epoch 29
2023-01-04 06:10:58,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:10:58,608 INFO:     Epoch: 30
2023-01-04 06:11:00,174 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4741844097773234, 'Total loss': 0.4741844097773234} | train loss {'Reaction outcome loss': 0.37087665312674456, 'Total loss': 0.37087665312674456}
2023-01-04 06:11:00,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:00,174 INFO:     Epoch: 31
2023-01-04 06:11:01,707 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45991264581680297, 'Total loss': 0.45991264581680297} | train loss {'Reaction outcome loss': 0.36854183493734716, 'Total loss': 0.36854183493734716}
2023-01-04 06:11:01,707 INFO:     Found new best model at epoch 31
2023-01-04 06:11:01,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:01,708 INFO:     Epoch: 32
2023-01-04 06:11:03,221 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4752466301123301, 'Total loss': 0.4752466301123301} | train loss {'Reaction outcome loss': 0.3658628225217372, 'Total loss': 0.3658628225217372}
2023-01-04 06:11:03,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:03,221 INFO:     Epoch: 33
2023-01-04 06:11:04,796 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4723118841648102, 'Total loss': 0.4723118841648102} | train loss {'Reaction outcome loss': 0.35730254652845117, 'Total loss': 0.35730254652845117}
2023-01-04 06:11:04,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:04,796 INFO:     Epoch: 34
2023-01-04 06:11:06,354 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47364687323570254, 'Total loss': 0.47364687323570254} | train loss {'Reaction outcome loss': 0.36073464103343283, 'Total loss': 0.36073464103343283}
2023-01-04 06:11:06,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:06,354 INFO:     Epoch: 35
2023-01-04 06:11:07,891 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48582220474878945, 'Total loss': 0.48582220474878945} | train loss {'Reaction outcome loss': 0.35888345042864483, 'Total loss': 0.35888345042864483}
2023-01-04 06:11:07,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:07,891 INFO:     Epoch: 36
2023-01-04 06:11:09,434 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4463012417157491, 'Total loss': 0.4463012417157491} | train loss {'Reaction outcome loss': 0.35593542464814343, 'Total loss': 0.35593542464814343}
2023-01-04 06:11:09,435 INFO:     Found new best model at epoch 36
2023-01-04 06:11:09,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:09,435 INFO:     Epoch: 37
2023-01-04 06:11:10,939 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4689159611860911, 'Total loss': 0.4689159611860911} | train loss {'Reaction outcome loss': 0.35048163117288234, 'Total loss': 0.35048163117288234}
2023-01-04 06:11:10,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:10,940 INFO:     Epoch: 38
2023-01-04 06:11:12,434 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4962934096654256, 'Total loss': 0.4962934096654256} | train loss {'Reaction outcome loss': 0.3470696464399278, 'Total loss': 0.3470696464399278}
2023-01-04 06:11:12,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:12,434 INFO:     Epoch: 39
2023-01-04 06:11:13,966 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44448974132537844, 'Total loss': 0.44448974132537844} | train loss {'Reaction outcome loss': 0.3505467329542715, 'Total loss': 0.3505467329542715}
2023-01-04 06:11:13,966 INFO:     Found new best model at epoch 39
2023-01-04 06:11:13,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:13,967 INFO:     Epoch: 40
2023-01-04 06:11:15,492 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43823258876800536, 'Total loss': 0.43823258876800536} | train loss {'Reaction outcome loss': 0.34712835133839876, 'Total loss': 0.34712835133839876}
2023-01-04 06:11:15,493 INFO:     Found new best model at epoch 40
2023-01-04 06:11:15,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:15,493 INFO:     Epoch: 41
2023-01-04 06:11:17,024 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48331838349501294, 'Total loss': 0.48331838349501294} | train loss {'Reaction outcome loss': 0.34411564684940343, 'Total loss': 0.34411564684940343}
2023-01-04 06:11:17,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:17,025 INFO:     Epoch: 42
2023-01-04 06:11:18,579 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4640626713633537, 'Total loss': 0.4640626713633537} | train loss {'Reaction outcome loss': 0.3393340365408541, 'Total loss': 0.3393340365408541}
2023-01-04 06:11:18,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:18,579 INFO:     Epoch: 43
2023-01-04 06:11:20,077 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49859878222147624, 'Total loss': 0.49859878222147624} | train loss {'Reaction outcome loss': 0.3387717414961193, 'Total loss': 0.3387717414961193}
2023-01-04 06:11:20,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:20,077 INFO:     Epoch: 44
2023-01-04 06:11:21,585 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4572019636631012, 'Total loss': 0.4572019636631012} | train loss {'Reaction outcome loss': 0.3357574567369325, 'Total loss': 0.3357574567369325}
2023-01-04 06:11:21,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:21,585 INFO:     Epoch: 45
2023-01-04 06:11:23,121 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45378809571266177, 'Total loss': 0.45378809571266177} | train loss {'Reaction outcome loss': 0.3413343135363016, 'Total loss': 0.3413343135363016}
2023-01-04 06:11:23,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:23,123 INFO:     Epoch: 46
2023-01-04 06:11:24,665 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46765315930048623, 'Total loss': 0.46765315930048623} | train loss {'Reaction outcome loss': 0.33272039827518846, 'Total loss': 0.33272039827518846}
2023-01-04 06:11:24,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:24,665 INFO:     Epoch: 47
2023-01-04 06:11:26,216 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4515983740488688, 'Total loss': 0.4515983740488688} | train loss {'Reaction outcome loss': 0.3307769491095028, 'Total loss': 0.3307769491095028}
2023-01-04 06:11:26,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:26,217 INFO:     Epoch: 48
2023-01-04 06:11:27,760 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43822487791379294, 'Total loss': 0.43822487791379294} | train loss {'Reaction outcome loss': 0.32617076472703355, 'Total loss': 0.32617076472703355}
2023-01-04 06:11:27,761 INFO:     Found new best model at epoch 48
2023-01-04 06:11:27,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:27,761 INFO:     Epoch: 49
2023-01-04 06:11:29,323 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45573142866293587, 'Total loss': 0.45573142866293587} | train loss {'Reaction outcome loss': 0.32222245216042134, 'Total loss': 0.32222245216042134}
2023-01-04 06:11:29,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:29,325 INFO:     Epoch: 50
2023-01-04 06:11:30,884 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48001448114713036, 'Total loss': 0.48001448114713036} | train loss {'Reaction outcome loss': 0.3214818871283269, 'Total loss': 0.3214818871283269}
2023-01-04 06:11:30,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:30,884 INFO:     Epoch: 51
2023-01-04 06:11:32,475 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44435872733592985, 'Total loss': 0.44435872733592985} | train loss {'Reaction outcome loss': 0.3195338624464723, 'Total loss': 0.3195338624464723}
2023-01-04 06:11:32,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:32,475 INFO:     Epoch: 52
2023-01-04 06:11:34,089 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4488186816374461, 'Total loss': 0.4488186816374461} | train loss {'Reaction outcome loss': 0.3190220191856444, 'Total loss': 0.3190220191856444}
2023-01-04 06:11:34,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:34,089 INFO:     Epoch: 53
2023-01-04 06:11:35,663 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45392743150393167, 'Total loss': 0.45392743150393167} | train loss {'Reaction outcome loss': 0.314888834189146, 'Total loss': 0.314888834189146}
2023-01-04 06:11:35,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:35,664 INFO:     Epoch: 54
2023-01-04 06:11:37,263 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45584047635396324, 'Total loss': 0.45584047635396324} | train loss {'Reaction outcome loss': 0.3207087774689381, 'Total loss': 0.3207087774689381}
2023-01-04 06:11:37,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:37,264 INFO:     Epoch: 55
2023-01-04 06:11:38,819 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4656335194905599, 'Total loss': 0.4656335194905599} | train loss {'Reaction outcome loss': 0.3153985065336411, 'Total loss': 0.3153985065336411}
2023-01-04 06:11:38,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:38,819 INFO:     Epoch: 56
2023-01-04 06:11:40,324 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4375501294930776, 'Total loss': 0.4375501294930776} | train loss {'Reaction outcome loss': 0.31252898303143706, 'Total loss': 0.31252898303143706}
2023-01-04 06:11:40,324 INFO:     Found new best model at epoch 56
2023-01-04 06:11:40,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:40,325 INFO:     Epoch: 57
2023-01-04 06:11:41,883 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47162148157755535, 'Total loss': 0.47162148157755535} | train loss {'Reaction outcome loss': 0.3072017848546252, 'Total loss': 0.3072017848546252}
2023-01-04 06:11:41,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:41,884 INFO:     Epoch: 58
2023-01-04 06:11:43,430 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5067779709895451, 'Total loss': 0.5067779709895451} | train loss {'Reaction outcome loss': 0.3122278666157862, 'Total loss': 0.3122278666157862}
2023-01-04 06:11:43,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:43,430 INFO:     Epoch: 59
2023-01-04 06:11:45,002 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47468447089195254, 'Total loss': 0.47468447089195254} | train loss {'Reaction outcome loss': 0.30336005980278546, 'Total loss': 0.30336005980278546}
2023-01-04 06:11:45,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:45,002 INFO:     Epoch: 60
2023-01-04 06:11:46,546 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4892987082401911, 'Total loss': 0.4892987082401911} | train loss {'Reaction outcome loss': 0.3057742975106388, 'Total loss': 0.3057742975106388}
2023-01-04 06:11:46,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:46,547 INFO:     Epoch: 61
2023-01-04 06:11:48,111 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4422896941502889, 'Total loss': 0.4422896941502889} | train loss {'Reaction outcome loss': 0.30597814270755747, 'Total loss': 0.30597814270755747}
2023-01-04 06:11:48,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:48,112 INFO:     Epoch: 62
2023-01-04 06:11:49,657 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45886633892854056, 'Total loss': 0.45886633892854056} | train loss {'Reaction outcome loss': 0.3070501358736129, 'Total loss': 0.3070501358736129}
2023-01-04 06:11:49,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:49,657 INFO:     Epoch: 63
2023-01-04 06:11:51,218 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44462829530239106, 'Total loss': 0.44462829530239106} | train loss {'Reaction outcome loss': 0.30879297623267543, 'Total loss': 0.30879297623267543}
2023-01-04 06:11:51,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:51,218 INFO:     Epoch: 64
2023-01-04 06:11:52,776 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4535509010155996, 'Total loss': 0.4535509010155996} | train loss {'Reaction outcome loss': 0.30107624113778053, 'Total loss': 0.30107624113778053}
2023-01-04 06:11:52,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:52,776 INFO:     Epoch: 65
2023-01-04 06:11:54,348 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4558223098516464, 'Total loss': 0.4558223098516464} | train loss {'Reaction outcome loss': 0.30169497190159317, 'Total loss': 0.30169497190159317}
2023-01-04 06:11:54,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:54,350 INFO:     Epoch: 66
2023-01-04 06:11:55,882 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4306164622306824, 'Total loss': 0.4306164622306824} | train loss {'Reaction outcome loss': 0.2954457249396887, 'Total loss': 0.2954457249396887}
2023-01-04 06:11:55,883 INFO:     Found new best model at epoch 66
2023-01-04 06:11:55,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:55,883 INFO:     Epoch: 67
2023-01-04 06:11:57,408 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4496600727240245, 'Total loss': 0.4496600727240245} | train loss {'Reaction outcome loss': 0.29421429052239373, 'Total loss': 0.29421429052239373}
2023-01-04 06:11:57,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:57,408 INFO:     Epoch: 68
2023-01-04 06:11:58,988 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44513612389564516, 'Total loss': 0.44513612389564516} | train loss {'Reaction outcome loss': 0.29356209210532924, 'Total loss': 0.29356209210532924}
2023-01-04 06:11:58,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:11:58,988 INFO:     Epoch: 69
2023-01-04 06:12:00,560 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42826158305009204, 'Total loss': 0.42826158305009204} | train loss {'Reaction outcome loss': 0.29252709246380426, 'Total loss': 0.29252709246380426}
2023-01-04 06:12:00,561 INFO:     Found new best model at epoch 69
2023-01-04 06:12:00,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:00,562 INFO:     Epoch: 70
2023-01-04 06:12:02,139 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39227513372898104, 'Total loss': 0.39227513372898104} | train loss {'Reaction outcome loss': 0.2900543218348926, 'Total loss': 0.2900543218348926}
2023-01-04 06:12:02,139 INFO:     Found new best model at epoch 70
2023-01-04 06:12:02,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:02,140 INFO:     Epoch: 71
2023-01-04 06:12:03,716 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4380326231320699, 'Total loss': 0.4380326231320699} | train loss {'Reaction outcome loss': 0.2899348890825069, 'Total loss': 0.2899348890825069}
2023-01-04 06:12:03,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:03,716 INFO:     Epoch: 72
2023-01-04 06:12:05,258 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4622776110967, 'Total loss': 0.4622776110967} | train loss {'Reaction outcome loss': 0.28931019938254093, 'Total loss': 0.28931019938254093}
2023-01-04 06:12:05,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:05,259 INFO:     Epoch: 73
2023-01-04 06:12:06,792 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44092579881350197, 'Total loss': 0.44092579881350197} | train loss {'Reaction outcome loss': 0.2943173060841831, 'Total loss': 0.2943173060841831}
2023-01-04 06:12:06,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:06,792 INFO:     Epoch: 74
2023-01-04 06:12:08,356 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4908674756685893, 'Total loss': 0.4908674756685893} | train loss {'Reaction outcome loss': 0.2849751974527652, 'Total loss': 0.2849751974527652}
2023-01-04 06:12:08,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:08,356 INFO:     Epoch: 75
2023-01-04 06:12:09,917 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42482095062732694, 'Total loss': 0.42482095062732694} | train loss {'Reaction outcome loss': 0.2873999086983038, 'Total loss': 0.2873999086983038}
2023-01-04 06:12:09,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:09,918 INFO:     Epoch: 76
2023-01-04 06:12:11,486 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42405392428239186, 'Total loss': 0.42405392428239186} | train loss {'Reaction outcome loss': 0.2800196363648652, 'Total loss': 0.2800196363648652}
2023-01-04 06:12:11,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:11,486 INFO:     Epoch: 77
2023-01-04 06:12:13,036 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42565668324629463, 'Total loss': 0.42565668324629463} | train loss {'Reaction outcome loss': 0.2838812518196228, 'Total loss': 0.2838812518196228}
2023-01-04 06:12:13,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:13,037 INFO:     Epoch: 78
2023-01-04 06:12:14,573 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46277629733085635, 'Total loss': 0.46277629733085635} | train loss {'Reaction outcome loss': 0.2824996443731444, 'Total loss': 0.2824996443731444}
2023-01-04 06:12:14,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:14,573 INFO:     Epoch: 79
2023-01-04 06:12:16,134 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42632806797822315, 'Total loss': 0.42632806797822315} | train loss {'Reaction outcome loss': 0.2779448494287856, 'Total loss': 0.2779448494287856}
2023-01-04 06:12:16,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:16,134 INFO:     Epoch: 80
2023-01-04 06:12:17,711 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42441264539957047, 'Total loss': 0.42441264539957047} | train loss {'Reaction outcome loss': 0.2815036760308804, 'Total loss': 0.2815036760308804}
2023-01-04 06:12:17,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:17,711 INFO:     Epoch: 81
2023-01-04 06:12:19,250 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45493508676687877, 'Total loss': 0.45493508676687877} | train loss {'Reaction outcome loss': 0.27982022356746833, 'Total loss': 0.27982022356746833}
2023-01-04 06:12:19,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:19,250 INFO:     Epoch: 82
2023-01-04 06:12:20,793 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42495645880699157, 'Total loss': 0.42495645880699157} | train loss {'Reaction outcome loss': 0.27806034225683945, 'Total loss': 0.27806034225683945}
2023-01-04 06:12:20,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:20,793 INFO:     Epoch: 83
2023-01-04 06:12:22,339 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5253519147634507, 'Total loss': 0.5253519147634507} | train loss {'Reaction outcome loss': 0.2782220351663265, 'Total loss': 0.2782220351663265}
2023-01-04 06:12:22,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:22,340 INFO:     Epoch: 84
2023-01-04 06:12:23,846 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4499675999085108, 'Total loss': 0.4499675999085108} | train loss {'Reaction outcome loss': 0.2770814440953426, 'Total loss': 0.2770814440953426}
2023-01-04 06:12:23,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:23,846 INFO:     Epoch: 85
2023-01-04 06:12:25,369 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4313515027364095, 'Total loss': 0.4313515027364095} | train loss {'Reaction outcome loss': 0.2723890215076588, 'Total loss': 0.2723890215076588}
2023-01-04 06:12:25,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:25,370 INFO:     Epoch: 86
2023-01-04 06:12:26,942 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4277189125617345, 'Total loss': 0.4277189125617345} | train loss {'Reaction outcome loss': 0.2688925504111327, 'Total loss': 0.2688925504111327}
2023-01-04 06:12:26,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:26,942 INFO:     Epoch: 87
2023-01-04 06:12:28,479 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4496972292661667, 'Total loss': 0.4496972292661667} | train loss {'Reaction outcome loss': 0.2732695269060659, 'Total loss': 0.2732695269060659}
2023-01-04 06:12:28,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:28,479 INFO:     Epoch: 88
2023-01-04 06:12:30,028 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4266312559445699, 'Total loss': 0.4266312559445699} | train loss {'Reaction outcome loss': 0.27347153889172243, 'Total loss': 0.27347153889172243}
2023-01-04 06:12:30,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:30,029 INFO:     Epoch: 89
2023-01-04 06:12:31,599 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46813420255978905, 'Total loss': 0.46813420255978905} | train loss {'Reaction outcome loss': 0.26844593187991955, 'Total loss': 0.26844593187991955}
2023-01-04 06:12:31,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:31,600 INFO:     Epoch: 90
2023-01-04 06:12:33,128 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4728598813215891, 'Total loss': 0.4728598813215891} | train loss {'Reaction outcome loss': 0.2662574488178387, 'Total loss': 0.2662574488178387}
2023-01-04 06:12:33,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:33,128 INFO:     Epoch: 91
2023-01-04 06:12:34,657 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39001797636349994, 'Total loss': 0.39001797636349994} | train loss {'Reaction outcome loss': 0.27222646145156887, 'Total loss': 0.27222646145156887}
2023-01-04 06:12:34,657 INFO:     Found new best model at epoch 91
2023-01-04 06:12:34,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:34,658 INFO:     Epoch: 92
2023-01-04 06:12:36,236 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44927063286304475, 'Total loss': 0.44927063286304475} | train loss {'Reaction outcome loss': 0.26518924878193784, 'Total loss': 0.26518924878193784}
2023-01-04 06:12:36,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:36,236 INFO:     Epoch: 93
2023-01-04 06:12:37,836 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4431471397479375, 'Total loss': 0.4431471397479375} | train loss {'Reaction outcome loss': 0.2676225958508013, 'Total loss': 0.2676225958508013}
2023-01-04 06:12:37,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:37,836 INFO:     Epoch: 94
2023-01-04 06:12:39,419 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4339712699254354, 'Total loss': 0.4339712699254354} | train loss {'Reaction outcome loss': 0.263527492081726, 'Total loss': 0.263527492081726}
2023-01-04 06:12:39,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:39,419 INFO:     Epoch: 95
2023-01-04 06:12:40,988 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4111038068930308, 'Total loss': 0.4111038068930308} | train loss {'Reaction outcome loss': 0.2606251099361823, 'Total loss': 0.2606251099361823}
2023-01-04 06:12:40,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:40,988 INFO:     Epoch: 96
2023-01-04 06:12:42,537 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4275624414285024, 'Total loss': 0.4275624414285024} | train loss {'Reaction outcome loss': 0.26586698804855785, 'Total loss': 0.26586698804855785}
2023-01-04 06:12:42,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:42,537 INFO:     Epoch: 97
2023-01-04 06:12:44,075 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4352655291557312, 'Total loss': 0.4352655291557312} | train loss {'Reaction outcome loss': 0.2660836876257435, 'Total loss': 0.2660836876257435}
2023-01-04 06:12:44,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:44,076 INFO:     Epoch: 98
2023-01-04 06:12:45,632 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.448790313800176, 'Total loss': 0.448790313800176} | train loss {'Reaction outcome loss': 0.2608475699174754, 'Total loss': 0.2608475699174754}
2023-01-04 06:12:45,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:45,632 INFO:     Epoch: 99
2023-01-04 06:12:47,191 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4492538472016652, 'Total loss': 0.4492538472016652} | train loss {'Reaction outcome loss': 0.2606242502128685, 'Total loss': 0.2606242502128685}
2023-01-04 06:12:47,192 INFO:     Best model found after epoch 92 of 100.
2023-01-04 06:12:47,192 INFO:   Done with stage: TRAINING
2023-01-04 06:12:47,192 INFO:   Starting stage: EVALUATION
2023-01-04 06:12:47,328 INFO:   Done with stage: EVALUATION
2023-01-04 06:12:47,328 INFO:   Leaving out SEQ value Fold_4
2023-01-04 06:12:47,341 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 06:12:47,341 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:12:47,989 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:12:47,989 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:12:48,059 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:12:48,059 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:12:48,059 INFO:     No hyperparam tuning for this model
2023-01-04 06:12:48,060 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:12:48,060 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:12:48,060 INFO:     None feature selector for col prot
2023-01-04 06:12:48,060 INFO:     None feature selector for col prot
2023-01-04 06:12:48,061 INFO:     None feature selector for col prot
2023-01-04 06:12:48,061 INFO:     None feature selector for col chem
2023-01-04 06:12:48,061 INFO:     None feature selector for col chem
2023-01-04 06:12:48,061 INFO:     None feature selector for col chem
2023-01-04 06:12:48,061 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:12:48,061 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:12:48,062 INFO:     Number of params in model 70111
2023-01-04 06:12:48,065 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:12:48,066 INFO:   Starting stage: TRAINING
2023-01-04 06:12:48,108 INFO:     Val loss before train {'Reaction outcome loss': 1.032916752497355, 'Total loss': 1.032916752497355}
2023-01-04 06:12:48,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:48,109 INFO:     Epoch: 0
2023-01-04 06:12:49,661 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7664866805076599, 'Total loss': 0.7664866805076599} | train loss {'Reaction outcome loss': 0.8370727294117865, 'Total loss': 0.8370727294117865}
2023-01-04 06:12:49,661 INFO:     Found new best model at epoch 0
2023-01-04 06:12:49,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:49,662 INFO:     Epoch: 1
2023-01-04 06:12:51,175 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6575164655844371, 'Total loss': 0.6575164655844371} | train loss {'Reaction outcome loss': 0.6755226846158939, 'Total loss': 0.6755226846158939}
2023-01-04 06:12:51,175 INFO:     Found new best model at epoch 1
2023-01-04 06:12:51,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:51,176 INFO:     Epoch: 2
2023-01-04 06:12:52,682 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5969228545824686, 'Total loss': 0.5969228545824686} | train loss {'Reaction outcome loss': 0.581532521730792, 'Total loss': 0.581532521730792}
2023-01-04 06:12:52,682 INFO:     Found new best model at epoch 2
2023-01-04 06:12:52,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:52,683 INFO:     Epoch: 3
2023-01-04 06:12:54,240 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5695534229278565, 'Total loss': 0.5695534229278565} | train loss {'Reaction outcome loss': 0.5405694028213076, 'Total loss': 0.5405694028213076}
2023-01-04 06:12:54,240 INFO:     Found new best model at epoch 3
2023-01-04 06:12:54,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:54,241 INFO:     Epoch: 4
2023-01-04 06:12:55,802 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5310665190219879, 'Total loss': 0.5310665190219879} | train loss {'Reaction outcome loss': 0.5223318334043461, 'Total loss': 0.5223318334043461}
2023-01-04 06:12:55,802 INFO:     Found new best model at epoch 4
2023-01-04 06:12:55,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:55,803 INFO:     Epoch: 5
2023-01-04 06:12:57,365 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5370647470156352, 'Total loss': 0.5370647470156352} | train loss {'Reaction outcome loss': 0.5070079759198384, 'Total loss': 0.5070079759198384}
2023-01-04 06:12:57,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:57,365 INFO:     Epoch: 6
2023-01-04 06:12:58,911 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5154877682526906, 'Total loss': 0.5154877682526906} | train loss {'Reaction outcome loss': 0.49602309309870657, 'Total loss': 0.49602309309870657}
2023-01-04 06:12:58,911 INFO:     Found new best model at epoch 6
2023-01-04 06:12:58,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:12:58,912 INFO:     Epoch: 7
2023-01-04 06:13:00,455 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5312512834866842, 'Total loss': 0.5312512834866842} | train loss {'Reaction outcome loss': 0.4831565119815569, 'Total loss': 0.4831565119815569}
2023-01-04 06:13:00,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:00,456 INFO:     Epoch: 8
2023-01-04 06:13:01,968 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5064291695753733, 'Total loss': 0.5064291695753733} | train loss {'Reaction outcome loss': 0.4814913356608718, 'Total loss': 0.4814913356608718}
2023-01-04 06:13:01,969 INFO:     Found new best model at epoch 8
2023-01-04 06:13:01,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:01,969 INFO:     Epoch: 9
2023-01-04 06:13:03,506 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4872086226940155, 'Total loss': 0.4872086226940155} | train loss {'Reaction outcome loss': 0.47061148639360484, 'Total loss': 0.47061148639360484}
2023-01-04 06:13:03,506 INFO:     Found new best model at epoch 9
2023-01-04 06:13:03,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:03,507 INFO:     Epoch: 10
2023-01-04 06:13:05,069 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5083496431509654, 'Total loss': 0.5083496431509654} | train loss {'Reaction outcome loss': 0.46250244980528404, 'Total loss': 0.46250244980528404}
2023-01-04 06:13:05,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:05,069 INFO:     Epoch: 11
2023-01-04 06:13:06,611 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49013975660006204, 'Total loss': 0.49013975660006204} | train loss {'Reaction outcome loss': 0.4614948257803917, 'Total loss': 0.4614948257803917}
2023-01-04 06:13:06,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:06,612 INFO:     Epoch: 12
2023-01-04 06:13:08,123 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49947826464970907, 'Total loss': 0.49947826464970907} | train loss {'Reaction outcome loss': 0.45268289989581073, 'Total loss': 0.45268289989581073}
2023-01-04 06:13:08,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:08,123 INFO:     Epoch: 13
2023-01-04 06:13:09,670 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4734415372212728, 'Total loss': 0.4734415372212728} | train loss {'Reaction outcome loss': 0.4532907643783702, 'Total loss': 0.4532907643783702}
2023-01-04 06:13:09,670 INFO:     Found new best model at epoch 13
2023-01-04 06:13:09,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:09,671 INFO:     Epoch: 14
2023-01-04 06:13:11,180 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47690060138702395, 'Total loss': 0.47690060138702395} | train loss {'Reaction outcome loss': 0.4456163611072693, 'Total loss': 0.4456163611072693}
2023-01-04 06:13:11,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:11,181 INFO:     Epoch: 15
2023-01-04 06:13:12,731 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46262223422527315, 'Total loss': 0.46262223422527315} | train loss {'Reaction outcome loss': 0.43956780240592297, 'Total loss': 0.43956780240592297}
2023-01-04 06:13:12,732 INFO:     Found new best model at epoch 15
2023-01-04 06:13:12,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:12,732 INFO:     Epoch: 16
2023-01-04 06:13:14,283 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4766702195008596, 'Total loss': 0.4766702195008596} | train loss {'Reaction outcome loss': 0.43559784621652897, 'Total loss': 0.43559784621652897}
2023-01-04 06:13:14,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:14,284 INFO:     Epoch: 17
2023-01-04 06:13:15,841 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4710133969783783, 'Total loss': 0.4710133969783783} | train loss {'Reaction outcome loss': 0.42995575005120606, 'Total loss': 0.42995575005120606}
2023-01-04 06:13:15,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:15,842 INFO:     Epoch: 18
2023-01-04 06:13:17,352 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5094994882742564, 'Total loss': 0.5094994882742564} | train loss {'Reaction outcome loss': 0.4271026896516772, 'Total loss': 0.4271026896516772}
2023-01-04 06:13:17,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:17,352 INFO:     Epoch: 19
2023-01-04 06:13:18,885 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4909344653288523, 'Total loss': 0.4909344653288523} | train loss {'Reaction outcome loss': 0.42015720014698316, 'Total loss': 0.42015720014698316}
2023-01-04 06:13:18,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:18,886 INFO:     Epoch: 20
2023-01-04 06:13:20,405 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46085864702860513, 'Total loss': 0.46085864702860513} | train loss {'Reaction outcome loss': 0.41870957066434145, 'Total loss': 0.41870957066434145}
2023-01-04 06:13:20,405 INFO:     Found new best model at epoch 20
2023-01-04 06:13:20,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:20,406 INFO:     Epoch: 21
2023-01-04 06:13:21,942 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4730647087097168, 'Total loss': 0.4730647087097168} | train loss {'Reaction outcome loss': 0.41220391944159557, 'Total loss': 0.41220391944159557}
2023-01-04 06:13:21,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:21,943 INFO:     Epoch: 22
2023-01-04 06:13:23,483 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4818253596623739, 'Total loss': 0.4818253596623739} | train loss {'Reaction outcome loss': 0.410399371037518, 'Total loss': 0.410399371037518}
2023-01-04 06:13:23,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:23,483 INFO:     Epoch: 23
2023-01-04 06:13:25,014 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4569065233071645, 'Total loss': 0.4569065233071645} | train loss {'Reaction outcome loss': 0.4064251294318777, 'Total loss': 0.4064251294318777}
2023-01-04 06:13:25,014 INFO:     Found new best model at epoch 23
2023-01-04 06:13:25,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:25,015 INFO:     Epoch: 24
2023-01-04 06:13:26,518 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4859049061934153, 'Total loss': 0.4859049061934153} | train loss {'Reaction outcome loss': 0.3995089647734035, 'Total loss': 0.3995089647734035}
2023-01-04 06:13:26,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:26,518 INFO:     Epoch: 25
2023-01-04 06:13:28,061 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46968008279800416, 'Total loss': 0.46968008279800416} | train loss {'Reaction outcome loss': 0.39873835743561276, 'Total loss': 0.39873835743561276}
2023-01-04 06:13:28,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:28,062 INFO:     Epoch: 26
2023-01-04 06:13:29,612 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4397139767805735, 'Total loss': 0.4397139767805735} | train loss {'Reaction outcome loss': 0.39251649265524247, 'Total loss': 0.39251649265524247}
2023-01-04 06:13:29,612 INFO:     Found new best model at epoch 26
2023-01-04 06:13:29,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:29,613 INFO:     Epoch: 27
2023-01-04 06:13:31,160 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4646395365397135, 'Total loss': 0.4646395365397135} | train loss {'Reaction outcome loss': 0.3882261852930932, 'Total loss': 0.3882261852930932}
2023-01-04 06:13:31,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:31,161 INFO:     Epoch: 28
2023-01-04 06:13:32,732 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4729572763045629, 'Total loss': 0.4729572763045629} | train loss {'Reaction outcome loss': 0.384238286691643, 'Total loss': 0.384238286691643}
2023-01-04 06:13:32,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:32,732 INFO:     Epoch: 29
2023-01-04 06:13:34,274 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45127390523751576, 'Total loss': 0.45127390523751576} | train loss {'Reaction outcome loss': 0.3832634576752673, 'Total loss': 0.3832634576752673}
2023-01-04 06:13:34,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:34,274 INFO:     Epoch: 30
2023-01-04 06:13:35,800 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4859464546044668, 'Total loss': 0.4859464546044668} | train loss {'Reaction outcome loss': 0.37873004730382975, 'Total loss': 0.37873004730382975}
2023-01-04 06:13:35,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:35,801 INFO:     Epoch: 31
2023-01-04 06:13:37,333 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4478049993515015, 'Total loss': 0.4478049993515015} | train loss {'Reaction outcome loss': 0.3745005727901946, 'Total loss': 0.3745005727901946}
2023-01-04 06:13:37,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:37,333 INFO:     Epoch: 32
2023-01-04 06:13:38,918 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4592084387938182, 'Total loss': 0.4592084387938182} | train loss {'Reaction outcome loss': 0.3708513473180959, 'Total loss': 0.3708513473180959}
2023-01-04 06:13:38,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:38,919 INFO:     Epoch: 33
2023-01-04 06:13:40,493 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.457235989967982, 'Total loss': 0.457235989967982} | train loss {'Reaction outcome loss': 0.3655056241546234, 'Total loss': 0.3655056241546234}
2023-01-04 06:13:40,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:40,494 INFO:     Epoch: 34
2023-01-04 06:13:42,061 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46824878056844077, 'Total loss': 0.46824878056844077} | train loss {'Reaction outcome loss': 0.36695055998046033, 'Total loss': 0.36695055998046033}
2023-01-04 06:13:42,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:42,061 INFO:     Epoch: 35
2023-01-04 06:13:43,631 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4414766291777293, 'Total loss': 0.4414766291777293} | train loss {'Reaction outcome loss': 0.36248783223385356, 'Total loss': 0.36248783223385356}
2023-01-04 06:13:43,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:43,631 INFO:     Epoch: 36
2023-01-04 06:13:45,176 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4534469127655029, 'Total loss': 0.4534469127655029} | train loss {'Reaction outcome loss': 0.35916263017341166, 'Total loss': 0.35916263017341166}
2023-01-04 06:13:45,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:45,177 INFO:     Epoch: 37
2023-01-04 06:13:46,726 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45224407116572063, 'Total loss': 0.45224407116572063} | train loss {'Reaction outcome loss': 0.3586873911919385, 'Total loss': 0.3586873911919385}
2023-01-04 06:13:46,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:46,726 INFO:     Epoch: 38
2023-01-04 06:13:48,294 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46412581006685893, 'Total loss': 0.46412581006685893} | train loss {'Reaction outcome loss': 0.35335152710441253, 'Total loss': 0.35335152710441253}
2023-01-04 06:13:48,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:48,294 INFO:     Epoch: 39
2023-01-04 06:13:49,855 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43369420170783995, 'Total loss': 0.43369420170783995} | train loss {'Reaction outcome loss': 0.34876999354166704, 'Total loss': 0.34876999354166704}
2023-01-04 06:13:49,856 INFO:     Found new best model at epoch 39
2023-01-04 06:13:49,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:49,856 INFO:     Epoch: 40
2023-01-04 06:13:51,408 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47189549009005227, 'Total loss': 0.47189549009005227} | train loss {'Reaction outcome loss': 0.3478541740753355, 'Total loss': 0.3478541740753355}
2023-01-04 06:13:51,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:51,409 INFO:     Epoch: 41
2023-01-04 06:13:52,968 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4869338969389598, 'Total loss': 0.4869338969389598} | train loss {'Reaction outcome loss': 0.3409162107991041, 'Total loss': 0.3409162107991041}
2023-01-04 06:13:52,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:52,968 INFO:     Epoch: 42
2023-01-04 06:13:54,490 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.442618524034818, 'Total loss': 0.442618524034818} | train loss {'Reaction outcome loss': 0.3379521122487792, 'Total loss': 0.3379521122487792}
2023-01-04 06:13:54,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:54,491 INFO:     Epoch: 43
2023-01-04 06:13:56,022 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47410934964815776, 'Total loss': 0.47410934964815776} | train loss {'Reaction outcome loss': 0.3367966604928901, 'Total loss': 0.3367966604928901}
2023-01-04 06:13:56,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:56,023 INFO:     Epoch: 44
2023-01-04 06:13:57,585 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45353678489724797, 'Total loss': 0.45353678489724797} | train loss {'Reaction outcome loss': 0.33734140651178185, 'Total loss': 0.33734140651178185}
2023-01-04 06:13:57,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:57,585 INFO:     Epoch: 45
2023-01-04 06:13:59,136 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42731305907169975, 'Total loss': 0.42731305907169975} | train loss {'Reaction outcome loss': 0.33309765576119843, 'Total loss': 0.33309765576119843}
2023-01-04 06:13:59,136 INFO:     Found new best model at epoch 45
2023-01-04 06:13:59,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:13:59,137 INFO:     Epoch: 46
2023-01-04 06:14:00,686 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43953097860018414, 'Total loss': 0.43953097860018414} | train loss {'Reaction outcome loss': 0.3323027672667573, 'Total loss': 0.3323027672667573}
2023-01-04 06:14:00,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:00,686 INFO:     Epoch: 47
2023-01-04 06:14:02,228 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42359697620073955, 'Total loss': 0.42359697620073955} | train loss {'Reaction outcome loss': 0.33101675335834496, 'Total loss': 0.33101675335834496}
2023-01-04 06:14:02,230 INFO:     Found new best model at epoch 47
2023-01-04 06:14:02,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:02,230 INFO:     Epoch: 48
2023-01-04 06:14:03,736 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4475376635789871, 'Total loss': 0.4475376635789871} | train loss {'Reaction outcome loss': 0.32322949388601485, 'Total loss': 0.32322949388601485}
2023-01-04 06:14:03,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:03,736 INFO:     Epoch: 49
2023-01-04 06:14:05,248 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.413596090922753, 'Total loss': 0.413596090922753} | train loss {'Reaction outcome loss': 0.32066164168454436, 'Total loss': 0.32066164168454436}
2023-01-04 06:14:05,248 INFO:     Found new best model at epoch 49
2023-01-04 06:14:05,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:05,249 INFO:     Epoch: 50
2023-01-04 06:14:06,780 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44411588708559674, 'Total loss': 0.44411588708559674} | train loss {'Reaction outcome loss': 0.3158193878883863, 'Total loss': 0.3158193878883863}
2023-01-04 06:14:06,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:06,780 INFO:     Epoch: 51
2023-01-04 06:14:08,337 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4687018483877182, 'Total loss': 0.4687018483877182} | train loss {'Reaction outcome loss': 0.3170459233496311, 'Total loss': 0.3170459233496311}
2023-01-04 06:14:08,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:08,338 INFO:     Epoch: 52
2023-01-04 06:14:09,878 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44346936270594595, 'Total loss': 0.44346936270594595} | train loss {'Reaction outcome loss': 0.3175295311549719, 'Total loss': 0.3175295311549719}
2023-01-04 06:14:09,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:09,878 INFO:     Epoch: 53
2023-01-04 06:14:11,435 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4546930571397146, 'Total loss': 0.4546930571397146} | train loss {'Reaction outcome loss': 0.31327077637623696, 'Total loss': 0.31327077637623696}
2023-01-04 06:14:11,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:11,435 INFO:     Epoch: 54
2023-01-04 06:14:12,962 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4477824568748474, 'Total loss': 0.4477824568748474} | train loss {'Reaction outcome loss': 0.315903694606828, 'Total loss': 0.315903694606828}
2023-01-04 06:14:12,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:12,962 INFO:     Epoch: 55
2023-01-04 06:14:14,485 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47205001711845396, 'Total loss': 0.47205001711845396} | train loss {'Reaction outcome loss': 0.3094643640202762, 'Total loss': 0.3094643640202762}
2023-01-04 06:14:14,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:14,485 INFO:     Epoch: 56
2023-01-04 06:14:16,043 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4384575754404068, 'Total loss': 0.4384575754404068} | train loss {'Reaction outcome loss': 0.31015526478851796, 'Total loss': 0.31015526478851796}
2023-01-04 06:14:16,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:16,044 INFO:     Epoch: 57
2023-01-04 06:14:17,617 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44138987759749093, 'Total loss': 0.44138987759749093} | train loss {'Reaction outcome loss': 0.3090626728197519, 'Total loss': 0.3090626728197519}
2023-01-04 06:14:17,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:17,617 INFO:     Epoch: 58
2023-01-04 06:14:19,167 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4407065729300181, 'Total loss': 0.4407065729300181} | train loss {'Reaction outcome loss': 0.30282745385257, 'Total loss': 0.30282745385257}
2023-01-04 06:14:19,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:19,168 INFO:     Epoch: 59
2023-01-04 06:14:20,685 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44336379766464235, 'Total loss': 0.44336379766464235} | train loss {'Reaction outcome loss': 0.2999778292583723, 'Total loss': 0.2999778292583723}
2023-01-04 06:14:20,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:20,686 INFO:     Epoch: 60
2023-01-04 06:14:22,233 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44135359724362694, 'Total loss': 0.44135359724362694} | train loss {'Reaction outcome loss': 0.30114974524744237, 'Total loss': 0.30114974524744237}
2023-01-04 06:14:22,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:22,234 INFO:     Epoch: 61
2023-01-04 06:14:23,759 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4456424355506897, 'Total loss': 0.4456424355506897} | train loss {'Reaction outcome loss': 0.2984305347050846, 'Total loss': 0.2984305347050846}
2023-01-04 06:14:23,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:23,759 INFO:     Epoch: 62
2023-01-04 06:14:25,304 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4465097059806188, 'Total loss': 0.4465097059806188} | train loss {'Reaction outcome loss': 0.2928065679641101, 'Total loss': 0.2928065679641101}
2023-01-04 06:14:25,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:25,305 INFO:     Epoch: 63
2023-01-04 06:14:26,868 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4280092517534892, 'Total loss': 0.4280092517534892} | train loss {'Reaction outcome loss': 0.2939256095211871, 'Total loss': 0.2939256095211871}
2023-01-04 06:14:26,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:26,869 INFO:     Epoch: 64
2023-01-04 06:14:28,424 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4210619181394577, 'Total loss': 0.4210619181394577} | train loss {'Reaction outcome loss': 0.2931932415405329, 'Total loss': 0.2931932415405329}
2023-01-04 06:14:28,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:28,424 INFO:     Epoch: 65
2023-01-04 06:14:29,956 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.417346994082133, 'Total loss': 0.417346994082133} | train loss {'Reaction outcome loss': 0.2918827694969891, 'Total loss': 0.2918827694969891}
2023-01-04 06:14:29,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:29,956 INFO:     Epoch: 66
2023-01-04 06:14:31,503 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4433656255404154, 'Total loss': 0.4433656255404154} | train loss {'Reaction outcome loss': 0.28958259705100614, 'Total loss': 0.28958259705100614}
2023-01-04 06:14:31,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:31,503 INFO:     Epoch: 67
2023-01-04 06:14:33,048 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41578799883524575, 'Total loss': 0.41578799883524575} | train loss {'Reaction outcome loss': 0.28559562746081907, 'Total loss': 0.28559562746081907}
2023-01-04 06:14:33,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:33,049 INFO:     Epoch: 68
2023-01-04 06:14:34,617 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4354453027248383, 'Total loss': 0.4354453027248383} | train loss {'Reaction outcome loss': 0.2852028002486612, 'Total loss': 0.2852028002486612}
2023-01-04 06:14:34,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:34,617 INFO:     Epoch: 69
2023-01-04 06:14:36,157 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4559175093968709, 'Total loss': 0.4559175093968709} | train loss {'Reaction outcome loss': 0.2829363924471566, 'Total loss': 0.2829363924471566}
2023-01-04 06:14:36,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:36,157 INFO:     Epoch: 70
2023-01-04 06:14:37,720 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42958455085754393, 'Total loss': 0.42958455085754393} | train loss {'Reaction outcome loss': 0.27880550988943037, 'Total loss': 0.27880550988943037}
2023-01-04 06:14:37,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:37,720 INFO:     Epoch: 71
2023-01-04 06:14:39,227 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4216861774524053, 'Total loss': 0.4216861774524053} | train loss {'Reaction outcome loss': 0.2804342295403463, 'Total loss': 0.2804342295403463}
2023-01-04 06:14:39,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:39,227 INFO:     Epoch: 72
2023-01-04 06:14:40,739 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44651962916056315, 'Total loss': 0.44651962916056315} | train loss {'Reaction outcome loss': 0.2835855189520512, 'Total loss': 0.2835855189520512}
2023-01-04 06:14:40,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:40,739 INFO:     Epoch: 73
2023-01-04 06:14:42,306 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4174499213695526, 'Total loss': 0.4174499213695526} | train loss {'Reaction outcome loss': 0.28162842999844656, 'Total loss': 0.28162842999844656}
2023-01-04 06:14:42,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:42,307 INFO:     Epoch: 74
2023-01-04 06:14:43,882 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.440867163737615, 'Total loss': 0.440867163737615} | train loss {'Reaction outcome loss': 0.27603667803163073, 'Total loss': 0.27603667803163073}
2023-01-04 06:14:43,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:43,882 INFO:     Epoch: 75
2023-01-04 06:14:45,436 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4357105334599813, 'Total loss': 0.4357105334599813} | train loss {'Reaction outcome loss': 0.2764017624223102, 'Total loss': 0.2764017624223102}
2023-01-04 06:14:45,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:45,436 INFO:     Epoch: 76
2023-01-04 06:14:46,998 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43402713934580484, 'Total loss': 0.43402713934580484} | train loss {'Reaction outcome loss': 0.27206745537093086, 'Total loss': 0.27206745537093086}
2023-01-04 06:14:46,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:46,998 INFO:     Epoch: 77
2023-01-04 06:14:48,519 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42984309792518616, 'Total loss': 0.42984309792518616} | train loss {'Reaction outcome loss': 0.2707735262539265, 'Total loss': 0.2707735262539265}
2023-01-04 06:14:48,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:48,519 INFO:     Epoch: 78
2023-01-04 06:14:50,027 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44958949089050293, 'Total loss': 0.44958949089050293} | train loss {'Reaction outcome loss': 0.26806831263332037, 'Total loss': 0.26806831263332037}
2023-01-04 06:14:50,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:50,027 INFO:     Epoch: 79
2023-01-04 06:14:51,575 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43971361219882965, 'Total loss': 0.43971361219882965} | train loss {'Reaction outcome loss': 0.2688462170262406, 'Total loss': 0.2688462170262406}
2023-01-04 06:14:51,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:51,576 INFO:     Epoch: 80
2023-01-04 06:14:53,128 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4455564424395561, 'Total loss': 0.4455564424395561} | train loss {'Reaction outcome loss': 0.27088095756234043, 'Total loss': 0.27088095756234043}
2023-01-04 06:14:53,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:53,128 INFO:     Epoch: 81
2023-01-04 06:14:54,679 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4489979147911072, 'Total loss': 0.4489979147911072} | train loss {'Reaction outcome loss': 0.26532720208820637, 'Total loss': 0.26532720208820637}
2023-01-04 06:14:54,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:54,679 INFO:     Epoch: 82
2023-01-04 06:14:56,230 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42264938751856485, 'Total loss': 0.42264938751856485} | train loss {'Reaction outcome loss': 0.26799484581625377, 'Total loss': 0.26799484581625377}
2023-01-04 06:14:56,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:56,230 INFO:     Epoch: 83
2023-01-04 06:14:57,750 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40934394697348275, 'Total loss': 0.40934394697348275} | train loss {'Reaction outcome loss': 0.2679728659508872, 'Total loss': 0.2679728659508872}
2023-01-04 06:14:57,750 INFO:     Found new best model at epoch 83
2023-01-04 06:14:57,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:57,751 INFO:     Epoch: 84
2023-01-04 06:14:59,291 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41828843553860984, 'Total loss': 0.41828843553860984} | train loss {'Reaction outcome loss': 0.26447796874618446, 'Total loss': 0.26447796874618446}
2023-01-04 06:14:59,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:14:59,291 INFO:     Epoch: 85
2023-01-04 06:15:00,855 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4527125358581543, 'Total loss': 0.4527125358581543} | train loss {'Reaction outcome loss': 0.26515768558113245, 'Total loss': 0.26515768558113245}
2023-01-04 06:15:00,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:00,855 INFO:     Epoch: 86
2023-01-04 06:15:02,397 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4191324586669604, 'Total loss': 0.4191324586669604} | train loss {'Reaction outcome loss': 0.2638261576529837, 'Total loss': 0.2638261576529837}
2023-01-04 06:15:02,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:02,397 INFO:     Epoch: 87
2023-01-04 06:15:03,948 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40191820164521536, 'Total loss': 0.40191820164521536} | train loss {'Reaction outcome loss': 0.26316315876523944, 'Total loss': 0.26316315876523944}
2023-01-04 06:15:03,950 INFO:     Found new best model at epoch 87
2023-01-04 06:15:03,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:03,950 INFO:     Epoch: 88
2023-01-04 06:15:05,515 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41495566864808403, 'Total loss': 0.41495566864808403} | train loss {'Reaction outcome loss': 0.25843188777076503, 'Total loss': 0.25843188777076503}
2023-01-04 06:15:05,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:05,515 INFO:     Epoch: 89
2023-01-04 06:15:07,041 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43922157883644103, 'Total loss': 0.43922157883644103} | train loss {'Reaction outcome loss': 0.2576730445326462, 'Total loss': 0.2576730445326462}
2023-01-04 06:15:07,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:07,041 INFO:     Epoch: 90
2023-01-04 06:15:08,574 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4129448145627975, 'Total loss': 0.4129448145627975} | train loss {'Reaction outcome loss': 0.263490277695993, 'Total loss': 0.263490277695993}
2023-01-04 06:15:08,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:08,574 INFO:     Epoch: 91
2023-01-04 06:15:10,131 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4188726524511973, 'Total loss': 0.4188726524511973} | train loss {'Reaction outcome loss': 0.2541153677297335, 'Total loss': 0.2541153677297335}
2023-01-04 06:15:10,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:10,132 INFO:     Epoch: 92
2023-01-04 06:15:11,684 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.422970375418663, 'Total loss': 0.422970375418663} | train loss {'Reaction outcome loss': 0.25524086306673766, 'Total loss': 0.25524086306673766}
2023-01-04 06:15:11,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:11,684 INFO:     Epoch: 93
2023-01-04 06:15:13,247 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4760838995377223, 'Total loss': 0.4760838995377223} | train loss {'Reaction outcome loss': 0.2554615028066574, 'Total loss': 0.2554615028066574}
2023-01-04 06:15:13,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:13,247 INFO:     Epoch: 94
2023-01-04 06:15:14,811 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4246243526538213, 'Total loss': 0.4246243526538213} | train loss {'Reaction outcome loss': 0.2563827846770304, 'Total loss': 0.2563827846770304}
2023-01-04 06:15:14,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:14,811 INFO:     Epoch: 95
2023-01-04 06:15:16,368 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43450716038544973, 'Total loss': 0.43450716038544973} | train loss {'Reaction outcome loss': 0.2493039134101276, 'Total loss': 0.2493039134101276}
2023-01-04 06:15:16,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:16,368 INFO:     Epoch: 96
2023-01-04 06:15:17,913 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42335112392902374, 'Total loss': 0.42335112392902374} | train loss {'Reaction outcome loss': 0.24669563940243563, 'Total loss': 0.24669563940243563}
2023-01-04 06:15:17,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:17,913 INFO:     Epoch: 97
2023-01-04 06:15:19,475 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.421691757440567, 'Total loss': 0.421691757440567} | train loss {'Reaction outcome loss': 0.25134274858410344, 'Total loss': 0.25134274858410344}
2023-01-04 06:15:19,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:19,475 INFO:     Epoch: 98
2023-01-04 06:15:21,033 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4291850835084915, 'Total loss': 0.4291850835084915} | train loss {'Reaction outcome loss': 0.25558534237372615, 'Total loss': 0.25558534237372615}
2023-01-04 06:15:21,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:21,033 INFO:     Epoch: 99
2023-01-04 06:15:22,589 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4332073489824931, 'Total loss': 0.4332073489824931} | train loss {'Reaction outcome loss': 0.24942224535302523, 'Total loss': 0.24942224535302523}
2023-01-04 06:15:22,590 INFO:     Best model found after epoch 88 of 100.
2023-01-04 06:15:22,590 INFO:   Done with stage: TRAINING
2023-01-04 06:15:22,590 INFO:   Starting stage: EVALUATION
2023-01-04 06:15:22,725 INFO:   Done with stage: EVALUATION
2023-01-04 06:15:22,725 INFO:   Leaving out SEQ value Fold_5
2023-01-04 06:15:22,737 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 06:15:22,737 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:15:23,390 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:15:23,390 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:15:23,460 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:15:23,460 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:15:23,460 INFO:     No hyperparam tuning for this model
2023-01-04 06:15:23,460 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:15:23,460 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:15:23,461 INFO:     None feature selector for col prot
2023-01-04 06:15:23,461 INFO:     None feature selector for col prot
2023-01-04 06:15:23,461 INFO:     None feature selector for col prot
2023-01-04 06:15:23,462 INFO:     None feature selector for col chem
2023-01-04 06:15:23,462 INFO:     None feature selector for col chem
2023-01-04 06:15:23,462 INFO:     None feature selector for col chem
2023-01-04 06:15:23,462 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:15:23,462 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:15:23,463 INFO:     Number of params in model 70111
2023-01-04 06:15:23,466 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:15:23,466 INFO:   Starting stage: TRAINING
2023-01-04 06:15:23,510 INFO:     Val loss before train {'Reaction outcome loss': 1.0861644983291625, 'Total loss': 1.0861644983291625}
2023-01-04 06:15:23,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:23,510 INFO:     Epoch: 0
2023-01-04 06:15:25,046 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8272330323855083, 'Total loss': 0.8272330323855083} | train loss {'Reaction outcome loss': 0.8669663149377574, 'Total loss': 0.8669663149377574}
2023-01-04 06:15:25,046 INFO:     Found new best model at epoch 0
2023-01-04 06:15:25,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:25,047 INFO:     Epoch: 1
2023-01-04 06:15:26,574 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7053305188814799, 'Total loss': 0.7053305188814799} | train loss {'Reaction outcome loss': 0.7346406276675238, 'Total loss': 0.7346406276675238}
2023-01-04 06:15:26,574 INFO:     Found new best model at epoch 1
2023-01-04 06:15:26,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:26,575 INFO:     Epoch: 2
2023-01-04 06:15:28,126 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6472187320391337, 'Total loss': 0.6472187320391337} | train loss {'Reaction outcome loss': 0.6667579778510592, 'Total loss': 0.6667579778510592}
2023-01-04 06:15:28,126 INFO:     Found new best model at epoch 2
2023-01-04 06:15:28,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:28,127 INFO:     Epoch: 3
2023-01-04 06:15:29,702 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6051358838876089, 'Total loss': 0.6051358838876089} | train loss {'Reaction outcome loss': 0.6075248812203822, 'Total loss': 0.6075248812203822}
2023-01-04 06:15:29,702 INFO:     Found new best model at epoch 3
2023-01-04 06:15:29,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:29,703 INFO:     Epoch: 4
2023-01-04 06:15:31,265 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5890726586182912, 'Total loss': 0.5890726586182912} | train loss {'Reaction outcome loss': 0.5587746785663447, 'Total loss': 0.5587746785663447}
2023-01-04 06:15:31,265 INFO:     Found new best model at epoch 4
2023-01-04 06:15:31,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:31,266 INFO:     Epoch: 5
2023-01-04 06:15:32,831 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5490890085697174, 'Total loss': 0.5490890085697174} | train loss {'Reaction outcome loss': 0.5283371989676, 'Total loss': 0.5283371989676}
2023-01-04 06:15:32,831 INFO:     Found new best model at epoch 5
2023-01-04 06:15:32,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:32,832 INFO:     Epoch: 6
2023-01-04 06:15:34,376 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.552472980817159, 'Total loss': 0.552472980817159} | train loss {'Reaction outcome loss': 0.5203260509432226, 'Total loss': 0.5203260509432226}
2023-01-04 06:15:34,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:34,378 INFO:     Epoch: 7
2023-01-04 06:15:35,904 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5424836854139964, 'Total loss': 0.5424836854139964} | train loss {'Reaction outcome loss': 0.5051559267221424, 'Total loss': 0.5051559267221424}
2023-01-04 06:15:35,904 INFO:     Found new best model at epoch 7
2023-01-04 06:15:35,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:35,904 INFO:     Epoch: 8
2023-01-04 06:15:37,480 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5202025632063548, 'Total loss': 0.5202025632063548} | train loss {'Reaction outcome loss': 0.49442203952998354, 'Total loss': 0.49442203952998354}
2023-01-04 06:15:37,480 INFO:     Found new best model at epoch 8
2023-01-04 06:15:37,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:37,481 INFO:     Epoch: 9
2023-01-04 06:15:39,045 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5374972283840179, 'Total loss': 0.5374972283840179} | train loss {'Reaction outcome loss': 0.48971928797444614, 'Total loss': 0.48971928797444614}
2023-01-04 06:15:39,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:39,045 INFO:     Epoch: 10
2023-01-04 06:15:40,604 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.502322777112325, 'Total loss': 0.502322777112325} | train loss {'Reaction outcome loss': 0.4788081757893003, 'Total loss': 0.4788081757893003}
2023-01-04 06:15:40,605 INFO:     Found new best model at epoch 10
2023-01-04 06:15:40,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:40,606 INFO:     Epoch: 11
2023-01-04 06:15:42,127 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5111831386884054, 'Total loss': 0.5111831386884054} | train loss {'Reaction outcome loss': 0.4708896663336866, 'Total loss': 0.4708896663336866}
2023-01-04 06:15:42,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:42,128 INFO:     Epoch: 12
2023-01-04 06:15:43,728 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5193579743305842, 'Total loss': 0.5193579743305842} | train loss {'Reaction outcome loss': 0.46875586204122804, 'Total loss': 0.46875586204122804}
2023-01-04 06:15:43,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:43,728 INFO:     Epoch: 13
2023-01-04 06:15:45,303 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5176373720169067, 'Total loss': 0.5176373720169067} | train loss {'Reaction outcome loss': 0.45994388395785424, 'Total loss': 0.45994388395785424}
2023-01-04 06:15:45,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:45,303 INFO:     Epoch: 14
2023-01-04 06:15:46,906 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49873049557209015, 'Total loss': 0.49873049557209015} | train loss {'Reaction outcome loss': 0.4556338169436524, 'Total loss': 0.4556338169436524}
2023-01-04 06:15:46,906 INFO:     Found new best model at epoch 14
2023-01-04 06:15:46,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:46,907 INFO:     Epoch: 15
2023-01-04 06:15:48,484 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49374416867891946, 'Total loss': 0.49374416867891946} | train loss {'Reaction outcome loss': 0.4493658948905658, 'Total loss': 0.4493658948905658}
2023-01-04 06:15:48,484 INFO:     Found new best model at epoch 15
2023-01-04 06:15:48,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:48,485 INFO:     Epoch: 16
2023-01-04 06:15:50,078 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5042653381824493, 'Total loss': 0.5042653381824493} | train loss {'Reaction outcome loss': 0.442508469970114, 'Total loss': 0.442508469970114}
2023-01-04 06:15:50,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:50,078 INFO:     Epoch: 17
2023-01-04 06:15:51,633 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4879744013150533, 'Total loss': 0.4879744013150533} | train loss {'Reaction outcome loss': 0.44361665547594253, 'Total loss': 0.44361665547594253}
2023-01-04 06:15:51,633 INFO:     Found new best model at epoch 17
2023-01-04 06:15:51,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:51,634 INFO:     Epoch: 18
2023-01-04 06:15:53,177 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48772577444712323, 'Total loss': 0.48772577444712323} | train loss {'Reaction outcome loss': 0.4354779470612403, 'Total loss': 0.4354779470612403}
2023-01-04 06:15:53,178 INFO:     Found new best model at epoch 18
2023-01-04 06:15:53,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:53,179 INFO:     Epoch: 19
2023-01-04 06:15:54,756 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45921124120553336, 'Total loss': 0.45921124120553336} | train loss {'Reaction outcome loss': 0.43174038490321004, 'Total loss': 0.43174038490321004}
2023-01-04 06:15:54,756 INFO:     Found new best model at epoch 19
2023-01-04 06:15:54,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:54,757 INFO:     Epoch: 20
2023-01-04 06:15:56,330 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4730324258406957, 'Total loss': 0.4730324258406957} | train loss {'Reaction outcome loss': 0.4256752548196043, 'Total loss': 0.4256752548196043}
2023-01-04 06:15:56,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:56,330 INFO:     Epoch: 21
2023-01-04 06:15:57,917 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4767351865768433, 'Total loss': 0.4767351865768433} | train loss {'Reaction outcome loss': 0.423037109096818, 'Total loss': 0.423037109096818}
2023-01-04 06:15:57,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:57,917 INFO:     Epoch: 22
2023-01-04 06:15:59,519 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48868821461995443, 'Total loss': 0.48868821461995443} | train loss {'Reaction outcome loss': 0.41949606211721036, 'Total loss': 0.41949606211721036}
2023-01-04 06:15:59,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:15:59,519 INFO:     Epoch: 23
2023-01-04 06:16:01,093 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4711234629154205, 'Total loss': 0.4711234629154205} | train loss {'Reaction outcome loss': 0.41402725254495937, 'Total loss': 0.41402725254495937}
2023-01-04 06:16:01,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:01,094 INFO:     Epoch: 24
2023-01-04 06:16:02,631 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4690119981765747, 'Total loss': 0.4690119981765747} | train loss {'Reaction outcome loss': 0.41231797526479175, 'Total loss': 0.41231797526479175}
2023-01-04 06:16:02,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:02,631 INFO:     Epoch: 25
2023-01-04 06:16:04,205 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47534817655881245, 'Total loss': 0.47534817655881245} | train loss {'Reaction outcome loss': 0.40325064638244035, 'Total loss': 0.40325064638244035}
2023-01-04 06:16:04,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:04,205 INFO:     Epoch: 26
2023-01-04 06:16:05,807 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4800532648960749, 'Total loss': 0.4800532648960749} | train loss {'Reaction outcome loss': 0.4029431862729615, 'Total loss': 0.4029431862729615}
2023-01-04 06:16:05,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:05,808 INFO:     Epoch: 27
2023-01-04 06:16:07,402 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45522058407465615, 'Total loss': 0.45522058407465615} | train loss {'Reaction outcome loss': 0.39936248819108383, 'Total loss': 0.39936248819108383}
2023-01-04 06:16:07,402 INFO:     Found new best model at epoch 27
2023-01-04 06:16:07,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:07,403 INFO:     Epoch: 28
2023-01-04 06:16:09,004 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5114684998989105, 'Total loss': 0.5114684998989105} | train loss {'Reaction outcome loss': 0.39540565332424815, 'Total loss': 0.39540565332424815}
2023-01-04 06:16:09,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:09,004 INFO:     Epoch: 29
2023-01-04 06:16:10,547 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46227667133013406, 'Total loss': 0.46227667133013406} | train loss {'Reaction outcome loss': 0.3951799488369969, 'Total loss': 0.3951799488369969}
2023-01-04 06:16:10,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:10,548 INFO:     Epoch: 30
2023-01-04 06:16:12,077 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4589228590329488, 'Total loss': 0.4589228590329488} | train loss {'Reaction outcome loss': 0.40563313560425374, 'Total loss': 0.40563313560425374}
2023-01-04 06:16:12,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:12,078 INFO:     Epoch: 31
2023-01-04 06:16:13,645 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4710277398427328, 'Total loss': 0.4710277398427328} | train loss {'Reaction outcome loss': 0.40896126355274, 'Total loss': 0.40896126355274}
2023-01-04 06:16:13,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:13,645 INFO:     Epoch: 32
2023-01-04 06:16:15,216 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45151819189389547, 'Total loss': 0.45151819189389547} | train loss {'Reaction outcome loss': 0.387223659866098, 'Total loss': 0.387223659866098}
2023-01-04 06:16:15,216 INFO:     Found new best model at epoch 32
2023-01-04 06:16:15,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:15,217 INFO:     Epoch: 33
2023-01-04 06:16:16,786 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4564926564693451, 'Total loss': 0.4564926564693451} | train loss {'Reaction outcome loss': 0.3767946277731571, 'Total loss': 0.3767946277731571}
2023-01-04 06:16:16,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:16,787 INFO:     Epoch: 34
2023-01-04 06:16:18,364 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48048953811327616, 'Total loss': 0.48048953811327616} | train loss {'Reaction outcome loss': 0.3916473713150059, 'Total loss': 0.3916473713150059}
2023-01-04 06:16:18,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:18,364 INFO:     Epoch: 35
2023-01-04 06:16:19,960 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45083165864149727, 'Total loss': 0.45083165864149727} | train loss {'Reaction outcome loss': 0.39425122249277605, 'Total loss': 0.39425122249277605}
2023-01-04 06:16:19,961 INFO:     Found new best model at epoch 35
2023-01-04 06:16:19,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:19,961 INFO:     Epoch: 36
2023-01-04 06:16:21,496 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4577783813079198, 'Total loss': 0.4577783813079198} | train loss {'Reaction outcome loss': 0.37007740029282327, 'Total loss': 0.37007740029282327}
2023-01-04 06:16:21,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:21,496 INFO:     Epoch: 37
2023-01-04 06:16:23,068 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4492480436960856, 'Total loss': 0.4492480436960856} | train loss {'Reaction outcome loss': 0.3649973761074353, 'Total loss': 0.3649973761074353}
2023-01-04 06:16:23,068 INFO:     Found new best model at epoch 37
2023-01-04 06:16:23,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:23,069 INFO:     Epoch: 38
2023-01-04 06:16:24,624 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4418750216563543, 'Total loss': 0.4418750216563543} | train loss {'Reaction outcome loss': 0.36323167153877084, 'Total loss': 0.36323167153877084}
2023-01-04 06:16:24,624 INFO:     Found new best model at epoch 38
2023-01-04 06:16:24,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:24,625 INFO:     Epoch: 39
2023-01-04 06:16:26,183 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4392046943306923, 'Total loss': 0.4392046943306923} | train loss {'Reaction outcome loss': 0.3625479983030886, 'Total loss': 0.3625479983030886}
2023-01-04 06:16:26,183 INFO:     Found new best model at epoch 39
2023-01-04 06:16:26,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:26,184 INFO:     Epoch: 40
2023-01-04 06:16:27,704 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4576146642367045, 'Total loss': 0.4576146642367045} | train loss {'Reaction outcome loss': 0.37606577070402925, 'Total loss': 0.37606577070402925}
2023-01-04 06:16:27,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:27,705 INFO:     Epoch: 41
2023-01-04 06:16:29,285 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4256804496049881, 'Total loss': 0.4256804496049881} | train loss {'Reaction outcome loss': 0.36012084822615853, 'Total loss': 0.36012084822615853}
2023-01-04 06:16:29,286 INFO:     Found new best model at epoch 41
2023-01-04 06:16:29,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:29,286 INFO:     Epoch: 42
2023-01-04 06:16:30,846 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4157996823390325, 'Total loss': 0.4157996823390325} | train loss {'Reaction outcome loss': 0.3494803787578586, 'Total loss': 0.3494803787578586}
2023-01-04 06:16:30,846 INFO:     Found new best model at epoch 42
2023-01-04 06:16:30,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:30,847 INFO:     Epoch: 43
2023-01-04 06:16:32,422 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42786043683687847, 'Total loss': 0.42786043683687847} | train loss {'Reaction outcome loss': 0.35050515546395944, 'Total loss': 0.35050515546395944}
2023-01-04 06:16:32,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:32,423 INFO:     Epoch: 44
2023-01-04 06:16:33,974 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4396259476741155, 'Total loss': 0.4396259476741155} | train loss {'Reaction outcome loss': 0.3478654169248066, 'Total loss': 0.3478654169248066}
2023-01-04 06:16:33,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:33,974 INFO:     Epoch: 45
2023-01-04 06:16:35,519 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41766146222750344, 'Total loss': 0.41766146222750344} | train loss {'Reaction outcome loss': 0.34773948260176374, 'Total loss': 0.34773948260176374}
2023-01-04 06:16:35,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:35,519 INFO:     Epoch: 46
2023-01-04 06:16:37,064 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4214544951915741, 'Total loss': 0.4214544951915741} | train loss {'Reaction outcome loss': 0.3436263956642453, 'Total loss': 0.3436263956642453}
2023-01-04 06:16:37,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:37,064 INFO:     Epoch: 47
2023-01-04 06:16:38,613 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43030462761720023, 'Total loss': 0.43030462761720023} | train loss {'Reaction outcome loss': 0.3401004299521446, 'Total loss': 0.3401004299521446}
2023-01-04 06:16:38,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:38,613 INFO:     Epoch: 48
2023-01-04 06:16:40,178 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4300455113252004, 'Total loss': 0.4300455113252004} | train loss {'Reaction outcome loss': 0.3384364781752769, 'Total loss': 0.3384364781752769}
2023-01-04 06:16:40,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:40,179 INFO:     Epoch: 49
2023-01-04 06:16:41,759 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4229622075955073, 'Total loss': 0.4229622075955073} | train loss {'Reaction outcome loss': 0.3355467518440623, 'Total loss': 0.3355467518440623}
2023-01-04 06:16:41,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:41,760 INFO:     Epoch: 50
2023-01-04 06:16:43,319 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4384929100672404, 'Total loss': 0.4384929100672404} | train loss {'Reaction outcome loss': 0.33335679873108753, 'Total loss': 0.33335679873108753}
2023-01-04 06:16:43,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:43,319 INFO:     Epoch: 51
2023-01-04 06:16:44,898 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45585886339346565, 'Total loss': 0.45585886339346565} | train loss {'Reaction outcome loss': 0.32758763996526546, 'Total loss': 0.32758763996526546}
2023-01-04 06:16:44,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:44,899 INFO:     Epoch: 52
2023-01-04 06:16:46,440 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44429991245269773, 'Total loss': 0.44429991245269773} | train loss {'Reaction outcome loss': 0.33327393252672494, 'Total loss': 0.33327393252672494}
2023-01-04 06:16:46,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:46,440 INFO:     Epoch: 53
2023-01-04 06:16:47,982 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45182333985964457, 'Total loss': 0.45182333985964457} | train loss {'Reaction outcome loss': 0.3240929793484637, 'Total loss': 0.3240929793484637}
2023-01-04 06:16:47,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:47,983 INFO:     Epoch: 54
2023-01-04 06:16:49,577 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4228858490784963, 'Total loss': 0.4228858490784963} | train loss {'Reaction outcome loss': 0.3232122101564554, 'Total loss': 0.3232122101564554}
2023-01-04 06:16:49,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:49,577 INFO:     Epoch: 55
2023-01-04 06:16:51,167 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4008968452612559, 'Total loss': 0.4008968452612559} | train loss {'Reaction outcome loss': 0.32123743260064225, 'Total loss': 0.32123743260064225}
2023-01-04 06:16:51,168 INFO:     Found new best model at epoch 55
2023-01-04 06:16:51,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:51,168 INFO:     Epoch: 56
2023-01-04 06:16:52,745 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43705563644568124, 'Total loss': 0.43705563644568124} | train loss {'Reaction outcome loss': 0.32404267636277084, 'Total loss': 0.32404267636277084}
2023-01-04 06:16:52,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:52,745 INFO:     Epoch: 57
2023-01-04 06:16:54,313 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41534496545791627, 'Total loss': 0.41534496545791627} | train loss {'Reaction outcome loss': 0.31695488753958023, 'Total loss': 0.31695488753958023}
2023-01-04 06:16:54,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:54,313 INFO:     Epoch: 58
2023-01-04 06:16:55,848 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42386763393878935, 'Total loss': 0.42386763393878935} | train loss {'Reaction outcome loss': 0.31755467080443667, 'Total loss': 0.31755467080443667}
2023-01-04 06:16:55,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:55,849 INFO:     Epoch: 59
2023-01-04 06:16:57,380 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4261161049207052, 'Total loss': 0.4261161049207052} | train loss {'Reaction outcome loss': 0.3188033626900743, 'Total loss': 0.3188033626900743}
2023-01-04 06:16:57,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:57,380 INFO:     Epoch: 60
2023-01-04 06:16:58,982 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40990728735923765, 'Total loss': 0.40990728735923765} | train loss {'Reaction outcome loss': 0.31542162097774556, 'Total loss': 0.31542162097774556}
2023-01-04 06:16:58,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:16:58,982 INFO:     Epoch: 61
2023-01-04 06:17:00,600 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4232585787773132, 'Total loss': 0.4232585787773132} | train loss {'Reaction outcome loss': 0.31239871273114195, 'Total loss': 0.31239871273114195}
2023-01-04 06:17:00,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:00,601 INFO:     Epoch: 62
2023-01-04 06:17:02,182 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.431402446826299, 'Total loss': 0.431402446826299} | train loss {'Reaction outcome loss': 0.31085677335268236, 'Total loss': 0.31085677335268236}
2023-01-04 06:17:02,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:02,182 INFO:     Epoch: 63
2023-01-04 06:17:03,743 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40658645232518514, 'Total loss': 0.40658645232518514} | train loss {'Reaction outcome loss': 0.31077694364585506, 'Total loss': 0.31077694364585506}
2023-01-04 06:17:03,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:03,743 INFO:     Epoch: 64
2023-01-04 06:17:05,303 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4743064324061076, 'Total loss': 0.4743064324061076} | train loss {'Reaction outcome loss': 0.30613833954524033, 'Total loss': 0.30613833954524033}
2023-01-04 06:17:05,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:05,303 INFO:     Epoch: 65
2023-01-04 06:17:06,838 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39675559997558596, 'Total loss': 0.39675559997558596} | train loss {'Reaction outcome loss': 0.30972346158671205, 'Total loss': 0.30972346158671205}
2023-01-04 06:17:06,838 INFO:     Found new best model at epoch 65
2023-01-04 06:17:06,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:06,839 INFO:     Epoch: 66
2023-01-04 06:17:08,406 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4009706894556681, 'Total loss': 0.4009706894556681} | train loss {'Reaction outcome loss': 0.3069716213352006, 'Total loss': 0.3069716213352006}
2023-01-04 06:17:08,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:08,406 INFO:     Epoch: 67
2023-01-04 06:17:09,965 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41541333198547364, 'Total loss': 0.41541333198547364} | train loss {'Reaction outcome loss': 0.30607954796025716, 'Total loss': 0.30607954796025716}
2023-01-04 06:17:09,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:09,965 INFO:     Epoch: 68
2023-01-04 06:17:11,522 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42876628736654915, 'Total loss': 0.42876628736654915} | train loss {'Reaction outcome loss': 0.30100329930259695, 'Total loss': 0.30100329930259695}
2023-01-04 06:17:11,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:11,522 INFO:     Epoch: 69
2023-01-04 06:17:13,057 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4326760013898214, 'Total loss': 0.4326760013898214} | train loss {'Reaction outcome loss': 0.3047516106263451, 'Total loss': 0.3047516106263451}
2023-01-04 06:17:13,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:13,058 INFO:     Epoch: 70
2023-01-04 06:17:14,596 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40780320167541506, 'Total loss': 0.40780320167541506} | train loss {'Reaction outcome loss': 0.2970218764537055, 'Total loss': 0.2970218764537055}
2023-01-04 06:17:14,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:14,596 INFO:     Epoch: 71
2023-01-04 06:17:16,140 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42411888142426807, 'Total loss': 0.42411888142426807} | train loss {'Reaction outcome loss': 0.3044764217583166, 'Total loss': 0.3044764217583166}
2023-01-04 06:17:16,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:16,141 INFO:     Epoch: 72
2023-01-04 06:17:17,741 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4069845745960871, 'Total loss': 0.4069845745960871} | train loss {'Reaction outcome loss': 0.2914907593091113, 'Total loss': 0.2914907593091113}
2023-01-04 06:17:17,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:17,741 INFO:     Epoch: 73
2023-01-04 06:17:19,336 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41562108397483827, 'Total loss': 0.41562108397483827} | train loss {'Reaction outcome loss': 0.2974812335240236, 'Total loss': 0.2974812335240236}
2023-01-04 06:17:19,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:19,337 INFO:     Epoch: 74
2023-01-04 06:17:20,935 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45415854652722676, 'Total loss': 0.45415854652722676} | train loss {'Reaction outcome loss': 0.2905811629767624, 'Total loss': 0.2905811629767624}
2023-01-04 06:17:20,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:20,935 INFO:     Epoch: 75
2023-01-04 06:17:22,510 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4110099494457245, 'Total loss': 0.4110099494457245} | train loss {'Reaction outcome loss': 0.2896256052738771, 'Total loss': 0.2896256052738771}
2023-01-04 06:17:22,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:22,511 INFO:     Epoch: 76
2023-01-04 06:17:24,059 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.416563872496287, 'Total loss': 0.416563872496287} | train loss {'Reaction outcome loss': 0.2985907224263402, 'Total loss': 0.2985907224263402}
2023-01-04 06:17:24,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:24,059 INFO:     Epoch: 77
2023-01-04 06:17:25,648 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3967177033424377, 'Total loss': 0.3967177033424377} | train loss {'Reaction outcome loss': 0.31392047729721106, 'Total loss': 0.31392047729721106}
2023-01-04 06:17:25,648 INFO:     Found new best model at epoch 77
2023-01-04 06:17:25,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:25,649 INFO:     Epoch: 78
2023-01-04 06:17:27,225 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.412616162498792, 'Total loss': 0.412616162498792} | train loss {'Reaction outcome loss': 0.2865918861243172, 'Total loss': 0.2865918861243172}
2023-01-04 06:17:27,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:27,225 INFO:     Epoch: 79
2023-01-04 06:17:28,821 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4078336477279663, 'Total loss': 0.4078336477279663} | train loss {'Reaction outcome loss': 0.3051522719417361, 'Total loss': 0.3051522719417361}
2023-01-04 06:17:28,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:28,822 INFO:     Epoch: 80
2023-01-04 06:17:30,404 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4144911085565885, 'Total loss': 0.4144911085565885} | train loss {'Reaction outcome loss': 0.295554059598109, 'Total loss': 0.295554059598109}
2023-01-04 06:17:30,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:30,404 INFO:     Epoch: 81
2023-01-04 06:17:31,938 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4181759595870972, 'Total loss': 0.4181759595870972} | train loss {'Reaction outcome loss': 0.29883468479080044, 'Total loss': 0.29883468479080044}
2023-01-04 06:17:31,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:31,939 INFO:     Epoch: 82
2023-01-04 06:17:33,483 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4071971118450165, 'Total loss': 0.4071971118450165} | train loss {'Reaction outcome loss': 0.2835510982326198, 'Total loss': 0.2835510982326198}
2023-01-04 06:17:33,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:33,484 INFO:     Epoch: 83
2023-01-04 06:17:35,053 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42335761388142906, 'Total loss': 0.42335761388142906} | train loss {'Reaction outcome loss': 0.27864448413036874, 'Total loss': 0.27864448413036874}
2023-01-04 06:17:35,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:35,053 INFO:     Epoch: 84
2023-01-04 06:17:36,627 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42569011052449546, 'Total loss': 0.42569011052449546} | train loss {'Reaction outcome loss': 0.2848021353850566, 'Total loss': 0.2848021353850566}
2023-01-04 06:17:36,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:36,627 INFO:     Epoch: 85
2023-01-04 06:17:38,211 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.398721299568812, 'Total loss': 0.398721299568812} | train loss {'Reaction outcome loss': 0.27887452280391817, 'Total loss': 0.27887452280391817}
2023-01-04 06:17:38,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:38,211 INFO:     Epoch: 86
2023-01-04 06:17:39,777 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3825857758522034, 'Total loss': 0.3825857758522034} | train loss {'Reaction outcome loss': 0.284902004795014, 'Total loss': 0.284902004795014}
2023-01-04 06:17:39,778 INFO:     Found new best model at epoch 86
2023-01-04 06:17:39,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:39,778 INFO:     Epoch: 87
2023-01-04 06:17:41,326 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42481402854124706, 'Total loss': 0.42481402854124706} | train loss {'Reaction outcome loss': 0.28448620728095586, 'Total loss': 0.28448620728095586}
2023-01-04 06:17:41,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:41,326 INFO:     Epoch: 88
2023-01-04 06:17:42,884 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39023731847604115, 'Total loss': 0.39023731847604115} | train loss {'Reaction outcome loss': 0.277664385070423, 'Total loss': 0.277664385070423}
2023-01-04 06:17:42,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:42,884 INFO:     Epoch: 89
2023-01-04 06:17:44,475 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4016495873530706, 'Total loss': 0.4016495873530706} | train loss {'Reaction outcome loss': 0.27945150410675484, 'Total loss': 0.27945150410675484}
2023-01-04 06:17:44,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:44,476 INFO:     Epoch: 90
2023-01-04 06:17:46,081 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4247513433297475, 'Total loss': 0.4247513433297475} | train loss {'Reaction outcome loss': 0.27966574979001196, 'Total loss': 0.27966574979001196}
2023-01-04 06:17:46,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:46,081 INFO:     Epoch: 91
2023-01-04 06:17:47,673 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3848752498626709, 'Total loss': 0.3848752498626709} | train loss {'Reaction outcome loss': 0.3237989484492685, 'Total loss': 0.3237989484492685}
2023-01-04 06:17:47,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:47,675 INFO:     Epoch: 92
2023-01-04 06:17:49,287 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40870137711366017, 'Total loss': 0.40870137711366017} | train loss {'Reaction outcome loss': 0.27644141883396567, 'Total loss': 0.27644141883396567}
2023-01-04 06:17:49,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:49,287 INFO:     Epoch: 93
2023-01-04 06:17:50,843 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4333570599555969, 'Total loss': 0.4333570599555969} | train loss {'Reaction outcome loss': 0.2740286680181389, 'Total loss': 0.2740286680181389}
2023-01-04 06:17:50,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:50,843 INFO:     Epoch: 94
2023-01-04 06:17:52,380 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.420166426897049, 'Total loss': 0.420166426897049} | train loss {'Reaction outcome loss': 0.273894939193691, 'Total loss': 0.273894939193691}
2023-01-04 06:17:52,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:52,381 INFO:     Epoch: 95
2023-01-04 06:17:53,947 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40272168020407356, 'Total loss': 0.40272168020407356} | train loss {'Reaction outcome loss': 0.2929825681308959, 'Total loss': 0.2929825681308959}
2023-01-04 06:17:53,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:53,948 INFO:     Epoch: 96
2023-01-04 06:17:55,505 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42800334890683495, 'Total loss': 0.42800334890683495} | train loss {'Reaction outcome loss': 0.2894513992106785, 'Total loss': 0.2894513992106785}
2023-01-04 06:17:55,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:55,505 INFO:     Epoch: 97
2023-01-04 06:17:57,073 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42479418019453685, 'Total loss': 0.42479418019453685} | train loss {'Reaction outcome loss': 0.3811168597228285, 'Total loss': 0.3811168597228285}
2023-01-04 06:17:57,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:57,074 INFO:     Epoch: 98
2023-01-04 06:17:58,641 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4297364254792531, 'Total loss': 0.4297364254792531} | train loss {'Reaction outcome loss': 0.2855847011587289, 'Total loss': 0.2855847011587289}
2023-01-04 06:17:58,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:17:58,641 INFO:     Epoch: 99
2023-01-04 06:18:00,192 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4019186690449715, 'Total loss': 0.4019186690449715} | train loss {'Reaction outcome loss': 0.27452447173604066, 'Total loss': 0.27452447173604066}
2023-01-04 06:18:00,192 INFO:     Best model found after epoch 87 of 100.
2023-01-04 06:18:00,193 INFO:   Done with stage: TRAINING
2023-01-04 06:18:00,193 INFO:   Starting stage: EVALUATION
2023-01-04 06:18:00,319 INFO:   Done with stage: EVALUATION
2023-01-04 06:18:00,320 INFO:   Leaving out SEQ value Fold_6
2023-01-04 06:18:00,332 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 06:18:00,332 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:18:00,986 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:18:00,986 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:18:01,057 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:18:01,057 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:18:01,057 INFO:     No hyperparam tuning for this model
2023-01-04 06:18:01,057 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:18:01,057 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:18:01,058 INFO:     None feature selector for col prot
2023-01-04 06:18:01,058 INFO:     None feature selector for col prot
2023-01-04 06:18:01,058 INFO:     None feature selector for col prot
2023-01-04 06:18:01,059 INFO:     None feature selector for col chem
2023-01-04 06:18:01,059 INFO:     None feature selector for col chem
2023-01-04 06:18:01,059 INFO:     None feature selector for col chem
2023-01-04 06:18:01,059 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:18:01,059 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:18:01,060 INFO:     Number of params in model 70111
2023-01-04 06:18:01,063 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:18:01,063 INFO:   Starting stage: TRAINING
2023-01-04 06:18:01,106 INFO:     Val loss before train {'Reaction outcome loss': 1.075474468866984, 'Total loss': 1.075474468866984}
2023-01-04 06:18:01,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:01,106 INFO:     Epoch: 0
2023-01-04 06:18:02,686 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.806608247756958, 'Total loss': 0.806608247756958} | train loss {'Reaction outcome loss': 0.8430101142032912, 'Total loss': 0.8430101142032912}
2023-01-04 06:18:02,686 INFO:     Found new best model at epoch 0
2023-01-04 06:18:02,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:02,686 INFO:     Epoch: 1
2023-01-04 06:18:04,259 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6806001047293345, 'Total loss': 0.6806001047293345} | train loss {'Reaction outcome loss': 0.6766260032834559, 'Total loss': 0.6766260032834559}
2023-01-04 06:18:04,259 INFO:     Found new best model at epoch 1
2023-01-04 06:18:04,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:04,260 INFO:     Epoch: 2
2023-01-04 06:18:05,845 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6271612087885539, 'Total loss': 0.6271612087885539} | train loss {'Reaction outcome loss': 0.5811390772408096, 'Total loss': 0.5811390772408096}
2023-01-04 06:18:05,845 INFO:     Found new best model at epoch 2
2023-01-04 06:18:05,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:05,846 INFO:     Epoch: 3
2023-01-04 06:18:07,405 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5817300856113434, 'Total loss': 0.5817300856113434} | train loss {'Reaction outcome loss': 0.5304777893348721, 'Total loss': 0.5304777893348721}
2023-01-04 06:18:07,406 INFO:     Found new best model at epoch 3
2023-01-04 06:18:07,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:07,407 INFO:     Epoch: 4
2023-01-04 06:18:08,951 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.566297001640002, 'Total loss': 0.566297001640002} | train loss {'Reaction outcome loss': 0.5078343643070559, 'Total loss': 0.5078343643070559}
2023-01-04 06:18:08,951 INFO:     Found new best model at epoch 4
2023-01-04 06:18:08,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:08,952 INFO:     Epoch: 5
2023-01-04 06:18:10,498 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5618719846010208, 'Total loss': 0.5618719846010208} | train loss {'Reaction outcome loss': 0.4917278086450556, 'Total loss': 0.4917278086450556}
2023-01-04 06:18:10,498 INFO:     Found new best model at epoch 5
2023-01-04 06:18:10,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:10,499 INFO:     Epoch: 6
2023-01-04 06:18:12,074 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5562054872512817, 'Total loss': 0.5562054872512817} | train loss {'Reaction outcome loss': 0.48125656411751083, 'Total loss': 0.48125656411751083}
2023-01-04 06:18:12,074 INFO:     Found new best model at epoch 6
2023-01-04 06:18:12,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:12,075 INFO:     Epoch: 7
2023-01-04 06:18:13,637 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5828556954860687, 'Total loss': 0.5828556954860687} | train loss {'Reaction outcome loss': 0.4706019105033324, 'Total loss': 0.4706019105033324}
2023-01-04 06:18:13,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:13,637 INFO:     Epoch: 8
2023-01-04 06:18:15,214 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5555231471856436, 'Total loss': 0.5555231471856436} | train loss {'Reaction outcome loss': 0.4668407149155648, 'Total loss': 0.4668407149155648}
2023-01-04 06:18:15,214 INFO:     Found new best model at epoch 8
2023-01-04 06:18:15,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:15,215 INFO:     Epoch: 9
2023-01-04 06:18:16,773 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5695645014444987, 'Total loss': 0.5695645014444987} | train loss {'Reaction outcome loss': 0.4554717467042083, 'Total loss': 0.4554717467042083}
2023-01-04 06:18:16,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:16,774 INFO:     Epoch: 10
2023-01-04 06:18:18,303 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5372456093629201, 'Total loss': 0.5372456093629201} | train loss {'Reaction outcome loss': 0.45597683727095706, 'Total loss': 0.45597683727095706}
2023-01-04 06:18:18,303 INFO:     Found new best model at epoch 10
2023-01-04 06:18:18,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:18,304 INFO:     Epoch: 11
2023-01-04 06:18:19,872 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5467381656169892, 'Total loss': 0.5467381656169892} | train loss {'Reaction outcome loss': 0.4458652353889245, 'Total loss': 0.4458652353889245}
2023-01-04 06:18:19,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:19,872 INFO:     Epoch: 12
2023-01-04 06:18:21,445 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5468686401844025, 'Total loss': 0.5468686401844025} | train loss {'Reaction outcome loss': 0.4407650471164001, 'Total loss': 0.4407650471164001}
2023-01-04 06:18:21,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:21,445 INFO:     Epoch: 13
2023-01-04 06:18:22,999 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5359414438406627, 'Total loss': 0.5359414438406627} | train loss {'Reaction outcome loss': 0.4376291897860675, 'Total loss': 0.4376291897860675}
2023-01-04 06:18:22,999 INFO:     Found new best model at epoch 13
2023-01-04 06:18:23,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:23,000 INFO:     Epoch: 14
2023-01-04 06:18:24,562 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5231194068988164, 'Total loss': 0.5231194068988164} | train loss {'Reaction outcome loss': 0.4310302143708033, 'Total loss': 0.4310302143708033}
2023-01-04 06:18:24,563 INFO:     Found new best model at epoch 14
2023-01-04 06:18:24,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:24,564 INFO:     Epoch: 15
2023-01-04 06:18:26,105 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5315829694271088, 'Total loss': 0.5315829694271088} | train loss {'Reaction outcome loss': 0.4259421575801037, 'Total loss': 0.4259421575801037}
2023-01-04 06:18:26,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:26,106 INFO:     Epoch: 16
2023-01-04 06:18:27,648 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5183410505453746, 'Total loss': 0.5183410505453746} | train loss {'Reaction outcome loss': 0.41777746486965067, 'Total loss': 0.41777746486965067}
2023-01-04 06:18:27,648 INFO:     Found new best model at epoch 16
2023-01-04 06:18:27,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:27,649 INFO:     Epoch: 17
2023-01-04 06:18:29,237 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5562248071034749, 'Total loss': 0.5562248071034749} | train loss {'Reaction outcome loss': 0.4156793053077016, 'Total loss': 0.4156793053077016}
2023-01-04 06:18:29,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:29,237 INFO:     Epoch: 18
2023-01-04 06:18:30,816 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5485001643498738, 'Total loss': 0.5485001643498738} | train loss {'Reaction outcome loss': 0.4107879523981349, 'Total loss': 0.4107879523981349}
2023-01-04 06:18:30,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:30,817 INFO:     Epoch: 19
2023-01-04 06:18:32,387 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5243686338265737, 'Total loss': 0.5243686338265737} | train loss {'Reaction outcome loss': 0.4089419707279343, 'Total loss': 0.4089419707279343}
2023-01-04 06:18:32,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:32,388 INFO:     Epoch: 20
2023-01-04 06:18:33,981 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5082279284795125, 'Total loss': 0.5082279284795125} | train loss {'Reaction outcome loss': 0.4007060221978043, 'Total loss': 0.4007060221978043}
2023-01-04 06:18:33,981 INFO:     Found new best model at epoch 20
2023-01-04 06:18:33,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:33,982 INFO:     Epoch: 21
2023-01-04 06:18:35,524 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5031523267428081, 'Total loss': 0.5031523267428081} | train loss {'Reaction outcome loss': 0.4000983500469893, 'Total loss': 0.4000983500469893}
2023-01-04 06:18:35,524 INFO:     Found new best model at epoch 21
2023-01-04 06:18:35,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:35,525 INFO:     Epoch: 22
2023-01-04 06:18:37,081 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.534957754611969, 'Total loss': 0.534957754611969} | train loss {'Reaction outcome loss': 0.39361787452917235, 'Total loss': 0.39361787452917235}
2023-01-04 06:18:37,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:37,081 INFO:     Epoch: 23
2023-01-04 06:18:38,676 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5008216867844264, 'Total loss': 0.5008216867844264} | train loss {'Reaction outcome loss': 0.39152585142140783, 'Total loss': 0.39152585142140783}
2023-01-04 06:18:38,676 INFO:     Found new best model at epoch 23
2023-01-04 06:18:38,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:38,677 INFO:     Epoch: 24
2023-01-04 06:18:40,273 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5107921679814657, 'Total loss': 0.5107921679814657} | train loss {'Reaction outcome loss': 0.3905351068891773, 'Total loss': 0.3905351068891773}
2023-01-04 06:18:40,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:40,273 INFO:     Epoch: 25
2023-01-04 06:18:41,871 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5017456452051798, 'Total loss': 0.5017456452051798} | train loss {'Reaction outcome loss': 0.3831515312732772, 'Total loss': 0.3831515312732772}
2023-01-04 06:18:41,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:41,871 INFO:     Epoch: 26
2023-01-04 06:18:43,466 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4867069979508718, 'Total loss': 0.4867069979508718} | train loss {'Reaction outcome loss': 0.3782925092840453, 'Total loss': 0.3782925092840453}
2023-01-04 06:18:43,467 INFO:     Found new best model at epoch 26
2023-01-04 06:18:43,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:43,468 INFO:     Epoch: 27
2023-01-04 06:18:45,027 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5033435364564259, 'Total loss': 0.5033435364564259} | train loss {'Reaction outcome loss': 0.37285992914696464, 'Total loss': 0.37285992914696464}
2023-01-04 06:18:45,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:45,027 INFO:     Epoch: 28
2023-01-04 06:18:46,589 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48506924510002136, 'Total loss': 0.48506924510002136} | train loss {'Reaction outcome loss': 0.3711154123344576, 'Total loss': 0.3711154123344576}
2023-01-04 06:18:46,589 INFO:     Found new best model at epoch 28
2023-01-04 06:18:46,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:46,590 INFO:     Epoch: 29
2023-01-04 06:18:48,175 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4979893147945404, 'Total loss': 0.4979893147945404} | train loss {'Reaction outcome loss': 0.3691204941767648, 'Total loss': 0.3691204941767648}
2023-01-04 06:18:48,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:48,175 INFO:     Epoch: 30
2023-01-04 06:18:49,737 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46710456113020576, 'Total loss': 0.46710456113020576} | train loss {'Reaction outcome loss': 0.36240761848132963, 'Total loss': 0.36240761848132963}
2023-01-04 06:18:49,738 INFO:     Found new best model at epoch 30
2023-01-04 06:18:49,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:49,738 INFO:     Epoch: 31
2023-01-04 06:18:51,314 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49294832944869993, 'Total loss': 0.49294832944869993} | train loss {'Reaction outcome loss': 0.3607580345460224, 'Total loss': 0.3607580345460224}
2023-01-04 06:18:51,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:51,314 INFO:     Epoch: 32
2023-01-04 06:18:52,851 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48068245152632394, 'Total loss': 0.48068245152632394} | train loss {'Reaction outcome loss': 0.3522803013613078, 'Total loss': 0.3522803013613078}
2023-01-04 06:18:52,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:52,852 INFO:     Epoch: 33
2023-01-04 06:18:54,384 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45913710792859397, 'Total loss': 0.45913710792859397} | train loss {'Reaction outcome loss': 0.3548804618391319, 'Total loss': 0.3548804618391319}
2023-01-04 06:18:54,384 INFO:     Found new best model at epoch 33
2023-01-04 06:18:54,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:54,385 INFO:     Epoch: 34
2023-01-04 06:18:55,963 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47646178007125856, 'Total loss': 0.47646178007125856} | train loss {'Reaction outcome loss': 0.34880556991922296, 'Total loss': 0.34880556991922296}
2023-01-04 06:18:55,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:55,963 INFO:     Epoch: 35
2023-01-04 06:18:57,544 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47937034368515014, 'Total loss': 0.47937034368515014} | train loss {'Reaction outcome loss': 0.3423733089105747, 'Total loss': 0.3423733089105747}
2023-01-04 06:18:57,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:57,544 INFO:     Epoch: 36
2023-01-04 06:18:59,128 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46648115913073224, 'Total loss': 0.46648115913073224} | train loss {'Reaction outcome loss': 0.34706343812632645, 'Total loss': 0.34706343812632645}
2023-01-04 06:18:59,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:18:59,128 INFO:     Epoch: 37
2023-01-04 06:19:00,706 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49136024216810864, 'Total loss': 0.49136024216810864} | train loss {'Reaction outcome loss': 0.34252952445392576, 'Total loss': 0.34252952445392576}
2023-01-04 06:19:00,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:00,707 INFO:     Epoch: 38
2023-01-04 06:19:02,248 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48889122207959496, 'Total loss': 0.48889122207959496} | train loss {'Reaction outcome loss': 0.3394069949481031, 'Total loss': 0.3394069949481031}
2023-01-04 06:19:02,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:02,248 INFO:     Epoch: 39
2023-01-04 06:19:03,787 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4620934039354324, 'Total loss': 0.4620934039354324} | train loss {'Reaction outcome loss': 0.33533179746530545, 'Total loss': 0.33533179746530545}
2023-01-04 06:19:03,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:03,787 INFO:     Epoch: 40
2023-01-04 06:19:05,370 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.481120890378952, 'Total loss': 0.481120890378952} | train loss {'Reaction outcome loss': 0.33044851902159544, 'Total loss': 0.33044851902159544}
2023-01-04 06:19:05,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:05,370 INFO:     Epoch: 41
2023-01-04 06:19:06,957 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4873781204223633, 'Total loss': 0.4873781204223633} | train loss {'Reaction outcome loss': 0.3301609906801678, 'Total loss': 0.3301609906801678}
2023-01-04 06:19:06,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:06,958 INFO:     Epoch: 42
2023-01-04 06:19:08,533 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47421913941701255, 'Total loss': 0.47421913941701255} | train loss {'Reaction outcome loss': 0.32980892441440574, 'Total loss': 0.32980892441440574}
2023-01-04 06:19:08,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:08,533 INFO:     Epoch: 43
2023-01-04 06:19:10,116 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4463722596565882, 'Total loss': 0.4463722596565882} | train loss {'Reaction outcome loss': 0.3236974725224051, 'Total loss': 0.3236974725224051}
2023-01-04 06:19:10,116 INFO:     Found new best model at epoch 43
2023-01-04 06:19:10,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:10,117 INFO:     Epoch: 44
2023-01-04 06:19:11,662 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4594714214404424, 'Total loss': 0.4594714214404424} | train loss {'Reaction outcome loss': 0.32129252125048463, 'Total loss': 0.32129252125048463}
2023-01-04 06:19:11,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:11,662 INFO:     Epoch: 45
2023-01-04 06:19:13,211 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47565760016441344, 'Total loss': 0.47565760016441344} | train loss {'Reaction outcome loss': 0.32055487413806605, 'Total loss': 0.32055487413806605}
2023-01-04 06:19:13,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:13,211 INFO:     Epoch: 46
2023-01-04 06:19:14,785 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4827434360980988, 'Total loss': 0.4827434360980988} | train loss {'Reaction outcome loss': 0.31796062831844235, 'Total loss': 0.31796062831844235}
2023-01-04 06:19:14,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:14,785 INFO:     Epoch: 47
2023-01-04 06:19:16,379 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46198169589042665, 'Total loss': 0.46198169589042665} | train loss {'Reaction outcome loss': 0.31332882550218905, 'Total loss': 0.31332882550218905}
2023-01-04 06:19:16,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:16,379 INFO:     Epoch: 48
2023-01-04 06:19:17,960 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4496550540129344, 'Total loss': 0.4496550540129344} | train loss {'Reaction outcome loss': 0.31397476742575314, 'Total loss': 0.31397476742575314}
2023-01-04 06:19:17,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:17,960 INFO:     Epoch: 49
2023-01-04 06:19:19,536 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4369415620962779, 'Total loss': 0.4369415620962779} | train loss {'Reaction outcome loss': 0.30883262545838686, 'Total loss': 0.30883262545838686}
2023-01-04 06:19:19,537 INFO:     Found new best model at epoch 49
2023-01-04 06:19:19,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:19,538 INFO:     Epoch: 50
2023-01-04 06:19:21,082 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45523404131333034, 'Total loss': 0.45523404131333034} | train loss {'Reaction outcome loss': 0.3060649100839016, 'Total loss': 0.3060649100839016}
2023-01-04 06:19:21,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:21,082 INFO:     Epoch: 51
2023-01-04 06:19:22,639 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44717496236165366, 'Total loss': 0.44717496236165366} | train loss {'Reaction outcome loss': 0.30732459179545996, 'Total loss': 0.30732459179545996}
2023-01-04 06:19:22,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:22,639 INFO:     Epoch: 52
2023-01-04 06:19:24,208 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.459123166402181, 'Total loss': 0.459123166402181} | train loss {'Reaction outcome loss': 0.30752738748108865, 'Total loss': 0.30752738748108865}
2023-01-04 06:19:24,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:24,209 INFO:     Epoch: 53
2023-01-04 06:19:25,779 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4505757749080658, 'Total loss': 0.4505757749080658} | train loss {'Reaction outcome loss': 0.3071774377181642, 'Total loss': 0.3071774377181642}
2023-01-04 06:19:25,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:25,779 INFO:     Epoch: 54
2023-01-04 06:19:27,356 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46490148504575096, 'Total loss': 0.46490148504575096} | train loss {'Reaction outcome loss': 0.3036178637981845, 'Total loss': 0.3036178637981845}
2023-01-04 06:19:27,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:27,357 INFO:     Epoch: 55
2023-01-04 06:19:28,938 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4471825917561849, 'Total loss': 0.4471825917561849} | train loss {'Reaction outcome loss': 0.3005592219450844, 'Total loss': 0.3005592219450844}
2023-01-04 06:19:28,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:28,939 INFO:     Epoch: 56
2023-01-04 06:19:30,493 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4687247037887573, 'Total loss': 0.4687247037887573} | train loss {'Reaction outcome loss': 0.2987659486138433, 'Total loss': 0.2987659486138433}
2023-01-04 06:19:30,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:30,493 INFO:     Epoch: 57
2023-01-04 06:19:32,021 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44992268880208336, 'Total loss': 0.44992268880208336} | train loss {'Reaction outcome loss': 0.2979894152402017, 'Total loss': 0.2979894152402017}
2023-01-04 06:19:32,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:32,021 INFO:     Epoch: 58
2023-01-04 06:19:33,596 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44574686586856843, 'Total loss': 0.44574686586856843} | train loss {'Reaction outcome loss': 0.29329339869401083, 'Total loss': 0.29329339869401083}
2023-01-04 06:19:33,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:33,596 INFO:     Epoch: 59
2023-01-04 06:19:35,172 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4560772697130839, 'Total loss': 0.4560772697130839} | train loss {'Reaction outcome loss': 0.2929635025856727, 'Total loss': 0.2929635025856727}
2023-01-04 06:19:35,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:35,174 INFO:     Epoch: 60
2023-01-04 06:19:36,750 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.442678960164388, 'Total loss': 0.442678960164388} | train loss {'Reaction outcome loss': 0.29510713158854507, 'Total loss': 0.29510713158854507}
2023-01-04 06:19:36,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:36,750 INFO:     Epoch: 61
2023-01-04 06:19:38,307 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44740278124809263, 'Total loss': 0.44740278124809263} | train loss {'Reaction outcome loss': 0.28841923798572283, 'Total loss': 0.28841923798572283}
2023-01-04 06:19:38,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:38,307 INFO:     Epoch: 62
2023-01-04 06:19:39,843 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4759954005479813, 'Total loss': 0.4759954005479813} | train loss {'Reaction outcome loss': 0.284560527746643, 'Total loss': 0.284560527746643}
2023-01-04 06:19:39,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:39,843 INFO:     Epoch: 63
2023-01-04 06:19:41,426 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44984442790349327, 'Total loss': 0.44984442790349327} | train loss {'Reaction outcome loss': 0.28876574549971934, 'Total loss': 0.28876574549971934}
2023-01-04 06:19:41,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:41,427 INFO:     Epoch: 64
2023-01-04 06:19:43,010 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42845491667588553, 'Total loss': 0.42845491667588553} | train loss {'Reaction outcome loss': 0.2873688944033767, 'Total loss': 0.2873688944033767}
2023-01-04 06:19:43,010 INFO:     Found new best model at epoch 64
2023-01-04 06:19:43,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:43,011 INFO:     Epoch: 65
2023-01-04 06:19:44,585 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43552788893381755, 'Total loss': 0.43552788893381755} | train loss {'Reaction outcome loss': 0.2840662007136035, 'Total loss': 0.2840662007136035}
2023-01-04 06:19:44,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:44,586 INFO:     Epoch: 66
2023-01-04 06:19:46,164 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42147834102312726, 'Total loss': 0.42147834102312726} | train loss {'Reaction outcome loss': 0.28280557202518203, 'Total loss': 0.28280557202518203}
2023-01-04 06:19:46,164 INFO:     Found new best model at epoch 66
2023-01-04 06:19:46,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:46,164 INFO:     Epoch: 67
2023-01-04 06:19:47,699 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45827905436356864, 'Total loss': 0.45827905436356864} | train loss {'Reaction outcome loss': 0.2837558190745137, 'Total loss': 0.2837558190745137}
2023-01-04 06:19:47,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:47,700 INFO:     Epoch: 68
2023-01-04 06:19:49,236 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4699830263853073, 'Total loss': 0.4699830263853073} | train loss {'Reaction outcome loss': 0.27937789995640194, 'Total loss': 0.27937789995640194}
2023-01-04 06:19:49,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:49,236 INFO:     Epoch: 69
2023-01-04 06:19:50,829 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4344950397809347, 'Total loss': 0.4344950397809347} | train loss {'Reaction outcome loss': 0.2797155312467568, 'Total loss': 0.2797155312467568}
2023-01-04 06:19:50,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:50,829 INFO:     Epoch: 70
2023-01-04 06:19:52,416 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4495738704999288, 'Total loss': 0.4495738704999288} | train loss {'Reaction outcome loss': 0.2778681770558822, 'Total loss': 0.2778681770558822}
2023-01-04 06:19:52,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:52,417 INFO:     Epoch: 71
2023-01-04 06:19:53,988 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.420737890402476, 'Total loss': 0.420737890402476} | train loss {'Reaction outcome loss': 0.2771486053344145, 'Total loss': 0.2771486053344145}
2023-01-04 06:19:53,988 INFO:     Found new best model at epoch 71
2023-01-04 06:19:53,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:53,989 INFO:     Epoch: 72
2023-01-04 06:19:55,587 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4478934605916341, 'Total loss': 0.4478934605916341} | train loss {'Reaction outcome loss': 0.27504949962942177, 'Total loss': 0.27504949962942177}
2023-01-04 06:19:55,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:55,588 INFO:     Epoch: 73
2023-01-04 06:19:57,182 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45384156902631123, 'Total loss': 0.45384156902631123} | train loss {'Reaction outcome loss': 0.2728485680766915, 'Total loss': 0.2728485680766915}
2023-01-04 06:19:57,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:57,182 INFO:     Epoch: 74
2023-01-04 06:19:58,534 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4201785971721013, 'Total loss': 0.4201785971721013} | train loss {'Reaction outcome loss': 0.27475299395701513, 'Total loss': 0.27475299395701513}
2023-01-04 06:19:58,534 INFO:     Found new best model at epoch 74
2023-01-04 06:19:58,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:58,535 INFO:     Epoch: 75
2023-01-04 06:19:59,582 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.449634779493014, 'Total loss': 0.449634779493014} | train loss {'Reaction outcome loss': 0.27020284552328855, 'Total loss': 0.27020284552328855}
2023-01-04 06:19:59,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:19:59,582 INFO:     Epoch: 76
2023-01-04 06:20:00,626 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4516394118467967, 'Total loss': 0.4516394118467967} | train loss {'Reaction outcome loss': 0.2676218293526543, 'Total loss': 0.2676218293526543}
2023-01-04 06:20:00,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:00,627 INFO:     Epoch: 77
2023-01-04 06:20:01,675 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44755268692970274, 'Total loss': 0.44755268692970274} | train loss {'Reaction outcome loss': 0.27031045291397976, 'Total loss': 0.27031045291397976}
2023-01-04 06:20:01,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:01,676 INFO:     Epoch: 78
2023-01-04 06:20:02,757 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4285278141498566, 'Total loss': 0.4285278141498566} | train loss {'Reaction outcome loss': 0.26548128058656456, 'Total loss': 0.26548128058656456}
2023-01-04 06:20:02,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:02,757 INFO:     Epoch: 79
2023-01-04 06:20:04,332 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4760436475276947, 'Total loss': 0.4760436475276947} | train loss {'Reaction outcome loss': 0.26559149866607645, 'Total loss': 0.26559149866607645}
2023-01-04 06:20:04,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:04,332 INFO:     Epoch: 80
2023-01-04 06:20:05,969 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44745294451713563, 'Total loss': 0.44745294451713563} | train loss {'Reaction outcome loss': 0.26497601151520167, 'Total loss': 0.26497601151520167}
2023-01-04 06:20:05,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:05,970 INFO:     Epoch: 81
2023-01-04 06:20:07,603 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44205403526624043, 'Total loss': 0.44205403526624043} | train loss {'Reaction outcome loss': 0.26444291519774427, 'Total loss': 0.26444291519774427}
2023-01-04 06:20:07,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:07,603 INFO:     Epoch: 82
2023-01-04 06:20:09,238 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4293503165245056, 'Total loss': 0.4293503165245056} | train loss {'Reaction outcome loss': 0.26738252836390525, 'Total loss': 0.26738252836390525}
2023-01-04 06:20:09,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:09,238 INFO:     Epoch: 83
2023-01-04 06:20:10,872 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43764365613460543, 'Total loss': 0.43764365613460543} | train loss {'Reaction outcome loss': 0.26359296568571877, 'Total loss': 0.26359296568571877}
2023-01-04 06:20:10,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:10,872 INFO:     Epoch: 84
2023-01-04 06:20:12,414 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45399113396803537, 'Total loss': 0.45399113396803537} | train loss {'Reaction outcome loss': 0.2599092068601171, 'Total loss': 0.2599092068601171}
2023-01-04 06:20:12,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:12,415 INFO:     Epoch: 85
2023-01-04 06:20:14,038 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43702075878779095, 'Total loss': 0.43702075878779095} | train loss {'Reaction outcome loss': 0.26155610947402375, 'Total loss': 0.26155610947402375}
2023-01-04 06:20:14,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:14,038 INFO:     Epoch: 86
2023-01-04 06:20:15,666 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43873874644438426, 'Total loss': 0.43873874644438426} | train loss {'Reaction outcome loss': 0.2610661104482864, 'Total loss': 0.2610661104482864}
2023-01-04 06:20:15,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:15,666 INFO:     Epoch: 87
2023-01-04 06:20:17,305 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45757256348927816, 'Total loss': 0.45757256348927816} | train loss {'Reaction outcome loss': 0.2595476152287924, 'Total loss': 0.2595476152287924}
2023-01-04 06:20:17,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:17,305 INFO:     Epoch: 88
2023-01-04 06:20:18,941 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4432242969671885, 'Total loss': 0.4432242969671885} | train loss {'Reaction outcome loss': 0.2602880032672564, 'Total loss': 0.2602880032672564}
2023-01-04 06:20:18,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:18,942 INFO:     Epoch: 89
2023-01-04 06:20:20,579 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46687350422143936, 'Total loss': 0.46687350422143936} | train loss {'Reaction outcome loss': 0.25634048686830146, 'Total loss': 0.25634048686830146}
2023-01-04 06:20:20,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:20,580 INFO:     Epoch: 90
2023-01-04 06:20:22,120 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4298229515552521, 'Total loss': 0.4298229515552521} | train loss {'Reaction outcome loss': 0.2525554785659597, 'Total loss': 0.2525554785659597}
2023-01-04 06:20:22,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:22,121 INFO:     Epoch: 91
2023-01-04 06:20:23,756 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4450792849063873, 'Total loss': 0.4450792849063873} | train loss {'Reaction outcome loss': 0.25129071337974457, 'Total loss': 0.25129071337974457}
2023-01-04 06:20:23,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:23,756 INFO:     Epoch: 92
2023-01-04 06:20:25,383 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46052735050519306, 'Total loss': 0.46052735050519306} | train loss {'Reaction outcome loss': 0.2504207293977053, 'Total loss': 0.2504207293977053}
2023-01-04 06:20:25,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:25,384 INFO:     Epoch: 93
2023-01-04 06:20:27,011 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42889232039451597, 'Total loss': 0.42889232039451597} | train loss {'Reaction outcome loss': 0.25268663019479826, 'Total loss': 0.25268663019479826}
2023-01-04 06:20:27,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:27,011 INFO:     Epoch: 94
2023-01-04 06:20:28,649 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4296844005584717, 'Total loss': 0.4296844005584717} | train loss {'Reaction outcome loss': 0.24890340289053933, 'Total loss': 0.24890340289053933}
2023-01-04 06:20:28,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:28,649 INFO:     Epoch: 95
2023-01-04 06:20:30,245 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4184929390748342, 'Total loss': 0.4184929390748342} | train loss {'Reaction outcome loss': 0.24811464970400188, 'Total loss': 0.24811464970400188}
2023-01-04 06:20:30,246 INFO:     Found new best model at epoch 95
2023-01-04 06:20:30,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:30,246 INFO:     Epoch: 96
2023-01-04 06:20:31,837 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44843400120735166, 'Total loss': 0.44843400120735166} | train loss {'Reaction outcome loss': 0.2506879688062392, 'Total loss': 0.2506879688062392}
2023-01-04 06:20:31,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:31,837 INFO:     Epoch: 97
2023-01-04 06:20:33,475 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4574549779295921, 'Total loss': 0.4574549779295921} | train loss {'Reaction outcome loss': 0.2520515700997213, 'Total loss': 0.2520515700997213}
2023-01-04 06:20:33,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:33,476 INFO:     Epoch: 98
2023-01-04 06:20:35,116 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45160402059555055, 'Total loss': 0.45160402059555055} | train loss {'Reaction outcome loss': 0.2520126885724412, 'Total loss': 0.2520126885724412}
2023-01-04 06:20:35,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:35,116 INFO:     Epoch: 99
2023-01-04 06:20:36,748 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4356682598590851, 'Total loss': 0.4356682598590851} | train loss {'Reaction outcome loss': 0.2498491913725753, 'Total loss': 0.2498491913725753}
2023-01-04 06:20:36,750 INFO:     Best model found after epoch 96 of 100.
2023-01-04 06:20:36,750 INFO:   Done with stage: TRAINING
2023-01-04 06:20:36,750 INFO:   Starting stage: EVALUATION
2023-01-04 06:20:36,870 INFO:   Done with stage: EVALUATION
2023-01-04 06:20:36,871 INFO:   Leaving out SEQ value Fold_7
2023-01-04 06:20:36,883 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 06:20:36,883 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:20:37,535 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:20:37,535 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:20:37,605 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:20:37,606 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:20:37,606 INFO:     No hyperparam tuning for this model
2023-01-04 06:20:37,606 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:20:37,606 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:20:37,606 INFO:     None feature selector for col prot
2023-01-04 06:20:37,607 INFO:     None feature selector for col prot
2023-01-04 06:20:37,607 INFO:     None feature selector for col prot
2023-01-04 06:20:37,607 INFO:     None feature selector for col chem
2023-01-04 06:20:37,607 INFO:     None feature selector for col chem
2023-01-04 06:20:37,607 INFO:     None feature selector for col chem
2023-01-04 06:20:37,607 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:20:37,607 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:20:37,608 INFO:     Number of params in model 70111
2023-01-04 06:20:37,611 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:20:37,612 INFO:   Starting stage: TRAINING
2023-01-04 06:20:37,655 INFO:     Val loss before train {'Reaction outcome loss': 1.1096584637959799, 'Total loss': 1.1096584637959799}
2023-01-04 06:20:37,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:37,655 INFO:     Epoch: 0
2023-01-04 06:20:39,222 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7827135801315308, 'Total loss': 0.7827135801315308} | train loss {'Reaction outcome loss': 0.8296940652687197, 'Total loss': 0.8296940652687197}
2023-01-04 06:20:39,222 INFO:     Found new best model at epoch 0
2023-01-04 06:20:39,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:39,223 INFO:     Epoch: 1
2023-01-04 06:20:40,830 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.734592451651891, 'Total loss': 0.734592451651891} | train loss {'Reaction outcome loss': 0.6665751277754883, 'Total loss': 0.6665751277754883}
2023-01-04 06:20:40,830 INFO:     Found new best model at epoch 1
2023-01-04 06:20:40,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:40,831 INFO:     Epoch: 2
2023-01-04 06:20:42,452 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6328993101914724, 'Total loss': 0.6328993101914724} | train loss {'Reaction outcome loss': 0.5827532124433277, 'Total loss': 0.5827532124433277}
2023-01-04 06:20:42,452 INFO:     Found new best model at epoch 2
2023-01-04 06:20:42,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:42,453 INFO:     Epoch: 3
2023-01-04 06:20:44,091 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5920192341009776, 'Total loss': 0.5920192341009776} | train loss {'Reaction outcome loss': 0.5450246665451931, 'Total loss': 0.5450246665451931}
2023-01-04 06:20:44,092 INFO:     Found new best model at epoch 3
2023-01-04 06:20:44,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:44,093 INFO:     Epoch: 4
2023-01-04 06:20:45,728 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5795921484629313, 'Total loss': 0.5795921484629313} | train loss {'Reaction outcome loss': 0.5111531479156405, 'Total loss': 0.5111531479156405}
2023-01-04 06:20:45,728 INFO:     Found new best model at epoch 4
2023-01-04 06:20:45,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:45,729 INFO:     Epoch: 5
2023-01-04 06:20:47,361 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5711825907230377, 'Total loss': 0.5711825907230377} | train loss {'Reaction outcome loss': 0.4967753346538716, 'Total loss': 0.4967753346538716}
2023-01-04 06:20:47,361 INFO:     Found new best model at epoch 5
2023-01-04 06:20:47,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:47,362 INFO:     Epoch: 6
2023-01-04 06:20:48,886 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5709993739922842, 'Total loss': 0.5709993739922842} | train loss {'Reaction outcome loss': 0.4835318419477139, 'Total loss': 0.4835318419477139}
2023-01-04 06:20:48,886 INFO:     Found new best model at epoch 6
2023-01-04 06:20:48,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:48,887 INFO:     Epoch: 7
2023-01-04 06:20:50,473 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.562981512149175, 'Total loss': 0.562981512149175} | train loss {'Reaction outcome loss': 0.4767668745497289, 'Total loss': 0.4767668745497289}
2023-01-04 06:20:50,473 INFO:     Found new best model at epoch 7
2023-01-04 06:20:50,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:50,474 INFO:     Epoch: 8
2023-01-04 06:20:52,063 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5692897975444794, 'Total loss': 0.5692897975444794} | train loss {'Reaction outcome loss': 0.46659078903576956, 'Total loss': 0.46659078903576956}
2023-01-04 06:20:52,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:52,063 INFO:     Epoch: 9
2023-01-04 06:20:53,650 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5666180650393168, 'Total loss': 0.5666180650393168} | train loss {'Reaction outcome loss': 0.4616066034520146, 'Total loss': 0.4616066034520146}
2023-01-04 06:20:53,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:53,650 INFO:     Epoch: 10
2023-01-04 06:20:55,260 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5484167893727621, 'Total loss': 0.5484167893727621} | train loss {'Reaction outcome loss': 0.45659839036447475, 'Total loss': 0.45659839036447475}
2023-01-04 06:20:55,260 INFO:     Found new best model at epoch 10
2023-01-04 06:20:55,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:55,261 INFO:     Epoch: 11
2023-01-04 06:20:56,864 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5527015686035156, 'Total loss': 0.5527015686035156} | train loss {'Reaction outcome loss': 0.4459851276573291, 'Total loss': 0.4459851276573291}
2023-01-04 06:20:56,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:56,865 INFO:     Epoch: 12
2023-01-04 06:20:58,387 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5499230364958445, 'Total loss': 0.5499230364958445} | train loss {'Reaction outcome loss': 0.445808299934821, 'Total loss': 0.445808299934821}
2023-01-04 06:20:58,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:58,387 INFO:     Epoch: 13
2023-01-04 06:20:59,992 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5272910714149475, 'Total loss': 0.5272910714149475} | train loss {'Reaction outcome loss': 0.44191703915811187, 'Total loss': 0.44191703915811187}
2023-01-04 06:20:59,992 INFO:     Found new best model at epoch 13
2023-01-04 06:20:59,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:20:59,993 INFO:     Epoch: 14
2023-01-04 06:21:01,575 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5418409109115601, 'Total loss': 0.5418409109115601} | train loss {'Reaction outcome loss': 0.4404148036069388, 'Total loss': 0.4404148036069388}
2023-01-04 06:21:01,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:01,576 INFO:     Epoch: 15
2023-01-04 06:21:03,177 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5045287291208903, 'Total loss': 0.5045287291208903} | train loss {'Reaction outcome loss': 0.43193792263953695, 'Total loss': 0.43193792263953695}
2023-01-04 06:21:03,177 INFO:     Found new best model at epoch 15
2023-01-04 06:21:03,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:03,178 INFO:     Epoch: 16
2023-01-04 06:21:04,790 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.531566392381986, 'Total loss': 0.531566392381986} | train loss {'Reaction outcome loss': 0.42624379898882087, 'Total loss': 0.42624379898882087}
2023-01-04 06:21:04,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:04,790 INFO:     Epoch: 17
2023-01-04 06:21:06,338 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5277790973583857, 'Total loss': 0.5277790973583857} | train loss {'Reaction outcome loss': 0.422552957431504, 'Total loss': 0.422552957431504}
2023-01-04 06:21:06,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:06,338 INFO:     Epoch: 18
2023-01-04 06:21:07,929 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5066877762476604, 'Total loss': 0.5066877762476604} | train loss {'Reaction outcome loss': 0.4189301238324668, 'Total loss': 0.4189301238324668}
2023-01-04 06:21:07,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:07,930 INFO:     Epoch: 19
2023-01-04 06:21:09,549 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5444121181964874, 'Total loss': 0.5444121181964874} | train loss {'Reaction outcome loss': 0.41437454591589284, 'Total loss': 0.41437454591589284}
2023-01-04 06:21:09,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:09,549 INFO:     Epoch: 20
2023-01-04 06:21:11,162 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5208707282940547, 'Total loss': 0.5208707282940547} | train loss {'Reaction outcome loss': 0.41087646879228873, 'Total loss': 0.41087646879228873}
2023-01-04 06:21:11,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:11,162 INFO:     Epoch: 21
2023-01-04 06:21:12,747 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5010992964108785, 'Total loss': 0.5010992964108785} | train loss {'Reaction outcome loss': 0.4075975040451284, 'Total loss': 0.4075975040451284}
2023-01-04 06:21:12,747 INFO:     Found new best model at epoch 21
2023-01-04 06:21:12,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:12,748 INFO:     Epoch: 22
2023-01-04 06:21:14,339 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5203527837991715, 'Total loss': 0.5203527837991715} | train loss {'Reaction outcome loss': 0.4052661660561062, 'Total loss': 0.4052661660561062}
2023-01-04 06:21:14,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:14,340 INFO:     Epoch: 23
2023-01-04 06:21:15,864 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5440875242153803, 'Total loss': 0.5440875242153803} | train loss {'Reaction outcome loss': 0.3976039677750763, 'Total loss': 0.3976039677750763}
2023-01-04 06:21:15,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:15,864 INFO:     Epoch: 24
2023-01-04 06:21:17,453 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.502828000485897, 'Total loss': 0.502828000485897} | train loss {'Reaction outcome loss': 0.3952147028129884, 'Total loss': 0.3952147028129884}
2023-01-04 06:21:17,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:17,454 INFO:     Epoch: 25
2023-01-04 06:21:19,034 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5325976431369781, 'Total loss': 0.5325976431369781} | train loss {'Reaction outcome loss': 0.3929465585505919, 'Total loss': 0.3929465585505919}
2023-01-04 06:21:19,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:19,034 INFO:     Epoch: 26
2023-01-04 06:21:20,628 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5175936003526052, 'Total loss': 0.5175936003526052} | train loss {'Reaction outcome loss': 0.39028785119525794, 'Total loss': 0.39028785119525794}
2023-01-04 06:21:20,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:20,629 INFO:     Epoch: 27
2023-01-04 06:21:22,242 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4956766237815221, 'Total loss': 0.4956766237815221} | train loss {'Reaction outcome loss': 0.3855277278094085, 'Total loss': 0.3855277278094085}
2023-01-04 06:21:22,242 INFO:     Found new best model at epoch 27
2023-01-04 06:21:22,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:22,243 INFO:     Epoch: 28
2023-01-04 06:21:23,797 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5196702321370442, 'Total loss': 0.5196702321370442} | train loss {'Reaction outcome loss': 0.3860183052099999, 'Total loss': 0.3860183052099999}
2023-01-04 06:21:23,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:23,797 INFO:     Epoch: 29
2023-01-04 06:21:25,317 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4890779087940852, 'Total loss': 0.4890779087940852} | train loss {'Reaction outcome loss': 0.3807972796557182, 'Total loss': 0.3807972796557182}
2023-01-04 06:21:25,317 INFO:     Found new best model at epoch 29
2023-01-04 06:21:25,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:25,318 INFO:     Epoch: 30
2023-01-04 06:21:26,920 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4999678005774816, 'Total loss': 0.4999678005774816} | train loss {'Reaction outcome loss': 0.3785451437323102, 'Total loss': 0.3785451437323102}
2023-01-04 06:21:26,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:26,921 INFO:     Epoch: 31
2023-01-04 06:21:28,514 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5103417714436849, 'Total loss': 0.5103417714436849} | train loss {'Reaction outcome loss': 0.3815608595898005, 'Total loss': 0.3815608595898005}
2023-01-04 06:21:28,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:28,514 INFO:     Epoch: 32
2023-01-04 06:21:30,113 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5112676521142324, 'Total loss': 0.5112676521142324} | train loss {'Reaction outcome loss': 0.36790493819257414, 'Total loss': 0.36790493819257414}
2023-01-04 06:21:30,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:30,113 INFO:     Epoch: 33
2023-01-04 06:21:31,716 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5046439200639725, 'Total loss': 0.5046439200639725} | train loss {'Reaction outcome loss': 0.367677849176128, 'Total loss': 0.367677849176128}
2023-01-04 06:21:31,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:31,716 INFO:     Epoch: 34
2023-01-04 06:21:33,320 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.503158821662267, 'Total loss': 0.503158821662267} | train loss {'Reaction outcome loss': 0.36601562090621526, 'Total loss': 0.36601562090621526}
2023-01-04 06:21:33,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:33,320 INFO:     Epoch: 35
2023-01-04 06:21:34,858 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4992751866579056, 'Total loss': 0.4992751866579056} | train loss {'Reaction outcome loss': 0.35972875472333027, 'Total loss': 0.35972875472333027}
2023-01-04 06:21:34,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:34,858 INFO:     Epoch: 36
2023-01-04 06:21:36,474 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48949573139349617, 'Total loss': 0.48949573139349617} | train loss {'Reaction outcome loss': 0.360005798430219, 'Total loss': 0.360005798430219}
2023-01-04 06:21:36,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:36,475 INFO:     Epoch: 37
2023-01-04 06:21:38,076 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5069694598515828, 'Total loss': 0.5069694598515828} | train loss {'Reaction outcome loss': 0.3583824299410362, 'Total loss': 0.3583824299410362}
2023-01-04 06:21:38,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:38,077 INFO:     Epoch: 38
2023-01-04 06:21:39,665 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5216705739498139, 'Total loss': 0.5216705739498139} | train loss {'Reaction outcome loss': 0.35714381957419944, 'Total loss': 0.35714381957419944}
2023-01-04 06:21:39,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:39,665 INFO:     Epoch: 39
2023-01-04 06:21:41,289 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49792307416598003, 'Total loss': 0.49792307416598003} | train loss {'Reaction outcome loss': 0.35427547157456296, 'Total loss': 0.35427547157456296}
2023-01-04 06:21:41,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:41,289 INFO:     Epoch: 40
2023-01-04 06:21:42,844 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4870592087507248, 'Total loss': 0.4870592087507248} | train loss {'Reaction outcome loss': 0.34762457548388503, 'Total loss': 0.34762457548388503}
2023-01-04 06:21:42,844 INFO:     Found new best model at epoch 40
2023-01-04 06:21:42,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:42,845 INFO:     Epoch: 41
2023-01-04 06:21:44,390 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49196958541870117, 'Total loss': 0.49196958541870117} | train loss {'Reaction outcome loss': 0.3436467459001696, 'Total loss': 0.3436467459001696}
2023-01-04 06:21:44,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:44,391 INFO:     Epoch: 42
2023-01-04 06:21:45,949 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5084775418043137, 'Total loss': 0.5084775418043137} | train loss {'Reaction outcome loss': 0.3434350077963908, 'Total loss': 0.3434350077963908}
2023-01-04 06:21:45,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:45,949 INFO:     Epoch: 43
2023-01-04 06:21:47,538 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5068616012732188, 'Total loss': 0.5068616012732188} | train loss {'Reaction outcome loss': 0.3473886772990227, 'Total loss': 0.3473886772990227}
2023-01-04 06:21:47,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:47,538 INFO:     Epoch: 44
2023-01-04 06:21:49,148 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5253480931123098, 'Total loss': 0.5253480931123098} | train loss {'Reaction outcome loss': 0.33702132318316813, 'Total loss': 0.33702132318316813}
2023-01-04 06:21:49,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:49,148 INFO:     Epoch: 45
2023-01-04 06:21:50,753 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4945623775323232, 'Total loss': 0.4945623775323232} | train loss {'Reaction outcome loss': 0.34196300062246704, 'Total loss': 0.34196300062246704}
2023-01-04 06:21:50,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:50,753 INFO:     Epoch: 46
2023-01-04 06:21:52,265 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.484447447458903, 'Total loss': 0.484447447458903} | train loss {'Reaction outcome loss': 0.336177895403726, 'Total loss': 0.336177895403726}
2023-01-04 06:21:52,265 INFO:     Found new best model at epoch 46
2023-01-04 06:21:52,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:52,266 INFO:     Epoch: 47
2023-01-04 06:21:53,853 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.487192044655482, 'Total loss': 0.487192044655482} | train loss {'Reaction outcome loss': 0.33123521549822194, 'Total loss': 0.33123521549822194}
2023-01-04 06:21:53,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:53,853 INFO:     Epoch: 48
2023-01-04 06:21:55,443 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5205891132354736, 'Total loss': 0.5205891132354736} | train loss {'Reaction outcome loss': 0.32966425542850786, 'Total loss': 0.32966425542850786}
2023-01-04 06:21:55,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:55,444 INFO:     Epoch: 49
2023-01-04 06:21:57,066 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4824466009934743, 'Total loss': 0.4824466009934743} | train loss {'Reaction outcome loss': 0.32209766282286456, 'Total loss': 0.32209766282286456}
2023-01-04 06:21:57,067 INFO:     Found new best model at epoch 49
2023-01-04 06:21:57,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:57,068 INFO:     Epoch: 50
2023-01-04 06:21:58,648 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4815557519594828, 'Total loss': 0.4815557519594828} | train loss {'Reaction outcome loss': 0.3264950486404371, 'Total loss': 0.3264950486404371}
2023-01-04 06:21:58,648 INFO:     Found new best model at epoch 50
2023-01-04 06:21:58,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:21:58,649 INFO:     Epoch: 51
2023-01-04 06:22:00,251 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49045424461364745, 'Total loss': 0.49045424461364745} | train loss {'Reaction outcome loss': 0.3207877317060202, 'Total loss': 0.3207877317060202}
2023-01-04 06:22:00,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:00,252 INFO:     Epoch: 52
2023-01-04 06:22:01,773 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49343945235013964, 'Total loss': 0.49343945235013964} | train loss {'Reaction outcome loss': 0.32156682218885596, 'Total loss': 0.32156682218885596}
2023-01-04 06:22:01,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:01,773 INFO:     Epoch: 53
2023-01-04 06:22:03,349 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5303648173809051, 'Total loss': 0.5303648173809051} | train loss {'Reaction outcome loss': 0.3168326229771552, 'Total loss': 0.3168326229771552}
2023-01-04 06:22:03,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:03,349 INFO:     Epoch: 54
2023-01-04 06:22:04,928 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5202397167682647, 'Total loss': 0.5202397167682647} | train loss {'Reaction outcome loss': 0.31587646511595174, 'Total loss': 0.31587646511595174}
2023-01-04 06:22:04,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:04,928 INFO:     Epoch: 55
2023-01-04 06:22:06,533 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5575513382752736, 'Total loss': 0.5575513382752736} | train loss {'Reaction outcome loss': 0.32160825669657883, 'Total loss': 0.32160825669657883}
2023-01-04 06:22:06,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:06,534 INFO:     Epoch: 56
2023-01-04 06:22:08,149 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48723362882932025, 'Total loss': 0.48723362882932025} | train loss {'Reaction outcome loss': 0.3120956021740979, 'Total loss': 0.3120956021740979}
2023-01-04 06:22:08,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:08,149 INFO:     Epoch: 57
2023-01-04 06:22:09,743 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5083245158195495, 'Total loss': 0.5083245158195495} | train loss {'Reaction outcome loss': 0.3113103018340651, 'Total loss': 0.3113103018340651}
2023-01-04 06:22:09,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:09,743 INFO:     Epoch: 58
2023-01-04 06:22:11,280 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5263611475626627, 'Total loss': 0.5263611475626627} | train loss {'Reaction outcome loss': 0.3084763504215096, 'Total loss': 0.3084763504215096}
2023-01-04 06:22:11,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:11,280 INFO:     Epoch: 59
2023-01-04 06:22:12,856 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5085958083470662, 'Total loss': 0.5085958083470662} | train loss {'Reaction outcome loss': 0.3077981342369899, 'Total loss': 0.3077981342369899}
2023-01-04 06:22:12,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:12,857 INFO:     Epoch: 60
2023-01-04 06:22:14,433 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48570560216903685, 'Total loss': 0.48570560216903685} | train loss {'Reaction outcome loss': 0.30817014646013724, 'Total loss': 0.30817014646013724}
2023-01-04 06:22:14,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:14,434 INFO:     Epoch: 61
2023-01-04 06:22:16,061 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5102172454198202, 'Total loss': 0.5102172454198202} | train loss {'Reaction outcome loss': 0.3091982465358417, 'Total loss': 0.3091982465358417}
2023-01-04 06:22:16,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:16,061 INFO:     Epoch: 62
2023-01-04 06:22:17,693 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49509229163328805, 'Total loss': 0.49509229163328805} | train loss {'Reaction outcome loss': 0.30804067758661746, 'Total loss': 0.30804067758661746}
2023-01-04 06:22:17,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:17,693 INFO:     Epoch: 63
2023-01-04 06:22:19,270 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5048917810122172, 'Total loss': 0.5048917810122172} | train loss {'Reaction outcome loss': 0.3020461841960461, 'Total loss': 0.3020461841960461}
2023-01-04 06:22:19,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:19,270 INFO:     Epoch: 64
2023-01-04 06:22:20,867 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5536223630110423, 'Total loss': 0.5536223630110423} | train loss {'Reaction outcome loss': 0.30088183364498056, 'Total loss': 0.30088183364498056}
2023-01-04 06:22:20,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:20,868 INFO:     Epoch: 65
2023-01-04 06:22:22,494 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5201611677805583, 'Total loss': 0.5201611677805583} | train loss {'Reaction outcome loss': 0.29677688850876655, 'Total loss': 0.29677688850876655}
2023-01-04 06:22:22,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:22,494 INFO:     Epoch: 66
2023-01-04 06:22:24,128 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5169774572054545, 'Total loss': 0.5169774572054545} | train loss {'Reaction outcome loss': 0.29529058704630134, 'Total loss': 0.29529058704630134}
2023-01-04 06:22:24,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:24,128 INFO:     Epoch: 67
2023-01-04 06:22:25,747 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.526933224995931, 'Total loss': 0.526933224995931} | train loss {'Reaction outcome loss': 0.29517579382614967, 'Total loss': 0.29517579382614967}
2023-01-04 06:22:25,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:25,747 INFO:     Epoch: 68
2023-01-04 06:22:27,360 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49848423302173617, 'Total loss': 0.49848423302173617} | train loss {'Reaction outcome loss': 0.29521378917814595, 'Total loss': 0.29521378917814595}
2023-01-04 06:22:27,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:27,360 INFO:     Epoch: 69
2023-01-04 06:22:28,912 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5225525359312694, 'Total loss': 0.5225525359312694} | train loss {'Reaction outcome loss': 0.29493348426874794, 'Total loss': 0.29493348426874794}
2023-01-04 06:22:28,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:28,913 INFO:     Epoch: 70
2023-01-04 06:22:30,537 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5027474065621694, 'Total loss': 0.5027474065621694} | train loss {'Reaction outcome loss': 0.29080698149621703, 'Total loss': 0.29080698149621703}
2023-01-04 06:22:30,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:30,537 INFO:     Epoch: 71
2023-01-04 06:22:32,165 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5210175315539042, 'Total loss': 0.5210175315539042} | train loss {'Reaction outcome loss': 0.29138356223971407, 'Total loss': 0.29138356223971407}
2023-01-04 06:22:32,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:32,165 INFO:     Epoch: 72
2023-01-04 06:22:33,790 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5067268321911494, 'Total loss': 0.5067268321911494} | train loss {'Reaction outcome loss': 0.2903753533582825, 'Total loss': 0.2903753533582825}
2023-01-04 06:22:33,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:33,790 INFO:     Epoch: 73
2023-01-04 06:22:35,417 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5004667580127716, 'Total loss': 0.5004667580127716} | train loss {'Reaction outcome loss': 0.28783500528077355, 'Total loss': 0.28783500528077355}
2023-01-04 06:22:35,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:35,417 INFO:     Epoch: 74
2023-01-04 06:22:37,037 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5143399278322855, 'Total loss': 0.5143399278322855} | train loss {'Reaction outcome loss': 0.28954794104564063, 'Total loss': 0.28954794104564063}
2023-01-04 06:22:37,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:37,037 INFO:     Epoch: 75
2023-01-04 06:22:38,596 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4994494597117106, 'Total loss': 0.4994494597117106} | train loss {'Reaction outcome loss': 0.2822561151203481, 'Total loss': 0.2822561151203481}
2023-01-04 06:22:38,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:38,596 INFO:     Epoch: 76
2023-01-04 06:22:40,223 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5130743384361267, 'Total loss': 0.5130743384361267} | train loss {'Reaction outcome loss': 0.28271524613514704, 'Total loss': 0.28271524613514704}
2023-01-04 06:22:40,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:40,224 INFO:     Epoch: 77
2023-01-04 06:22:41,831 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4940719485282898, 'Total loss': 0.4940719485282898} | train loss {'Reaction outcome loss': 0.2831871360271416, 'Total loss': 0.2831871360271416}
2023-01-04 06:22:41,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:41,831 INFO:     Epoch: 78
2023-01-04 06:22:43,454 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4867196768522263, 'Total loss': 0.4867196768522263} | train loss {'Reaction outcome loss': 0.282425761464916, 'Total loss': 0.282425761464916}
2023-01-04 06:22:43,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:43,454 INFO:     Epoch: 79
2023-01-04 06:22:45,074 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5062275409698487, 'Total loss': 0.5062275409698487} | train loss {'Reaction outcome loss': 0.2826422379227752, 'Total loss': 0.2826422379227752}
2023-01-04 06:22:45,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:45,076 INFO:     Epoch: 80
2023-01-04 06:22:46,635 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4904021968444188, 'Total loss': 0.4904021968444188} | train loss {'Reaction outcome loss': 0.2811043639583278, 'Total loss': 0.2811043639583278}
2023-01-04 06:22:46,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:46,635 INFO:     Epoch: 81
2023-01-04 06:22:48,236 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5030642777681351, 'Total loss': 0.5030642777681351} | train loss {'Reaction outcome loss': 0.27939035883341456, 'Total loss': 0.27939035883341456}
2023-01-04 06:22:48,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:48,236 INFO:     Epoch: 82
2023-01-04 06:22:49,794 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4842701156934102, 'Total loss': 0.4842701156934102} | train loss {'Reaction outcome loss': 0.27612608298659325, 'Total loss': 0.27612608298659325}
2023-01-04 06:22:49,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:49,794 INFO:     Epoch: 83
2023-01-04 06:22:51,356 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49947965641816455, 'Total loss': 0.49947965641816455} | train loss {'Reaction outcome loss': 0.2760483257284233, 'Total loss': 0.2760483257284233}
2023-01-04 06:22:51,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:51,357 INFO:     Epoch: 84
2023-01-04 06:22:52,930 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5137462794780732, 'Total loss': 0.5137462794780732} | train loss {'Reaction outcome loss': 0.27581035248289687, 'Total loss': 0.27581035248289687}
2023-01-04 06:22:52,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:52,931 INFO:     Epoch: 85
2023-01-04 06:22:54,505 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5296449462572733, 'Total loss': 0.5296449462572733} | train loss {'Reaction outcome loss': 0.27359380641622666, 'Total loss': 0.27359380641622666}
2023-01-04 06:22:54,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:54,505 INFO:     Epoch: 86
2023-01-04 06:22:56,004 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5021053532759349, 'Total loss': 0.5021053532759349} | train loss {'Reaction outcome loss': 0.27669380018857415, 'Total loss': 0.27669380018857415}
2023-01-04 06:22:56,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:56,004 INFO:     Epoch: 87
2023-01-04 06:22:57,584 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5115152418613433, 'Total loss': 0.5115152418613433} | train loss {'Reaction outcome loss': 0.2725195005159516, 'Total loss': 0.2725195005159516}
2023-01-04 06:22:57,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:57,584 INFO:     Epoch: 88
2023-01-04 06:22:59,170 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5059701859951019, 'Total loss': 0.5059701859951019} | train loss {'Reaction outcome loss': 0.27165946482751346, 'Total loss': 0.27165946482751346}
2023-01-04 06:22:59,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:22:59,170 INFO:     Epoch: 89
2023-01-04 06:23:00,734 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4905403887232145, 'Total loss': 0.4905403887232145} | train loss {'Reaction outcome loss': 0.268443063842906, 'Total loss': 0.268443063842906}
2023-01-04 06:23:00,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:00,734 INFO:     Epoch: 90
2023-01-04 06:23:02,313 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.503074711561203, 'Total loss': 0.503074711561203} | train loss {'Reaction outcome loss': 0.26674470727732036, 'Total loss': 0.26674470727732036}
2023-01-04 06:23:02,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:02,313 INFO:     Epoch: 91
2023-01-04 06:23:03,881 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5061572114626567, 'Total loss': 0.5061572114626567} | train loss {'Reaction outcome loss': 0.26991989584606046, 'Total loss': 0.26991989584606046}
2023-01-04 06:23:03,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:03,882 INFO:     Epoch: 92
2023-01-04 06:23:05,382 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5234407345453899, 'Total loss': 0.5234407345453899} | train loss {'Reaction outcome loss': 0.26905976295040834, 'Total loss': 0.26905976295040834}
2023-01-04 06:23:05,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:05,382 INFO:     Epoch: 93
2023-01-04 06:23:06,944 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5155926624933879, 'Total loss': 0.5155926624933879} | train loss {'Reaction outcome loss': 0.2650046763867678, 'Total loss': 0.2650046763867678}
2023-01-04 06:23:06,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:06,944 INFO:     Epoch: 94
2023-01-04 06:23:08,529 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5146916548411051, 'Total loss': 0.5146916548411051} | train loss {'Reaction outcome loss': 0.26431493432889774, 'Total loss': 0.26431493432889774}
2023-01-04 06:23:08,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:08,529 INFO:     Epoch: 95
2023-01-04 06:23:10,101 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4756506716211637, 'Total loss': 0.4756506716211637} | train loss {'Reaction outcome loss': 0.269246603338727, 'Total loss': 0.269246603338727}
2023-01-04 06:23:10,101 INFO:     Found new best model at epoch 95
2023-01-04 06:23:10,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:10,102 INFO:     Epoch: 96
2023-01-04 06:23:11,662 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5262240469455719, 'Total loss': 0.5262240469455719} | train loss {'Reaction outcome loss': 0.2601609436344584, 'Total loss': 0.2601609436344584}
2023-01-04 06:23:11,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:11,662 INFO:     Epoch: 97
2023-01-04 06:23:13,185 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46884629329045613, 'Total loss': 0.46884629329045613} | train loss {'Reaction outcome loss': 0.2647513111898615, 'Total loss': 0.2647513111898615}
2023-01-04 06:23:13,185 INFO:     Found new best model at epoch 97
2023-01-04 06:23:13,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:13,186 INFO:     Epoch: 98
2023-01-04 06:23:14,659 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5042863428592682, 'Total loss': 0.5042863428592682} | train loss {'Reaction outcome loss': 0.2595866082592561, 'Total loss': 0.2595866082592561}
2023-01-04 06:23:14,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:14,659 INFO:     Epoch: 99
2023-01-04 06:23:16,251 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4845681597789129, 'Total loss': 0.4845681597789129} | train loss {'Reaction outcome loss': 0.26463068197296413, 'Total loss': 0.26463068197296413}
2023-01-04 06:23:16,252 INFO:     Best model found after epoch 98 of 100.
2023-01-04 06:23:16,252 INFO:   Done with stage: TRAINING
2023-01-04 06:23:16,252 INFO:   Starting stage: EVALUATION
2023-01-04 06:23:16,373 INFO:   Done with stage: EVALUATION
2023-01-04 06:23:16,373 INFO:   Leaving out SEQ value Fold_8
2023-01-04 06:23:16,385 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 06:23:16,385 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:23:17,034 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:23:17,034 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:23:17,104 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:23:17,104 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:23:17,105 INFO:     No hyperparam tuning for this model
2023-01-04 06:23:17,105 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:23:17,105 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:23:17,105 INFO:     None feature selector for col prot
2023-01-04 06:23:17,106 INFO:     None feature selector for col prot
2023-01-04 06:23:17,106 INFO:     None feature selector for col prot
2023-01-04 06:23:17,106 INFO:     None feature selector for col chem
2023-01-04 06:23:17,106 INFO:     None feature selector for col chem
2023-01-04 06:23:17,106 INFO:     None feature selector for col chem
2023-01-04 06:23:17,106 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:23:17,106 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:23:17,107 INFO:     Number of params in model 70111
2023-01-04 06:23:17,111 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:23:17,111 INFO:   Starting stage: TRAINING
2023-01-04 06:23:17,153 INFO:     Val loss before train {'Reaction outcome loss': 1.136590588092804, 'Total loss': 1.136590588092804}
2023-01-04 06:23:17,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:17,153 INFO:     Epoch: 0
2023-01-04 06:23:18,749 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8222893377145132, 'Total loss': 0.8222893377145132} | train loss {'Reaction outcome loss': 0.8407753512695215, 'Total loss': 0.8407753512695215}
2023-01-04 06:23:18,749 INFO:     Found new best model at epoch 0
2023-01-04 06:23:18,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:18,749 INFO:     Epoch: 1
2023-01-04 06:23:20,336 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6684512317180633, 'Total loss': 0.6684512317180633} | train loss {'Reaction outcome loss': 0.6737571061197398, 'Total loss': 0.6737571061197398}
2023-01-04 06:23:20,336 INFO:     Found new best model at epoch 1
2023-01-04 06:23:20,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:20,337 INFO:     Epoch: 2
2023-01-04 06:23:21,903 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5985551873842875, 'Total loss': 0.5985551873842875} | train loss {'Reaction outcome loss': 0.5800659614075245, 'Total loss': 0.5800659614075245}
2023-01-04 06:23:21,903 INFO:     Found new best model at epoch 2
2023-01-04 06:23:21,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:21,904 INFO:     Epoch: 3
2023-01-04 06:23:23,411 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.594439568122228, 'Total loss': 0.594439568122228} | train loss {'Reaction outcome loss': 0.5374567464965841, 'Total loss': 0.5374567464965841}
2023-01-04 06:23:23,411 INFO:     Found new best model at epoch 3
2023-01-04 06:23:23,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:23,412 INFO:     Epoch: 4
2023-01-04 06:23:25,001 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5728438357512157, 'Total loss': 0.5728438357512157} | train loss {'Reaction outcome loss': 0.5181363462082421, 'Total loss': 0.5181363462082421}
2023-01-04 06:23:25,001 INFO:     Found new best model at epoch 4
2023-01-04 06:23:25,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:25,002 INFO:     Epoch: 5
2023-01-04 06:23:26,585 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5501420636971791, 'Total loss': 0.5501420636971791} | train loss {'Reaction outcome loss': 0.5094999753586624, 'Total loss': 0.5094999753586624}
2023-01-04 06:23:26,586 INFO:     Found new best model at epoch 5
2023-01-04 06:23:26,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:26,586 INFO:     Epoch: 6
2023-01-04 06:23:28,135 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5638807753721873, 'Total loss': 0.5638807753721873} | train loss {'Reaction outcome loss': 0.4933013013307599, 'Total loss': 0.4933013013307599}
2023-01-04 06:23:28,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:28,135 INFO:     Epoch: 7
2023-01-04 06:23:29,699 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.57804128130277, 'Total loss': 0.57804128130277} | train loss {'Reaction outcome loss': 0.488648206697426, 'Total loss': 0.488648206697426}
2023-01-04 06:23:29,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:29,699 INFO:     Epoch: 8
2023-01-04 06:23:31,272 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5836886505285899, 'Total loss': 0.5836886505285899} | train loss {'Reaction outcome loss': 0.48450325657714804, 'Total loss': 0.48450325657714804}
2023-01-04 06:23:31,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:31,272 INFO:     Epoch: 9
2023-01-04 06:23:32,812 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5491079250971477, 'Total loss': 0.5491079250971477} | train loss {'Reaction outcome loss': 0.4703049167882705, 'Total loss': 0.4703049167882705}
2023-01-04 06:23:32,813 INFO:     Found new best model at epoch 9
2023-01-04 06:23:32,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:32,813 INFO:     Epoch: 10
2023-01-04 06:23:34,427 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5441489199797312, 'Total loss': 0.5441489199797312} | train loss {'Reaction outcome loss': 0.48311349603792897, 'Total loss': 0.48311349603792897}
2023-01-04 06:23:34,427 INFO:     Found new best model at epoch 10
2023-01-04 06:23:34,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:34,427 INFO:     Epoch: 11
2023-01-04 06:23:36,054 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5369672318299611, 'Total loss': 0.5369672318299611} | train loss {'Reaction outcome loss': 0.49114695358751476, 'Total loss': 0.49114695358751476}
2023-01-04 06:23:36,054 INFO:     Found new best model at epoch 11
2023-01-04 06:23:36,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:36,055 INFO:     Epoch: 12
2023-01-04 06:23:37,686 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5462714652220408, 'Total loss': 0.5462714652220408} | train loss {'Reaction outcome loss': 0.4816607145619565, 'Total loss': 0.4816607145619565}
2023-01-04 06:23:37,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:37,687 INFO:     Epoch: 13
2023-01-04 06:23:39,311 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5296266982952754, 'Total loss': 0.5296266982952754} | train loss {'Reaction outcome loss': 0.4711887149707131, 'Total loss': 0.4711887149707131}
2023-01-04 06:23:39,311 INFO:     Found new best model at epoch 13
2023-01-04 06:23:39,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:39,312 INFO:     Epoch: 14
2023-01-04 06:23:40,875 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5362512727578481, 'Total loss': 0.5362512727578481} | train loss {'Reaction outcome loss': 0.450991004317378, 'Total loss': 0.450991004317378}
2023-01-04 06:23:40,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:40,875 INFO:     Epoch: 15
2023-01-04 06:23:42,492 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.535751336812973, 'Total loss': 0.535751336812973} | train loss {'Reaction outcome loss': 0.4383941329811089, 'Total loss': 0.4383941329811089}
2023-01-04 06:23:42,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:42,492 INFO:     Epoch: 16
2023-01-04 06:23:44,115 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5144820729891459, 'Total loss': 0.5144820729891459} | train loss {'Reaction outcome loss': 0.43651382714017306, 'Total loss': 0.43651382714017306}
2023-01-04 06:23:44,116 INFO:     Found new best model at epoch 16
2023-01-04 06:23:44,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:44,116 INFO:     Epoch: 17
2023-01-04 06:23:45,742 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5074387113253276, 'Total loss': 0.5074387113253276} | train loss {'Reaction outcome loss': 0.4328307305155592, 'Total loss': 0.4328307305155592}
2023-01-04 06:23:45,742 INFO:     Found new best model at epoch 17
2023-01-04 06:23:45,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:45,743 INFO:     Epoch: 18
2023-01-04 06:23:47,365 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5304410894711812, 'Total loss': 0.5304410894711812} | train loss {'Reaction outcome loss': 0.4298892879575589, 'Total loss': 0.4298892879575589}
2023-01-04 06:23:47,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:47,366 INFO:     Epoch: 19
2023-01-04 06:23:48,998 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5051010688145955, 'Total loss': 0.5051010688145955} | train loss {'Reaction outcome loss': 0.42627318628955685, 'Total loss': 0.42627318628955685}
2023-01-04 06:23:48,999 INFO:     Found new best model at epoch 19
2023-01-04 06:23:48,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:48,999 INFO:     Epoch: 20
2023-01-04 06:23:50,548 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5121318568785985, 'Total loss': 0.5121318568785985} | train loss {'Reaction outcome loss': 0.42499486383968504, 'Total loss': 0.42499486383968504}
2023-01-04 06:23:50,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:50,548 INFO:     Epoch: 21
2023-01-04 06:23:52,177 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.512905208269755, 'Total loss': 0.512905208269755} | train loss {'Reaction outcome loss': 0.42361578113142995, 'Total loss': 0.42361578113142995}
2023-01-04 06:23:52,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:52,179 INFO:     Epoch: 22
2023-01-04 06:23:53,796 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5245283444722494, 'Total loss': 0.5245283444722494} | train loss {'Reaction outcome loss': 0.4151504193905039, 'Total loss': 0.4151504193905039}
2023-01-04 06:23:53,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:53,796 INFO:     Epoch: 23
2023-01-04 06:23:55,415 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5087002654870351, 'Total loss': 0.5087002654870351} | train loss {'Reaction outcome loss': 0.4126453752076064, 'Total loss': 0.4126453752076064}
2023-01-04 06:23:55,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:55,415 INFO:     Epoch: 24
2023-01-04 06:23:57,044 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5425595303376516, 'Total loss': 0.5425595303376516} | train loss {'Reaction outcome loss': 0.4098907712655816, 'Total loss': 0.4098907712655816}
2023-01-04 06:23:57,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:57,044 INFO:     Epoch: 25
2023-01-04 06:23:58,667 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5350524812936783, 'Total loss': 0.5350524812936783} | train loss {'Reaction outcome loss': 0.4053999195704186, 'Total loss': 0.4053999195704186}
2023-01-04 06:23:58,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:23:58,668 INFO:     Epoch: 26
2023-01-04 06:24:00,215 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5013505736986796, 'Total loss': 0.5013505736986796} | train loss {'Reaction outcome loss': 0.40977488220601843, 'Total loss': 0.40977488220601843}
2023-01-04 06:24:00,215 INFO:     Found new best model at epoch 26
2023-01-04 06:24:00,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:00,216 INFO:     Epoch: 27
2023-01-04 06:24:01,841 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4841249903043111, 'Total loss': 0.4841249903043111} | train loss {'Reaction outcome loss': 0.41932777993587894, 'Total loss': 0.41932777993587894}
2023-01-04 06:24:01,841 INFO:     Found new best model at epoch 27
2023-01-04 06:24:01,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:01,842 INFO:     Epoch: 28
2023-01-04 06:24:03,461 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4919413189093272, 'Total loss': 0.4919413189093272} | train loss {'Reaction outcome loss': 0.39678179343362624, 'Total loss': 0.39678179343362624}
2023-01-04 06:24:03,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:03,461 INFO:     Epoch: 29
2023-01-04 06:24:05,093 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4862126290798187, 'Total loss': 0.4862126290798187} | train loss {'Reaction outcome loss': 0.393111921954846, 'Total loss': 0.393111921954846}
2023-01-04 06:24:05,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:05,093 INFO:     Epoch: 30
2023-01-04 06:24:06,717 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4853119234244029, 'Total loss': 0.4853119234244029} | train loss {'Reaction outcome loss': 0.3913086048880781, 'Total loss': 0.3913086048880781}
2023-01-04 06:24:06,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:06,718 INFO:     Epoch: 31
2023-01-04 06:24:08,242 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46942161122957865, 'Total loss': 0.46942161122957865} | train loss {'Reaction outcome loss': 0.38507348645910405, 'Total loss': 0.38507348645910405}
2023-01-04 06:24:08,242 INFO:     Found new best model at epoch 31
2023-01-04 06:24:08,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:08,243 INFO:     Epoch: 32
2023-01-04 06:24:09,804 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46967497169971467, 'Total loss': 0.46967497169971467} | train loss {'Reaction outcome loss': 0.39140735140097316, 'Total loss': 0.39140735140097316}
2023-01-04 06:24:09,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:09,804 INFO:     Epoch: 33
2023-01-04 06:24:11,392 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4750455737113953, 'Total loss': 0.4750455737113953} | train loss {'Reaction outcome loss': 0.3902349530219816, 'Total loss': 0.3902349530219816}
2023-01-04 06:24:11,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:11,393 INFO:     Epoch: 34
2023-01-04 06:24:12,974 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49069488048553467, 'Total loss': 0.49069488048553467} | train loss {'Reaction outcome loss': 0.37609252792553627, 'Total loss': 0.37609252792553627}
2023-01-04 06:24:12,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:12,974 INFO:     Epoch: 35
2023-01-04 06:24:14,552 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47243327101071675, 'Total loss': 0.47243327101071675} | train loss {'Reaction outcome loss': 0.3712669823591199, 'Total loss': 0.3712669823591199}
2023-01-04 06:24:14,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:14,552 INFO:     Epoch: 36
2023-01-04 06:24:16,138 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48111695746580757, 'Total loss': 0.48111695746580757} | train loss {'Reaction outcome loss': 0.36582253357356304, 'Total loss': 0.36582253357356304}
2023-01-04 06:24:16,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:16,138 INFO:     Epoch: 37
2023-01-04 06:24:17,682 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49076045453548434, 'Total loss': 0.49076045453548434} | train loss {'Reaction outcome loss': 0.3648063585270142, 'Total loss': 0.3648063585270142}
2023-01-04 06:24:17,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:17,682 INFO:     Epoch: 38
2023-01-04 06:24:19,306 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4832261443138123, 'Total loss': 0.4832261443138123} | train loss {'Reaction outcome loss': 0.3651376504322811, 'Total loss': 0.3651376504322811}
2023-01-04 06:24:19,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:19,306 INFO:     Epoch: 39
2023-01-04 06:24:20,936 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4652024259169896, 'Total loss': 0.4652024259169896} | train loss {'Reaction outcome loss': 0.36251324129061424, 'Total loss': 0.36251324129061424}
2023-01-04 06:24:20,936 INFO:     Found new best model at epoch 39
2023-01-04 06:24:20,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:20,937 INFO:     Epoch: 40
2023-01-04 06:24:22,568 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5016556918621063, 'Total loss': 0.5016556918621063} | train loss {'Reaction outcome loss': 0.3586504656065264, 'Total loss': 0.3586504656065264}
2023-01-04 06:24:22,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:22,568 INFO:     Epoch: 41
2023-01-04 06:24:24,196 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4613933821519216, 'Total loss': 0.4613933821519216} | train loss {'Reaction outcome loss': 0.35788392812432046, 'Total loss': 0.35788392812432046}
2023-01-04 06:24:24,196 INFO:     Found new best model at epoch 41
2023-01-04 06:24:24,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:24,197 INFO:     Epoch: 42
2023-01-04 06:24:25,783 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47523244718710583, 'Total loss': 0.47523244718710583} | train loss {'Reaction outcome loss': 0.3504284787045765, 'Total loss': 0.3504284787045765}
2023-01-04 06:24:25,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:25,784 INFO:     Epoch: 43
2023-01-04 06:24:27,298 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4729490980505943, 'Total loss': 0.4729490980505943} | train loss {'Reaction outcome loss': 0.3499433552804977, 'Total loss': 0.3499433552804977}
2023-01-04 06:24:27,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:27,299 INFO:     Epoch: 44
2023-01-04 06:24:28,873 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4759564946095149, 'Total loss': 0.4759564946095149} | train loss {'Reaction outcome loss': 0.3470515208595105, 'Total loss': 0.3470515208595105}
2023-01-04 06:24:28,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:28,874 INFO:     Epoch: 45
2023-01-04 06:24:30,439 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4799387673536936, 'Total loss': 0.4799387673536936} | train loss {'Reaction outcome loss': 0.3491455244737259, 'Total loss': 0.3491455244737259}
2023-01-04 06:24:30,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:30,440 INFO:     Epoch: 46
2023-01-04 06:24:32,015 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5044121384620667, 'Total loss': 0.5044121384620667} | train loss {'Reaction outcome loss': 0.35323903315525124, 'Total loss': 0.35323903315525124}
2023-01-04 06:24:32,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:32,015 INFO:     Epoch: 47
2023-01-04 06:24:33,588 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.497391951084137, 'Total loss': 0.497391951084137} | train loss {'Reaction outcome loss': 0.33833318746284297, 'Total loss': 0.33833318746284297}
2023-01-04 06:24:33,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:33,589 INFO:     Epoch: 48
2023-01-04 06:24:35,140 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4772461990515391, 'Total loss': 0.4772461990515391} | train loss {'Reaction outcome loss': 0.3408019434697791, 'Total loss': 0.3408019434697791}
2023-01-04 06:24:35,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:35,141 INFO:     Epoch: 49
2023-01-04 06:24:36,665 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4862106362978617, 'Total loss': 0.4862106362978617} | train loss {'Reaction outcome loss': 0.33280984649731626, 'Total loss': 0.33280984649731626}
2023-01-04 06:24:36,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:36,666 INFO:     Epoch: 50
2023-01-04 06:24:38,220 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5018541892369588, 'Total loss': 0.5018541892369588} | train loss {'Reaction outcome loss': 0.3354882797887684, 'Total loss': 0.3354882797887684}
2023-01-04 06:24:38,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:38,220 INFO:     Epoch: 51
2023-01-04 06:24:39,794 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4608626484870911, 'Total loss': 0.4608626484870911} | train loss {'Reaction outcome loss': 0.33030712728699047, 'Total loss': 0.33030712728699047}
2023-01-04 06:24:39,794 INFO:     Found new best model at epoch 51
2023-01-04 06:24:39,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:39,795 INFO:     Epoch: 52
2023-01-04 06:24:41,395 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4638146976629893, 'Total loss': 0.4638146976629893} | train loss {'Reaction outcome loss': 0.3246472921438407, 'Total loss': 0.3246472921438407}
2023-01-04 06:24:41,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:41,395 INFO:     Epoch: 53
2023-01-04 06:24:42,969 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4627051462729772, 'Total loss': 0.4627051462729772} | train loss {'Reaction outcome loss': 0.3291786698138584, 'Total loss': 0.3291786698138584}
2023-01-04 06:24:42,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:42,969 INFO:     Epoch: 54
2023-01-04 06:24:44,491 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4856794317563375, 'Total loss': 0.4856794317563375} | train loss {'Reaction outcome loss': 0.3249755056871884, 'Total loss': 0.3249755056871884}
2023-01-04 06:24:44,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:44,491 INFO:     Epoch: 55
2023-01-04 06:24:46,024 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48341616690158845, 'Total loss': 0.48341616690158845} | train loss {'Reaction outcome loss': 0.33340969619651634, 'Total loss': 0.33340969619651634}
2023-01-04 06:24:46,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:46,025 INFO:     Epoch: 56
2023-01-04 06:24:47,586 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46501723329226174, 'Total loss': 0.46501723329226174} | train loss {'Reaction outcome loss': 0.34456412944370607, 'Total loss': 0.34456412944370607}
2023-01-04 06:24:47,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:47,586 INFO:     Epoch: 57
2023-01-04 06:24:49,166 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4441521942615509, 'Total loss': 0.4441521942615509} | train loss {'Reaction outcome loss': 0.318828300792265, 'Total loss': 0.318828300792265}
2023-01-04 06:24:49,166 INFO:     Found new best model at epoch 57
2023-01-04 06:24:49,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:49,167 INFO:     Epoch: 58
2023-01-04 06:24:50,729 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.453816294670105, 'Total loss': 0.453816294670105} | train loss {'Reaction outcome loss': 0.31631442300124984, 'Total loss': 0.31631442300124984}
2023-01-04 06:24:50,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:50,730 INFO:     Epoch: 59
2023-01-04 06:24:52,277 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4707844575246175, 'Total loss': 0.4707844575246175} | train loss {'Reaction outcome loss': 0.3148976588078728, 'Total loss': 0.3148976588078728}
2023-01-04 06:24:52,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:52,277 INFO:     Epoch: 60
2023-01-04 06:24:53,768 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48668416142463683, 'Total loss': 0.48668416142463683} | train loss {'Reaction outcome loss': 0.3175632687204558, 'Total loss': 0.3175632687204558}
2023-01-04 06:24:53,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:53,768 INFO:     Epoch: 61
2023-01-04 06:24:55,310 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.503357877333959, 'Total loss': 0.503357877333959} | train loss {'Reaction outcome loss': 0.3240142320080296, 'Total loss': 0.3240142320080296}
2023-01-04 06:24:55,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:55,311 INFO:     Epoch: 62
2023-01-04 06:24:56,847 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4795452435811361, 'Total loss': 0.4795452435811361} | train loss {'Reaction outcome loss': 0.3369602512406266, 'Total loss': 0.3369602512406266}
2023-01-04 06:24:56,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:56,847 INFO:     Epoch: 63
2023-01-04 06:24:58,400 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44197418093681334, 'Total loss': 0.44197418093681334} | train loss {'Reaction outcome loss': 0.3066228716948451, 'Total loss': 0.3066228716948451}
2023-01-04 06:24:58,401 INFO:     Found new best model at epoch 63
2023-01-04 06:24:58,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:58,402 INFO:     Epoch: 64
2023-01-04 06:24:59,938 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4306537538766861, 'Total loss': 0.4306537538766861} | train loss {'Reaction outcome loss': 0.3028186361062462, 'Total loss': 0.3028186361062462}
2023-01-04 06:24:59,938 INFO:     Found new best model at epoch 64
2023-01-04 06:24:59,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:24:59,939 INFO:     Epoch: 65
2023-01-04 06:25:01,478 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4584326128164927, 'Total loss': 0.4584326128164927} | train loss {'Reaction outcome loss': 0.3032817702928235, 'Total loss': 0.3032817702928235}
2023-01-04 06:25:01,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:01,479 INFO:     Epoch: 66
2023-01-04 06:25:02,959 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4508982648452123, 'Total loss': 0.4508982648452123} | train loss {'Reaction outcome loss': 0.3009270961949791, 'Total loss': 0.3009270961949791}
2023-01-04 06:25:02,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:02,959 INFO:     Epoch: 67
2023-01-04 06:25:04,493 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4521404127279917, 'Total loss': 0.4521404127279917} | train loss {'Reaction outcome loss': 0.3017947617918253, 'Total loss': 0.3017947617918253}
2023-01-04 06:25:04,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:04,494 INFO:     Epoch: 68
2023-01-04 06:25:06,039 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45898271799087526, 'Total loss': 0.45898271799087526} | train loss {'Reaction outcome loss': 0.3098766061893253, 'Total loss': 0.3098766061893253}
2023-01-04 06:25:06,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:06,039 INFO:     Epoch: 69
2023-01-04 06:25:07,584 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4498507618904114, 'Total loss': 0.4498507618904114} | train loss {'Reaction outcome loss': 0.3020738931507736, 'Total loss': 0.3020738931507736}
2023-01-04 06:25:07,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:07,584 INFO:     Epoch: 70
2023-01-04 06:25:09,126 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4228870103756587, 'Total loss': 0.4228870103756587} | train loss {'Reaction outcome loss': 0.30350993291485, 'Total loss': 0.30350993291485}
2023-01-04 06:25:09,126 INFO:     Found new best model at epoch 70
2023-01-04 06:25:09,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:09,127 INFO:     Epoch: 71
2023-01-04 06:25:10,670 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4311897665262222, 'Total loss': 0.4311897665262222} | train loss {'Reaction outcome loss': 0.30453233590916445, 'Total loss': 0.30453233590916445}
2023-01-04 06:25:10,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:10,670 INFO:     Epoch: 72
2023-01-04 06:25:12,155 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4371038009723028, 'Total loss': 0.4371038009723028} | train loss {'Reaction outcome loss': 0.31839674972529197, 'Total loss': 0.31839674972529197}
2023-01-04 06:25:12,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:12,156 INFO:     Epoch: 73
2023-01-04 06:25:13,684 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.493157958984375, 'Total loss': 0.493157958984375} | train loss {'Reaction outcome loss': 0.2962543248921039, 'Total loss': 0.2962543248921039}
2023-01-04 06:25:13,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:13,684 INFO:     Epoch: 74
2023-01-04 06:25:15,229 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42667163113753, 'Total loss': 0.42667163113753} | train loss {'Reaction outcome loss': 0.2904572777747028, 'Total loss': 0.2904572777747028}
2023-01-04 06:25:15,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:15,229 INFO:     Epoch: 75
2023-01-04 06:25:16,776 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4477346420288086, 'Total loss': 0.4477346420288086} | train loss {'Reaction outcome loss': 0.29286412396670686, 'Total loss': 0.29286412396670686}
2023-01-04 06:25:16,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:16,777 INFO:     Epoch: 76
2023-01-04 06:25:18,343 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4524695654710134, 'Total loss': 0.4524695654710134} | train loss {'Reaction outcome loss': 0.2976967065824547, 'Total loss': 0.2976967065824547}
2023-01-04 06:25:18,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:18,343 INFO:     Epoch: 77
2023-01-04 06:25:19,906 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42095458606878916, 'Total loss': 0.42095458606878916} | train loss {'Reaction outcome loss': 0.30407124433153565, 'Total loss': 0.30407124433153565}
2023-01-04 06:25:19,906 INFO:     Found new best model at epoch 77
2023-01-04 06:25:19,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:19,907 INFO:     Epoch: 78
2023-01-04 06:25:21,266 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4501581092675527, 'Total loss': 0.4501581092675527} | train loss {'Reaction outcome loss': 0.29690135583497473, 'Total loss': 0.29690135583497473}
2023-01-04 06:25:21,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:21,266 INFO:     Epoch: 79
2023-01-04 06:25:22,295 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43662815789381665, 'Total loss': 0.43662815789381665} | train loss {'Reaction outcome loss': 0.33129403897918813, 'Total loss': 0.33129403897918813}
2023-01-04 06:25:22,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:22,296 INFO:     Epoch: 80
2023-01-04 06:25:23,320 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4515738825003306, 'Total loss': 0.4515738825003306} | train loss {'Reaction outcome loss': 0.31208783830853476, 'Total loss': 0.31208783830853476}
2023-01-04 06:25:23,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:23,320 INFO:     Epoch: 81
2023-01-04 06:25:24,345 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4362158586581548, 'Total loss': 0.4362158586581548} | train loss {'Reaction outcome loss': 0.29463350880837097, 'Total loss': 0.29463350880837097}
2023-01-04 06:25:24,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:24,345 INFO:     Epoch: 82
2023-01-04 06:25:25,465 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44878689050674436, 'Total loss': 0.44878689050674436} | train loss {'Reaction outcome loss': 0.2996727843377469, 'Total loss': 0.2996727843377469}
2023-01-04 06:25:25,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:25,465 INFO:     Epoch: 83
2023-01-04 06:25:27,022 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44418865442276, 'Total loss': 0.44418865442276} | train loss {'Reaction outcome loss': 0.28597273311069055, 'Total loss': 0.28597273311069055}
2023-01-04 06:25:27,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:27,023 INFO:     Epoch: 84
2023-01-04 06:25:28,541 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4582650164763133, 'Total loss': 0.4582650164763133} | train loss {'Reaction outcome loss': 0.28328116489844263, 'Total loss': 0.28328116489844263}
2023-01-04 06:25:28,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:28,542 INFO:     Epoch: 85
2023-01-04 06:25:30,087 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.434657218058904, 'Total loss': 0.434657218058904} | train loss {'Reaction outcome loss': 0.28304364904761314, 'Total loss': 0.28304364904761314}
2023-01-04 06:25:30,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:30,087 INFO:     Epoch: 86
2023-01-04 06:25:31,634 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4949039379755656, 'Total loss': 0.4949039379755656} | train loss {'Reaction outcome loss': 0.28183731399643136, 'Total loss': 0.28183731399643136}
2023-01-04 06:25:31,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:31,634 INFO:     Epoch: 87
2023-01-04 06:25:33,193 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4644085059563319, 'Total loss': 0.4644085059563319} | train loss {'Reaction outcome loss': 0.27971386683331756, 'Total loss': 0.27971386683331756}
2023-01-04 06:25:33,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:33,193 INFO:     Epoch: 88
2023-01-04 06:25:34,698 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4074624945720037, 'Total loss': 0.4074624945720037} | train loss {'Reaction outcome loss': 0.2784897928544577, 'Total loss': 0.2784897928544577}
2023-01-04 06:25:34,700 INFO:     Found new best model at epoch 88
2023-01-04 06:25:34,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:34,700 INFO:     Epoch: 89
2023-01-04 06:25:36,249 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4393394351005554, 'Total loss': 0.4393394351005554} | train loss {'Reaction outcome loss': 0.28132803011844837, 'Total loss': 0.28132803011844837}
2023-01-04 06:25:36,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:36,249 INFO:     Epoch: 90
2023-01-04 06:25:37,782 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44328404366970064, 'Total loss': 0.44328404366970064} | train loss {'Reaction outcome loss': 0.27590908141322923, 'Total loss': 0.27590908141322923}
2023-01-04 06:25:37,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:37,782 INFO:     Epoch: 91
2023-01-04 06:25:39,346 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4717936058839162, 'Total loss': 0.4717936058839162} | train loss {'Reaction outcome loss': 0.271883595742427, 'Total loss': 0.271883595742427}
2023-01-04 06:25:39,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:39,346 INFO:     Epoch: 92
2023-01-04 06:25:40,903 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4371419111887614, 'Total loss': 0.4371419111887614} | train loss {'Reaction outcome loss': 0.2718204348348081, 'Total loss': 0.2718204348348081}
2023-01-04 06:25:40,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:40,904 INFO:     Epoch: 93
2023-01-04 06:25:42,443 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43652637402216593, 'Total loss': 0.43652637402216593} | train loss {'Reaction outcome loss': 0.2744543643799472, 'Total loss': 0.2744543643799472}
2023-01-04 06:25:42,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:42,443 INFO:     Epoch: 94
2023-01-04 06:25:43,960 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4751306583484014, 'Total loss': 0.4751306583484014} | train loss {'Reaction outcome loss': 0.27766215156061924, 'Total loss': 0.27766215156061924}
2023-01-04 06:25:43,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:43,960 INFO:     Epoch: 95
2023-01-04 06:25:45,495 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4467148760954539, 'Total loss': 0.4467148760954539} | train loss {'Reaction outcome loss': 0.3263373004299575, 'Total loss': 0.3263373004299575}
2023-01-04 06:25:45,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:45,495 INFO:     Epoch: 96
2023-01-04 06:25:47,039 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4359794735908508, 'Total loss': 0.4359794735908508} | train loss {'Reaction outcome loss': 0.27639568907055206, 'Total loss': 0.27639568907055206}
2023-01-04 06:25:47,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:47,039 INFO:     Epoch: 97
2023-01-04 06:25:48,584 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4576177636782328, 'Total loss': 0.4576177636782328} | train loss {'Reaction outcome loss': 0.26995167472481285, 'Total loss': 0.26995167472481285}
2023-01-04 06:25:48,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:48,584 INFO:     Epoch: 98
2023-01-04 06:25:50,139 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4814904421567917, 'Total loss': 0.4814904421567917} | train loss {'Reaction outcome loss': 0.2669984126814466, 'Total loss': 0.2669984126814466}
2023-01-04 06:25:50,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:50,139 INFO:     Epoch: 99
2023-01-04 06:25:51,705 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4917111476262411, 'Total loss': 0.4917111476262411} | train loss {'Reaction outcome loss': 0.27965511840538704, 'Total loss': 0.27965511840538704}
2023-01-04 06:25:51,706 INFO:     Best model found after epoch 89 of 100.
2023-01-04 06:25:51,706 INFO:   Done with stage: TRAINING
2023-01-04 06:25:51,706 INFO:   Starting stage: EVALUATION
2023-01-04 06:25:51,834 INFO:   Done with stage: EVALUATION
2023-01-04 06:25:51,834 INFO:   Leaving out SEQ value Fold_9
2023-01-04 06:25:51,846 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 06:25:51,846 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:25:52,492 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:25:52,492 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:25:52,562 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:25:52,562 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:25:52,562 INFO:     No hyperparam tuning for this model
2023-01-04 06:25:52,563 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:25:52,563 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:25:52,563 INFO:     None feature selector for col prot
2023-01-04 06:25:52,563 INFO:     None feature selector for col prot
2023-01-04 06:25:52,563 INFO:     None feature selector for col prot
2023-01-04 06:25:52,564 INFO:     None feature selector for col chem
2023-01-04 06:25:52,564 INFO:     None feature selector for col chem
2023-01-04 06:25:52,564 INFO:     None feature selector for col chem
2023-01-04 06:25:52,564 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:25:52,564 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:25:52,565 INFO:     Number of params in model 70111
2023-01-04 06:25:52,568 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:25:52,569 INFO:   Starting stage: TRAINING
2023-01-04 06:25:52,612 INFO:     Val loss before train {'Reaction outcome loss': 0.9912758270899454, 'Total loss': 0.9912758270899454}
2023-01-04 06:25:52,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:52,612 INFO:     Epoch: 0
2023-01-04 06:25:54,154 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7277654469013214, 'Total loss': 0.7277654469013214} | train loss {'Reaction outcome loss': 0.8397661187158164, 'Total loss': 0.8397661187158164}
2023-01-04 06:25:54,155 INFO:     Found new best model at epoch 0
2023-01-04 06:25:54,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:54,156 INFO:     Epoch: 1
2023-01-04 06:25:55,712 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6133272568384807, 'Total loss': 0.6133272568384807} | train loss {'Reaction outcome loss': 0.6857447984631742, 'Total loss': 0.6857447984631742}
2023-01-04 06:25:55,712 INFO:     Found new best model at epoch 1
2023-01-04 06:25:55,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:55,712 INFO:     Epoch: 2
2023-01-04 06:25:57,274 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5569289108117421, 'Total loss': 0.5569289108117421} | train loss {'Reaction outcome loss': 0.5929965743734518, 'Total loss': 0.5929965743734518}
2023-01-04 06:25:57,274 INFO:     Found new best model at epoch 2
2023-01-04 06:25:57,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:57,274 INFO:     Epoch: 3
2023-01-04 06:25:58,830 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5065431257088979, 'Total loss': 0.5065431257088979} | train loss {'Reaction outcome loss': 0.550335490101081, 'Total loss': 0.550335490101081}
2023-01-04 06:25:58,830 INFO:     Found new best model at epoch 3
2023-01-04 06:25:58,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:25:58,831 INFO:     Epoch: 4
2023-01-04 06:26:00,386 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5176920652389526, 'Total loss': 0.5176920652389526} | train loss {'Reaction outcome loss': 0.5260567505867473, 'Total loss': 0.5260567505867473}
2023-01-04 06:26:00,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:00,386 INFO:     Epoch: 5
2023-01-04 06:26:01,912 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5009772280852, 'Total loss': 0.5009772280852} | train loss {'Reaction outcome loss': 0.5113445210004972, 'Total loss': 0.5113445210004972}
2023-01-04 06:26:01,912 INFO:     Found new best model at epoch 5
2023-01-04 06:26:01,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:01,913 INFO:     Epoch: 6
2023-01-04 06:26:03,432 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47783419489860535, 'Total loss': 0.47783419489860535} | train loss {'Reaction outcome loss': 0.5046729941983515, 'Total loss': 0.5046729941983515}
2023-01-04 06:26:03,433 INFO:     Found new best model at epoch 6
2023-01-04 06:26:03,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:03,433 INFO:     Epoch: 7
2023-01-04 06:26:04,988 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4708435783783595, 'Total loss': 0.4708435783783595} | train loss {'Reaction outcome loss': 0.4927553170854865, 'Total loss': 0.4927553170854865}
2023-01-04 06:26:04,988 INFO:     Found new best model at epoch 7
2023-01-04 06:26:04,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:04,989 INFO:     Epoch: 8
2023-01-04 06:26:06,541 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48087685406208036, 'Total loss': 0.48087685406208036} | train loss {'Reaction outcome loss': 0.4881221205534057, 'Total loss': 0.4881221205534057}
2023-01-04 06:26:06,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:06,541 INFO:     Epoch: 9
2023-01-04 06:26:08,133 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4716736594835917, 'Total loss': 0.4716736594835917} | train loss {'Reaction outcome loss': 0.4773494110103118, 'Total loss': 0.4773494110103118}
2023-01-04 06:26:08,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:08,134 INFO:     Epoch: 10
2023-01-04 06:26:09,771 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45800619522730507, 'Total loss': 0.45800619522730507} | train loss {'Reaction outcome loss': 0.4750171667939919, 'Total loss': 0.4750171667939919}
2023-01-04 06:26:09,773 INFO:     Found new best model at epoch 10
2023-01-04 06:26:09,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:09,774 INFO:     Epoch: 11
2023-01-04 06:26:11,362 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46558888455231984, 'Total loss': 0.46558888455231984} | train loss {'Reaction outcome loss': 0.4657600226169889, 'Total loss': 0.4657600226169889}
2023-01-04 06:26:11,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:11,362 INFO:     Epoch: 12
2023-01-04 06:26:12,951 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4551800866921743, 'Total loss': 0.4551800866921743} | train loss {'Reaction outcome loss': 0.461511701829597, 'Total loss': 0.461511701829597}
2023-01-04 06:26:12,951 INFO:     Found new best model at epoch 12
2023-01-04 06:26:12,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:12,952 INFO:     Epoch: 13
2023-01-04 06:26:14,545 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4457150727510452, 'Total loss': 0.4457150727510452} | train loss {'Reaction outcome loss': 0.4581184005801858, 'Total loss': 0.4581184005801858}
2023-01-04 06:26:14,545 INFO:     Found new best model at epoch 13
2023-01-04 06:26:14,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:14,546 INFO:     Epoch: 14
2023-01-04 06:26:16,154 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46342865626017254, 'Total loss': 0.46342865626017254} | train loss {'Reaction outcome loss': 0.45292105485385936, 'Total loss': 0.45292105485385936}
2023-01-04 06:26:16,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:16,155 INFO:     Epoch: 15
2023-01-04 06:26:17,788 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4744860172271729, 'Total loss': 0.4744860172271729} | train loss {'Reaction outcome loss': 0.4503274478744514, 'Total loss': 0.4503274478744514}
2023-01-04 06:26:17,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:17,788 INFO:     Epoch: 16
2023-01-04 06:26:19,412 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4355158428351084, 'Total loss': 0.4355158428351084} | train loss {'Reaction outcome loss': 0.44441330895527176, 'Total loss': 0.44441330895527176}
2023-01-04 06:26:19,412 INFO:     Found new best model at epoch 16
2023-01-04 06:26:19,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:19,413 INFO:     Epoch: 17
2023-01-04 06:26:21,032 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4494010696808497, 'Total loss': 0.4494010696808497} | train loss {'Reaction outcome loss': 0.4379484222038558, 'Total loss': 0.4379484222038558}
2023-01-04 06:26:21,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:21,032 INFO:     Epoch: 18
2023-01-04 06:26:22,609 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43570176561673485, 'Total loss': 0.43570176561673485} | train loss {'Reaction outcome loss': 0.43325941565880277, 'Total loss': 0.43325941565880277}
2023-01-04 06:26:22,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:22,609 INFO:     Epoch: 19
2023-01-04 06:26:24,245 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44527847568194073, 'Total loss': 0.44527847568194073} | train loss {'Reaction outcome loss': 0.429480281493724, 'Total loss': 0.429480281493724}
2023-01-04 06:26:24,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:24,245 INFO:     Epoch: 20
2023-01-04 06:26:25,883 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44602155884106953, 'Total loss': 0.44602155884106953} | train loss {'Reaction outcome loss': 0.42588594050183626, 'Total loss': 0.42588594050183626}
2023-01-04 06:26:25,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:25,883 INFO:     Epoch: 21
2023-01-04 06:26:27,519 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.427272899945577, 'Total loss': 0.427272899945577} | train loss {'Reaction outcome loss': 0.41953181096147546, 'Total loss': 0.41953181096147546}
2023-01-04 06:26:27,520 INFO:     Found new best model at epoch 21
2023-01-04 06:26:27,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:27,520 INFO:     Epoch: 22
2023-01-04 06:26:29,107 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4363046805063883, 'Total loss': 0.4363046805063883} | train loss {'Reaction outcome loss': 0.41720414220856417, 'Total loss': 0.41720414220856417}
2023-01-04 06:26:29,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:29,108 INFO:     Epoch: 23
2023-01-04 06:26:30,692 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41977829337120054, 'Total loss': 0.41977829337120054} | train loss {'Reaction outcome loss': 0.4150590424288051, 'Total loss': 0.4150590424288051}
2023-01-04 06:26:30,692 INFO:     Found new best model at epoch 23
2023-01-04 06:26:30,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:30,693 INFO:     Epoch: 24
2023-01-04 06:26:32,332 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42379077076911925, 'Total loss': 0.42379077076911925} | train loss {'Reaction outcome loss': 0.4078027553291527, 'Total loss': 0.4078027553291527}
2023-01-04 06:26:32,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:32,333 INFO:     Epoch: 25
2023-01-04 06:26:33,971 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.425925013422966, 'Total loss': 0.425925013422966} | train loss {'Reaction outcome loss': 0.402227178646339, 'Total loss': 0.402227178646339}
2023-01-04 06:26:33,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:33,971 INFO:     Epoch: 26
2023-01-04 06:26:35,609 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4212625453869502, 'Total loss': 0.4212625453869502} | train loss {'Reaction outcome loss': 0.39930340623489785, 'Total loss': 0.39930340623489785}
2023-01-04 06:26:35,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:35,609 INFO:     Epoch: 27
2023-01-04 06:26:37,176 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41638071835041046, 'Total loss': 0.41638071835041046} | train loss {'Reaction outcome loss': 0.39604232500606495, 'Total loss': 0.39604232500606495}
2023-01-04 06:26:37,176 INFO:     Found new best model at epoch 27
2023-01-04 06:26:37,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:37,177 INFO:     Epoch: 28
2023-01-04 06:26:38,706 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4246055702368418, 'Total loss': 0.4246055702368418} | train loss {'Reaction outcome loss': 0.39208241600529814, 'Total loss': 0.39208241600529814}
2023-01-04 06:26:38,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:38,706 INFO:     Epoch: 29
2023-01-04 06:26:40,248 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4382609824339549, 'Total loss': 0.4382609824339549} | train loss {'Reaction outcome loss': 0.3900581773652927, 'Total loss': 0.3900581773652927}
2023-01-04 06:26:40,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:40,249 INFO:     Epoch: 30
2023-01-04 06:26:41,816 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4362038960059484, 'Total loss': 0.4362038960059484} | train loss {'Reaction outcome loss': 0.38978353067425614, 'Total loss': 0.38978353067425614}
2023-01-04 06:26:41,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:41,816 INFO:     Epoch: 31
2023-01-04 06:26:43,392 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4471095860004425, 'Total loss': 0.4471095860004425} | train loss {'Reaction outcome loss': 0.3801187350942555, 'Total loss': 0.3801187350942555}
2023-01-04 06:26:43,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:43,392 INFO:     Epoch: 32
2023-01-04 06:26:44,954 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3946592599153519, 'Total loss': 0.3946592599153519} | train loss {'Reaction outcome loss': 0.38281564922862105, 'Total loss': 0.38281564922862105}
2023-01-04 06:26:44,955 INFO:     Found new best model at epoch 32
2023-01-04 06:26:44,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:44,955 INFO:     Epoch: 33
2023-01-04 06:26:46,526 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4013448655605316, 'Total loss': 0.4013448655605316} | train loss {'Reaction outcome loss': 0.3721076158625124, 'Total loss': 0.3721076158625124}
2023-01-04 06:26:46,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:46,527 INFO:     Epoch: 34
2023-01-04 06:26:48,072 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39911997616291045, 'Total loss': 0.39911997616291045} | train loss {'Reaction outcome loss': 0.37288205591887774, 'Total loss': 0.37288205591887774}
2023-01-04 06:26:48,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:48,072 INFO:     Epoch: 35
2023-01-04 06:26:49,614 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40538221995035806, 'Total loss': 0.40538221995035806} | train loss {'Reaction outcome loss': 0.3700923470222132, 'Total loss': 0.3700923470222132}
2023-01-04 06:26:49,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:49,614 INFO:     Epoch: 36
2023-01-04 06:26:51,204 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.404252560933431, 'Total loss': 0.404252560933431} | train loss {'Reaction outcome loss': 0.36211899509283607, 'Total loss': 0.36211899509283607}
2023-01-04 06:26:51,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:51,204 INFO:     Epoch: 37
2023-01-04 06:26:52,786 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4132403592268626, 'Total loss': 0.4132403592268626} | train loss {'Reaction outcome loss': 0.35556788162903236, 'Total loss': 0.35556788162903236}
2023-01-04 06:26:52,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:52,786 INFO:     Epoch: 38
2023-01-04 06:26:54,347 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40454225689172746, 'Total loss': 0.40454225689172746} | train loss {'Reaction outcome loss': 0.3570244108404063, 'Total loss': 0.3570244108404063}
2023-01-04 06:26:54,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:54,347 INFO:     Epoch: 39
2023-01-04 06:26:55,895 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3851637045542399, 'Total loss': 0.3851637045542399} | train loss {'Reaction outcome loss': 0.35491961154696744, 'Total loss': 0.35491961154696744}
2023-01-04 06:26:55,896 INFO:     Found new best model at epoch 39
2023-01-04 06:26:55,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:55,896 INFO:     Epoch: 40
2023-01-04 06:26:57,487 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.391896054148674, 'Total loss': 0.391896054148674} | train loss {'Reaction outcome loss': 0.35078170475976994, 'Total loss': 0.35078170475976994}
2023-01-04 06:26:57,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:57,487 INFO:     Epoch: 41
2023-01-04 06:26:59,034 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4219105621178945, 'Total loss': 0.4219105621178945} | train loss {'Reaction outcome loss': 0.3482529116451525, 'Total loss': 0.3482529116451525}
2023-01-04 06:26:59,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:26:59,035 INFO:     Epoch: 42
2023-01-04 06:27:00,634 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3819614003101985, 'Total loss': 0.3819614003101985} | train loss {'Reaction outcome loss': 0.3447087502059954, 'Total loss': 0.3447087502059954}
2023-01-04 06:27:00,635 INFO:     Found new best model at epoch 42
2023-01-04 06:27:00,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:00,635 INFO:     Epoch: 43
2023-01-04 06:27:02,207 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39501276512940725, 'Total loss': 0.39501276512940725} | train loss {'Reaction outcome loss': 0.3386035900737835, 'Total loss': 0.3386035900737835}
2023-01-04 06:27:02,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:02,207 INFO:     Epoch: 44
2023-01-04 06:27:03,799 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39002673228581747, 'Total loss': 0.39002673228581747} | train loss {'Reaction outcome loss': 0.34229162639336463, 'Total loss': 0.34229162639336463}
2023-01-04 06:27:03,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:03,800 INFO:     Epoch: 45
2023-01-04 06:27:05,354 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3833364019791285, 'Total loss': 0.3833364019791285} | train loss {'Reaction outcome loss': 0.3335936785766364, 'Total loss': 0.3335936785766364}
2023-01-04 06:27:05,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:05,354 INFO:     Epoch: 46
2023-01-04 06:27:06,891 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39368904531002047, 'Total loss': 0.39368904531002047} | train loss {'Reaction outcome loss': 0.33334540817819347, 'Total loss': 0.33334540817819347}
2023-01-04 06:27:06,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:06,892 INFO:     Epoch: 47
2023-01-04 06:27:08,426 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39064774016539255, 'Total loss': 0.39064774016539255} | train loss {'Reaction outcome loss': 0.3319471767071352, 'Total loss': 0.3319471767071352}
2023-01-04 06:27:08,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:08,426 INFO:     Epoch: 48
2023-01-04 06:27:09,983 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3816353529691696, 'Total loss': 0.3816353529691696} | train loss {'Reaction outcome loss': 0.32625912839970433, 'Total loss': 0.32625912839970433}
2023-01-04 06:27:09,983 INFO:     Found new best model at epoch 48
2023-01-04 06:27:09,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:09,983 INFO:     Epoch: 49
2023-01-04 06:27:11,537 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3912269453207652, 'Total loss': 0.3912269453207652} | train loss {'Reaction outcome loss': 0.32800463318071643, 'Total loss': 0.32800463318071643}
2023-01-04 06:27:11,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:11,538 INFO:     Epoch: 50
2023-01-04 06:27:13,081 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37893072168032327, 'Total loss': 0.37893072168032327} | train loss {'Reaction outcome loss': 0.32133181036755926, 'Total loss': 0.32133181036755926}
2023-01-04 06:27:13,082 INFO:     Found new best model at epoch 50
2023-01-04 06:27:13,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:13,082 INFO:     Epoch: 51
2023-01-04 06:27:14,621 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37138592402140297, 'Total loss': 0.37138592402140297} | train loss {'Reaction outcome loss': 0.32487665584801767, 'Total loss': 0.32487665584801767}
2023-01-04 06:27:14,621 INFO:     Found new best model at epoch 51
2023-01-04 06:27:14,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:14,622 INFO:     Epoch: 52
2023-01-04 06:27:16,145 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38856195906798047, 'Total loss': 0.38856195906798047} | train loss {'Reaction outcome loss': 0.3248712823117683, 'Total loss': 0.3248712823117683}
2023-01-04 06:27:16,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:16,145 INFO:     Epoch: 53
2023-01-04 06:27:17,692 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38023455142974855, 'Total loss': 0.38023455142974855} | train loss {'Reaction outcome loss': 0.32264919301985834, 'Total loss': 0.32264919301985834}
2023-01-04 06:27:17,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:17,693 INFO:     Epoch: 54
2023-01-04 06:27:19,273 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40668419897556307, 'Total loss': 0.40668419897556307} | train loss {'Reaction outcome loss': 0.3159846946166741, 'Total loss': 0.3159846946166741}
2023-01-04 06:27:19,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:19,273 INFO:     Epoch: 55
2023-01-04 06:27:20,864 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37208176652590436, 'Total loss': 0.37208176652590436} | train loss {'Reaction outcome loss': 0.31270048027649683, 'Total loss': 0.31270048027649683}
2023-01-04 06:27:20,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:20,865 INFO:     Epoch: 56
2023-01-04 06:27:22,469 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.382193694015344, 'Total loss': 0.382193694015344} | train loss {'Reaction outcome loss': 0.3088119475957719, 'Total loss': 0.3088119475957719}
2023-01-04 06:27:22,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:22,469 INFO:     Epoch: 57
2023-01-04 06:27:24,055 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3651151751478513, 'Total loss': 0.3651151751478513} | train loss {'Reaction outcome loss': 0.30808579292323185, 'Total loss': 0.30808579292323185}
2023-01-04 06:27:24,055 INFO:     Found new best model at epoch 57
2023-01-04 06:27:24,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:24,055 INFO:     Epoch: 58
2023-01-04 06:27:25,635 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35720115999380747, 'Total loss': 0.35720115999380747} | train loss {'Reaction outcome loss': 0.3035960746424723, 'Total loss': 0.3035960746424723}
2023-01-04 06:27:25,636 INFO:     Found new best model at epoch 58
2023-01-04 06:27:25,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:25,636 INFO:     Epoch: 59
2023-01-04 06:27:27,239 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3975996265808741, 'Total loss': 0.3975996265808741} | train loss {'Reaction outcome loss': 0.30736122409466804, 'Total loss': 0.30736122409466804}
2023-01-04 06:27:27,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:27,239 INFO:     Epoch: 60
2023-01-04 06:27:28,846 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3805111398299535, 'Total loss': 0.3805111398299535} | train loss {'Reaction outcome loss': 0.3043165105774945, 'Total loss': 0.3043165105774945}
2023-01-04 06:27:28,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:28,846 INFO:     Epoch: 61
2023-01-04 06:27:30,453 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3778572221597036, 'Total loss': 0.3778572221597036} | train loss {'Reaction outcome loss': 0.2935205933365581, 'Total loss': 0.2935205933365581}
2023-01-04 06:27:30,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:30,454 INFO:     Epoch: 62
2023-01-04 06:27:32,058 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3491067955891291, 'Total loss': 0.3491067955891291} | train loss {'Reaction outcome loss': 0.3030805002212094, 'Total loss': 0.3030805002212094}
2023-01-04 06:27:32,058 INFO:     Found new best model at epoch 62
2023-01-04 06:27:32,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:32,059 INFO:     Epoch: 63
2023-01-04 06:27:33,641 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37498793452978135, 'Total loss': 0.37498793452978135} | train loss {'Reaction outcome loss': 0.2936088124875127, 'Total loss': 0.2936088124875127}
2023-01-04 06:27:33,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:33,642 INFO:     Epoch: 64
2023-01-04 06:27:35,212 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3629726698001226, 'Total loss': 0.3629726698001226} | train loss {'Reaction outcome loss': 0.2914373400866555, 'Total loss': 0.2914373400866555}
2023-01-04 06:27:35,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:35,212 INFO:     Epoch: 65
2023-01-04 06:27:36,814 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36205502077937124, 'Total loss': 0.36205502077937124} | train loss {'Reaction outcome loss': 0.2928169045718353, 'Total loss': 0.2928169045718353}
2023-01-04 06:27:36,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:36,815 INFO:     Epoch: 66
2023-01-04 06:27:38,420 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3902777363856634, 'Total loss': 0.3902777363856634} | train loss {'Reaction outcome loss': 0.29396289304598144, 'Total loss': 0.29396289304598144}
2023-01-04 06:27:38,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:38,420 INFO:     Epoch: 67
2023-01-04 06:27:40,018 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37045860091845195, 'Total loss': 0.37045860091845195} | train loss {'Reaction outcome loss': 0.2893101701963464, 'Total loss': 0.2893101701963464}
2023-01-04 06:27:40,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:40,019 INFO:     Epoch: 68
2023-01-04 06:27:41,619 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37642574310302734, 'Total loss': 0.37642574310302734} | train loss {'Reaction outcome loss': 0.28673448357125914, 'Total loss': 0.28673448357125914}
2023-01-04 06:27:41,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:41,619 INFO:     Epoch: 69
2023-01-04 06:27:43,162 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3783235907554626, 'Total loss': 0.3783235907554626} | train loss {'Reaction outcome loss': 0.2845659590988598, 'Total loss': 0.2845659590988598}
2023-01-04 06:27:43,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:43,163 INFO:     Epoch: 70
2023-01-04 06:27:44,766 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34743991096814475, 'Total loss': 0.34743991096814475} | train loss {'Reaction outcome loss': 0.2827103646061911, 'Total loss': 0.2827103646061911}
2023-01-04 06:27:44,767 INFO:     Found new best model at epoch 70
2023-01-04 06:27:44,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:44,767 INFO:     Epoch: 71
2023-01-04 06:27:46,368 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35592079162597656, 'Total loss': 0.35592079162597656} | train loss {'Reaction outcome loss': 0.28346029114959903, 'Total loss': 0.28346029114959903}
2023-01-04 06:27:46,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:46,369 INFO:     Epoch: 72
2023-01-04 06:27:47,953 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3702014585336049, 'Total loss': 0.3702014585336049} | train loss {'Reaction outcome loss': 0.2765937821959761, 'Total loss': 0.2765937821959761}
2023-01-04 06:27:47,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:47,954 INFO:     Epoch: 73
2023-01-04 06:27:49,494 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4036121558398008, 'Total loss': 0.4036121558398008} | train loss {'Reaction outcome loss': 0.28192668351670896, 'Total loss': 0.28192668351670896}
2023-01-04 06:27:49,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:49,495 INFO:     Epoch: 74
2023-01-04 06:27:51,033 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40000521938006084, 'Total loss': 0.40000521938006084} | train loss {'Reaction outcome loss': 0.2773496257376585, 'Total loss': 0.2773496257376585}
2023-01-04 06:27:51,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:51,034 INFO:     Epoch: 75
2023-01-04 06:27:52,508 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35937384963035585, 'Total loss': 0.35937384963035585} | train loss {'Reaction outcome loss': 0.2818509586128517, 'Total loss': 0.2818509586128517}
2023-01-04 06:27:52,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:52,508 INFO:     Epoch: 76
2023-01-04 06:27:54,041 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3625100553035736, 'Total loss': 0.3625100553035736} | train loss {'Reaction outcome loss': 0.27854717920941136, 'Total loss': 0.27854717920941136}
2023-01-04 06:27:54,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:54,041 INFO:     Epoch: 77
2023-01-04 06:27:55,579 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37489955325921376, 'Total loss': 0.37489955325921376} | train loss {'Reaction outcome loss': 0.27700450080396466, 'Total loss': 0.27700450080396466}
2023-01-04 06:27:55,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:55,580 INFO:     Epoch: 78
2023-01-04 06:27:57,127 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3684830794731776, 'Total loss': 0.3684830794731776} | train loss {'Reaction outcome loss': 0.2739739481507656, 'Total loss': 0.2739739481507656}
2023-01-04 06:27:57,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:57,128 INFO:     Epoch: 79
2023-01-04 06:27:58,665 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38025568922360736, 'Total loss': 0.38025568922360736} | train loss {'Reaction outcome loss': 0.26812064637588034, 'Total loss': 0.26812064637588034}
2023-01-04 06:27:58,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:27:58,666 INFO:     Epoch: 80
2023-01-04 06:28:00,205 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37036337653795876, 'Total loss': 0.37036337653795876} | train loss {'Reaction outcome loss': 0.2751705296848655, 'Total loss': 0.2751705296848655}
2023-01-04 06:28:00,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:00,205 INFO:     Epoch: 81
2023-01-04 06:28:01,712 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3775648276011149, 'Total loss': 0.3775648276011149} | train loss {'Reaction outcome loss': 0.2737112147767191, 'Total loss': 0.2737112147767191}
2023-01-04 06:28:01,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:01,713 INFO:     Epoch: 82
2023-01-04 06:28:03,275 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3660882870356242, 'Total loss': 0.3660882870356242} | train loss {'Reaction outcome loss': 0.27045674202459385, 'Total loss': 0.27045674202459385}
2023-01-04 06:28:03,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:03,275 INFO:     Epoch: 83
2023-01-04 06:28:04,848 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36836905777454376, 'Total loss': 0.36836905777454376} | train loss {'Reaction outcome loss': 0.2664143704550361, 'Total loss': 0.2664143704550361}
2023-01-04 06:28:04,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:04,849 INFO:     Epoch: 84
2023-01-04 06:28:06,400 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38836954136689505, 'Total loss': 0.38836954136689505} | train loss {'Reaction outcome loss': 0.26578422350681213, 'Total loss': 0.26578422350681213}
2023-01-04 06:28:06,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:06,401 INFO:     Epoch: 85
2023-01-04 06:28:07,957 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35863840679327647, 'Total loss': 0.35863840679327647} | train loss {'Reaction outcome loss': 0.2661692149372307, 'Total loss': 0.2661692149372307}
2023-01-04 06:28:07,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:07,957 INFO:     Epoch: 86
2023-01-04 06:28:09,513 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3677360783020655, 'Total loss': 0.3677360783020655} | train loss {'Reaction outcome loss': 0.2616901052073451, 'Total loss': 0.2616901052073451}
2023-01-04 06:28:09,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:09,514 INFO:     Epoch: 87
2023-01-04 06:28:11,022 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36193930804729463, 'Total loss': 0.36193930804729463} | train loss {'Reaction outcome loss': 0.26153331782520894, 'Total loss': 0.26153331782520894}
2023-01-04 06:28:11,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:11,022 INFO:     Epoch: 88
2023-01-04 06:28:12,579 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3825948476791382, 'Total loss': 0.3825948476791382} | train loss {'Reaction outcome loss': 0.2631435185428776, 'Total loss': 0.2631435185428776}
2023-01-04 06:28:12,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:12,579 INFO:     Epoch: 89
2023-01-04 06:28:14,146 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3765173390507698, 'Total loss': 0.3765173390507698} | train loss {'Reaction outcome loss': 0.261219922950767, 'Total loss': 0.261219922950767}
2023-01-04 06:28:14,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:14,146 INFO:     Epoch: 90
2023-01-04 06:28:15,731 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36456544399261476, 'Total loss': 0.36456544399261476} | train loss {'Reaction outcome loss': 0.2595983951046579, 'Total loss': 0.2595983951046579}
2023-01-04 06:28:15,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:15,732 INFO:     Epoch: 91
2023-01-04 06:28:17,330 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3714900289972623, 'Total loss': 0.3714900289972623} | train loss {'Reaction outcome loss': 0.2596817502099684, 'Total loss': 0.2596817502099684}
2023-01-04 06:28:17,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:17,330 INFO:     Epoch: 92
2023-01-04 06:28:18,903 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36998377442359925, 'Total loss': 0.36998377442359925} | train loss {'Reaction outcome loss': 0.25924259978296094, 'Total loss': 0.25924259978296094}
2023-01-04 06:28:18,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:18,904 INFO:     Epoch: 93
2023-01-04 06:28:20,413 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3839805508653323, 'Total loss': 0.3839805508653323} | train loss {'Reaction outcome loss': 0.2648369378077424, 'Total loss': 0.2648369378077424}
2023-01-04 06:28:20,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:20,413 INFO:     Epoch: 94
2023-01-04 06:28:22,003 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3682010143995285, 'Total loss': 0.3682010143995285} | train loss {'Reaction outcome loss': 0.2563139157174727, 'Total loss': 0.2563139157174727}
2023-01-04 06:28:22,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:22,003 INFO:     Epoch: 95
2023-01-04 06:28:23,576 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35735907753308616, 'Total loss': 0.35735907753308616} | train loss {'Reaction outcome loss': 0.2569325237605546, 'Total loss': 0.2569325237605546}
2023-01-04 06:28:23,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:23,576 INFO:     Epoch: 96
2023-01-04 06:28:25,147 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35263535380363464, 'Total loss': 0.35263535380363464} | train loss {'Reaction outcome loss': 0.25572622727454786, 'Total loss': 0.25572622727454786}
2023-01-04 06:28:25,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:25,148 INFO:     Epoch: 97
2023-01-04 06:28:26,721 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3613296051820119, 'Total loss': 0.3613296051820119} | train loss {'Reaction outcome loss': 0.25295896236431725, 'Total loss': 0.25295896236431725}
2023-01-04 06:28:26,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:26,721 INFO:     Epoch: 98
2023-01-04 06:28:28,286 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3644813751180967, 'Total loss': 0.3644813751180967} | train loss {'Reaction outcome loss': 0.2579228454925093, 'Total loss': 0.2579228454925093}
2023-01-04 06:28:28,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:28,286 INFO:     Epoch: 99
2023-01-04 06:28:29,800 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37691059708595276, 'Total loss': 0.37691059708595276} | train loss {'Reaction outcome loss': 0.25305932011145976, 'Total loss': 0.25305932011145976}
2023-01-04 06:28:29,800 INFO:     Best model found after epoch 71 of 100.
2023-01-04 06:28:29,800 INFO:   Done with stage: TRAINING
2023-01-04 06:28:29,800 INFO:   Starting stage: EVALUATION
2023-01-04 06:28:29,922 INFO:   Done with stage: EVALUATION
2023-01-04 06:28:29,930 INFO:   Leaving out SEQ value Fold_0
2023-01-04 06:28:29,943 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 06:28:29,943 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:28:30,590 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:28:30,590 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:28:30,658 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:28:30,658 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:28:30,658 INFO:     No hyperparam tuning for this model
2023-01-04 06:28:30,658 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:28:30,658 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:28:30,659 INFO:     None feature selector for col prot
2023-01-04 06:28:30,659 INFO:     None feature selector for col prot
2023-01-04 06:28:30,659 INFO:     None feature selector for col prot
2023-01-04 06:28:30,660 INFO:     None feature selector for col chem
2023-01-04 06:28:30,660 INFO:     None feature selector for col chem
2023-01-04 06:28:30,660 INFO:     None feature selector for col chem
2023-01-04 06:28:30,660 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:28:30,660 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:28:30,661 INFO:     Number of params in model 70111
2023-01-04 06:28:30,664 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:28:30,664 INFO:   Starting stage: TRAINING
2023-01-04 06:28:30,707 INFO:     Val loss before train {'Reaction outcome loss': 1.0137705047925314, 'Total loss': 1.0137705047925314}
2023-01-04 06:28:30,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:30,707 INFO:     Epoch: 0
2023-01-04 06:28:32,308 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7716781457265218, 'Total loss': 0.7716781457265218} | train loss {'Reaction outcome loss': 0.8410303785200537, 'Total loss': 0.8410303785200537}
2023-01-04 06:28:32,308 INFO:     Found new best model at epoch 0
2023-01-04 06:28:32,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:32,309 INFO:     Epoch: 1
2023-01-04 06:28:33,879 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6514322280883789, 'Total loss': 0.6514322280883789} | train loss {'Reaction outcome loss': 0.6912659477360927, 'Total loss': 0.6912659477360927}
2023-01-04 06:28:33,879 INFO:     Found new best model at epoch 1
2023-01-04 06:28:33,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:33,880 INFO:     Epoch: 2
2023-01-04 06:28:35,424 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5603831946849823, 'Total loss': 0.5603831946849823} | train loss {'Reaction outcome loss': 0.6042323408879503, 'Total loss': 0.6042323408879503}
2023-01-04 06:28:35,424 INFO:     Found new best model at epoch 2
2023-01-04 06:28:35,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:35,425 INFO:     Epoch: 3
2023-01-04 06:28:36,999 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5336700240770976, 'Total loss': 0.5336700240770976} | train loss {'Reaction outcome loss': 0.5579453339650683, 'Total loss': 0.5579453339650683}
2023-01-04 06:28:36,999 INFO:     Found new best model at epoch 3
2023-01-04 06:28:36,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:37,000 INFO:     Epoch: 4
2023-01-04 06:28:38,476 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5322862505912781, 'Total loss': 0.5322862505912781} | train loss {'Reaction outcome loss': 0.5329046437013758, 'Total loss': 0.5329046437013758}
2023-01-04 06:28:38,477 INFO:     Found new best model at epoch 4
2023-01-04 06:28:38,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:38,477 INFO:     Epoch: 5
2023-01-04 06:28:40,040 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5118410329023997, 'Total loss': 0.5118410329023997} | train loss {'Reaction outcome loss': 0.5206290300745163, 'Total loss': 0.5206290300745163}
2023-01-04 06:28:40,041 INFO:     Found new best model at epoch 5
2023-01-04 06:28:40,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:40,041 INFO:     Epoch: 6
2023-01-04 06:28:41,604 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5072544773419698, 'Total loss': 0.5072544773419698} | train loss {'Reaction outcome loss': 0.5060559742315842, 'Total loss': 0.5060559742315842}
2023-01-04 06:28:41,604 INFO:     Found new best model at epoch 6
2023-01-04 06:28:41,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:41,605 INFO:     Epoch: 7
2023-01-04 06:28:43,177 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5025468170642853, 'Total loss': 0.5025468170642853} | train loss {'Reaction outcome loss': 0.492808973702201, 'Total loss': 0.492808973702201}
2023-01-04 06:28:43,177 INFO:     Found new best model at epoch 7
2023-01-04 06:28:43,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:43,178 INFO:     Epoch: 8
2023-01-04 06:28:44,752 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4896780927975973, 'Total loss': 0.4896780927975973} | train loss {'Reaction outcome loss': 0.4838660784663945, 'Total loss': 0.4838660784663945}
2023-01-04 06:28:44,752 INFO:     Found new best model at epoch 8
2023-01-04 06:28:44,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:44,753 INFO:     Epoch: 9
2023-01-04 06:28:46,302 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47125830948352815, 'Total loss': 0.47125830948352815} | train loss {'Reaction outcome loss': 0.47301095783928016, 'Total loss': 0.47301095783928016}
2023-01-04 06:28:46,302 INFO:     Found new best model at epoch 9
2023-01-04 06:28:46,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:46,303 INFO:     Epoch: 10
2023-01-04 06:28:47,806 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4559626599152883, 'Total loss': 0.4559626599152883} | train loss {'Reaction outcome loss': 0.46258797061486834, 'Total loss': 0.46258797061486834}
2023-01-04 06:28:47,806 INFO:     Found new best model at epoch 10
2023-01-04 06:28:47,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:47,807 INFO:     Epoch: 11
2023-01-04 06:28:49,373 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4598176658153534, 'Total loss': 0.4598176658153534} | train loss {'Reaction outcome loss': 0.4564306396093682, 'Total loss': 0.4564306396093682}
2023-01-04 06:28:49,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:49,373 INFO:     Epoch: 12
2023-01-04 06:28:50,943 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49309688806533813, 'Total loss': 0.49309688806533813} | train loss {'Reaction outcome loss': 0.45377905253511275, 'Total loss': 0.45377905253511275}
2023-01-04 06:28:50,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:50,943 INFO:     Epoch: 13
2023-01-04 06:28:52,524 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.474596893787384, 'Total loss': 0.474596893787384} | train loss {'Reaction outcome loss': 0.4446909173398557, 'Total loss': 0.4446909173398557}
2023-01-04 06:28:52,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:52,524 INFO:     Epoch: 14
2023-01-04 06:28:54,088 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4593286573886871, 'Total loss': 0.4593286573886871} | train loss {'Reaction outcome loss': 0.4417758338207746, 'Total loss': 0.4417758338207746}
2023-01-04 06:28:54,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:54,089 INFO:     Epoch: 15
2023-01-04 06:28:55,608 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47721549272537234, 'Total loss': 0.47721549272537234} | train loss {'Reaction outcome loss': 0.43755186207755636, 'Total loss': 0.43755186207755636}
2023-01-04 06:28:55,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:55,608 INFO:     Epoch: 16
2023-01-04 06:28:57,196 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45449915329615276, 'Total loss': 0.45449915329615276} | train loss {'Reaction outcome loss': 0.4312741488598994, 'Total loss': 0.4312741488598994}
2023-01-04 06:28:57,196 INFO:     Found new best model at epoch 16
2023-01-04 06:28:57,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:57,197 INFO:     Epoch: 17
2023-01-04 06:28:58,804 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44369853536287945, 'Total loss': 0.44369853536287945} | train loss {'Reaction outcome loss': 0.42519068543928384, 'Total loss': 0.42519068543928384}
2023-01-04 06:28:58,804 INFO:     Found new best model at epoch 17
2023-01-04 06:28:58,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:28:58,805 INFO:     Epoch: 18
2023-01-04 06:29:00,405 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4478188236554464, 'Total loss': 0.4478188236554464} | train loss {'Reaction outcome loss': 0.42069938294861436, 'Total loss': 0.42069938294861436}
2023-01-04 06:29:00,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:00,406 INFO:     Epoch: 19
2023-01-04 06:29:02,005 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4399312059084574, 'Total loss': 0.4399312059084574} | train loss {'Reaction outcome loss': 0.4182358872498909, 'Total loss': 0.4182358872498909}
2023-01-04 06:29:02,005 INFO:     Found new best model at epoch 19
2023-01-04 06:29:02,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:02,006 INFO:     Epoch: 20
2023-01-04 06:29:03,619 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.451896537343661, 'Total loss': 0.451896537343661} | train loss {'Reaction outcome loss': 0.4128416060966297, 'Total loss': 0.4128416060966297}
2023-01-04 06:29:03,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:03,620 INFO:     Epoch: 21
2023-01-04 06:29:05,150 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4239100247621536, 'Total loss': 0.4239100247621536} | train loss {'Reaction outcome loss': 0.41179198026657104, 'Total loss': 0.41179198026657104}
2023-01-04 06:29:05,150 INFO:     Found new best model at epoch 21
2023-01-04 06:29:05,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:05,151 INFO:     Epoch: 22
2023-01-04 06:29:06,766 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4361131111780802, 'Total loss': 0.4361131111780802} | train loss {'Reaction outcome loss': 0.40327802180808825, 'Total loss': 0.40327802180808825}
2023-01-04 06:29:06,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:06,767 INFO:     Epoch: 23
2023-01-04 06:29:08,369 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4338287274042765, 'Total loss': 0.4338287274042765} | train loss {'Reaction outcome loss': 0.3985865197695085, 'Total loss': 0.3985865197695085}
2023-01-04 06:29:08,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:08,369 INFO:     Epoch: 24
2023-01-04 06:29:09,981 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43527035812536874, 'Total loss': 0.43527035812536874} | train loss {'Reaction outcome loss': 0.3949618810502282, 'Total loss': 0.3949618810502282}
2023-01-04 06:29:09,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:09,981 INFO:     Epoch: 25
2023-01-04 06:29:11,599 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4520249585310618, 'Total loss': 0.4520249585310618} | train loss {'Reaction outcome loss': 0.39475440799537365, 'Total loss': 0.39475440799537365}
2023-01-04 06:29:11,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:11,599 INFO:     Epoch: 26
2023-01-04 06:29:13,217 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4425892213980357, 'Total loss': 0.4425892213980357} | train loss {'Reaction outcome loss': 0.3902011854696448, 'Total loss': 0.3902011854696448}
2023-01-04 06:29:13,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:13,218 INFO:     Epoch: 27
2023-01-04 06:29:14,745 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45747751196225483, 'Total loss': 0.45747751196225483} | train loss {'Reaction outcome loss': 0.38713262714173674, 'Total loss': 0.38713262714173674}
2023-01-04 06:29:14,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:14,746 INFO:     Epoch: 28
2023-01-04 06:29:16,362 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43297071059544884, 'Total loss': 0.43297071059544884} | train loss {'Reaction outcome loss': 0.3827711311406898, 'Total loss': 0.3827711311406898}
2023-01-04 06:29:16,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:16,363 INFO:     Epoch: 29
2023-01-04 06:29:17,983 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4225009083747864, 'Total loss': 0.4225009083747864} | train loss {'Reaction outcome loss': 0.37701432194805495, 'Total loss': 0.37701432194805495}
2023-01-04 06:29:17,983 INFO:     Found new best model at epoch 29
2023-01-04 06:29:17,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:17,984 INFO:     Epoch: 30
2023-01-04 06:29:19,596 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42395529548327127, 'Total loss': 0.42395529548327127} | train loss {'Reaction outcome loss': 0.3723622053916002, 'Total loss': 0.3723622053916002}
2023-01-04 06:29:19,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:19,597 INFO:     Epoch: 31
2023-01-04 06:29:21,213 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4474289000034332, 'Total loss': 0.4474289000034332} | train loss {'Reaction outcome loss': 0.3723947213024554, 'Total loss': 0.3723947213024554}
2023-01-04 06:29:21,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:21,213 INFO:     Epoch: 32
2023-01-04 06:29:22,799 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4306245644887288, 'Total loss': 0.4306245644887288} | train loss {'Reaction outcome loss': 0.3655366106026799, 'Total loss': 0.3655366106026799}
2023-01-04 06:29:22,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:22,800 INFO:     Epoch: 33
2023-01-04 06:29:24,367 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4563168744246165, 'Total loss': 0.4563168744246165} | train loss {'Reaction outcome loss': 0.3680177090322449, 'Total loss': 0.3680177090322449}
2023-01-04 06:29:24,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:24,369 INFO:     Epoch: 34
2023-01-04 06:29:25,975 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42115094264348346, 'Total loss': 0.42115094264348346} | train loss {'Reaction outcome loss': 0.36062172876439824, 'Total loss': 0.36062172876439824}
2023-01-04 06:29:25,975 INFO:     Found new best model at epoch 34
2023-01-04 06:29:25,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:25,976 INFO:     Epoch: 35
2023-01-04 06:29:27,594 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4462241431077321, 'Total loss': 0.4462241431077321} | train loss {'Reaction outcome loss': 0.35493364380876513, 'Total loss': 0.35493364380876513}
2023-01-04 06:29:27,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:27,594 INFO:     Epoch: 36
2023-01-04 06:29:29,212 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4167427549759547, 'Total loss': 0.4167427549759547} | train loss {'Reaction outcome loss': 0.3565782725974156, 'Total loss': 0.3565782725974156}
2023-01-04 06:29:29,212 INFO:     Found new best model at epoch 36
2023-01-04 06:29:29,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:29,213 INFO:     Epoch: 37
2023-01-04 06:29:30,831 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4407145162423452, 'Total loss': 0.4407145162423452} | train loss {'Reaction outcome loss': 0.35039417559865615, 'Total loss': 0.35039417559865615}
2023-01-04 06:29:30,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:30,832 INFO:     Epoch: 38
2023-01-04 06:29:32,363 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4421303182840347, 'Total loss': 0.4421303182840347} | train loss {'Reaction outcome loss': 0.34720346304404476, 'Total loss': 0.34720346304404476}
2023-01-04 06:29:32,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:32,363 INFO:     Epoch: 39
2023-01-04 06:29:33,978 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44711564977963764, 'Total loss': 0.44711564977963764} | train loss {'Reaction outcome loss': 0.349919412964887, 'Total loss': 0.349919412964887}
2023-01-04 06:29:33,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:33,978 INFO:     Epoch: 40
2023-01-04 06:29:35,594 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4193283865849177, 'Total loss': 0.4193283865849177} | train loss {'Reaction outcome loss': 0.34028201109736506, 'Total loss': 0.34028201109736506}
2023-01-04 06:29:35,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:35,594 INFO:     Epoch: 41
2023-01-04 06:29:37,211 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4351856370766958, 'Total loss': 0.4351856370766958} | train loss {'Reaction outcome loss': 0.34331387207999714, 'Total loss': 0.34331387207999714}
2023-01-04 06:29:37,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:37,212 INFO:     Epoch: 42
2023-01-04 06:29:38,829 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40682636201381683, 'Total loss': 0.40682636201381683} | train loss {'Reaction outcome loss': 0.3380877579813891, 'Total loss': 0.3380877579813891}
2023-01-04 06:29:38,829 INFO:     Found new best model at epoch 42
2023-01-04 06:29:38,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:38,830 INFO:     Epoch: 43
2023-01-04 06:29:40,438 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41760207811991373, 'Total loss': 0.41760207811991373} | train loss {'Reaction outcome loss': 0.33534791891592264, 'Total loss': 0.33534791891592264}
2023-01-04 06:29:40,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:40,438 INFO:     Epoch: 44
2023-01-04 06:29:41,955 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42048888504505155, 'Total loss': 0.42048888504505155} | train loss {'Reaction outcome loss': 0.33617037042540354, 'Total loss': 0.33617037042540354}
2023-01-04 06:29:41,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:41,955 INFO:     Epoch: 45
2023-01-04 06:29:43,567 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4252514878908793, 'Total loss': 0.4252514878908793} | train loss {'Reaction outcome loss': 0.3278488458073052, 'Total loss': 0.3278488458073052}
2023-01-04 06:29:43,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:43,568 INFO:     Epoch: 46
2023-01-04 06:29:45,184 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47336685359478, 'Total loss': 0.47336685359478} | train loss {'Reaction outcome loss': 0.32803672432464404, 'Total loss': 0.32803672432464404}
2023-01-04 06:29:45,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:45,185 INFO:     Epoch: 47
2023-01-04 06:29:46,802 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43617769579092663, 'Total loss': 0.43617769579092663} | train loss {'Reaction outcome loss': 0.32567187890845495, 'Total loss': 0.32567187890845495}
2023-01-04 06:29:46,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:46,802 INFO:     Epoch: 48
2023-01-04 06:29:48,420 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4051530400911967, 'Total loss': 0.4051530400911967} | train loss {'Reaction outcome loss': 0.32277364281080934, 'Total loss': 0.32277364281080934}
2023-01-04 06:29:48,420 INFO:     Found new best model at epoch 48
2023-01-04 06:29:48,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:48,420 INFO:     Epoch: 49
2023-01-04 06:29:50,023 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4258414248625437, 'Total loss': 0.4258414248625437} | train loss {'Reaction outcome loss': 0.3182867592758071, 'Total loss': 0.3182867592758071}
2023-01-04 06:29:50,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:50,023 INFO:     Epoch: 50
2023-01-04 06:29:51,584 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41393208503723145, 'Total loss': 0.41393208503723145} | train loss {'Reaction outcome loss': 0.3196239449682027, 'Total loss': 0.3196239449682027}
2023-01-04 06:29:51,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:51,584 INFO:     Epoch: 51
2023-01-04 06:29:53,200 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42682722210884094, 'Total loss': 0.42682722210884094} | train loss {'Reaction outcome loss': 0.31754237386214473, 'Total loss': 0.31754237386214473}
2023-01-04 06:29:53,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:53,200 INFO:     Epoch: 52
2023-01-04 06:29:54,815 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40942999919255574, 'Total loss': 0.40942999919255574} | train loss {'Reaction outcome loss': 0.31744347858059146, 'Total loss': 0.31744347858059146}
2023-01-04 06:29:54,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:54,817 INFO:     Epoch: 53
2023-01-04 06:29:56,429 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40494723866383237, 'Total loss': 0.40494723866383237} | train loss {'Reaction outcome loss': 0.31241874570829153, 'Total loss': 0.31241874570829153}
2023-01-04 06:29:56,429 INFO:     Found new best model at epoch 53
2023-01-04 06:29:56,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:56,430 INFO:     Epoch: 54
2023-01-04 06:29:58,038 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4225604911645254, 'Total loss': 0.4225604911645254} | train loss {'Reaction outcome loss': 0.31024332787759984, 'Total loss': 0.31024332787759984}
2023-01-04 06:29:58,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:58,038 INFO:     Epoch: 55
2023-01-04 06:29:59,558 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42577319939931235, 'Total loss': 0.42577319939931235} | train loss {'Reaction outcome loss': 0.3058988864186907, 'Total loss': 0.3058988864186907}
2023-01-04 06:29:59,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:29:59,558 INFO:     Epoch: 56
2023-01-04 06:30:01,160 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42694652477900186, 'Total loss': 0.42694652477900186} | train loss {'Reaction outcome loss': 0.30792652831895506, 'Total loss': 0.30792652831895506}
2023-01-04 06:30:01,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:01,161 INFO:     Epoch: 57
2023-01-04 06:30:02,770 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4149487962325414, 'Total loss': 0.4149487962325414} | train loss {'Reaction outcome loss': 0.3035721978186256, 'Total loss': 0.3035721978186256}
2023-01-04 06:30:02,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:02,770 INFO:     Epoch: 58
2023-01-04 06:30:04,376 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42404670516649884, 'Total loss': 0.42404670516649884} | train loss {'Reaction outcome loss': 0.30107990270276574, 'Total loss': 0.30107990270276574}
2023-01-04 06:30:04,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:04,376 INFO:     Epoch: 59
2023-01-04 06:30:05,986 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4307218730449677, 'Total loss': 0.4307218730449677} | train loss {'Reaction outcome loss': 0.2973571895302212, 'Total loss': 0.2973571895302212}
2023-01-04 06:30:05,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:05,986 INFO:     Epoch: 60
2023-01-04 06:30:07,603 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42260170181592305, 'Total loss': 0.42260170181592305} | train loss {'Reaction outcome loss': 0.2955810998967529, 'Total loss': 0.2955810998967529}
2023-01-04 06:30:07,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:07,603 INFO:     Epoch: 61
2023-01-04 06:30:09,131 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4216245065132777, 'Total loss': 0.4216245065132777} | train loss {'Reaction outcome loss': 0.2943090164802805, 'Total loss': 0.2943090164802805}
2023-01-04 06:30:09,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:09,131 INFO:     Epoch: 62
2023-01-04 06:30:10,748 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4018615255753199, 'Total loss': 0.4018615255753199} | train loss {'Reaction outcome loss': 0.2941478745073733, 'Total loss': 0.2941478745073733}
2023-01-04 06:30:10,748 INFO:     Found new best model at epoch 62
2023-01-04 06:30:10,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:10,749 INFO:     Epoch: 63
2023-01-04 06:30:12,367 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4049272179603577, 'Total loss': 0.4049272179603577} | train loss {'Reaction outcome loss': 0.29231133537679693, 'Total loss': 0.29231133537679693}
2023-01-04 06:30:12,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:12,367 INFO:     Epoch: 64
2023-01-04 06:30:13,942 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40196606119473777, 'Total loss': 0.40196606119473777} | train loss {'Reaction outcome loss': 0.28725059140120107, 'Total loss': 0.28725059140120107}
2023-01-04 06:30:13,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:13,943 INFO:     Epoch: 65
2023-01-04 06:30:15,499 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4077849398056666, 'Total loss': 0.4077849398056666} | train loss {'Reaction outcome loss': 0.2917121795080874, 'Total loss': 0.2917121795080874}
2023-01-04 06:30:15,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:15,500 INFO:     Epoch: 66
2023-01-04 06:30:17,081 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4251152406136195, 'Total loss': 0.4251152406136195} | train loss {'Reaction outcome loss': 0.288003748051659, 'Total loss': 0.288003748051659}
2023-01-04 06:30:17,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:17,081 INFO:     Epoch: 67
2023-01-04 06:30:18,582 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.401331061621507, 'Total loss': 0.401331061621507} | train loss {'Reaction outcome loss': 0.28801144640484866, 'Total loss': 0.28801144640484866}
2023-01-04 06:30:18,582 INFO:     Found new best model at epoch 67
2023-01-04 06:30:18,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:18,583 INFO:     Epoch: 68
2023-01-04 06:30:20,145 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42664967278639476, 'Total loss': 0.42664967278639476} | train loss {'Reaction outcome loss': 0.28937999168614836, 'Total loss': 0.28937999168614836}
2023-01-04 06:30:20,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:20,145 INFO:     Epoch: 69
2023-01-04 06:30:21,707 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41211669022838276, 'Total loss': 0.41211669022838276} | train loss {'Reaction outcome loss': 0.2807760931633032, 'Total loss': 0.2807760931633032}
2023-01-04 06:30:21,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:21,707 INFO:     Epoch: 70
2023-01-04 06:30:23,269 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4346093773841858, 'Total loss': 0.4346093773841858} | train loss {'Reaction outcome loss': 0.2801025107938008, 'Total loss': 0.2801025107938008}
2023-01-04 06:30:23,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:23,269 INFO:     Epoch: 71
2023-01-04 06:30:24,820 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4116960326830546, 'Total loss': 0.4116960326830546} | train loss {'Reaction outcome loss': 0.2779004061934504, 'Total loss': 0.2779004061934504}
2023-01-04 06:30:24,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:24,820 INFO:     Epoch: 72
2023-01-04 06:30:26,381 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43458849291006724, 'Total loss': 0.43458849291006724} | train loss {'Reaction outcome loss': 0.2821947073659105, 'Total loss': 0.2821947073659105}
2023-01-04 06:30:26,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:26,381 INFO:     Epoch: 73
2023-01-04 06:30:27,861 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3895418067773183, 'Total loss': 0.3895418067773183} | train loss {'Reaction outcome loss': 0.27480386096956955, 'Total loss': 0.27480386096956955}
2023-01-04 06:30:27,861 INFO:     Found new best model at epoch 73
2023-01-04 06:30:27,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:27,862 INFO:     Epoch: 74
2023-01-04 06:30:29,440 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4111985852320989, 'Total loss': 0.4111985852320989} | train loss {'Reaction outcome loss': 0.2792492230715108, 'Total loss': 0.2792492230715108}
2023-01-04 06:30:29,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:29,440 INFO:     Epoch: 75
2023-01-04 06:30:31,001 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41007455984751384, 'Total loss': 0.41007455984751384} | train loss {'Reaction outcome loss': 0.2701303886290449, 'Total loss': 0.2701303886290449}
2023-01-04 06:30:31,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:31,002 INFO:     Epoch: 76
2023-01-04 06:30:32,552 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42598379254341123, 'Total loss': 0.42598379254341123} | train loss {'Reaction outcome loss': 0.272733113354575, 'Total loss': 0.272733113354575}
2023-01-04 06:30:32,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:32,553 INFO:     Epoch: 77
2023-01-04 06:30:34,094 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4294492483139038, 'Total loss': 0.4294492483139038} | train loss {'Reaction outcome loss': 0.27435770935385767, 'Total loss': 0.27435770935385767}
2023-01-04 06:30:34,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:34,095 INFO:     Epoch: 78
2023-01-04 06:30:35,622 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41158841997385026, 'Total loss': 0.41158841997385026} | train loss {'Reaction outcome loss': 0.2688642960232105, 'Total loss': 0.2688642960232105}
2023-01-04 06:30:35,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:35,622 INFO:     Epoch: 79
2023-01-04 06:30:37,151 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41808728178342186, 'Total loss': 0.41808728178342186} | train loss {'Reaction outcome loss': 0.2732266546872846, 'Total loss': 0.2732266546872846}
2023-01-04 06:30:37,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:37,152 INFO:     Epoch: 80
2023-01-04 06:30:38,681 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4100943346818288, 'Total loss': 0.4100943346818288} | train loss {'Reaction outcome loss': 0.2689867853900812, 'Total loss': 0.2689867853900812}
2023-01-04 06:30:38,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:38,681 INFO:     Epoch: 81
2023-01-04 06:30:40,222 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4129150817791621, 'Total loss': 0.4129150817791621} | train loss {'Reaction outcome loss': 0.26663557048479136, 'Total loss': 0.26663557048479136}
2023-01-04 06:30:40,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:40,222 INFO:     Epoch: 82
2023-01-04 06:30:41,773 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41272974809010826, 'Total loss': 0.41272974809010826} | train loss {'Reaction outcome loss': 0.2627667054452383, 'Total loss': 0.2627667054452383}
2023-01-04 06:30:41,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:41,773 INFO:     Epoch: 83
2023-01-04 06:30:43,323 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4008037656545639, 'Total loss': 0.4008037656545639} | train loss {'Reaction outcome loss': 0.2636827258461148, 'Total loss': 0.2636827258461148}
2023-01-04 06:30:43,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:43,323 INFO:     Epoch: 84
2023-01-04 06:30:44,802 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40550457338492074, 'Total loss': 0.40550457338492074} | train loss {'Reaction outcome loss': 0.2651004174139595, 'Total loss': 0.2651004174139595}
2023-01-04 06:30:44,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:44,803 INFO:     Epoch: 85
2023-01-04 06:30:46,320 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4126642197370529, 'Total loss': 0.4126642197370529} | train loss {'Reaction outcome loss': 0.2603241641917368, 'Total loss': 0.2603241641917368}
2023-01-04 06:30:46,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:46,321 INFO:     Epoch: 86
2023-01-04 06:30:47,857 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4252518316109975, 'Total loss': 0.4252518316109975} | train loss {'Reaction outcome loss': 0.26043140639408224, 'Total loss': 0.26043140639408224}
2023-01-04 06:30:47,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:47,857 INFO:     Epoch: 87
2023-01-04 06:30:49,394 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39896965622901914, 'Total loss': 0.39896965622901914} | train loss {'Reaction outcome loss': 0.2610946307434653, 'Total loss': 0.2610946307434653}
2023-01-04 06:30:49,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:49,395 INFO:     Epoch: 88
2023-01-04 06:30:50,935 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3834789534409841, 'Total loss': 0.3834789534409841} | train loss {'Reaction outcome loss': 0.261329917665435, 'Total loss': 0.261329917665435}
2023-01-04 06:30:50,935 INFO:     Found new best model at epoch 88
2023-01-04 06:30:50,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:50,936 INFO:     Epoch: 89
2023-01-04 06:30:52,485 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4007630864779154, 'Total loss': 0.4007630864779154} | train loss {'Reaction outcome loss': 0.2575065721315842, 'Total loss': 0.2575065721315842}
2023-01-04 06:30:52,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:52,485 INFO:     Epoch: 90
2023-01-04 06:30:53,963 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4023083170255025, 'Total loss': 0.4023083170255025} | train loss {'Reaction outcome loss': 0.2579547278243151, 'Total loss': 0.2579547278243151}
2023-01-04 06:30:53,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:53,964 INFO:     Epoch: 91
2023-01-04 06:30:55,527 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4109209259351095, 'Total loss': 0.4109209259351095} | train loss {'Reaction outcome loss': 0.2543039499870399, 'Total loss': 0.2543039499870399}
2023-01-04 06:30:55,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:55,528 INFO:     Epoch: 92
2023-01-04 06:30:57,093 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3996486802895864, 'Total loss': 0.3996486802895864} | train loss {'Reaction outcome loss': 0.2524293556700658, 'Total loss': 0.2524293556700658}
2023-01-04 06:30:57,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:57,093 INFO:     Epoch: 93
2023-01-04 06:30:58,650 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39670848846435547, 'Total loss': 0.39670848846435547} | train loss {'Reaction outcome loss': 0.25544600088122116, 'Total loss': 0.25544600088122116}
2023-01-04 06:30:58,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:30:58,651 INFO:     Epoch: 94
2023-01-04 06:31:00,196 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4304015715916952, 'Total loss': 0.4304015715916952} | train loss {'Reaction outcome loss': 0.2515051974948958, 'Total loss': 0.2515051974948958}
2023-01-04 06:31:00,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:00,197 INFO:     Epoch: 95
2023-01-04 06:31:01,753 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3861863334973653, 'Total loss': 0.3861863334973653} | train loss {'Reaction outcome loss': 0.2508025990839857, 'Total loss': 0.2508025990839857}
2023-01-04 06:31:01,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:01,754 INFO:     Epoch: 96
2023-01-04 06:31:03,221 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4342354049285253, 'Total loss': 0.4342354049285253} | train loss {'Reaction outcome loss': 0.24956086273882946, 'Total loss': 0.24956086273882946}
2023-01-04 06:31:03,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:03,221 INFO:     Epoch: 97
2023-01-04 06:31:04,790 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4363219420115153, 'Total loss': 0.4363219420115153} | train loss {'Reaction outcome loss': 0.24934916153386996, 'Total loss': 0.24934916153386996}
2023-01-04 06:31:04,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:04,791 INFO:     Epoch: 98
2023-01-04 06:31:06,344 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3924364070097605, 'Total loss': 0.3924364070097605} | train loss {'Reaction outcome loss': 0.2473037601006727, 'Total loss': 0.2473037601006727}
2023-01-04 06:31:06,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:06,345 INFO:     Epoch: 99
2023-01-04 06:31:07,905 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4243512650330861, 'Total loss': 0.4243512650330861} | train loss {'Reaction outcome loss': 0.24604053172643167, 'Total loss': 0.24604053172643167}
2023-01-04 06:31:07,905 INFO:     Best model found after epoch 89 of 100.
2023-01-04 06:31:07,906 INFO:   Done with stage: TRAINING
2023-01-04 06:31:07,906 INFO:   Starting stage: EVALUATION
2023-01-04 06:31:08,037 INFO:   Done with stage: EVALUATION
2023-01-04 06:31:08,037 INFO:   Leaving out SEQ value Fold_1
2023-01-04 06:31:08,050 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 06:31:08,050 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:31:08,690 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:31:08,690 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:31:08,758 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:31:08,759 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:31:08,759 INFO:     No hyperparam tuning for this model
2023-01-04 06:31:08,759 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:31:08,759 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:31:08,759 INFO:     None feature selector for col prot
2023-01-04 06:31:08,760 INFO:     None feature selector for col prot
2023-01-04 06:31:08,760 INFO:     None feature selector for col prot
2023-01-04 06:31:08,760 INFO:     None feature selector for col chem
2023-01-04 06:31:08,760 INFO:     None feature selector for col chem
2023-01-04 06:31:08,760 INFO:     None feature selector for col chem
2023-01-04 06:31:08,760 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:31:08,760 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:31:08,761 INFO:     Number of params in model 70111
2023-01-04 06:31:08,764 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:31:08,765 INFO:   Starting stage: TRAINING
2023-01-04 06:31:08,807 INFO:     Val loss before train {'Reaction outcome loss': 1.0583385586738587, 'Total loss': 1.0583385586738587}
2023-01-04 06:31:08,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:08,807 INFO:     Epoch: 0
2023-01-04 06:31:10,339 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7181301196416219, 'Total loss': 0.7181301196416219} | train loss {'Reaction outcome loss': 0.820237690122365, 'Total loss': 0.820237690122365}
2023-01-04 06:31:10,339 INFO:     Found new best model at epoch 0
2023-01-04 06:31:10,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:10,340 INFO:     Epoch: 1
2023-01-04 06:31:11,798 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5926567475001018, 'Total loss': 0.5926567475001018} | train loss {'Reaction outcome loss': 0.6517376931611022, 'Total loss': 0.6517376931611022}
2023-01-04 06:31:11,799 INFO:     Found new best model at epoch 1
2023-01-04 06:31:11,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:11,799 INFO:     Epoch: 2
2023-01-04 06:31:13,318 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5733203530311585, 'Total loss': 0.5733203530311585} | train loss {'Reaction outcome loss': 0.5684801001940266, 'Total loss': 0.5684801001940266}
2023-01-04 06:31:13,318 INFO:     Found new best model at epoch 2
2023-01-04 06:31:13,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:13,319 INFO:     Epoch: 3
2023-01-04 06:31:14,834 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5299837013085683, 'Total loss': 0.5299837013085683} | train loss {'Reaction outcome loss': 0.5359206395395567, 'Total loss': 0.5359206395395567}
2023-01-04 06:31:14,834 INFO:     Found new best model at epoch 3
2023-01-04 06:31:14,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:14,835 INFO:     Epoch: 4
2023-01-04 06:31:16,355 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4967586755752563, 'Total loss': 0.4967586755752563} | train loss {'Reaction outcome loss': 0.5143743992621609, 'Total loss': 0.5143743992621609}
2023-01-04 06:31:16,355 INFO:     Found new best model at epoch 4
2023-01-04 06:31:16,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:16,356 INFO:     Epoch: 5
2023-01-04 06:31:17,889 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4939473867416382, 'Total loss': 0.4939473867416382} | train loss {'Reaction outcome loss': 0.5007092794369068, 'Total loss': 0.5007092794369068}
2023-01-04 06:31:17,889 INFO:     Found new best model at epoch 5
2023-01-04 06:31:17,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:17,890 INFO:     Epoch: 6
2023-01-04 06:31:19,424 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4984963874022166, 'Total loss': 0.4984963874022166} | train loss {'Reaction outcome loss': 0.49259285232897615, 'Total loss': 0.49259285232897615}
2023-01-04 06:31:19,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:19,425 INFO:     Epoch: 7
2023-01-04 06:31:20,896 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49094269474347435, 'Total loss': 0.49094269474347435} | train loss {'Reaction outcome loss': 0.48372009374558705, 'Total loss': 0.48372009374558705}
2023-01-04 06:31:20,897 INFO:     Found new best model at epoch 7
2023-01-04 06:31:20,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:20,897 INFO:     Epoch: 8
2023-01-04 06:31:22,429 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4742098848025004, 'Total loss': 0.4742098848025004} | train loss {'Reaction outcome loss': 0.47539733108339277, 'Total loss': 0.47539733108339277}
2023-01-04 06:31:22,429 INFO:     Found new best model at epoch 8
2023-01-04 06:31:22,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:22,430 INFO:     Epoch: 9
2023-01-04 06:31:23,958 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4957641104857127, 'Total loss': 0.4957641104857127} | train loss {'Reaction outcome loss': 0.46933201565733695, 'Total loss': 0.46933201565733695}
2023-01-04 06:31:23,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:23,959 INFO:     Epoch: 10
2023-01-04 06:31:25,503 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46846025586128237, 'Total loss': 0.46846025586128237} | train loss {'Reaction outcome loss': 0.46119060023684344, 'Total loss': 0.46119060023684344}
2023-01-04 06:31:25,503 INFO:     Found new best model at epoch 10
2023-01-04 06:31:25,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:25,504 INFO:     Epoch: 11
2023-01-04 06:31:27,059 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4546169638633728, 'Total loss': 0.4546169638633728} | train loss {'Reaction outcome loss': 0.45246432149762156, 'Total loss': 0.45246432149762156}
2023-01-04 06:31:27,060 INFO:     Found new best model at epoch 11
2023-01-04 06:31:27,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:27,060 INFO:     Epoch: 12
2023-01-04 06:31:28,605 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4709749102592468, 'Total loss': 0.4709749102592468} | train loss {'Reaction outcome loss': 0.4468745091634483, 'Total loss': 0.4468745091634483}
2023-01-04 06:31:28,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:28,605 INFO:     Epoch: 13
2023-01-04 06:31:30,067 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5052933196226755, 'Total loss': 0.5052933196226755} | train loss {'Reaction outcome loss': 0.4438907511229885, 'Total loss': 0.4438907511229885}
2023-01-04 06:31:30,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:30,067 INFO:     Epoch: 14
2023-01-04 06:31:31,588 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4774805287520091, 'Total loss': 0.4774805287520091} | train loss {'Reaction outcome loss': 0.44348343189572054, 'Total loss': 0.44348343189572054}
2023-01-04 06:31:31,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:31,589 INFO:     Epoch: 15
2023-01-04 06:31:33,123 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47051859299341836, 'Total loss': 0.47051859299341836} | train loss {'Reaction outcome loss': 0.4329849163489588, 'Total loss': 0.4329849163489588}
2023-01-04 06:31:33,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:33,124 INFO:     Epoch: 16
2023-01-04 06:31:34,655 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46369211822748185, 'Total loss': 0.46369211822748185} | train loss {'Reaction outcome loss': 0.4263304895360531, 'Total loss': 0.4263304895360531}
2023-01-04 06:31:34,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:34,656 INFO:     Epoch: 17
2023-01-04 06:31:36,178 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44938214421272277, 'Total loss': 0.44938214421272277} | train loss {'Reaction outcome loss': 0.4245345556208128, 'Total loss': 0.4245345556208128}
2023-01-04 06:31:36,178 INFO:     Found new best model at epoch 17
2023-01-04 06:31:36,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:36,179 INFO:     Epoch: 18
2023-01-04 06:31:37,692 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43982287446657814, 'Total loss': 0.43982287446657814} | train loss {'Reaction outcome loss': 0.41908434280830115, 'Total loss': 0.41908434280830115}
2023-01-04 06:31:37,692 INFO:     Found new best model at epoch 18
2023-01-04 06:31:37,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:37,693 INFO:     Epoch: 19
2023-01-04 06:31:39,138 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46070392926534015, 'Total loss': 0.46070392926534015} | train loss {'Reaction outcome loss': 0.41192081262704633, 'Total loss': 0.41192081262704633}
2023-01-04 06:31:39,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:39,139 INFO:     Epoch: 20
2023-01-04 06:31:40,692 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5228650351365407, 'Total loss': 0.5228650351365407} | train loss {'Reaction outcome loss': 0.4125692227174875, 'Total loss': 0.4125692227174875}
2023-01-04 06:31:40,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:40,692 INFO:     Epoch: 21
2023-01-04 06:31:42,264 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4494306614001592, 'Total loss': 0.4494306614001592} | train loss {'Reaction outcome loss': 0.40530866401001975, 'Total loss': 0.40530866401001975}
2023-01-04 06:31:42,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:42,264 INFO:     Epoch: 22
2023-01-04 06:31:43,836 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46065133015314735, 'Total loss': 0.46065133015314735} | train loss {'Reaction outcome loss': 0.39671043941675516, 'Total loss': 0.39671043941675516}
2023-01-04 06:31:43,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:43,836 INFO:     Epoch: 23
2023-01-04 06:31:45,400 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4677795320749283, 'Total loss': 0.4677795320749283} | train loss {'Reaction outcome loss': 0.39175896385059145, 'Total loss': 0.39175896385059145}
2023-01-04 06:31:45,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:45,400 INFO:     Epoch: 24
2023-01-04 06:31:46,963 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4790551155805588, 'Total loss': 0.4790551155805588} | train loss {'Reaction outcome loss': 0.38832257896991673, 'Total loss': 0.38832257896991673}
2023-01-04 06:31:46,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:46,963 INFO:     Epoch: 25
2023-01-04 06:31:48,480 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43011791110038755, 'Total loss': 0.43011791110038755} | train loss {'Reaction outcome loss': 0.38203049720543336, 'Total loss': 0.38203049720543336}
2023-01-04 06:31:48,480 INFO:     Found new best model at epoch 25
2023-01-04 06:31:48,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:48,481 INFO:     Epoch: 26
2023-01-04 06:31:50,051 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4562330017487208, 'Total loss': 0.4562330017487208} | train loss {'Reaction outcome loss': 0.3790946323218381, 'Total loss': 0.3790946323218381}
2023-01-04 06:31:50,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:50,051 INFO:     Epoch: 27
2023-01-04 06:31:51,621 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4198164135217667, 'Total loss': 0.4198164135217667} | train loss {'Reaction outcome loss': 0.37668653451098727, 'Total loss': 0.37668653451098727}
2023-01-04 06:31:51,622 INFO:     Found new best model at epoch 27
2023-01-04 06:31:51,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:51,623 INFO:     Epoch: 28
2023-01-04 06:31:53,192 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43077906568845115, 'Total loss': 0.43077906568845115} | train loss {'Reaction outcome loss': 0.37013686759005615, 'Total loss': 0.37013686759005615}
2023-01-04 06:31:53,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:53,193 INFO:     Epoch: 29
2023-01-04 06:31:54,761 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44205809334913887, 'Total loss': 0.44205809334913887} | train loss {'Reaction outcome loss': 0.3662260046909216, 'Total loss': 0.3662260046909216}
2023-01-04 06:31:54,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:54,761 INFO:     Epoch: 30
2023-01-04 06:31:56,337 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42028231422106427, 'Total loss': 0.42028231422106427} | train loss {'Reaction outcome loss': 0.36152373237803415, 'Total loss': 0.36152373237803415}
2023-01-04 06:31:56,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:56,337 INFO:     Epoch: 31
2023-01-04 06:31:57,865 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42808255304892856, 'Total loss': 0.42808255304892856} | train loss {'Reaction outcome loss': 0.3582876130553629, 'Total loss': 0.3582876130553629}
2023-01-04 06:31:57,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:57,865 INFO:     Epoch: 32
2023-01-04 06:31:59,431 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.446291654308637, 'Total loss': 0.446291654308637} | train loss {'Reaction outcome loss': 0.35438180299702604, 'Total loss': 0.35438180299702604}
2023-01-04 06:31:59,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:31:59,431 INFO:     Epoch: 33
2023-01-04 06:32:00,996 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4538006246089935, 'Total loss': 0.4538006246089935} | train loss {'Reaction outcome loss': 0.3503276474251518, 'Total loss': 0.3503276474251518}
2023-01-04 06:32:00,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:00,996 INFO:     Epoch: 34
2023-01-04 06:32:02,564 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4806073397397995, 'Total loss': 0.4806073397397995} | train loss {'Reaction outcome loss': 0.3483047987647162, 'Total loss': 0.3483047987647162}
2023-01-04 06:32:02,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:02,564 INFO:     Epoch: 35
2023-01-04 06:32:04,134 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43093507587909696, 'Total loss': 0.43093507587909696} | train loss {'Reaction outcome loss': 0.3458838278901973, 'Total loss': 0.3458838278901973}
2023-01-04 06:32:04,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:04,135 INFO:     Epoch: 36
2023-01-04 06:32:05,700 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4120249390602112, 'Total loss': 0.4120249390602112} | train loss {'Reaction outcome loss': 0.3381731728181188, 'Total loss': 0.3381731728181188}
2023-01-04 06:32:05,700 INFO:     Found new best model at epoch 36
2023-01-04 06:32:05,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:05,701 INFO:     Epoch: 37
2023-01-04 06:32:07,245 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4519765337308248, 'Total loss': 0.4519765337308248} | train loss {'Reaction outcome loss': 0.33396669752153524, 'Total loss': 0.33396669752153524}
2023-01-04 06:32:07,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:07,245 INFO:     Epoch: 38
2023-01-04 06:32:08,789 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4335238450517257, 'Total loss': 0.4335238450517257} | train loss {'Reaction outcome loss': 0.3377424534616435, 'Total loss': 0.3377424534616435}
2023-01-04 06:32:08,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:08,790 INFO:     Epoch: 39
2023-01-04 06:32:10,352 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4107144594192505, 'Total loss': 0.4107144594192505} | train loss {'Reaction outcome loss': 0.33271266929667814, 'Total loss': 0.33271266929667814}
2023-01-04 06:32:10,353 INFO:     Found new best model at epoch 39
2023-01-04 06:32:10,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:10,353 INFO:     Epoch: 40
2023-01-04 06:32:11,919 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4416624883810679, 'Total loss': 0.4416624883810679} | train loss {'Reaction outcome loss': 0.32795774656248267, 'Total loss': 0.32795774656248267}
2023-01-04 06:32:11,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:11,919 INFO:     Epoch: 41
2023-01-04 06:32:13,486 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.454691876967748, 'Total loss': 0.454691876967748} | train loss {'Reaction outcome loss': 0.3255446985418946, 'Total loss': 0.3255446985418946}
2023-01-04 06:32:13,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:13,486 INFO:     Epoch: 42
2023-01-04 06:32:15,024 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43490642805894214, 'Total loss': 0.43490642805894214} | train loss {'Reaction outcome loss': 0.3244592426447851, 'Total loss': 0.3244592426447851}
2023-01-04 06:32:15,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:15,024 INFO:     Epoch: 43
2023-01-04 06:32:16,567 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4693862517674764, 'Total loss': 0.4693862517674764} | train loss {'Reaction outcome loss': 0.324059248657904, 'Total loss': 0.324059248657904}
2023-01-04 06:32:16,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:16,567 INFO:     Epoch: 44
2023-01-04 06:32:18,030 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42595617671807606, 'Total loss': 0.42595617671807606} | train loss {'Reaction outcome loss': 0.3169114682892152, 'Total loss': 0.3169114682892152}
2023-01-04 06:32:18,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:18,030 INFO:     Epoch: 45
2023-01-04 06:32:19,536 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41870641509691875, 'Total loss': 0.41870641509691875} | train loss {'Reaction outcome loss': 0.3149368027534432, 'Total loss': 0.3149368027534432}
2023-01-04 06:32:19,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:19,536 INFO:     Epoch: 46
2023-01-04 06:32:21,040 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4506485442320506, 'Total loss': 0.4506485442320506} | train loss {'Reaction outcome loss': 0.31574392472685925, 'Total loss': 0.31574392472685925}
2023-01-04 06:32:21,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:21,040 INFO:     Epoch: 47
2023-01-04 06:32:22,573 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4166093031565348, 'Total loss': 0.4166093031565348} | train loss {'Reaction outcome loss': 0.31516023233148005, 'Total loss': 0.31516023233148005}
2023-01-04 06:32:22,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:22,574 INFO:     Epoch: 48
2023-01-04 06:32:24,115 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42347997923692066, 'Total loss': 0.42347997923692066} | train loss {'Reaction outcome loss': 0.31088699427917876, 'Total loss': 0.31088699427917876}
2023-01-04 06:32:24,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:24,116 INFO:     Epoch: 49
2023-01-04 06:32:25,639 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4241986950238546, 'Total loss': 0.4241986950238546} | train loss {'Reaction outcome loss': 0.3091349754056367, 'Total loss': 0.3091349754056367}
2023-01-04 06:32:25,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:25,639 INFO:     Epoch: 50
2023-01-04 06:32:27,148 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4075221624225378, 'Total loss': 0.4075221624225378} | train loss {'Reaction outcome loss': 0.3001715532363121, 'Total loss': 0.3001715532363121}
2023-01-04 06:32:27,148 INFO:     Found new best model at epoch 50
2023-01-04 06:32:27,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:27,149 INFO:     Epoch: 51
2023-01-04 06:32:28,693 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41638804972171783, 'Total loss': 0.41638804972171783} | train loss {'Reaction outcome loss': 0.30286484376640777, 'Total loss': 0.30286484376640777}
2023-01-04 06:32:28,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:28,693 INFO:     Epoch: 52
2023-01-04 06:32:30,247 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4305829753478368, 'Total loss': 0.4305829753478368} | train loss {'Reaction outcome loss': 0.3017742556014624, 'Total loss': 0.3017742556014624}
2023-01-04 06:32:30,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:30,247 INFO:     Epoch: 53
2023-01-04 06:32:31,793 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41409159104029336, 'Total loss': 0.41409159104029336} | train loss {'Reaction outcome loss': 0.3001303274418155, 'Total loss': 0.3001303274418155}
2023-01-04 06:32:31,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:31,793 INFO:     Epoch: 54
2023-01-04 06:32:33,307 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43298894762992857, 'Total loss': 0.43298894762992857} | train loss {'Reaction outcome loss': 0.3046060668586365, 'Total loss': 0.3046060668586365}
2023-01-04 06:32:33,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:33,308 INFO:     Epoch: 55
2023-01-04 06:32:34,873 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40628264943758646, 'Total loss': 0.40628264943758646} | train loss {'Reaction outcome loss': 0.29788692936136274, 'Total loss': 0.29788692936136274}
2023-01-04 06:32:34,874 INFO:     Found new best model at epoch 55
2023-01-04 06:32:34,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:34,875 INFO:     Epoch: 56
2023-01-04 06:32:36,385 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4214849919080734, 'Total loss': 0.4214849919080734} | train loss {'Reaction outcome loss': 0.28951271672860285, 'Total loss': 0.28951271672860285}
2023-01-04 06:32:36,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:36,385 INFO:     Epoch: 57
2023-01-04 06:32:37,923 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.471229100227356, 'Total loss': 0.471229100227356} | train loss {'Reaction outcome loss': 0.2920681431174718, 'Total loss': 0.2920681431174718}
2023-01-04 06:32:37,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:37,923 INFO:     Epoch: 58
2023-01-04 06:32:39,465 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4540443996588389, 'Total loss': 0.4540443996588389} | train loss {'Reaction outcome loss': 0.29287190476906694, 'Total loss': 0.29287190476906694}
2023-01-04 06:32:39,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:39,465 INFO:     Epoch: 59
2023-01-04 06:32:41,040 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4140843331813812, 'Total loss': 0.4140843331813812} | train loss {'Reaction outcome loss': 0.28634641830881585, 'Total loss': 0.28634641830881585}
2023-01-04 06:32:41,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:41,042 INFO:     Epoch: 60
2023-01-04 06:32:42,577 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4539192795753479, 'Total loss': 0.4539192795753479} | train loss {'Reaction outcome loss': 0.2889457194897522, 'Total loss': 0.2889457194897522}
2023-01-04 06:32:42,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:42,577 INFO:     Epoch: 61
2023-01-04 06:32:44,164 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4511194537083308, 'Total loss': 0.4511194537083308} | train loss {'Reaction outcome loss': 0.28850599408589606, 'Total loss': 0.28850599408589606}
2023-01-04 06:32:44,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:44,165 INFO:     Epoch: 62
2023-01-04 06:32:45,704 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4188317100207011, 'Total loss': 0.4188317100207011} | train loss {'Reaction outcome loss': 0.28641685782983295, 'Total loss': 0.28641685782983295}
2023-01-04 06:32:45,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:45,704 INFO:     Epoch: 63
2023-01-04 06:32:47,270 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46106685598691305, 'Total loss': 0.46106685598691305} | train loss {'Reaction outcome loss': 0.2837803562023983, 'Total loss': 0.2837803562023983}
2023-01-04 06:32:47,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:47,271 INFO:     Epoch: 64
2023-01-04 06:32:48,836 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41288393139839175, 'Total loss': 0.41288393139839175} | train loss {'Reaction outcome loss': 0.2817411367881122, 'Total loss': 0.2817411367881122}
2023-01-04 06:32:48,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:48,836 INFO:     Epoch: 65
2023-01-04 06:32:50,385 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40381147265434264, 'Total loss': 0.40381147265434264} | train loss {'Reaction outcome loss': 0.2803628826135859, 'Total loss': 0.2803628826135859}
2023-01-04 06:32:50,385 INFO:     Found new best model at epoch 65
2023-01-04 06:32:50,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:50,386 INFO:     Epoch: 66
2023-01-04 06:32:51,878 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42312074104944863, 'Total loss': 0.42312074104944863} | train loss {'Reaction outcome loss': 0.2775991503080539, 'Total loss': 0.2775991503080539}
2023-01-04 06:32:51,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:51,879 INFO:     Epoch: 67
2023-01-04 06:32:53,440 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39848047196865083, 'Total loss': 0.39848047196865083} | train loss {'Reaction outcome loss': 0.2782135735853572, 'Total loss': 0.2782135735853572}
2023-01-04 06:32:53,440 INFO:     Found new best model at epoch 67
2023-01-04 06:32:53,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:53,441 INFO:     Epoch: 68
2023-01-04 06:32:54,975 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4413518567879995, 'Total loss': 0.4413518567879995} | train loss {'Reaction outcome loss': 0.2782311366383, 'Total loss': 0.2782311366383}
2023-01-04 06:32:54,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:54,975 INFO:     Epoch: 69
2023-01-04 06:32:56,534 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4283349961042404, 'Total loss': 0.4283349961042404} | train loss {'Reaction outcome loss': 0.272676525355705, 'Total loss': 0.272676525355705}
2023-01-04 06:32:56,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:56,535 INFO:     Epoch: 70
2023-01-04 06:32:58,120 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39228564749161404, 'Total loss': 0.39228564749161404} | train loss {'Reaction outcome loss': 0.27079321806941087, 'Total loss': 0.27079321806941087}
2023-01-04 06:32:58,120 INFO:     Found new best model at epoch 70
2023-01-04 06:32:58,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:58,121 INFO:     Epoch: 71
2023-01-04 06:32:59,678 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4187522570292155, 'Total loss': 0.4187522570292155} | train loss {'Reaction outcome loss': 0.27140930376094646, 'Total loss': 0.27140930376094646}
2023-01-04 06:32:59,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:32:59,678 INFO:     Epoch: 72
2023-01-04 06:33:01,208 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43085519870122274, 'Total loss': 0.43085519870122274} | train loss {'Reaction outcome loss': 0.27008177796413096, 'Total loss': 0.27008177796413096}
2023-01-04 06:33:01,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:01,208 INFO:     Epoch: 73
2023-01-04 06:33:02,744 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4044664025306702, 'Total loss': 0.4044664025306702} | train loss {'Reaction outcome loss': 0.26768541061130396, 'Total loss': 0.26768541061130396}
2023-01-04 06:33:02,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:02,744 INFO:     Epoch: 74
2023-01-04 06:33:04,300 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4163655281066895, 'Total loss': 0.4163655281066895} | train loss {'Reaction outcome loss': 0.2699752972629677, 'Total loss': 0.2699752972629677}
2023-01-04 06:33:04,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:04,301 INFO:     Epoch: 75
2023-01-04 06:33:05,841 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.395777823527654, 'Total loss': 0.395777823527654} | train loss {'Reaction outcome loss': 0.2652554782829161, 'Total loss': 0.2652554782829161}
2023-01-04 06:33:05,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:05,842 INFO:     Epoch: 76
2023-01-04 06:33:07,385 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4086184839407603, 'Total loss': 0.4086184839407603} | train loss {'Reaction outcome loss': 0.26647321050952283, 'Total loss': 0.26647321050952283}
2023-01-04 06:33:07,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:07,385 INFO:     Epoch: 77
2023-01-04 06:33:08,940 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4209333774944147, 'Total loss': 0.4209333774944147} | train loss {'Reaction outcome loss': 0.263289609271002, 'Total loss': 0.263289609271002}
2023-01-04 06:33:08,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:08,940 INFO:     Epoch: 78
2023-01-04 06:33:10,461 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3917746067047119, 'Total loss': 0.3917746067047119} | train loss {'Reaction outcome loss': 0.2659465401429972, 'Total loss': 0.2659465401429972}
2023-01-04 06:33:10,461 INFO:     Found new best model at epoch 78
2023-01-04 06:33:10,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:10,462 INFO:     Epoch: 79
2023-01-04 06:33:11,987 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4456622004508972, 'Total loss': 0.4456622004508972} | train loss {'Reaction outcome loss': 0.2630108763975851, 'Total loss': 0.2630108763975851}
2023-01-04 06:33:11,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:11,988 INFO:     Epoch: 80
2023-01-04 06:33:13,529 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44758605360984804, 'Total loss': 0.44758605360984804} | train loss {'Reaction outcome loss': 0.26186840148209645, 'Total loss': 0.26186840148209645}
2023-01-04 06:33:13,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:13,529 INFO:     Epoch: 81
2023-01-04 06:33:15,065 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4454162657260895, 'Total loss': 0.4454162657260895} | train loss {'Reaction outcome loss': 0.26275278757089177, 'Total loss': 0.26275278757089177}
2023-01-04 06:33:15,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:15,065 INFO:     Epoch: 82
2023-01-04 06:33:16,621 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4435931146144867, 'Total loss': 0.4435931146144867} | train loss {'Reaction outcome loss': 0.2619765148639019, 'Total loss': 0.2619765148639019}
2023-01-04 06:33:16,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:16,621 INFO:     Epoch: 83
2023-01-04 06:33:18,167 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4162617027759552, 'Total loss': 0.4162617027759552} | train loss {'Reaction outcome loss': 0.26280126074583327, 'Total loss': 0.26280126074583327}
2023-01-04 06:33:18,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:18,167 INFO:     Epoch: 84
2023-01-04 06:33:19,680 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41326785683631895, 'Total loss': 0.41326785683631895} | train loss {'Reaction outcome loss': 0.25787287559429, 'Total loss': 0.25787287559429}
2023-01-04 06:33:19,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:19,680 INFO:     Epoch: 85
2023-01-04 06:33:21,173 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41596000691254936, 'Total loss': 0.41596000691254936} | train loss {'Reaction outcome loss': 0.2549628718752703, 'Total loss': 0.2549628718752703}
2023-01-04 06:33:21,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:21,173 INFO:     Epoch: 86
2023-01-04 06:33:22,745 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4327765812476476, 'Total loss': 0.4327765812476476} | train loss {'Reaction outcome loss': 0.25269790510629814, 'Total loss': 0.25269790510629814}
2023-01-04 06:33:22,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:22,745 INFO:     Epoch: 87
2023-01-04 06:33:24,324 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41461892823378244, 'Total loss': 0.41461892823378244} | train loss {'Reaction outcome loss': 0.2570169297806451, 'Total loss': 0.2570169297806451}
2023-01-04 06:33:24,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:24,325 INFO:     Epoch: 88
2023-01-04 06:33:25,914 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41909468472003936, 'Total loss': 0.41909468472003936} | train loss {'Reaction outcome loss': 0.26182898950532796, 'Total loss': 0.26182898950532796}
2023-01-04 06:33:25,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:25,915 INFO:     Epoch: 89
2023-01-04 06:33:27,519 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44360758463541666, 'Total loss': 0.44360758463541666} | train loss {'Reaction outcome loss': 0.2529977976011174, 'Total loss': 0.2529977976011174}
2023-01-04 06:33:27,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:27,519 INFO:     Epoch: 90
2023-01-04 06:33:29,072 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.429477459192276, 'Total loss': 0.429477459192276} | train loss {'Reaction outcome loss': 0.2534048445797714, 'Total loss': 0.2534048445797714}
2023-01-04 06:33:29,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:29,072 INFO:     Epoch: 91
2023-01-04 06:33:30,614 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4402026693026225, 'Total loss': 0.4402026693026225} | train loss {'Reaction outcome loss': 0.2523484208184635, 'Total loss': 0.2523484208184635}
2023-01-04 06:33:30,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:30,614 INFO:     Epoch: 92
2023-01-04 06:33:32,211 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39056499153375623, 'Total loss': 0.39056499153375623} | train loss {'Reaction outcome loss': 0.25284627040098956, 'Total loss': 0.25284627040098956}
2023-01-04 06:33:32,211 INFO:     Found new best model at epoch 92
2023-01-04 06:33:32,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:32,211 INFO:     Epoch: 93
2023-01-04 06:33:33,796 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41459808746973675, 'Total loss': 0.41459808746973675} | train loss {'Reaction outcome loss': 0.25005580159076024, 'Total loss': 0.25005580159076024}
2023-01-04 06:33:33,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:33,797 INFO:     Epoch: 94
2023-01-04 06:33:35,387 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42857572038968406, 'Total loss': 0.42857572038968406} | train loss {'Reaction outcome loss': 0.2554870586828552, 'Total loss': 0.2554870586828552}
2023-01-04 06:33:35,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:35,387 INFO:     Epoch: 95
2023-01-04 06:33:36,936 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4053693781296412, 'Total loss': 0.4053693781296412} | train loss {'Reaction outcome loss': 0.24941324365644876, 'Total loss': 0.24941324365644876}
2023-01-04 06:33:36,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:36,937 INFO:     Epoch: 96
2023-01-04 06:33:38,525 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45905995965003965, 'Total loss': 0.45905995965003965} | train loss {'Reaction outcome loss': 0.24927455489265962, 'Total loss': 0.24927455489265962}
2023-01-04 06:33:38,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:38,525 INFO:     Epoch: 97
2023-01-04 06:33:40,064 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42957565089066824, 'Total loss': 0.42957565089066824} | train loss {'Reaction outcome loss': 0.24858346750540486, 'Total loss': 0.24858346750540486}
2023-01-04 06:33:40,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:40,064 INFO:     Epoch: 98
2023-01-04 06:33:41,658 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43391381700833637, 'Total loss': 0.43391381700833637} | train loss {'Reaction outcome loss': 0.246539038320749, 'Total loss': 0.246539038320749}
2023-01-04 06:33:41,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:41,658 INFO:     Epoch: 99
2023-01-04 06:33:43,247 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4197781225045522, 'Total loss': 0.4197781225045522} | train loss {'Reaction outcome loss': 0.24903422341135595, 'Total loss': 0.24903422341135595}
2023-01-04 06:33:43,248 INFO:     Best model found after epoch 93 of 100.
2023-01-04 06:33:43,248 INFO:   Done with stage: TRAINING
2023-01-04 06:33:43,248 INFO:   Starting stage: EVALUATION
2023-01-04 06:33:43,393 INFO:   Done with stage: EVALUATION
2023-01-04 06:33:43,393 INFO:   Leaving out SEQ value Fold_2
2023-01-04 06:33:43,406 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 06:33:43,406 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:33:44,050 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:33:44,051 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:33:44,121 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:33:44,121 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:33:44,121 INFO:     No hyperparam tuning for this model
2023-01-04 06:33:44,121 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:33:44,121 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:33:44,122 INFO:     None feature selector for col prot
2023-01-04 06:33:44,122 INFO:     None feature selector for col prot
2023-01-04 06:33:44,122 INFO:     None feature selector for col prot
2023-01-04 06:33:44,122 INFO:     None feature selector for col chem
2023-01-04 06:33:44,122 INFO:     None feature selector for col chem
2023-01-04 06:33:44,122 INFO:     None feature selector for col chem
2023-01-04 06:33:44,123 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:33:44,123 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:33:44,124 INFO:     Number of params in model 70111
2023-01-04 06:33:44,127 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:33:44,127 INFO:   Starting stage: TRAINING
2023-01-04 06:33:44,170 INFO:     Val loss before train {'Reaction outcome loss': 0.9216767271359761, 'Total loss': 0.9216767271359761}
2023-01-04 06:33:44,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:44,170 INFO:     Epoch: 0
2023-01-04 06:33:45,750 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7056351025899251, 'Total loss': 0.7056351025899251} | train loss {'Reaction outcome loss': 0.8451836162611194, 'Total loss': 0.8451836162611194}
2023-01-04 06:33:45,751 INFO:     Found new best model at epoch 0
2023-01-04 06:33:45,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:45,751 INFO:     Epoch: 1
2023-01-04 06:33:47,328 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5959328850110371, 'Total loss': 0.5959328850110371} | train loss {'Reaction outcome loss': 0.6906606795657907, 'Total loss': 0.6906606795657907}
2023-01-04 06:33:47,329 INFO:     Found new best model at epoch 1
2023-01-04 06:33:47,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:47,329 INFO:     Epoch: 2
2023-01-04 06:33:48,863 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5328012088934581, 'Total loss': 0.5328012088934581} | train loss {'Reaction outcome loss': 0.600260948964759, 'Total loss': 0.600260948964759}
2023-01-04 06:33:48,863 INFO:     Found new best model at epoch 2
2023-01-04 06:33:48,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:48,864 INFO:     Epoch: 3
2023-01-04 06:33:50,430 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5202759464581808, 'Total loss': 0.5202759464581808} | train loss {'Reaction outcome loss': 0.553110491842929, 'Total loss': 0.553110491842929}
2023-01-04 06:33:50,430 INFO:     Found new best model at epoch 3
2023-01-04 06:33:50,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:50,431 INFO:     Epoch: 4
2023-01-04 06:33:52,003 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48599736094474794, 'Total loss': 0.48599736094474794} | train loss {'Reaction outcome loss': 0.5245009859774153, 'Total loss': 0.5245009859774153}
2023-01-04 06:33:52,003 INFO:     Found new best model at epoch 4
2023-01-04 06:33:52,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:52,004 INFO:     Epoch: 5
2023-01-04 06:33:53,551 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46403234601020815, 'Total loss': 0.46403234601020815} | train loss {'Reaction outcome loss': 0.5115906882869161, 'Total loss': 0.5115906882869161}
2023-01-04 06:33:53,551 INFO:     Found new best model at epoch 5
2023-01-04 06:33:53,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:53,551 INFO:     Epoch: 6
2023-01-04 06:33:55,088 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48590766787528994, 'Total loss': 0.48590766787528994} | train loss {'Reaction outcome loss': 0.49584641428816173, 'Total loss': 0.49584641428816173}
2023-01-04 06:33:55,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:55,089 INFO:     Epoch: 7
2023-01-04 06:33:56,653 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47645092209180195, 'Total loss': 0.47645092209180195} | train loss {'Reaction outcome loss': 0.4832866727779417, 'Total loss': 0.4832866727779417}
2023-01-04 06:33:56,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:56,654 INFO:     Epoch: 8
2023-01-04 06:33:58,176 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.480191179116567, 'Total loss': 0.480191179116567} | train loss {'Reaction outcome loss': 0.48524633498079534, 'Total loss': 0.48524633498079534}
2023-01-04 06:33:58,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:58,177 INFO:     Epoch: 9
2023-01-04 06:33:59,744 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44957321981589, 'Total loss': 0.44957321981589} | train loss {'Reaction outcome loss': 0.5042586800088917, 'Total loss': 0.5042586800088917}
2023-01-04 06:33:59,744 INFO:     Found new best model at epoch 9
2023-01-04 06:33:59,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:33:59,745 INFO:     Epoch: 10
2023-01-04 06:34:01,300 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4804083168506622, 'Total loss': 0.4804083168506622} | train loss {'Reaction outcome loss': 0.4717966313271419, 'Total loss': 0.4717966313271419}
2023-01-04 06:34:01,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:01,300 INFO:     Epoch: 11
2023-01-04 06:34:02,852 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4513113717238108, 'Total loss': 0.4513113717238108} | train loss {'Reaction outcome loss': 0.46992135541918484, 'Total loss': 0.46992135541918484}
2023-01-04 06:34:02,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:02,852 INFO:     Epoch: 12
2023-01-04 06:34:04,383 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4460313538710276, 'Total loss': 0.4460313538710276} | train loss {'Reaction outcome loss': 0.4544619663578013, 'Total loss': 0.4544619663578013}
2023-01-04 06:34:04,383 INFO:     Found new best model at epoch 12
2023-01-04 06:34:04,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:04,384 INFO:     Epoch: 13
2023-01-04 06:34:05,963 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42320406138896943, 'Total loss': 0.42320406138896943} | train loss {'Reaction outcome loss': 0.4559433730390584, 'Total loss': 0.4559433730390584}
2023-01-04 06:34:05,963 INFO:     Found new best model at epoch 13
2023-01-04 06:34:05,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:05,964 INFO:     Epoch: 14
2023-01-04 06:34:07,495 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4441346526145935, 'Total loss': 0.4441346526145935} | train loss {'Reaction outcome loss': 0.44116067788158747, 'Total loss': 0.44116067788158747}
2023-01-04 06:34:07,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:07,496 INFO:     Epoch: 15
2023-01-04 06:34:09,045 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45255403220653534, 'Total loss': 0.45255403220653534} | train loss {'Reaction outcome loss': 0.43533146406369505, 'Total loss': 0.43533146406369505}
2023-01-04 06:34:09,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:09,045 INFO:     Epoch: 16
2023-01-04 06:34:10,619 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46602099438508354, 'Total loss': 0.46602099438508354} | train loss {'Reaction outcome loss': 0.4523952944015247, 'Total loss': 0.4523952944015247}
2023-01-04 06:34:10,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:10,619 INFO:     Epoch: 17
2023-01-04 06:34:12,166 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4496215204397837, 'Total loss': 0.4496215204397837} | train loss {'Reaction outcome loss': 0.4378283000034466, 'Total loss': 0.4378283000034466}
2023-01-04 06:34:12,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:12,166 INFO:     Epoch: 18
2023-01-04 06:34:13,688 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46598639488220217, 'Total loss': 0.46598639488220217} | train loss {'Reaction outcome loss': 0.4272287491594266, 'Total loss': 0.4272287491594266}
2023-01-04 06:34:13,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:13,689 INFO:     Epoch: 19
2023-01-04 06:34:15,256 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42613038619359334, 'Total loss': 0.42613038619359334} | train loss {'Reaction outcome loss': 0.4219907931983471, 'Total loss': 0.4219907931983471}
2023-01-04 06:34:15,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:15,256 INFO:     Epoch: 20
2023-01-04 06:34:16,811 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42489225467046104, 'Total loss': 0.42489225467046104} | train loss {'Reaction outcome loss': 0.4186480993040554, 'Total loss': 0.4186480993040554}
2023-01-04 06:34:16,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:16,812 INFO:     Epoch: 21
2023-01-04 06:34:18,369 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4390403707822164, 'Total loss': 0.4390403707822164} | train loss {'Reaction outcome loss': 0.41592421898267407, 'Total loss': 0.41592421898267407}
2023-01-04 06:34:18,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:18,369 INFO:     Epoch: 22
2023-01-04 06:34:19,942 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43335658411184946, 'Total loss': 0.43335658411184946} | train loss {'Reaction outcome loss': 0.4119375244835797, 'Total loss': 0.4119375244835797}
2023-01-04 06:34:19,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:19,943 INFO:     Epoch: 23
2023-01-04 06:34:21,505 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4298409362634023, 'Total loss': 0.4298409362634023} | train loss {'Reaction outcome loss': 0.4107279979448388, 'Total loss': 0.4107279979448388}
2023-01-04 06:34:21,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:21,505 INFO:     Epoch: 24
2023-01-04 06:34:23,034 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.438918067018191, 'Total loss': 0.438918067018191} | train loss {'Reaction outcome loss': 0.4051582666815839, 'Total loss': 0.4051582666815839}
2023-01-04 06:34:23,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:23,034 INFO:     Epoch: 25
2023-01-04 06:34:24,569 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4169253607590993, 'Total loss': 0.4169253607590993} | train loss {'Reaction outcome loss': 0.40195998650312464, 'Total loss': 0.40195998650312464}
2023-01-04 06:34:24,569 INFO:     Found new best model at epoch 25
2023-01-04 06:34:24,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:24,570 INFO:     Epoch: 26
2023-01-04 06:34:26,129 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4341254641612371, 'Total loss': 0.4341254641612371} | train loss {'Reaction outcome loss': 0.3995554363490015, 'Total loss': 0.3995554363490015}
2023-01-04 06:34:26,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:26,130 INFO:     Epoch: 27
2023-01-04 06:34:27,694 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44075063268343606, 'Total loss': 0.44075063268343606} | train loss {'Reaction outcome loss': 0.3948759962754, 'Total loss': 0.3948759962754}
2023-01-04 06:34:27,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:27,695 INFO:     Epoch: 28
2023-01-04 06:34:29,261 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4354009985923767, 'Total loss': 0.4354009985923767} | train loss {'Reaction outcome loss': 0.39611697070759494, 'Total loss': 0.39611697070759494}
2023-01-04 06:34:29,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:29,261 INFO:     Epoch: 29
2023-01-04 06:34:30,825 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4296875456968943, 'Total loss': 0.4296875456968943} | train loss {'Reaction outcome loss': 0.3872995704612391, 'Total loss': 0.3872995704612391}
2023-01-04 06:34:30,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:30,825 INFO:     Epoch: 30
2023-01-04 06:34:32,363 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42231834133466084, 'Total loss': 0.42231834133466084} | train loss {'Reaction outcome loss': 0.38277813211080036, 'Total loss': 0.38277813211080036}
2023-01-04 06:34:32,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:32,363 INFO:     Epoch: 31
2023-01-04 06:34:33,885 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42327092587947845, 'Total loss': 0.42327092587947845} | train loss {'Reaction outcome loss': 0.3825820349966702, 'Total loss': 0.3825820349966702}
2023-01-04 06:34:33,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:33,885 INFO:     Epoch: 32
2023-01-04 06:34:35,468 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4109727640946706, 'Total loss': 0.4109727640946706} | train loss {'Reaction outcome loss': 0.3802406041734461, 'Total loss': 0.3802406041734461}
2023-01-04 06:34:35,468 INFO:     Found new best model at epoch 32
2023-01-04 06:34:35,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:35,469 INFO:     Epoch: 33
2023-01-04 06:34:37,042 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41667405267556507, 'Total loss': 0.41667405267556507} | train loss {'Reaction outcome loss': 0.37709044304969924, 'Total loss': 0.37709044304969924}
2023-01-04 06:34:37,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:37,042 INFO:     Epoch: 34
2023-01-04 06:34:38,608 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4122990995645523, 'Total loss': 0.4122990995645523} | train loss {'Reaction outcome loss': 0.3698424097366523, 'Total loss': 0.3698424097366523}
2023-01-04 06:34:38,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:38,609 INFO:     Epoch: 35
2023-01-04 06:34:40,157 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4159074435631434, 'Total loss': 0.4159074435631434} | train loss {'Reaction outcome loss': 0.382332155028817, 'Total loss': 0.382332155028817}
2023-01-04 06:34:40,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:40,157 INFO:     Epoch: 36
2023-01-04 06:34:41,737 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4071872572104136, 'Total loss': 0.4071872572104136} | train loss {'Reaction outcome loss': 0.3674354344889846, 'Total loss': 0.3674354344889846}
2023-01-04 06:34:41,737 INFO:     Found new best model at epoch 36
2023-01-04 06:34:41,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:41,738 INFO:     Epoch: 37
2023-01-04 06:34:43,277 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4408493429422379, 'Total loss': 0.4408493429422379} | train loss {'Reaction outcome loss': 0.3644555174624142, 'Total loss': 0.3644555174624142}
2023-01-04 06:34:43,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:43,277 INFO:     Epoch: 38
2023-01-04 06:34:44,848 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42478922605514524, 'Total loss': 0.42478922605514524} | train loss {'Reaction outcome loss': 0.3618361392679314, 'Total loss': 0.3618361392679314}
2023-01-04 06:34:44,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:44,849 INFO:     Epoch: 39
2023-01-04 06:34:46,422 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4247845937808355, 'Total loss': 0.4247845937808355} | train loss {'Reaction outcome loss': 0.37485644928571105, 'Total loss': 0.37485644928571105}
2023-01-04 06:34:46,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:46,423 INFO:     Epoch: 40
2023-01-04 06:34:47,968 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4352074682712555, 'Total loss': 0.4352074682712555} | train loss {'Reaction outcome loss': 0.3763050709936394, 'Total loss': 0.3763050709936394}
2023-01-04 06:34:47,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:47,969 INFO:     Epoch: 41
2023-01-04 06:34:49,500 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38962060610453286, 'Total loss': 0.38962060610453286} | train loss {'Reaction outcome loss': 0.35207332249104883, 'Total loss': 0.35207332249104883}
2023-01-04 06:34:49,500 INFO:     Found new best model at epoch 41
2023-01-04 06:34:49,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:49,501 INFO:     Epoch: 42
2023-01-04 06:34:51,089 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41134979923566184, 'Total loss': 0.41134979923566184} | train loss {'Reaction outcome loss': 0.35212371807606163, 'Total loss': 0.35212371807606163}
2023-01-04 06:34:51,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:51,090 INFO:     Epoch: 43
2023-01-04 06:34:52,618 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4356568952401479, 'Total loss': 0.4356568952401479} | train loss {'Reaction outcome loss': 0.3440841796067273, 'Total loss': 0.3440841796067273}
2023-01-04 06:34:52,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:52,619 INFO:     Epoch: 44
2023-01-04 06:34:54,184 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4259379953145981, 'Total loss': 0.4259379953145981} | train loss {'Reaction outcome loss': 0.3475868277035762, 'Total loss': 0.3475868277035762}
2023-01-04 06:34:54,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:54,185 INFO:     Epoch: 45
2023-01-04 06:34:55,757 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4214452097813288, 'Total loss': 0.4214452097813288} | train loss {'Reaction outcome loss': 0.346989350218897, 'Total loss': 0.346989350218897}
2023-01-04 06:34:55,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:55,757 INFO:     Epoch: 46
2023-01-04 06:34:57,334 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4054233133792877, 'Total loss': 0.4054233133792877} | train loss {'Reaction outcome loss': 0.3403877099449544, 'Total loss': 0.3403877099449544}
2023-01-04 06:34:57,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:57,335 INFO:     Epoch: 47
2023-01-04 06:34:58,881 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40940866867701214, 'Total loss': 0.40940866867701214} | train loss {'Reaction outcome loss': 0.36102146514947864, 'Total loss': 0.36102146514947864}
2023-01-04 06:34:58,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:34:58,881 INFO:     Epoch: 48
2023-01-04 06:35:00,446 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3921522835890452, 'Total loss': 0.3921522835890452} | train loss {'Reaction outcome loss': 0.3460335919589852, 'Total loss': 0.3460335919589852}
2023-01-04 06:35:00,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:00,446 INFO:     Epoch: 49
2023-01-04 06:35:01,981 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39580769340197247, 'Total loss': 0.39580769340197247} | train loss {'Reaction outcome loss': 0.338532734554315, 'Total loss': 0.338532734554315}
2023-01-04 06:35:01,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:01,981 INFO:     Epoch: 50
2023-01-04 06:35:03,570 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4030369738737742, 'Total loss': 0.4030369738737742} | train loss {'Reaction outcome loss': 0.3462017473171674, 'Total loss': 0.3462017473171674}
2023-01-04 06:35:03,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:03,570 INFO:     Epoch: 51
2023-01-04 06:35:05,204 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3867500980695089, 'Total loss': 0.3867500980695089} | train loss {'Reaction outcome loss': 0.32671207522777707, 'Total loss': 0.32671207522777707}
2023-01-04 06:35:05,204 INFO:     Found new best model at epoch 51
2023-01-04 06:35:05,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:05,205 INFO:     Epoch: 52
2023-01-04 06:35:06,830 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4085727284351985, 'Total loss': 0.4085727284351985} | train loss {'Reaction outcome loss': 0.32759564559555787, 'Total loss': 0.32759564559555787}
2023-01-04 06:35:06,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:06,830 INFO:     Epoch: 53
2023-01-04 06:35:08,130 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39291154642899834, 'Total loss': 0.39291154642899834} | train loss {'Reaction outcome loss': 0.32894775389286224, 'Total loss': 0.32894775389286224}
2023-01-04 06:35:08,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:08,130 INFO:     Epoch: 54
2023-01-04 06:35:09,158 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39231883486111957, 'Total loss': 0.39231883486111957} | train loss {'Reaction outcome loss': 0.32663942495549936, 'Total loss': 0.32663942495549936}
2023-01-04 06:35:09,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:09,158 INFO:     Epoch: 55
2023-01-04 06:35:10,178 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41409486134847007, 'Total loss': 0.41409486134847007} | train loss {'Reaction outcome loss': 0.32985711879218405, 'Total loss': 0.32985711879218405}
2023-01-04 06:35:10,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:10,178 INFO:     Epoch: 56
2023-01-04 06:35:11,199 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43491070767243706, 'Total loss': 0.43491070767243706} | train loss {'Reaction outcome loss': 0.32279718101473415, 'Total loss': 0.32279718101473415}
2023-01-04 06:35:11,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:11,199 INFO:     Epoch: 57
2023-01-04 06:35:12,252 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3803791026274363, 'Total loss': 0.3803791026274363} | train loss {'Reaction outcome loss': 0.31960876716935227, 'Total loss': 0.31960876716935227}
2023-01-04 06:35:12,253 INFO:     Found new best model at epoch 57
2023-01-04 06:35:12,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:12,253 INFO:     Epoch: 58
2023-01-04 06:35:13,861 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42111963828404747, 'Total loss': 0.42111963828404747} | train loss {'Reaction outcome loss': 0.3209931203096673, 'Total loss': 0.3209931203096673}
2023-01-04 06:35:13,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:13,862 INFO:     Epoch: 59
2023-01-04 06:35:15,485 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40108635326226555, 'Total loss': 0.40108635326226555} | train loss {'Reaction outcome loss': 0.3266354723415081, 'Total loss': 0.3266354723415081}
2023-01-04 06:35:15,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:15,485 INFO:     Epoch: 60
2023-01-04 06:35:17,081 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38455090721448265, 'Total loss': 0.38455090721448265} | train loss {'Reaction outcome loss': 0.31949496617459733, 'Total loss': 0.31949496617459733}
2023-01-04 06:35:17,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:17,081 INFO:     Epoch: 61
2023-01-04 06:35:18,714 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3909489909807841, 'Total loss': 0.3909489909807841} | train loss {'Reaction outcome loss': 0.32387681362097676, 'Total loss': 0.32387681362097676}
2023-01-04 06:35:18,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:18,714 INFO:     Epoch: 62
2023-01-04 06:35:20,323 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4251846839984258, 'Total loss': 0.4251846839984258} | train loss {'Reaction outcome loss': 0.3455485660781868, 'Total loss': 0.3455485660781868}
2023-01-04 06:35:20,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:20,324 INFO:     Epoch: 63
2023-01-04 06:35:21,896 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4226211051146189, 'Total loss': 0.4226211051146189} | train loss {'Reaction outcome loss': 0.32478503248505836, 'Total loss': 0.32478503248505836}
2023-01-04 06:35:21,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:21,897 INFO:     Epoch: 64
2023-01-04 06:35:23,490 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4124268054962158, 'Total loss': 0.4124268054962158} | train loss {'Reaction outcome loss': 0.3408216908304156, 'Total loss': 0.3408216908304156}
2023-01-04 06:35:23,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:23,490 INFO:     Epoch: 65
2023-01-04 06:35:25,057 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41278230051199594, 'Total loss': 0.41278230051199594} | train loss {'Reaction outcome loss': 0.3561168052121133, 'Total loss': 0.3561168052121133}
2023-01-04 06:35:25,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:25,058 INFO:     Epoch: 66
2023-01-04 06:35:26,621 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4324218422174454, 'Total loss': 0.4324218422174454} | train loss {'Reaction outcome loss': 0.3083904713722945, 'Total loss': 0.3083904713722945}
2023-01-04 06:35:26,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:26,622 INFO:     Epoch: 67
2023-01-04 06:35:28,202 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38126472135384876, 'Total loss': 0.38126472135384876} | train loss {'Reaction outcome loss': 0.3019088698092146, 'Total loss': 0.3019088698092146}
2023-01-04 06:35:28,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:28,202 INFO:     Epoch: 68
2023-01-04 06:35:29,769 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3802832265694936, 'Total loss': 0.3802832265694936} | train loss {'Reaction outcome loss': 0.297978131853017, 'Total loss': 0.297978131853017}
2023-01-04 06:35:29,769 INFO:     Found new best model at epoch 68
2023-01-04 06:35:29,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:29,770 INFO:     Epoch: 69
2023-01-04 06:35:31,305 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3886525789896647, 'Total loss': 0.3886525789896647} | train loss {'Reaction outcome loss': 0.29876651387219655, 'Total loss': 0.29876651387219655}
2023-01-04 06:35:31,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:31,305 INFO:     Epoch: 70
2023-01-04 06:35:32,894 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40069568157196045, 'Total loss': 0.40069568157196045} | train loss {'Reaction outcome loss': 0.29884267742813064, 'Total loss': 0.29884267742813064}
2023-01-04 06:35:32,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:32,895 INFO:     Epoch: 71
2023-01-04 06:35:34,442 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42920817534128824, 'Total loss': 0.42920817534128824} | train loss {'Reaction outcome loss': 0.2945998682880072, 'Total loss': 0.2945998682880072}
2023-01-04 06:35:34,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:34,443 INFO:     Epoch: 72
2023-01-04 06:35:36,030 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3907793750365575, 'Total loss': 0.3907793750365575} | train loss {'Reaction outcome loss': 0.29860770331878733, 'Total loss': 0.29860770331878733}
2023-01-04 06:35:36,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:36,030 INFO:     Epoch: 73
2023-01-04 06:35:37,611 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4003169387578964, 'Total loss': 0.4003169387578964} | train loss {'Reaction outcome loss': 0.29144084310430934, 'Total loss': 0.29144084310430934}
2023-01-04 06:35:37,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:37,612 INFO:     Epoch: 74
2023-01-04 06:35:39,189 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4057812253634135, 'Total loss': 0.4057812253634135} | train loss {'Reaction outcome loss': 0.291665423081081, 'Total loss': 0.291665423081081}
2023-01-04 06:35:39,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:39,189 INFO:     Epoch: 75
2023-01-04 06:35:40,749 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4103638192017873, 'Total loss': 0.4103638192017873} | train loss {'Reaction outcome loss': 0.3017036840724556, 'Total loss': 0.3017036840724556}
2023-01-04 06:35:40,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:40,749 INFO:     Epoch: 76
2023-01-04 06:35:42,333 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38581404785315193, 'Total loss': 0.38581404785315193} | train loss {'Reaction outcome loss': 0.2892181843448455, 'Total loss': 0.2892181843448455}
2023-01-04 06:35:42,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:42,334 INFO:     Epoch: 77
2023-01-04 06:35:43,902 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40214201211929324, 'Total loss': 0.40214201211929324} | train loss {'Reaction outcome loss': 0.2865646938992448, 'Total loss': 0.2865646938992448}
2023-01-04 06:35:43,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:43,902 INFO:     Epoch: 78
2023-01-04 06:35:45,469 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4132870674133301, 'Total loss': 0.4132870674133301} | train loss {'Reaction outcome loss': 0.28626206124697445, 'Total loss': 0.28626206124697445}
2023-01-04 06:35:45,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:45,470 INFO:     Epoch: 79
2023-01-04 06:35:47,057 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3952419000367324, 'Total loss': 0.3952419000367324} | train loss {'Reaction outcome loss': 0.28581490721283614, 'Total loss': 0.28581490721283614}
2023-01-04 06:35:47,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:47,058 INFO:     Epoch: 80
2023-01-04 06:35:48,661 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39159813274939853, 'Total loss': 0.39159813274939853} | train loss {'Reaction outcome loss': 0.28872483631140855, 'Total loss': 0.28872483631140855}
2023-01-04 06:35:48,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:48,661 INFO:     Epoch: 81
2023-01-04 06:35:50,203 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38526910146077475, 'Total loss': 0.38526910146077475} | train loss {'Reaction outcome loss': 0.2877013418795853, 'Total loss': 0.2877013418795853}
2023-01-04 06:35:50,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:50,203 INFO:     Epoch: 82
2023-01-04 06:35:51,766 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4121392657359441, 'Total loss': 0.4121392657359441} | train loss {'Reaction outcome loss': 0.2854091060226378, 'Total loss': 0.2854091060226378}
2023-01-04 06:35:51,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:51,767 INFO:     Epoch: 83
2023-01-04 06:35:53,317 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42896885275840757, 'Total loss': 0.42896885275840757} | train loss {'Reaction outcome loss': 0.2916989754817948, 'Total loss': 0.2916989754817948}
2023-01-04 06:35:53,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:53,317 INFO:     Epoch: 84
2023-01-04 06:35:54,879 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40435329377651213, 'Total loss': 0.40435329377651213} | train loss {'Reaction outcome loss': 0.28664885204088403, 'Total loss': 0.28664885204088403}
2023-01-04 06:35:54,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:54,880 INFO:     Epoch: 85
2023-01-04 06:35:56,439 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.397653262813886, 'Total loss': 0.397653262813886} | train loss {'Reaction outcome loss': 0.2787475699244327, 'Total loss': 0.2787475699244327}
2023-01-04 06:35:56,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:56,439 INFO:     Epoch: 86
2023-01-04 06:35:58,003 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4573525180419286, 'Total loss': 0.4573525180419286} | train loss {'Reaction outcome loss': 0.2790552917395489, 'Total loss': 0.2790552917395489}
2023-01-04 06:35:58,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:58,004 INFO:     Epoch: 87
2023-01-04 06:35:59,547 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.404166167974472, 'Total loss': 0.404166167974472} | train loss {'Reaction outcome loss': 0.2793557481175715, 'Total loss': 0.2793557481175715}
2023-01-04 06:35:59,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:35:59,547 INFO:     Epoch: 88
2023-01-04 06:36:01,107 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4093914538621902, 'Total loss': 0.4093914538621902} | train loss {'Reaction outcome loss': 0.2738430330907737, 'Total loss': 0.2738430330907737}
2023-01-04 06:36:01,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:01,107 INFO:     Epoch: 89
2023-01-04 06:36:02,638 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45845429052909215, 'Total loss': 0.45845429052909215} | train loss {'Reaction outcome loss': 0.2776062972972294, 'Total loss': 0.2776062972972294}
2023-01-04 06:36:02,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:02,638 INFO:     Epoch: 90
2023-01-04 06:36:04,187 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4210000197092692, 'Total loss': 0.4210000197092692} | train loss {'Reaction outcome loss': 0.27802208370691084, 'Total loss': 0.27802208370691084}
2023-01-04 06:36:04,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:04,188 INFO:     Epoch: 91
2023-01-04 06:36:05,762 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4115256945292155, 'Total loss': 0.4115256945292155} | train loss {'Reaction outcome loss': 0.2721011681192001, 'Total loss': 0.2721011681192001}
2023-01-04 06:36:05,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:05,763 INFO:     Epoch: 92
2023-01-04 06:36:07,320 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3898256282011668, 'Total loss': 0.3898256282011668} | train loss {'Reaction outcome loss': 0.27119998022182856, 'Total loss': 0.27119998022182856}
2023-01-04 06:36:07,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:07,320 INFO:     Epoch: 93
2023-01-04 06:36:08,847 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4008795440196991, 'Total loss': 0.4008795440196991} | train loss {'Reaction outcome loss': 0.2713715257561779, 'Total loss': 0.2713715257561779}
2023-01-04 06:36:08,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:08,847 INFO:     Epoch: 94
2023-01-04 06:36:10,423 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37458957036336266, 'Total loss': 0.37458957036336266} | train loss {'Reaction outcome loss': 0.27343458118506847, 'Total loss': 0.27343458118506847}
2023-01-04 06:36:10,423 INFO:     Found new best model at epoch 94
2023-01-04 06:36:10,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:10,424 INFO:     Epoch: 95
2023-01-04 06:36:11,990 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4048329571882884, 'Total loss': 0.4048329571882884} | train loss {'Reaction outcome loss': 0.2740929258339431, 'Total loss': 0.2740929258339431}
2023-01-04 06:36:11,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:11,990 INFO:     Epoch: 96
2023-01-04 06:36:13,575 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43235615094502766, 'Total loss': 0.43235615094502766} | train loss {'Reaction outcome loss': 0.2857236923595917, 'Total loss': 0.2857236923595917}
2023-01-04 06:36:13,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:13,575 INFO:     Epoch: 97
2023-01-04 06:36:15,165 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4205629567305247, 'Total loss': 0.4205629567305247} | train loss {'Reaction outcome loss': 0.2710804859867705, 'Total loss': 0.2710804859867705}
2023-01-04 06:36:15,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:15,165 INFO:     Epoch: 98
2023-01-04 06:36:16,698 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.412430148323377, 'Total loss': 0.412430148323377} | train loss {'Reaction outcome loss': 0.2689505578339289, 'Total loss': 0.2689505578339289}
2023-01-04 06:36:16,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:16,699 INFO:     Epoch: 99
2023-01-04 06:36:18,246 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41936417669057846, 'Total loss': 0.41936417669057846} | train loss {'Reaction outcome loss': 0.26564384192444274, 'Total loss': 0.26564384192444274}
2023-01-04 06:36:18,246 INFO:     Best model found after epoch 95 of 100.
2023-01-04 06:36:18,246 INFO:   Done with stage: TRAINING
2023-01-04 06:36:18,246 INFO:   Starting stage: EVALUATION
2023-01-04 06:36:18,373 INFO:   Done with stage: EVALUATION
2023-01-04 06:36:18,373 INFO:   Leaving out SEQ value Fold_3
2023-01-04 06:36:18,386 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 06:36:18,386 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:36:19,020 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:36:19,020 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:36:19,089 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:36:19,089 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:36:19,089 INFO:     No hyperparam tuning for this model
2023-01-04 06:36:19,089 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:36:19,089 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:36:19,090 INFO:     None feature selector for col prot
2023-01-04 06:36:19,090 INFO:     None feature selector for col prot
2023-01-04 06:36:19,090 INFO:     None feature selector for col prot
2023-01-04 06:36:19,091 INFO:     None feature selector for col chem
2023-01-04 06:36:19,091 INFO:     None feature selector for col chem
2023-01-04 06:36:19,091 INFO:     None feature selector for col chem
2023-01-04 06:36:19,091 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:36:19,091 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:36:19,092 INFO:     Number of params in model 70111
2023-01-04 06:36:19,095 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:36:19,095 INFO:   Starting stage: TRAINING
2023-01-04 06:36:19,135 INFO:     Val loss before train {'Reaction outcome loss': 1.1032395799954733, 'Total loss': 1.1032395799954733}
2023-01-04 06:36:19,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:19,135 INFO:     Epoch: 0
2023-01-04 06:36:20,677 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7764889617760976, 'Total loss': 0.7764889617760976} | train loss {'Reaction outcome loss': 0.828857727649011, 'Total loss': 0.828857727649011}
2023-01-04 06:36:20,677 INFO:     Found new best model at epoch 0
2023-01-04 06:36:20,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:20,678 INFO:     Epoch: 1
2023-01-04 06:36:22,250 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6622499763965607, 'Total loss': 0.6622499763965607} | train loss {'Reaction outcome loss': 0.6782184188619201, 'Total loss': 0.6782184188619201}
2023-01-04 06:36:22,250 INFO:     Found new best model at epoch 1
2023-01-04 06:36:22,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:22,251 INFO:     Epoch: 2
2023-01-04 06:36:23,790 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5746685922145843, 'Total loss': 0.5746685922145843} | train loss {'Reaction outcome loss': 0.5900580181088639, 'Total loss': 0.5900580181088639}
2023-01-04 06:36:23,791 INFO:     Found new best model at epoch 2
2023-01-04 06:36:23,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:23,792 INFO:     Epoch: 3
2023-01-04 06:36:25,313 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5418430765469869, 'Total loss': 0.5418430765469869} | train loss {'Reaction outcome loss': 0.5432195418374443, 'Total loss': 0.5432195418374443}
2023-01-04 06:36:25,314 INFO:     Found new best model at epoch 3
2023-01-04 06:36:25,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:25,314 INFO:     Epoch: 4
2023-01-04 06:36:26,850 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5348299702008565, 'Total loss': 0.5348299702008565} | train loss {'Reaction outcome loss': 0.5144344092288733, 'Total loss': 0.5144344092288733}
2023-01-04 06:36:26,850 INFO:     Found new best model at epoch 4
2023-01-04 06:36:26,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:26,851 INFO:     Epoch: 5
2023-01-04 06:36:28,346 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5262145429849625, 'Total loss': 0.5262145429849625} | train loss {'Reaction outcome loss': 0.5006705307207264, 'Total loss': 0.5006705307207264}
2023-01-04 06:36:28,346 INFO:     Found new best model at epoch 5
2023-01-04 06:36:28,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:28,347 INFO:     Epoch: 6
2023-01-04 06:36:29,906 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5106683204571406, 'Total loss': 0.5106683204571406} | train loss {'Reaction outcome loss': 0.48784002596205406, 'Total loss': 0.48784002596205406}
2023-01-04 06:36:29,906 INFO:     Found new best model at epoch 6
2023-01-04 06:36:29,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:29,907 INFO:     Epoch: 7
2023-01-04 06:36:31,463 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5088175892829895, 'Total loss': 0.5088175892829895} | train loss {'Reaction outcome loss': 0.47940434215269684, 'Total loss': 0.47940434215269684}
2023-01-04 06:36:31,463 INFO:     Found new best model at epoch 7
2023-01-04 06:36:31,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:31,464 INFO:     Epoch: 8
2023-01-04 06:36:33,030 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5015241821606954, 'Total loss': 0.5015241821606954} | train loss {'Reaction outcome loss': 0.468236505603179, 'Total loss': 0.468236505603179}
2023-01-04 06:36:33,030 INFO:     Found new best model at epoch 8
2023-01-04 06:36:33,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:33,031 INFO:     Epoch: 9
2023-01-04 06:36:34,543 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5047453780968983, 'Total loss': 0.5047453780968983} | train loss {'Reaction outcome loss': 0.46059636586096697, 'Total loss': 0.46059636586096697}
2023-01-04 06:36:34,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:34,543 INFO:     Epoch: 10
2023-01-04 06:36:36,097 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.511403210957845, 'Total loss': 0.511403210957845} | train loss {'Reaction outcome loss': 0.45263470933114214, 'Total loss': 0.45263470933114214}
2023-01-04 06:36:36,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:36,098 INFO:     Epoch: 11
2023-01-04 06:36:37,619 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5022609313329061, 'Total loss': 0.5022609313329061} | train loss {'Reaction outcome loss': 0.4485401205663934, 'Total loss': 0.4485401205663934}
2023-01-04 06:36:37,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:37,619 INFO:     Epoch: 12
2023-01-04 06:36:39,142 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47447613974412284, 'Total loss': 0.47447613974412284} | train loss {'Reaction outcome loss': 0.44661354319953217, 'Total loss': 0.44661354319953217}
2023-01-04 06:36:39,143 INFO:     Found new best model at epoch 12
2023-01-04 06:36:39,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:39,143 INFO:     Epoch: 13
2023-01-04 06:36:40,692 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4806970715522766, 'Total loss': 0.4806970715522766} | train loss {'Reaction outcome loss': 0.4391486642561553, 'Total loss': 0.4391486642561553}
2023-01-04 06:36:40,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:40,693 INFO:     Epoch: 14
2023-01-04 06:36:42,235 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4863761146863302, 'Total loss': 0.4863761146863302} | train loss {'Reaction outcome loss': 0.43068126288853287, 'Total loss': 0.43068126288853287}
2023-01-04 06:36:42,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:42,235 INFO:     Epoch: 15
2023-01-04 06:36:43,753 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48964822888374326, 'Total loss': 0.48964822888374326} | train loss {'Reaction outcome loss': 0.4296250262266987, 'Total loss': 0.4296250262266987}
2023-01-04 06:36:43,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:43,753 INFO:     Epoch: 16
2023-01-04 06:36:45,323 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4765025059382121, 'Total loss': 0.4765025059382121} | train loss {'Reaction outcome loss': 0.42291538471922335, 'Total loss': 0.42291538471922335}
2023-01-04 06:36:45,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:45,324 INFO:     Epoch: 17
2023-01-04 06:36:46,819 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44314868478104474, 'Total loss': 0.44314868478104474} | train loss {'Reaction outcome loss': 0.42137367594918923, 'Total loss': 0.42137367594918923}
2023-01-04 06:36:46,820 INFO:     Found new best model at epoch 17
2023-01-04 06:36:46,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:46,821 INFO:     Epoch: 18
2023-01-04 06:36:48,387 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44159113665421806, 'Total loss': 0.44159113665421806} | train loss {'Reaction outcome loss': 0.41062628556957176, 'Total loss': 0.41062628556957176}
2023-01-04 06:36:48,387 INFO:     Found new best model at epoch 18
2023-01-04 06:36:48,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:48,388 INFO:     Epoch: 19
2023-01-04 06:36:49,933 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4609092732270559, 'Total loss': 0.4609092732270559} | train loss {'Reaction outcome loss': 0.4037836026059184, 'Total loss': 0.4037836026059184}
2023-01-04 06:36:49,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:49,933 INFO:     Epoch: 20
2023-01-04 06:36:51,468 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.451875638961792, 'Total loss': 0.451875638961792} | train loss {'Reaction outcome loss': 0.4034683885045977, 'Total loss': 0.4034683885045977}
2023-01-04 06:36:51,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:51,468 INFO:     Epoch: 21
2023-01-04 06:36:52,985 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44511883755524956, 'Total loss': 0.44511883755524956} | train loss {'Reaction outcome loss': 0.39836142191683854, 'Total loss': 0.39836142191683854}
2023-01-04 06:36:52,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:52,986 INFO:     Epoch: 22
2023-01-04 06:36:54,556 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4776693979899089, 'Total loss': 0.4776693979899089} | train loss {'Reaction outcome loss': 0.3960406070800273, 'Total loss': 0.3960406070800273}
2023-01-04 06:36:54,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:54,557 INFO:     Epoch: 23
2023-01-04 06:36:56,118 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4677366137504578, 'Total loss': 0.4677366137504578} | train loss {'Reaction outcome loss': 0.3885859982161732, 'Total loss': 0.3885859982161732}
2023-01-04 06:36:56,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:56,118 INFO:     Epoch: 24
2023-01-04 06:36:57,716 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4546432912349701, 'Total loss': 0.4546432912349701} | train loss {'Reaction outcome loss': 0.38540960455333795, 'Total loss': 0.38540960455333795}
2023-01-04 06:36:57,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:57,716 INFO:     Epoch: 25
2023-01-04 06:36:59,311 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45397559106349944, 'Total loss': 0.45397559106349944} | train loss {'Reaction outcome loss': 0.37588351116184787, 'Total loss': 0.37588351116184787}
2023-01-04 06:36:59,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:36:59,312 INFO:     Epoch: 26
2023-01-04 06:37:00,925 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46196626822153725, 'Total loss': 0.46196626822153725} | train loss {'Reaction outcome loss': 0.3753897094137066, 'Total loss': 0.3753897094137066}
2023-01-04 06:37:00,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:00,925 INFO:     Epoch: 27
2023-01-04 06:37:02,480 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46166263620058695, 'Total loss': 0.46166263620058695} | train loss {'Reaction outcome loss': 0.3705015679098147, 'Total loss': 0.3705015679098147}
2023-01-04 06:37:02,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:02,480 INFO:     Epoch: 28
2023-01-04 06:37:04,088 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43393517335255943, 'Total loss': 0.43393517335255943} | train loss {'Reaction outcome loss': 0.36829002114224346, 'Total loss': 0.36829002114224346}
2023-01-04 06:37:04,088 INFO:     Found new best model at epoch 28
2023-01-04 06:37:04,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:04,089 INFO:     Epoch: 29
2023-01-04 06:37:05,624 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4264736771583557, 'Total loss': 0.4264736771583557} | train loss {'Reaction outcome loss': 0.3662308480440479, 'Total loss': 0.3662308480440479}
2023-01-04 06:37:05,625 INFO:     Found new best model at epoch 29
2023-01-04 06:37:05,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:05,626 INFO:     Epoch: 30
2023-01-04 06:37:07,163 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4580863853295644, 'Total loss': 0.4580863853295644} | train loss {'Reaction outcome loss': 0.3587257167249372, 'Total loss': 0.3587257167249372}
2023-01-04 06:37:07,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:07,163 INFO:     Epoch: 31
2023-01-04 06:37:08,693 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4410864730676015, 'Total loss': 0.4410864730676015} | train loss {'Reaction outcome loss': 0.3548326990243061, 'Total loss': 0.3548326990243061}
2023-01-04 06:37:08,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:08,693 INFO:     Epoch: 32
2023-01-04 06:37:10,232 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5153664608796438, 'Total loss': 0.5153664608796438} | train loss {'Reaction outcome loss': 0.35857447848106044, 'Total loss': 0.35857447848106044}
2023-01-04 06:37:10,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:10,233 INFO:     Epoch: 33
2023-01-04 06:37:11,721 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4287234644095103, 'Total loss': 0.4287234644095103} | train loss {'Reaction outcome loss': 0.3520625272404143, 'Total loss': 0.3520625272404143}
2023-01-04 06:37:11,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:11,721 INFO:     Epoch: 34
2023-01-04 06:37:13,267 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4435893932978312, 'Total loss': 0.4435893932978312} | train loss {'Reaction outcome loss': 0.3477765615388151, 'Total loss': 0.3477765615388151}
2023-01-04 06:37:13,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:13,267 INFO:     Epoch: 35
2023-01-04 06:37:14,790 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4640640487273534, 'Total loss': 0.4640640487273534} | train loss {'Reaction outcome loss': 0.3493501238060958, 'Total loss': 0.3493501238060958}
2023-01-04 06:37:14,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:14,790 INFO:     Epoch: 36
2023-01-04 06:37:16,326 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43900301257769264, 'Total loss': 0.43900301257769264} | train loss {'Reaction outcome loss': 0.3446796913068373, 'Total loss': 0.3446796913068373}
2023-01-04 06:37:16,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:16,326 INFO:     Epoch: 37
2023-01-04 06:37:17,914 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4060388535261154, 'Total loss': 0.4060388535261154} | train loss {'Reaction outcome loss': 0.3383348556883606, 'Total loss': 0.3383348556883606}
2023-01-04 06:37:17,915 INFO:     Found new best model at epoch 37
2023-01-04 06:37:17,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:17,916 INFO:     Epoch: 38
2023-01-04 06:37:19,493 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42204897503058114, 'Total loss': 0.42204897503058114} | train loss {'Reaction outcome loss': 0.33755758797729407, 'Total loss': 0.33755758797729407}
2023-01-04 06:37:19,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:19,494 INFO:     Epoch: 39
2023-01-04 06:37:21,030 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.433106795946757, 'Total loss': 0.433106795946757} | train loss {'Reaction outcome loss': 0.3386067035488593, 'Total loss': 0.3386067035488593}
2023-01-04 06:37:21,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:21,031 INFO:     Epoch: 40
2023-01-04 06:37:22,577 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4586427976687749, 'Total loss': 0.4586427976687749} | train loss {'Reaction outcome loss': 0.33354851838214933, 'Total loss': 0.33354851838214933}
2023-01-04 06:37:22,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:22,577 INFO:     Epoch: 41
2023-01-04 06:37:24,104 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4562248051166534, 'Total loss': 0.4562248051166534} | train loss {'Reaction outcome loss': 0.32735803718559253, 'Total loss': 0.32735803718559253}
2023-01-04 06:37:24,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:24,105 INFO:     Epoch: 42
2023-01-04 06:37:25,665 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41097128291924795, 'Total loss': 0.41097128291924795} | train loss {'Reaction outcome loss': 0.3303271945388544, 'Total loss': 0.3303271945388544}
2023-01-04 06:37:25,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:25,666 INFO:     Epoch: 43
2023-01-04 06:37:27,240 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4647802452246348, 'Total loss': 0.4647802452246348} | train loss {'Reaction outcome loss': 0.32469965099960896, 'Total loss': 0.32469965099960896}
2023-01-04 06:37:27,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:27,240 INFO:     Epoch: 44
2023-01-04 06:37:28,783 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4075428212682406, 'Total loss': 0.4075428212682406} | train loss {'Reaction outcome loss': 0.3219709553288453, 'Total loss': 0.3219709553288453}
2023-01-04 06:37:28,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:28,783 INFO:     Epoch: 45
2023-01-04 06:37:30,329 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.411022158463796, 'Total loss': 0.411022158463796} | train loss {'Reaction outcome loss': 0.3204703891561145, 'Total loss': 0.3204703891561145}
2023-01-04 06:37:30,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:30,329 INFO:     Epoch: 46
2023-01-04 06:37:31,868 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42620163361231483, 'Total loss': 0.42620163361231483} | train loss {'Reaction outcome loss': 0.3190075881069615, 'Total loss': 0.3190075881069615}
2023-01-04 06:37:31,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:31,868 INFO:     Epoch: 47
2023-01-04 06:37:33,414 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41607473691304525, 'Total loss': 0.41607473691304525} | train loss {'Reaction outcome loss': 0.31945937848735206, 'Total loss': 0.31945937848735206}
2023-01-04 06:37:33,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:33,414 INFO:     Epoch: 48
2023-01-04 06:37:34,972 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4460083295901616, 'Total loss': 0.4460083295901616} | train loss {'Reaction outcome loss': 0.31242885877252063, 'Total loss': 0.31242885877252063}
2023-01-04 06:37:34,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:34,972 INFO:     Epoch: 49
2023-01-04 06:37:36,537 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42097364862759906, 'Total loss': 0.42097364862759906} | train loss {'Reaction outcome loss': 0.3153821344559009, 'Total loss': 0.3153821344559009}
2023-01-04 06:37:36,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:36,538 INFO:     Epoch: 50
2023-01-04 06:37:38,055 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42346277932326, 'Total loss': 0.42346277932326} | train loss {'Reaction outcome loss': 0.3135571892717819, 'Total loss': 0.3135571892717819}
2023-01-04 06:37:38,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:38,056 INFO:     Epoch: 51
2023-01-04 06:37:39,608 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4242294043302536, 'Total loss': 0.4242294043302536} | train loss {'Reaction outcome loss': 0.30501064292458824, 'Total loss': 0.30501064292458824}
2023-01-04 06:37:39,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:39,608 INFO:     Epoch: 52
2023-01-04 06:37:41,119 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3937176287174225, 'Total loss': 0.3937176287174225} | train loss {'Reaction outcome loss': 0.30418998376899586, 'Total loss': 0.30418998376899586}
2023-01-04 06:37:41,119 INFO:     Found new best model at epoch 52
2023-01-04 06:37:41,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:41,120 INFO:     Epoch: 53
2023-01-04 06:37:42,649 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46678374509016674, 'Total loss': 0.46678374509016674} | train loss {'Reaction outcome loss': 0.3038645271969202, 'Total loss': 0.3038645271969202}
2023-01-04 06:37:42,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:42,649 INFO:     Epoch: 54
2023-01-04 06:37:44,179 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46589695413907367, 'Total loss': 0.46589695413907367} | train loss {'Reaction outcome loss': 0.29892472341492937, 'Total loss': 0.29892472341492937}
2023-01-04 06:37:44,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:44,179 INFO:     Epoch: 55
2023-01-04 06:37:45,713 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4258337537447611, 'Total loss': 0.4258337537447611} | train loss {'Reaction outcome loss': 0.30150225418773324, 'Total loss': 0.30150225418773324}
2023-01-04 06:37:45,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:45,713 INFO:     Epoch: 56
2023-01-04 06:37:47,222 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41890741189320885, 'Total loss': 0.41890741189320885} | train loss {'Reaction outcome loss': 0.29981978447773516, 'Total loss': 0.29981978447773516}
2023-01-04 06:37:47,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:47,222 INFO:     Epoch: 57
2023-01-04 06:37:48,785 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4187557409207026, 'Total loss': 0.4187557409207026} | train loss {'Reaction outcome loss': 0.29703759325620455, 'Total loss': 0.29703759325620455}
2023-01-04 06:37:48,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:48,786 INFO:     Epoch: 58
2023-01-04 06:37:50,300 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40534375607967377, 'Total loss': 0.40534375607967377} | train loss {'Reaction outcome loss': 0.29889517478071725, 'Total loss': 0.29889517478071725}
2023-01-04 06:37:50,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:50,300 INFO:     Epoch: 59
2023-01-04 06:37:51,835 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4335235079129537, 'Total loss': 0.4335235079129537} | train loss {'Reaction outcome loss': 0.29499965554082785, 'Total loss': 0.29499965554082785}
2023-01-04 06:37:51,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:51,835 INFO:     Epoch: 60
2023-01-04 06:37:53,366 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42996345857779183, 'Total loss': 0.42996345857779183} | train loss {'Reaction outcome loss': 0.2946888132518901, 'Total loss': 0.2946888132518901}
2023-01-04 06:37:53,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:53,366 INFO:     Epoch: 61
2023-01-04 06:37:54,910 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4180249869823456, 'Total loss': 0.4180249869823456} | train loss {'Reaction outcome loss': 0.2926764666433736, 'Total loss': 0.2926764666433736}
2023-01-04 06:37:54,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:54,911 INFO:     Epoch: 62
2023-01-04 06:37:56,445 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42850350886583327, 'Total loss': 0.42850350886583327} | train loss {'Reaction outcome loss': 0.28386212994545806, 'Total loss': 0.28386212994545806}
2023-01-04 06:37:56,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:56,445 INFO:     Epoch: 63
2023-01-04 06:37:58,037 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.459190301100413, 'Total loss': 0.459190301100413} | train loss {'Reaction outcome loss': 0.28764913561361616, 'Total loss': 0.28764913561361616}
2023-01-04 06:37:58,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:58,038 INFO:     Epoch: 64
2023-01-04 06:37:59,578 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3907887111107508, 'Total loss': 0.3907887111107508} | train loss {'Reaction outcome loss': 0.2905069409218027, 'Total loss': 0.2905069409218027}
2023-01-04 06:37:59,578 INFO:     Found new best model at epoch 64
2023-01-04 06:37:59,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:37:59,579 INFO:     Epoch: 65
2023-01-04 06:38:01,169 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4009898285071055, 'Total loss': 0.4009898285071055} | train loss {'Reaction outcome loss': 0.2827249028798425, 'Total loss': 0.2827249028798425}
2023-01-04 06:38:01,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:01,170 INFO:     Epoch: 66
2023-01-04 06:38:02,729 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37974921812613804, 'Total loss': 0.37974921812613804} | train loss {'Reaction outcome loss': 0.28704081795045305, 'Total loss': 0.28704081795045305}
2023-01-04 06:38:02,729 INFO:     Found new best model at epoch 66
2023-01-04 06:38:02,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:02,730 INFO:     Epoch: 67
2023-01-04 06:38:04,284 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41910245617230735, 'Total loss': 0.41910245617230735} | train loss {'Reaction outcome loss': 0.2810366555720895, 'Total loss': 0.2810366555720895}
2023-01-04 06:38:04,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:04,284 INFO:     Epoch: 68
2023-01-04 06:38:05,818 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42733031113942466, 'Total loss': 0.42733031113942466} | train loss {'Reaction outcome loss': 0.2844779031835633, 'Total loss': 0.2844779031835633}
2023-01-04 06:38:05,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:05,818 INFO:     Epoch: 69
2023-01-04 06:38:07,412 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4123797674973806, 'Total loss': 0.4123797674973806} | train loss {'Reaction outcome loss': 0.27978935804995864, 'Total loss': 0.27978935804995864}
2023-01-04 06:38:07,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:07,413 INFO:     Epoch: 70
2023-01-04 06:38:08,974 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4343644181887309, 'Total loss': 0.4343644181887309} | train loss {'Reaction outcome loss': 0.2765205487090371, 'Total loss': 0.2765205487090371}
2023-01-04 06:38:08,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:08,975 INFO:     Epoch: 71
2023-01-04 06:38:10,539 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44211271504561106, 'Total loss': 0.44211271504561106} | train loss {'Reaction outcome loss': 0.2733699202865035, 'Total loss': 0.2733699202865035}
2023-01-04 06:38:10,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:10,539 INFO:     Epoch: 72
2023-01-04 06:38:12,104 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4319429059823354, 'Total loss': 0.4319429059823354} | train loss {'Reaction outcome loss': 0.27436249594002854, 'Total loss': 0.27436249594002854}
2023-01-04 06:38:12,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:12,105 INFO:     Epoch: 73
2023-01-04 06:38:13,685 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4152059505383174, 'Total loss': 0.4152059505383174} | train loss {'Reaction outcome loss': 0.2755452229098959, 'Total loss': 0.2755452229098959}
2023-01-04 06:38:13,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:13,685 INFO:     Epoch: 74
2023-01-04 06:38:15,219 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40784406463305156, 'Total loss': 0.40784406463305156} | train loss {'Reaction outcome loss': 0.27601099345874003, 'Total loss': 0.27601099345874003}
2023-01-04 06:38:15,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:15,220 INFO:     Epoch: 75
2023-01-04 06:38:16,771 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4150932232538859, 'Total loss': 0.4150932232538859} | train loss {'Reaction outcome loss': 0.2796408417378808, 'Total loss': 0.2796408417378808}
2023-01-04 06:38:16,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:16,771 INFO:     Epoch: 76
2023-01-04 06:38:18,293 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42286155819892884, 'Total loss': 0.42286155819892884} | train loss {'Reaction outcome loss': 0.2737099902752118, 'Total loss': 0.2737099902752118}
2023-01-04 06:38:18,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:18,293 INFO:     Epoch: 77
2023-01-04 06:38:19,849 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46906992395718894, 'Total loss': 0.46906992395718894} | train loss {'Reaction outcome loss': 0.27343924959009386, 'Total loss': 0.27343924959009386}
2023-01-04 06:38:19,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:19,850 INFO:     Epoch: 78
2023-01-04 06:38:21,402 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48448136150836946, 'Total loss': 0.48448136150836946} | train loss {'Reaction outcome loss': 0.26578742621173135, 'Total loss': 0.26578742621173135}
2023-01-04 06:38:21,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:21,402 INFO:     Epoch: 79
2023-01-04 06:38:22,954 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4533370832602183, 'Total loss': 0.4533370832602183} | train loss {'Reaction outcome loss': 0.2661883035476828, 'Total loss': 0.2661883035476828}
2023-01-04 06:38:22,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:22,954 INFO:     Epoch: 80
2023-01-04 06:38:24,472 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4333302249511083, 'Total loss': 0.4333302249511083} | train loss {'Reaction outcome loss': 0.2722176405918467, 'Total loss': 0.2722176405918467}
2023-01-04 06:38:24,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:24,472 INFO:     Epoch: 81
2023-01-04 06:38:26,009 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41798983216285707, 'Total loss': 0.41798983216285707} | train loss {'Reaction outcome loss': 0.27359805097837586, 'Total loss': 0.27359805097837586}
2023-01-04 06:38:26,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:26,010 INFO:     Epoch: 82
2023-01-04 06:38:27,547 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41438958545525867, 'Total loss': 0.41438958545525867} | train loss {'Reaction outcome loss': 0.2614525386811176, 'Total loss': 0.2614525386811176}
2023-01-04 06:38:27,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:27,547 INFO:     Epoch: 83
2023-01-04 06:38:29,123 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4090444813172022, 'Total loss': 0.4090444813172022} | train loss {'Reaction outcome loss': 0.26459620123381145, 'Total loss': 0.26459620123381145}
2023-01-04 06:38:29,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:29,123 INFO:     Epoch: 84
2023-01-04 06:38:30,719 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3997345189253489, 'Total loss': 0.3997345189253489} | train loss {'Reaction outcome loss': 0.26095206847230157, 'Total loss': 0.26095206847230157}
2023-01-04 06:38:30,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:30,719 INFO:     Epoch: 85
2023-01-04 06:38:32,318 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39926445682843525, 'Total loss': 0.39926445682843525} | train loss {'Reaction outcome loss': 0.26488731520407366, 'Total loss': 0.26488731520407366}
2023-01-04 06:38:32,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:32,318 INFO:     Epoch: 86
2023-01-04 06:38:33,850 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4161505748828252, 'Total loss': 0.4161505748828252} | train loss {'Reaction outcome loss': 0.2624294134505066, 'Total loss': 0.2624294134505066}
2023-01-04 06:38:33,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:33,850 INFO:     Epoch: 87
2023-01-04 06:38:35,428 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41683535973230995, 'Total loss': 0.41683535973230995} | train loss {'Reaction outcome loss': 0.25838677219418815, 'Total loss': 0.25838677219418815}
2023-01-04 06:38:35,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:35,429 INFO:     Epoch: 88
2023-01-04 06:38:37,005 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43586043318112694, 'Total loss': 0.43586043318112694} | train loss {'Reaction outcome loss': 0.26017557246262557, 'Total loss': 0.26017557246262557}
2023-01-04 06:38:37,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:37,005 INFO:     Epoch: 89
2023-01-04 06:38:38,590 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4056945820649465, 'Total loss': 0.4056945820649465} | train loss {'Reaction outcome loss': 0.2572275826625608, 'Total loss': 0.2572275826625608}
2023-01-04 06:38:38,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:38,591 INFO:     Epoch: 90
2023-01-04 06:38:40,157 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3899691204229991, 'Total loss': 0.3899691204229991} | train loss {'Reaction outcome loss': 0.2560414780654532, 'Total loss': 0.2560414780654532}
2023-01-04 06:38:40,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:40,157 INFO:     Epoch: 91
2023-01-04 06:38:41,684 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4085833678642909, 'Total loss': 0.4085833678642909} | train loss {'Reaction outcome loss': 0.2554470458965162, 'Total loss': 0.2554470458965162}
2023-01-04 06:38:41,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:41,684 INFO:     Epoch: 92
2023-01-04 06:38:43,254 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41281742056210835, 'Total loss': 0.41281742056210835} | train loss {'Reaction outcome loss': 0.2545945833508785, 'Total loss': 0.2545945833508785}
2023-01-04 06:38:43,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:43,254 INFO:     Epoch: 93
2023-01-04 06:38:44,785 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4456003059943517, 'Total loss': 0.4456003059943517} | train loss {'Reaction outcome loss': 0.257904477144554, 'Total loss': 0.257904477144554}
2023-01-04 06:38:44,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:44,785 INFO:     Epoch: 94
2023-01-04 06:38:46,349 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41997580726941425, 'Total loss': 0.41997580726941425} | train loss {'Reaction outcome loss': 0.2576368292827746, 'Total loss': 0.2576368292827746}
2023-01-04 06:38:46,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:46,349 INFO:     Epoch: 95
2023-01-04 06:38:47,909 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42984041819969815, 'Total loss': 0.42984041819969815} | train loss {'Reaction outcome loss': 0.2480097790333978, 'Total loss': 0.2480097790333978}
2023-01-04 06:38:47,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:47,910 INFO:     Epoch: 96
2023-01-04 06:38:49,470 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42284235954284666, 'Total loss': 0.42284235954284666} | train loss {'Reaction outcome loss': 0.2492095125845937, 'Total loss': 0.2492095125845937}
2023-01-04 06:38:49,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:49,471 INFO:     Epoch: 97
2023-01-04 06:38:50,988 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4274923543135325, 'Total loss': 0.4274923543135325} | train loss {'Reaction outcome loss': 0.25077588381348076, 'Total loss': 0.25077588381348076}
2023-01-04 06:38:50,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:50,988 INFO:     Epoch: 98
2023-01-04 06:38:52,538 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42984163264433545, 'Total loss': 0.42984163264433545} | train loss {'Reaction outcome loss': 0.2502660629844409, 'Total loss': 0.2502660629844409}
2023-01-04 06:38:52,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:52,538 INFO:     Epoch: 99
2023-01-04 06:38:54,054 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38236937671899796, 'Total loss': 0.38236937671899796} | train loss {'Reaction outcome loss': 0.25244000524064125, 'Total loss': 0.25244000524064125}
2023-01-04 06:38:54,054 INFO:     Best model found after epoch 67 of 100.
2023-01-04 06:38:54,054 INFO:   Done with stage: TRAINING
2023-01-04 06:38:54,054 INFO:   Starting stage: EVALUATION
2023-01-04 06:38:54,195 INFO:   Done with stage: EVALUATION
2023-01-04 06:38:54,195 INFO:   Leaving out SEQ value Fold_4
2023-01-04 06:38:54,207 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 06:38:54,207 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:38:54,870 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:38:54,871 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:38:54,941 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:38:54,941 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:38:54,941 INFO:     No hyperparam tuning for this model
2023-01-04 06:38:54,942 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:38:54,942 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:38:54,942 INFO:     None feature selector for col prot
2023-01-04 06:38:54,942 INFO:     None feature selector for col prot
2023-01-04 06:38:54,943 INFO:     None feature selector for col prot
2023-01-04 06:38:54,943 INFO:     None feature selector for col chem
2023-01-04 06:38:54,943 INFO:     None feature selector for col chem
2023-01-04 06:38:54,943 INFO:     None feature selector for col chem
2023-01-04 06:38:54,943 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:38:54,943 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:38:54,944 INFO:     Number of params in model 70111
2023-01-04 06:38:54,947 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:38:54,947 INFO:   Starting stage: TRAINING
2023-01-04 06:38:54,990 INFO:     Val loss before train {'Reaction outcome loss': 1.0819790840148926, 'Total loss': 1.0819790840148926}
2023-01-04 06:38:54,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:54,991 INFO:     Epoch: 0
2023-01-04 06:38:56,573 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7563038468360901, 'Total loss': 0.7563038468360901} | train loss {'Reaction outcome loss': 0.8388539671037172, 'Total loss': 0.8388539671037172}
2023-01-04 06:38:56,574 INFO:     Found new best model at epoch 0
2023-01-04 06:38:56,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:56,574 INFO:     Epoch: 1
2023-01-04 06:38:58,152 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.616472617785136, 'Total loss': 0.616472617785136} | train loss {'Reaction outcome loss': 0.6639750925857668, 'Total loss': 0.6639750925857668}
2023-01-04 06:38:58,152 INFO:     Found new best model at epoch 1
2023-01-04 06:38:58,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:58,153 INFO:     Epoch: 2
2023-01-04 06:38:59,698 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5864677925904592, 'Total loss': 0.5864677925904592} | train loss {'Reaction outcome loss': 0.5761433689172517, 'Total loss': 0.5761433689172517}
2023-01-04 06:38:59,698 INFO:     Found new best model at epoch 2
2023-01-04 06:38:59,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:38:59,699 INFO:     Epoch: 3
2023-01-04 06:39:01,268 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5421370605627696, 'Total loss': 0.5421370605627696} | train loss {'Reaction outcome loss': 0.5391390395723956, 'Total loss': 0.5391390395723956}
2023-01-04 06:39:01,269 INFO:     Found new best model at epoch 3
2023-01-04 06:39:01,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:01,270 INFO:     Epoch: 4
2023-01-04 06:39:02,788 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5343963861465454, 'Total loss': 0.5343963861465454} | train loss {'Reaction outcome loss': 0.5175631895715149, 'Total loss': 0.5175631895715149}
2023-01-04 06:39:02,788 INFO:     Found new best model at epoch 4
2023-01-04 06:39:02,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:02,789 INFO:     Epoch: 5
2023-01-04 06:39:04,331 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5256238996982574, 'Total loss': 0.5256238996982574} | train loss {'Reaction outcome loss': 0.4996047371238578, 'Total loss': 0.4996047371238578}
2023-01-04 06:39:04,331 INFO:     Found new best model at epoch 5
2023-01-04 06:39:04,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:04,332 INFO:     Epoch: 6
2023-01-04 06:39:05,879 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5391799092292786, 'Total loss': 0.5391799092292786} | train loss {'Reaction outcome loss': 0.4933010841642476, 'Total loss': 0.4933010841642476}
2023-01-04 06:39:05,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:05,879 INFO:     Epoch: 7
2023-01-04 06:39:07,426 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5134870906670889, 'Total loss': 0.5134870906670889} | train loss {'Reaction outcome loss': 0.48522105000724863, 'Total loss': 0.48522105000724863}
2023-01-04 06:39:07,426 INFO:     Found new best model at epoch 7
2023-01-04 06:39:07,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:07,427 INFO:     Epoch: 8
2023-01-04 06:39:08,940 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5348816374937694, 'Total loss': 0.5348816374937694} | train loss {'Reaction outcome loss': 0.4765786481247912, 'Total loss': 0.4765786481247912}
2023-01-04 06:39:08,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:08,940 INFO:     Epoch: 9
2023-01-04 06:39:10,506 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5379187742869059, 'Total loss': 0.5379187742869059} | train loss {'Reaction outcome loss': 0.4703282837618129, 'Total loss': 0.4703282837618129}
2023-01-04 06:39:10,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:10,506 INFO:     Epoch: 10
2023-01-04 06:39:12,017 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5134932120641073, 'Total loss': 0.5134932120641073} | train loss {'Reaction outcome loss': 0.4625759389964252, 'Total loss': 0.4625759389964252}
2023-01-04 06:39:12,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:12,017 INFO:     Epoch: 11
2023-01-04 06:39:13,569 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4941193113724391, 'Total loss': 0.4941193113724391} | train loss {'Reaction outcome loss': 0.45780791250807285, 'Total loss': 0.45780791250807285}
2023-01-04 06:39:13,570 INFO:     Found new best model at epoch 11
2023-01-04 06:39:13,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:13,571 INFO:     Epoch: 12
2023-01-04 06:39:15,119 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49960997303326926, 'Total loss': 0.49960997303326926} | train loss {'Reaction outcome loss': 0.45144225925960263, 'Total loss': 0.45144225925960263}
2023-01-04 06:39:15,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:15,119 INFO:     Epoch: 13
2023-01-04 06:39:16,675 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.512211432059606, 'Total loss': 0.512211432059606} | train loss {'Reaction outcome loss': 0.44610882945869806, 'Total loss': 0.44610882945869806}
2023-01-04 06:39:16,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:16,676 INFO:     Epoch: 14
2023-01-04 06:39:18,195 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5072150508562724, 'Total loss': 0.5072150508562724} | train loss {'Reaction outcome loss': 0.44079220136257713, 'Total loss': 0.44079220136257713}
2023-01-04 06:39:18,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:18,195 INFO:     Epoch: 15
2023-01-04 06:39:19,749 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5232963780562083, 'Total loss': 0.5232963780562083} | train loss {'Reaction outcome loss': 0.4405893723779637, 'Total loss': 0.4405893723779637}
2023-01-04 06:39:19,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:19,749 INFO:     Epoch: 16
2023-01-04 06:39:21,267 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48948725263277687, 'Total loss': 0.48948725263277687} | train loss {'Reaction outcome loss': 0.43262120726306513, 'Total loss': 0.43262120726306513}
2023-01-04 06:39:21,267 INFO:     Found new best model at epoch 16
2023-01-04 06:39:21,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:21,268 INFO:     Epoch: 17
2023-01-04 06:39:22,802 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4902593692143758, 'Total loss': 0.4902593692143758} | train loss {'Reaction outcome loss': 0.4297146210278845, 'Total loss': 0.4297146210278845}
2023-01-04 06:39:22,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:22,802 INFO:     Epoch: 18
2023-01-04 06:39:24,359 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48115709026654563, 'Total loss': 0.48115709026654563} | train loss {'Reaction outcome loss': 0.4259775862743278, 'Total loss': 0.4259775862743278}
2023-01-04 06:39:24,359 INFO:     Found new best model at epoch 18
2023-01-04 06:39:24,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:24,360 INFO:     Epoch: 19
2023-01-04 06:39:25,923 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46779995461304985, 'Total loss': 0.46779995461304985} | train loss {'Reaction outcome loss': 0.4219570633575374, 'Total loss': 0.4219570633575374}
2023-01-04 06:39:25,923 INFO:     Found new best model at epoch 19
2023-01-04 06:39:25,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:25,924 INFO:     Epoch: 20
2023-01-04 06:39:27,442 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.490532719095548, 'Total loss': 0.490532719095548} | train loss {'Reaction outcome loss': 0.41604402844225885, 'Total loss': 0.41604402844225885}
2023-01-04 06:39:27,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:27,442 INFO:     Epoch: 21
2023-01-04 06:39:28,981 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4967828412850698, 'Total loss': 0.4967828412850698} | train loss {'Reaction outcome loss': 0.4136235576244037, 'Total loss': 0.4136235576244037}
2023-01-04 06:39:28,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:28,981 INFO:     Epoch: 22
2023-01-04 06:39:30,510 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4994384557008743, 'Total loss': 0.4994384557008743} | train loss {'Reaction outcome loss': 0.4058535289463153, 'Total loss': 0.4058535289463153}
2023-01-04 06:39:30,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:30,510 INFO:     Epoch: 23
2023-01-04 06:39:32,062 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4863118400176366, 'Total loss': 0.4863118400176366} | train loss {'Reaction outcome loss': 0.4021901055255952, 'Total loss': 0.4021901055255952}
2023-01-04 06:39:32,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:32,063 INFO:     Epoch: 24
2023-01-04 06:39:33,620 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49311646620432537, 'Total loss': 0.49311646620432537} | train loss {'Reaction outcome loss': 0.3981397604899286, 'Total loss': 0.3981397604899286}
2023-01-04 06:39:33,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:33,621 INFO:     Epoch: 25
2023-01-04 06:39:35,165 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4857781012852987, 'Total loss': 0.4857781012852987} | train loss {'Reaction outcome loss': 0.3979919578624546, 'Total loss': 0.3979919578624546}
2023-01-04 06:39:35,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:35,165 INFO:     Epoch: 26
2023-01-04 06:39:36,679 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4769036362568537, 'Total loss': 0.4769036362568537} | train loss {'Reaction outcome loss': 0.39359129766264545, 'Total loss': 0.39359129766264545}
2023-01-04 06:39:36,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:36,679 INFO:     Epoch: 27
2023-01-04 06:39:38,221 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47144819498062135, 'Total loss': 0.47144819498062135} | train loss {'Reaction outcome loss': 0.38766671937725605, 'Total loss': 0.38766671937725605}
2023-01-04 06:39:38,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:38,222 INFO:     Epoch: 28
2023-01-04 06:39:39,760 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4633002440134684, 'Total loss': 0.4633002440134684} | train loss {'Reaction outcome loss': 0.38884756044360275, 'Total loss': 0.38884756044360275}
2023-01-04 06:39:39,760 INFO:     Found new best model at epoch 28
2023-01-04 06:39:39,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:39,761 INFO:     Epoch: 29
2023-01-04 06:39:41,334 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4814297119776408, 'Total loss': 0.4814297119776408} | train loss {'Reaction outcome loss': 0.38001795726347487, 'Total loss': 0.38001795726347487}
2023-01-04 06:39:41,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:41,334 INFO:     Epoch: 30
2023-01-04 06:39:42,924 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4879276990890503, 'Total loss': 0.4879276990890503} | train loss {'Reaction outcome loss': 0.37845056600841803, 'Total loss': 0.37845056600841803}
2023-01-04 06:39:42,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:42,924 INFO:     Epoch: 31
2023-01-04 06:39:44,505 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48344255685806276, 'Total loss': 0.48344255685806276} | train loss {'Reaction outcome loss': 0.37439114549314934, 'Total loss': 0.37439114549314934}
2023-01-04 06:39:44,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:44,505 INFO:     Epoch: 32
2023-01-04 06:39:46,053 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4605027715365092, 'Total loss': 0.4605027715365092} | train loss {'Reaction outcome loss': 0.3716566176943831, 'Total loss': 0.3716566176943831}
2023-01-04 06:39:46,054 INFO:     Found new best model at epoch 32
2023-01-04 06:39:46,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:46,054 INFO:     Epoch: 33
2023-01-04 06:39:47,616 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46563162207603453, 'Total loss': 0.46563162207603453} | train loss {'Reaction outcome loss': 0.3688555902361009, 'Total loss': 0.3688555902361009}
2023-01-04 06:39:47,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:47,617 INFO:     Epoch: 34
2023-01-04 06:39:49,187 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47285447518030804, 'Total loss': 0.47285447518030804} | train loss {'Reaction outcome loss': 0.36552845805022693, 'Total loss': 0.36552845805022693}
2023-01-04 06:39:49,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:49,187 INFO:     Epoch: 35
2023-01-04 06:39:50,793 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4823377996683121, 'Total loss': 0.4823377996683121} | train loss {'Reaction outcome loss': 0.3634724246089209, 'Total loss': 0.3634724246089209}
2023-01-04 06:39:50,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:50,793 INFO:     Epoch: 36
2023-01-04 06:39:52,377 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44527183175086976, 'Total loss': 0.44527183175086976} | train loss {'Reaction outcome loss': 0.35973242387874893, 'Total loss': 0.35973242387874893}
2023-01-04 06:39:52,377 INFO:     Found new best model at epoch 36
2023-01-04 06:39:52,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:52,378 INFO:     Epoch: 37
2023-01-04 06:39:53,922 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45473678906758624, 'Total loss': 0.45473678906758624} | train loss {'Reaction outcome loss': 0.35847142669590804, 'Total loss': 0.35847142669590804}
2023-01-04 06:39:53,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:53,923 INFO:     Epoch: 38
2023-01-04 06:39:55,516 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4805318127075831, 'Total loss': 0.4805318127075831} | train loss {'Reaction outcome loss': 0.35373536193413857, 'Total loss': 0.35373536193413857}
2023-01-04 06:39:55,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:55,516 INFO:     Epoch: 39
2023-01-04 06:39:57,048 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4626347154378891, 'Total loss': 0.4626347154378891} | train loss {'Reaction outcome loss': 0.34910287361067555, 'Total loss': 0.34910287361067555}
2023-01-04 06:39:57,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:57,049 INFO:     Epoch: 40
2023-01-04 06:39:58,638 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4562055389086405, 'Total loss': 0.4562055389086405} | train loss {'Reaction outcome loss': 0.34279738178322033, 'Total loss': 0.34279738178322033}
2023-01-04 06:39:58,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:39:58,639 INFO:     Epoch: 41
2023-01-04 06:40:00,226 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4368926207224528, 'Total loss': 0.4368926207224528} | train loss {'Reaction outcome loss': 0.34757261903492553, 'Total loss': 0.34757261903492553}
2023-01-04 06:40:00,226 INFO:     Found new best model at epoch 41
2023-01-04 06:40:00,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:00,227 INFO:     Epoch: 42
2023-01-04 06:40:01,827 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46368300914764404, 'Total loss': 0.46368300914764404} | train loss {'Reaction outcome loss': 0.34006859354056174, 'Total loss': 0.34006859354056174}
2023-01-04 06:40:01,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:01,827 INFO:     Epoch: 43
2023-01-04 06:40:03,378 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44808265566825867, 'Total loss': 0.44808265566825867} | train loss {'Reaction outcome loss': 0.339046525718503, 'Total loss': 0.339046525718503}
2023-01-04 06:40:03,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:03,378 INFO:     Epoch: 44
2023-01-04 06:40:04,960 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45051635106404625, 'Total loss': 0.45051635106404625} | train loss {'Reaction outcome loss': 0.3394365271129763, 'Total loss': 0.3394365271129763}
2023-01-04 06:40:04,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:04,960 INFO:     Epoch: 45
2023-01-04 06:40:06,508 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4516815602779388, 'Total loss': 0.4516815602779388} | train loss {'Reaction outcome loss': 0.3278010698163122, 'Total loss': 0.3278010698163122}
2023-01-04 06:40:06,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:06,509 INFO:     Epoch: 46
2023-01-04 06:40:08,084 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4552369256814321, 'Total loss': 0.4552369256814321} | train loss {'Reaction outcome loss': 0.3324471909539364, 'Total loss': 0.3324471909539364}
2023-01-04 06:40:08,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:08,085 INFO:     Epoch: 47
2023-01-04 06:40:09,671 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.466632412870725, 'Total loss': 0.466632412870725} | train loss {'Reaction outcome loss': 0.3240343122625394, 'Total loss': 0.3240343122625394}
2023-01-04 06:40:09,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:09,671 INFO:     Epoch: 48
2023-01-04 06:40:11,226 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44576143225034076, 'Total loss': 0.44576143225034076} | train loss {'Reaction outcome loss': 0.3240755401847595, 'Total loss': 0.3240755401847595}
2023-01-04 06:40:11,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:11,226 INFO:     Epoch: 49
2023-01-04 06:40:12,761 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46032111048698426, 'Total loss': 0.46032111048698426} | train loss {'Reaction outcome loss': 0.32270721012612114, 'Total loss': 0.32270721012612114}
2023-01-04 06:40:12,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:12,762 INFO:     Epoch: 50
2023-01-04 06:40:14,326 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4422063221534093, 'Total loss': 0.4422063221534093} | train loss {'Reaction outcome loss': 0.31541119343752466, 'Total loss': 0.31541119343752466}
2023-01-04 06:40:14,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:14,326 INFO:     Epoch: 51
2023-01-04 06:40:15,856 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4360078235467275, 'Total loss': 0.4360078235467275} | train loss {'Reaction outcome loss': 0.31620275726817576, 'Total loss': 0.31620275726817576}
2023-01-04 06:40:15,856 INFO:     Found new best model at epoch 51
2023-01-04 06:40:15,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:15,857 INFO:     Epoch: 52
2023-01-04 06:40:17,426 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4501460611820221, 'Total loss': 0.4501460611820221} | train loss {'Reaction outcome loss': 0.31326486514578655, 'Total loss': 0.31326486514578655}
2023-01-04 06:40:17,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:17,426 INFO:     Epoch: 53
2023-01-04 06:40:18,983 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44981818993886313, 'Total loss': 0.44981818993886313} | train loss {'Reaction outcome loss': 0.3072878416049351, 'Total loss': 0.3072878416049351}
2023-01-04 06:40:18,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:18,983 INFO:     Epoch: 54
2023-01-04 06:40:20,551 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44710620840390525, 'Total loss': 0.44710620840390525} | train loss {'Reaction outcome loss': 0.31084034777505304, 'Total loss': 0.31084034777505304}
2023-01-04 06:40:20,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:20,551 INFO:     Epoch: 55
2023-01-04 06:40:22,082 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4448966364065806, 'Total loss': 0.4448966364065806} | train loss {'Reaction outcome loss': 0.3064463121634958, 'Total loss': 0.3064463121634958}
2023-01-04 06:40:22,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:22,083 INFO:     Epoch: 56
2023-01-04 06:40:23,669 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4414772162834803, 'Total loss': 0.4414772162834803} | train loss {'Reaction outcome loss': 0.30116990106415664, 'Total loss': 0.30116990106415664}
2023-01-04 06:40:23,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:23,669 INFO:     Epoch: 57
2023-01-04 06:40:25,223 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4241868356863658, 'Total loss': 0.4241868356863658} | train loss {'Reaction outcome loss': 0.3040230307015271, 'Total loss': 0.3040230307015271}
2023-01-04 06:40:25,224 INFO:     Found new best model at epoch 57
2023-01-04 06:40:25,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:25,225 INFO:     Epoch: 58
2023-01-04 06:40:26,815 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4300468683242798, 'Total loss': 0.4300468683242798} | train loss {'Reaction outcome loss': 0.2988265701418319, 'Total loss': 0.2988265701418319}
2023-01-04 06:40:26,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:26,815 INFO:     Epoch: 59
2023-01-04 06:40:28,404 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45968823234240214, 'Total loss': 0.45968823234240214} | train loss {'Reaction outcome loss': 0.2957616659009069, 'Total loss': 0.2957616659009069}
2023-01-04 06:40:28,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:28,405 INFO:     Epoch: 60
2023-01-04 06:40:29,989 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4318815112113953, 'Total loss': 0.4318815112113953} | train loss {'Reaction outcome loss': 0.29832578757071754, 'Total loss': 0.29832578757071754}
2023-01-04 06:40:29,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:29,989 INFO:     Epoch: 61
2023-01-04 06:40:31,472 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.440421794851621, 'Total loss': 0.440421794851621} | train loss {'Reaction outcome loss': 0.29457863545320956, 'Total loss': 0.29457863545320956}
2023-01-04 06:40:31,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:31,473 INFO:     Epoch: 62
2023-01-04 06:40:33,041 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43302034338315326, 'Total loss': 0.43302034338315326} | train loss {'Reaction outcome loss': 0.2991251517557926, 'Total loss': 0.2991251517557926}
2023-01-04 06:40:33,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:33,041 INFO:     Epoch: 63
2023-01-04 06:40:34,183 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42865381836891175, 'Total loss': 0.42865381836891175} | train loss {'Reaction outcome loss': 0.29602567734539725, 'Total loss': 0.29602567734539725}
2023-01-04 06:40:34,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:34,183 INFO:     Epoch: 64
2023-01-04 06:40:35,209 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4302675247192383, 'Total loss': 0.4302675247192383} | train loss {'Reaction outcome loss': 0.2921743592523065, 'Total loss': 0.2921743592523065}
2023-01-04 06:40:35,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:35,210 INFO:     Epoch: 65
2023-01-04 06:40:36,234 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44451092183589935, 'Total loss': 0.44451092183589935} | train loss {'Reaction outcome loss': 0.2900914812077254, 'Total loss': 0.2900914812077254}
2023-01-04 06:40:36,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:36,234 INFO:     Epoch: 66
2023-01-04 06:40:37,266 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47268636723359425, 'Total loss': 0.47268636723359425} | train loss {'Reaction outcome loss': 0.28731106444924315, 'Total loss': 0.28731106444924315}
2023-01-04 06:40:37,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:37,267 INFO:     Epoch: 67
2023-01-04 06:40:38,643 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43526206264893214, 'Total loss': 0.43526206264893214} | train loss {'Reaction outcome loss': 0.2862161263850407, 'Total loss': 0.2862161263850407}
2023-01-04 06:40:38,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:38,643 INFO:     Epoch: 68
2023-01-04 06:40:40,199 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4680233975251516, 'Total loss': 0.4680233975251516} | train loss {'Reaction outcome loss': 0.2876956207872728, 'Total loss': 0.2876956207872728}
2023-01-04 06:40:40,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:40,200 INFO:     Epoch: 69
2023-01-04 06:40:41,775 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41029994885126747, 'Total loss': 0.41029994885126747} | train loss {'Reaction outcome loss': 0.28029976790562433, 'Total loss': 0.28029976790562433}
2023-01-04 06:40:41,775 INFO:     Found new best model at epoch 69
2023-01-04 06:40:41,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:41,776 INFO:     Epoch: 70
2023-01-04 06:40:43,347 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41967571079730986, 'Total loss': 0.41967571079730986} | train loss {'Reaction outcome loss': 0.2813381632581515, 'Total loss': 0.2813381632581515}
2023-01-04 06:40:43,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:43,348 INFO:     Epoch: 71
2023-01-04 06:40:44,921 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.432430362701416, 'Total loss': 0.432430362701416} | train loss {'Reaction outcome loss': 0.28119630463394446, 'Total loss': 0.28119630463394446}
2023-01-04 06:40:44,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:44,921 INFO:     Epoch: 72
2023-01-04 06:40:46,467 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4222362498442332, 'Total loss': 0.4222362498442332} | train loss {'Reaction outcome loss': 0.2807134966288663, 'Total loss': 0.2807134966288663}
2023-01-04 06:40:46,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:46,467 INFO:     Epoch: 73
2023-01-04 06:40:48,003 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4490647812684377, 'Total loss': 0.4490647812684377} | train loss {'Reaction outcome loss': 0.27706905015969535, 'Total loss': 0.27706905015969535}
2023-01-04 06:40:48,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:48,004 INFO:     Epoch: 74
2023-01-04 06:40:49,557 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4463219285011292, 'Total loss': 0.4463219285011292} | train loss {'Reaction outcome loss': 0.27885389282277345, 'Total loss': 0.27885389282277345}
2023-01-04 06:40:49,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:49,557 INFO:     Epoch: 75
2023-01-04 06:40:51,115 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43775553405284884, 'Total loss': 0.43775553405284884} | train loss {'Reaction outcome loss': 0.2787799596356141, 'Total loss': 0.2787799596356141}
2023-01-04 06:40:51,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:51,115 INFO:     Epoch: 76
2023-01-04 06:40:52,672 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44139981766541797, 'Total loss': 0.44139981766541797} | train loss {'Reaction outcome loss': 0.26770447731179453, 'Total loss': 0.26770447731179453}
2023-01-04 06:40:52,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:52,673 INFO:     Epoch: 77
2023-01-04 06:40:54,242 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4286428610483805, 'Total loss': 0.4286428610483805} | train loss {'Reaction outcome loss': 0.27143456212611405, 'Total loss': 0.27143456212611405}
2023-01-04 06:40:54,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:54,243 INFO:     Epoch: 78
2023-01-04 06:40:55,770 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45572163661321, 'Total loss': 0.45572163661321} | train loss {'Reaction outcome loss': 0.27286270540543844, 'Total loss': 0.27286270540543844}
2023-01-04 06:40:55,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:55,771 INFO:     Epoch: 79
2023-01-04 06:40:57,297 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42876124382019043, 'Total loss': 0.42876124382019043} | train loss {'Reaction outcome loss': 0.2742368921852714, 'Total loss': 0.2742368921852714}
2023-01-04 06:40:57,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:57,297 INFO:     Epoch: 80
2023-01-04 06:40:58,860 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43351373771826424, 'Total loss': 0.43351373771826424} | train loss {'Reaction outcome loss': 0.26671791529881395, 'Total loss': 0.26671791529881395}
2023-01-04 06:40:58,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:40:58,860 INFO:     Epoch: 81
2023-01-04 06:41:00,405 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42040593226750694, 'Total loss': 0.42040593226750694} | train loss {'Reaction outcome loss': 0.26380406127778633, 'Total loss': 0.26380406127778633}
2023-01-04 06:41:00,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:00,406 INFO:     Epoch: 82
2023-01-04 06:41:01,971 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4419889787832896, 'Total loss': 0.4419889787832896} | train loss {'Reaction outcome loss': 0.26642679795622826, 'Total loss': 0.26642679795622826}
2023-01-04 06:41:01,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:01,971 INFO:     Epoch: 83
2023-01-04 06:41:03,518 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.411686435341835, 'Total loss': 0.411686435341835} | train loss {'Reaction outcome loss': 0.2663772868846513, 'Total loss': 0.2663772868846513}
2023-01-04 06:41:03,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:03,518 INFO:     Epoch: 84
2023-01-04 06:41:05,012 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4235520044962565, 'Total loss': 0.4235520044962565} | train loss {'Reaction outcome loss': 0.26878181960608555, 'Total loss': 0.26878181960608555}
2023-01-04 06:41:05,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:05,012 INFO:     Epoch: 85
2023-01-04 06:41:06,567 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4503971298535665, 'Total loss': 0.4503971298535665} | train loss {'Reaction outcome loss': 0.263094487475628, 'Total loss': 0.263094487475628}
2023-01-04 06:41:06,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:06,567 INFO:     Epoch: 86
2023-01-04 06:41:08,130 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4171077211697896, 'Total loss': 0.4171077211697896} | train loss {'Reaction outcome loss': 0.26577276260413846, 'Total loss': 0.26577276260413846}
2023-01-04 06:41:08,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:08,131 INFO:     Epoch: 87
2023-01-04 06:41:09,673 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4033399850130081, 'Total loss': 0.4033399850130081} | train loss {'Reaction outcome loss': 0.2612224950821606, 'Total loss': 0.2612224950821606}
2023-01-04 06:41:09,673 INFO:     Found new best model at epoch 87
2023-01-04 06:41:09,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:09,674 INFO:     Epoch: 88
2023-01-04 06:41:11,222 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4234527577956518, 'Total loss': 0.4234527577956518} | train loss {'Reaction outcome loss': 0.26165256658669844, 'Total loss': 0.26165256658669844}
2023-01-04 06:41:11,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:11,223 INFO:     Epoch: 89
2023-01-04 06:41:12,785 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41850704749425255, 'Total loss': 0.41850704749425255} | train loss {'Reaction outcome loss': 0.2627058374806432, 'Total loss': 0.2627058374806432}
2023-01-04 06:41:12,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:12,786 INFO:     Epoch: 90
2023-01-04 06:41:14,277 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.440294282635053, 'Total loss': 0.440294282635053} | train loss {'Reaction outcome loss': 0.26470421639267716, 'Total loss': 0.26470421639267716}
2023-01-04 06:41:14,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:14,278 INFO:     Epoch: 91
2023-01-04 06:41:15,874 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4131782720486323, 'Total loss': 0.4131782720486323} | train loss {'Reaction outcome loss': 0.25878247563535556, 'Total loss': 0.25878247563535556}
2023-01-04 06:41:15,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:15,874 INFO:     Epoch: 92
2023-01-04 06:41:17,440 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45581377744674684, 'Total loss': 0.45581377744674684} | train loss {'Reaction outcome loss': 0.26284469204151245, 'Total loss': 0.26284469204151245}
2023-01-04 06:41:17,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:17,440 INFO:     Epoch: 93
2023-01-04 06:41:19,005 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4270367999871572, 'Total loss': 0.4270367999871572} | train loss {'Reaction outcome loss': 0.2591588746904251, 'Total loss': 0.2591588746904251}
2023-01-04 06:41:19,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:19,005 INFO:     Epoch: 94
2023-01-04 06:41:20,581 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4159794827302297, 'Total loss': 0.4159794827302297} | train loss {'Reaction outcome loss': 0.2568370334077828, 'Total loss': 0.2568370334077828}
2023-01-04 06:41:20,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:20,581 INFO:     Epoch: 95
2023-01-04 06:41:22,173 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42744643886884054, 'Total loss': 0.42744643886884054} | train loss {'Reaction outcome loss': 0.2610705497166956, 'Total loss': 0.2610705497166956}
2023-01-04 06:41:22,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:22,174 INFO:     Epoch: 96
2023-01-04 06:41:23,702 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40909743507703145, 'Total loss': 0.40909743507703145} | train loss {'Reaction outcome loss': 0.2580741490321469, 'Total loss': 0.2580741490321469}
2023-01-04 06:41:23,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:23,703 INFO:     Epoch: 97
2023-01-04 06:41:25,276 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4391436288754145, 'Total loss': 0.4391436288754145} | train loss {'Reaction outcome loss': 0.2563324341624437, 'Total loss': 0.2563324341624437}
2023-01-04 06:41:25,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:25,277 INFO:     Epoch: 98
2023-01-04 06:41:26,871 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41279199222723645, 'Total loss': 0.41279199222723645} | train loss {'Reaction outcome loss': 0.25456066082638523, 'Total loss': 0.25456066082638523}
2023-01-04 06:41:26,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:26,872 INFO:     Epoch: 99
2023-01-04 06:41:28,448 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4266625156005224, 'Total loss': 0.4266625156005224} | train loss {'Reaction outcome loss': 0.25145086530421185, 'Total loss': 0.25145086530421185}
2023-01-04 06:41:28,449 INFO:     Best model found after epoch 88 of 100.
2023-01-04 06:41:28,449 INFO:   Done with stage: TRAINING
2023-01-04 06:41:28,449 INFO:   Starting stage: EVALUATION
2023-01-04 06:41:28,568 INFO:   Done with stage: EVALUATION
2023-01-04 06:41:28,569 INFO:   Leaving out SEQ value Fold_5
2023-01-04 06:41:28,581 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 06:41:28,581 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:41:29,226 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:41:29,226 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:41:29,296 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:41:29,296 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:41:29,296 INFO:     No hyperparam tuning for this model
2023-01-04 06:41:29,296 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:41:29,296 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:41:29,297 INFO:     None feature selector for col prot
2023-01-04 06:41:29,297 INFO:     None feature selector for col prot
2023-01-04 06:41:29,297 INFO:     None feature selector for col prot
2023-01-04 06:41:29,297 INFO:     None feature selector for col chem
2023-01-04 06:41:29,297 INFO:     None feature selector for col chem
2023-01-04 06:41:29,298 INFO:     None feature selector for col chem
2023-01-04 06:41:29,298 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:41:29,298 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:41:29,299 INFO:     Number of params in model 70111
2023-01-04 06:41:29,302 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:41:29,302 INFO:   Starting stage: TRAINING
2023-01-04 06:41:29,344 INFO:     Val loss before train {'Reaction outcome loss': 1.0821157733599345, 'Total loss': 1.0821157733599345}
2023-01-04 06:41:29,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:29,344 INFO:     Epoch: 0
2023-01-04 06:41:30,915 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8079648852348328, 'Total loss': 0.8079648852348328} | train loss {'Reaction outcome loss': 0.8417105392242471, 'Total loss': 0.8417105392242471}
2023-01-04 06:41:30,915 INFO:     Found new best model at epoch 0
2023-01-04 06:41:30,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:30,916 INFO:     Epoch: 1
2023-01-04 06:41:32,391 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6814140359560649, 'Total loss': 0.6814140359560649} | train loss {'Reaction outcome loss': 0.690951947460248, 'Total loss': 0.690951947460248}
2023-01-04 06:41:32,391 INFO:     Found new best model at epoch 1
2023-01-04 06:41:32,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:32,391 INFO:     Epoch: 2
2023-01-04 06:41:33,941 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6058793167273203, 'Total loss': 0.6058793167273203} | train loss {'Reaction outcome loss': 0.6169528607009114, 'Total loss': 0.6169528607009114}
2023-01-04 06:41:33,941 INFO:     Found new best model at epoch 2
2023-01-04 06:41:33,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:33,942 INFO:     Epoch: 3
2023-01-04 06:41:35,512 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5333829402923584, 'Total loss': 0.5333829402923584} | train loss {'Reaction outcome loss': 0.5569293986258529, 'Total loss': 0.5569293986258529}
2023-01-04 06:41:35,512 INFO:     Found new best model at epoch 3
2023-01-04 06:41:35,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:35,513 INFO:     Epoch: 4
2023-01-04 06:41:37,057 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5334320863087972, 'Total loss': 0.5334320863087972} | train loss {'Reaction outcome loss': 0.524778812618393, 'Total loss': 0.524778812618393}
2023-01-04 06:41:37,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:37,057 INFO:     Epoch: 5
2023-01-04 06:41:38,616 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5349920431772868, 'Total loss': 0.5349920431772868} | train loss {'Reaction outcome loss': 0.5122925104384405, 'Total loss': 0.5122925104384405}
2023-01-04 06:41:38,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:38,617 INFO:     Epoch: 6
2023-01-04 06:41:40,143 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5186009834210078, 'Total loss': 0.5186009834210078} | train loss {'Reaction outcome loss': 0.49981280313669774, 'Total loss': 0.49981280313669774}
2023-01-04 06:41:40,143 INFO:     Found new best model at epoch 6
2023-01-04 06:41:40,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:40,144 INFO:     Epoch: 7
2023-01-04 06:41:41,641 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.50844686627388, 'Total loss': 0.50844686627388} | train loss {'Reaction outcome loss': 0.4913525184771667, 'Total loss': 0.4913525184771667}
2023-01-04 06:41:41,641 INFO:     Found new best model at epoch 7
2023-01-04 06:41:41,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:41,642 INFO:     Epoch: 8
2023-01-04 06:41:43,207 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5136047800381979, 'Total loss': 0.5136047800381979} | train loss {'Reaction outcome loss': 0.47968343407526426, 'Total loss': 0.47968343407526426}
2023-01-04 06:41:43,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:43,207 INFO:     Epoch: 9
2023-01-04 06:41:44,765 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4942064583301544, 'Total loss': 0.4942064583301544} | train loss {'Reaction outcome loss': 0.4724197274116329, 'Total loss': 0.4724197274116329}
2023-01-04 06:41:44,766 INFO:     Found new best model at epoch 9
2023-01-04 06:41:44,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:44,767 INFO:     Epoch: 10
2023-01-04 06:41:46,317 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5079507013161977, 'Total loss': 0.5079507013161977} | train loss {'Reaction outcome loss': 0.4889034407510274, 'Total loss': 0.4889034407510274}
2023-01-04 06:41:46,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:46,317 INFO:     Epoch: 11
2023-01-04 06:41:47,870 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48507992227872215, 'Total loss': 0.48507992227872215} | train loss {'Reaction outcome loss': 0.48194951574871503, 'Total loss': 0.48194951574871503}
2023-01-04 06:41:47,870 INFO:     Found new best model at epoch 11
2023-01-04 06:41:47,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:47,871 INFO:     Epoch: 12
2023-01-04 06:41:49,401 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48753083546956383, 'Total loss': 0.48753083546956383} | train loss {'Reaction outcome loss': 0.4604079311416633, 'Total loss': 0.4604079311416633}
2023-01-04 06:41:49,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:49,401 INFO:     Epoch: 13
2023-01-04 06:41:50,915 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5003339946269989, 'Total loss': 0.5003339946269989} | train loss {'Reaction outcome loss': 0.4575541342838087, 'Total loss': 0.4575541342838087}
2023-01-04 06:41:50,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:50,915 INFO:     Epoch: 14
2023-01-04 06:41:52,500 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49118243853251137, 'Total loss': 0.49118243853251137} | train loss {'Reaction outcome loss': 0.4654314888130036, 'Total loss': 0.4654314888130036}
2023-01-04 06:41:52,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:52,500 INFO:     Epoch: 15
2023-01-04 06:41:54,117 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4931457281112671, 'Total loss': 0.4931457281112671} | train loss {'Reaction outcome loss': 0.44474421910590667, 'Total loss': 0.44474421910590667}
2023-01-04 06:41:54,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:54,117 INFO:     Epoch: 16
2023-01-04 06:41:55,713 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.485490882396698, 'Total loss': 0.485490882396698} | train loss {'Reaction outcome loss': 0.4397690834450549, 'Total loss': 0.4397690834450549}
2023-01-04 06:41:55,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:55,713 INFO:     Epoch: 17
2023-01-04 06:41:57,299 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4720350166161855, 'Total loss': 0.4720350166161855} | train loss {'Reaction outcome loss': 0.44147820886143524, 'Total loss': 0.44147820886143524}
2023-01-04 06:41:57,299 INFO:     Found new best model at epoch 17
2023-01-04 06:41:57,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:57,300 INFO:     Epoch: 18
2023-01-04 06:41:58,859 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47433382471402485, 'Total loss': 0.47433382471402485} | train loss {'Reaction outcome loss': 0.4331892596574239, 'Total loss': 0.4331892596574239}
2023-01-04 06:41:58,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:41:58,860 INFO:     Epoch: 19
2023-01-04 06:42:00,433 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4710182070732117, 'Total loss': 0.4710182070732117} | train loss {'Reaction outcome loss': 0.4269405337695059, 'Total loss': 0.4269405337695059}
2023-01-04 06:42:00,433 INFO:     Found new best model at epoch 19
2023-01-04 06:42:00,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:00,434 INFO:     Epoch: 20
2023-01-04 06:42:02,054 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4669886459906896, 'Total loss': 0.4669886459906896} | train loss {'Reaction outcome loss': 0.4204644657590467, 'Total loss': 0.4204644657590467}
2023-01-04 06:42:02,054 INFO:     Found new best model at epoch 20
2023-01-04 06:42:02,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:02,055 INFO:     Epoch: 21
2023-01-04 06:42:03,654 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4803454299767812, 'Total loss': 0.4803454299767812} | train loss {'Reaction outcome loss': 0.41894282146877493, 'Total loss': 0.41894282146877493}
2023-01-04 06:42:03,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:03,654 INFO:     Epoch: 22
2023-01-04 06:42:05,271 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.467515105009079, 'Total loss': 0.467515105009079} | train loss {'Reaction outcome loss': 0.41749151418005803, 'Total loss': 0.41749151418005803}
2023-01-04 06:42:05,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:05,271 INFO:     Epoch: 23
2023-01-04 06:42:06,809 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4638884882132212, 'Total loss': 0.4638884882132212} | train loss {'Reaction outcome loss': 0.4159284069378307, 'Total loss': 0.4159284069378307}
2023-01-04 06:42:06,809 INFO:     Found new best model at epoch 23
2023-01-04 06:42:06,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:06,810 INFO:     Epoch: 24
2023-01-04 06:42:08,301 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48147852420806886, 'Total loss': 0.48147852420806886} | train loss {'Reaction outcome loss': 0.4177649060831122, 'Total loss': 0.4177649060831122}
2023-01-04 06:42:08,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:08,301 INFO:     Epoch: 25
2023-01-04 06:42:09,885 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44740506609280906, 'Total loss': 0.44740506609280906} | train loss {'Reaction outcome loss': 0.4049101207762589, 'Total loss': 0.4049101207762589}
2023-01-04 06:42:09,885 INFO:     Found new best model at epoch 25
2023-01-04 06:42:09,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:09,886 INFO:     Epoch: 26
2023-01-04 06:42:11,464 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4345806837081909, 'Total loss': 0.4345806837081909} | train loss {'Reaction outcome loss': 0.401985185328817, 'Total loss': 0.401985185328817}
2023-01-04 06:42:11,464 INFO:     Found new best model at epoch 26
2023-01-04 06:42:11,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:11,465 INFO:     Epoch: 27
2023-01-04 06:42:13,048 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46315375169118245, 'Total loss': 0.46315375169118245} | train loss {'Reaction outcome loss': 0.400927585608282, 'Total loss': 0.400927585608282}
2023-01-04 06:42:13,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:13,048 INFO:     Epoch: 28
2023-01-04 06:42:14,630 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44829663236935935, 'Total loss': 0.44829663236935935} | train loss {'Reaction outcome loss': 0.3938689216186016, 'Total loss': 0.3938689216186016}
2023-01-04 06:42:14,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:14,631 INFO:     Epoch: 29
2023-01-04 06:42:16,211 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4948217292626699, 'Total loss': 0.4948217292626699} | train loss {'Reaction outcome loss': 0.3922840287989896, 'Total loss': 0.3922840287989896}
2023-01-04 06:42:16,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:16,211 INFO:     Epoch: 30
2023-01-04 06:42:17,733 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44640915195147196, 'Total loss': 0.44640915195147196} | train loss {'Reaction outcome loss': 0.3969473676027163, 'Total loss': 0.3969473676027163}
2023-01-04 06:42:17,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:17,733 INFO:     Epoch: 31
2023-01-04 06:42:19,315 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.444538825750351, 'Total loss': 0.444538825750351} | train loss {'Reaction outcome loss': 0.38966549803971895, 'Total loss': 0.38966549803971895}
2023-01-04 06:42:19,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:19,315 INFO:     Epoch: 32
2023-01-04 06:42:20,897 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46135374108950294, 'Total loss': 0.46135374108950294} | train loss {'Reaction outcome loss': 0.3823835165678537, 'Total loss': 0.3823835165678537}
2023-01-04 06:42:20,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:20,898 INFO:     Epoch: 33
2023-01-04 06:42:22,477 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4419230043888092, 'Total loss': 0.4419230043888092} | train loss {'Reaction outcome loss': 0.37602427882560785, 'Total loss': 0.37602427882560785}
2023-01-04 06:42:22,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:22,478 INFO:     Epoch: 34
2023-01-04 06:42:24,050 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4318101684252421, 'Total loss': 0.4318101684252421} | train loss {'Reaction outcome loss': 0.3789876889946965, 'Total loss': 0.3789876889946965}
2023-01-04 06:42:24,050 INFO:     Found new best model at epoch 34
2023-01-04 06:42:24,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:24,051 INFO:     Epoch: 35
2023-01-04 06:42:25,632 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4570244272549947, 'Total loss': 0.4570244272549947} | train loss {'Reaction outcome loss': 0.36925763813643786, 'Total loss': 0.36925763813643786}
2023-01-04 06:42:25,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:25,633 INFO:     Epoch: 36
2023-01-04 06:42:27,138 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4401058574517568, 'Total loss': 0.4401058574517568} | train loss {'Reaction outcome loss': 0.36712379131695605, 'Total loss': 0.36712379131695605}
2023-01-04 06:42:27,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:27,138 INFO:     Epoch: 37
2023-01-04 06:42:28,684 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4321593920389811, 'Total loss': 0.4321593920389811} | train loss {'Reaction outcome loss': 0.36564149544911756, 'Total loss': 0.36564149544911756}
2023-01-04 06:42:28,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:28,684 INFO:     Epoch: 38
2023-01-04 06:42:30,229 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4861194252967834, 'Total loss': 0.4861194252967834} | train loss {'Reaction outcome loss': 0.36355641547909373, 'Total loss': 0.36355641547909373}
2023-01-04 06:42:30,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:30,229 INFO:     Epoch: 39
2023-01-04 06:42:31,769 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4419087886810303, 'Total loss': 0.4419087886810303} | train loss {'Reaction outcome loss': 0.3599732566719362, 'Total loss': 0.3599732566719362}
2023-01-04 06:42:31,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:31,769 INFO:     Epoch: 40
2023-01-04 06:42:33,316 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40883636673291524, 'Total loss': 0.40883636673291524} | train loss {'Reaction outcome loss': 0.35719494161995774, 'Total loss': 0.35719494161995774}
2023-01-04 06:42:33,317 INFO:     Found new best model at epoch 40
2023-01-04 06:42:33,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:33,318 INFO:     Epoch: 41
2023-01-04 06:42:34,852 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43380061686038973, 'Total loss': 0.43380061686038973} | train loss {'Reaction outcome loss': 0.3545560445771485, 'Total loss': 0.3545560445771485}
2023-01-04 06:42:34,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:34,852 INFO:     Epoch: 42
2023-01-04 06:42:36,334 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44282868405183157, 'Total loss': 0.44282868405183157} | train loss {'Reaction outcome loss': 0.35634061886820995, 'Total loss': 0.35634061886820995}
2023-01-04 06:42:36,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:36,334 INFO:     Epoch: 43
2023-01-04 06:42:37,887 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42593702574570974, 'Total loss': 0.42593702574570974} | train loss {'Reaction outcome loss': 0.3742181493806234, 'Total loss': 0.3742181493806234}
2023-01-04 06:42:37,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:37,888 INFO:     Epoch: 44
2023-01-04 06:42:39,447 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4256967564423879, 'Total loss': 0.4256967564423879} | train loss {'Reaction outcome loss': 0.35259584323469334, 'Total loss': 0.35259584323469334}
2023-01-04 06:42:39,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:39,447 INFO:     Epoch: 45
2023-01-04 06:42:41,020 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47058977584044137, 'Total loss': 0.47058977584044137} | train loss {'Reaction outcome loss': 0.35065128667738993, 'Total loss': 0.35065128667738993}
2023-01-04 06:42:41,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:41,020 INFO:     Epoch: 46
2023-01-04 06:42:42,577 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4163207213083903, 'Total loss': 0.4163207213083903} | train loss {'Reaction outcome loss': 0.39087692834436893, 'Total loss': 0.39087692834436893}
2023-01-04 06:42:42,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:42,577 INFO:     Epoch: 47
2023-01-04 06:42:44,115 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4151967296997706, 'Total loss': 0.4151967296997706} | train loss {'Reaction outcome loss': 0.3633767778350823, 'Total loss': 0.3633767778350823}
2023-01-04 06:42:44,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:44,115 INFO:     Epoch: 48
2023-01-04 06:42:45,636 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43625702063242594, 'Total loss': 0.43625702063242594} | train loss {'Reaction outcome loss': 0.343827928001385, 'Total loss': 0.343827928001385}
2023-01-04 06:42:45,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:45,637 INFO:     Epoch: 49
2023-01-04 06:42:47,175 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41335577170054116, 'Total loss': 0.41335577170054116} | train loss {'Reaction outcome loss': 0.34032283057256235, 'Total loss': 0.34032283057256235}
2023-01-04 06:42:47,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:47,175 INFO:     Epoch: 50
2023-01-04 06:42:48,718 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4148207426071167, 'Total loss': 0.4148207426071167} | train loss {'Reaction outcome loss': 0.33697965453409223, 'Total loss': 0.33697965453409223}
2023-01-04 06:42:48,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:48,718 INFO:     Epoch: 51
2023-01-04 06:42:50,275 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42820707758267723, 'Total loss': 0.42820707758267723} | train loss {'Reaction outcome loss': 0.3355248673562554, 'Total loss': 0.3355248673562554}
2023-01-04 06:42:50,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:50,275 INFO:     Epoch: 52
2023-01-04 06:42:51,806 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40783505886793137, 'Total loss': 0.40783505886793137} | train loss {'Reaction outcome loss': 0.334663054595391, 'Total loss': 0.334663054595391}
2023-01-04 06:42:51,807 INFO:     Found new best model at epoch 52
2023-01-04 06:42:51,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:51,808 INFO:     Epoch: 53
2023-01-04 06:42:53,311 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4444294591744741, 'Total loss': 0.4444294591744741} | train loss {'Reaction outcome loss': 0.3425834267855809, 'Total loss': 0.3425834267855809}
2023-01-04 06:42:53,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:53,311 INFO:     Epoch: 54
2023-01-04 06:42:54,820 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42362504998842876, 'Total loss': 0.42362504998842876} | train loss {'Reaction outcome loss': 0.3388006570411549, 'Total loss': 0.3388006570411549}
2023-01-04 06:42:54,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:54,820 INFO:     Epoch: 55
2023-01-04 06:42:56,389 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4070898433526357, 'Total loss': 0.4070898433526357} | train loss {'Reaction outcome loss': 0.3599629587615314, 'Total loss': 0.3599629587615314}
2023-01-04 06:42:56,389 INFO:     Found new best model at epoch 55
2023-01-04 06:42:56,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:56,390 INFO:     Epoch: 56
2023-01-04 06:42:57,949 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42531061768531797, 'Total loss': 0.42531061768531797} | train loss {'Reaction outcome loss': 0.33076084775013337, 'Total loss': 0.33076084775013337}
2023-01-04 06:42:57,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:57,949 INFO:     Epoch: 57
2023-01-04 06:42:59,507 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39419128447771073, 'Total loss': 0.39419128447771073} | train loss {'Reaction outcome loss': 0.32156225391140586, 'Total loss': 0.32156225391140586}
2023-01-04 06:42:59,508 INFO:     Found new best model at epoch 57
2023-01-04 06:42:59,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:42:59,508 INFO:     Epoch: 58
2023-01-04 06:43:01,076 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38388190666834515, 'Total loss': 0.38388190666834515} | train loss {'Reaction outcome loss': 0.3206228964111727, 'Total loss': 0.3206228964111727}
2023-01-04 06:43:01,076 INFO:     Found new best model at epoch 58
2023-01-04 06:43:01,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:01,077 INFO:     Epoch: 59
2023-01-04 06:43:02,596 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4019675195217133, 'Total loss': 0.4019675195217133} | train loss {'Reaction outcome loss': 0.31779264113393385, 'Total loss': 0.31779264113393385}
2023-01-04 06:43:02,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:02,597 INFO:     Epoch: 60
2023-01-04 06:43:04,142 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39861473043759665, 'Total loss': 0.39861473043759665} | train loss {'Reaction outcome loss': 0.3204239060214388, 'Total loss': 0.3204239060214388}
2023-01-04 06:43:04,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:04,143 INFO:     Epoch: 61
2023-01-04 06:43:05,718 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3861006319522858, 'Total loss': 0.3861006319522858} | train loss {'Reaction outcome loss': 0.3158460389974568, 'Total loss': 0.3158460389974568}
2023-01-04 06:43:05,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:05,718 INFO:     Epoch: 62
2023-01-04 06:43:07,295 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42139352957407633, 'Total loss': 0.42139352957407633} | train loss {'Reaction outcome loss': 0.3158156954724699, 'Total loss': 0.3158156954724699}
2023-01-04 06:43:07,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:07,295 INFO:     Epoch: 63
2023-01-04 06:43:08,855 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40387137134869894, 'Total loss': 0.40387137134869894} | train loss {'Reaction outcome loss': 0.31195228279946186, 'Total loss': 0.31195228279946186}
2023-01-04 06:43:08,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:08,855 INFO:     Epoch: 64
2023-01-04 06:43:10,418 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4196718985835711, 'Total loss': 0.4196718985835711} | train loss {'Reaction outcome loss': 0.3183173954054929, 'Total loss': 0.3183173954054929}
2023-01-04 06:43:10,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:10,418 INFO:     Epoch: 65
2023-01-04 06:43:11,907 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4102403144041697, 'Total loss': 0.4102403144041697} | train loss {'Reaction outcome loss': 0.3648811580910199, 'Total loss': 0.3648811580910199}
2023-01-04 06:43:11,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:11,908 INFO:     Epoch: 66
2023-01-04 06:43:13,530 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40525330205758414, 'Total loss': 0.40525330205758414} | train loss {'Reaction outcome loss': 0.31797157200323284, 'Total loss': 0.31797157200323284}
2023-01-04 06:43:13,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:13,530 INFO:     Epoch: 67
2023-01-04 06:43:15,150 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.415709987282753, 'Total loss': 0.415709987282753} | train loss {'Reaction outcome loss': 0.3062390153080333, 'Total loss': 0.3062390153080333}
2023-01-04 06:43:15,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:15,150 INFO:     Epoch: 68
2023-01-04 06:43:16,775 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4242922435204188, 'Total loss': 0.4242922435204188} | train loss {'Reaction outcome loss': 0.3171553787221943, 'Total loss': 0.3171553787221943}
2023-01-04 06:43:16,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:16,777 INFO:     Epoch: 69
2023-01-04 06:43:18,386 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.436343456308047, 'Total loss': 0.436343456308047} | train loss {'Reaction outcome loss': 0.3460903924829124, 'Total loss': 0.3460903924829124}
2023-01-04 06:43:18,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:18,386 INFO:     Epoch: 70
2023-01-04 06:43:19,978 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3912672117352486, 'Total loss': 0.3912672117352486} | train loss {'Reaction outcome loss': 0.3342936747855898, 'Total loss': 0.3342936747855898}
2023-01-04 06:43:19,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:19,978 INFO:     Epoch: 71
2023-01-04 06:43:21,490 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41090428630510967, 'Total loss': 0.41090428630510967} | train loss {'Reaction outcome loss': 0.3499168867284965, 'Total loss': 0.3499168867284965}
2023-01-04 06:43:21,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:21,491 INFO:     Epoch: 72
2023-01-04 06:43:23,092 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39485596418380736, 'Total loss': 0.39485596418380736} | train loss {'Reaction outcome loss': 0.3054168810166419, 'Total loss': 0.3054168810166419}
2023-01-04 06:43:23,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:23,093 INFO:     Epoch: 73
2023-01-04 06:43:24,710 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3866917550563812, 'Total loss': 0.3866917550563812} | train loss {'Reaction outcome loss': 0.30494831543857825, 'Total loss': 0.30494831543857825}
2023-01-04 06:43:24,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:24,711 INFO:     Epoch: 74
2023-01-04 06:43:26,325 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4184802899758021, 'Total loss': 0.4184802899758021} | train loss {'Reaction outcome loss': 0.30132150542044983, 'Total loss': 0.30132150542044983}
2023-01-04 06:43:26,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:26,325 INFO:     Epoch: 75
2023-01-04 06:43:27,935 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38570443789164227, 'Total loss': 0.38570443789164227} | train loss {'Reaction outcome loss': 0.3074713023784368, 'Total loss': 0.3074713023784368}
2023-01-04 06:43:27,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:27,935 INFO:     Epoch: 76
2023-01-04 06:43:29,492 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4158510108788808, 'Total loss': 0.4158510108788808} | train loss {'Reaction outcome loss': 0.32313147117721214, 'Total loss': 0.32313147117721214}
2023-01-04 06:43:29,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:29,493 INFO:     Epoch: 77
2023-01-04 06:43:31,032 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4130751530329386, 'Total loss': 0.4130751530329386} | train loss {'Reaction outcome loss': 0.29924110791214026, 'Total loss': 0.29924110791214026}
2023-01-04 06:43:31,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:31,033 INFO:     Epoch: 78
2023-01-04 06:43:32,621 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38971022963523866, 'Total loss': 0.38971022963523866} | train loss {'Reaction outcome loss': 0.2935975049571741, 'Total loss': 0.2935975049571741}
2023-01-04 06:43:32,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:32,621 INFO:     Epoch: 79
2023-01-04 06:43:34,204 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4155278583367666, 'Total loss': 0.4155278583367666} | train loss {'Reaction outcome loss': 0.28961525743133004, 'Total loss': 0.28961525743133004}
2023-01-04 06:43:34,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:34,204 INFO:     Epoch: 80
2023-01-04 06:43:35,808 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38734349310398103, 'Total loss': 0.38734349310398103} | train loss {'Reaction outcome loss': 0.29286473043316946, 'Total loss': 0.29286473043316946}
2023-01-04 06:43:35,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:35,809 INFO:     Epoch: 81
2023-01-04 06:43:37,386 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41412853002548217, 'Total loss': 0.41412853002548217} | train loss {'Reaction outcome loss': 0.29415137588005996, 'Total loss': 0.29415137588005996}
2023-01-04 06:43:37,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:37,386 INFO:     Epoch: 82
2023-01-04 06:43:38,929 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36932182560364407, 'Total loss': 0.36932182560364407} | train loss {'Reaction outcome loss': 0.306724059541433, 'Total loss': 0.306724059541433}
2023-01-04 06:43:38,930 INFO:     Found new best model at epoch 82
2023-01-04 06:43:38,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:38,930 INFO:     Epoch: 83
2023-01-04 06:43:40,525 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3763118346532186, 'Total loss': 0.3763118346532186} | train loss {'Reaction outcome loss': 0.2861780761800153, 'Total loss': 0.2861780761800153}
2023-01-04 06:43:40,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:40,526 INFO:     Epoch: 84
2023-01-04 06:43:42,111 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3729308615128199, 'Total loss': 0.3729308615128199} | train loss {'Reaction outcome loss': 0.28259010828501696, 'Total loss': 0.28259010828501696}
2023-01-04 06:43:42,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:42,111 INFO:     Epoch: 85
2023-01-04 06:43:43,717 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37269664903481803, 'Total loss': 0.37269664903481803} | train loss {'Reaction outcome loss': 0.28233244962868176, 'Total loss': 0.28233244962868176}
2023-01-04 06:43:43,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:43,718 INFO:     Epoch: 86
2023-01-04 06:43:45,297 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38816282550493875, 'Total loss': 0.38816282550493875} | train loss {'Reaction outcome loss': 0.2790035054697554, 'Total loss': 0.2790035054697554}
2023-01-04 06:43:45,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:45,297 INFO:     Epoch: 87
2023-01-04 06:43:46,866 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4215542619427045, 'Total loss': 0.4215542619427045} | train loss {'Reaction outcome loss': 0.28405658468820044, 'Total loss': 0.28405658468820044}
2023-01-04 06:43:46,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:46,866 INFO:     Epoch: 88
2023-01-04 06:43:48,365 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4124811013539632, 'Total loss': 0.4124811013539632} | train loss {'Reaction outcome loss': 0.3274178469580585, 'Total loss': 0.3274178469580585}
2023-01-04 06:43:48,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:48,365 INFO:     Epoch: 89
2023-01-04 06:43:49,944 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3904783772925536, 'Total loss': 0.3904783772925536} | train loss {'Reaction outcome loss': 0.29652907434796943, 'Total loss': 0.29652907434796943}
2023-01-04 06:43:49,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:49,945 INFO:     Epoch: 90
2023-01-04 06:43:51,497 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4128943433364232, 'Total loss': 0.4128943433364232} | train loss {'Reaction outcome loss': 0.29426606282915757, 'Total loss': 0.29426606282915757}
2023-01-04 06:43:51,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:51,497 INFO:     Epoch: 91
2023-01-04 06:43:53,040 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4055848757425944, 'Total loss': 0.4055848757425944} | train loss {'Reaction outcome loss': 0.2860199956871245, 'Total loss': 0.2860199956871245}
2023-01-04 06:43:53,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:53,042 INFO:     Epoch: 92
2023-01-04 06:43:54,598 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4323249141375224, 'Total loss': 0.4323249141375224} | train loss {'Reaction outcome loss': 0.2839834286790827, 'Total loss': 0.2839834286790827}
2023-01-04 06:43:54,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:54,599 INFO:     Epoch: 93
2023-01-04 06:43:56,155 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42230390111605326, 'Total loss': 0.42230390111605326} | train loss {'Reaction outcome loss': 0.33014731261926866, 'Total loss': 0.33014731261926866}
2023-01-04 06:43:56,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:56,155 INFO:     Epoch: 94
2023-01-04 06:43:57,647 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3995445470015208, 'Total loss': 0.3995445470015208} | train loss {'Reaction outcome loss': 0.29246523612285574, 'Total loss': 0.29246523612285574}
2023-01-04 06:43:57,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:57,647 INFO:     Epoch: 95
2023-01-04 06:43:59,215 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42849984566370647, 'Total loss': 0.42849984566370647} | train loss {'Reaction outcome loss': 0.2820477556383264, 'Total loss': 0.2820477556383264}
2023-01-04 06:43:59,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:43:59,216 INFO:     Epoch: 96
2023-01-04 06:44:00,783 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.420794207851092, 'Total loss': 0.420794207851092} | train loss {'Reaction outcome loss': 0.2800851560373237, 'Total loss': 0.2800851560373237}
2023-01-04 06:44:00,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:00,783 INFO:     Epoch: 97
2023-01-04 06:44:02,338 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4023448834816615, 'Total loss': 0.4023448834816615} | train loss {'Reaction outcome loss': 0.2925697146658448, 'Total loss': 0.2925697146658448}
2023-01-04 06:44:02,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:02,338 INFO:     Epoch: 98
2023-01-04 06:44:03,897 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4102639317512512, 'Total loss': 0.4102639317512512} | train loss {'Reaction outcome loss': 0.276880485329615, 'Total loss': 0.276880485329615}
2023-01-04 06:44:03,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:03,897 INFO:     Epoch: 99
2023-01-04 06:44:05,462 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4236523156364759, 'Total loss': 0.4236523156364759} | train loss {'Reaction outcome loss': 0.29243348524028406, 'Total loss': 0.29243348524028406}
2023-01-04 06:44:05,462 INFO:     Best model found after epoch 83 of 100.
2023-01-04 06:44:05,462 INFO:   Done with stage: TRAINING
2023-01-04 06:44:05,462 INFO:   Starting stage: EVALUATION
2023-01-04 06:44:05,590 INFO:   Done with stage: EVALUATION
2023-01-04 06:44:05,590 INFO:   Leaving out SEQ value Fold_6
2023-01-04 06:44:05,602 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 06:44:05,602 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:44:06,249 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:44:06,249 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:44:06,319 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:44:06,319 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:44:06,319 INFO:     No hyperparam tuning for this model
2023-01-04 06:44:06,319 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:44:06,319 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:44:06,320 INFO:     None feature selector for col prot
2023-01-04 06:44:06,320 INFO:     None feature selector for col prot
2023-01-04 06:44:06,320 INFO:     None feature selector for col prot
2023-01-04 06:44:06,321 INFO:     None feature selector for col chem
2023-01-04 06:44:06,321 INFO:     None feature selector for col chem
2023-01-04 06:44:06,321 INFO:     None feature selector for col chem
2023-01-04 06:44:06,321 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:44:06,321 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:44:06,322 INFO:     Number of params in model 70111
2023-01-04 06:44:06,325 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:44:06,325 INFO:   Starting stage: TRAINING
2023-01-04 06:44:06,368 INFO:     Val loss before train {'Reaction outcome loss': 0.9893786350886027, 'Total loss': 0.9893786350886027}
2023-01-04 06:44:06,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:06,368 INFO:     Epoch: 0
2023-01-04 06:44:07,918 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7292189200719198, 'Total loss': 0.7292189200719198} | train loss {'Reaction outcome loss': 0.8240132652465186, 'Total loss': 0.8240132652465186}
2023-01-04 06:44:07,918 INFO:     Found new best model at epoch 0
2023-01-04 06:44:07,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:07,918 INFO:     Epoch: 1
2023-01-04 06:44:09,476 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6483755966027578, 'Total loss': 0.6483755966027578} | train loss {'Reaction outcome loss': 0.6607596447106303, 'Total loss': 0.6607596447106303}
2023-01-04 06:44:09,476 INFO:     Found new best model at epoch 1
2023-01-04 06:44:09,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:09,477 INFO:     Epoch: 2
2023-01-04 06:44:11,033 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5800144672393799, 'Total loss': 0.5800144672393799} | train loss {'Reaction outcome loss': 0.5837583105594243, 'Total loss': 0.5837583105594243}
2023-01-04 06:44:11,033 INFO:     Found new best model at epoch 2
2023-01-04 06:44:11,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:11,033 INFO:     Epoch: 3
2023-01-04 06:44:12,590 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5483967363834381, 'Total loss': 0.5483967363834381} | train loss {'Reaction outcome loss': 0.5402191217302845, 'Total loss': 0.5402191217302845}
2023-01-04 06:44:12,591 INFO:     Found new best model at epoch 3
2023-01-04 06:44:12,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:12,592 INFO:     Epoch: 4
2023-01-04 06:44:14,145 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5507966299851735, 'Total loss': 0.5507966299851735} | train loss {'Reaction outcome loss': 0.5253055201110427, 'Total loss': 0.5253055201110427}
2023-01-04 06:44:14,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:14,145 INFO:     Epoch: 5
2023-01-04 06:44:15,638 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5421788314978282, 'Total loss': 0.5421788314978282} | train loss {'Reaction outcome loss': 0.5041353926331558, 'Total loss': 0.5041353926331558}
2023-01-04 06:44:15,639 INFO:     Found new best model at epoch 5
2023-01-04 06:44:15,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:15,639 INFO:     Epoch: 6
2023-01-04 06:44:17,208 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5356053312619528, 'Total loss': 0.5356053312619528} | train loss {'Reaction outcome loss': 0.49543764972084264, 'Total loss': 0.49543764972084264}
2023-01-04 06:44:17,208 INFO:     Found new best model at epoch 6
2023-01-04 06:44:17,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:17,209 INFO:     Epoch: 7
2023-01-04 06:44:18,771 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.552527861793836, 'Total loss': 0.552527861793836} | train loss {'Reaction outcome loss': 0.4874168719410466, 'Total loss': 0.4874168719410466}
2023-01-04 06:44:18,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:18,771 INFO:     Epoch: 8
2023-01-04 06:44:20,328 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5415163199106853, 'Total loss': 0.5415163199106853} | train loss {'Reaction outcome loss': 0.47803949828289904, 'Total loss': 0.47803949828289904}
2023-01-04 06:44:20,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:20,329 INFO:     Epoch: 9
2023-01-04 06:44:21,892 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5097999741633733, 'Total loss': 0.5097999741633733} | train loss {'Reaction outcome loss': 0.4702213512000624, 'Total loss': 0.4702213512000624}
2023-01-04 06:44:21,893 INFO:     Found new best model at epoch 9
2023-01-04 06:44:21,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:21,893 INFO:     Epoch: 10
2023-01-04 06:44:23,469 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5321468432744344, 'Total loss': 0.5321468432744344} | train loss {'Reaction outcome loss': 0.46464403898922546, 'Total loss': 0.46464403898922546}
2023-01-04 06:44:23,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:23,469 INFO:     Epoch: 11
2023-01-04 06:44:24,973 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4974505583445231, 'Total loss': 0.4974505583445231} | train loss {'Reaction outcome loss': 0.4599069657093351, 'Total loss': 0.4599069657093351}
2023-01-04 06:44:24,974 INFO:     Found new best model at epoch 11
2023-01-04 06:44:24,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:24,974 INFO:     Epoch: 12
2023-01-04 06:44:26,526 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5107183853785197, 'Total loss': 0.5107183853785197} | train loss {'Reaction outcome loss': 0.4528932574638821, 'Total loss': 0.4528932574638821}
2023-01-04 06:44:26,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:26,526 INFO:     Epoch: 13
2023-01-04 06:44:28,071 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5210878113905589, 'Total loss': 0.5210878113905589} | train loss {'Reaction outcome loss': 0.4459710469745126, 'Total loss': 0.4459710469745126}
2023-01-04 06:44:28,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:28,072 INFO:     Epoch: 14
2023-01-04 06:44:29,626 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5085182269414266, 'Total loss': 0.5085182269414266} | train loss {'Reaction outcome loss': 0.4462262158036662, 'Total loss': 0.4462262158036662}
2023-01-04 06:44:29,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:29,626 INFO:     Epoch: 15
2023-01-04 06:44:31,178 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5430014987786611, 'Total loss': 0.5430014987786611} | train loss {'Reaction outcome loss': 0.43989765181438156, 'Total loss': 0.43989765181438156}
2023-01-04 06:44:31,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:31,178 INFO:     Epoch: 16
2023-01-04 06:44:32,699 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49755423069000243, 'Total loss': 0.49755423069000243} | train loss {'Reaction outcome loss': 0.4309978056900768, 'Total loss': 0.4309978056900768}
2023-01-04 06:44:32,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:32,699 INFO:     Epoch: 17
2023-01-04 06:44:34,224 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4986828009287516, 'Total loss': 0.4986828009287516} | train loss {'Reaction outcome loss': 0.42690035800318427, 'Total loss': 0.42690035800318427}
2023-01-04 06:44:34,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:34,225 INFO:     Epoch: 18
2023-01-04 06:44:35,769 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49344830711682636, 'Total loss': 0.49344830711682636} | train loss {'Reaction outcome loss': 0.42086896402525986, 'Total loss': 0.42086896402525986}
2023-01-04 06:44:35,769 INFO:     Found new best model at epoch 18
2023-01-04 06:44:35,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:35,770 INFO:     Epoch: 19
2023-01-04 06:44:37,313 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48185326556364694, 'Total loss': 0.48185326556364694} | train loss {'Reaction outcome loss': 0.4205779260031153, 'Total loss': 0.4205779260031153}
2023-01-04 06:44:37,313 INFO:     Found new best model at epoch 19
2023-01-04 06:44:37,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:37,314 INFO:     Epoch: 20
2023-01-04 06:44:38,862 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4997356911500295, 'Total loss': 0.4997356911500295} | train loss {'Reaction outcome loss': 0.4115655616409942, 'Total loss': 0.4115655616409942}
2023-01-04 06:44:38,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:38,862 INFO:     Epoch: 21
2023-01-04 06:44:40,419 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49705562790234886, 'Total loss': 0.49705562790234886} | train loss {'Reaction outcome loss': 0.4131139091851479, 'Total loss': 0.4131139091851479}
2023-01-04 06:44:40,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:40,420 INFO:     Epoch: 22
2023-01-04 06:44:41,943 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4810654819011688, 'Total loss': 0.4810654819011688} | train loss {'Reaction outcome loss': 0.40552370607960525, 'Total loss': 0.40552370607960525}
2023-01-04 06:44:41,943 INFO:     Found new best model at epoch 22
2023-01-04 06:44:41,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:41,944 INFO:     Epoch: 23
2023-01-04 06:44:43,461 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.466573957602183, 'Total loss': 0.466573957602183} | train loss {'Reaction outcome loss': 0.40571032851826844, 'Total loss': 0.40571032851826844}
2023-01-04 06:44:43,461 INFO:     Found new best model at epoch 23
2023-01-04 06:44:43,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:43,462 INFO:     Epoch: 24
2023-01-04 06:44:45,011 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4622568964958191, 'Total loss': 0.4622568964958191} | train loss {'Reaction outcome loss': 0.400003010077597, 'Total loss': 0.400003010077597}
2023-01-04 06:44:45,012 INFO:     Found new best model at epoch 24
2023-01-04 06:44:45,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:45,012 INFO:     Epoch: 25
2023-01-04 06:44:46,576 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4912737717231115, 'Total loss': 0.4912737717231115} | train loss {'Reaction outcome loss': 0.3963907429618956, 'Total loss': 0.3963907429618956}
2023-01-04 06:44:46,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:46,577 INFO:     Epoch: 26
2023-01-04 06:44:48,126 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47081146836280824, 'Total loss': 0.47081146836280824} | train loss {'Reaction outcome loss': 0.3899176244755084, 'Total loss': 0.3899176244755084}
2023-01-04 06:44:48,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:48,127 INFO:     Epoch: 27
2023-01-04 06:44:49,676 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4670017311970393, 'Total loss': 0.4670017311970393} | train loss {'Reaction outcome loss': 0.3894201998568614, 'Total loss': 0.3894201998568614}
2023-01-04 06:44:49,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:49,676 INFO:     Epoch: 28
2023-01-04 06:44:51,186 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5002355128526688, 'Total loss': 0.5002355128526688} | train loss {'Reaction outcome loss': 0.3801156938721557, 'Total loss': 0.3801156938721557}
2023-01-04 06:44:51,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:51,186 INFO:     Epoch: 29
2023-01-04 06:44:52,716 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5032737811406454, 'Total loss': 0.5032737811406454} | train loss {'Reaction outcome loss': 0.38207582276758306, 'Total loss': 0.38207582276758306}
2023-01-04 06:44:52,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:52,717 INFO:     Epoch: 30
2023-01-04 06:44:54,271 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45564019282658896, 'Total loss': 0.45564019282658896} | train loss {'Reaction outcome loss': 0.37672932524005426, 'Total loss': 0.37672932524005426}
2023-01-04 06:44:54,271 INFO:     Found new best model at epoch 30
2023-01-04 06:44:54,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:54,272 INFO:     Epoch: 31
2023-01-04 06:44:55,831 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46310616433620455, 'Total loss': 0.46310616433620455} | train loss {'Reaction outcome loss': 0.3698816053461727, 'Total loss': 0.3698816053461727}
2023-01-04 06:44:55,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:55,831 INFO:     Epoch: 32
2023-01-04 06:44:57,378 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46703513264656066, 'Total loss': 0.46703513264656066} | train loss {'Reaction outcome loss': 0.37289471181936645, 'Total loss': 0.37289471181936645}
2023-01-04 06:44:57,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:57,379 INFO:     Epoch: 33
2023-01-04 06:44:58,942 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45484187801678977, 'Total loss': 0.45484187801678977} | train loss {'Reaction outcome loss': 0.3699929006532211, 'Total loss': 0.3699929006532211}
2023-01-04 06:44:58,943 INFO:     Found new best model at epoch 33
2023-01-04 06:44:58,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:44:58,944 INFO:     Epoch: 34
2023-01-04 06:45:00,449 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5240484813849131, 'Total loss': 0.5240484813849131} | train loss {'Reaction outcome loss': 0.36349448281935404, 'Total loss': 0.36349448281935404}
2023-01-04 06:45:00,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:00,449 INFO:     Epoch: 35
2023-01-04 06:45:02,000 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4565197358528773, 'Total loss': 0.4565197358528773} | train loss {'Reaction outcome loss': 0.35685300794749486, 'Total loss': 0.35685300794749486}
2023-01-04 06:45:02,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:02,000 INFO:     Epoch: 36
2023-01-04 06:45:03,552 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4564232250054677, 'Total loss': 0.4564232250054677} | train loss {'Reaction outcome loss': 0.35944841882812417, 'Total loss': 0.35944841882812417}
2023-01-04 06:45:03,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:03,552 INFO:     Epoch: 37
2023-01-04 06:45:05,116 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45568509300549825, 'Total loss': 0.45568509300549825} | train loss {'Reaction outcome loss': 0.35117039918254, 'Total loss': 0.35117039918254}
2023-01-04 06:45:05,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:05,117 INFO:     Epoch: 38
2023-01-04 06:45:06,681 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4585075706243515, 'Total loss': 0.4585075706243515} | train loss {'Reaction outcome loss': 0.351428021189323, 'Total loss': 0.351428021189323}
2023-01-04 06:45:06,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:06,681 INFO:     Epoch: 39
2023-01-04 06:45:08,228 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4386356850465139, 'Total loss': 0.4386356850465139} | train loss {'Reaction outcome loss': 0.34467471345237016, 'Total loss': 0.34467471345237016}
2023-01-04 06:45:08,228 INFO:     Found new best model at epoch 39
2023-01-04 06:45:08,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:08,229 INFO:     Epoch: 40
2023-01-04 06:45:09,714 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4593173841635386, 'Total loss': 0.4593173841635386} | train loss {'Reaction outcome loss': 0.3472413684002759, 'Total loss': 0.3472413684002759}
2023-01-04 06:45:09,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:09,714 INFO:     Epoch: 41
2023-01-04 06:45:11,279 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45208568970362345, 'Total loss': 0.45208568970362345} | train loss {'Reaction outcome loss': 0.3444317975199179, 'Total loss': 0.3444317975199179}
2023-01-04 06:45:11,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:11,279 INFO:     Epoch: 42
2023-01-04 06:45:12,839 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44642883936564126, 'Total loss': 0.44642883936564126} | train loss {'Reaction outcome loss': 0.3401358170360865, 'Total loss': 0.3401358170360865}
2023-01-04 06:45:12,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:12,839 INFO:     Epoch: 43
2023-01-04 06:45:14,405 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4624682048956553, 'Total loss': 0.4624682048956553} | train loss {'Reaction outcome loss': 0.33479673184104775, 'Total loss': 0.33479673184104775}
2023-01-04 06:45:14,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:14,405 INFO:     Epoch: 44
2023-01-04 06:45:15,964 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4425823539495468, 'Total loss': 0.4425823539495468} | train loss {'Reaction outcome loss': 0.33342215359641325, 'Total loss': 0.33342215359641325}
2023-01-04 06:45:15,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:15,965 INFO:     Epoch: 45
2023-01-04 06:45:17,515 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45810228685537974, 'Total loss': 0.45810228685537974} | train loss {'Reaction outcome loss': 0.3293327752648708, 'Total loss': 0.3293327752648708}
2023-01-04 06:45:17,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:17,516 INFO:     Epoch: 46
2023-01-04 06:45:19,007 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4521092305580775, 'Total loss': 0.4521092305580775} | train loss {'Reaction outcome loss': 0.3297006535454778, 'Total loss': 0.3297006535454778}
2023-01-04 06:45:19,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:19,007 INFO:     Epoch: 47
2023-01-04 06:45:20,570 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45349866449832915, 'Total loss': 0.45349866449832915} | train loss {'Reaction outcome loss': 0.3261949528371814, 'Total loss': 0.3261949528371814}
2023-01-04 06:45:20,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:20,570 INFO:     Epoch: 48
2023-01-04 06:45:22,120 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4607791503270467, 'Total loss': 0.4607791503270467} | train loss {'Reaction outcome loss': 0.3250024296908172, 'Total loss': 0.3250024296908172}
2023-01-04 06:45:22,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:22,120 INFO:     Epoch: 49
2023-01-04 06:45:23,673 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45803843438625336, 'Total loss': 0.45803843438625336} | train loss {'Reaction outcome loss': 0.3186961501729187, 'Total loss': 0.3186961501729187}
2023-01-04 06:45:23,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:23,673 INFO:     Epoch: 50
2023-01-04 06:45:25,227 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4633378177881241, 'Total loss': 0.4633378177881241} | train loss {'Reaction outcome loss': 0.3171577345754696, 'Total loss': 0.3171577345754696}
2023-01-04 06:45:25,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:25,227 INFO:     Epoch: 51
2023-01-04 06:45:26,785 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44088794887065885, 'Total loss': 0.44088794887065885} | train loss {'Reaction outcome loss': 0.3215881865538845, 'Total loss': 0.3215881865538845}
2023-01-04 06:45:26,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:26,785 INFO:     Epoch: 52
2023-01-04 06:45:28,282 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44565755128860474, 'Total loss': 0.44565755128860474} | train loss {'Reaction outcome loss': 0.3157254139815427, 'Total loss': 0.3157254139815427}
2023-01-04 06:45:28,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:28,283 INFO:     Epoch: 53
2023-01-04 06:45:29,840 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45604804356892903, 'Total loss': 0.45604804356892903} | train loss {'Reaction outcome loss': 0.31095743835617917, 'Total loss': 0.31095743835617917}
2023-01-04 06:45:29,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:29,842 INFO:     Epoch: 54
2023-01-04 06:45:31,394 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.449237185716629, 'Total loss': 0.449237185716629} | train loss {'Reaction outcome loss': 0.3140649774014304, 'Total loss': 0.3140649774014304}
2023-01-04 06:45:31,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:31,394 INFO:     Epoch: 55
2023-01-04 06:45:32,955 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4271402726570765, 'Total loss': 0.4271402726570765} | train loss {'Reaction outcome loss': 0.3121798506228502, 'Total loss': 0.3121798506228502}
2023-01-04 06:45:32,955 INFO:     Found new best model at epoch 55
2023-01-04 06:45:32,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:32,956 INFO:     Epoch: 56
2023-01-04 06:45:34,515 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43454099595546725, 'Total loss': 0.43454099595546725} | train loss {'Reaction outcome loss': 0.3089586349762304, 'Total loss': 0.3089586349762304}
2023-01-04 06:45:34,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:34,515 INFO:     Epoch: 57
2023-01-04 06:45:36,064 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43635984857877097, 'Total loss': 0.43635984857877097} | train loss {'Reaction outcome loss': 0.30753070363499196, 'Total loss': 0.30753070363499196}
2023-01-04 06:45:36,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:36,065 INFO:     Epoch: 58
2023-01-04 06:45:37,565 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4203649997711182, 'Total loss': 0.4203649997711182} | train loss {'Reaction outcome loss': 0.30411988289670394, 'Total loss': 0.30411988289670394}
2023-01-04 06:45:37,565 INFO:     Found new best model at epoch 58
2023-01-04 06:45:37,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:37,566 INFO:     Epoch: 59
2023-01-04 06:45:39,124 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4202635198831558, 'Total loss': 0.4202635198831558} | train loss {'Reaction outcome loss': 0.3020201793431375, 'Total loss': 0.3020201793431375}
2023-01-04 06:45:39,124 INFO:     Found new best model at epoch 59
2023-01-04 06:45:39,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:39,125 INFO:     Epoch: 60
2023-01-04 06:45:40,691 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46052846908569334, 'Total loss': 0.46052846908569334} | train loss {'Reaction outcome loss': 0.30370746977923146, 'Total loss': 0.30370746977923146}
2023-01-04 06:45:40,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:40,692 INFO:     Epoch: 61
2023-01-04 06:45:42,245 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42417954007784525, 'Total loss': 0.42417954007784525} | train loss {'Reaction outcome loss': 0.3023517516976229, 'Total loss': 0.3023517516976229}
2023-01-04 06:45:42,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:42,246 INFO:     Epoch: 62
2023-01-04 06:45:43,800 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4492460697889328, 'Total loss': 0.4492460697889328} | train loss {'Reaction outcome loss': 0.2999528598591739, 'Total loss': 0.2999528598591739}
2023-01-04 06:45:43,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:43,800 INFO:     Epoch: 63
2023-01-04 06:45:45,333 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4663250188032786, 'Total loss': 0.4663250188032786} | train loss {'Reaction outcome loss': 0.298449058852256, 'Total loss': 0.298449058852256}
2023-01-04 06:45:45,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:45,333 INFO:     Epoch: 64
2023-01-04 06:45:46,857 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4456072648366292, 'Total loss': 0.4456072648366292} | train loss {'Reaction outcome loss': 0.2983106016467194, 'Total loss': 0.2983106016467194}
2023-01-04 06:45:46,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:46,858 INFO:     Epoch: 65
2023-01-04 06:45:48,438 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4499547054370244, 'Total loss': 0.4499547054370244} | train loss {'Reaction outcome loss': 0.2934752579657395, 'Total loss': 0.2934752579657395}
2023-01-04 06:45:48,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:48,439 INFO:     Epoch: 66
2023-01-04 06:45:50,009 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43258984833955766, 'Total loss': 0.43258984833955766} | train loss {'Reaction outcome loss': 0.2953375532470025, 'Total loss': 0.2953375532470025}
2023-01-04 06:45:50,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:50,009 INFO:     Epoch: 67
2023-01-04 06:45:51,567 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45866666436195375, 'Total loss': 0.45866666436195375} | train loss {'Reaction outcome loss': 0.29209975664258436, 'Total loss': 0.29209975664258436}
2023-01-04 06:45:51,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:51,567 INFO:     Epoch: 68
2023-01-04 06:45:53,119 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44328744808832804, 'Total loss': 0.44328744808832804} | train loss {'Reaction outcome loss': 0.29068210989989957, 'Total loss': 0.29068210989989957}
2023-01-04 06:45:53,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:53,120 INFO:     Epoch: 69
2023-01-04 06:45:54,649 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46298526326815287, 'Total loss': 0.46298526326815287} | train loss {'Reaction outcome loss': 0.288709061885999, 'Total loss': 0.288709061885999}
2023-01-04 06:45:54,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:54,649 INFO:     Epoch: 70
2023-01-04 06:45:56,187 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45531890690326693, 'Total loss': 0.45531890690326693} | train loss {'Reaction outcome loss': 0.28494308679112457, 'Total loss': 0.28494308679112457}
2023-01-04 06:45:56,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:56,187 INFO:     Epoch: 71
2023-01-04 06:45:57,745 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44786992222070693, 'Total loss': 0.44786992222070693} | train loss {'Reaction outcome loss': 0.2900164265871478, 'Total loss': 0.2900164265871478}
2023-01-04 06:45:57,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:57,745 INFO:     Epoch: 72
2023-01-04 06:45:59,310 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4799651215473811, 'Total loss': 0.4799651215473811} | train loss {'Reaction outcome loss': 0.2859536959967889, 'Total loss': 0.2859536959967889}
2023-01-04 06:45:59,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:45:59,310 INFO:     Epoch: 73
2023-01-04 06:46:00,896 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44665241837501524, 'Total loss': 0.44665241837501524} | train loss {'Reaction outcome loss': 0.28205989228581696, 'Total loss': 0.28205989228581696}
2023-01-04 06:46:00,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:00,896 INFO:     Epoch: 74
2023-01-04 06:46:02,475 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4556461930274963, 'Total loss': 0.4556461930274963} | train loss {'Reaction outcome loss': 0.28067747288339834, 'Total loss': 0.28067747288339834}
2023-01-04 06:46:02,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:02,475 INFO:     Epoch: 75
2023-01-04 06:46:03,992 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.432766917347908, 'Total loss': 0.432766917347908} | train loss {'Reaction outcome loss': 0.2805030238999572, 'Total loss': 0.2805030238999572}
2023-01-04 06:46:03,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:03,992 INFO:     Epoch: 76
2023-01-04 06:46:05,557 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4528010427951813, 'Total loss': 0.4528010427951813} | train loss {'Reaction outcome loss': 0.27651467120496803, 'Total loss': 0.27651467120496803}
2023-01-04 06:46:05,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:05,558 INFO:     Epoch: 77
2023-01-04 06:46:07,192 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4404511193434397, 'Total loss': 0.4404511193434397} | train loss {'Reaction outcome loss': 0.2783423174132294, 'Total loss': 0.2783423174132294}
2023-01-04 06:46:07,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:07,193 INFO:     Epoch: 78
2023-01-04 06:46:08,831 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42914628187815346, 'Total loss': 0.42914628187815346} | train loss {'Reaction outcome loss': 0.2760388978659461, 'Total loss': 0.2760388978659461}
2023-01-04 06:46:08,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:08,832 INFO:     Epoch: 79
2023-01-04 06:46:10,469 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4123883922894796, 'Total loss': 0.4123883922894796} | train loss {'Reaction outcome loss': 0.2720246862230103, 'Total loss': 0.2720246862230103}
2023-01-04 06:46:10,469 INFO:     Found new best model at epoch 79
2023-01-04 06:46:10,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:10,470 INFO:     Epoch: 80
2023-01-04 06:46:12,098 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44795291423797606, 'Total loss': 0.44795291423797606} | train loss {'Reaction outcome loss': 0.2687551532115532, 'Total loss': 0.2687551532115532}
2023-01-04 06:46:12,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:12,099 INFO:     Epoch: 81
2023-01-04 06:46:13,635 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4682835300763448, 'Total loss': 0.4682835300763448} | train loss {'Reaction outcome loss': 0.2685488646964304, 'Total loss': 0.2685488646964304}
2023-01-04 06:46:13,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:13,635 INFO:     Epoch: 82
2023-01-04 06:46:15,271 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45852522452672323, 'Total loss': 0.45852522452672323} | train loss {'Reaction outcome loss': 0.27240350425566145, 'Total loss': 0.27240350425566145}
2023-01-04 06:46:15,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:15,271 INFO:     Epoch: 83
2023-01-04 06:46:16,911 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4572898666063944, 'Total loss': 0.4572898666063944} | train loss {'Reaction outcome loss': 0.268842300958259, 'Total loss': 0.268842300958259}
2023-01-04 06:46:16,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:16,912 INFO:     Epoch: 84
2023-01-04 06:46:18,548 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4659507383902868, 'Total loss': 0.4659507383902868} | train loss {'Reaction outcome loss': 0.26835986428527625, 'Total loss': 0.26835986428527625}
2023-01-04 06:46:18,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:18,548 INFO:     Epoch: 85
2023-01-04 06:46:20,186 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4377424955368042, 'Total loss': 0.4377424955368042} | train loss {'Reaction outcome loss': 0.2672630055044317, 'Total loss': 0.2672630055044317}
2023-01-04 06:46:20,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:20,186 INFO:     Epoch: 86
2023-01-04 06:46:21,779 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43026697834332783, 'Total loss': 0.43026697834332783} | train loss {'Reaction outcome loss': 0.2672126763080001, 'Total loss': 0.2672126763080001}
2023-01-04 06:46:21,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:21,779 INFO:     Epoch: 87
2023-01-04 06:46:23,365 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43466601669788363, 'Total loss': 0.43466601669788363} | train loss {'Reaction outcome loss': 0.26616075733131883, 'Total loss': 0.26616075733131883}
2023-01-04 06:46:23,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:23,366 INFO:     Epoch: 88
2023-01-04 06:46:24,927 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4531123528877894, 'Total loss': 0.4531123528877894} | train loss {'Reaction outcome loss': 0.26320043861166664, 'Total loss': 0.26320043861166664}
2023-01-04 06:46:24,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:24,928 INFO:     Epoch: 89
2023-01-04 06:46:26,565 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4396457036336263, 'Total loss': 0.4396457036336263} | train loss {'Reaction outcome loss': 0.26617922442914776, 'Total loss': 0.26617922442914776}
2023-01-04 06:46:26,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:26,565 INFO:     Epoch: 90
2023-01-04 06:46:28,149 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44610812862714133, 'Total loss': 0.44610812862714133} | train loss {'Reaction outcome loss': 0.26359629698285986, 'Total loss': 0.26359629698285986}
2023-01-04 06:46:28,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:28,150 INFO:     Epoch: 91
2023-01-04 06:46:29,729 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43492379089196526, 'Total loss': 0.43492379089196526} | train loss {'Reaction outcome loss': 0.261445905488751, 'Total loss': 0.261445905488751}
2023-01-04 06:46:29,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:29,729 INFO:     Epoch: 92
2023-01-04 06:46:31,244 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4743319968382517, 'Total loss': 0.4743319968382517} | train loss {'Reaction outcome loss': 0.261958478240545, 'Total loss': 0.261958478240545}
2023-01-04 06:46:31,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:31,244 INFO:     Epoch: 93
2023-01-04 06:46:32,813 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44842514793078103, 'Total loss': 0.44842514793078103} | train loss {'Reaction outcome loss': 0.25999730738007637, 'Total loss': 0.25999730738007637}
2023-01-04 06:46:32,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:32,813 INFO:     Epoch: 94
2023-01-04 06:46:34,399 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4283408249417941, 'Total loss': 0.4283408249417941} | train loss {'Reaction outcome loss': 0.25701432143899505, 'Total loss': 0.25701432143899505}
2023-01-04 06:46:34,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:34,399 INFO:     Epoch: 95
2023-01-04 06:46:35,973 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4640913208325704, 'Total loss': 0.4640913208325704} | train loss {'Reaction outcome loss': 0.254266513329981, 'Total loss': 0.254266513329981}
2023-01-04 06:46:35,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:35,974 INFO:     Epoch: 96
2023-01-04 06:46:37,591 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.446619979540507, 'Total loss': 0.446619979540507} | train loss {'Reaction outcome loss': 0.2567227327732188, 'Total loss': 0.2567227327732188}
2023-01-04 06:46:37,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:37,591 INFO:     Epoch: 97
2023-01-04 06:46:39,229 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4202177405357361, 'Total loss': 0.4202177405357361} | train loss {'Reaction outcome loss': 0.2542372644620036, 'Total loss': 0.2542372644620036}
2023-01-04 06:46:39,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:39,229 INFO:     Epoch: 98
2023-01-04 06:46:40,775 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4297975937525431, 'Total loss': 0.4297975937525431} | train loss {'Reaction outcome loss': 0.25285988592875563, 'Total loss': 0.25285988592875563}
2023-01-04 06:46:40,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:40,776 INFO:     Epoch: 99
2023-01-04 06:46:42,395 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4392451484998067, 'Total loss': 0.4392451484998067} | train loss {'Reaction outcome loss': 0.25911733322517966, 'Total loss': 0.25911733322517966}
2023-01-04 06:46:42,396 INFO:     Best model found after epoch 80 of 100.
2023-01-04 06:46:42,396 INFO:   Done with stage: TRAINING
2023-01-04 06:46:42,396 INFO:   Starting stage: EVALUATION
2023-01-04 06:46:42,519 INFO:   Done with stage: EVALUATION
2023-01-04 06:46:42,519 INFO:   Leaving out SEQ value Fold_7
2023-01-04 06:46:42,532 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 06:46:42,532 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:46:43,180 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:46:43,180 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:46:43,249 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:46:43,249 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:46:43,249 INFO:     No hyperparam tuning for this model
2023-01-04 06:46:43,249 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:46:43,249 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:46:43,250 INFO:     None feature selector for col prot
2023-01-04 06:46:43,250 INFO:     None feature selector for col prot
2023-01-04 06:46:43,250 INFO:     None feature selector for col prot
2023-01-04 06:46:43,251 INFO:     None feature selector for col chem
2023-01-04 06:46:43,251 INFO:     None feature selector for col chem
2023-01-04 06:46:43,251 INFO:     None feature selector for col chem
2023-01-04 06:46:43,251 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:46:43,251 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:46:43,252 INFO:     Number of params in model 70111
2023-01-04 06:46:43,255 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:46:43,256 INFO:   Starting stage: TRAINING
2023-01-04 06:46:43,298 INFO:     Val loss before train {'Reaction outcome loss': 1.041097911198934, 'Total loss': 1.041097911198934}
2023-01-04 06:46:43,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:43,298 INFO:     Epoch: 0
2023-01-04 06:46:44,917 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7537050823370616, 'Total loss': 0.7537050823370616} | train loss {'Reaction outcome loss': 0.834874788013688, 'Total loss': 0.834874788013688}
2023-01-04 06:46:44,917 INFO:     Found new best model at epoch 0
2023-01-04 06:46:44,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:44,918 INFO:     Epoch: 1
2023-01-04 06:46:46,534 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6263576825459798, 'Total loss': 0.6263576825459798} | train loss {'Reaction outcome loss': 0.681449228829711, 'Total loss': 0.681449228829711}
2023-01-04 06:46:46,534 INFO:     Found new best model at epoch 1
2023-01-04 06:46:46,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:46,535 INFO:     Epoch: 2
2023-01-04 06:46:48,154 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.582179601987203, 'Total loss': 0.582179601987203} | train loss {'Reaction outcome loss': 0.5822180278979949, 'Total loss': 0.5822180278979949}
2023-01-04 06:46:48,154 INFO:     Found new best model at epoch 2
2023-01-04 06:46:48,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:48,155 INFO:     Epoch: 3
2023-01-04 06:46:49,668 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5286085665225982, 'Total loss': 0.5286085665225982} | train loss {'Reaction outcome loss': 0.5444805495386577, 'Total loss': 0.5444805495386577}
2023-01-04 06:46:49,668 INFO:     Found new best model at epoch 3
2023-01-04 06:46:49,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:49,669 INFO:     Epoch: 4
2023-01-04 06:46:51,235 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5284391979376475, 'Total loss': 0.5284391979376475} | train loss {'Reaction outcome loss': 0.518091751439293, 'Total loss': 0.518091751439293}
2023-01-04 06:46:51,235 INFO:     Found new best model at epoch 4
2023-01-04 06:46:51,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:51,235 INFO:     Epoch: 5
2023-01-04 06:46:52,786 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49328772226969403, 'Total loss': 0.49328772226969403} | train loss {'Reaction outcome loss': 0.507472421620449, 'Total loss': 0.507472421620449}
2023-01-04 06:46:52,786 INFO:     Found new best model at epoch 5
2023-01-04 06:46:52,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:52,787 INFO:     Epoch: 6
2023-01-04 06:46:54,337 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4678536186615626, 'Total loss': 0.4678536186615626} | train loss {'Reaction outcome loss': 0.49001117366073776, 'Total loss': 0.49001117366073776}
2023-01-04 06:46:54,337 INFO:     Found new best model at epoch 6
2023-01-04 06:46:54,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:54,338 INFO:     Epoch: 7
2023-01-04 06:46:55,907 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.483530060450236, 'Total loss': 0.483530060450236} | train loss {'Reaction outcome loss': 0.4847140594446746, 'Total loss': 0.4847140594446746}
2023-01-04 06:46:55,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:55,908 INFO:     Epoch: 8
2023-01-04 06:46:57,466 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4703275223573049, 'Total loss': 0.4703275223573049} | train loss {'Reaction outcome loss': 0.4773513716067711, 'Total loss': 0.4773513716067711}
2023-01-04 06:46:57,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:57,466 INFO:     Epoch: 9
2023-01-04 06:46:58,960 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45023703773816426, 'Total loss': 0.45023703773816426} | train loss {'Reaction outcome loss': 0.4702033986792947, 'Total loss': 0.4702033986792947}
2023-01-04 06:46:58,960 INFO:     Found new best model at epoch 9
2023-01-04 06:46:58,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:46:58,961 INFO:     Epoch: 10
2023-01-04 06:47:00,516 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45555059413115184, 'Total loss': 0.45555059413115184} | train loss {'Reaction outcome loss': 0.4655928101635327, 'Total loss': 0.4655928101635327}
2023-01-04 06:47:00,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:00,516 INFO:     Epoch: 11
2023-01-04 06:47:02,058 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4872478783130646, 'Total loss': 0.4872478783130646} | train loss {'Reaction outcome loss': 0.45578525068551085, 'Total loss': 0.45578525068551085}
2023-01-04 06:47:02,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:02,058 INFO:     Epoch: 12
2023-01-04 06:47:03,586 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4223319003979365, 'Total loss': 0.4223319003979365} | train loss {'Reaction outcome loss': 0.45531075567442136, 'Total loss': 0.45531075567442136}
2023-01-04 06:47:03,586 INFO:     Found new best model at epoch 12
2023-01-04 06:47:03,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:03,587 INFO:     Epoch: 13
2023-01-04 06:47:05,122 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44557055036226906, 'Total loss': 0.44557055036226906} | train loss {'Reaction outcome loss': 0.4471587957474437, 'Total loss': 0.4471587957474437}
2023-01-04 06:47:05,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:05,122 INFO:     Epoch: 14
2023-01-04 06:47:06,662 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44014678299427035, 'Total loss': 0.44014678299427035} | train loss {'Reaction outcome loss': 0.44405822833850433, 'Total loss': 0.44405822833850433}
2023-01-04 06:47:06,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:06,663 INFO:     Epoch: 15
2023-01-04 06:47:08,157 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4309737910827001, 'Total loss': 0.4309737910827001} | train loss {'Reaction outcome loss': 0.43388160943549914, 'Total loss': 0.43388160943549914}
2023-01-04 06:47:08,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:08,158 INFO:     Epoch: 16
2023-01-04 06:47:09,689 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48357876141866046, 'Total loss': 0.48357876141866046} | train loss {'Reaction outcome loss': 0.4334360696103451, 'Total loss': 0.4334360696103451}
2023-01-04 06:47:09,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:09,689 INFO:     Epoch: 17
2023-01-04 06:47:11,233 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4270767370859782, 'Total loss': 0.4270767370859782} | train loss {'Reaction outcome loss': 0.42780910383393295, 'Total loss': 0.42780910383393295}
2023-01-04 06:47:11,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:11,234 INFO:     Epoch: 18
2023-01-04 06:47:12,777 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4401947408914566, 'Total loss': 0.4401947408914566} | train loss {'Reaction outcome loss': 0.4212021438309746, 'Total loss': 0.4212021438309746}
2023-01-04 06:47:12,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:12,778 INFO:     Epoch: 19
2023-01-04 06:47:14,316 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4375814735889435, 'Total loss': 0.4375814735889435} | train loss {'Reaction outcome loss': 0.41745802768281776, 'Total loss': 0.41745802768281776}
2023-01-04 06:47:14,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:14,316 INFO:     Epoch: 20
2023-01-04 06:47:15,835 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44137299954891207, 'Total loss': 0.44137299954891207} | train loss {'Reaction outcome loss': 0.41389983566137994, 'Total loss': 0.41389983566137994}
2023-01-04 06:47:15,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:15,835 INFO:     Epoch: 21
2023-01-04 06:47:17,336 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4319297393163045, 'Total loss': 0.4319297393163045} | train loss {'Reaction outcome loss': 0.4078395707111289, 'Total loss': 0.4078395707111289}
2023-01-04 06:47:17,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:17,336 INFO:     Epoch: 22
2023-01-04 06:47:18,886 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4307608892520269, 'Total loss': 0.4307608892520269} | train loss {'Reaction outcome loss': 0.40893199990918166, 'Total loss': 0.40893199990918166}
2023-01-04 06:47:18,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:18,886 INFO:     Epoch: 23
2023-01-04 06:47:20,439 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41884217063585916, 'Total loss': 0.41884217063585916} | train loss {'Reaction outcome loss': 0.40439223982121825, 'Total loss': 0.40439223982121825}
2023-01-04 06:47:20,440 INFO:     Found new best model at epoch 23
2023-01-04 06:47:20,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:20,440 INFO:     Epoch: 24
2023-01-04 06:47:21,975 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40870545456806817, 'Total loss': 0.40870545456806817} | train loss {'Reaction outcome loss': 0.4004494728941987, 'Total loss': 0.4004494728941987}
2023-01-04 06:47:21,976 INFO:     Found new best model at epoch 24
2023-01-04 06:47:21,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:21,976 INFO:     Epoch: 25
2023-01-04 06:47:23,504 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4341692507266998, 'Total loss': 0.4341692507266998} | train loss {'Reaction outcome loss': 0.39822365349009087, 'Total loss': 0.39822365349009087}
2023-01-04 06:47:23,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:23,504 INFO:     Epoch: 26
2023-01-04 06:47:25,009 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4127871811389923, 'Total loss': 0.4127871811389923} | train loss {'Reaction outcome loss': 0.3946217909781602, 'Total loss': 0.3946217909781602}
2023-01-04 06:47:25,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:25,010 INFO:     Epoch: 27
2023-01-04 06:47:26,509 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4216697682936986, 'Total loss': 0.4216697682936986} | train loss {'Reaction outcome loss': 0.38686536105662367, 'Total loss': 0.38686536105662367}
2023-01-04 06:47:26,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:26,510 INFO:     Epoch: 28
2023-01-04 06:47:28,048 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42304515540599824, 'Total loss': 0.42304515540599824} | train loss {'Reaction outcome loss': 0.3827889375116703, 'Total loss': 0.3827889375116703}
2023-01-04 06:47:28,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:28,048 INFO:     Epoch: 29
2023-01-04 06:47:29,587 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4199845770994822, 'Total loss': 0.4199845770994822} | train loss {'Reaction outcome loss': 0.38128652790710876, 'Total loss': 0.38128652790710876}
2023-01-04 06:47:29,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:29,587 INFO:     Epoch: 30
2023-01-04 06:47:31,112 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4323611050844193, 'Total loss': 0.4323611050844193} | train loss {'Reaction outcome loss': 0.38001154216319105, 'Total loss': 0.38001154216319105}
2023-01-04 06:47:31,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:31,113 INFO:     Epoch: 31
2023-01-04 06:47:32,644 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.385856568813324, 'Total loss': 0.385856568813324} | train loss {'Reaction outcome loss': 0.37596089137296607, 'Total loss': 0.37596089137296607}
2023-01-04 06:47:32,645 INFO:     Found new best model at epoch 31
2023-01-04 06:47:32,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:32,645 INFO:     Epoch: 32
2023-01-04 06:47:34,154 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4219085454940796, 'Total loss': 0.4219085454940796} | train loss {'Reaction outcome loss': 0.37497181415449093, 'Total loss': 0.37497181415449093}
2023-01-04 06:47:34,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:34,155 INFO:     Epoch: 33
2023-01-04 06:47:35,665 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4280558009942373, 'Total loss': 0.4280558009942373} | train loss {'Reaction outcome loss': 0.36665379930369174, 'Total loss': 0.36665379930369174}
2023-01-04 06:47:35,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:35,665 INFO:     Epoch: 34
2023-01-04 06:47:37,206 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40308155318101246, 'Total loss': 0.40308155318101246} | train loss {'Reaction outcome loss': 0.36366200629268247, 'Total loss': 0.36366200629268247}
2023-01-04 06:47:37,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:37,207 INFO:     Epoch: 35
2023-01-04 06:47:38,821 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4098056435585022, 'Total loss': 0.4098056435585022} | train loss {'Reaction outcome loss': 0.3579180336346591, 'Total loss': 0.3579180336346591}
2023-01-04 06:47:38,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:38,821 INFO:     Epoch: 36
2023-01-04 06:47:40,432 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4072025060653687, 'Total loss': 0.4072025060653687} | train loss {'Reaction outcome loss': 0.3583268109899368, 'Total loss': 0.3583268109899368}
2023-01-04 06:47:40,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:40,432 INFO:     Epoch: 37
2023-01-04 06:47:42,040 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38784028589725494, 'Total loss': 0.38784028589725494} | train loss {'Reaction outcome loss': 0.35612741566813777, 'Total loss': 0.35612741566813777}
2023-01-04 06:47:42,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:42,041 INFO:     Epoch: 38
2023-01-04 06:47:43,603 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4291534552971522, 'Total loss': 0.4291534552971522} | train loss {'Reaction outcome loss': 0.35057495925983373, 'Total loss': 0.35057495925983373}
2023-01-04 06:47:43,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:43,605 INFO:     Epoch: 39
2023-01-04 06:47:45,182 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38527759313583376, 'Total loss': 0.38527759313583376} | train loss {'Reaction outcome loss': 0.3521411563847622, 'Total loss': 0.3521411563847622}
2023-01-04 06:47:45,182 INFO:     Found new best model at epoch 39
2023-01-04 06:47:45,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:45,183 INFO:     Epoch: 40
2023-01-04 06:47:46,796 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4403103232383728, 'Total loss': 0.4403103232383728} | train loss {'Reaction outcome loss': 0.3450125229211837, 'Total loss': 0.3450125229211837}
2023-01-04 06:47:46,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:46,796 INFO:     Epoch: 41
2023-01-04 06:47:48,408 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38818154235680896, 'Total loss': 0.38818154235680896} | train loss {'Reaction outcome loss': 0.3443746510757147, 'Total loss': 0.3443746510757147}
2023-01-04 06:47:48,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:48,408 INFO:     Epoch: 42
2023-01-04 06:47:50,015 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40317397316296893, 'Total loss': 0.40317397316296893} | train loss {'Reaction outcome loss': 0.3457358635989201, 'Total loss': 0.3457358635989201}
2023-01-04 06:47:50,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:50,015 INFO:     Epoch: 43
2023-01-04 06:47:51,621 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4138950705528259, 'Total loss': 0.4138950705528259} | train loss {'Reaction outcome loss': 0.3398424167811436, 'Total loss': 0.3398424167811436}
2023-01-04 06:47:51,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:51,621 INFO:     Epoch: 44
2023-01-04 06:47:53,082 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4189896394809087, 'Total loss': 0.4189896394809087} | train loss {'Reaction outcome loss': 0.3362157817413337, 'Total loss': 0.3362157817413337}
2023-01-04 06:47:53,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:53,082 INFO:     Epoch: 45
2023-01-04 06:47:54,708 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3997800350189209, 'Total loss': 0.3997800350189209} | train loss {'Reaction outcome loss': 0.33569609313985727, 'Total loss': 0.33569609313985727}
2023-01-04 06:47:54,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:54,708 INFO:     Epoch: 46
2023-01-04 06:47:56,265 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3908011794090271, 'Total loss': 0.3908011794090271} | train loss {'Reaction outcome loss': 0.3334672721034854, 'Total loss': 0.3334672721034854}
2023-01-04 06:47:56,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:56,266 INFO:     Epoch: 47
2023-01-04 06:47:57,809 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3885243500272433, 'Total loss': 0.3885243500272433} | train loss {'Reaction outcome loss': 0.32863621139069543, 'Total loss': 0.32863621139069543}
2023-01-04 06:47:57,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:57,809 INFO:     Epoch: 48
2023-01-04 06:47:59,375 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38305966357390087, 'Total loss': 0.38305966357390087} | train loss {'Reaction outcome loss': 0.3262898390908746, 'Total loss': 0.3262898390908746}
2023-01-04 06:47:59,375 INFO:     Found new best model at epoch 48
2023-01-04 06:47:59,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:47:59,376 INFO:     Epoch: 49
2023-01-04 06:48:00,932 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4389958639939626, 'Total loss': 0.4389958639939626} | train loss {'Reaction outcome loss': 0.3244703609333204, 'Total loss': 0.3244703609333204}
2023-01-04 06:48:00,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:00,932 INFO:     Epoch: 50
2023-01-04 06:48:02,336 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38237639764944714, 'Total loss': 0.38237639764944714} | train loss {'Reaction outcome loss': 0.3256974544947165, 'Total loss': 0.3256974544947165}
2023-01-04 06:48:02,336 INFO:     Found new best model at epoch 50
2023-01-04 06:48:02,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:02,337 INFO:     Epoch: 51
2023-01-04 06:48:03,877 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38756863673528036, 'Total loss': 0.38756863673528036} | train loss {'Reaction outcome loss': 0.32309669862589696, 'Total loss': 0.32309669862589696}
2023-01-04 06:48:03,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:03,877 INFO:     Epoch: 52
2023-01-04 06:48:05,409 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39303445468346276, 'Total loss': 0.39303445468346276} | train loss {'Reaction outcome loss': 0.3180192673347727, 'Total loss': 0.3180192673347727}
2023-01-04 06:48:05,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:05,409 INFO:     Epoch: 53
2023-01-04 06:48:06,942 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39220452308654785, 'Total loss': 0.39220452308654785} | train loss {'Reaction outcome loss': 0.31019377754661287, 'Total loss': 0.31019377754661287}
2023-01-04 06:48:06,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:06,942 INFO:     Epoch: 54
2023-01-04 06:48:08,477 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3935011674960454, 'Total loss': 0.3935011674960454} | train loss {'Reaction outcome loss': 0.31926791601046156, 'Total loss': 0.31926791601046156}
2023-01-04 06:48:08,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:08,479 INFO:     Epoch: 55
2023-01-04 06:48:10,007 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3976396898428599, 'Total loss': 0.3976396898428599} | train loss {'Reaction outcome loss': 0.31037312770520686, 'Total loss': 0.31037312770520686}
2023-01-04 06:48:10,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:10,008 INFO:     Epoch: 56
2023-01-04 06:48:11,428 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3844865133364995, 'Total loss': 0.3844865133364995} | train loss {'Reaction outcome loss': 0.3111981404741315, 'Total loss': 0.3111981404741315}
2023-01-04 06:48:11,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:11,428 INFO:     Epoch: 57
2023-01-04 06:48:12,959 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42457429667313895, 'Total loss': 0.42457429667313895} | train loss {'Reaction outcome loss': 0.3128454175634976, 'Total loss': 0.3128454175634976}
2023-01-04 06:48:12,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:12,959 INFO:     Epoch: 58
2023-01-04 06:48:14,487 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39546894828478496, 'Total loss': 0.39546894828478496} | train loss {'Reaction outcome loss': 0.3033786333118477, 'Total loss': 0.3033786333118477}
2023-01-04 06:48:14,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:14,488 INFO:     Epoch: 59
2023-01-04 06:48:16,024 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4159145454565684, 'Total loss': 0.4159145454565684} | train loss {'Reaction outcome loss': 0.30429521241109736, 'Total loss': 0.30429521241109736}
2023-01-04 06:48:16,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:16,025 INFO:     Epoch: 60
2023-01-04 06:48:17,590 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3944852948188782, 'Total loss': 0.3944852948188782} | train loss {'Reaction outcome loss': 0.30589631788541366, 'Total loss': 0.30589631788541366}
2023-01-04 06:48:17,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:17,591 INFO:     Epoch: 61
2023-01-04 06:48:19,145 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37199650208155316, 'Total loss': 0.37199650208155316} | train loss {'Reaction outcome loss': 0.29920431574548245, 'Total loss': 0.29920431574548245}
2023-01-04 06:48:19,145 INFO:     Found new best model at epoch 61
2023-01-04 06:48:19,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:19,146 INFO:     Epoch: 62
2023-01-04 06:48:20,572 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4079267750183741, 'Total loss': 0.4079267750183741} | train loss {'Reaction outcome loss': 0.29670107525086753, 'Total loss': 0.29670107525086753}
2023-01-04 06:48:20,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:20,572 INFO:     Epoch: 63
2023-01-04 06:48:22,129 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3843063235282898, 'Total loss': 0.3843063235282898} | train loss {'Reaction outcome loss': 0.2977508405753731, 'Total loss': 0.2977508405753731}
2023-01-04 06:48:22,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:22,129 INFO:     Epoch: 64
2023-01-04 06:48:23,673 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39803202549616495, 'Total loss': 0.39803202549616495} | train loss {'Reaction outcome loss': 0.2960135043755065, 'Total loss': 0.2960135043755065}
2023-01-04 06:48:23,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:23,673 INFO:     Epoch: 65
2023-01-04 06:48:25,213 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38762542108694714, 'Total loss': 0.38762542108694714} | train loss {'Reaction outcome loss': 0.2984613359355143, 'Total loss': 0.2984613359355143}
2023-01-04 06:48:25,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:25,214 INFO:     Epoch: 66
2023-01-04 06:48:26,776 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4088599383831024, 'Total loss': 0.4088599383831024} | train loss {'Reaction outcome loss': 0.29280878967829865, 'Total loss': 0.29280878967829865}
2023-01-04 06:48:26,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:26,777 INFO:     Epoch: 67
2023-01-04 06:48:28,323 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36139300068219504, 'Total loss': 0.36139300068219504} | train loss {'Reaction outcome loss': 0.29295435867333497, 'Total loss': 0.29295435867333497}
2023-01-04 06:48:28,323 INFO:     Found new best model at epoch 67
2023-01-04 06:48:28,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:28,324 INFO:     Epoch: 68
2023-01-04 06:48:29,750 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43294960061709087, 'Total loss': 0.43294960061709087} | train loss {'Reaction outcome loss': 0.2912796309666477, 'Total loss': 0.2912796309666477}
2023-01-04 06:48:29,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:29,750 INFO:     Epoch: 69
2023-01-04 06:48:31,298 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3898572971423467, 'Total loss': 0.3898572971423467} | train loss {'Reaction outcome loss': 0.28692614276261225, 'Total loss': 0.28692614276261225}
2023-01-04 06:48:31,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:31,298 INFO:     Epoch: 70
2023-01-04 06:48:32,843 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41433825294176735, 'Total loss': 0.41433825294176735} | train loss {'Reaction outcome loss': 0.29039915683713274, 'Total loss': 0.29039915683713274}
2023-01-04 06:48:32,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:32,843 INFO:     Epoch: 71
2023-01-04 06:48:34,407 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39870747228463493, 'Total loss': 0.39870747228463493} | train loss {'Reaction outcome loss': 0.2866228317202878, 'Total loss': 0.2866228317202878}
2023-01-04 06:48:34,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:34,407 INFO:     Epoch: 72
2023-01-04 06:48:35,962 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41557367940743767, 'Total loss': 0.41557367940743767} | train loss {'Reaction outcome loss': 0.28299104561009547, 'Total loss': 0.28299104561009547}
2023-01-04 06:48:35,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:35,962 INFO:     Epoch: 73
2023-01-04 06:48:37,510 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3910006503264109, 'Total loss': 0.3910006503264109} | train loss {'Reaction outcome loss': 0.28501038049368094, 'Total loss': 0.28501038049368094}
2023-01-04 06:48:37,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:37,510 INFO:     Epoch: 74
2023-01-04 06:48:38,923 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3818620542685191, 'Total loss': 0.3818620542685191} | train loss {'Reaction outcome loss': 0.287299447060719, 'Total loss': 0.287299447060719}
2023-01-04 06:48:38,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:38,923 INFO:     Epoch: 75
2023-01-04 06:48:40,497 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38982042570908865, 'Total loss': 0.38982042570908865} | train loss {'Reaction outcome loss': 0.2820130206345424, 'Total loss': 0.2820130206345424}
2023-01-04 06:48:40,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:40,497 INFO:     Epoch: 76
2023-01-04 06:48:42,040 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3869090755780538, 'Total loss': 0.3869090755780538} | train loss {'Reaction outcome loss': 0.2770566911756122, 'Total loss': 0.2770566911756122}
2023-01-04 06:48:42,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:42,041 INFO:     Epoch: 77
2023-01-04 06:48:43,593 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3752214292685191, 'Total loss': 0.3752214292685191} | train loss {'Reaction outcome loss': 0.27668380270963605, 'Total loss': 0.27668380270963605}
2023-01-04 06:48:43,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:43,594 INFO:     Epoch: 78
2023-01-04 06:48:45,158 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3762467473745346, 'Total loss': 0.3762467473745346} | train loss {'Reaction outcome loss': 0.2752493061669116, 'Total loss': 0.2752493061669116}
2023-01-04 06:48:45,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:45,158 INFO:     Epoch: 79
2023-01-04 06:48:46,710 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4106215417385101, 'Total loss': 0.4106215417385101} | train loss {'Reaction outcome loss': 0.28085944608506497, 'Total loss': 0.28085944608506497}
2023-01-04 06:48:46,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:46,710 INFO:     Epoch: 80
2023-01-04 06:48:48,135 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3710842835406462, 'Total loss': 0.3710842835406462} | train loss {'Reaction outcome loss': 0.27657595759488807, 'Total loss': 0.27657595759488807}
2023-01-04 06:48:48,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:48,135 INFO:     Epoch: 81
2023-01-04 06:48:49,690 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39481815497080486, 'Total loss': 0.39481815497080486} | train loss {'Reaction outcome loss': 0.27602462239400316, 'Total loss': 0.27602462239400316}
2023-01-04 06:48:49,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:49,691 INFO:     Epoch: 82
2023-01-04 06:48:51,255 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42022971510887147, 'Total loss': 0.42022971510887147} | train loss {'Reaction outcome loss': 0.2723269730425664, 'Total loss': 0.2723269730425664}
2023-01-04 06:48:51,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:51,255 INFO:     Epoch: 83
2023-01-04 06:48:52,822 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3891634225845337, 'Total loss': 0.3891634225845337} | train loss {'Reaction outcome loss': 0.2705641313435605, 'Total loss': 0.2705641313435605}
2023-01-04 06:48:52,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:52,822 INFO:     Epoch: 84
2023-01-04 06:48:54,366 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4405084033807119, 'Total loss': 0.4405084033807119} | train loss {'Reaction outcome loss': 0.27146753826498116, 'Total loss': 0.27146753826498116}
2023-01-04 06:48:54,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:54,366 INFO:     Epoch: 85
2023-01-04 06:48:55,894 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3944448014100393, 'Total loss': 0.3944448014100393} | train loss {'Reaction outcome loss': 0.26873825442888877, 'Total loss': 0.26873825442888877}
2023-01-04 06:48:55,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:55,894 INFO:     Epoch: 86
2023-01-04 06:48:57,302 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36933224896589917, 'Total loss': 0.36933224896589917} | train loss {'Reaction outcome loss': 0.2690957339793226, 'Total loss': 0.2690957339793226}
2023-01-04 06:48:57,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:57,303 INFO:     Epoch: 87
2023-01-04 06:48:58,860 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4006140500307083, 'Total loss': 0.4006140500307083} | train loss {'Reaction outcome loss': 0.2672198390193882, 'Total loss': 0.2672198390193882}
2023-01-04 06:48:58,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:48:58,860 INFO:     Epoch: 88
2023-01-04 06:49:00,420 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4232836922009786, 'Total loss': 0.4232836922009786} | train loss {'Reaction outcome loss': 0.27128318958256364, 'Total loss': 0.27128318958256364}
2023-01-04 06:49:00,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:00,420 INFO:     Epoch: 89
2023-01-04 06:49:02,037 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4072604149580002, 'Total loss': 0.4072604149580002} | train loss {'Reaction outcome loss': 0.26817369259839513, 'Total loss': 0.26817369259839513}
2023-01-04 06:49:02,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:02,038 INFO:     Epoch: 90
2023-01-04 06:49:03,653 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3961048165957133, 'Total loss': 0.3961048165957133} | train loss {'Reaction outcome loss': 0.26674592678509923, 'Total loss': 0.26674592678509923}
2023-01-04 06:49:03,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:03,653 INFO:     Epoch: 91
2023-01-04 06:49:05,259 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37376172840595245, 'Total loss': 0.37376172840595245} | train loss {'Reaction outcome loss': 0.2625316381726387, 'Total loss': 0.2625316381726387}
2023-01-04 06:49:05,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:05,260 INFO:     Epoch: 92
2023-01-04 06:49:06,778 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36106135149796803, 'Total loss': 0.36106135149796803} | train loss {'Reaction outcome loss': 0.2626573043148013, 'Total loss': 0.2626573043148013}
2023-01-04 06:49:06,778 INFO:     Found new best model at epoch 92
2023-01-04 06:49:06,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:06,779 INFO:     Epoch: 93
2023-01-04 06:49:08,389 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4031226173043251, 'Total loss': 0.4031226173043251} | train loss {'Reaction outcome loss': 0.2622618496445191, 'Total loss': 0.2622618496445191}
2023-01-04 06:49:08,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:08,390 INFO:     Epoch: 94
2023-01-04 06:49:10,008 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4244305948416392, 'Total loss': 0.4244305948416392} | train loss {'Reaction outcome loss': 0.26427851040867995, 'Total loss': 0.26427851040867995}
2023-01-04 06:49:10,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:10,008 INFO:     Epoch: 95
2023-01-04 06:49:11,616 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4277089357376099, 'Total loss': 0.4277089357376099} | train loss {'Reaction outcome loss': 0.2635662243803487, 'Total loss': 0.2635662243803487}
2023-01-04 06:49:11,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:11,617 INFO:     Epoch: 96
2023-01-04 06:49:13,225 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38872455259164174, 'Total loss': 0.38872455259164174} | train loss {'Reaction outcome loss': 0.26117530454249277, 'Total loss': 0.26117530454249277}
2023-01-04 06:49:13,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:13,225 INFO:     Epoch: 97
2023-01-04 06:49:14,790 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3809005488952001, 'Total loss': 0.3809005488952001} | train loss {'Reaction outcome loss': 0.26032101662054546, 'Total loss': 0.26032101662054546}
2023-01-04 06:49:14,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:14,792 INFO:     Epoch: 98
2023-01-04 06:49:16,353 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40497218867143, 'Total loss': 0.40497218867143} | train loss {'Reaction outcome loss': 0.25807371129193446, 'Total loss': 0.25807371129193446}
2023-01-04 06:49:16,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:16,353 INFO:     Epoch: 99
2023-01-04 06:49:17,948 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36525549987951916, 'Total loss': 0.36525549987951916} | train loss {'Reaction outcome loss': 0.2612608953576236, 'Total loss': 0.2612608953576236}
2023-01-04 06:49:17,948 INFO:     Best model found after epoch 93 of 100.
2023-01-04 06:49:17,948 INFO:   Done with stage: TRAINING
2023-01-04 06:49:17,948 INFO:   Starting stage: EVALUATION
2023-01-04 06:49:18,100 INFO:   Done with stage: EVALUATION
2023-01-04 06:49:18,101 INFO:   Leaving out SEQ value Fold_8
2023-01-04 06:49:18,114 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 06:49:18,114 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:49:18,810 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:49:18,810 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:49:18,888 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:49:18,888 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:49:18,888 INFO:     No hyperparam tuning for this model
2023-01-04 06:49:18,888 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:49:18,888 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:49:18,889 INFO:     None feature selector for col prot
2023-01-04 06:49:18,889 INFO:     None feature selector for col prot
2023-01-04 06:49:18,889 INFO:     None feature selector for col prot
2023-01-04 06:49:18,890 INFO:     None feature selector for col chem
2023-01-04 06:49:18,890 INFO:     None feature selector for col chem
2023-01-04 06:49:18,890 INFO:     None feature selector for col chem
2023-01-04 06:49:18,890 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:49:18,890 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:49:18,892 INFO:     Number of params in model 70111
2023-01-04 06:49:18,895 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:49:18,895 INFO:   Starting stage: TRAINING
2023-01-04 06:49:18,940 INFO:     Val loss before train {'Reaction outcome loss': 0.9776186227798462, 'Total loss': 0.9776186227798462}
2023-01-04 06:49:18,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:18,940 INFO:     Epoch: 0
2023-01-04 06:49:20,570 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.716803228855133, 'Total loss': 0.716803228855133} | train loss {'Reaction outcome loss': 0.8394945259559026, 'Total loss': 0.8394945259559026}
2023-01-04 06:49:20,570 INFO:     Found new best model at epoch 0
2023-01-04 06:49:20,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:20,571 INFO:     Epoch: 1
2023-01-04 06:49:22,205 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5666532715161642, 'Total loss': 0.5666532715161642} | train loss {'Reaction outcome loss': 0.6831252172535507, 'Total loss': 0.6831252172535507}
2023-01-04 06:49:22,205 INFO:     Found new best model at epoch 1
2023-01-04 06:49:22,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:22,206 INFO:     Epoch: 2
2023-01-04 06:49:23,787 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4973958631356557, 'Total loss': 0.4973958631356557} | train loss {'Reaction outcome loss': 0.5868287253250715, 'Total loss': 0.5868287253250715}
2023-01-04 06:49:23,787 INFO:     Found new best model at epoch 2
2023-01-04 06:49:23,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:23,788 INFO:     Epoch: 3
2023-01-04 06:49:25,366 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5034772465626399, 'Total loss': 0.5034772465626399} | train loss {'Reaction outcome loss': 0.5506574729396978, 'Total loss': 0.5506574729396978}
2023-01-04 06:49:25,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:25,367 INFO:     Epoch: 4
2023-01-04 06:49:26,994 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4868725180625916, 'Total loss': 0.4868725180625916} | train loss {'Reaction outcome loss': 0.5273695204016965, 'Total loss': 0.5273695204016965}
2023-01-04 06:49:26,994 INFO:     Found new best model at epoch 4
2023-01-04 06:49:26,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:26,995 INFO:     Epoch: 5
2023-01-04 06:49:28,616 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4619874119758606, 'Total loss': 0.4619874119758606} | train loss {'Reaction outcome loss': 0.5134316160467988, 'Total loss': 0.5134316160467988}
2023-01-04 06:49:28,616 INFO:     Found new best model at epoch 5
2023-01-04 06:49:28,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:28,617 INFO:     Epoch: 6
2023-01-04 06:49:30,248 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46594077746073403, 'Total loss': 0.46594077746073403} | train loss {'Reaction outcome loss': 0.5072721813667552, 'Total loss': 0.5072721813667552}
2023-01-04 06:49:30,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:30,249 INFO:     Epoch: 7
2023-01-04 06:49:31,844 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4612411618232727, 'Total loss': 0.4612411618232727} | train loss {'Reaction outcome loss': 0.497392182046756, 'Total loss': 0.497392182046756}
2023-01-04 06:49:31,844 INFO:     Found new best model at epoch 7
2023-01-04 06:49:31,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:31,844 INFO:     Epoch: 8
2023-01-04 06:49:33,373 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43895751535892485, 'Total loss': 0.43895751535892485} | train loss {'Reaction outcome loss': 0.4866413959312095, 'Total loss': 0.4866413959312095}
2023-01-04 06:49:33,373 INFO:     Found new best model at epoch 8
2023-01-04 06:49:33,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:33,374 INFO:     Epoch: 9
2023-01-04 06:49:34,909 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44671446879704796, 'Total loss': 0.44671446879704796} | train loss {'Reaction outcome loss': 0.4813044419249903, 'Total loss': 0.4813044419249903}
2023-01-04 06:49:34,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:34,910 INFO:     Epoch: 10
2023-01-04 06:49:36,487 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4446399341026942, 'Total loss': 0.4446399341026942} | train loss {'Reaction outcome loss': 0.4791415211902629, 'Total loss': 0.4791415211902629}
2023-01-04 06:49:36,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:36,487 INFO:     Epoch: 11
2023-01-04 06:49:38,046 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4271458347638448, 'Total loss': 0.4271458347638448} | train loss {'Reaction outcome loss': 0.46949948257487606, 'Total loss': 0.46949948257487606}
2023-01-04 06:49:38,047 INFO:     Found new best model at epoch 11
2023-01-04 06:49:38,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:38,047 INFO:     Epoch: 12
2023-01-04 06:49:39,616 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4473550220330556, 'Total loss': 0.4473550220330556} | train loss {'Reaction outcome loss': 0.4681195857184889, 'Total loss': 0.4681195857184889}
2023-01-04 06:49:39,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:39,617 INFO:     Epoch: 13
2023-01-04 06:49:41,187 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44790487686793007, 'Total loss': 0.44790487686793007} | train loss {'Reaction outcome loss': 0.46110402128326333, 'Total loss': 0.46110402128326333}
2023-01-04 06:49:41,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:41,187 INFO:     Epoch: 14
2023-01-04 06:49:42,706 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42637800176938373, 'Total loss': 0.42637800176938373} | train loss {'Reaction outcome loss': 0.45456343727852033, 'Total loss': 0.45456343727852033}
2023-01-04 06:49:42,706 INFO:     Found new best model at epoch 14
2023-01-04 06:49:42,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:42,707 INFO:     Epoch: 15
2023-01-04 06:49:44,283 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4338034888108571, 'Total loss': 0.4338034888108571} | train loss {'Reaction outcome loss': 0.4512401764896372, 'Total loss': 0.4512401764896372}
2023-01-04 06:49:44,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:44,283 INFO:     Epoch: 16
2023-01-04 06:49:45,854 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40789403518040973, 'Total loss': 0.40789403518040973} | train loss {'Reaction outcome loss': 0.44276983336636305, 'Total loss': 0.44276983336636305}
2023-01-04 06:49:45,856 INFO:     Found new best model at epoch 16
2023-01-04 06:49:45,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:45,856 INFO:     Epoch: 17
2023-01-04 06:49:47,459 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4179145097732544, 'Total loss': 0.4179145097732544} | train loss {'Reaction outcome loss': 0.44129715208972836, 'Total loss': 0.44129715208972836}
2023-01-04 06:49:47,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:47,459 INFO:     Epoch: 18
2023-01-04 06:49:49,078 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4083778868118922, 'Total loss': 0.4083778868118922} | train loss {'Reaction outcome loss': 0.44069992473839853, 'Total loss': 0.44069992473839853}
2023-01-04 06:49:49,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:49,079 INFO:     Epoch: 19
2023-01-04 06:49:50,667 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4115106920401255, 'Total loss': 0.4115106920401255} | train loss {'Reaction outcome loss': 0.43508324037820423, 'Total loss': 0.43508324037820423}
2023-01-04 06:49:50,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:50,667 INFO:     Epoch: 20
2023-01-04 06:49:52,197 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4017491380373637, 'Total loss': 0.4017491380373637} | train loss {'Reaction outcome loss': 0.4335173015560054, 'Total loss': 0.4335173015560054}
2023-01-04 06:49:52,198 INFO:     Found new best model at epoch 20
2023-01-04 06:49:52,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:52,199 INFO:     Epoch: 21
2023-01-04 06:49:53,782 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39978587031364443, 'Total loss': 0.39978587031364443} | train loss {'Reaction outcome loss': 0.42448604730922823, 'Total loss': 0.42448604730922823}
2023-01-04 06:49:53,782 INFO:     Found new best model at epoch 21
2023-01-04 06:49:53,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:53,783 INFO:     Epoch: 22
2023-01-04 06:49:55,356 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4065897911787033, 'Total loss': 0.4065897911787033} | train loss {'Reaction outcome loss': 0.42555159252365576, 'Total loss': 0.42555159252365576}
2023-01-04 06:49:55,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:55,356 INFO:     Epoch: 23
2023-01-04 06:49:56,942 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39558288057645163, 'Total loss': 0.39558288057645163} | train loss {'Reaction outcome loss': 0.419956105818387, 'Total loss': 0.419956105818387}
2023-01-04 06:49:56,942 INFO:     Found new best model at epoch 23
2023-01-04 06:49:56,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:56,943 INFO:     Epoch: 24
2023-01-04 06:49:58,512 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42559552391370137, 'Total loss': 0.42559552391370137} | train loss {'Reaction outcome loss': 0.4162559933180413, 'Total loss': 0.4162559933180413}
2023-01-04 06:49:58,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:49:58,512 INFO:     Epoch: 25
2023-01-04 06:50:00,061 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3841809531052907, 'Total loss': 0.3841809531052907} | train loss {'Reaction outcome loss': 0.4168658480855102, 'Total loss': 0.4168658480855102}
2023-01-04 06:50:00,061 INFO:     Found new best model at epoch 25
2023-01-04 06:50:00,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:00,062 INFO:     Epoch: 26
2023-01-04 06:50:01,611 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39780103663603467, 'Total loss': 0.39780103663603467} | train loss {'Reaction outcome loss': 0.40880674035002607, 'Total loss': 0.40880674035002607}
2023-01-04 06:50:01,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:01,611 INFO:     Epoch: 27
2023-01-04 06:50:03,177 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3850786248842875, 'Total loss': 0.3850786248842875} | train loss {'Reaction outcome loss': 0.40233236126305827, 'Total loss': 0.40233236126305827}
2023-01-04 06:50:03,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:03,178 INFO:     Epoch: 28
2023-01-04 06:50:04,739 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38198321461677553, 'Total loss': 0.38198321461677553} | train loss {'Reaction outcome loss': 0.4012722130394154, 'Total loss': 0.4012722130394154}
2023-01-04 06:50:04,740 INFO:     Found new best model at epoch 28
2023-01-04 06:50:04,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:04,741 INFO:     Epoch: 29
2023-01-04 06:50:06,293 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3898803174495697, 'Total loss': 0.3898803174495697} | train loss {'Reaction outcome loss': 0.39361536123584756, 'Total loss': 0.39361536123584756}
2023-01-04 06:50:06,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:06,294 INFO:     Epoch: 30
2023-01-04 06:50:07,850 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38646257917086285, 'Total loss': 0.38646257917086285} | train loss {'Reaction outcome loss': 0.39444983425123165, 'Total loss': 0.39444983425123165}
2023-01-04 06:50:07,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:07,851 INFO:     Epoch: 31
2023-01-04 06:50:09,384 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37736971775690714, 'Total loss': 0.37736971775690714} | train loss {'Reaction outcome loss': 0.3906618151746502, 'Total loss': 0.3906618151746502}
2023-01-04 06:50:09,384 INFO:     Found new best model at epoch 31
2023-01-04 06:50:09,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:09,385 INFO:     Epoch: 32
2023-01-04 06:50:10,920 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39363242288430533, 'Total loss': 0.39363242288430533} | train loss {'Reaction outcome loss': 0.3884080030319923, 'Total loss': 0.3884080030319923}
2023-01-04 06:50:10,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:10,920 INFO:     Epoch: 33
2023-01-04 06:50:12,506 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38273709615071616, 'Total loss': 0.38273709615071616} | train loss {'Reaction outcome loss': 0.3839255970791789, 'Total loss': 0.3839255970791789}
2023-01-04 06:50:12,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:12,507 INFO:     Epoch: 34
2023-01-04 06:50:14,079 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3870252251625061, 'Total loss': 0.3870252251625061} | train loss {'Reaction outcome loss': 0.3779446649422284, 'Total loss': 0.3779446649422284}
2023-01-04 06:50:14,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:14,079 INFO:     Epoch: 35
2023-01-04 06:50:15,668 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39139227718114855, 'Total loss': 0.39139227718114855} | train loss {'Reaction outcome loss': 0.3762199539247403, 'Total loss': 0.3762199539247403}
2023-01-04 06:50:15,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:15,669 INFO:     Epoch: 36
2023-01-04 06:50:17,253 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40424138903617857, 'Total loss': 0.40424138903617857} | train loss {'Reaction outcome loss': 0.3720689639718094, 'Total loss': 0.3720689639718094}
2023-01-04 06:50:17,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:17,254 INFO:     Epoch: 37
2023-01-04 06:50:18,490 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37516950170199076, 'Total loss': 0.37516950170199076} | train loss {'Reaction outcome loss': 0.3733286397121443, 'Total loss': 0.3733286397121443}
2023-01-04 06:50:18,490 INFO:     Found new best model at epoch 37
2023-01-04 06:50:18,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:18,491 INFO:     Epoch: 38
2023-01-04 06:50:19,517 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4137992262840271, 'Total loss': 0.4137992262840271} | train loss {'Reaction outcome loss': 0.3688198408441423, 'Total loss': 0.3688198408441423}
2023-01-04 06:50:19,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:19,517 INFO:     Epoch: 39
2023-01-04 06:50:20,537 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38965153992176055, 'Total loss': 0.38965153992176055} | train loss {'Reaction outcome loss': 0.36307746432856103, 'Total loss': 0.36307746432856103}
2023-01-04 06:50:20,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:20,537 INFO:     Epoch: 40
2023-01-04 06:50:21,554 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3792420307795207, 'Total loss': 0.3792420307795207} | train loss {'Reaction outcome loss': 0.3616663931401628, 'Total loss': 0.3616663931401628}
2023-01-04 06:50:21,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:21,556 INFO:     Epoch: 41
2023-01-04 06:50:22,649 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3911146640777588, 'Total loss': 0.3911146640777588} | train loss {'Reaction outcome loss': 0.3560423583115051, 'Total loss': 0.3560423583115051}
2023-01-04 06:50:22,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:22,649 INFO:     Epoch: 42
2023-01-04 06:50:24,221 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3814886689186096, 'Total loss': 0.3814886689186096} | train loss {'Reaction outcome loss': 0.3553458979951776, 'Total loss': 0.3553458979951776}
2023-01-04 06:50:24,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:24,221 INFO:     Epoch: 43
2023-01-04 06:50:25,732 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3995268871386846, 'Total loss': 0.3995268871386846} | train loss {'Reaction outcome loss': 0.34984454367350154, 'Total loss': 0.34984454367350154}
2023-01-04 06:50:25,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:25,732 INFO:     Epoch: 44
2023-01-04 06:50:27,290 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38196791609128317, 'Total loss': 0.38196791609128317} | train loss {'Reaction outcome loss': 0.34719522127928715, 'Total loss': 0.34719522127928715}
2023-01-04 06:50:27,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:27,290 INFO:     Epoch: 45
2023-01-04 06:50:28,839 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37009892414013545, 'Total loss': 0.37009892414013545} | train loss {'Reaction outcome loss': 0.35002449940257985, 'Total loss': 0.35002449940257985}
2023-01-04 06:50:28,840 INFO:     Found new best model at epoch 45
2023-01-04 06:50:28,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:28,841 INFO:     Epoch: 46
2023-01-04 06:50:30,393 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3540897011756897, 'Total loss': 0.3540897011756897} | train loss {'Reaction outcome loss': 0.3462004336101484, 'Total loss': 0.3462004336101484}
2023-01-04 06:50:30,393 INFO:     Found new best model at epoch 46
2023-01-04 06:50:30,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:30,393 INFO:     Epoch: 47
2023-01-04 06:50:31,905 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37325156132380166, 'Total loss': 0.37325156132380166} | train loss {'Reaction outcome loss': 0.3415209408378773, 'Total loss': 0.3415209408378773}
2023-01-04 06:50:31,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:31,905 INFO:     Epoch: 48
2023-01-04 06:50:33,455 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3575892945130666, 'Total loss': 0.3575892945130666} | train loss {'Reaction outcome loss': 0.3425499789874046, 'Total loss': 0.3425499789874046}
2023-01-04 06:50:33,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:33,455 INFO:     Epoch: 49
2023-01-04 06:50:34,972 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3638494710127513, 'Total loss': 0.3638494710127513} | train loss {'Reaction outcome loss': 0.34003924037790473, 'Total loss': 0.34003924037790473}
2023-01-04 06:50:34,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:34,972 INFO:     Epoch: 50
2023-01-04 06:50:36,532 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40699483156204225, 'Total loss': 0.40699483156204225} | train loss {'Reaction outcome loss': 0.33785631881509015, 'Total loss': 0.33785631881509015}
2023-01-04 06:50:36,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:36,533 INFO:     Epoch: 51
2023-01-04 06:50:38,089 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39493824243545533, 'Total loss': 0.39493824243545533} | train loss {'Reaction outcome loss': 0.3329941223943707, 'Total loss': 0.3329941223943707}
2023-01-04 06:50:38,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:38,089 INFO:     Epoch: 52
2023-01-04 06:50:39,652 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37875207563241325, 'Total loss': 0.37875207563241325} | train loss {'Reaction outcome loss': 0.33511350992461836, 'Total loss': 0.33511350992461836}
2023-01-04 06:50:39,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:39,652 INFO:     Epoch: 53
2023-01-04 06:50:41,169 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3694643586874008, 'Total loss': 0.3694643586874008} | train loss {'Reaction outcome loss': 0.33070720882837523, 'Total loss': 0.33070720882837523}
2023-01-04 06:50:41,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:41,170 INFO:     Epoch: 54
2023-01-04 06:50:42,714 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36252259810765586, 'Total loss': 0.36252259810765586} | train loss {'Reaction outcome loss': 0.32525541305219224, 'Total loss': 0.32525541305219224}
2023-01-04 06:50:42,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:42,714 INFO:     Epoch: 55
2023-01-04 06:50:44,256 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39391496976216633, 'Total loss': 0.39391496976216633} | train loss {'Reaction outcome loss': 0.32697066188611706, 'Total loss': 0.32697066188611706}
2023-01-04 06:50:44,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:44,256 INFO:     Epoch: 56
2023-01-04 06:50:45,814 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38701578676700593, 'Total loss': 0.38701578676700593} | train loss {'Reaction outcome loss': 0.32533158369980997, 'Total loss': 0.32533158369980997}
2023-01-04 06:50:45,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:45,815 INFO:     Epoch: 57
2023-01-04 06:50:47,367 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3856974100073179, 'Total loss': 0.3856974100073179} | train loss {'Reaction outcome loss': 0.323664304137983, 'Total loss': 0.323664304137983}
2023-01-04 06:50:47,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:47,367 INFO:     Epoch: 58
2023-01-04 06:50:48,924 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36298050681749977, 'Total loss': 0.36298050681749977} | train loss {'Reaction outcome loss': 0.3198109138958721, 'Total loss': 0.3198109138958721}
2023-01-04 06:50:48,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:48,924 INFO:     Epoch: 59
2023-01-04 06:50:50,446 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.390788663427035, 'Total loss': 0.390788663427035} | train loss {'Reaction outcome loss': 0.3199576483467856, 'Total loss': 0.3199576483467856}
2023-01-04 06:50:50,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:50,446 INFO:     Epoch: 60
2023-01-04 06:50:52,018 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3893056094646454, 'Total loss': 0.3893056094646454} | train loss {'Reaction outcome loss': 0.31951756441851387, 'Total loss': 0.31951756441851387}
2023-01-04 06:50:52,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:52,019 INFO:     Epoch: 61
2023-01-04 06:50:53,546 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3720255066951116, 'Total loss': 0.3720255066951116} | train loss {'Reaction outcome loss': 0.31365306817990346, 'Total loss': 0.31365306817990346}
2023-01-04 06:50:53,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:53,546 INFO:     Epoch: 62
2023-01-04 06:50:55,092 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37588958541552225, 'Total loss': 0.37588958541552225} | train loss {'Reaction outcome loss': 0.31139929511917197, 'Total loss': 0.31139929511917197}
2023-01-04 06:50:55,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:55,092 INFO:     Epoch: 63
2023-01-04 06:50:56,640 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.344471667210261, 'Total loss': 0.344471667210261} | train loss {'Reaction outcome loss': 0.31170882190500354, 'Total loss': 0.31170882190500354}
2023-01-04 06:50:56,641 INFO:     Found new best model at epoch 63
2023-01-04 06:50:56,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:56,642 INFO:     Epoch: 64
2023-01-04 06:50:58,195 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3815280745426814, 'Total loss': 0.3815280745426814} | train loss {'Reaction outcome loss': 0.30988101884453734, 'Total loss': 0.30988101884453734}
2023-01-04 06:50:58,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:58,195 INFO:     Epoch: 65
2023-01-04 06:50:59,748 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37323734958966576, 'Total loss': 0.37323734958966576} | train loss {'Reaction outcome loss': 0.3101261155377226, 'Total loss': 0.3101261155377226}
2023-01-04 06:50:59,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:50:59,748 INFO:     Epoch: 66
2023-01-04 06:51:01,297 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38465780317783355, 'Total loss': 0.38465780317783355} | train loss {'Reaction outcome loss': 0.3040739161765963, 'Total loss': 0.3040739161765963}
2023-01-04 06:51:01,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:01,297 INFO:     Epoch: 67
2023-01-04 06:51:02,822 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3630481128891309, 'Total loss': 0.3630481128891309} | train loss {'Reaction outcome loss': 0.3038811830783579, 'Total loss': 0.3038811830783579}
2023-01-04 06:51:02,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:02,823 INFO:     Epoch: 68
2023-01-04 06:51:04,382 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3561757023135821, 'Total loss': 0.3561757023135821} | train loss {'Reaction outcome loss': 0.30128603643781443, 'Total loss': 0.30128603643781443}
2023-01-04 06:51:04,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:04,383 INFO:     Epoch: 69
2023-01-04 06:51:05,941 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35875246226787566, 'Total loss': 0.35875246226787566} | train loss {'Reaction outcome loss': 0.3021466007947061, 'Total loss': 0.3021466007947061}
2023-01-04 06:51:05,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:05,941 INFO:     Epoch: 70
2023-01-04 06:51:07,500 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3837115546067556, 'Total loss': 0.3837115546067556} | train loss {'Reaction outcome loss': 0.3026126630953933, 'Total loss': 0.3026126630953933}
2023-01-04 06:51:07,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:07,500 INFO:     Epoch: 71
2023-01-04 06:51:09,014 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3687025189399719, 'Total loss': 0.3687025189399719} | train loss {'Reaction outcome loss': 0.3006187328793082, 'Total loss': 0.3006187328793082}
2023-01-04 06:51:09,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:09,015 INFO:     Epoch: 72
2023-01-04 06:51:10,554 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36985470751921334, 'Total loss': 0.36985470751921334} | train loss {'Reaction outcome loss': 0.29991695270049873, 'Total loss': 0.29991695270049873}
2023-01-04 06:51:10,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:10,554 INFO:     Epoch: 73
2023-01-04 06:51:12,081 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38531699279944104, 'Total loss': 0.38531699279944104} | train loss {'Reaction outcome loss': 0.2950280889169404, 'Total loss': 0.2950280889169404}
2023-01-04 06:51:12,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:12,082 INFO:     Epoch: 74
2023-01-04 06:51:13,636 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38356356620788573, 'Total loss': 0.38356356620788573} | train loss {'Reaction outcome loss': 0.2977864949658029, 'Total loss': 0.2977864949658029}
2023-01-04 06:51:13,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:13,637 INFO:     Epoch: 75
2023-01-04 06:51:15,202 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3868470331033071, 'Total loss': 0.3868470331033071} | train loss {'Reaction outcome loss': 0.29341189380372046, 'Total loss': 0.29341189380372046}
2023-01-04 06:51:15,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:15,203 INFO:     Epoch: 76
2023-01-04 06:51:16,765 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3522290865580241, 'Total loss': 0.3522290865580241} | train loss {'Reaction outcome loss': 0.2910811676230241, 'Total loss': 0.2910811676230241}
2023-01-04 06:51:16,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:16,765 INFO:     Epoch: 77
2023-01-04 06:51:18,316 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3995035121838252, 'Total loss': 0.3995035121838252} | train loss {'Reaction outcome loss': 0.28605736243380536, 'Total loss': 0.28605736243380536}
2023-01-04 06:51:18,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:18,316 INFO:     Epoch: 78
2023-01-04 06:51:19,862 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3842086335023244, 'Total loss': 0.3842086335023244} | train loss {'Reaction outcome loss': 0.2904488596567608, 'Total loss': 0.2904488596567608}
2023-01-04 06:51:19,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:19,862 INFO:     Epoch: 79
2023-01-04 06:51:21,444 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3744437257448832, 'Total loss': 0.3744437257448832} | train loss {'Reaction outcome loss': 0.2922071424255733, 'Total loss': 0.2922071424255733}
2023-01-04 06:51:21,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:21,444 INFO:     Epoch: 80
2023-01-04 06:51:22,998 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3720720360676448, 'Total loss': 0.3720720360676448} | train loss {'Reaction outcome loss': 0.2880870543608597, 'Total loss': 0.2880870543608597}
2023-01-04 06:51:22,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:22,998 INFO:     Epoch: 81
2023-01-04 06:51:24,570 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3575756172339121, 'Total loss': 0.3575756172339121} | train loss {'Reaction outcome loss': 0.28241464202477184, 'Total loss': 0.28241464202477184}
2023-01-04 06:51:24,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:24,570 INFO:     Epoch: 82
2023-01-04 06:51:26,114 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36601341764132184, 'Total loss': 0.36601341764132184} | train loss {'Reaction outcome loss': 0.28384971361782146, 'Total loss': 0.28384971361782146}
2023-01-04 06:51:26,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:26,115 INFO:     Epoch: 83
2023-01-04 06:51:27,668 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3990122854709625, 'Total loss': 0.3990122854709625} | train loss {'Reaction outcome loss': 0.2833583328321522, 'Total loss': 0.2833583328321522}
2023-01-04 06:51:27,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:27,668 INFO:     Epoch: 84
2023-01-04 06:51:29,208 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3705538431803385, 'Total loss': 0.3705538431803385} | train loss {'Reaction outcome loss': 0.2815357551570403, 'Total loss': 0.2815357551570403}
2023-01-04 06:51:29,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:29,209 INFO:     Epoch: 85
2023-01-04 06:51:30,783 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3611948738495509, 'Total loss': 0.3611948738495509} | train loss {'Reaction outcome loss': 0.2812085656267641, 'Total loss': 0.2812085656267641}
2023-01-04 06:51:30,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:30,783 INFO:     Epoch: 86
2023-01-04 06:51:32,356 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37557533060510956, 'Total loss': 0.37557533060510956} | train loss {'Reaction outcome loss': 0.2813303664003899, 'Total loss': 0.2813303664003899}
2023-01-04 06:51:32,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:32,357 INFO:     Epoch: 87
2023-01-04 06:51:33,916 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3597981403271357, 'Total loss': 0.3597981403271357} | train loss {'Reaction outcome loss': 0.2761399157694961, 'Total loss': 0.2761399157694961}
2023-01-04 06:51:33,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:33,918 INFO:     Epoch: 88
2023-01-04 06:51:35,474 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37341602742671964, 'Total loss': 0.37341602742671964} | train loss {'Reaction outcome loss': 0.28172913301292307, 'Total loss': 0.28172913301292307}
2023-01-04 06:51:35,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:35,474 INFO:     Epoch: 89
2023-01-04 06:51:37,052 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37775495946407317, 'Total loss': 0.37775495946407317} | train loss {'Reaction outcome loss': 0.27499314034458533, 'Total loss': 0.27499314034458533}
2023-01-04 06:51:37,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:37,052 INFO:     Epoch: 90
2023-01-04 06:51:38,586 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3689941535393397, 'Total loss': 0.3689941535393397} | train loss {'Reaction outcome loss': 0.2760280701281362, 'Total loss': 0.2760280701281362}
2023-01-04 06:51:38,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:38,586 INFO:     Epoch: 91
2023-01-04 06:51:40,177 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3590955719351768, 'Total loss': 0.3590955719351768} | train loss {'Reaction outcome loss': 0.28007099940189384, 'Total loss': 0.28007099940189384}
2023-01-04 06:51:40,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:40,178 INFO:     Epoch: 92
2023-01-04 06:51:41,752 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36149022976557416, 'Total loss': 0.36149022976557416} | train loss {'Reaction outcome loss': 0.27915629877671866, 'Total loss': 0.27915629877671866}
2023-01-04 06:51:41,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:41,753 INFO:     Epoch: 93
2023-01-04 06:51:43,318 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36723918716112774, 'Total loss': 0.36723918716112774} | train loss {'Reaction outcome loss': 0.2740377780816615, 'Total loss': 0.2740377780816615}
2023-01-04 06:51:43,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:43,319 INFO:     Epoch: 94
2023-01-04 06:51:44,867 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3605156630277634, 'Total loss': 0.3605156630277634} | train loss {'Reaction outcome loss': 0.270214874768085, 'Total loss': 0.270214874768085}
2023-01-04 06:51:44,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:44,867 INFO:     Epoch: 95
2023-01-04 06:51:46,446 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3691928207874298, 'Total loss': 0.3691928207874298} | train loss {'Reaction outcome loss': 0.2735451773508361, 'Total loss': 0.2735451773508361}
2023-01-04 06:51:46,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:46,446 INFO:     Epoch: 96
2023-01-04 06:51:47,992 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3388091782728831, 'Total loss': 0.3388091782728831} | train loss {'Reaction outcome loss': 0.27110331231183527, 'Total loss': 0.27110331231183527}
2023-01-04 06:51:47,992 INFO:     Found new best model at epoch 96
2023-01-04 06:51:47,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:47,993 INFO:     Epoch: 97
2023-01-04 06:51:49,568 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3886867513259252, 'Total loss': 0.3886867513259252} | train loss {'Reaction outcome loss': 0.27395498331649637, 'Total loss': 0.27395498331649637}
2023-01-04 06:51:49,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:49,568 INFO:     Epoch: 98
2023-01-04 06:51:51,159 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3736532717943192, 'Total loss': 0.3736532717943192} | train loss {'Reaction outcome loss': 0.2733533502916136, 'Total loss': 0.2733533502916136}
2023-01-04 06:51:51,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:51,160 INFO:     Epoch: 99
2023-01-04 06:51:52,744 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3829036206007004, 'Total loss': 0.3829036206007004} | train loss {'Reaction outcome loss': 0.26877811045422884, 'Total loss': 0.26877811045422884}
2023-01-04 06:51:52,745 INFO:     Best model found after epoch 97 of 100.
2023-01-04 06:51:52,745 INFO:   Done with stage: TRAINING
2023-01-04 06:51:52,745 INFO:   Starting stage: EVALUATION
2023-01-04 06:51:52,867 INFO:   Done with stage: EVALUATION
2023-01-04 06:51:52,867 INFO:   Leaving out SEQ value Fold_9
2023-01-04 06:51:52,880 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 06:51:52,880 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:51:53,528 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:51:53,528 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:51:53,597 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:51:53,597 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:51:53,597 INFO:     No hyperparam tuning for this model
2023-01-04 06:51:53,598 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:51:53,598 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:51:53,598 INFO:     None feature selector for col prot
2023-01-04 06:51:53,598 INFO:     None feature selector for col prot
2023-01-04 06:51:53,599 INFO:     None feature selector for col prot
2023-01-04 06:51:53,599 INFO:     None feature selector for col chem
2023-01-04 06:51:53,599 INFO:     None feature selector for col chem
2023-01-04 06:51:53,599 INFO:     None feature selector for col chem
2023-01-04 06:51:53,599 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:51:53,599 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:51:53,600 INFO:     Number of params in model 70111
2023-01-04 06:51:53,603 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:51:53,604 INFO:   Starting stage: TRAINING
2023-01-04 06:51:53,646 INFO:     Val loss before train {'Reaction outcome loss': 0.979175865650177, 'Total loss': 0.979175865650177}
2023-01-04 06:51:53,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:53,647 INFO:     Epoch: 0
2023-01-04 06:51:55,213 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7257826904455821, 'Total loss': 0.7257826904455821} | train loss {'Reaction outcome loss': 0.8642546926503596, 'Total loss': 0.8642546926503596}
2023-01-04 06:51:55,213 INFO:     Found new best model at epoch 0
2023-01-04 06:51:55,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:55,213 INFO:     Epoch: 1
2023-01-04 06:51:56,755 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6423534532388051, 'Total loss': 0.6423534532388051} | train loss {'Reaction outcome loss': 0.7256780441688455, 'Total loss': 0.7256780441688455}
2023-01-04 06:51:56,755 INFO:     Found new best model at epoch 1
2023-01-04 06:51:56,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:56,756 INFO:     Epoch: 2
2023-01-04 06:51:58,342 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6250807881355286, 'Total loss': 0.6250807881355286} | train loss {'Reaction outcome loss': 0.625018518148125, 'Total loss': 0.625018518148125}
2023-01-04 06:51:58,343 INFO:     Found new best model at epoch 2
2023-01-04 06:51:58,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:58,343 INFO:     Epoch: 3
2023-01-04 06:51:59,939 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5791211863358815, 'Total loss': 0.5791211863358815} | train loss {'Reaction outcome loss': 0.5737697853828254, 'Total loss': 0.5737697853828254}
2023-01-04 06:51:59,939 INFO:     Found new best model at epoch 3
2023-01-04 06:51:59,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:51:59,939 INFO:     Epoch: 4
2023-01-04 06:52:01,528 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5706912438074748, 'Total loss': 0.5706912438074748} | train loss {'Reaction outcome loss': 0.5329044793826946, 'Total loss': 0.5329044793826946}
2023-01-04 06:52:01,528 INFO:     Found new best model at epoch 4
2023-01-04 06:52:01,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:01,529 INFO:     Epoch: 5
2023-01-04 06:52:03,078 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5452578127384186, 'Total loss': 0.5452578127384186} | train loss {'Reaction outcome loss': 0.5141597598035267, 'Total loss': 0.5141597598035267}
2023-01-04 06:52:03,078 INFO:     Found new best model at epoch 5
2023-01-04 06:52:03,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:03,079 INFO:     Epoch: 6
2023-01-04 06:52:04,640 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5383912821610769, 'Total loss': 0.5383912821610769} | train loss {'Reaction outcome loss': 0.5043207338295769, 'Total loss': 0.5043207338295769}
2023-01-04 06:52:04,641 INFO:     Found new best model at epoch 6
2023-01-04 06:52:04,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:04,641 INFO:     Epoch: 7
2023-01-04 06:52:06,220 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5688874165217082, 'Total loss': 0.5688874165217082} | train loss {'Reaction outcome loss': 0.49273116689890734, 'Total loss': 0.49273116689890734}
2023-01-04 06:52:06,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:06,220 INFO:     Epoch: 8
2023-01-04 06:52:07,814 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5129505753517151, 'Total loss': 0.5129505753517151} | train loss {'Reaction outcome loss': 0.4815270528332263, 'Total loss': 0.4815270528332263}
2023-01-04 06:52:07,814 INFO:     Found new best model at epoch 8
2023-01-04 06:52:07,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:07,815 INFO:     Epoch: 9
2023-01-04 06:52:09,400 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.50359974304835, 'Total loss': 0.50359974304835} | train loss {'Reaction outcome loss': 0.47412754481057706, 'Total loss': 0.47412754481057706}
2023-01-04 06:52:09,401 INFO:     Found new best model at epoch 9
2023-01-04 06:52:09,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:09,402 INFO:     Epoch: 10
2023-01-04 06:52:10,983 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5134470979372661, 'Total loss': 0.5134470979372661} | train loss {'Reaction outcome loss': 0.4650917998312608, 'Total loss': 0.4650917998312608}
2023-01-04 06:52:10,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:10,984 INFO:     Epoch: 11
2023-01-04 06:52:12,590 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5314985096454621, 'Total loss': 0.5314985096454621} | train loss {'Reaction outcome loss': 0.4606941059785153, 'Total loss': 0.4606941059785153}
2023-01-04 06:52:12,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:12,590 INFO:     Epoch: 12
2023-01-04 06:52:14,140 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4948176383972168, 'Total loss': 0.4948176383972168} | train loss {'Reaction outcome loss': 0.4569956449710805, 'Total loss': 0.4569956449710805}
2023-01-04 06:52:14,141 INFO:     Found new best model at epoch 12
2023-01-04 06:52:14,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:14,141 INFO:     Epoch: 13
2023-01-04 06:52:15,755 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49868012269337975, 'Total loss': 0.49868012269337975} | train loss {'Reaction outcome loss': 0.45375718427079637, 'Total loss': 0.45375718427079637}
2023-01-04 06:52:15,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:15,756 INFO:     Epoch: 14
2023-01-04 06:52:17,329 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5167248845100403, 'Total loss': 0.5167248845100403} | train loss {'Reaction outcome loss': 0.46975403057708254, 'Total loss': 0.46975403057708254}
2023-01-04 06:52:17,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:17,329 INFO:     Epoch: 15
2023-01-04 06:52:18,894 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4850589632987976, 'Total loss': 0.4850589632987976} | train loss {'Reaction outcome loss': 0.44713496572027606, 'Total loss': 0.44713496572027606}
2023-01-04 06:52:18,895 INFO:     Found new best model at epoch 15
2023-01-04 06:52:18,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:18,895 INFO:     Epoch: 16
2023-01-04 06:52:20,414 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48301882147789, 'Total loss': 0.48301882147789} | train loss {'Reaction outcome loss': 0.4383745822461619, 'Total loss': 0.4383745822461619}
2023-01-04 06:52:20,414 INFO:     Found new best model at epoch 16
2023-01-04 06:52:20,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:20,415 INFO:     Epoch: 17
2023-01-04 06:52:21,972 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5027842442194621, 'Total loss': 0.5027842442194621} | train loss {'Reaction outcome loss': 0.4328977853275727, 'Total loss': 0.4328977853275727}
2023-01-04 06:52:21,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:21,973 INFO:     Epoch: 18
2023-01-04 06:52:23,485 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5709509253501892, 'Total loss': 0.5709509253501892} | train loss {'Reaction outcome loss': 0.43519843180758366, 'Total loss': 0.43519843180758366}
2023-01-04 06:52:23,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:23,485 INFO:     Epoch: 19
2023-01-04 06:52:25,033 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4813821812470754, 'Total loss': 0.4813821812470754} | train loss {'Reaction outcome loss': 0.4436345799299686, 'Total loss': 0.4436345799299686}
2023-01-04 06:52:25,033 INFO:     Found new best model at epoch 19
2023-01-04 06:52:25,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:25,034 INFO:     Epoch: 20
2023-01-04 06:52:26,594 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47905345062414806, 'Total loss': 0.47905345062414806} | train loss {'Reaction outcome loss': 0.41751160286704375, 'Total loss': 0.41751160286704375}
2023-01-04 06:52:26,594 INFO:     Found new best model at epoch 20
2023-01-04 06:52:26,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:26,595 INFO:     Epoch: 21
2023-01-04 06:52:28,148 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45942063331604005, 'Total loss': 0.45942063331604005} | train loss {'Reaction outcome loss': 0.4145408557967091, 'Total loss': 0.4145408557967091}
2023-01-04 06:52:28,149 INFO:     Found new best model at epoch 21
2023-01-04 06:52:28,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:28,150 INFO:     Epoch: 22
2023-01-04 06:52:29,675 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46280160347620647, 'Total loss': 0.46280160347620647} | train loss {'Reaction outcome loss': 0.40832959373306105, 'Total loss': 0.40832959373306105}
2023-01-04 06:52:29,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:29,675 INFO:     Epoch: 23
2023-01-04 06:52:31,226 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4642001132170359, 'Total loss': 0.4642001132170359} | train loss {'Reaction outcome loss': 0.4073186841712374, 'Total loss': 0.4073186841712374}
2023-01-04 06:52:31,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:31,227 INFO:     Epoch: 24
2023-01-04 06:52:32,752 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4547629378736019, 'Total loss': 0.4547629378736019} | train loss {'Reaction outcome loss': 0.4013039593448174, 'Total loss': 0.4013039593448174}
2023-01-04 06:52:32,752 INFO:     Found new best model at epoch 24
2023-01-04 06:52:32,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:32,753 INFO:     Epoch: 25
2023-01-04 06:52:34,312 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45655061999956764, 'Total loss': 0.45655061999956764} | train loss {'Reaction outcome loss': 0.4034753997094821, 'Total loss': 0.4034753997094821}
2023-01-04 06:52:34,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:34,313 INFO:     Epoch: 26
2023-01-04 06:52:35,863 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46471029818058013, 'Total loss': 0.46471029818058013} | train loss {'Reaction outcome loss': 0.39913355165660597, 'Total loss': 0.39913355165660597}
2023-01-04 06:52:35,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:35,863 INFO:     Epoch: 27
2023-01-04 06:52:37,430 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45786769191424054, 'Total loss': 0.45786769191424054} | train loss {'Reaction outcome loss': 0.38993975172090123, 'Total loss': 0.38993975172090123}
2023-01-04 06:52:37,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:37,430 INFO:     Epoch: 28
2023-01-04 06:52:38,957 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4620649993419647, 'Total loss': 0.4620649993419647} | train loss {'Reaction outcome loss': 0.38694533303487993, 'Total loss': 0.38694533303487993}
2023-01-04 06:52:38,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:38,957 INFO:     Epoch: 29
2023-01-04 06:52:40,532 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4514442145824432, 'Total loss': 0.4514442145824432} | train loss {'Reaction outcome loss': 0.3826341951076967, 'Total loss': 0.3826341951076967}
2023-01-04 06:52:40,532 INFO:     Found new best model at epoch 29
2023-01-04 06:52:40,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:40,533 INFO:     Epoch: 30
2023-01-04 06:52:42,064 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44119927485783894, 'Total loss': 0.44119927485783894} | train loss {'Reaction outcome loss': 0.37564992983748263, 'Total loss': 0.37564992983748263}
2023-01-04 06:52:42,064 INFO:     Found new best model at epoch 30
2023-01-04 06:52:42,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:42,065 INFO:     Epoch: 31
2023-01-04 06:52:43,644 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.508960243066152, 'Total loss': 0.508960243066152} | train loss {'Reaction outcome loss': 0.37703627711027, 'Total loss': 0.37703627711027}
2023-01-04 06:52:43,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:43,644 INFO:     Epoch: 32
2023-01-04 06:52:45,217 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46176633139451345, 'Total loss': 0.46176633139451345} | train loss {'Reaction outcome loss': 0.3750628676211488, 'Total loss': 0.3750628676211488}
2023-01-04 06:52:45,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:45,218 INFO:     Epoch: 33
2023-01-04 06:52:46,795 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4459380825360616, 'Total loss': 0.4459380825360616} | train loss {'Reaction outcome loss': 0.3745371437213127, 'Total loss': 0.3745371437213127}
2023-01-04 06:52:46,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:46,795 INFO:     Epoch: 34
2023-01-04 06:52:48,327 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41391103665033974, 'Total loss': 0.41391103665033974} | train loss {'Reaction outcome loss': 0.3665387759633038, 'Total loss': 0.3665387759633038}
2023-01-04 06:52:48,327 INFO:     Found new best model at epoch 34
2023-01-04 06:52:48,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:48,327 INFO:     Epoch: 35
2023-01-04 06:52:49,878 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4244892746210098, 'Total loss': 0.4244892746210098} | train loss {'Reaction outcome loss': 0.3849663605940515, 'Total loss': 0.3849663605940515}
2023-01-04 06:52:49,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:49,879 INFO:     Epoch: 36
2023-01-04 06:52:51,423 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4742479960123698, 'Total loss': 0.4742479960123698} | train loss {'Reaction outcome loss': 0.3651655345473547, 'Total loss': 0.3651655345473547}
2023-01-04 06:52:51,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:51,424 INFO:     Epoch: 37
2023-01-04 06:52:52,986 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4459984004497528, 'Total loss': 0.4459984004497528} | train loss {'Reaction outcome loss': 0.36258683376852235, 'Total loss': 0.36258683376852235}
2023-01-04 06:52:52,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:52,987 INFO:     Epoch: 38
2023-01-04 06:52:54,548 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4585105220476786, 'Total loss': 0.4585105220476786} | train loss {'Reaction outcome loss': 0.35298461820428306, 'Total loss': 0.35298461820428306}
2023-01-04 06:52:54,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:54,548 INFO:     Epoch: 39
2023-01-04 06:52:56,100 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44069235722223915, 'Total loss': 0.44069235722223915} | train loss {'Reaction outcome loss': 0.3465581239973856, 'Total loss': 0.3465581239973856}
2023-01-04 06:52:56,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:56,100 INFO:     Epoch: 40
2023-01-04 06:52:57,636 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4548397938410441, 'Total loss': 0.4548397938410441} | train loss {'Reaction outcome loss': 0.37043075325588387, 'Total loss': 0.37043075325588387}
2023-01-04 06:52:57,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:57,636 INFO:     Epoch: 41
2023-01-04 06:52:59,195 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4438557078440984, 'Total loss': 0.4438557078440984} | train loss {'Reaction outcome loss': 0.35457864228827524, 'Total loss': 0.35457864228827524}
2023-01-04 06:52:59,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:52:59,195 INFO:     Epoch: 42
2023-01-04 06:53:00,723 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47247567772865295, 'Total loss': 0.47247567772865295} | train loss {'Reaction outcome loss': 0.3386239646886521, 'Total loss': 0.3386239646886521}
2023-01-04 06:53:00,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:00,723 INFO:     Epoch: 43
2023-01-04 06:53:02,296 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42956689099470774, 'Total loss': 0.42956689099470774} | train loss {'Reaction outcome loss': 0.34139771656929585, 'Total loss': 0.34139771656929585}
2023-01-04 06:53:02,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:02,296 INFO:     Epoch: 44
2023-01-04 06:53:03,853 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42994852463404337, 'Total loss': 0.42994852463404337} | train loss {'Reaction outcome loss': 0.3370133862928555, 'Total loss': 0.3370133862928555}
2023-01-04 06:53:03,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:03,854 INFO:     Epoch: 45
2023-01-04 06:53:05,422 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4196139395236969, 'Total loss': 0.4196139395236969} | train loss {'Reaction outcome loss': 0.33286714817117224, 'Total loss': 0.33286714817117224}
2023-01-04 06:53:05,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:05,422 INFO:     Epoch: 46
2023-01-04 06:53:06,942 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4263567934433619, 'Total loss': 0.4263567934433619} | train loss {'Reaction outcome loss': 0.33120826646420715, 'Total loss': 0.33120826646420715}
2023-01-04 06:53:06,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:06,942 INFO:     Epoch: 47
2023-01-04 06:53:08,508 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42120655824740727, 'Total loss': 0.42120655824740727} | train loss {'Reaction outcome loss': 0.32645722702516755, 'Total loss': 0.32645722702516755}
2023-01-04 06:53:08,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:08,508 INFO:     Epoch: 48
2023-01-04 06:53:10,101 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.447660286227862, 'Total loss': 0.447660286227862} | train loss {'Reaction outcome loss': 0.3383006732101026, 'Total loss': 0.3383006732101026}
2023-01-04 06:53:10,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:10,102 INFO:     Epoch: 49
2023-01-04 06:53:11,697 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4296820471684138, 'Total loss': 0.4296820471684138} | train loss {'Reaction outcome loss': 0.38273683384708734, 'Total loss': 0.38273683384708734}
2023-01-04 06:53:11,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:11,697 INFO:     Epoch: 50
2023-01-04 06:53:13,275 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4569899300734202, 'Total loss': 0.4569899300734202} | train loss {'Reaction outcome loss': 0.3406575247645378, 'Total loss': 0.3406575247645378}
2023-01-04 06:53:13,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:13,275 INFO:     Epoch: 51
2023-01-04 06:53:14,843 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4165236751238505, 'Total loss': 0.4165236751238505} | train loss {'Reaction outcome loss': 0.3236230360457937, 'Total loss': 0.3236230360457937}
2023-01-04 06:53:14,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:14,843 INFO:     Epoch: 52
2023-01-04 06:53:16,395 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4048505653937658, 'Total loss': 0.4048505653937658} | train loss {'Reaction outcome loss': 0.3174572483032429, 'Total loss': 0.3174572483032429}
2023-01-04 06:53:16,395 INFO:     Found new best model at epoch 52
2023-01-04 06:53:16,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:16,396 INFO:     Epoch: 53
2023-01-04 06:53:17,940 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47948727011680603, 'Total loss': 0.47948727011680603} | train loss {'Reaction outcome loss': 0.3161284384499911, 'Total loss': 0.3161284384499911}
2023-01-04 06:53:17,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:17,940 INFO:     Epoch: 54
2023-01-04 06:53:19,505 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48059675097465515, 'Total loss': 0.48059675097465515} | train loss {'Reaction outcome loss': 0.3129396271163031, 'Total loss': 0.3129396271163031}
2023-01-04 06:53:19,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:19,505 INFO:     Epoch: 55
2023-01-04 06:53:21,079 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42845498621463773, 'Total loss': 0.42845498621463773} | train loss {'Reaction outcome loss': 0.3126670070764637, 'Total loss': 0.3126670070764637}
2023-01-04 06:53:21,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:21,080 INFO:     Epoch: 56
2023-01-04 06:53:22,647 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43032242854436237, 'Total loss': 0.43032242854436237} | train loss {'Reaction outcome loss': 0.30860047444593214, 'Total loss': 0.30860047444593214}
2023-01-04 06:53:22,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:22,647 INFO:     Epoch: 57
2023-01-04 06:53:24,170 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42247986992200215, 'Total loss': 0.42247986992200215} | train loss {'Reaction outcome loss': 0.310127428719315, 'Total loss': 0.310127428719315}
2023-01-04 06:53:24,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:24,170 INFO:     Epoch: 58
2023-01-04 06:53:25,746 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42152603566646574, 'Total loss': 0.42152603566646574} | train loss {'Reaction outcome loss': 0.30725412992625567, 'Total loss': 0.30725412992625567}
2023-01-04 06:53:25,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:25,746 INFO:     Epoch: 59
2023-01-04 06:53:27,275 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46685171524683633, 'Total loss': 0.46685171524683633} | train loss {'Reaction outcome loss': 0.3024466551939005, 'Total loss': 0.3024466551939005}
2023-01-04 06:53:27,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:27,276 INFO:     Epoch: 60
2023-01-04 06:53:28,839 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.441116464138031, 'Total loss': 0.441116464138031} | train loss {'Reaction outcome loss': 0.30217972235160245, 'Total loss': 0.30217972235160245}
2023-01-04 06:53:28,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:28,839 INFO:     Epoch: 61
2023-01-04 06:53:30,398 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4538625458876292, 'Total loss': 0.4538625458876292} | train loss {'Reaction outcome loss': 0.29519496097877296, 'Total loss': 0.29519496097877296}
2023-01-04 06:53:30,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:30,399 INFO:     Epoch: 62
2023-01-04 06:53:31,949 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4367865651845932, 'Total loss': 0.4367865651845932} | train loss {'Reaction outcome loss': 0.29830059655391605, 'Total loss': 0.29830059655391605}
2023-01-04 06:53:31,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:31,949 INFO:     Epoch: 63
2023-01-04 06:53:33,484 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4127546976010005, 'Total loss': 0.4127546976010005} | train loss {'Reaction outcome loss': 0.30260537445977115, 'Total loss': 0.30260537445977115}
2023-01-04 06:53:33,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:33,484 INFO:     Epoch: 64
2023-01-04 06:53:35,072 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4588019162416458, 'Total loss': 0.4588019162416458} | train loss {'Reaction outcome loss': 0.32551757982878043, 'Total loss': 0.32551757982878043}
2023-01-04 06:53:35,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:35,072 INFO:     Epoch: 65
2023-01-04 06:53:36,633 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4238360603650411, 'Total loss': 0.4238360603650411} | train loss {'Reaction outcome loss': 0.2978901654562872, 'Total loss': 0.2978901654562872}
2023-01-04 06:53:36,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:36,633 INFO:     Epoch: 66
2023-01-04 06:53:38,207 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44546757141749066, 'Total loss': 0.44546757141749066} | train loss {'Reaction outcome loss': 0.30537959266254894, 'Total loss': 0.30537959266254894}
2023-01-04 06:53:38,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:38,207 INFO:     Epoch: 67
2023-01-04 06:53:39,798 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4097283542156219, 'Total loss': 0.4097283542156219} | train loss {'Reaction outcome loss': 0.2916512616633343, 'Total loss': 0.2916512616633343}
2023-01-04 06:53:39,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:39,799 INFO:     Epoch: 68
2023-01-04 06:53:41,370 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4382497479518255, 'Total loss': 0.4382497479518255} | train loss {'Reaction outcome loss': 0.28802613790174003, 'Total loss': 0.28802613790174003}
2023-01-04 06:53:41,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:41,370 INFO:     Epoch: 69
2023-01-04 06:53:42,920 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42778241833051045, 'Total loss': 0.42778241833051045} | train loss {'Reaction outcome loss': 0.29232729202055413, 'Total loss': 0.29232729202055413}
2023-01-04 06:53:42,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:42,920 INFO:     Epoch: 70
2023-01-04 06:53:44,488 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43972307741641997, 'Total loss': 0.43972307741641997} | train loss {'Reaction outcome loss': 0.2953704203542472, 'Total loss': 0.2953704203542472}
2023-01-04 06:53:44,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:44,488 INFO:     Epoch: 71
2023-01-04 06:53:46,022 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4230640520652135, 'Total loss': 0.4230640520652135} | train loss {'Reaction outcome loss': 0.2849408117632476, 'Total loss': 0.2849408117632476}
2023-01-04 06:53:46,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:46,022 INFO:     Epoch: 72
2023-01-04 06:53:47,576 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4247098525365194, 'Total loss': 0.4247098525365194} | train loss {'Reaction outcome loss': 0.27911784418308566, 'Total loss': 0.27911784418308566}
2023-01-04 06:53:47,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:47,577 INFO:     Epoch: 73
2023-01-04 06:53:49,140 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41880755523840585, 'Total loss': 0.41880755523840585} | train loss {'Reaction outcome loss': 0.2819480515908504, 'Total loss': 0.2819480515908504}
2023-01-04 06:53:49,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:49,140 INFO:     Epoch: 74
2023-01-04 06:53:50,695 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.451055775086085, 'Total loss': 0.451055775086085} | train loss {'Reaction outcome loss': 0.2819632226111961, 'Total loss': 0.2819632226111961}
2023-01-04 06:53:50,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:50,695 INFO:     Epoch: 75
2023-01-04 06:53:52,225 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43068364361921946, 'Total loss': 0.43068364361921946} | train loss {'Reaction outcome loss': 0.27838354930323816, 'Total loss': 0.27838354930323816}
2023-01-04 06:53:52,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:52,225 INFO:     Epoch: 76
2023-01-04 06:53:53,783 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4227750192085902, 'Total loss': 0.4227750192085902} | train loss {'Reaction outcome loss': 0.2749800098142747, 'Total loss': 0.2749800098142747}
2023-01-04 06:53:53,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:53,783 INFO:     Epoch: 77
2023-01-04 06:53:55,366 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46022251645723977, 'Total loss': 0.46022251645723977} | train loss {'Reaction outcome loss': 0.2930838987501203, 'Total loss': 0.2930838987501203}
2023-01-04 06:53:55,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:55,366 INFO:     Epoch: 78
2023-01-04 06:53:57,001 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42844154238700866, 'Total loss': 0.42844154238700866} | train loss {'Reaction outcome loss': 0.31585496156543924, 'Total loss': 0.31585496156543924}
2023-01-04 06:53:57,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:57,002 INFO:     Epoch: 79
2023-01-04 06:53:58,596 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.433914707104365, 'Total loss': 0.433914707104365} | train loss {'Reaction outcome loss': 0.3274415391632288, 'Total loss': 0.3274415391632288}
2023-01-04 06:53:58,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:53:58,596 INFO:     Epoch: 80
2023-01-04 06:54:00,164 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42966307600339254, 'Total loss': 0.42966307600339254} | train loss {'Reaction outcome loss': 0.28711152411119983, 'Total loss': 0.28711152411119983}
2023-01-04 06:54:00,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:00,165 INFO:     Epoch: 81
2023-01-04 06:54:01,699 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41149616638819375, 'Total loss': 0.41149616638819375} | train loss {'Reaction outcome loss': 0.2793667473879, 'Total loss': 0.2793667473879}
2023-01-04 06:54:01,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:01,699 INFO:     Epoch: 82
2023-01-04 06:54:03,222 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44530378679434457, 'Total loss': 0.44530378679434457} | train loss {'Reaction outcome loss': 0.2726179465818754, 'Total loss': 0.2726179465818754}
2023-01-04 06:54:03,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:03,222 INFO:     Epoch: 83
2023-01-04 06:54:04,780 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45252712070941925, 'Total loss': 0.45252712070941925} | train loss {'Reaction outcome loss': 0.2713572891704077, 'Total loss': 0.2713572891704077}
2023-01-04 06:54:04,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:04,781 INFO:     Epoch: 84
2023-01-04 06:54:06,322 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4416667560736338, 'Total loss': 0.4416667560736338} | train loss {'Reaction outcome loss': 0.266628249845319, 'Total loss': 0.266628249845319}
2023-01-04 06:54:06,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:06,322 INFO:     Epoch: 85
2023-01-04 06:54:07,879 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46367779076099397, 'Total loss': 0.46367779076099397} | train loss {'Reaction outcome loss': 0.266890037426914, 'Total loss': 0.266890037426914}
2023-01-04 06:54:07,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:07,879 INFO:     Epoch: 86
2023-01-04 06:54:09,424 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41918377776940663, 'Total loss': 0.41918377776940663} | train loss {'Reaction outcome loss': 0.27422988097701373, 'Total loss': 0.27422988097701373}
2023-01-04 06:54:09,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:09,425 INFO:     Epoch: 87
2023-01-04 06:54:10,969 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41109301447868346, 'Total loss': 0.41109301447868346} | train loss {'Reaction outcome loss': 0.28295156104571145, 'Total loss': 0.28295156104571145}
2023-01-04 06:54:10,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:10,969 INFO:     Epoch: 88
2023-01-04 06:54:12,494 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4358952055374781, 'Total loss': 0.4358952055374781} | train loss {'Reaction outcome loss': 0.28364953733440756, 'Total loss': 0.28364953733440756}
2023-01-04 06:54:12,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:12,495 INFO:     Epoch: 89
2023-01-04 06:54:14,039 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4445635745922724, 'Total loss': 0.4445635745922724} | train loss {'Reaction outcome loss': 0.2691390390492692, 'Total loss': 0.2691390390492692}
2023-01-04 06:54:14,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:14,039 INFO:     Epoch: 90
2023-01-04 06:54:15,589 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4314910034338633, 'Total loss': 0.4314910034338633} | train loss {'Reaction outcome loss': 0.25894331602730614, 'Total loss': 0.25894331602730614}
2023-01-04 06:54:15,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:15,590 INFO:     Epoch: 91
2023-01-04 06:54:17,132 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40980587402979535, 'Total loss': 0.40980587402979535} | train loss {'Reaction outcome loss': 0.26595428156113066, 'Total loss': 0.26595428156113066}
2023-01-04 06:54:17,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:17,132 INFO:     Epoch: 92
2023-01-04 06:54:18,648 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44357776443163555, 'Total loss': 0.44357776443163555} | train loss {'Reaction outcome loss': 0.25692578842627234, 'Total loss': 0.25692578842627234}
2023-01-04 06:54:18,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:18,648 INFO:     Epoch: 93
2023-01-04 06:54:20,197 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40729576150576274, 'Total loss': 0.40729576150576274} | train loss {'Reaction outcome loss': 0.25561442227521236, 'Total loss': 0.25561442227521236}
2023-01-04 06:54:20,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:20,197 INFO:     Epoch: 94
2023-01-04 06:54:21,711 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4608294486999512, 'Total loss': 0.4608294486999512} | train loss {'Reaction outcome loss': 0.2586216892831136, 'Total loss': 0.2586216892831136}
2023-01-04 06:54:21,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:21,711 INFO:     Epoch: 95
2023-01-04 06:54:23,283 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4137565712134043, 'Total loss': 0.4137565712134043} | train loss {'Reaction outcome loss': 0.26599068160884193, 'Total loss': 0.26599068160884193}
2023-01-04 06:54:23,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:23,283 INFO:     Epoch: 96
2023-01-04 06:54:24,844 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4132671892642975, 'Total loss': 0.4132671892642975} | train loss {'Reaction outcome loss': 0.25897804970606453, 'Total loss': 0.25897804970606453}
2023-01-04 06:54:24,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:24,844 INFO:     Epoch: 97
2023-01-04 06:54:26,389 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43254521787166594, 'Total loss': 0.43254521787166594} | train loss {'Reaction outcome loss': 0.2613774711664578, 'Total loss': 0.2613774711664578}
2023-01-04 06:54:26,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:26,390 INFO:     Epoch: 98
2023-01-04 06:54:27,899 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43438360492388406, 'Total loss': 0.43438360492388406} | train loss {'Reaction outcome loss': 0.2560308768913366, 'Total loss': 0.2560308768913366}
2023-01-04 06:54:27,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:27,899 INFO:     Epoch: 99
2023-01-04 06:54:29,447 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49393278459707896, 'Total loss': 0.49393278459707896} | train loss {'Reaction outcome loss': 0.2634142646970956, 'Total loss': 0.2634142646970956}
2023-01-04 06:54:29,447 INFO:     Best model found after epoch 53 of 100.
2023-01-04 06:54:29,447 INFO:   Done with stage: TRAINING
2023-01-04 06:54:29,447 INFO:   Starting stage: EVALUATION
2023-01-04 06:54:29,573 INFO:   Done with stage: EVALUATION
2023-01-04 06:54:29,581 INFO:   Leaving out SEQ value Fold_0
2023-01-04 06:54:29,593 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 06:54:29,594 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:54:30,238 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:54:30,238 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:54:30,308 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:54:30,308 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:54:30,308 INFO:     No hyperparam tuning for this model
2023-01-04 06:54:30,308 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:54:30,308 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:54:30,309 INFO:     None feature selector for col prot
2023-01-04 06:54:30,309 INFO:     None feature selector for col prot
2023-01-04 06:54:30,309 INFO:     None feature selector for col prot
2023-01-04 06:54:30,309 INFO:     None feature selector for col chem
2023-01-04 06:54:30,309 INFO:     None feature selector for col chem
2023-01-04 06:54:30,310 INFO:     None feature selector for col chem
2023-01-04 06:54:30,310 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:54:30,310 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:54:30,311 INFO:     Number of params in model 70111
2023-01-04 06:54:30,314 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:54:30,314 INFO:   Starting stage: TRAINING
2023-01-04 06:54:30,359 INFO:     Val loss before train {'Reaction outcome loss': 1.030888032913208, 'Total loss': 1.030888032913208}
2023-01-04 06:54:30,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:30,359 INFO:     Epoch: 0
2023-01-04 06:54:31,904 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7347857574621837, 'Total loss': 0.7347857574621837} | train loss {'Reaction outcome loss': 0.8447284946476457, 'Total loss': 0.8447284946476457}
2023-01-04 06:54:31,905 INFO:     Found new best model at epoch 0
2023-01-04 06:54:31,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:31,906 INFO:     Epoch: 1
2023-01-04 06:54:33,445 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5958067774772644, 'Total loss': 0.5958067774772644} | train loss {'Reaction outcome loss': 0.6807090370324407, 'Total loss': 0.6807090370324407}
2023-01-04 06:54:33,445 INFO:     Found new best model at epoch 1
2023-01-04 06:54:33,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:33,446 INFO:     Epoch: 2
2023-01-04 06:54:35,023 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5623910009860993, 'Total loss': 0.5623910009860993} | train loss {'Reaction outcome loss': 0.5795326970354484, 'Total loss': 0.5795326970354484}
2023-01-04 06:54:35,023 INFO:     Found new best model at epoch 2
2023-01-04 06:54:35,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:35,024 INFO:     Epoch: 3
2023-01-04 06:54:36,528 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5661707580089569, 'Total loss': 0.5661707580089569} | train loss {'Reaction outcome loss': 0.5344037138415079, 'Total loss': 0.5344037138415079}
2023-01-04 06:54:36,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:36,528 INFO:     Epoch: 4
2023-01-04 06:54:38,065 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5380754232406616, 'Total loss': 0.5380754232406616} | train loss {'Reaction outcome loss': 0.515647664883711, 'Total loss': 0.515647664883711}
2023-01-04 06:54:38,066 INFO:     Found new best model at epoch 4
2023-01-04 06:54:38,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:38,066 INFO:     Epoch: 5
2023-01-04 06:54:39,588 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5125574335455895, 'Total loss': 0.5125574335455895} | train loss {'Reaction outcome loss': 0.5007252528937194, 'Total loss': 0.5007252528937194}
2023-01-04 06:54:39,588 INFO:     Found new best model at epoch 5
2023-01-04 06:54:39,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:39,589 INFO:     Epoch: 6
2023-01-04 06:54:41,141 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5307394176721573, 'Total loss': 0.5307394176721573} | train loss {'Reaction outcome loss': 0.49155757641487746, 'Total loss': 0.49155757641487746}
2023-01-04 06:54:41,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:41,142 INFO:     Epoch: 7
2023-01-04 06:54:42,669 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5092205385367076, 'Total loss': 0.5092205385367076} | train loss {'Reaction outcome loss': 0.48127742027388004, 'Total loss': 0.48127742027388004}
2023-01-04 06:54:42,669 INFO:     Found new best model at epoch 7
2023-01-04 06:54:42,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:42,670 INFO:     Epoch: 8
2023-01-04 06:54:44,204 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49772757291793823, 'Total loss': 0.49772757291793823} | train loss {'Reaction outcome loss': 0.4768776800891344, 'Total loss': 0.4768776800891344}
2023-01-04 06:54:44,204 INFO:     Found new best model at epoch 8
2023-01-04 06:54:44,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:44,205 INFO:     Epoch: 9
2023-01-04 06:54:45,711 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4998543381690979, 'Total loss': 0.4998543381690979} | train loss {'Reaction outcome loss': 0.46872305883652104, 'Total loss': 0.46872305883652104}
2023-01-04 06:54:45,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:45,712 INFO:     Epoch: 10
2023-01-04 06:54:47,239 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5025651355584463, 'Total loss': 0.5025651355584463} | train loss {'Reaction outcome loss': 0.4609687667693535, 'Total loss': 0.4609687667693535}
2023-01-04 06:54:47,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:47,239 INFO:     Epoch: 11
2023-01-04 06:54:48,730 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4958334654569626, 'Total loss': 0.4958334654569626} | train loss {'Reaction outcome loss': 0.455502044817392, 'Total loss': 0.455502044817392}
2023-01-04 06:54:48,730 INFO:     Found new best model at epoch 11
2023-01-04 06:54:48,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:48,731 INFO:     Epoch: 12
2023-01-04 06:54:50,280 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4722791572411855, 'Total loss': 0.4722791572411855} | train loss {'Reaction outcome loss': 0.45235618089672425, 'Total loss': 0.45235618089672425}
2023-01-04 06:54:50,281 INFO:     Found new best model at epoch 12
2023-01-04 06:54:50,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:50,282 INFO:     Epoch: 13
2023-01-04 06:54:51,814 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4852372586727142, 'Total loss': 0.4852372586727142} | train loss {'Reaction outcome loss': 0.4460441622964657, 'Total loss': 0.4460441622964657}
2023-01-04 06:54:51,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:51,814 INFO:     Epoch: 14
2023-01-04 06:54:53,351 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48829576969146726, 'Total loss': 0.48829576969146726} | train loss {'Reaction outcome loss': 0.44141485512147854, 'Total loss': 0.44141485512147854}
2023-01-04 06:54:53,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:53,352 INFO:     Epoch: 15
2023-01-04 06:54:54,842 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46633642812569936, 'Total loss': 0.46633642812569936} | train loss {'Reaction outcome loss': 0.4369002490365592, 'Total loss': 0.4369002490365592}
2023-01-04 06:54:54,842 INFO:     Found new best model at epoch 15
2023-01-04 06:54:54,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:54,843 INFO:     Epoch: 16
2023-01-04 06:54:56,363 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4996928970019023, 'Total loss': 0.4996928970019023} | train loss {'Reaction outcome loss': 0.431328677021674, 'Total loss': 0.431328677021674}
2023-01-04 06:54:56,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:56,363 INFO:     Epoch: 17
2023-01-04 06:54:57,869 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47449131806691486, 'Total loss': 0.47449131806691486} | train loss {'Reaction outcome loss': 0.4290573017223038, 'Total loss': 0.4290573017223038}
2023-01-04 06:54:57,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:57,869 INFO:     Epoch: 18
2023-01-04 06:54:59,390 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4761682281891505, 'Total loss': 0.4761682281891505} | train loss {'Reaction outcome loss': 0.4270845927352453, 'Total loss': 0.4270845927352453}
2023-01-04 06:54:59,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:54:59,391 INFO:     Epoch: 19
2023-01-04 06:55:00,921 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4603486071030299, 'Total loss': 0.4603486071030299} | train loss {'Reaction outcome loss': 0.4253191316541094, 'Total loss': 0.4253191316541094}
2023-01-04 06:55:00,922 INFO:     Found new best model at epoch 19
2023-01-04 06:55:00,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:00,922 INFO:     Epoch: 20
2023-01-04 06:55:02,461 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46433841486771904, 'Total loss': 0.46433841486771904} | train loss {'Reaction outcome loss': 0.41683807626475383, 'Total loss': 0.41683807626475383}
2023-01-04 06:55:02,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:02,461 INFO:     Epoch: 21
2023-01-04 06:55:03,973 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45390416781107584, 'Total loss': 0.45390416781107584} | train loss {'Reaction outcome loss': 0.4149028706724626, 'Total loss': 0.4149028706724626}
2023-01-04 06:55:03,973 INFO:     Found new best model at epoch 21
2023-01-04 06:55:03,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:03,973 INFO:     Epoch: 22
2023-01-04 06:55:05,513 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4509261002143224, 'Total loss': 0.4509261002143224} | train loss {'Reaction outcome loss': 0.4075751388377517, 'Total loss': 0.4075751388377517}
2023-01-04 06:55:05,513 INFO:     Found new best model at epoch 22
2023-01-04 06:55:05,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:05,514 INFO:     Epoch: 23
2023-01-04 06:55:07,030 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.467719375093778, 'Total loss': 0.467719375093778} | train loss {'Reaction outcome loss': 0.4061931211800471, 'Total loss': 0.4061931211800471}
2023-01-04 06:55:07,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:07,030 INFO:     Epoch: 24
2023-01-04 06:55:08,561 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4730531215667725, 'Total loss': 0.4730531215667725} | train loss {'Reaction outcome loss': 0.40295286971504674, 'Total loss': 0.40295286971504674}
2023-01-04 06:55:08,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:08,562 INFO:     Epoch: 25
2023-01-04 06:55:10,105 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4496143877506256, 'Total loss': 0.4496143877506256} | train loss {'Reaction outcome loss': 0.4002782232569952, 'Total loss': 0.4002782232569952}
2023-01-04 06:55:10,105 INFO:     Found new best model at epoch 25
2023-01-04 06:55:10,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:10,106 INFO:     Epoch: 26
2023-01-04 06:55:11,644 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4530902475118637, 'Total loss': 0.4530902475118637} | train loss {'Reaction outcome loss': 0.3937732505265379, 'Total loss': 0.3937732505265379}
2023-01-04 06:55:11,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:11,645 INFO:     Epoch: 27
2023-01-04 06:55:13,142 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44364853103955587, 'Total loss': 0.44364853103955587} | train loss {'Reaction outcome loss': 0.39237050350456343, 'Total loss': 0.39237050350456343}
2023-01-04 06:55:13,143 INFO:     Found new best model at epoch 27
2023-01-04 06:55:13,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:13,143 INFO:     Epoch: 28
2023-01-04 06:55:14,683 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4359657257795334, 'Total loss': 0.4359657257795334} | train loss {'Reaction outcome loss': 0.38908756540639555, 'Total loss': 0.38908756540639555}
2023-01-04 06:55:14,684 INFO:     Found new best model at epoch 28
2023-01-04 06:55:14,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:14,685 INFO:     Epoch: 29
2023-01-04 06:55:16,185 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44965558548768364, 'Total loss': 0.44965558548768364} | train loss {'Reaction outcome loss': 0.385104729202542, 'Total loss': 0.385104729202542}
2023-01-04 06:55:16,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:16,185 INFO:     Epoch: 30
2023-01-04 06:55:17,747 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44018683036168416, 'Total loss': 0.44018683036168416} | train loss {'Reaction outcome loss': 0.382844139651878, 'Total loss': 0.382844139651878}
2023-01-04 06:55:17,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:17,747 INFO:     Epoch: 31
2023-01-04 06:55:19,295 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43403078615665436, 'Total loss': 0.43403078615665436} | train loss {'Reaction outcome loss': 0.3808808401770835, 'Total loss': 0.3808808401770835}
2023-01-04 06:55:19,295 INFO:     Found new best model at epoch 31
2023-01-04 06:55:19,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:19,296 INFO:     Epoch: 32
2023-01-04 06:55:20,849 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45551722049713134, 'Total loss': 0.45551722049713134} | train loss {'Reaction outcome loss': 0.37624455379308575, 'Total loss': 0.37624455379308575}
2023-01-04 06:55:20,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:20,850 INFO:     Epoch: 33
2023-01-04 06:55:22,370 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44020508031050365, 'Total loss': 0.44020508031050365} | train loss {'Reaction outcome loss': 0.3708026049672252, 'Total loss': 0.3708026049672252}
2023-01-04 06:55:22,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:22,370 INFO:     Epoch: 34
2023-01-04 06:55:23,942 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43730307221412656, 'Total loss': 0.43730307221412656} | train loss {'Reaction outcome loss': 0.37347342590563487, 'Total loss': 0.37347342590563487}
2023-01-04 06:55:23,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:23,942 INFO:     Epoch: 35
2023-01-04 06:55:25,475 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43846396207809446, 'Total loss': 0.43846396207809446} | train loss {'Reaction outcome loss': 0.36813741446520293, 'Total loss': 0.36813741446520293}
2023-01-04 06:55:25,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:25,475 INFO:     Epoch: 36
2023-01-04 06:55:27,042 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43802589078744253, 'Total loss': 0.43802589078744253} | train loss {'Reaction outcome loss': 0.36125555751423766, 'Total loss': 0.36125555751423766}
2023-01-04 06:55:27,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:27,043 INFO:     Epoch: 37
2023-01-04 06:55:28,607 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4430809160073598, 'Total loss': 0.4430809160073598} | train loss {'Reaction outcome loss': 0.35837462577071505, 'Total loss': 0.35837462577071505}
2023-01-04 06:55:28,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:28,607 INFO:     Epoch: 38
2023-01-04 06:55:30,132 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43414423366387683, 'Total loss': 0.43414423366387683} | train loss {'Reaction outcome loss': 0.3568069401339893, 'Total loss': 0.3568069401339893}
2023-01-04 06:55:30,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:30,132 INFO:     Epoch: 39
2023-01-04 06:55:31,673 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.422777451078097, 'Total loss': 0.422777451078097} | train loss {'Reaction outcome loss': 0.3538814447276349, 'Total loss': 0.3538814447276349}
2023-01-04 06:55:31,673 INFO:     Found new best model at epoch 39
2023-01-04 06:55:31,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:31,674 INFO:     Epoch: 40
2023-01-04 06:55:33,235 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4229352762301763, 'Total loss': 0.4229352762301763} | train loss {'Reaction outcome loss': 0.35159721007964906, 'Total loss': 0.35159721007964906}
2023-01-04 06:55:33,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:33,235 INFO:     Epoch: 41
2023-01-04 06:55:34,759 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.424145245552063, 'Total loss': 0.424145245552063} | train loss {'Reaction outcome loss': 0.3478933501254468, 'Total loss': 0.3478933501254468}
2023-01-04 06:55:34,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:34,759 INFO:     Epoch: 42
2023-01-04 06:55:36,332 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4378744959831238, 'Total loss': 0.4378744959831238} | train loss {'Reaction outcome loss': 0.35000114787342773, 'Total loss': 0.35000114787342773}
2023-01-04 06:55:36,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:36,332 INFO:     Epoch: 43
2023-01-04 06:55:37,898 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43281093140443166, 'Total loss': 0.43281093140443166} | train loss {'Reaction outcome loss': 0.34295861787387055, 'Total loss': 0.34295861787387055}
2023-01-04 06:55:37,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:37,898 INFO:     Epoch: 44
2023-01-04 06:55:39,469 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4057069520155589, 'Total loss': 0.4057069520155589} | train loss {'Reaction outcome loss': 0.33869638462571333, 'Total loss': 0.33869638462571333}
2023-01-04 06:55:39,469 INFO:     Found new best model at epoch 44
2023-01-04 06:55:39,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:39,470 INFO:     Epoch: 45
2023-01-04 06:55:40,995 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4013702760140101, 'Total loss': 0.4013702760140101} | train loss {'Reaction outcome loss': 0.3419174819532102, 'Total loss': 0.3419174819532102}
2023-01-04 06:55:40,996 INFO:     Found new best model at epoch 45
2023-01-04 06:55:40,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:40,996 INFO:     Epoch: 46
2023-01-04 06:55:42,551 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4116022119919459, 'Total loss': 0.4116022119919459} | train loss {'Reaction outcome loss': 0.3381485763366205, 'Total loss': 0.3381485763366205}
2023-01-04 06:55:42,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:42,551 INFO:     Epoch: 47
2023-01-04 06:55:43,625 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4229107548793157, 'Total loss': 0.4229107548793157} | train loss {'Reaction outcome loss': 0.3319292876624713, 'Total loss': 0.3319292876624713}
2023-01-04 06:55:43,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:43,626 INFO:     Epoch: 48
2023-01-04 06:55:44,641 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4052727222442627, 'Total loss': 0.4052727222442627} | train loss {'Reaction outcome loss': 0.33479856414190173, 'Total loss': 0.33479856414190173}
2023-01-04 06:55:44,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:44,642 INFO:     Epoch: 49
2023-01-04 06:55:45,653 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4189439833164215, 'Total loss': 0.4189439833164215} | train loss {'Reaction outcome loss': 0.33139949754206804, 'Total loss': 0.33139949754206804}
2023-01-04 06:55:45,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:45,653 INFO:     Epoch: 50
2023-01-04 06:55:46,665 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4101744830608368, 'Total loss': 0.4101744830608368} | train loss {'Reaction outcome loss': 0.3222931918490977, 'Total loss': 0.3222931918490977}
2023-01-04 06:55:46,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:46,665 INFO:     Epoch: 51
2023-01-04 06:55:48,095 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43197169502576194, 'Total loss': 0.43197169502576194} | train loss {'Reaction outcome loss': 0.3202706100623103, 'Total loss': 0.3202706100623103}
2023-01-04 06:55:48,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:48,095 INFO:     Epoch: 52
2023-01-04 06:55:49,679 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4060423920551936, 'Total loss': 0.4060423920551936} | train loss {'Reaction outcome loss': 0.32138540459810383, 'Total loss': 0.32138540459810383}
2023-01-04 06:55:49,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:49,680 INFO:     Epoch: 53
2023-01-04 06:55:51,260 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4107226744294167, 'Total loss': 0.4107226744294167} | train loss {'Reaction outcome loss': 0.32265469804406166, 'Total loss': 0.32265469804406166}
2023-01-04 06:55:51,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:51,260 INFO:     Epoch: 54
2023-01-04 06:55:52,844 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4323985705773036, 'Total loss': 0.4323985705773036} | train loss {'Reaction outcome loss': 0.31584718396520095, 'Total loss': 0.31584718396520095}
2023-01-04 06:55:52,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:52,844 INFO:     Epoch: 55
2023-01-04 06:55:54,428 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41360089580217996, 'Total loss': 0.41360089580217996} | train loss {'Reaction outcome loss': 0.3161107393892577, 'Total loss': 0.3161107393892577}
2023-01-04 06:55:54,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:54,428 INFO:     Epoch: 56
2023-01-04 06:55:55,975 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4199781676133474, 'Total loss': 0.4199781676133474} | train loss {'Reaction outcome loss': 0.3137506541462928, 'Total loss': 0.3137506541462928}
2023-01-04 06:55:55,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:55,976 INFO:     Epoch: 57
2023-01-04 06:55:57,515 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4288551390171051, 'Total loss': 0.4288551390171051} | train loss {'Reaction outcome loss': 0.3087422085830765, 'Total loss': 0.3087422085830765}
2023-01-04 06:55:57,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:57,515 INFO:     Epoch: 58
2023-01-04 06:55:59,094 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41550060907999675, 'Total loss': 0.41550060907999675} | train loss {'Reaction outcome loss': 0.30933477743154897, 'Total loss': 0.30933477743154897}
2023-01-04 06:55:59,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:55:59,094 INFO:     Epoch: 59
2023-01-04 06:56:00,665 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4209787716468175, 'Total loss': 0.4209787716468175} | train loss {'Reaction outcome loss': 0.3079469963418741, 'Total loss': 0.3079469963418741}
2023-01-04 06:56:00,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:00,665 INFO:     Epoch: 60
2023-01-04 06:56:02,241 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41395310560862225, 'Total loss': 0.41395310560862225} | train loss {'Reaction outcome loss': 0.308126052610413, 'Total loss': 0.308126052610413}
2023-01-04 06:56:02,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:02,242 INFO:     Epoch: 61
2023-01-04 06:56:03,796 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4108828127384186, 'Total loss': 0.4108828127384186} | train loss {'Reaction outcome loss': 0.3054145233311357, 'Total loss': 0.3054145233311357}
2023-01-04 06:56:03,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:03,796 INFO:     Epoch: 62
2023-01-04 06:56:05,317 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4052653561035792, 'Total loss': 0.4052653561035792} | train loss {'Reaction outcome loss': 0.3054596890770171, 'Total loss': 0.3054596890770171}
2023-01-04 06:56:05,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:05,317 INFO:     Epoch: 63
2023-01-04 06:56:06,881 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4075267642736435, 'Total loss': 0.4075267642736435} | train loss {'Reaction outcome loss': 0.29892900009659956, 'Total loss': 0.29892900009659956}
2023-01-04 06:56:06,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:06,882 INFO:     Epoch: 64
2023-01-04 06:56:08,458 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3979361633459727, 'Total loss': 0.3979361633459727} | train loss {'Reaction outcome loss': 0.30264465529879514, 'Total loss': 0.30264465529879514}
2023-01-04 06:56:08,458 INFO:     Found new best model at epoch 64
2023-01-04 06:56:08,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:08,459 INFO:     Epoch: 65
2023-01-04 06:56:10,030 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3945608526468277, 'Total loss': 0.3945608526468277} | train loss {'Reaction outcome loss': 0.29669610666532586, 'Total loss': 0.29669610666532586}
2023-01-04 06:56:10,030 INFO:     Found new best model at epoch 65
2023-01-04 06:56:10,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:10,031 INFO:     Epoch: 66
2023-01-04 06:56:11,612 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38495645026365916, 'Total loss': 0.38495645026365916} | train loss {'Reaction outcome loss': 0.2953392321339054, 'Total loss': 0.2953392321339054}
2023-01-04 06:56:11,612 INFO:     Found new best model at epoch 66
2023-01-04 06:56:11,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:11,613 INFO:     Epoch: 67
2023-01-04 06:56:13,168 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3981643547614416, 'Total loss': 0.3981643547614416} | train loss {'Reaction outcome loss': 0.2911265587339001, 'Total loss': 0.2911265587339001}
2023-01-04 06:56:13,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:13,168 INFO:     Epoch: 68
2023-01-04 06:56:14,633 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44319144984086356, 'Total loss': 0.44319144984086356} | train loss {'Reaction outcome loss': 0.29332475592620183, 'Total loss': 0.29332475592620183}
2023-01-04 06:56:14,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:14,634 INFO:     Epoch: 69
2023-01-04 06:56:16,171 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41639088888963066, 'Total loss': 0.41639088888963066} | train loss {'Reaction outcome loss': 0.29432088297105186, 'Total loss': 0.29432088297105186}
2023-01-04 06:56:16,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:16,172 INFO:     Epoch: 70
2023-01-04 06:56:17,705 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38449924339850744, 'Total loss': 0.38449924339850744} | train loss {'Reaction outcome loss': 0.29351825082171573, 'Total loss': 0.29351825082171573}
2023-01-04 06:56:17,705 INFO:     Found new best model at epoch 70
2023-01-04 06:56:17,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:17,706 INFO:     Epoch: 71
2023-01-04 06:56:19,241 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40152282317479454, 'Total loss': 0.40152282317479454} | train loss {'Reaction outcome loss': 0.28905964865736716, 'Total loss': 0.28905964865736716}
2023-01-04 06:56:19,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:19,242 INFO:     Epoch: 72
2023-01-04 06:56:20,781 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43837762375672656, 'Total loss': 0.43837762375672656} | train loss {'Reaction outcome loss': 0.28969629522222673, 'Total loss': 0.28969629522222673}
2023-01-04 06:56:20,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:20,782 INFO:     Epoch: 73
2023-01-04 06:56:22,324 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42061087985833484, 'Total loss': 0.42061087985833484} | train loss {'Reaction outcome loss': 0.2892455724849753, 'Total loss': 0.2892455724849753}
2023-01-04 06:56:22,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:22,324 INFO:     Epoch: 74
2023-01-04 06:56:23,803 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42655460635821024, 'Total loss': 0.42655460635821024} | train loss {'Reaction outcome loss': 0.28547290641896045, 'Total loss': 0.28547290641896045}
2023-01-04 06:56:23,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:23,804 INFO:     Epoch: 75
2023-01-04 06:56:25,343 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40864548285802205, 'Total loss': 0.40864548285802205} | train loss {'Reaction outcome loss': 0.2819554922952704, 'Total loss': 0.2819554922952704}
2023-01-04 06:56:25,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:25,343 INFO:     Epoch: 76
2023-01-04 06:56:26,898 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41415552894274393, 'Total loss': 0.41415552894274393} | train loss {'Reaction outcome loss': 0.2811751136161985, 'Total loss': 0.2811751136161985}
2023-01-04 06:56:26,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:26,899 INFO:     Epoch: 77
2023-01-04 06:56:28,445 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.426066447297732, 'Total loss': 0.426066447297732} | train loss {'Reaction outcome loss': 0.28602530312364116, 'Total loss': 0.28602530312364116}
2023-01-04 06:56:28,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:28,445 INFO:     Epoch: 78
2023-01-04 06:56:29,986 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40627960761388143, 'Total loss': 0.40627960761388143} | train loss {'Reaction outcome loss': 0.2782831892343986, 'Total loss': 0.2782831892343986}
2023-01-04 06:56:29,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:29,987 INFO:     Epoch: 79
2023-01-04 06:56:31,533 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3954012165466944, 'Total loss': 0.3954012165466944} | train loss {'Reaction outcome loss': 0.2782002664341109, 'Total loss': 0.2782002664341109}
2023-01-04 06:56:31,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:31,534 INFO:     Epoch: 80
2023-01-04 06:56:33,004 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3888868550459544, 'Total loss': 0.3888868550459544} | train loss {'Reaction outcome loss': 0.2769445768237984, 'Total loss': 0.2769445768237984}
2023-01-04 06:56:33,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:33,005 INFO:     Epoch: 81
2023-01-04 06:56:34,580 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3898104836543401, 'Total loss': 0.3898104836543401} | train loss {'Reaction outcome loss': 0.27392885132427636, 'Total loss': 0.27392885132427636}
2023-01-04 06:56:34,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:34,580 INFO:     Epoch: 82
2023-01-04 06:56:36,170 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.407120872537295, 'Total loss': 0.407120872537295} | train loss {'Reaction outcome loss': 0.27410509013128975, 'Total loss': 0.27410509013128975}
2023-01-04 06:56:36,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:36,170 INFO:     Epoch: 83
2023-01-04 06:56:37,762 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4122707406679789, 'Total loss': 0.4122707406679789} | train loss {'Reaction outcome loss': 0.27777572827291314, 'Total loss': 0.27777572827291314}
2023-01-04 06:56:37,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:37,763 INFO:     Epoch: 84
2023-01-04 06:56:39,369 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3846462627251943, 'Total loss': 0.3846462627251943} | train loss {'Reaction outcome loss': 0.27509658556621874, 'Total loss': 0.27509658556621874}
2023-01-04 06:56:39,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:39,369 INFO:     Epoch: 85
2023-01-04 06:56:40,976 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4214348077774048, 'Total loss': 0.4214348077774048} | train loss {'Reaction outcome loss': 0.27382442719527406, 'Total loss': 0.27382442719527406}
2023-01-04 06:56:40,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:40,976 INFO:     Epoch: 86
2023-01-04 06:56:42,497 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38859848082065584, 'Total loss': 0.38859848082065584} | train loss {'Reaction outcome loss': 0.27321093562093096, 'Total loss': 0.27321093562093096}
2023-01-04 06:56:42,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:42,497 INFO:     Epoch: 87
2023-01-04 06:56:44,068 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3771166384220123, 'Total loss': 0.3771166384220123} | train loss {'Reaction outcome loss': 0.2659299088723577, 'Total loss': 0.2659299088723577}
2023-01-04 06:56:44,068 INFO:     Found new best model at epoch 87
2023-01-04 06:56:44,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:44,069 INFO:     Epoch: 88
2023-01-04 06:56:45,644 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.414897362391154, 'Total loss': 0.414897362391154} | train loss {'Reaction outcome loss': 0.2671704632875911, 'Total loss': 0.2671704632875911}
2023-01-04 06:56:45,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:45,646 INFO:     Epoch: 89
2023-01-04 06:56:47,228 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40039501984914144, 'Total loss': 0.40039501984914144} | train loss {'Reaction outcome loss': 0.2653886733753403, 'Total loss': 0.2653886733753403}
2023-01-04 06:56:47,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:47,228 INFO:     Epoch: 90
2023-01-04 06:56:48,815 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.381646795074145, 'Total loss': 0.381646795074145} | train loss {'Reaction outcome loss': 0.2643575960919805, 'Total loss': 0.2643575960919805}
2023-01-04 06:56:48,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:48,815 INFO:     Epoch: 91
2023-01-04 06:56:50,377 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3935834328333537, 'Total loss': 0.3935834328333537} | train loss {'Reaction outcome loss': 0.2603163303413095, 'Total loss': 0.2603163303413095}
2023-01-04 06:56:50,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:50,377 INFO:     Epoch: 92
2023-01-04 06:56:51,911 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4108976870775223, 'Total loss': 0.4108976870775223} | train loss {'Reaction outcome loss': 0.26721939526117633, 'Total loss': 0.26721939526117633}
2023-01-04 06:56:51,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:51,912 INFO:     Epoch: 93
2023-01-04 06:56:53,485 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4181253174940745, 'Total loss': 0.4181253174940745} | train loss {'Reaction outcome loss': 0.26046991617466414, 'Total loss': 0.26046991617466414}
2023-01-04 06:56:53,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:53,485 INFO:     Epoch: 94
2023-01-04 06:56:55,054 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38709812859694165, 'Total loss': 0.38709812859694165} | train loss {'Reaction outcome loss': 0.27041879380597683, 'Total loss': 0.27041879380597683}
2023-01-04 06:56:55,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:55,054 INFO:     Epoch: 95
2023-01-04 06:56:56,644 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4132809927066167, 'Total loss': 0.4132809927066167} | train loss {'Reaction outcome loss': 0.2653356412303274, 'Total loss': 0.2653356412303274}
2023-01-04 06:56:56,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:56,645 INFO:     Epoch: 96
2023-01-04 06:56:58,227 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42960973680019376, 'Total loss': 0.42960973680019376} | train loss {'Reaction outcome loss': 0.260909642793075, 'Total loss': 0.260909642793075}
2023-01-04 06:56:58,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:58,227 INFO:     Epoch: 97
2023-01-04 06:56:59,771 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3938385248184204, 'Total loss': 0.3938385248184204} | train loss {'Reaction outcome loss': 0.25840326591673557, 'Total loss': 0.25840326591673557}
2023-01-04 06:56:59,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:56:59,771 INFO:     Epoch: 98
2023-01-04 06:57:01,303 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3970611661672592, 'Total loss': 0.3970611661672592} | train loss {'Reaction outcome loss': 0.26634426817406703, 'Total loss': 0.26634426817406703}
2023-01-04 06:57:01,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:01,303 INFO:     Epoch: 99
2023-01-04 06:57:02,863 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40552878975868223, 'Total loss': 0.40552878975868223} | train loss {'Reaction outcome loss': 0.2621724218007748, 'Total loss': 0.2621724218007748}
2023-01-04 06:57:02,863 INFO:     Best model found after epoch 88 of 100.
2023-01-04 06:57:02,864 INFO:   Done with stage: TRAINING
2023-01-04 06:57:02,864 INFO:   Starting stage: EVALUATION
2023-01-04 06:57:02,995 INFO:   Done with stage: EVALUATION
2023-01-04 06:57:02,996 INFO:   Leaving out SEQ value Fold_1
2023-01-04 06:57:03,008 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 06:57:03,008 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:57:03,648 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:57:03,648 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:57:03,717 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:57:03,717 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:57:03,718 INFO:     No hyperparam tuning for this model
2023-01-04 06:57:03,718 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:57:03,718 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:57:03,718 INFO:     None feature selector for col prot
2023-01-04 06:57:03,719 INFO:     None feature selector for col prot
2023-01-04 06:57:03,719 INFO:     None feature selector for col prot
2023-01-04 06:57:03,719 INFO:     None feature selector for col chem
2023-01-04 06:57:03,719 INFO:     None feature selector for col chem
2023-01-04 06:57:03,719 INFO:     None feature selector for col chem
2023-01-04 06:57:03,719 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:57:03,719 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:57:03,720 INFO:     Number of params in model 70111
2023-01-04 06:57:03,724 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:57:03,724 INFO:   Starting stage: TRAINING
2023-01-04 06:57:03,766 INFO:     Val loss before train {'Reaction outcome loss': 0.9902813116709391, 'Total loss': 0.9902813116709391}
2023-01-04 06:57:03,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:03,767 INFO:     Epoch: 0
2023-01-04 06:57:05,317 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6595698893070221, 'Total loss': 0.6595698893070221} | train loss {'Reaction outcome loss': 0.837460147529623, 'Total loss': 0.837460147529623}
2023-01-04 06:57:05,318 INFO:     Found new best model at epoch 0
2023-01-04 06:57:05,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:05,319 INFO:     Epoch: 1
2023-01-04 06:57:06,852 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5661278347174327, 'Total loss': 0.5661278347174327} | train loss {'Reaction outcome loss': 0.6649506194856916, 'Total loss': 0.6649506194856916}
2023-01-04 06:57:06,853 INFO:     Found new best model at epoch 1
2023-01-04 06:57:06,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:06,853 INFO:     Epoch: 2
2023-01-04 06:57:08,386 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5172292470932007, 'Total loss': 0.5172292470932007} | train loss {'Reaction outcome loss': 0.5812315153923348, 'Total loss': 0.5812315153923348}
2023-01-04 06:57:08,386 INFO:     Found new best model at epoch 2
2023-01-04 06:57:08,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:08,387 INFO:     Epoch: 3
2023-01-04 06:57:09,914 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5081494470437368, 'Total loss': 0.5081494470437368} | train loss {'Reaction outcome loss': 0.5369217904814838, 'Total loss': 0.5369217904814838}
2023-01-04 06:57:09,914 INFO:     Found new best model at epoch 3
2023-01-04 06:57:09,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:09,915 INFO:     Epoch: 4
2023-01-04 06:57:11,480 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4904497762521108, 'Total loss': 0.4904497762521108} | train loss {'Reaction outcome loss': 0.519201674111133, 'Total loss': 0.519201674111133}
2023-01-04 06:57:11,480 INFO:     Found new best model at epoch 4
2023-01-04 06:57:11,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:11,481 INFO:     Epoch: 5
2023-01-04 06:57:13,046 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4809003700812658, 'Total loss': 0.4809003700812658} | train loss {'Reaction outcome loss': 0.4958895253439019, 'Total loss': 0.4958895253439019}
2023-01-04 06:57:13,046 INFO:     Found new best model at epoch 5
2023-01-04 06:57:13,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:13,047 INFO:     Epoch: 6
2023-01-04 06:57:14,617 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.457110204299291, 'Total loss': 0.457110204299291} | train loss {'Reaction outcome loss': 0.4891114031528904, 'Total loss': 0.4891114031528904}
2023-01-04 06:57:14,617 INFO:     Found new best model at epoch 6
2023-01-04 06:57:14,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:14,618 INFO:     Epoch: 7
2023-01-04 06:57:16,227 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48931226432323455, 'Total loss': 0.48931226432323455} | train loss {'Reaction outcome loss': 0.4790008329126957, 'Total loss': 0.4790008329126957}
2023-01-04 06:57:16,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:16,229 INFO:     Epoch: 8
2023-01-04 06:57:17,768 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4695064703623454, 'Total loss': 0.4695064703623454} | train loss {'Reaction outcome loss': 0.4718084748644028, 'Total loss': 0.4718084748644028}
2023-01-04 06:57:17,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:17,768 INFO:     Epoch: 9
2023-01-04 06:57:19,359 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4481419881184896, 'Total loss': 0.4481419881184896} | train loss {'Reaction outcome loss': 0.46854765555501854, 'Total loss': 0.46854765555501854}
2023-01-04 06:57:19,359 INFO:     Found new best model at epoch 9
2023-01-04 06:57:19,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:19,360 INFO:     Epoch: 10
2023-01-04 06:57:20,972 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45365912119547525, 'Total loss': 0.45365912119547525} | train loss {'Reaction outcome loss': 0.4561937170198364, 'Total loss': 0.4561937170198364}
2023-01-04 06:57:20,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:20,972 INFO:     Epoch: 11
2023-01-04 06:57:22,582 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4519200672705968, 'Total loss': 0.4519200672705968} | train loss {'Reaction outcome loss': 0.45926405019024863, 'Total loss': 0.45926405019024863}
2023-01-04 06:57:22,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:22,583 INFO:     Epoch: 12
2023-01-04 06:57:24,191 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44116853376229603, 'Total loss': 0.44116853376229603} | train loss {'Reaction outcome loss': 0.44859296317300656, 'Total loss': 0.44859296317300656}
2023-01-04 06:57:24,191 INFO:     Found new best model at epoch 12
2023-01-04 06:57:24,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:24,192 INFO:     Epoch: 13
2023-01-04 06:57:25,791 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4268074889977773, 'Total loss': 0.4268074889977773} | train loss {'Reaction outcome loss': 0.4455968585327594, 'Total loss': 0.4455968585327594}
2023-01-04 06:57:25,791 INFO:     Found new best model at epoch 13
2023-01-04 06:57:25,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:25,792 INFO:     Epoch: 14
2023-01-04 06:57:27,305 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4307842214902242, 'Total loss': 0.4307842214902242} | train loss {'Reaction outcome loss': 0.4385421829719613, 'Total loss': 0.4385421829719613}
2023-01-04 06:57:27,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:27,305 INFO:     Epoch: 15
2023-01-04 06:57:28,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44435200492540994, 'Total loss': 0.44435200492540994} | train loss {'Reaction outcome loss': 0.4382306359653925, 'Total loss': 0.4382306359653925}
2023-01-04 06:57:28,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:28,909 INFO:     Epoch: 16
2023-01-04 06:57:30,514 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4137500067551931, 'Total loss': 0.4137500067551931} | train loss {'Reaction outcome loss': 0.4326464385338073, 'Total loss': 0.4326464385338073}
2023-01-04 06:57:30,514 INFO:     Found new best model at epoch 16
2023-01-04 06:57:30,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:30,515 INFO:     Epoch: 17
2023-01-04 06:57:32,115 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4218296051025391, 'Total loss': 0.4218296051025391} | train loss {'Reaction outcome loss': 0.43101172111112707, 'Total loss': 0.43101172111112707}
2023-01-04 06:57:32,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:32,115 INFO:     Epoch: 18
2023-01-04 06:57:33,721 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4443433900674184, 'Total loss': 0.4443433900674184} | train loss {'Reaction outcome loss': 0.42629007538304714, 'Total loss': 0.42629007538304714}
2023-01-04 06:57:33,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:33,721 INFO:     Epoch: 19
2023-01-04 06:57:35,323 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4316707452138265, 'Total loss': 0.4316707452138265} | train loss {'Reaction outcome loss': 0.41989449259355993, 'Total loss': 0.41989449259355993}
2023-01-04 06:57:35,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:35,324 INFO:     Epoch: 20
2023-01-04 06:57:36,844 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42542778452237445, 'Total loss': 0.42542778452237445} | train loss {'Reaction outcome loss': 0.4149845046174787, 'Total loss': 0.4149845046174787}
2023-01-04 06:57:36,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:36,844 INFO:     Epoch: 21
2023-01-04 06:57:38,455 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39599709312121073, 'Total loss': 0.39599709312121073} | train loss {'Reaction outcome loss': 0.4124026726523455, 'Total loss': 0.4124026726523455}
2023-01-04 06:57:38,455 INFO:     Found new best model at epoch 21
2023-01-04 06:57:38,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:38,456 INFO:     Epoch: 22
2023-01-04 06:57:40,071 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4298703591028849, 'Total loss': 0.4298703591028849} | train loss {'Reaction outcome loss': 0.4116191643487363, 'Total loss': 0.4116191643487363}
2023-01-04 06:57:40,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:40,071 INFO:     Epoch: 23
2023-01-04 06:57:41,676 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41643730252981187, 'Total loss': 0.41643730252981187} | train loss {'Reaction outcome loss': 0.4050532811096985, 'Total loss': 0.4050532811096985}
2023-01-04 06:57:41,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:41,676 INFO:     Epoch: 24
2023-01-04 06:57:43,280 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40046168168385826, 'Total loss': 0.40046168168385826} | train loss {'Reaction outcome loss': 0.3998771804201342, 'Total loss': 0.3998771804201342}
2023-01-04 06:57:43,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:43,280 INFO:     Epoch: 25
2023-01-04 06:57:44,890 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4156877299149831, 'Total loss': 0.4156877299149831} | train loss {'Reaction outcome loss': 0.39743698453598647, 'Total loss': 0.39743698453598647}
2023-01-04 06:57:44,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:44,890 INFO:     Epoch: 26
2023-01-04 06:57:46,417 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39437490900357564, 'Total loss': 0.39437490900357564} | train loss {'Reaction outcome loss': 0.3959459651560679, 'Total loss': 0.3959459651560679}
2023-01-04 06:57:46,418 INFO:     Found new best model at epoch 26
2023-01-04 06:57:46,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:46,418 INFO:     Epoch: 27
2023-01-04 06:57:47,955 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41422971288363136, 'Total loss': 0.41422971288363136} | train loss {'Reaction outcome loss': 0.3901477117281761, 'Total loss': 0.3901477117281761}
2023-01-04 06:57:47,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:47,956 INFO:     Epoch: 28
2023-01-04 06:57:49,497 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42935276130835215, 'Total loss': 0.42935276130835215} | train loss {'Reaction outcome loss': 0.3872289284519906, 'Total loss': 0.3872289284519906}
2023-01-04 06:57:49,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:49,497 INFO:     Epoch: 29
2023-01-04 06:57:51,035 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40124021569887797, 'Total loss': 0.40124021569887797} | train loss {'Reaction outcome loss': 0.3798247586636648, 'Total loss': 0.3798247586636648}
2023-01-04 06:57:51,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:51,036 INFO:     Epoch: 30
2023-01-04 06:57:52,597 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4008066654205322, 'Total loss': 0.4008066654205322} | train loss {'Reaction outcome loss': 0.37828873057108725, 'Total loss': 0.37828873057108725}
2023-01-04 06:57:52,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:52,597 INFO:     Epoch: 31
2023-01-04 06:57:54,120 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39522775610287986, 'Total loss': 0.39522775610287986} | train loss {'Reaction outcome loss': 0.378079379235741, 'Total loss': 0.378079379235741}
2023-01-04 06:57:54,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:54,121 INFO:     Epoch: 32
2023-01-04 06:57:55,657 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38544493168592453, 'Total loss': 0.38544493168592453} | train loss {'Reaction outcome loss': 0.373766902834177, 'Total loss': 0.373766902834177}
2023-01-04 06:57:55,657 INFO:     Found new best model at epoch 32
2023-01-04 06:57:55,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:55,658 INFO:     Epoch: 33
2023-01-04 06:57:57,270 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40073350369930266, 'Total loss': 0.40073350369930266} | train loss {'Reaction outcome loss': 0.36679084370606135, 'Total loss': 0.36679084370606135}
2023-01-04 06:57:57,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:57,270 INFO:     Epoch: 34
2023-01-04 06:57:58,864 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3867532819509506, 'Total loss': 0.3867532819509506} | train loss {'Reaction outcome loss': 0.36926981863858055, 'Total loss': 0.36926981863858055}
2023-01-04 06:57:58,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:57:58,864 INFO:     Epoch: 35
2023-01-04 06:58:00,468 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3779817223548889, 'Total loss': 0.3779817223548889} | train loss {'Reaction outcome loss': 0.3667977524608591, 'Total loss': 0.3667977524608591}
2023-01-04 06:58:00,468 INFO:     Found new best model at epoch 35
2023-01-04 06:58:00,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:00,469 INFO:     Epoch: 36
2023-01-04 06:58:02,061 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37794142266114555, 'Total loss': 0.37794142266114555} | train loss {'Reaction outcome loss': 0.36040204469739956, 'Total loss': 0.36040204469739956}
2023-01-04 06:58:02,061 INFO:     Found new best model at epoch 36
2023-01-04 06:58:02,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:02,062 INFO:     Epoch: 37
2023-01-04 06:58:03,629 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40249451001485187, 'Total loss': 0.40249451001485187} | train loss {'Reaction outcome loss': 0.3555240070406538, 'Total loss': 0.3555240070406538}
2023-01-04 06:58:03,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:03,630 INFO:     Epoch: 38
2023-01-04 06:58:05,175 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.378973451256752, 'Total loss': 0.378973451256752} | train loss {'Reaction outcome loss': 0.3544985319141054, 'Total loss': 0.3544985319141054}
2023-01-04 06:58:05,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:05,176 INFO:     Epoch: 39
2023-01-04 06:58:06,764 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4012638658285141, 'Total loss': 0.4012638658285141} | train loss {'Reaction outcome loss': 0.35055238655666365, 'Total loss': 0.35055238655666365}
2023-01-04 06:58:06,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:06,765 INFO:     Epoch: 40
2023-01-04 06:58:08,342 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3844753901163737, 'Total loss': 0.3844753901163737} | train loss {'Reaction outcome loss': 0.3443565538601719, 'Total loss': 0.3443565538601719}
2023-01-04 06:58:08,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:08,342 INFO:     Epoch: 41
2023-01-04 06:58:09,944 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40431625545024874, 'Total loss': 0.40431625545024874} | train loss {'Reaction outcome loss': 0.3428371560345166, 'Total loss': 0.3428371560345166}
2023-01-04 06:58:09,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:09,944 INFO:     Epoch: 42
2023-01-04 06:58:11,534 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3787986397743225, 'Total loss': 0.3787986397743225} | train loss {'Reaction outcome loss': 0.335605427106149, 'Total loss': 0.335605427106149}
2023-01-04 06:58:11,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:11,534 INFO:     Epoch: 43
2023-01-04 06:58:13,095 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3803336093823115, 'Total loss': 0.3803336093823115} | train loss {'Reaction outcome loss': 0.33937571412564194, 'Total loss': 0.33937571412564194}
2023-01-04 06:58:13,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:13,095 INFO:     Epoch: 44
2023-01-04 06:58:14,651 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3865258812904358, 'Total loss': 0.3865258812904358} | train loss {'Reaction outcome loss': 0.3360436173414227, 'Total loss': 0.3360436173414227}
2023-01-04 06:58:14,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:14,652 INFO:     Epoch: 45
2023-01-04 06:58:16,246 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3894460956255595, 'Total loss': 0.3894460956255595} | train loss {'Reaction outcome loss': 0.32906843384687046, 'Total loss': 0.32906843384687046}
2023-01-04 06:58:16,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:16,246 INFO:     Epoch: 46
2023-01-04 06:58:17,826 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3882557948430379, 'Total loss': 0.3882557948430379} | train loss {'Reaction outcome loss': 0.32880481139478024, 'Total loss': 0.32880481139478024}
2023-01-04 06:58:17,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:17,826 INFO:     Epoch: 47
2023-01-04 06:58:19,430 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38180456062157947, 'Total loss': 0.38180456062157947} | train loss {'Reaction outcome loss': 0.3278377074884237, 'Total loss': 0.3278377074884237}
2023-01-04 06:58:19,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:19,430 INFO:     Epoch: 48
2023-01-04 06:58:21,047 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39722786843776703, 'Total loss': 0.39722786843776703} | train loss {'Reaction outcome loss': 0.32297073133344195, 'Total loss': 0.32297073133344195}
2023-01-04 06:58:21,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:21,047 INFO:     Epoch: 49
2023-01-04 06:58:22,586 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38032038857539496, 'Total loss': 0.38032038857539496} | train loss {'Reaction outcome loss': 0.3209496673441281, 'Total loss': 0.3209496673441281}
2023-01-04 06:58:22,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:22,587 INFO:     Epoch: 50
2023-01-04 06:58:24,165 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3998033026854197, 'Total loss': 0.3998033026854197} | train loss {'Reaction outcome loss': 0.3206820638891119, 'Total loss': 0.3206820638891119}
2023-01-04 06:58:24,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:24,166 INFO:     Epoch: 51
2023-01-04 06:58:25,731 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3718447123964628, 'Total loss': 0.3718447123964628} | train loss {'Reaction outcome loss': 0.318193351999469, 'Total loss': 0.318193351999469}
2023-01-04 06:58:25,731 INFO:     Found new best model at epoch 51
2023-01-04 06:58:25,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:25,732 INFO:     Epoch: 52
2023-01-04 06:58:27,293 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4005615214506785, 'Total loss': 0.4005615214506785} | train loss {'Reaction outcome loss': 0.3162591217806304, 'Total loss': 0.3162591217806304}
2023-01-04 06:58:27,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:27,294 INFO:     Epoch: 53
2023-01-04 06:58:28,874 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39902183016141257, 'Total loss': 0.39902183016141257} | train loss {'Reaction outcome loss': 0.3133822369939872, 'Total loss': 0.3133822369939872}
2023-01-04 06:58:28,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:28,875 INFO:     Epoch: 54
2023-01-04 06:58:30,448 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41188302139441174, 'Total loss': 0.41188302139441174} | train loss {'Reaction outcome loss': 0.30849967750102064, 'Total loss': 0.30849967750102064}
2023-01-04 06:58:30,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:30,448 INFO:     Epoch: 55
2023-01-04 06:58:31,956 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39654426972071327, 'Total loss': 0.39654426972071327} | train loss {'Reaction outcome loss': 0.3109774877500795, 'Total loss': 0.3109774877500795}
2023-01-04 06:58:31,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:31,956 INFO:     Epoch: 56
2023-01-04 06:58:33,567 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3923080344994863, 'Total loss': 0.3923080344994863} | train loss {'Reaction outcome loss': 0.3049496517509875, 'Total loss': 0.3049496517509875}
2023-01-04 06:58:33,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:33,567 INFO:     Epoch: 57
2023-01-04 06:58:35,139 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38848268886407217, 'Total loss': 0.38848268886407217} | train loss {'Reaction outcome loss': 0.30169327676731306, 'Total loss': 0.30169327676731306}
2023-01-04 06:58:35,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:35,140 INFO:     Epoch: 58
2023-01-04 06:58:36,725 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3901781032482783, 'Total loss': 0.3901781032482783} | train loss {'Reaction outcome loss': 0.30210862044979186, 'Total loss': 0.30210862044979186}
2023-01-04 06:58:36,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:36,725 INFO:     Epoch: 59
2023-01-04 06:58:38,286 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39089259654283526, 'Total loss': 0.39089259654283526} | train loss {'Reaction outcome loss': 0.3026912558796632, 'Total loss': 0.3026912558796632}
2023-01-04 06:58:38,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:38,287 INFO:     Epoch: 60
2023-01-04 06:58:39,820 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36580666303634646, 'Total loss': 0.36580666303634646} | train loss {'Reaction outcome loss': 0.30136243426614867, 'Total loss': 0.30136243426614867}
2023-01-04 06:58:39,820 INFO:     Found new best model at epoch 60
2023-01-04 06:58:39,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:39,821 INFO:     Epoch: 61
2023-01-04 06:58:41,338 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39281552930672964, 'Total loss': 0.39281552930672964} | train loss {'Reaction outcome loss': 0.2959132506138217, 'Total loss': 0.2959132506138217}
2023-01-04 06:58:41,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:41,339 INFO:     Epoch: 62
2023-01-04 06:58:42,907 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39420355757077535, 'Total loss': 0.39420355757077535} | train loss {'Reaction outcome loss': 0.2940790285866191, 'Total loss': 0.2940790285866191}
2023-01-04 06:58:42,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:42,907 INFO:     Epoch: 63
2023-01-04 06:58:44,478 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39378268718719484, 'Total loss': 0.39378268718719484} | train loss {'Reaction outcome loss': 0.29385790820267516, 'Total loss': 0.29385790820267516}
2023-01-04 06:58:44,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:44,478 INFO:     Epoch: 64
2023-01-04 06:58:46,051 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4059148242076238, 'Total loss': 0.4059148242076238} | train loss {'Reaction outcome loss': 0.2911292406981879, 'Total loss': 0.2911292406981879}
2023-01-04 06:58:46,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:46,051 INFO:     Epoch: 65
2023-01-04 06:58:47,623 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.377269871532917, 'Total loss': 0.377269871532917} | train loss {'Reaction outcome loss': 0.2887816811184378, 'Total loss': 0.2887816811184378}
2023-01-04 06:58:47,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:47,623 INFO:     Epoch: 66
2023-01-04 06:58:49,138 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3960191955169042, 'Total loss': 0.3960191955169042} | train loss {'Reaction outcome loss': 0.2884441609256459, 'Total loss': 0.2884441609256459}
2023-01-04 06:58:49,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:49,139 INFO:     Epoch: 67
2023-01-04 06:58:50,681 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.384344220161438, 'Total loss': 0.384344220161438} | train loss {'Reaction outcome loss': 0.28675824920408916, 'Total loss': 0.28675824920408916}
2023-01-04 06:58:50,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:50,681 INFO:     Epoch: 68
2023-01-04 06:58:52,248 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39556586543718975, 'Total loss': 0.39556586543718975} | train loss {'Reaction outcome loss': 0.28304945790365227, 'Total loss': 0.28304945790365227}
2023-01-04 06:58:52,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:52,248 INFO:     Epoch: 69
2023-01-04 06:58:53,818 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3731220324834188, 'Total loss': 0.3731220324834188} | train loss {'Reaction outcome loss': 0.28341730568476403, 'Total loss': 0.28341730568476403}
2023-01-04 06:58:53,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:53,818 INFO:     Epoch: 70
2023-01-04 06:58:55,376 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.373976198832194, 'Total loss': 0.373976198832194} | train loss {'Reaction outcome loss': 0.28056991669981585, 'Total loss': 0.28056991669981585}
2023-01-04 06:58:55,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:55,377 INFO:     Epoch: 71
2023-01-04 06:58:56,940 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39667604168256126, 'Total loss': 0.39667604168256126} | train loss {'Reaction outcome loss': 0.28030978470877577, 'Total loss': 0.28030978470877577}
2023-01-04 06:58:56,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:56,940 INFO:     Epoch: 72
2023-01-04 06:58:58,458 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41082832018534343, 'Total loss': 0.41082832018534343} | train loss {'Reaction outcome loss': 0.28359796751263366, 'Total loss': 0.28359796751263366}
2023-01-04 06:58:58,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:58,459 INFO:     Epoch: 73
2023-01-04 06:58:59,981 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37932474265495936, 'Total loss': 0.37932474265495936} | train loss {'Reaction outcome loss': 0.2809530214345368, 'Total loss': 0.2809530214345368}
2023-01-04 06:58:59,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:58:59,981 INFO:     Epoch: 74
2023-01-04 06:59:01,541 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3817243029673894, 'Total loss': 0.3817243029673894} | train loss {'Reaction outcome loss': 0.2747786998422477, 'Total loss': 0.2747786998422477}
2023-01-04 06:59:01,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:01,541 INFO:     Epoch: 75
2023-01-04 06:59:03,118 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41850651750961937, 'Total loss': 0.41850651750961937} | train loss {'Reaction outcome loss': 0.27294177812163845, 'Total loss': 0.27294177812163845}
2023-01-04 06:59:03,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:03,118 INFO:     Epoch: 76
2023-01-04 06:59:04,667 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.391891293724378, 'Total loss': 0.391891293724378} | train loss {'Reaction outcome loss': 0.2706271945124995, 'Total loss': 0.2706271945124995}
2023-01-04 06:59:04,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:04,668 INFO:     Epoch: 77
2023-01-04 06:59:06,221 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3652457495530446, 'Total loss': 0.3652457495530446} | train loss {'Reaction outcome loss': 0.27108612071967475, 'Total loss': 0.27108612071967475}
2023-01-04 06:59:06,221 INFO:     Found new best model at epoch 77
2023-01-04 06:59:06,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:06,222 INFO:     Epoch: 78
2023-01-04 06:59:07,737 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37749928136666616, 'Total loss': 0.37749928136666616} | train loss {'Reaction outcome loss': 0.2718651058138722, 'Total loss': 0.2718651058138722}
2023-01-04 06:59:07,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:07,738 INFO:     Epoch: 79
2023-01-04 06:59:09,259 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3953201403220495, 'Total loss': 0.3953201403220495} | train loss {'Reaction outcome loss': 0.2732734859370402, 'Total loss': 0.2732734859370402}
2023-01-04 06:59:09,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:09,259 INFO:     Epoch: 80
2023-01-04 06:59:10,797 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3866387118895849, 'Total loss': 0.3866387118895849} | train loss {'Reaction outcome loss': 0.2654631633556237, 'Total loss': 0.2654631633556237}
2023-01-04 06:59:10,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:10,797 INFO:     Epoch: 81
2023-01-04 06:59:12,336 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3709782878557841, 'Total loss': 0.3709782878557841} | train loss {'Reaction outcome loss': 0.26575899260105007, 'Total loss': 0.26575899260105007}
2023-01-04 06:59:12,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:12,336 INFO:     Epoch: 82
2023-01-04 06:59:13,865 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.399530835946401, 'Total loss': 0.399530835946401} | train loss {'Reaction outcome loss': 0.2672444103272074, 'Total loss': 0.2672444103272074}
2023-01-04 06:59:13,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:13,865 INFO:     Epoch: 83
2023-01-04 06:59:15,399 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3961096505324046, 'Total loss': 0.3961096505324046} | train loss {'Reaction outcome loss': 0.265893342775585, 'Total loss': 0.265893342775585}
2023-01-04 06:59:15,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:15,400 INFO:     Epoch: 84
2023-01-04 06:59:16,911 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3766413350900014, 'Total loss': 0.3766413350900014} | train loss {'Reaction outcome loss': 0.2615441355555162, 'Total loss': 0.2615441355555162}
2023-01-04 06:59:16,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:16,912 INFO:     Epoch: 85
2023-01-04 06:59:18,429 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38464918931325276, 'Total loss': 0.38464918931325276} | train loss {'Reaction outcome loss': 0.2645120771370665, 'Total loss': 0.2645120771370665}
2023-01-04 06:59:18,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:18,429 INFO:     Epoch: 86
2023-01-04 06:59:19,973 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38832310239473977, 'Total loss': 0.38832310239473977} | train loss {'Reaction outcome loss': 0.2641289862022348, 'Total loss': 0.2641289862022348}
2023-01-04 06:59:19,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:19,973 INFO:     Epoch: 87
2023-01-04 06:59:21,516 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36874621858199436, 'Total loss': 0.36874621858199436} | train loss {'Reaction outcome loss': 0.26022138072680817, 'Total loss': 0.26022138072680817}
2023-01-04 06:59:21,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:21,516 INFO:     Epoch: 88
2023-01-04 06:59:23,054 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3819955190022786, 'Total loss': 0.3819955190022786} | train loss {'Reaction outcome loss': 0.25849034756857114, 'Total loss': 0.25849034756857114}
2023-01-04 06:59:23,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:23,054 INFO:     Epoch: 89
2023-01-04 06:59:24,598 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36447072476148606, 'Total loss': 0.36447072476148606} | train loss {'Reaction outcome loss': 0.2630308762083959, 'Total loss': 0.2630308762083959}
2023-01-04 06:59:24,598 INFO:     Found new best model at epoch 89
2023-01-04 06:59:24,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:24,599 INFO:     Epoch: 90
2023-01-04 06:59:26,126 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40211272488037747, 'Total loss': 0.40211272488037747} | train loss {'Reaction outcome loss': 0.26448764174795936, 'Total loss': 0.26448764174795936}
2023-01-04 06:59:26,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:26,126 INFO:     Epoch: 91
2023-01-04 06:59:27,649 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.378092877070109, 'Total loss': 0.378092877070109} | train loss {'Reaction outcome loss': 0.25396221038633887, 'Total loss': 0.25396221038633887}
2023-01-04 06:59:27,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:27,649 INFO:     Epoch: 92
2023-01-04 06:59:29,191 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3656540741523107, 'Total loss': 0.3656540741523107} | train loss {'Reaction outcome loss': 0.25620228991619426, 'Total loss': 0.25620228991619426}
2023-01-04 06:59:29,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:29,192 INFO:     Epoch: 93
2023-01-04 06:59:30,720 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41092776159445443, 'Total loss': 0.41092776159445443} | train loss {'Reaction outcome loss': 0.25120854282574934, 'Total loss': 0.25120854282574934}
2023-01-04 06:59:30,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:30,720 INFO:     Epoch: 94
2023-01-04 06:59:32,261 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3885291357835134, 'Total loss': 0.3885291357835134} | train loss {'Reaction outcome loss': 0.2514265693561004, 'Total loss': 0.2514265693561004}
2023-01-04 06:59:32,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:32,261 INFO:     Epoch: 95
2023-01-04 06:59:33,797 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35803512036800383, 'Total loss': 0.35803512036800383} | train loss {'Reaction outcome loss': 0.2549804238752075, 'Total loss': 0.2549804238752075}
2023-01-04 06:59:33,797 INFO:     Found new best model at epoch 95
2023-01-04 06:59:33,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:33,798 INFO:     Epoch: 96
2023-01-04 06:59:35,315 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41078826288382214, 'Total loss': 0.41078826288382214} | train loss {'Reaction outcome loss': 0.2543453671799524, 'Total loss': 0.2543453671799524}
2023-01-04 06:59:35,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:35,316 INFO:     Epoch: 97
2023-01-04 06:59:36,847 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38214763104915617, 'Total loss': 0.38214763104915617} | train loss {'Reaction outcome loss': 0.2527265225394364, 'Total loss': 0.2527265225394364}
2023-01-04 06:59:36,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:36,847 INFO:     Epoch: 98
2023-01-04 06:59:38,394 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3758701721827189, 'Total loss': 0.3758701721827189} | train loss {'Reaction outcome loss': 0.25072233872420163, 'Total loss': 0.25072233872420163}
2023-01-04 06:59:38,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:38,394 INFO:     Epoch: 99
2023-01-04 06:59:39,953 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3784617076317469, 'Total loss': 0.3784617076317469} | train loss {'Reaction outcome loss': 0.2513129055690374, 'Total loss': 0.2513129055690374}
2023-01-04 06:59:39,954 INFO:     Best model found after epoch 96 of 100.
2023-01-04 06:59:39,954 INFO:   Done with stage: TRAINING
2023-01-04 06:59:39,954 INFO:   Starting stage: EVALUATION
2023-01-04 06:59:40,086 INFO:   Done with stage: EVALUATION
2023-01-04 06:59:40,086 INFO:   Leaving out SEQ value Fold_2
2023-01-04 06:59:40,099 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 06:59:40,099 INFO:   Starting stage: FEATURE SCALING
2023-01-04 06:59:40,746 INFO:   Done with stage: FEATURE SCALING
2023-01-04 06:59:40,746 INFO:   Starting stage: SCALING TARGETS
2023-01-04 06:59:40,815 INFO:   Done with stage: SCALING TARGETS
2023-01-04 06:59:40,815 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:59:40,815 INFO:     No hyperparam tuning for this model
2023-01-04 06:59:40,815 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 06:59:40,815 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 06:59:40,816 INFO:     None feature selector for col prot
2023-01-04 06:59:40,816 INFO:     None feature selector for col prot
2023-01-04 06:59:40,816 INFO:     None feature selector for col prot
2023-01-04 06:59:40,817 INFO:     None feature selector for col chem
2023-01-04 06:59:40,817 INFO:     None feature selector for col chem
2023-01-04 06:59:40,817 INFO:     None feature selector for col chem
2023-01-04 06:59:40,817 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 06:59:40,817 INFO:   Starting stage: BUILD MODEL
2023-01-04 06:59:40,818 INFO:     Number of params in model 70111
2023-01-04 06:59:40,821 INFO:   Done with stage: BUILD MODEL
2023-01-04 06:59:40,821 INFO:   Starting stage: TRAINING
2023-01-04 06:59:40,865 INFO:     Val loss before train {'Reaction outcome loss': 1.0349059263865152, 'Total loss': 1.0349059263865152}
2023-01-04 06:59:40,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:40,866 INFO:     Epoch: 0
2023-01-04 06:59:42,427 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7177411357561747, 'Total loss': 0.7177411357561747} | train loss {'Reaction outcome loss': 0.8398861913145452, 'Total loss': 0.8398861913145452}
2023-01-04 06:59:42,428 INFO:     Found new best model at epoch 0
2023-01-04 06:59:42,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:42,429 INFO:     Epoch: 1
2023-01-04 06:59:43,961 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6126721402009329, 'Total loss': 0.6126721402009329} | train loss {'Reaction outcome loss': 0.6669514397618131, 'Total loss': 0.6669514397618131}
2023-01-04 06:59:43,961 INFO:     Found new best model at epoch 1
2023-01-04 06:59:43,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:43,962 INFO:     Epoch: 2
2023-01-04 06:59:45,507 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5304267505804697, 'Total loss': 0.5304267505804697} | train loss {'Reaction outcome loss': 0.5861591153062772, 'Total loss': 0.5861591153062772}
2023-01-04 06:59:45,507 INFO:     Found new best model at epoch 2
2023-01-04 06:59:45,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:45,508 INFO:     Epoch: 3
2023-01-04 06:59:47,082 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5087947050730387, 'Total loss': 0.5087947050730387} | train loss {'Reaction outcome loss': 0.5520473843156968, 'Total loss': 0.5520473843156968}
2023-01-04 06:59:47,082 INFO:     Found new best model at epoch 3
2023-01-04 06:59:47,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:47,083 INFO:     Epoch: 4
2023-01-04 06:59:48,640 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49798471927642823, 'Total loss': 0.49798471927642823} | train loss {'Reaction outcome loss': 0.5316629136062186, 'Total loss': 0.5316629136062186}
2023-01-04 06:59:48,640 INFO:     Found new best model at epoch 4
2023-01-04 06:59:48,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:48,641 INFO:     Epoch: 5
2023-01-04 06:59:50,214 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5080451925595602, 'Total loss': 0.5080451925595602} | train loss {'Reaction outcome loss': 0.5279191241100214, 'Total loss': 0.5279191241100214}
2023-01-04 06:59:50,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:50,214 INFO:     Epoch: 6
2023-01-04 06:59:51,785 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5080167939265569, 'Total loss': 0.5080167939265569} | train loss {'Reaction outcome loss': 0.521141338661529, 'Total loss': 0.521141338661529}
2023-01-04 06:59:51,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:51,785 INFO:     Epoch: 7
2023-01-04 06:59:53,289 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4767832467953364, 'Total loss': 0.4767832467953364} | train loss {'Reaction outcome loss': 0.49978331437982293, 'Total loss': 0.49978331437982293}
2023-01-04 06:59:53,289 INFO:     Found new best model at epoch 7
2023-01-04 06:59:53,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:53,290 INFO:     Epoch: 8
2023-01-04 06:59:54,849 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49882383545239767, 'Total loss': 0.49882383545239767} | train loss {'Reaction outcome loss': 0.4866995323935281, 'Total loss': 0.4866995323935281}
2023-01-04 06:59:54,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:54,850 INFO:     Epoch: 9
2023-01-04 06:59:56,431 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46618402699629463, 'Total loss': 0.46618402699629463} | train loss {'Reaction outcome loss': 0.485930312215688, 'Total loss': 0.485930312215688}
2023-01-04 06:59:56,431 INFO:     Found new best model at epoch 9
2023-01-04 06:59:56,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:56,432 INFO:     Epoch: 10
2023-01-04 06:59:58,003 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48548530737559, 'Total loss': 0.48548530737559} | train loss {'Reaction outcome loss': 0.48497863669974217, 'Total loss': 0.48497863669974217}
2023-01-04 06:59:58,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:58,003 INFO:     Epoch: 11
2023-01-04 06:59:59,576 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4512747019529343, 'Total loss': 0.4512747019529343} | train loss {'Reaction outcome loss': 0.48962985170816165, 'Total loss': 0.48962985170816165}
2023-01-04 06:59:59,576 INFO:     Found new best model at epoch 11
2023-01-04 06:59:59,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 06:59:59,577 INFO:     Epoch: 12
2023-01-04 07:00:01,119 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4710693260033925, 'Total loss': 0.4710693260033925} | train loss {'Reaction outcome loss': 0.47028828865807987, 'Total loss': 0.47028828865807987}
2023-01-04 07:00:01,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:01,119 INFO:     Epoch: 13
2023-01-04 07:00:02,629 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4576430251200994, 'Total loss': 0.4576430251200994} | train loss {'Reaction outcome loss': 0.46968175042960525, 'Total loss': 0.46968175042960525}
2023-01-04 07:00:02,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:02,630 INFO:     Epoch: 14
2023-01-04 07:00:04,178 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45937359929084776, 'Total loss': 0.45937359929084776} | train loss {'Reaction outcome loss': 0.4558423534323821, 'Total loss': 0.4558423534323821}
2023-01-04 07:00:04,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:04,178 INFO:     Epoch: 15
2023-01-04 07:00:05,722 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4850770692030589, 'Total loss': 0.4850770692030589} | train loss {'Reaction outcome loss': 0.44920929494327394, 'Total loss': 0.44920929494327394}
2023-01-04 07:00:05,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:05,723 INFO:     Epoch: 16
2023-01-04 07:00:07,336 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45240506529808044, 'Total loss': 0.45240506529808044} | train loss {'Reaction outcome loss': 0.44896753307809867, 'Total loss': 0.44896753307809867}
2023-01-04 07:00:07,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:07,336 INFO:     Epoch: 17
2023-01-04 07:00:08,970 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46210133930047353, 'Total loss': 0.46210133930047353} | train loss {'Reaction outcome loss': 0.4420534901698862, 'Total loss': 0.4420534901698862}
2023-01-04 07:00:08,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:08,970 INFO:     Epoch: 18
2023-01-04 07:00:10,547 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46120235820611316, 'Total loss': 0.46120235820611316} | train loss {'Reaction outcome loss': 0.44123777990487567, 'Total loss': 0.44123777990487567}
2023-01-04 07:00:10,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:10,549 INFO:     Epoch: 19
2023-01-04 07:00:12,129 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45206454197565715, 'Total loss': 0.45206454197565715} | train loss {'Reaction outcome loss': 0.4321460386019443, 'Total loss': 0.4321460386019443}
2023-01-04 07:00:12,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:12,129 INFO:     Epoch: 20
2023-01-04 07:00:13,763 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4542591591676076, 'Total loss': 0.4542591591676076} | train loss {'Reaction outcome loss': 0.4317782361223787, 'Total loss': 0.4317782361223787}
2023-01-04 07:00:13,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:13,763 INFO:     Epoch: 21
2023-01-04 07:00:15,397 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43979716102282207, 'Total loss': 0.43979716102282207} | train loss {'Reaction outcome loss': 0.4235530545820307, 'Total loss': 0.4235530545820307}
2023-01-04 07:00:15,397 INFO:     Found new best model at epoch 21
2023-01-04 07:00:15,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:15,398 INFO:     Epoch: 22
2023-01-04 07:00:16,943 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4391500145196915, 'Total loss': 0.4391500145196915} | train loss {'Reaction outcome loss': 0.42460111226292624, 'Total loss': 0.42460111226292624}
2023-01-04 07:00:16,944 INFO:     Found new best model at epoch 22
2023-01-04 07:00:16,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:16,945 INFO:     Epoch: 23
2023-01-04 07:00:18,490 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44784616827964785, 'Total loss': 0.44784616827964785} | train loss {'Reaction outcome loss': 0.4265370358106589, 'Total loss': 0.4265370358106589}
2023-01-04 07:00:18,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:18,491 INFO:     Epoch: 24
2023-01-04 07:00:20,021 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4630946934223175, 'Total loss': 0.4630946934223175} | train loss {'Reaction outcome loss': 0.4164503256830832, 'Total loss': 0.4164503256830832}
2023-01-04 07:00:20,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:20,021 INFO:     Epoch: 25
2023-01-04 07:00:21,562 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43815803676843645, 'Total loss': 0.43815803676843645} | train loss {'Reaction outcome loss': 0.4242542169286289, 'Total loss': 0.4242542169286289}
2023-01-04 07:00:21,562 INFO:     Found new best model at epoch 25
2023-01-04 07:00:21,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:21,563 INFO:     Epoch: 26
2023-01-04 07:00:23,114 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4469241976737976, 'Total loss': 0.4469241976737976} | train loss {'Reaction outcome loss': 0.455424718140368, 'Total loss': 0.455424718140368}
2023-01-04 07:00:23,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:23,114 INFO:     Epoch: 27
2023-01-04 07:00:24,671 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4299730400244395, 'Total loss': 0.4299730400244395} | train loss {'Reaction outcome loss': 0.4178156207486029, 'Total loss': 0.4178156207486029}
2023-01-04 07:00:24,671 INFO:     Found new best model at epoch 27
2023-01-04 07:00:24,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:24,672 INFO:     Epoch: 28
2023-01-04 07:00:26,220 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4277469257513682, 'Total loss': 0.4277469257513682} | train loss {'Reaction outcome loss': 0.40673115076598426, 'Total loss': 0.40673115076598426}
2023-01-04 07:00:26,220 INFO:     Found new best model at epoch 28
2023-01-04 07:00:26,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:26,221 INFO:     Epoch: 29
2023-01-04 07:00:27,765 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4548611263434092, 'Total loss': 0.4548611263434092} | train loss {'Reaction outcome loss': 0.400438629563196, 'Total loss': 0.400438629563196}
2023-01-04 07:00:27,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:27,765 INFO:     Epoch: 30
2023-01-04 07:00:29,293 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4319659799337387, 'Total loss': 0.4319659799337387} | train loss {'Reaction outcome loss': 0.39872175185461156, 'Total loss': 0.39872175185461156}
2023-01-04 07:00:29,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:29,294 INFO:     Epoch: 31
2023-01-04 07:00:30,824 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43282356758912405, 'Total loss': 0.43282356758912405} | train loss {'Reaction outcome loss': 0.3932576535296613, 'Total loss': 0.3932576535296613}
2023-01-04 07:00:30,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:30,824 INFO:     Epoch: 32
2023-01-04 07:00:32,407 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4393288969993591, 'Total loss': 0.4393288969993591} | train loss {'Reaction outcome loss': 0.38911136690918624, 'Total loss': 0.38911136690918624}
2023-01-04 07:00:32,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:32,408 INFO:     Epoch: 33
2023-01-04 07:00:33,962 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4463040371735891, 'Total loss': 0.4463040371735891} | train loss {'Reaction outcome loss': 0.38472301020300476, 'Total loss': 0.38472301020300476}
2023-01-04 07:00:33,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:33,962 INFO:     Epoch: 34
2023-01-04 07:00:35,501 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4541084220012029, 'Total loss': 0.4541084220012029} | train loss {'Reaction outcome loss': 0.38656222717701527, 'Total loss': 0.38656222717701527}
2023-01-04 07:00:35,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:35,501 INFO:     Epoch: 35
2023-01-04 07:00:37,042 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45828989942868553, 'Total loss': 0.45828989942868553} | train loss {'Reaction outcome loss': 0.3850998940769637, 'Total loss': 0.3850998940769637}
2023-01-04 07:00:37,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:37,042 INFO:     Epoch: 36
2023-01-04 07:00:38,539 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44181138078371684, 'Total loss': 0.44181138078371684} | train loss {'Reaction outcome loss': 0.3759044172255781, 'Total loss': 0.3759044172255781}
2023-01-04 07:00:38,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:38,539 INFO:     Epoch: 37
2023-01-04 07:00:40,092 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.415851898988088, 'Total loss': 0.415851898988088} | train loss {'Reaction outcome loss': 0.37506436151654826, 'Total loss': 0.37506436151654826}
2023-01-04 07:00:40,092 INFO:     Found new best model at epoch 37
2023-01-04 07:00:40,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:40,093 INFO:     Epoch: 38
2023-01-04 07:00:41,676 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4092451443274816, 'Total loss': 0.4092451443274816} | train loss {'Reaction outcome loss': 0.37325051376947027, 'Total loss': 0.37325051376947027}
2023-01-04 07:00:41,677 INFO:     Found new best model at epoch 38
2023-01-04 07:00:41,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:41,677 INFO:     Epoch: 39
2023-01-04 07:00:43,277 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4289302994807561, 'Total loss': 0.4289302994807561} | train loss {'Reaction outcome loss': 0.3657584487345826, 'Total loss': 0.3657584487345826}
2023-01-04 07:00:43,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:43,277 INFO:     Epoch: 40
2023-01-04 07:00:44,864 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43678213357925416, 'Total loss': 0.43678213357925416} | train loss {'Reaction outcome loss': 0.36585452488583065, 'Total loss': 0.36585452488583065}
2023-01-04 07:00:44,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:44,865 INFO:     Epoch: 41
2023-01-04 07:00:46,451 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4441670417785645, 'Total loss': 0.4441670417785645} | train loss {'Reaction outcome loss': 0.3639433615422551, 'Total loss': 0.3639433615422551}
2023-01-04 07:00:46,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:46,452 INFO:     Epoch: 42
2023-01-04 07:00:48,001 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4220622181892395, 'Total loss': 0.4220622181892395} | train loss {'Reaction outcome loss': 0.3577458398396392, 'Total loss': 0.3577458398396392}
2023-01-04 07:00:48,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:48,002 INFO:     Epoch: 43
2023-01-04 07:00:49,636 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4233173837264379, 'Total loss': 0.4233173837264379} | train loss {'Reaction outcome loss': 0.35271210105333856, 'Total loss': 0.35271210105333856}
2023-01-04 07:00:49,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:49,636 INFO:     Epoch: 44
2023-01-04 07:00:51,251 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42755965193112694, 'Total loss': 0.42755965193112694} | train loss {'Reaction outcome loss': 0.35077674169282336, 'Total loss': 0.35077674169282336}
2023-01-04 07:00:51,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:51,251 INFO:     Epoch: 45
2023-01-04 07:00:52,862 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41804994543393453, 'Total loss': 0.41804994543393453} | train loss {'Reaction outcome loss': 0.3506895905610282, 'Total loss': 0.3506895905610282}
2023-01-04 07:00:52,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:52,863 INFO:     Epoch: 46
2023-01-04 07:00:54,485 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4169883559147517, 'Total loss': 0.4169883559147517} | train loss {'Reaction outcome loss': 0.34084672947105044, 'Total loss': 0.34084672947105044}
2023-01-04 07:00:54,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:54,486 INFO:     Epoch: 47
2023-01-04 07:00:56,066 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4298071384429932, 'Total loss': 0.4298071384429932} | train loss {'Reaction outcome loss': 0.3468072611085254, 'Total loss': 0.3468072611085254}
2023-01-04 07:00:56,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:56,066 INFO:     Epoch: 48
2023-01-04 07:00:57,636 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4335479815800985, 'Total loss': 0.4335479815800985} | train loss {'Reaction outcome loss': 0.3401534437662517, 'Total loss': 0.3401534437662517}
2023-01-04 07:00:57,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:57,636 INFO:     Epoch: 49
2023-01-04 07:00:59,261 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4201598773399989, 'Total loss': 0.4201598773399989} | train loss {'Reaction outcome loss': 0.34379669322051865, 'Total loss': 0.34379669322051865}
2023-01-04 07:00:59,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:00:59,261 INFO:     Epoch: 50
2023-01-04 07:01:00,884 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43108600775400796, 'Total loss': 0.43108600775400796} | train loss {'Reaction outcome loss': 0.3605825474580237, 'Total loss': 0.3605825474580237}
2023-01-04 07:01:00,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:00,885 INFO:     Epoch: 51
2023-01-04 07:01:02,502 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40204978783925377, 'Total loss': 0.40204978783925377} | train loss {'Reaction outcome loss': 0.3396510641374018, 'Total loss': 0.3396510641374018}
2023-01-04 07:01:02,503 INFO:     Found new best model at epoch 51
2023-01-04 07:01:02,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:02,503 INFO:     Epoch: 52
2023-01-04 07:01:04,122 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40153970519701637, 'Total loss': 0.40153970519701637} | train loss {'Reaction outcome loss': 0.3391643265623302, 'Total loss': 0.3391643265623302}
2023-01-04 07:01:04,123 INFO:     Found new best model at epoch 52
2023-01-04 07:01:04,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:04,123 INFO:     Epoch: 53
2023-01-04 07:01:05,704 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4195824881394704, 'Total loss': 0.4195824881394704} | train loss {'Reaction outcome loss': 0.3335500800631184, 'Total loss': 0.3335500800631184}
2023-01-04 07:01:05,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:05,705 INFO:     Epoch: 54
2023-01-04 07:01:07,300 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4262797017892202, 'Total loss': 0.4262797017892202} | train loss {'Reaction outcome loss': 0.36018521832707134, 'Total loss': 0.36018521832707134}
2023-01-04 07:01:07,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:07,300 INFO:     Epoch: 55
2023-01-04 07:01:08,926 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4176089495420456, 'Total loss': 0.4176089495420456} | train loss {'Reaction outcome loss': 0.3518867871312398, 'Total loss': 0.3518867871312398}
2023-01-04 07:01:08,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:08,926 INFO:     Epoch: 56
2023-01-04 07:01:10,545 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4110479970773061, 'Total loss': 0.4110479970773061} | train loss {'Reaction outcome loss': 0.33116436355571816, 'Total loss': 0.33116436355571816}
2023-01-04 07:01:10,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:10,546 INFO:     Epoch: 57
2023-01-04 07:01:12,156 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42598026196161903, 'Total loss': 0.42598026196161903} | train loss {'Reaction outcome loss': 0.3307182711373637, 'Total loss': 0.3307182711373637}
2023-01-04 07:01:12,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:12,156 INFO:     Epoch: 58
2023-01-04 07:01:13,760 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40333930899699527, 'Total loss': 0.40333930899699527} | train loss {'Reaction outcome loss': 0.3247634489063943, 'Total loss': 0.3247634489063943}
2023-01-04 07:01:13,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:13,760 INFO:     Epoch: 59
2023-01-04 07:01:15,309 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4176446338494619, 'Total loss': 0.4176446338494619} | train loss {'Reaction outcome loss': 0.3232024914561433, 'Total loss': 0.3232024914561433}
2023-01-04 07:01:15,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:15,309 INFO:     Epoch: 60
2023-01-04 07:01:16,882 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41668874124685923, 'Total loss': 0.41668874124685923} | train loss {'Reaction outcome loss': 0.3292781568901694, 'Total loss': 0.3292781568901694}
2023-01-04 07:01:16,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:16,883 INFO:     Epoch: 61
2023-01-04 07:01:18,457 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4127434422572454, 'Total loss': 0.4127434422572454} | train loss {'Reaction outcome loss': 0.355123502296814, 'Total loss': 0.355123502296814}
2023-01-04 07:01:18,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:18,457 INFO:     Epoch: 62
2023-01-04 07:01:20,040 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4279400885105133, 'Total loss': 0.4279400885105133} | train loss {'Reaction outcome loss': 0.32663889936352, 'Total loss': 0.32663889936352}
2023-01-04 07:01:20,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:20,040 INFO:     Epoch: 63
2023-01-04 07:01:21,643 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4087129980325699, 'Total loss': 0.4087129980325699} | train loss {'Reaction outcome loss': 0.31794247289518895, 'Total loss': 0.31794247289518895}
2023-01-04 07:01:21,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:21,644 INFO:     Epoch: 64
2023-01-04 07:01:23,207 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4234850168228149, 'Total loss': 0.4234850168228149} | train loss {'Reaction outcome loss': 0.3156716962824947, 'Total loss': 0.3156716962824947}
2023-01-04 07:01:23,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:23,208 INFO:     Epoch: 65
2023-01-04 07:01:24,765 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41463380455970766, 'Total loss': 0.41463380455970766} | train loss {'Reaction outcome loss': 0.3182346398631732, 'Total loss': 0.3182346398631732}
2023-01-04 07:01:24,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:24,766 INFO:     Epoch: 66
2023-01-04 07:01:26,347 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4417210747798284, 'Total loss': 0.4417210747798284} | train loss {'Reaction outcome loss': 0.33160715788582584, 'Total loss': 0.33160715788582584}
2023-01-04 07:01:26,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:26,347 INFO:     Epoch: 67
2023-01-04 07:01:27,931 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39508633812268573, 'Total loss': 0.39508633812268573} | train loss {'Reaction outcome loss': 0.3159880022639814, 'Total loss': 0.3159880022639814}
2023-01-04 07:01:27,931 INFO:     Found new best model at epoch 67
2023-01-04 07:01:27,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:27,932 INFO:     Epoch: 68
2023-01-04 07:01:29,518 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42472528318564096, 'Total loss': 0.42472528318564096} | train loss {'Reaction outcome loss': 0.3324962644905284, 'Total loss': 0.3324962644905284}
2023-01-04 07:01:29,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:29,519 INFO:     Epoch: 69
2023-01-04 07:01:31,104 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43959307471911113, 'Total loss': 0.43959307471911113} | train loss {'Reaction outcome loss': 0.37870689891818643, 'Total loss': 0.37870689891818643}
2023-01-04 07:01:31,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:31,105 INFO:     Epoch: 70
2023-01-04 07:01:32,649 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.413801180322965, 'Total loss': 0.413801180322965} | train loss {'Reaction outcome loss': 0.34044539508834964, 'Total loss': 0.34044539508834964}
2023-01-04 07:01:32,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:32,649 INFO:     Epoch: 71
2023-01-04 07:01:34,194 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42259964942932127, 'Total loss': 0.42259964942932127} | train loss {'Reaction outcome loss': 0.3125402959657536, 'Total loss': 0.3125402959657536}
2023-01-04 07:01:34,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:34,194 INFO:     Epoch: 72
2023-01-04 07:01:35,772 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41634924213091534, 'Total loss': 0.41634924213091534} | train loss {'Reaction outcome loss': 0.30995008040348615, 'Total loss': 0.30995008040348615}
2023-01-04 07:01:35,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:35,773 INFO:     Epoch: 73
2023-01-04 07:01:37,367 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41047672033309934, 'Total loss': 0.41047672033309934} | train loss {'Reaction outcome loss': 0.30046064641657355, 'Total loss': 0.30046064641657355}
2023-01-04 07:01:37,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:37,367 INFO:     Epoch: 74
2023-01-04 07:01:38,959 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41241599718729655, 'Total loss': 0.41241599718729655} | train loss {'Reaction outcome loss': 0.30096603323961946, 'Total loss': 0.30096603323961946}
2023-01-04 07:01:38,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:38,959 INFO:     Epoch: 75
2023-01-04 07:01:40,549 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40581639607747394, 'Total loss': 0.40581639607747394} | train loss {'Reaction outcome loss': 0.3019814854476177, 'Total loss': 0.3019814854476177}
2023-01-04 07:01:40,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:40,550 INFO:     Epoch: 76
2023-01-04 07:01:42,098 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4136709600687027, 'Total loss': 0.4136709600687027} | train loss {'Reaction outcome loss': 0.3006749596662711, 'Total loss': 0.3006749596662711}
2023-01-04 07:01:42,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:42,098 INFO:     Epoch: 77
2023-01-04 07:01:43,660 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4162895858287811, 'Total loss': 0.4162895858287811} | train loss {'Reaction outcome loss': 0.29656238773447735, 'Total loss': 0.29656238773447735}
2023-01-04 07:01:43,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:43,661 INFO:     Epoch: 78
2023-01-04 07:01:45,253 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4157860477765401, 'Total loss': 0.4157860477765401} | train loss {'Reaction outcome loss': 0.30079341423360334, 'Total loss': 0.30079341423360334}
2023-01-04 07:01:45,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:45,253 INFO:     Epoch: 79
2023-01-04 07:01:46,835 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40396334528923034, 'Total loss': 0.40396334528923034} | train loss {'Reaction outcome loss': 0.30695169278107537, 'Total loss': 0.30695169278107537}
2023-01-04 07:01:46,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:46,835 INFO:     Epoch: 80
2023-01-04 07:01:48,420 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4182305335998535, 'Total loss': 0.4182305335998535} | train loss {'Reaction outcome loss': 0.295521482099687, 'Total loss': 0.295521482099687}
2023-01-04 07:01:48,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:48,422 INFO:     Epoch: 81
2023-01-04 07:01:50,043 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41387709975242615, 'Total loss': 0.41387709975242615} | train loss {'Reaction outcome loss': 0.2939148293048872, 'Total loss': 0.2939148293048872}
2023-01-04 07:01:50,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:50,043 INFO:     Epoch: 82
2023-01-04 07:01:51,559 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41019486586252846, 'Total loss': 0.41019486586252846} | train loss {'Reaction outcome loss': 0.29635347228463943, 'Total loss': 0.29635347228463943}
2023-01-04 07:01:51,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:51,559 INFO:     Epoch: 83
2023-01-04 07:01:53,140 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40094457467397054, 'Total loss': 0.40094457467397054} | train loss {'Reaction outcome loss': 0.28973994637287787, 'Total loss': 0.28973994637287787}
2023-01-04 07:01:53,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:53,140 INFO:     Epoch: 84
2023-01-04 07:01:54,735 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38846431573232015, 'Total loss': 0.38846431573232015} | train loss {'Reaction outcome loss': 0.31237854378000984, 'Total loss': 0.31237854378000984}
2023-01-04 07:01:54,736 INFO:     Found new best model at epoch 84
2023-01-04 07:01:54,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:54,736 INFO:     Epoch: 85
2023-01-04 07:01:56,349 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39565805395444237, 'Total loss': 0.39565805395444237} | train loss {'Reaction outcome loss': 0.30399167814386496, 'Total loss': 0.30399167814386496}
2023-01-04 07:01:56,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:56,349 INFO:     Epoch: 86
2023-01-04 07:01:57,929 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44293280839920046, 'Total loss': 0.44293280839920046} | train loss {'Reaction outcome loss': 0.29331287560795527, 'Total loss': 0.29331287560795527}
2023-01-04 07:01:57,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:57,929 INFO:     Epoch: 87
2023-01-04 07:01:59,490 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42904006143411, 'Total loss': 0.42904006143411} | train loss {'Reaction outcome loss': 0.3180311171310967, 'Total loss': 0.3180311171310967}
2023-01-04 07:01:59,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:01:59,490 INFO:     Epoch: 88
2023-01-04 07:02:01,032 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4078442414601644, 'Total loss': 0.4078442414601644} | train loss {'Reaction outcome loss': 0.30896397378545365, 'Total loss': 0.30896397378545365}
2023-01-04 07:02:01,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:01,032 INFO:     Epoch: 89
2023-01-04 07:02:02,637 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4183934311072032, 'Total loss': 0.4183934311072032} | train loss {'Reaction outcome loss': 0.28352233552141115, 'Total loss': 0.28352233552141115}
2023-01-04 07:02:02,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:02,637 INFO:     Epoch: 90
2023-01-04 07:02:04,223 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3910100022951762, 'Total loss': 0.3910100022951762} | train loss {'Reaction outcome loss': 0.2823839256332418, 'Total loss': 0.2823839256332418}
2023-01-04 07:02:04,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:04,223 INFO:     Epoch: 91
2023-01-04 07:02:05,806 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41689128379027046, 'Total loss': 0.41689128379027046} | train loss {'Reaction outcome loss': 0.28142395603403647, 'Total loss': 0.28142395603403647}
2023-01-04 07:02:05,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:05,806 INFO:     Epoch: 92
2023-01-04 07:02:07,404 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4103741596142451, 'Total loss': 0.4103741596142451} | train loss {'Reaction outcome loss': 0.2839979785224558, 'Total loss': 0.2839979785224558}
2023-01-04 07:02:07,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:07,405 INFO:     Epoch: 93
2023-01-04 07:02:08,965 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41367718974749246, 'Total loss': 0.41367718974749246} | train loss {'Reaction outcome loss': 0.2810214622438872, 'Total loss': 0.2810214622438872}
2023-01-04 07:02:08,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:08,965 INFO:     Epoch: 94
2023-01-04 07:02:10,529 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40695018470287325, 'Total loss': 0.40695018470287325} | train loss {'Reaction outcome loss': 0.28252946504432225, 'Total loss': 0.28252946504432225}
2023-01-04 07:02:10,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:10,529 INFO:     Epoch: 95
2023-01-04 07:02:12,104 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4084937592347463, 'Total loss': 0.4084937592347463} | train loss {'Reaction outcome loss': 0.2801777992492029, 'Total loss': 0.2801777992492029}
2023-01-04 07:02:12,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:12,104 INFO:     Epoch: 96
2023-01-04 07:02:13,688 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4312852700551351, 'Total loss': 0.4312852700551351} | train loss {'Reaction outcome loss': 0.28339597617741674, 'Total loss': 0.28339597617741674}
2023-01-04 07:02:13,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:13,688 INFO:     Epoch: 97
2023-01-04 07:02:15,269 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44218090971310936, 'Total loss': 0.44218090971310936} | train loss {'Reaction outcome loss': 0.2799369224374169, 'Total loss': 0.2799369224374169}
2023-01-04 07:02:15,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:15,270 INFO:     Epoch: 98
2023-01-04 07:02:16,851 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41461010873317716, 'Total loss': 0.41461010873317716} | train loss {'Reaction outcome loss': 0.27806544097383384, 'Total loss': 0.27806544097383384}
2023-01-04 07:02:16,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:16,851 INFO:     Epoch: 99
2023-01-04 07:02:18,390 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44121670921643574, 'Total loss': 0.44121670921643574} | train loss {'Reaction outcome loss': 0.2749874777686985, 'Total loss': 0.2749874777686985}
2023-01-04 07:02:18,390 INFO:     Best model found after epoch 85 of 100.
2023-01-04 07:02:18,390 INFO:   Done with stage: TRAINING
2023-01-04 07:02:18,390 INFO:   Starting stage: EVALUATION
2023-01-04 07:02:18,516 INFO:   Done with stage: EVALUATION
2023-01-04 07:02:18,516 INFO:   Leaving out SEQ value Fold_3
2023-01-04 07:02:18,528 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 07:02:18,529 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:02:19,171 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:02:19,171 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:02:19,240 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:02:19,240 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:02:19,240 INFO:     No hyperparam tuning for this model
2023-01-04 07:02:19,240 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:02:19,240 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:02:19,241 INFO:     None feature selector for col prot
2023-01-04 07:02:19,241 INFO:     None feature selector for col prot
2023-01-04 07:02:19,241 INFO:     None feature selector for col prot
2023-01-04 07:02:19,242 INFO:     None feature selector for col chem
2023-01-04 07:02:19,242 INFO:     None feature selector for col chem
2023-01-04 07:02:19,242 INFO:     None feature selector for col chem
2023-01-04 07:02:19,242 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:02:19,242 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:02:19,243 INFO:     Number of params in model 70111
2023-01-04 07:02:19,246 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:02:19,246 INFO:   Starting stage: TRAINING
2023-01-04 07:02:19,290 INFO:     Val loss before train {'Reaction outcome loss': 1.0463522990544638, 'Total loss': 1.0463522990544638}
2023-01-04 07:02:19,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:19,290 INFO:     Epoch: 0
2023-01-04 07:02:20,845 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7845296025276184, 'Total loss': 0.7845296025276184} | train loss {'Reaction outcome loss': 0.8218930123278695, 'Total loss': 0.8218930123278695}
2023-01-04 07:02:20,845 INFO:     Found new best model at epoch 0
2023-01-04 07:02:20,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:20,846 INFO:     Epoch: 1
2023-01-04 07:02:22,402 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6616134126981099, 'Total loss': 0.6616134126981099} | train loss {'Reaction outcome loss': 0.6585891686216758, 'Total loss': 0.6585891686216758}
2023-01-04 07:02:22,402 INFO:     Found new best model at epoch 1
2023-01-04 07:02:22,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:22,403 INFO:     Epoch: 2
2023-01-04 07:02:23,954 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6152562876542409, 'Total loss': 0.6152562876542409} | train loss {'Reaction outcome loss': 0.5697245449371582, 'Total loss': 0.5697245449371582}
2023-01-04 07:02:23,955 INFO:     Found new best model at epoch 2
2023-01-04 07:02:23,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:23,956 INFO:     Epoch: 3
2023-01-04 07:02:25,516 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5950075189272562, 'Total loss': 0.5950075189272562} | train loss {'Reaction outcome loss': 0.531767380933692, 'Total loss': 0.531767380933692}
2023-01-04 07:02:25,517 INFO:     Found new best model at epoch 3
2023-01-04 07:02:25,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:25,517 INFO:     Epoch: 4
2023-01-04 07:02:27,037 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5661423643430074, 'Total loss': 0.5661423643430074} | train loss {'Reaction outcome loss': 0.5119194642905771, 'Total loss': 0.5119194642905771}
2023-01-04 07:02:27,037 INFO:     Found new best model at epoch 4
2023-01-04 07:02:27,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:27,038 INFO:     Epoch: 5
2023-01-04 07:02:28,568 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5409489711125691, 'Total loss': 0.5409489711125691} | train loss {'Reaction outcome loss': 0.49835269724148035, 'Total loss': 0.49835269724148035}
2023-01-04 07:02:28,568 INFO:     Found new best model at epoch 5
2023-01-04 07:02:28,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:28,569 INFO:     Epoch: 6
2023-01-04 07:02:30,134 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5490415573120118, 'Total loss': 0.5490415573120118} | train loss {'Reaction outcome loss': 0.4897638158532825, 'Total loss': 0.4897638158532825}
2023-01-04 07:02:30,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:30,135 INFO:     Epoch: 7
2023-01-04 07:02:31,692 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5371213634808858, 'Total loss': 0.5371213634808858} | train loss {'Reaction outcome loss': 0.4817747736934328, 'Total loss': 0.4817747736934328}
2023-01-04 07:02:31,692 INFO:     Found new best model at epoch 7
2023-01-04 07:02:31,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:31,693 INFO:     Epoch: 8
2023-01-04 07:02:33,270 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5214711497227351, 'Total loss': 0.5214711497227351} | train loss {'Reaction outcome loss': 0.471523705081348, 'Total loss': 0.471523705081348}
2023-01-04 07:02:33,270 INFO:     Found new best model at epoch 8
2023-01-04 07:02:33,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:33,271 INFO:     Epoch: 9
2023-01-04 07:02:34,824 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5453714430332184, 'Total loss': 0.5453714430332184} | train loss {'Reaction outcome loss': 0.46592202600445193, 'Total loss': 0.46592202600445193}
2023-01-04 07:02:34,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:34,824 INFO:     Epoch: 10
2023-01-04 07:02:36,337 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5188860992590586, 'Total loss': 0.5188860992590586} | train loss {'Reaction outcome loss': 0.4589693144942722, 'Total loss': 0.4589693144942722}
2023-01-04 07:02:36,337 INFO:     Found new best model at epoch 10
2023-01-04 07:02:36,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:36,337 INFO:     Epoch: 11
2023-01-04 07:02:37,883 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5180009841918946, 'Total loss': 0.5180009841918946} | train loss {'Reaction outcome loss': 0.45652898507070366, 'Total loss': 0.45652898507070366}
2023-01-04 07:02:37,883 INFO:     Found new best model at epoch 11
2023-01-04 07:02:37,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:37,884 INFO:     Epoch: 12
2023-01-04 07:02:39,446 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5565941413243611, 'Total loss': 0.5565941413243611} | train loss {'Reaction outcome loss': 0.447813801385843, 'Total loss': 0.447813801385843}
2023-01-04 07:02:39,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:39,446 INFO:     Epoch: 13
2023-01-04 07:02:41,013 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5503717819849651, 'Total loss': 0.5503717819849651} | train loss {'Reaction outcome loss': 0.4454634199394797, 'Total loss': 0.4454634199394797}
2023-01-04 07:02:41,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:41,013 INFO:     Epoch: 14
2023-01-04 07:02:42,582 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5323479632536571, 'Total loss': 0.5323479632536571} | train loss {'Reaction outcome loss': 0.43959834317873864, 'Total loss': 0.43959834317873864}
2023-01-04 07:02:42,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:42,583 INFO:     Epoch: 15
2023-01-04 07:02:44,151 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.501813671986262, 'Total loss': 0.501813671986262} | train loss {'Reaction outcome loss': 0.43576993592029073, 'Total loss': 0.43576993592029073}
2023-01-04 07:02:44,151 INFO:     Found new best model at epoch 15
2023-01-04 07:02:44,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:44,152 INFO:     Epoch: 16
2023-01-04 07:02:45,640 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5055056174596151, 'Total loss': 0.5055056174596151} | train loss {'Reaction outcome loss': 0.429302159805585, 'Total loss': 0.429302159805585}
2023-01-04 07:02:45,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:45,640 INFO:     Epoch: 17
2023-01-04 07:02:47,224 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.497458271185557, 'Total loss': 0.497458271185557} | train loss {'Reaction outcome loss': 0.4290131976569656, 'Total loss': 0.4290131976569656}
2023-01-04 07:02:47,224 INFO:     Found new best model at epoch 17
2023-01-04 07:02:47,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:47,225 INFO:     Epoch: 18
2023-01-04 07:02:48,852 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48911300698916116, 'Total loss': 0.48911300698916116} | train loss {'Reaction outcome loss': 0.41989235400500957, 'Total loss': 0.41989235400500957}
2023-01-04 07:02:48,852 INFO:     Found new best model at epoch 18
2023-01-04 07:02:48,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:48,853 INFO:     Epoch: 19
2023-01-04 07:02:50,471 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48756664991378784, 'Total loss': 0.48756664991378784} | train loss {'Reaction outcome loss': 0.4166661810374608, 'Total loss': 0.4166661810374608}
2023-01-04 07:02:50,471 INFO:     Found new best model at epoch 19
2023-01-04 07:02:50,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:50,472 INFO:     Epoch: 20
2023-01-04 07:02:52,098 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4941338976224264, 'Total loss': 0.4941338976224264} | train loss {'Reaction outcome loss': 0.4110323935203309, 'Total loss': 0.4110323935203309}
2023-01-04 07:02:52,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:52,098 INFO:     Epoch: 21
2023-01-04 07:02:53,670 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4830804169178009, 'Total loss': 0.4830804169178009} | train loss {'Reaction outcome loss': 0.40594851388765946, 'Total loss': 0.40594851388765946}
2023-01-04 07:02:53,670 INFO:     Found new best model at epoch 21
2023-01-04 07:02:53,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:53,671 INFO:     Epoch: 22
2023-01-04 07:02:55,232 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5119878073533376, 'Total loss': 0.5119878073533376} | train loss {'Reaction outcome loss': 0.40192142879440834, 'Total loss': 0.40192142879440834}
2023-01-04 07:02:55,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:55,233 INFO:     Epoch: 23
2023-01-04 07:02:56,857 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4889382948478063, 'Total loss': 0.4889382948478063} | train loss {'Reaction outcome loss': 0.3987538052083802, 'Total loss': 0.3987538052083802}
2023-01-04 07:02:56,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:56,857 INFO:     Epoch: 24
2023-01-04 07:02:58,464 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5185117065906525, 'Total loss': 0.5185117065906525} | train loss {'Reaction outcome loss': 0.3946254811365239, 'Total loss': 0.3946254811365239}
2023-01-04 07:02:58,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:02:58,465 INFO:     Epoch: 25
2023-01-04 07:03:00,071 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48799978494644164, 'Total loss': 0.48799978494644164} | train loss {'Reaction outcome loss': 0.3912701803619844, 'Total loss': 0.3912701803619844}
2023-01-04 07:03:00,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:00,072 INFO:     Epoch: 26
2023-01-04 07:03:01,698 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47063555419445036, 'Total loss': 0.47063555419445036} | train loss {'Reaction outcome loss': 0.38955020121414297, 'Total loss': 0.38955020121414297}
2023-01-04 07:03:01,699 INFO:     Found new best model at epoch 26
2023-01-04 07:03:01,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:01,700 INFO:     Epoch: 27
2023-01-04 07:03:03,270 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4626019795735677, 'Total loss': 0.4626019795735677} | train loss {'Reaction outcome loss': 0.38108940808659925, 'Total loss': 0.38108940808659925}
2023-01-04 07:03:03,271 INFO:     Found new best model at epoch 27
2023-01-04 07:03:03,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:03,271 INFO:     Epoch: 28
2023-01-04 07:03:04,843 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4569624344507853, 'Total loss': 0.4569624344507853} | train loss {'Reaction outcome loss': 0.375048470649406, 'Total loss': 0.375048470649406}
2023-01-04 07:03:04,843 INFO:     Found new best model at epoch 28
2023-01-04 07:03:04,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:04,844 INFO:     Epoch: 29
2023-01-04 07:03:06,433 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44285288254419963, 'Total loss': 0.44285288254419963} | train loss {'Reaction outcome loss': 0.37445862909411864, 'Total loss': 0.37445862909411864}
2023-01-04 07:03:06,433 INFO:     Found new best model at epoch 29
2023-01-04 07:03:06,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:06,434 INFO:     Epoch: 30
2023-01-04 07:03:07,976 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.466972279548645, 'Total loss': 0.466972279548645} | train loss {'Reaction outcome loss': 0.37151591162992653, 'Total loss': 0.37151591162992653}
2023-01-04 07:03:07,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:07,976 INFO:     Epoch: 31
2023-01-04 07:03:09,529 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4509020566940308, 'Total loss': 0.4509020566940308} | train loss {'Reaction outcome loss': 0.3691749132245126, 'Total loss': 0.3691749132245126}
2023-01-04 07:03:09,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:09,529 INFO:     Epoch: 32
2023-01-04 07:03:11,072 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44104763070742287, 'Total loss': 0.44104763070742287} | train loss {'Reaction outcome loss': 0.3625650853190544, 'Total loss': 0.3625650853190544}
2023-01-04 07:03:11,072 INFO:     Found new best model at epoch 32
2023-01-04 07:03:11,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:11,073 INFO:     Epoch: 33
2023-01-04 07:03:12,600 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4414008975028992, 'Total loss': 0.4414008975028992} | train loss {'Reaction outcome loss': 0.3609461730250912, 'Total loss': 0.3609461730250912}
2023-01-04 07:03:12,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:12,600 INFO:     Epoch: 34
2023-01-04 07:03:14,125 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43657991190751394, 'Total loss': 0.43657991190751394} | train loss {'Reaction outcome loss': 0.35812029960381725, 'Total loss': 0.35812029960381725}
2023-01-04 07:03:14,126 INFO:     Found new best model at epoch 34
2023-01-04 07:03:14,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:14,126 INFO:     Epoch: 35
2023-01-04 07:03:15,681 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4555299391349157, 'Total loss': 0.4555299391349157} | train loss {'Reaction outcome loss': 0.35370335969937977, 'Total loss': 0.35370335969937977}
2023-01-04 07:03:15,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:15,681 INFO:     Epoch: 36
2023-01-04 07:03:17,270 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4441878656546275, 'Total loss': 0.4441878656546275} | train loss {'Reaction outcome loss': 0.34914618309070594, 'Total loss': 0.34914618309070594}
2023-01-04 07:03:17,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:17,270 INFO:     Epoch: 37
2023-01-04 07:03:18,804 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44881943265597024, 'Total loss': 0.44881943265597024} | train loss {'Reaction outcome loss': 0.34871050777987844, 'Total loss': 0.34871050777987844}
2023-01-04 07:03:18,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:18,805 INFO:     Epoch: 38
2023-01-04 07:03:20,350 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.468206861615181, 'Total loss': 0.468206861615181} | train loss {'Reaction outcome loss': 0.34408010811592543, 'Total loss': 0.34408010811592543}
2023-01-04 07:03:20,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:20,350 INFO:     Epoch: 39
2023-01-04 07:03:21,878 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43882720271746317, 'Total loss': 0.43882720271746317} | train loss {'Reaction outcome loss': 0.3410735609431336, 'Total loss': 0.3410735609431336}
2023-01-04 07:03:21,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:21,879 INFO:     Epoch: 40
2023-01-04 07:03:23,410 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4460994760195414, 'Total loss': 0.4460994760195414} | train loss {'Reaction outcome loss': 0.3389930810616182, 'Total loss': 0.3389930810616182}
2023-01-04 07:03:23,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:23,410 INFO:     Epoch: 41
2023-01-04 07:03:24,967 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40104824503262837, 'Total loss': 0.40104824503262837} | train loss {'Reaction outcome loss': 0.3357591587424713, 'Total loss': 0.3357591587424713}
2023-01-04 07:03:24,967 INFO:     Found new best model at epoch 41
2023-01-04 07:03:24,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:24,968 INFO:     Epoch: 42
2023-01-04 07:03:26,516 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4349480261405309, 'Total loss': 0.4349480261405309} | train loss {'Reaction outcome loss': 0.33148161185918934, 'Total loss': 0.33148161185918934}
2023-01-04 07:03:26,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:26,517 INFO:     Epoch: 43
2023-01-04 07:03:28,053 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.414589516321818, 'Total loss': 0.414589516321818} | train loss {'Reaction outcome loss': 0.33350448419142814, 'Total loss': 0.33350448419142814}
2023-01-04 07:03:28,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:28,054 INFO:     Epoch: 44
2023-01-04 07:03:29,584 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4512147714694341, 'Total loss': 0.4512147714694341} | train loss {'Reaction outcome loss': 0.3243856035499242, 'Total loss': 0.3243856035499242}
2023-01-04 07:03:29,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:29,584 INFO:     Epoch: 45
2023-01-04 07:03:31,079 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42138271729151405, 'Total loss': 0.42138271729151405} | train loss {'Reaction outcome loss': 0.32486763955467807, 'Total loss': 0.32486763955467807}
2023-01-04 07:03:31,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:31,080 INFO:     Epoch: 46
2023-01-04 07:03:32,597 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4193605323632558, 'Total loss': 0.4193605323632558} | train loss {'Reaction outcome loss': 0.3201264301790808, 'Total loss': 0.3201264301790808}
2023-01-04 07:03:32,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:32,598 INFO:     Epoch: 47
2023-01-04 07:03:34,155 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4364432493845622, 'Total loss': 0.4364432493845622} | train loss {'Reaction outcome loss': 0.318010648943647, 'Total loss': 0.318010648943647}
2023-01-04 07:03:34,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:34,155 INFO:     Epoch: 48
2023-01-04 07:03:35,701 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4269498566786448, 'Total loss': 0.4269498566786448} | train loss {'Reaction outcome loss': 0.32080204086038316, 'Total loss': 0.32080204086038316}
2023-01-04 07:03:35,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:35,702 INFO:     Epoch: 49
2023-01-04 07:03:37,253 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4325592239697774, 'Total loss': 0.4325592239697774} | train loss {'Reaction outcome loss': 0.31085696079543906, 'Total loss': 0.31085696079543906}
2023-01-04 07:03:37,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:37,253 INFO:     Epoch: 50
2023-01-04 07:03:38,802 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3954316814740499, 'Total loss': 0.3954316814740499} | train loss {'Reaction outcome loss': 0.3121615401911039, 'Total loss': 0.3121615401911039}
2023-01-04 07:03:38,802 INFO:     Found new best model at epoch 50
2023-01-04 07:03:38,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:38,803 INFO:     Epoch: 51
2023-01-04 07:03:40,292 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4449587404727936, 'Total loss': 0.4449587404727936} | train loss {'Reaction outcome loss': 0.30993908086288585, 'Total loss': 0.30993908086288585}
2023-01-04 07:03:40,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:40,293 INFO:     Epoch: 52
2023-01-04 07:03:41,828 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4027664621671041, 'Total loss': 0.4027664621671041} | train loss {'Reaction outcome loss': 0.30157920092779356, 'Total loss': 0.30157920092779356}
2023-01-04 07:03:41,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:41,828 INFO:     Epoch: 53
2023-01-04 07:03:43,381 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4474028686682383, 'Total loss': 0.4474028686682383} | train loss {'Reaction outcome loss': 0.30059593714719274, 'Total loss': 0.30059593714719274}
2023-01-04 07:03:43,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:43,382 INFO:     Epoch: 54
2023-01-04 07:03:44,947 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41129171252250674, 'Total loss': 0.41129171252250674} | train loss {'Reaction outcome loss': 0.30142580451321427, 'Total loss': 0.30142580451321427}
2023-01-04 07:03:44,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:44,948 INFO:     Epoch: 55
2023-01-04 07:03:46,508 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39255438645680746, 'Total loss': 0.39255438645680746} | train loss {'Reaction outcome loss': 0.30283305010873907, 'Total loss': 0.30283305010873907}
2023-01-04 07:03:46,508 INFO:     Found new best model at epoch 55
2023-01-04 07:03:46,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:46,509 INFO:     Epoch: 56
2023-01-04 07:03:48,046 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3936650464932124, 'Total loss': 0.3936650464932124} | train loss {'Reaction outcome loss': 0.29416424418072196, 'Total loss': 0.29416424418072196}
2023-01-04 07:03:48,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:48,047 INFO:     Epoch: 57
2023-01-04 07:03:49,521 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42289105703433355, 'Total loss': 0.42289105703433355} | train loss {'Reaction outcome loss': 0.2961096705964012, 'Total loss': 0.2961096705964012}
2023-01-04 07:03:49,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:49,521 INFO:     Epoch: 58
2023-01-04 07:03:51,075 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4175112505753835, 'Total loss': 0.4175112505753835} | train loss {'Reaction outcome loss': 0.2935247826152039, 'Total loss': 0.2935247826152039}
2023-01-04 07:03:51,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:51,075 INFO:     Epoch: 59
2023-01-04 07:03:52,628 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3917826582988103, 'Total loss': 0.3917826582988103} | train loss {'Reaction outcome loss': 0.29051598684903046, 'Total loss': 0.29051598684903046}
2023-01-04 07:03:52,628 INFO:     Found new best model at epoch 59
2023-01-04 07:03:52,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:52,629 INFO:     Epoch: 60
2023-01-04 07:03:54,196 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.417686527967453, 'Total loss': 0.417686527967453} | train loss {'Reaction outcome loss': 0.2897227000934582, 'Total loss': 0.2897227000934582}
2023-01-04 07:03:54,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:54,196 INFO:     Epoch: 61
2023-01-04 07:03:55,742 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4180766810973485, 'Total loss': 0.4180766810973485} | train loss {'Reaction outcome loss': 0.28798948065207824, 'Total loss': 0.28798948065207824}
2023-01-04 07:03:55,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:55,742 INFO:     Epoch: 62
2023-01-04 07:03:57,264 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44209816654523215, 'Total loss': 0.44209816654523215} | train loss {'Reaction outcome loss': 0.2853963860738887, 'Total loss': 0.2853963860738887}
2023-01-04 07:03:57,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:57,265 INFO:     Epoch: 63
2023-01-04 07:03:58,783 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4232740640640259, 'Total loss': 0.4232740640640259} | train loss {'Reaction outcome loss': 0.2800643666491021, 'Total loss': 0.2800643666491021}
2023-01-04 07:03:58,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:03:58,783 INFO:     Epoch: 64
2023-01-04 07:04:00,337 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3976389373342196, 'Total loss': 0.3976389373342196} | train loss {'Reaction outcome loss': 0.2854208376013885, 'Total loss': 0.2854208376013885}
2023-01-04 07:04:00,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:00,337 INFO:     Epoch: 65
2023-01-04 07:04:01,896 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3788173665603002, 'Total loss': 0.3788173665603002} | train loss {'Reaction outcome loss': 0.2769529881622017, 'Total loss': 0.2769529881622017}
2023-01-04 07:04:01,896 INFO:     Found new best model at epoch 65
2023-01-04 07:04:01,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:01,897 INFO:     Epoch: 66
2023-01-04 07:04:03,455 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40388346314430235, 'Total loss': 0.40388346314430235} | train loss {'Reaction outcome loss': 0.27786414828287426, 'Total loss': 0.27786414828287426}
2023-01-04 07:04:03,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:03,456 INFO:     Epoch: 67
2023-01-04 07:04:05,013 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40428152481714885, 'Total loss': 0.40428152481714885} | train loss {'Reaction outcome loss': 0.27852387951999685, 'Total loss': 0.27852387951999685}
2023-01-04 07:04:05,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:05,013 INFO:     Epoch: 68
2023-01-04 07:04:06,544 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39473322629928587, 'Total loss': 0.39473322629928587} | train loss {'Reaction outcome loss': 0.27951347509766145, 'Total loss': 0.27951347509766145}
2023-01-04 07:04:06,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:06,545 INFO:     Epoch: 69
2023-01-04 07:04:08,058 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4000114103158315, 'Total loss': 0.4000114103158315} | train loss {'Reaction outcome loss': 0.27108655135779486, 'Total loss': 0.27108655135779486}
2023-01-04 07:04:08,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:08,058 INFO:     Epoch: 70
2023-01-04 07:04:09,567 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4389093736807505, 'Total loss': 0.4389093736807505} | train loss {'Reaction outcome loss': 0.27195428513044856, 'Total loss': 0.27195428513044856}
2023-01-04 07:04:09,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:09,567 INFO:     Epoch: 71
2023-01-04 07:04:11,093 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3915845642487208, 'Total loss': 0.3915845642487208} | train loss {'Reaction outcome loss': 0.2725828906833908, 'Total loss': 0.2725828906833908}
2023-01-04 07:04:11,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:11,093 INFO:     Epoch: 72
2023-01-04 07:04:12,606 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4117790162563324, 'Total loss': 0.4117790162563324} | train loss {'Reaction outcome loss': 0.26964718212176414, 'Total loss': 0.26964718212176414}
2023-01-04 07:04:12,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:12,606 INFO:     Epoch: 73
2023-01-04 07:04:14,118 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42560463547706606, 'Total loss': 0.42560463547706606} | train loss {'Reaction outcome loss': 0.2700610231526577, 'Total loss': 0.2700610231526577}
2023-01-04 07:04:14,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:14,118 INFO:     Epoch: 74
2023-01-04 07:04:15,631 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4291808843612671, 'Total loss': 0.4291808843612671} | train loss {'Reaction outcome loss': 0.268102781398453, 'Total loss': 0.268102781398453}
2023-01-04 07:04:15,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:15,632 INFO:     Epoch: 75
2023-01-04 07:04:17,087 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40041908423105876, 'Total loss': 0.40041908423105876} | train loss {'Reaction outcome loss': 0.2659238871105396, 'Total loss': 0.2659238871105396}
2023-01-04 07:04:17,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:17,088 INFO:     Epoch: 76
2023-01-04 07:04:18,595 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38973217010498046, 'Total loss': 0.38973217010498046} | train loss {'Reaction outcome loss': 0.26255213930169596, 'Total loss': 0.26255213930169596}
2023-01-04 07:04:18,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:18,595 INFO:     Epoch: 77
2023-01-04 07:04:20,140 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3842388426264127, 'Total loss': 0.3842388426264127} | train loss {'Reaction outcome loss': 0.2634922602506232, 'Total loss': 0.2634922602506232}
2023-01-04 07:04:20,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:20,140 INFO:     Epoch: 78
2023-01-04 07:04:21,689 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4137338916460673, 'Total loss': 0.4137338916460673} | train loss {'Reaction outcome loss': 0.26725014436473377, 'Total loss': 0.26725014436473377}
2023-01-04 07:04:21,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:21,689 INFO:     Epoch: 79
2023-01-04 07:04:23,240 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3982014268636703, 'Total loss': 0.3982014268636703} | train loss {'Reaction outcome loss': 0.2659893706304966, 'Total loss': 0.2659893706304966}
2023-01-04 07:04:23,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:23,240 INFO:     Epoch: 80
2023-01-04 07:04:24,777 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3687102640668551, 'Total loss': 0.3687102640668551} | train loss {'Reaction outcome loss': 0.2606830552601031, 'Total loss': 0.2606830552601031}
2023-01-04 07:04:24,778 INFO:     Found new best model at epoch 80
2023-01-04 07:04:24,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:24,778 INFO:     Epoch: 81
2023-01-04 07:04:26,268 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3919881204764048, 'Total loss': 0.3919881204764048} | train loss {'Reaction outcome loss': 0.2587649820467634, 'Total loss': 0.2587649820467634}
2023-01-04 07:04:26,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:26,268 INFO:     Epoch: 82
2023-01-04 07:04:27,853 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3847009167075157, 'Total loss': 0.3847009167075157} | train loss {'Reaction outcome loss': 0.26113781626642185, 'Total loss': 0.26113781626642185}
2023-01-04 07:04:27,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:27,855 INFO:     Epoch: 83
2023-01-04 07:04:29,418 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4276161680618922, 'Total loss': 0.4276161680618922} | train loss {'Reaction outcome loss': 0.25941107855824225, 'Total loss': 0.25941107855824225}
2023-01-04 07:04:29,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:29,418 INFO:     Epoch: 84
2023-01-04 07:04:30,968 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3883548001448313, 'Total loss': 0.3883548001448313} | train loss {'Reaction outcome loss': 0.25687306469483095, 'Total loss': 0.25687306469483095}
2023-01-04 07:04:30,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:30,968 INFO:     Epoch: 85
2023-01-04 07:04:32,523 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40007338325182595, 'Total loss': 0.40007338325182595} | train loss {'Reaction outcome loss': 0.25480150833834697, 'Total loss': 0.25480150833834697}
2023-01-04 07:04:32,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:32,523 INFO:     Epoch: 86
2023-01-04 07:04:34,078 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42315423289934795, 'Total loss': 0.42315423289934795} | train loss {'Reaction outcome loss': 0.25226406474346225, 'Total loss': 0.25226406474346225}
2023-01-04 07:04:34,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:34,079 INFO:     Epoch: 87
2023-01-04 07:04:35,592 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3952122728029887, 'Total loss': 0.3952122728029887} | train loss {'Reaction outcome loss': 0.255725797809606, 'Total loss': 0.255725797809606}
2023-01-04 07:04:35,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:35,592 INFO:     Epoch: 88
2023-01-04 07:04:37,159 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3872577577829361, 'Total loss': 0.3872577577829361} | train loss {'Reaction outcome loss': 0.2570716909330039, 'Total loss': 0.2570716909330039}
2023-01-04 07:04:37,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:37,160 INFO:     Epoch: 89
2023-01-04 07:04:38,704 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4049938837687174, 'Total loss': 0.4049938837687174} | train loss {'Reaction outcome loss': 0.25378982907664166, 'Total loss': 0.25378982907664166}
2023-01-04 07:04:38,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:38,705 INFO:     Epoch: 90
2023-01-04 07:04:40,261 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39380692442258197, 'Total loss': 0.39380692442258197} | train loss {'Reaction outcome loss': 0.25218529148149665, 'Total loss': 0.25218529148149665}
2023-01-04 07:04:40,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:40,262 INFO:     Epoch: 91
2023-01-04 07:04:41,839 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39681989947954815, 'Total loss': 0.39681989947954815} | train loss {'Reaction outcome loss': 0.25448216140324614, 'Total loss': 0.25448216140324614}
2023-01-04 07:04:41,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:41,839 INFO:     Epoch: 92
2023-01-04 07:04:43,383 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38800861189762753, 'Total loss': 0.38800861189762753} | train loss {'Reaction outcome loss': 0.25070593911257105, 'Total loss': 0.25070593911257105}
2023-01-04 07:04:43,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:43,383 INFO:     Epoch: 93
2023-01-04 07:04:44,925 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38944811522960665, 'Total loss': 0.38944811522960665} | train loss {'Reaction outcome loss': 0.2509928557369178, 'Total loss': 0.2509928557369178}
2023-01-04 07:04:44,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:44,925 INFO:     Epoch: 94
2023-01-04 07:04:46,503 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4102320929368337, 'Total loss': 0.4102320929368337} | train loss {'Reaction outcome loss': 0.2521540298106244, 'Total loss': 0.2521540298106244}
2023-01-04 07:04:46,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:46,504 INFO:     Epoch: 95
2023-01-04 07:04:48,084 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3733983799815178, 'Total loss': 0.3733983799815178} | train loss {'Reaction outcome loss': 0.24495682295710935, 'Total loss': 0.24495682295710935}
2023-01-04 07:04:48,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:48,084 INFO:     Epoch: 96
2023-01-04 07:04:49,649 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3819864551226298, 'Total loss': 0.3819864551226298} | train loss {'Reaction outcome loss': 0.250533773896903, 'Total loss': 0.250533773896903}
2023-01-04 07:04:49,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:49,650 INFO:     Epoch: 97
2023-01-04 07:04:51,248 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40702700018882754, 'Total loss': 0.40702700018882754} | train loss {'Reaction outcome loss': 0.2479171446884853, 'Total loss': 0.2479171446884853}
2023-01-04 07:04:51,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:51,248 INFO:     Epoch: 98
2023-01-04 07:04:52,799 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3919170409440994, 'Total loss': 0.3919170409440994} | train loss {'Reaction outcome loss': 0.24281051735917147, 'Total loss': 0.24281051735917147}
2023-01-04 07:04:52,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:52,799 INFO:     Epoch: 99
2023-01-04 07:04:54,326 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.381010885288318, 'Total loss': 0.381010885288318} | train loss {'Reaction outcome loss': 0.24727795471566438, 'Total loss': 0.24727795471566438}
2023-01-04 07:04:54,326 INFO:     Best model found after epoch 81 of 100.
2023-01-04 07:04:54,327 INFO:   Done with stage: TRAINING
2023-01-04 07:04:54,327 INFO:   Starting stage: EVALUATION
2023-01-04 07:04:54,457 INFO:   Done with stage: EVALUATION
2023-01-04 07:04:54,458 INFO:   Leaving out SEQ value Fold_4
2023-01-04 07:04:54,470 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:04:54,470 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:04:55,115 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:04:55,115 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:04:55,185 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:04:55,185 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:04:55,185 INFO:     No hyperparam tuning for this model
2023-01-04 07:04:55,185 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:04:55,185 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:04:55,186 INFO:     None feature selector for col prot
2023-01-04 07:04:55,186 INFO:     None feature selector for col prot
2023-01-04 07:04:55,186 INFO:     None feature selector for col prot
2023-01-04 07:04:55,187 INFO:     None feature selector for col chem
2023-01-04 07:04:55,187 INFO:     None feature selector for col chem
2023-01-04 07:04:55,187 INFO:     None feature selector for col chem
2023-01-04 07:04:55,187 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:04:55,187 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:04:55,188 INFO:     Number of params in model 70111
2023-01-04 07:04:55,191 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:04:55,191 INFO:   Starting stage: TRAINING
2023-01-04 07:04:55,234 INFO:     Val loss before train {'Reaction outcome loss': 0.8620531996091206, 'Total loss': 0.8620531996091206}
2023-01-04 07:04:55,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:55,234 INFO:     Epoch: 0
2023-01-04 07:04:56,797 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6635721087455749, 'Total loss': 0.6635721087455749} | train loss {'Reaction outcome loss': 0.8612832910772683, 'Total loss': 0.8612832910772683}
2023-01-04 07:04:56,798 INFO:     Found new best model at epoch 0
2023-01-04 07:04:56,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:56,798 INFO:     Epoch: 1
2023-01-04 07:04:58,359 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5495790719985962, 'Total loss': 0.5495790719985962} | train loss {'Reaction outcome loss': 0.684868088916646, 'Total loss': 0.684868088916646}
2023-01-04 07:04:58,360 INFO:     Found new best model at epoch 1
2023-01-04 07:04:58,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:58,361 INFO:     Epoch: 2
2023-01-04 07:04:59,927 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49781411488850913, 'Total loss': 0.49781411488850913} | train loss {'Reaction outcome loss': 0.5855255045158707, 'Total loss': 0.5855255045158707}
2023-01-04 07:04:59,927 INFO:     Found new best model at epoch 2
2023-01-04 07:04:59,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:04:59,928 INFO:     Epoch: 3
2023-01-04 07:05:01,471 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49415715436140695, 'Total loss': 0.49415715436140695} | train loss {'Reaction outcome loss': 0.5411200864912025, 'Total loss': 0.5411200864912025}
2023-01-04 07:05:01,471 INFO:     Found new best model at epoch 3
2023-01-04 07:05:01,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:01,472 INFO:     Epoch: 4
2023-01-04 07:05:02,999 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4695258210102717, 'Total loss': 0.4695258210102717} | train loss {'Reaction outcome loss': 0.5176622531498256, 'Total loss': 0.5176622531498256}
2023-01-04 07:05:02,999 INFO:     Found new best model at epoch 4
2023-01-04 07:05:03,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:03,000 INFO:     Epoch: 5
2023-01-04 07:05:04,546 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47412505447864534, 'Total loss': 0.47412505447864534} | train loss {'Reaction outcome loss': 0.5049781639759928, 'Total loss': 0.5049781639759928}
2023-01-04 07:05:04,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:04,547 INFO:     Epoch: 6
2023-01-04 07:05:06,089 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4425379514694214, 'Total loss': 0.4425379514694214} | train loss {'Reaction outcome loss': 0.49778800191141775, 'Total loss': 0.49778800191141775}
2023-01-04 07:05:06,089 INFO:     Found new best model at epoch 6
2023-01-04 07:05:06,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:06,090 INFO:     Epoch: 7
2023-01-04 07:05:07,633 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45871409873167673, 'Total loss': 0.45871409873167673} | train loss {'Reaction outcome loss': 0.4834081170560819, 'Total loss': 0.4834081170560819}
2023-01-04 07:05:07,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:07,633 INFO:     Epoch: 8
2023-01-04 07:05:09,202 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4417768677075704, 'Total loss': 0.4417768677075704} | train loss {'Reaction outcome loss': 0.47965541132050904, 'Total loss': 0.47965541132050904}
2023-01-04 07:05:09,202 INFO:     Found new best model at epoch 8
2023-01-04 07:05:09,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:09,203 INFO:     Epoch: 9
2023-01-04 07:05:10,736 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4549426684776942, 'Total loss': 0.4549426684776942} | train loss {'Reaction outcome loss': 0.47212482096991787, 'Total loss': 0.47212482096991787}
2023-01-04 07:05:10,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:10,737 INFO:     Epoch: 10
2023-01-04 07:05:12,261 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4410028398036957, 'Total loss': 0.4410028398036957} | train loss {'Reaction outcome loss': 0.4651402857498792, 'Total loss': 0.4651402857498792}
2023-01-04 07:05:12,261 INFO:     Found new best model at epoch 10
2023-01-04 07:05:12,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:12,262 INFO:     Epoch: 11
2023-01-04 07:05:13,796 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4349471092224121, 'Total loss': 0.4349471092224121} | train loss {'Reaction outcome loss': 0.4644299068427442, 'Total loss': 0.4644299068427442}
2023-01-04 07:05:13,796 INFO:     Found new best model at epoch 11
2023-01-04 07:05:13,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:13,797 INFO:     Epoch: 12
2023-01-04 07:05:15,341 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4219481448332469, 'Total loss': 0.4219481448332469} | train loss {'Reaction outcome loss': 0.45581581582652864, 'Total loss': 0.45581581582652864}
2023-01-04 07:05:15,341 INFO:     Found new best model at epoch 12
2023-01-04 07:05:15,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:15,342 INFO:     Epoch: 13
2023-01-04 07:05:16,943 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45064353942871094, 'Total loss': 0.45064353942871094} | train loss {'Reaction outcome loss': 0.4518859296574943, 'Total loss': 0.4518859296574943}
2023-01-04 07:05:16,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:16,944 INFO:     Epoch: 14
2023-01-04 07:05:18,559 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42331786155700685, 'Total loss': 0.42331786155700685} | train loss {'Reaction outcome loss': 0.47259205925291864, 'Total loss': 0.47259205925291864}
2023-01-04 07:05:18,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:18,559 INFO:     Epoch: 15
2023-01-04 07:05:20,147 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4281477431456248, 'Total loss': 0.4281477431456248} | train loss {'Reaction outcome loss': 0.4500510227415994, 'Total loss': 0.4500510227415994}
2023-01-04 07:05:20,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:20,148 INFO:     Epoch: 16
2023-01-04 07:05:21,741 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42624621391296386, 'Total loss': 0.42624621391296386} | train loss {'Reaction outcome loss': 0.4418770550799546, 'Total loss': 0.4418770550799546}
2023-01-04 07:05:21,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:21,741 INFO:     Epoch: 17
2023-01-04 07:05:23,363 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44016225238641105, 'Total loss': 0.44016225238641105} | train loss {'Reaction outcome loss': 0.43813100924919546, 'Total loss': 0.43813100924919546}
2023-01-04 07:05:23,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:23,363 INFO:     Epoch: 18
2023-01-04 07:05:24,986 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4147241155306498, 'Total loss': 0.4147241155306498} | train loss {'Reaction outcome loss': 0.4289300629917188, 'Total loss': 0.4289300629917188}
2023-01-04 07:05:24,986 INFO:     Found new best model at epoch 18
2023-01-04 07:05:24,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:24,987 INFO:     Epoch: 19
2023-01-04 07:05:26,609 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4088529467582703, 'Total loss': 0.4088529467582703} | train loss {'Reaction outcome loss': 0.4251520824956073, 'Total loss': 0.4251520824956073}
2023-01-04 07:05:26,609 INFO:     Found new best model at epoch 19
2023-01-04 07:05:26,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:26,610 INFO:     Epoch: 20
2023-01-04 07:05:28,237 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4267577568689982, 'Total loss': 0.4267577568689982} | train loss {'Reaction outcome loss': 0.42472912202272023, 'Total loss': 0.42472912202272023}
2023-01-04 07:05:28,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:28,238 INFO:     Epoch: 21
2023-01-04 07:05:29,726 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41557934979597727, 'Total loss': 0.41557934979597727} | train loss {'Reaction outcome loss': 0.4211710304885671, 'Total loss': 0.4211710304885671}
2023-01-04 07:05:29,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:29,727 INFO:     Epoch: 22
2023-01-04 07:05:30,766 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42777946988741555, 'Total loss': 0.42777946988741555} | train loss {'Reaction outcome loss': 0.4152831069153288, 'Total loss': 0.4152831069153288}
2023-01-04 07:05:30,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:30,766 INFO:     Epoch: 23
2023-01-04 07:05:31,798 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44569577972094215, 'Total loss': 0.44569577972094215} | train loss {'Reaction outcome loss': 0.41509761207777524, 'Total loss': 0.41509761207777524}
2023-01-04 07:05:31,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:31,798 INFO:     Epoch: 24
2023-01-04 07:05:32,831 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4373343219359716, 'Total loss': 0.4373343219359716} | train loss {'Reaction outcome loss': 0.4318425843249197, 'Total loss': 0.4318425843249197}
2023-01-04 07:05:32,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:32,832 INFO:     Epoch: 25
2023-01-04 07:05:33,865 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4150560249884923, 'Total loss': 0.4150560249884923} | train loss {'Reaction outcome loss': 0.40627196787492087, 'Total loss': 0.40627196787492087}
2023-01-04 07:05:33,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:33,865 INFO:     Epoch: 26
2023-01-04 07:05:35,296 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4187788595755895, 'Total loss': 0.4187788595755895} | train loss {'Reaction outcome loss': 0.40299647920967446, 'Total loss': 0.40299647920967446}
2023-01-04 07:05:35,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:35,296 INFO:     Epoch: 27
2023-01-04 07:05:36,906 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42516730924447377, 'Total loss': 0.42516730924447377} | train loss {'Reaction outcome loss': 0.41177862367012363, 'Total loss': 0.41177862367012363}
2023-01-04 07:05:36,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:36,907 INFO:     Epoch: 28
2023-01-04 07:05:38,527 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40476149717966714, 'Total loss': 0.40476149717966714} | train loss {'Reaction outcome loss': 0.41554389040296275, 'Total loss': 0.41554389040296275}
2023-01-04 07:05:38,527 INFO:     Found new best model at epoch 28
2023-01-04 07:05:38,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:38,528 INFO:     Epoch: 29
2023-01-04 07:05:40,142 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41728807290395104, 'Total loss': 0.41728807290395104} | train loss {'Reaction outcome loss': 0.3907015396086364, 'Total loss': 0.3907015396086364}
2023-01-04 07:05:40,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:40,142 INFO:     Epoch: 30
2023-01-04 07:05:41,765 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43752100865046184, 'Total loss': 0.43752100865046184} | train loss {'Reaction outcome loss': 0.3873404984672864, 'Total loss': 0.3873404984672864}
2023-01-04 07:05:41,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:41,765 INFO:     Epoch: 31
2023-01-04 07:05:43,365 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41795096000035603, 'Total loss': 0.41795096000035603} | train loss {'Reaction outcome loss': 0.4087131882045904, 'Total loss': 0.4087131882045904}
2023-01-04 07:05:43,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:43,366 INFO:     Epoch: 32
2023-01-04 07:05:44,947 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40077305932839713, 'Total loss': 0.40077305932839713} | train loss {'Reaction outcome loss': 0.3871014064474814, 'Total loss': 0.3871014064474814}
2023-01-04 07:05:44,947 INFO:     Found new best model at epoch 32
2023-01-04 07:05:44,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:44,948 INFO:     Epoch: 33
2023-01-04 07:05:46,544 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3854108303785324, 'Total loss': 0.3854108303785324} | train loss {'Reaction outcome loss': 0.37938598370764987, 'Total loss': 0.37938598370764987}
2023-01-04 07:05:46,544 INFO:     Found new best model at epoch 33
2023-01-04 07:05:46,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:46,545 INFO:     Epoch: 34
2023-01-04 07:05:48,115 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3981560548146566, 'Total loss': 0.3981560548146566} | train loss {'Reaction outcome loss': 0.381677002112037, 'Total loss': 0.381677002112037}
2023-01-04 07:05:48,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:48,115 INFO:     Epoch: 35
2023-01-04 07:05:49,686 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3756987084945043, 'Total loss': 0.3756987084945043} | train loss {'Reaction outcome loss': 0.3744066936652298, 'Total loss': 0.3744066936652298}
2023-01-04 07:05:49,687 INFO:     Found new best model at epoch 35
2023-01-04 07:05:49,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:49,688 INFO:     Epoch: 36
2023-01-04 07:05:51,263 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3740869770447413, 'Total loss': 0.3740869770447413} | train loss {'Reaction outcome loss': 0.3762455548006245, 'Total loss': 0.3762455548006245}
2023-01-04 07:05:51,263 INFO:     Found new best model at epoch 36
2023-01-04 07:05:51,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:51,264 INFO:     Epoch: 37
2023-01-04 07:05:52,809 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4086654355128606, 'Total loss': 0.4086654355128606} | train loss {'Reaction outcome loss': 0.36740132257261354, 'Total loss': 0.36740132257261354}
2023-01-04 07:05:52,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:52,810 INFO:     Epoch: 38
2023-01-04 07:05:54,360 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42020542124907173, 'Total loss': 0.42020542124907173} | train loss {'Reaction outcome loss': 0.383523099421375, 'Total loss': 0.383523099421375}
2023-01-04 07:05:54,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:54,361 INFO:     Epoch: 39
2023-01-04 07:05:55,935 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4066102147102356, 'Total loss': 0.4066102147102356} | train loss {'Reaction outcome loss': 0.4090828581070325, 'Total loss': 0.4090828581070325}
2023-01-04 07:05:55,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:55,935 INFO:     Epoch: 40
2023-01-04 07:05:57,499 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40229903558890023, 'Total loss': 0.40229903558890023} | train loss {'Reaction outcome loss': 0.36796833245434624, 'Total loss': 0.36796833245434624}
2023-01-04 07:05:57,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:57,500 INFO:     Epoch: 41
2023-01-04 07:05:59,113 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4014719138542811, 'Total loss': 0.4014719138542811} | train loss {'Reaction outcome loss': 0.3639277698376527, 'Total loss': 0.3639277698376527}
2023-01-04 07:05:59,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:05:59,113 INFO:     Epoch: 42
2023-01-04 07:06:00,716 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38990626732508343, 'Total loss': 0.38990626732508343} | train loss {'Reaction outcome loss': 0.36178194892093324, 'Total loss': 0.36178194892093324}
2023-01-04 07:06:00,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:00,717 INFO:     Epoch: 43
2023-01-04 07:06:02,255 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41409714420636495, 'Total loss': 0.41409714420636495} | train loss {'Reaction outcome loss': 0.3652323982745841, 'Total loss': 0.3652323982745841}
2023-01-04 07:06:02,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:02,256 INFO:     Epoch: 44
2023-01-04 07:06:03,808 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3716997226079305, 'Total loss': 0.3716997226079305} | train loss {'Reaction outcome loss': 0.3798563721873612, 'Total loss': 0.3798563721873612}
2023-01-04 07:06:03,808 INFO:     Found new best model at epoch 44
2023-01-04 07:06:03,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:03,809 INFO:     Epoch: 45
2023-01-04 07:06:05,383 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3796193987131119, 'Total loss': 0.3796193987131119} | train loss {'Reaction outcome loss': 0.3546729439775041, 'Total loss': 0.3546729439775041}
2023-01-04 07:06:05,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:05,384 INFO:     Epoch: 46
2023-01-04 07:06:06,961 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3648254930973053, 'Total loss': 0.3648254930973053} | train loss {'Reaction outcome loss': 0.35646765198612557, 'Total loss': 0.35646765198612557}
2023-01-04 07:06:06,961 INFO:     Found new best model at epoch 46
2023-01-04 07:06:06,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:06,962 INFO:     Epoch: 47
2023-01-04 07:06:08,532 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.371843550602595, 'Total loss': 0.371843550602595} | train loss {'Reaction outcome loss': 0.384450435079128, 'Total loss': 0.384450435079128}
2023-01-04 07:06:08,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:08,532 INFO:     Epoch: 48
2023-01-04 07:06:10,100 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39944424529870354, 'Total loss': 0.39944424529870354} | train loss {'Reaction outcome loss': 0.34500213590976986, 'Total loss': 0.34500213590976986}
2023-01-04 07:06:10,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:10,100 INFO:     Epoch: 49
2023-01-04 07:06:11,622 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3745617657899857, 'Total loss': 0.3745617657899857} | train loss {'Reaction outcome loss': 0.34133412683571596, 'Total loss': 0.34133412683571596}
2023-01-04 07:06:11,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:11,623 INFO:     Epoch: 50
2023-01-04 07:06:13,198 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37384444375832876, 'Total loss': 0.37384444375832876} | train loss {'Reaction outcome loss': 0.3437373801202014, 'Total loss': 0.3437373801202014}
2023-01-04 07:06:13,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:13,199 INFO:     Epoch: 51
2023-01-04 07:06:14,794 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3735679934422175, 'Total loss': 0.3735679934422175} | train loss {'Reaction outcome loss': 0.34242922365935385, 'Total loss': 0.34242922365935385}
2023-01-04 07:06:14,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:14,795 INFO:     Epoch: 52
2023-01-04 07:06:16,418 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38646175265312194, 'Total loss': 0.38646175265312194} | train loss {'Reaction outcome loss': 0.337103388906605, 'Total loss': 0.337103388906605}
2023-01-04 07:06:16,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:16,419 INFO:     Epoch: 53
2023-01-04 07:06:18,008 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39778779248396556, 'Total loss': 0.39778779248396556} | train loss {'Reaction outcome loss': 0.3353002917947774, 'Total loss': 0.3353002917947774}
2023-01-04 07:06:18,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:18,008 INFO:     Epoch: 54
2023-01-04 07:06:19,602 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39011066655317944, 'Total loss': 0.39011066655317944} | train loss {'Reaction outcome loss': 0.33145288047650695, 'Total loss': 0.33145288047650695}
2023-01-04 07:06:19,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:19,602 INFO:     Epoch: 55
2023-01-04 07:06:21,110 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.34692921737829846, 'Total loss': 0.34692921737829846} | train loss {'Reaction outcome loss': 0.33105248639333074, 'Total loss': 0.33105248639333074}
2023-01-04 07:06:21,110 INFO:     Found new best model at epoch 55
2023-01-04 07:06:21,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:21,111 INFO:     Epoch: 56
2023-01-04 07:06:22,687 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37975459297498065, 'Total loss': 0.37975459297498065} | train loss {'Reaction outcome loss': 0.330771260611389, 'Total loss': 0.330771260611389}
2023-01-04 07:06:22,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:22,687 INFO:     Epoch: 57
2023-01-04 07:06:24,267 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3701106160879135, 'Total loss': 0.3701106160879135} | train loss {'Reaction outcome loss': 0.3312007306443959, 'Total loss': 0.3312007306443959}
2023-01-04 07:06:24,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:24,268 INFO:     Epoch: 58
2023-01-04 07:06:25,845 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3857661257187525, 'Total loss': 0.3857661257187525} | train loss {'Reaction outcome loss': 0.32536533501242165, 'Total loss': 0.32536533501242165}
2023-01-04 07:06:25,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:25,845 INFO:     Epoch: 59
2023-01-04 07:06:27,409 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37511991361776986, 'Total loss': 0.37511991361776986} | train loss {'Reaction outcome loss': 0.3206357232099264, 'Total loss': 0.3206357232099264}
2023-01-04 07:06:27,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:27,410 INFO:     Epoch: 60
2023-01-04 07:06:28,952 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38432624836762747, 'Total loss': 0.38432624836762747} | train loss {'Reaction outcome loss': 0.32273147831016313, 'Total loss': 0.32273147831016313}
2023-01-04 07:06:28,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:28,952 INFO:     Epoch: 61
2023-01-04 07:06:30,492 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.35064986447493235, 'Total loss': 0.35064986447493235} | train loss {'Reaction outcome loss': 0.3194180048759217, 'Total loss': 0.3194180048759217}
2023-01-04 07:06:30,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:30,492 INFO:     Epoch: 62
2023-01-04 07:06:32,048 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3521855433781942, 'Total loss': 0.3521855433781942} | train loss {'Reaction outcome loss': 0.31780634189057755, 'Total loss': 0.31780634189057755}
2023-01-04 07:06:32,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:32,048 INFO:     Epoch: 63
2023-01-04 07:06:33,631 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37970294753710426, 'Total loss': 0.37970294753710426} | train loss {'Reaction outcome loss': 0.3174425668038421, 'Total loss': 0.3174425668038421}
2023-01-04 07:06:33,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:33,631 INFO:     Epoch: 64
2023-01-04 07:06:35,187 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37179968456427254, 'Total loss': 0.37179968456427254} | train loss {'Reaction outcome loss': 0.3110015550290869, 'Total loss': 0.3110015550290869}
2023-01-04 07:06:35,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:35,187 INFO:     Epoch: 65
2023-01-04 07:06:36,750 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36644901235898336, 'Total loss': 0.36644901235898336} | train loss {'Reaction outcome loss': 0.317094283596869, 'Total loss': 0.317094283596869}
2023-01-04 07:06:36,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:36,752 INFO:     Epoch: 66
2023-01-04 07:06:38,277 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3681855375568072, 'Total loss': 0.3681855375568072} | train loss {'Reaction outcome loss': 0.318062763215731, 'Total loss': 0.318062763215731}
2023-01-04 07:06:38,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:38,277 INFO:     Epoch: 67
2023-01-04 07:06:39,863 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3866692433754603, 'Total loss': 0.3866692433754603} | train loss {'Reaction outcome loss': 0.3138403744585272, 'Total loss': 0.3138403744585272}
2023-01-04 07:06:39,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:39,863 INFO:     Epoch: 68
2023-01-04 07:06:41,474 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39853820701440174, 'Total loss': 0.39853820701440174} | train loss {'Reaction outcome loss': 0.32829686159780924, 'Total loss': 0.32829686159780924}
2023-01-04 07:06:41,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:41,474 INFO:     Epoch: 69
2023-01-04 07:06:43,090 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3733320593833923, 'Total loss': 0.3733320593833923} | train loss {'Reaction outcome loss': 0.3153385885221803, 'Total loss': 0.3153385885221803}
2023-01-04 07:06:43,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:43,091 INFO:     Epoch: 70
2023-01-04 07:06:44,710 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37989883273839953, 'Total loss': 0.37989883273839953} | train loss {'Reaction outcome loss': 0.3180114379881517, 'Total loss': 0.3180114379881517}
2023-01-04 07:06:44,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:44,710 INFO:     Epoch: 71
2023-01-04 07:06:46,322 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38232943912347156, 'Total loss': 0.38232943912347156} | train loss {'Reaction outcome loss': 0.30603157356961386, 'Total loss': 0.30603157356961386}
2023-01-04 07:06:46,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:46,323 INFO:     Epoch: 72
2023-01-04 07:06:47,899 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36487234036127725, 'Total loss': 0.36487234036127725} | train loss {'Reaction outcome loss': 0.2996423339498216, 'Total loss': 0.2996423339498216}
2023-01-04 07:06:47,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:47,899 INFO:     Epoch: 73
2023-01-04 07:06:49,489 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37313024202982586, 'Total loss': 0.37313024202982586} | train loss {'Reaction outcome loss': 0.29987221262063424, 'Total loss': 0.29987221262063424}
2023-01-04 07:06:49,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:49,489 INFO:     Epoch: 74
2023-01-04 07:06:51,102 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36868252356847125, 'Total loss': 0.36868252356847125} | train loss {'Reaction outcome loss': 0.3064945323554718, 'Total loss': 0.3064945323554718}
2023-01-04 07:06:51,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:51,102 INFO:     Epoch: 75
2023-01-04 07:06:52,727 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3997193108002345, 'Total loss': 0.3997193108002345} | train loss {'Reaction outcome loss': 0.29926659481260803, 'Total loss': 0.29926659481260803}
2023-01-04 07:06:52,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:52,728 INFO:     Epoch: 76
2023-01-04 07:06:54,332 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3993729382753372, 'Total loss': 0.3993729382753372} | train loss {'Reaction outcome loss': 0.2999944614543431, 'Total loss': 0.2999944614543431}
2023-01-04 07:06:54,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:54,332 INFO:     Epoch: 77
2023-01-04 07:06:55,953 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3725648999214172, 'Total loss': 0.3725648999214172} | train loss {'Reaction outcome loss': 0.32157284798219166, 'Total loss': 0.32157284798219166}
2023-01-04 07:06:55,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:55,954 INFO:     Epoch: 78
2023-01-04 07:06:57,488 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3730660160382589, 'Total loss': 0.3730660160382589} | train loss {'Reaction outcome loss': 0.29611673471652833, 'Total loss': 0.29611673471652833}
2023-01-04 07:06:57,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:57,488 INFO:     Epoch: 79
2023-01-04 07:06:59,109 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3631941984097163, 'Total loss': 0.3631941984097163} | train loss {'Reaction outcome loss': 0.29436876530340617, 'Total loss': 0.29436876530340617}
2023-01-04 07:06:59,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:06:59,109 INFO:     Epoch: 80
2023-01-04 07:07:00,730 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37537537266810733, 'Total loss': 0.37537537266810733} | train loss {'Reaction outcome loss': 0.2982283660717455, 'Total loss': 0.2982283660717455}
2023-01-04 07:07:00,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:00,731 INFO:     Epoch: 81
2023-01-04 07:07:02,355 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3501773660381635, 'Total loss': 0.3501773660381635} | train loss {'Reaction outcome loss': 0.29400198508485936, 'Total loss': 0.29400198508485936}
2023-01-04 07:07:02,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:02,355 INFO:     Epoch: 82
2023-01-04 07:07:03,974 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37674662172794343, 'Total loss': 0.37674662172794343} | train loss {'Reaction outcome loss': 0.2912625023211472, 'Total loss': 0.2912625023211472}
2023-01-04 07:07:03,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:03,974 INFO:     Epoch: 83
2023-01-04 07:07:05,532 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35976224939028423, 'Total loss': 0.35976224939028423} | train loss {'Reaction outcome loss': 0.29248187605994064, 'Total loss': 0.29248187605994064}
2023-01-04 07:07:05,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:05,533 INFO:     Epoch: 84
2023-01-04 07:07:07,054 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38653209805488586, 'Total loss': 0.38653209805488586} | train loss {'Reaction outcome loss': 0.2871154430831666, 'Total loss': 0.2871154430831666}
2023-01-04 07:07:07,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:07,054 INFO:     Epoch: 85
2023-01-04 07:07:08,614 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.361822638909022, 'Total loss': 0.361822638909022} | train loss {'Reaction outcome loss': 0.2922010867988465, 'Total loss': 0.2922010867988465}
2023-01-04 07:07:08,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:08,614 INFO:     Epoch: 86
2023-01-04 07:07:10,166 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3565342495838801, 'Total loss': 0.3565342495838801} | train loss {'Reaction outcome loss': 0.2885749367672005, 'Total loss': 0.2885749367672005}
2023-01-04 07:07:10,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:10,167 INFO:     Epoch: 87
2023-01-04 07:07:11,733 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37473934491475425, 'Total loss': 0.37473934491475425} | train loss {'Reaction outcome loss': 0.2873270056012004, 'Total loss': 0.2873270056012004}
2023-01-04 07:07:11,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:11,734 INFO:     Epoch: 88
2023-01-04 07:07:13,293 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3626109222571055, 'Total loss': 0.3626109222571055} | train loss {'Reaction outcome loss': 0.2840309660661159, 'Total loss': 0.2840309660661159}
2023-01-04 07:07:13,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:13,294 INFO:     Epoch: 89
2023-01-04 07:07:14,824 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3866459051767985, 'Total loss': 0.3866459051767985} | train loss {'Reaction outcome loss': 0.2838460764648609, 'Total loss': 0.2838460764648609}
2023-01-04 07:07:14,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:14,824 INFO:     Epoch: 90
2023-01-04 07:07:16,348 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3754587004582087, 'Total loss': 0.3754587004582087} | train loss {'Reaction outcome loss': 0.28824105958683766, 'Total loss': 0.28824105958683766}
2023-01-04 07:07:16,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:16,349 INFO:     Epoch: 91
2023-01-04 07:07:17,909 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38068412939707436, 'Total loss': 0.38068412939707436} | train loss {'Reaction outcome loss': 0.3164160353657992, 'Total loss': 0.3164160353657992}
2023-01-04 07:07:17,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:17,910 INFO:     Epoch: 92
2023-01-04 07:07:19,472 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36221041679382326, 'Total loss': 0.36221041679382326} | train loss {'Reaction outcome loss': 0.2846517526963051, 'Total loss': 0.2846517526963051}
2023-01-04 07:07:19,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:19,472 INFO:     Epoch: 93
2023-01-04 07:07:21,040 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34794128040472666, 'Total loss': 0.34794128040472666} | train loss {'Reaction outcome loss': 0.28059284566594556, 'Total loss': 0.28059284566594556}
2023-01-04 07:07:21,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:21,041 INFO:     Epoch: 94
2023-01-04 07:07:22,631 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3775831013917923, 'Total loss': 0.3775831013917923} | train loss {'Reaction outcome loss': 0.2828581437878587, 'Total loss': 0.2828581437878587}
2023-01-04 07:07:22,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:22,631 INFO:     Epoch: 95
2023-01-04 07:07:24,191 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38003570834795636, 'Total loss': 0.38003570834795636} | train loss {'Reaction outcome loss': 0.2836918180639285, 'Total loss': 0.2836918180639285}
2023-01-04 07:07:24,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:24,191 INFO:     Epoch: 96
2023-01-04 07:07:25,775 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34819929450750353, 'Total loss': 0.34819929450750353} | train loss {'Reaction outcome loss': 0.2760073332600228, 'Total loss': 0.2760073332600228}
2023-01-04 07:07:25,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:25,775 INFO:     Epoch: 97
2023-01-04 07:07:27,402 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3864068587621053, 'Total loss': 0.3864068587621053} | train loss {'Reaction outcome loss': 0.278326042662071, 'Total loss': 0.278326042662071}
2023-01-04 07:07:27,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:27,403 INFO:     Epoch: 98
2023-01-04 07:07:29,035 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34558373093605044, 'Total loss': 0.34558373093605044} | train loss {'Reaction outcome loss': 0.27628230846122553, 'Total loss': 0.27628230846122553}
2023-01-04 07:07:29,035 INFO:     Found new best model at epoch 98
2023-01-04 07:07:29,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:29,035 INFO:     Epoch: 99
2023-01-04 07:07:30,651 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35995347499847413, 'Total loss': 0.35995347499847413} | train loss {'Reaction outcome loss': 0.2723864594171165, 'Total loss': 0.2723864594171165}
2023-01-04 07:07:30,652 INFO:     Best model found after epoch 99 of 100.
2023-01-04 07:07:30,652 INFO:   Done with stage: TRAINING
2023-01-04 07:07:30,652 INFO:   Starting stage: EVALUATION
2023-01-04 07:07:30,779 INFO:   Done with stage: EVALUATION
2023-01-04 07:07:30,779 INFO:   Leaving out SEQ value Fold_5
2023-01-04 07:07:30,792 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 07:07:30,792 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:07:31,443 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:07:31,443 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:07:31,513 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:07:31,513 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:07:31,513 INFO:     No hyperparam tuning for this model
2023-01-04 07:07:31,513 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:07:31,513 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:07:31,514 INFO:     None feature selector for col prot
2023-01-04 07:07:31,514 INFO:     None feature selector for col prot
2023-01-04 07:07:31,514 INFO:     None feature selector for col prot
2023-01-04 07:07:31,514 INFO:     None feature selector for col chem
2023-01-04 07:07:31,514 INFO:     None feature selector for col chem
2023-01-04 07:07:31,515 INFO:     None feature selector for col chem
2023-01-04 07:07:31,515 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:07:31,515 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:07:31,516 INFO:     Number of params in model 70111
2023-01-04 07:07:31,519 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:07:31,519 INFO:   Starting stage: TRAINING
2023-01-04 07:07:31,562 INFO:     Val loss before train {'Reaction outcome loss': 1.0567736983299256, 'Total loss': 1.0567736983299256}
2023-01-04 07:07:31,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:31,562 INFO:     Epoch: 0
2023-01-04 07:07:33,108 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7588002363840739, 'Total loss': 0.7588002363840739} | train loss {'Reaction outcome loss': 0.8578199672139508, 'Total loss': 0.8578199672139508}
2023-01-04 07:07:33,108 INFO:     Found new best model at epoch 0
2023-01-04 07:07:33,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:33,109 INFO:     Epoch: 1
2023-01-04 07:07:34,643 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6477226833502452, 'Total loss': 0.6477226833502452} | train loss {'Reaction outcome loss': 0.6909769833733459, 'Total loss': 0.6909769833733459}
2023-01-04 07:07:34,643 INFO:     Found new best model at epoch 1
2023-01-04 07:07:34,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:34,644 INFO:     Epoch: 2
2023-01-04 07:07:36,207 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5713892777760824, 'Total loss': 0.5713892777760824} | train loss {'Reaction outcome loss': 0.5973641058490595, 'Total loss': 0.5973641058490595}
2023-01-04 07:07:36,207 INFO:     Found new best model at epoch 2
2023-01-04 07:07:36,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:36,208 INFO:     Epoch: 3
2023-01-04 07:07:37,785 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5355230828126272, 'Total loss': 0.5355230828126272} | train loss {'Reaction outcome loss': 0.5527954241966943, 'Total loss': 0.5527954241966943}
2023-01-04 07:07:37,786 INFO:     Found new best model at epoch 3
2023-01-04 07:07:37,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:37,786 INFO:     Epoch: 4
2023-01-04 07:07:39,365 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5324175645907719, 'Total loss': 0.5324175645907719} | train loss {'Reaction outcome loss': 0.5247784202064418, 'Total loss': 0.5247784202064418}
2023-01-04 07:07:39,365 INFO:     Found new best model at epoch 4
2023-01-04 07:07:39,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:39,366 INFO:     Epoch: 5
2023-01-04 07:07:40,967 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5414440115292867, 'Total loss': 0.5414440115292867} | train loss {'Reaction outcome loss': 0.5099809566774953, 'Total loss': 0.5099809566774953}
2023-01-04 07:07:40,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:40,968 INFO:     Epoch: 6
2023-01-04 07:07:42,467 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5118389030297598, 'Total loss': 0.5118389030297598} | train loss {'Reaction outcome loss': 0.4902326825616162, 'Total loss': 0.4902326825616162}
2023-01-04 07:07:42,468 INFO:     Found new best model at epoch 6
2023-01-04 07:07:42,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:42,469 INFO:     Epoch: 7
2023-01-04 07:07:44,060 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5003358999888102, 'Total loss': 0.5003358999888102} | train loss {'Reaction outcome loss': 0.4908012940349992, 'Total loss': 0.4908012940349992}
2023-01-04 07:07:44,060 INFO:     Found new best model at epoch 7
2023-01-04 07:07:44,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:44,060 INFO:     Epoch: 8
2023-01-04 07:07:45,644 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4858405113220215, 'Total loss': 0.4858405113220215} | train loss {'Reaction outcome loss': 0.4806754083409637, 'Total loss': 0.4806754083409637}
2023-01-04 07:07:45,644 INFO:     Found new best model at epoch 8
2023-01-04 07:07:45,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:45,645 INFO:     Epoch: 9
2023-01-04 07:07:47,219 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4802075137694677, 'Total loss': 0.4802075137694677} | train loss {'Reaction outcome loss': 0.47300363302446014, 'Total loss': 0.47300363302446014}
2023-01-04 07:07:47,219 INFO:     Found new best model at epoch 9
2023-01-04 07:07:47,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:47,220 INFO:     Epoch: 10
2023-01-04 07:07:48,782 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47655235131581625, 'Total loss': 0.47655235131581625} | train loss {'Reaction outcome loss': 0.46415340814349454, 'Total loss': 0.46415340814349454}
2023-01-04 07:07:48,782 INFO:     Found new best model at epoch 10
2023-01-04 07:07:48,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:48,783 INFO:     Epoch: 11
2023-01-04 07:07:50,335 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47074148456255593, 'Total loss': 0.47074148456255593} | train loss {'Reaction outcome loss': 0.46223088964443343, 'Total loss': 0.46223088964443343}
2023-01-04 07:07:50,336 INFO:     Found new best model at epoch 11
2023-01-04 07:07:50,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:50,336 INFO:     Epoch: 12
2023-01-04 07:07:51,861 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46698873937129975, 'Total loss': 0.46698873937129975} | train loss {'Reaction outcome loss': 0.4558058252511042, 'Total loss': 0.4558058252511042}
2023-01-04 07:07:51,861 INFO:     Found new best model at epoch 12
2023-01-04 07:07:51,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:51,862 INFO:     Epoch: 13
2023-01-04 07:07:53,430 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4872167805830638, 'Total loss': 0.4872167805830638} | train loss {'Reaction outcome loss': 0.44998072117351884, 'Total loss': 0.44998072117351884}
2023-01-04 07:07:53,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:53,430 INFO:     Epoch: 14
2023-01-04 07:07:55,014 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4458476444085439, 'Total loss': 0.4458476444085439} | train loss {'Reaction outcome loss': 0.4456383918919718, 'Total loss': 0.4456383918919718}
2023-01-04 07:07:55,014 INFO:     Found new best model at epoch 14
2023-01-04 07:07:55,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:55,015 INFO:     Epoch: 15
2023-01-04 07:07:56,581 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46862489183743794, 'Total loss': 0.46862489183743794} | train loss {'Reaction outcome loss': 0.4410170272584426, 'Total loss': 0.4410170272584426}
2023-01-04 07:07:56,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:56,581 INFO:     Epoch: 16
2023-01-04 07:07:58,140 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.464424134294192, 'Total loss': 0.464424134294192} | train loss {'Reaction outcome loss': 0.43580648881326084, 'Total loss': 0.43580648881326084}
2023-01-04 07:07:58,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:58,140 INFO:     Epoch: 17
2023-01-04 07:07:59,662 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4602117081483205, 'Total loss': 0.4602117081483205} | train loss {'Reaction outcome loss': 0.43198352966067594, 'Total loss': 0.43198352966067594}
2023-01-04 07:07:59,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:07:59,662 INFO:     Epoch: 18
2023-01-04 07:08:01,188 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4427216668923696, 'Total loss': 0.4427216668923696} | train loss {'Reaction outcome loss': 0.4262481151074709, 'Total loss': 0.4262481151074709}
2023-01-04 07:08:01,189 INFO:     Found new best model at epoch 18
2023-01-04 07:08:01,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:01,190 INFO:     Epoch: 19
2023-01-04 07:08:02,756 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44133848945299786, 'Total loss': 0.44133848945299786} | train loss {'Reaction outcome loss': 0.4234614364722145, 'Total loss': 0.4234614364722145}
2023-01-04 07:08:02,756 INFO:     Found new best model at epoch 19
2023-01-04 07:08:02,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:02,757 INFO:     Epoch: 20
2023-01-04 07:08:04,313 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45527618130048114, 'Total loss': 0.45527618130048114} | train loss {'Reaction outcome loss': 0.4217514279786, 'Total loss': 0.4217514279786}
2023-01-04 07:08:04,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:04,313 INFO:     Epoch: 21
2023-01-04 07:08:05,889 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4384801000356674, 'Total loss': 0.4384801000356674} | train loss {'Reaction outcome loss': 0.4160527854297135, 'Total loss': 0.4160527854297135}
2023-01-04 07:08:05,889 INFO:     Found new best model at epoch 21
2023-01-04 07:08:05,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:05,890 INFO:     Epoch: 22
2023-01-04 07:08:07,463 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44599440892537434, 'Total loss': 0.44599440892537434} | train loss {'Reaction outcome loss': 0.41096259223209824, 'Total loss': 0.41096259223209824}
2023-01-04 07:08:07,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:07,463 INFO:     Epoch: 23
2023-01-04 07:08:08,998 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4308277646700541, 'Total loss': 0.4308277646700541} | train loss {'Reaction outcome loss': 0.4077530284866099, 'Total loss': 0.4077530284866099}
2023-01-04 07:08:08,998 INFO:     Found new best model at epoch 23
2023-01-04 07:08:08,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:08,999 INFO:     Epoch: 24
2023-01-04 07:08:10,530 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.435562926530838, 'Total loss': 0.435562926530838} | train loss {'Reaction outcome loss': 0.40276195994487524, 'Total loss': 0.40276195994487524}
2023-01-04 07:08:10,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:10,531 INFO:     Epoch: 25
2023-01-04 07:08:12,082 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44557167291641236, 'Total loss': 0.44557167291641236} | train loss {'Reaction outcome loss': 0.4007422389321379, 'Total loss': 0.4007422389321379}
2023-01-04 07:08:12,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:12,083 INFO:     Epoch: 26
2023-01-04 07:08:13,635 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4142361988623937, 'Total loss': 0.4142361988623937} | train loss {'Reaction outcome loss': 0.3967144344042354, 'Total loss': 0.3967144344042354}
2023-01-04 07:08:13,636 INFO:     Found new best model at epoch 26
2023-01-04 07:08:13,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:13,637 INFO:     Epoch: 27
2023-01-04 07:08:15,202 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44037704467773436, 'Total loss': 0.44037704467773436} | train loss {'Reaction outcome loss': 0.39299559948246404, 'Total loss': 0.39299559948246404}
2023-01-04 07:08:15,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:15,203 INFO:     Epoch: 28
2023-01-04 07:08:16,761 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4345377842585246, 'Total loss': 0.4345377842585246} | train loss {'Reaction outcome loss': 0.38930163785331084, 'Total loss': 0.38930163785331084}
2023-01-04 07:08:16,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:16,761 INFO:     Epoch: 29
2023-01-04 07:08:18,311 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44971123735109964, 'Total loss': 0.44971123735109964} | train loss {'Reaction outcome loss': 0.3852935747011474, 'Total loss': 0.3852935747011474}
2023-01-04 07:08:18,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:18,311 INFO:     Epoch: 30
2023-01-04 07:08:19,841 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45175983011722565, 'Total loss': 0.45175983011722565} | train loss {'Reaction outcome loss': 0.3793048292048787, 'Total loss': 0.3793048292048787}
2023-01-04 07:08:19,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:19,842 INFO:     Epoch: 31
2023-01-04 07:08:21,417 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43668119112650555, 'Total loss': 0.43668119112650555} | train loss {'Reaction outcome loss': 0.3829140635980596, 'Total loss': 0.3829140635980596}
2023-01-04 07:08:21,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:21,418 INFO:     Epoch: 32
2023-01-04 07:08:23,002 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4348759323358536, 'Total loss': 0.4348759323358536} | train loss {'Reaction outcome loss': 0.38035178601419023, 'Total loss': 0.38035178601419023}
2023-01-04 07:08:23,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:23,002 INFO:     Epoch: 33
2023-01-04 07:08:24,553 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42440879146258037, 'Total loss': 0.42440879146258037} | train loss {'Reaction outcome loss': 0.3727608621389427, 'Total loss': 0.3727608621389427}
2023-01-04 07:08:24,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:24,554 INFO:     Epoch: 34
2023-01-04 07:08:26,136 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4059075782696406, 'Total loss': 0.4059075782696406} | train loss {'Reaction outcome loss': 0.37134121363774103, 'Total loss': 0.37134121363774103}
2023-01-04 07:08:26,136 INFO:     Found new best model at epoch 34
2023-01-04 07:08:26,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:26,137 INFO:     Epoch: 35
2023-01-04 07:08:27,636 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4341367761294047, 'Total loss': 0.4341367761294047} | train loss {'Reaction outcome loss': 0.3679313827776737, 'Total loss': 0.3679313827776737}
2023-01-04 07:08:27,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:27,637 INFO:     Epoch: 36
2023-01-04 07:08:29,189 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4420815666516622, 'Total loss': 0.4420815666516622} | train loss {'Reaction outcome loss': 0.36469486322832234, 'Total loss': 0.36469486322832234}
2023-01-04 07:08:29,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:29,189 INFO:     Epoch: 37
2023-01-04 07:08:30,747 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4468754251797994, 'Total loss': 0.4468754251797994} | train loss {'Reaction outcome loss': 0.36139800387438026, 'Total loss': 0.36139800387438026}
2023-01-04 07:08:30,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:30,748 INFO:     Epoch: 38
2023-01-04 07:08:32,298 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41908871233463285, 'Total loss': 0.41908871233463285} | train loss {'Reaction outcome loss': 0.35850506192510306, 'Total loss': 0.35850506192510306}
2023-01-04 07:08:32,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:32,299 INFO:     Epoch: 39
2023-01-04 07:08:33,858 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41695950826009115, 'Total loss': 0.41695950826009115} | train loss {'Reaction outcome loss': 0.3525491145705058, 'Total loss': 0.3525491145705058}
2023-01-04 07:08:33,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:33,858 INFO:     Epoch: 40
2023-01-04 07:08:35,413 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4044063021739324, 'Total loss': 0.4044063021739324} | train loss {'Reaction outcome loss': 0.3566441099673832, 'Total loss': 0.3566441099673832}
2023-01-04 07:08:35,413 INFO:     Found new best model at epoch 40
2023-01-04 07:08:35,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:35,414 INFO:     Epoch: 41
2023-01-04 07:08:36,910 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4451948404312134, 'Total loss': 0.4451948404312134} | train loss {'Reaction outcome loss': 0.3511834937393235, 'Total loss': 0.3511834937393235}
2023-01-04 07:08:36,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:36,910 INFO:     Epoch: 42
2023-01-04 07:08:38,468 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4083372821410497, 'Total loss': 0.4083372821410497} | train loss {'Reaction outcome loss': 0.34625844097955133, 'Total loss': 0.34625844097955133}
2023-01-04 07:08:38,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:38,468 INFO:     Epoch: 43
2023-01-04 07:08:40,028 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4088672647873561, 'Total loss': 0.4088672647873561} | train loss {'Reaction outcome loss': 0.3452104028274006, 'Total loss': 0.3452104028274006}
2023-01-04 07:08:40,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:40,028 INFO:     Epoch: 44
2023-01-04 07:08:41,579 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41144260863463084, 'Total loss': 0.41144260863463084} | train loss {'Reaction outcome loss': 0.34342328126841504, 'Total loss': 0.34342328126841504}
2023-01-04 07:08:41,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:41,579 INFO:     Epoch: 45
2023-01-04 07:08:43,144 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41912718017896017, 'Total loss': 0.41912718017896017} | train loss {'Reaction outcome loss': 0.3407874978567719, 'Total loss': 0.3407874978567719}
2023-01-04 07:08:43,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:43,145 INFO:     Epoch: 46
2023-01-04 07:08:44,704 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4218614081541697, 'Total loss': 0.4218614081541697} | train loss {'Reaction outcome loss': 0.3339101941684523, 'Total loss': 0.3339101941684523}
2023-01-04 07:08:44,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:44,706 INFO:     Epoch: 47
2023-01-04 07:08:46,248 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.415499480565389, 'Total loss': 0.415499480565389} | train loss {'Reaction outcome loss': 0.3351676310765614, 'Total loss': 0.3351676310765614}
2023-01-04 07:08:46,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:46,248 INFO:     Epoch: 48
2023-01-04 07:08:47,830 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4200644850730896, 'Total loss': 0.4200644850730896} | train loss {'Reaction outcome loss': 0.333709911480277, 'Total loss': 0.333709911480277}
2023-01-04 07:08:47,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:47,831 INFO:     Epoch: 49
2023-01-04 07:08:49,387 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3887965202331543, 'Total loss': 0.3887965202331543} | train loss {'Reaction outcome loss': 0.33165666089806745, 'Total loss': 0.33165666089806745}
2023-01-04 07:08:49,387 INFO:     Found new best model at epoch 49
2023-01-04 07:08:49,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:49,388 INFO:     Epoch: 50
2023-01-04 07:08:50,937 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4015747586886088, 'Total loss': 0.4015747586886088} | train loss {'Reaction outcome loss': 0.3268536055319361, 'Total loss': 0.3268536055319361}
2023-01-04 07:08:50,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:50,938 INFO:     Epoch: 51
2023-01-04 07:08:52,488 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4023935308059057, 'Total loss': 0.4023935308059057} | train loss {'Reaction outcome loss': 0.3269628435373306, 'Total loss': 0.3269628435373306}
2023-01-04 07:08:52,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:52,488 INFO:     Epoch: 52
2023-01-04 07:08:54,006 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39833659728368126, 'Total loss': 0.39833659728368126} | train loss {'Reaction outcome loss': 0.32408932634101445, 'Total loss': 0.32408932634101445}
2023-01-04 07:08:54,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:54,006 INFO:     Epoch: 53
2023-01-04 07:08:55,528 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41481706003348034, 'Total loss': 0.41481706003348034} | train loss {'Reaction outcome loss': 0.3266158213549788, 'Total loss': 0.3266158213549788}
2023-01-04 07:08:55,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:55,528 INFO:     Epoch: 54
2023-01-04 07:08:57,080 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4025322695573171, 'Total loss': 0.4025322695573171} | train loss {'Reaction outcome loss': 0.32257141444549664, 'Total loss': 0.32257141444549664}
2023-01-04 07:08:57,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:57,080 INFO:     Epoch: 55
2023-01-04 07:08:58,648 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42150454918543495, 'Total loss': 0.42150454918543495} | train loss {'Reaction outcome loss': 0.318952561446906, 'Total loss': 0.318952561446906}
2023-01-04 07:08:58,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:08:58,648 INFO:     Epoch: 56
2023-01-04 07:09:00,230 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42306081056594846, 'Total loss': 0.42306081056594846} | train loss {'Reaction outcome loss': 0.315874969970018, 'Total loss': 0.315874969970018}
2023-01-04 07:09:00,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:00,231 INFO:     Epoch: 57
2023-01-04 07:09:01,795 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40593520601590477, 'Total loss': 0.40593520601590477} | train loss {'Reaction outcome loss': 0.3166880046525156, 'Total loss': 0.3166880046525156}
2023-01-04 07:09:01,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:01,796 INFO:     Epoch: 58
2023-01-04 07:09:03,332 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4316518485546112, 'Total loss': 0.4316518485546112} | train loss {'Reaction outcome loss': 0.3091385986400425, 'Total loss': 0.3091385986400425}
2023-01-04 07:09:03,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:03,333 INFO:     Epoch: 59
2023-01-04 07:09:04,860 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3995459645986557, 'Total loss': 0.3995459645986557} | train loss {'Reaction outcome loss': 0.31788736355864183, 'Total loss': 0.31788736355864183}
2023-01-04 07:09:04,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:04,861 INFO:     Epoch: 60
2023-01-04 07:09:06,412 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3992191910743713, 'Total loss': 0.3992191910743713} | train loss {'Reaction outcome loss': 0.309413410965286, 'Total loss': 0.309413410965286}
2023-01-04 07:09:06,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:06,412 INFO:     Epoch: 61
2023-01-04 07:09:07,972 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40353817542394005, 'Total loss': 0.40353817542394005} | train loss {'Reaction outcome loss': 0.30992829509160147, 'Total loss': 0.30992829509160147}
2023-01-04 07:09:07,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:07,972 INFO:     Epoch: 62
2023-01-04 07:09:09,529 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39718110164006554, 'Total loss': 0.39718110164006554} | train loss {'Reaction outcome loss': 0.3056872154078329, 'Total loss': 0.3056872154078329}
2023-01-04 07:09:09,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:09,529 INFO:     Epoch: 63
2023-01-04 07:09:11,092 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38958247800668083, 'Total loss': 0.38958247800668083} | train loss {'Reaction outcome loss': 0.3081507849295217, 'Total loss': 0.3081507849295217}
2023-01-04 07:09:11,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:11,092 INFO:     Epoch: 64
2023-01-04 07:09:12,638 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3991013079881668, 'Total loss': 0.3991013079881668} | train loss {'Reaction outcome loss': 0.3030754396900373, 'Total loss': 0.3030754396900373}
2023-01-04 07:09:12,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:12,638 INFO:     Epoch: 65
2023-01-04 07:09:14,189 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4215178151925405, 'Total loss': 0.4215178151925405} | train loss {'Reaction outcome loss': 0.30057936737360935, 'Total loss': 0.30057936737360935}
2023-01-04 07:09:14,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:14,189 INFO:     Epoch: 66
2023-01-04 07:09:15,778 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4916020562251409, 'Total loss': 0.4916020562251409} | train loss {'Reaction outcome loss': 0.3050163507945701, 'Total loss': 0.3050163507945701}
2023-01-04 07:09:15,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:15,780 INFO:     Epoch: 67
2023-01-04 07:09:17,354 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4269801676273346, 'Total loss': 0.4269801676273346} | train loss {'Reaction outcome loss': 0.3001965043884752, 'Total loss': 0.3001965043884752}
2023-01-04 07:09:17,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:17,354 INFO:     Epoch: 68
2023-01-04 07:09:18,919 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40836263497670494, 'Total loss': 0.40836263497670494} | train loss {'Reaction outcome loss': 0.2949569135473954, 'Total loss': 0.2949569135473954}
2023-01-04 07:09:18,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:18,919 INFO:     Epoch: 69
2023-01-04 07:09:20,486 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3986553341150284, 'Total loss': 0.3986553341150284} | train loss {'Reaction outcome loss': 0.29608276637022246, 'Total loss': 0.29608276637022246}
2023-01-04 07:09:20,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:20,486 INFO:     Epoch: 70
2023-01-04 07:09:22,021 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4276681880156199, 'Total loss': 0.4276681880156199} | train loss {'Reaction outcome loss': 0.2950584597966301, 'Total loss': 0.2950584597966301}
2023-01-04 07:09:22,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:22,023 INFO:     Epoch: 71
2023-01-04 07:09:23,554 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38310390909512837, 'Total loss': 0.38310390909512837} | train loss {'Reaction outcome loss': 0.2983536889460543, 'Total loss': 0.2983536889460543}
2023-01-04 07:09:23,554 INFO:     Found new best model at epoch 71
2023-01-04 07:09:23,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:23,555 INFO:     Epoch: 72
2023-01-04 07:09:25,129 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41590298811594645, 'Total loss': 0.41590298811594645} | train loss {'Reaction outcome loss': 0.2967804177304468, 'Total loss': 0.2967804177304468}
2023-01-04 07:09:25,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:25,129 INFO:     Epoch: 73
2023-01-04 07:09:26,708 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4153137435515722, 'Total loss': 0.4153137435515722} | train loss {'Reaction outcome loss': 0.29270384807664135, 'Total loss': 0.29270384807664135}
2023-01-04 07:09:26,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:26,708 INFO:     Epoch: 74
2023-01-04 07:09:28,271 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42175445556640623, 'Total loss': 0.42175445556640623} | train loss {'Reaction outcome loss': 0.28864055331325705, 'Total loss': 0.28864055331325705}
2023-01-04 07:09:28,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:28,271 INFO:     Epoch: 75
2023-01-04 07:09:29,838 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41189287503560384, 'Total loss': 0.41189287503560384} | train loss {'Reaction outcome loss': 0.28904280093387574, 'Total loss': 0.28904280093387574}
2023-01-04 07:09:29,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:29,839 INFO:     Epoch: 76
2023-01-04 07:09:31,337 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4330794890721639, 'Total loss': 0.4330794890721639} | train loss {'Reaction outcome loss': 0.2843214488363008, 'Total loss': 0.2843214488363008}
2023-01-04 07:09:31,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:31,337 INFO:     Epoch: 77
2023-01-04 07:09:32,903 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4073538362979889, 'Total loss': 0.4073538362979889} | train loss {'Reaction outcome loss': 0.2911947507021229, 'Total loss': 0.2911947507021229}
2023-01-04 07:09:32,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:32,903 INFO:     Epoch: 78
2023-01-04 07:09:34,460 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4032230079174042, 'Total loss': 0.4032230079174042} | train loss {'Reaction outcome loss': 0.2863372479857951, 'Total loss': 0.2863372479857951}
2023-01-04 07:09:34,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:34,461 INFO:     Epoch: 79
2023-01-04 07:09:36,026 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40101290146509805, 'Total loss': 0.40101290146509805} | train loss {'Reaction outcome loss': 0.2821471305893539, 'Total loss': 0.2821471305893539}
2023-01-04 07:09:36,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:36,027 INFO:     Epoch: 80
2023-01-04 07:09:37,591 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4020655115445455, 'Total loss': 0.4020655115445455} | train loss {'Reaction outcome loss': 0.2799876521102788, 'Total loss': 0.2799876521102788}
2023-01-04 07:09:37,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:37,592 INFO:     Epoch: 81
2023-01-04 07:09:39,170 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4058876285950343, 'Total loss': 0.4058876285950343} | train loss {'Reaction outcome loss': 0.28502720365778206, 'Total loss': 0.28502720365778206}
2023-01-04 07:09:39,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:39,170 INFO:     Epoch: 82
2023-01-04 07:09:40,668 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4259584868947665, 'Total loss': 0.4259584868947665} | train loss {'Reaction outcome loss': 0.2828858045168517, 'Total loss': 0.2828858045168517}
2023-01-04 07:09:40,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:40,669 INFO:     Epoch: 83
2023-01-04 07:09:42,245 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3915950387716293, 'Total loss': 0.3915950387716293} | train loss {'Reaction outcome loss': 0.27998677689568663, 'Total loss': 0.27998677689568663}
2023-01-04 07:09:42,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:42,246 INFO:     Epoch: 84
2023-01-04 07:09:43,816 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3923906813065211, 'Total loss': 0.3923906813065211} | train loss {'Reaction outcome loss': 0.28089584606541623, 'Total loss': 0.28089584606541623}
2023-01-04 07:09:43,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:43,816 INFO:     Epoch: 85
2023-01-04 07:09:45,372 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39065488874912263, 'Total loss': 0.39065488874912263} | train loss {'Reaction outcome loss': 0.27423452327720527, 'Total loss': 0.27423452327720527}
2023-01-04 07:09:45,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:45,372 INFO:     Epoch: 86
2023-01-04 07:09:46,929 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38248084088166556, 'Total loss': 0.38248084088166556} | train loss {'Reaction outcome loss': 0.2775937693482702, 'Total loss': 0.2775937693482702}
2023-01-04 07:09:46,930 INFO:     Found new best model at epoch 86
2023-01-04 07:09:46,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:46,930 INFO:     Epoch: 87
2023-01-04 07:09:48,445 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41886003414789835, 'Total loss': 0.41886003414789835} | train loss {'Reaction outcome loss': 0.27628196958815576, 'Total loss': 0.27628196958815576}
2023-01-04 07:09:48,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:48,445 INFO:     Epoch: 88
2023-01-04 07:09:49,973 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3936135898033778, 'Total loss': 0.3936135898033778} | train loss {'Reaction outcome loss': 0.2694275018486736, 'Total loss': 0.2694275018486736}
2023-01-04 07:09:49,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:49,973 INFO:     Epoch: 89
2023-01-04 07:09:51,548 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4503845363855362, 'Total loss': 0.4503845363855362} | train loss {'Reaction outcome loss': 0.27361025741922296, 'Total loss': 0.27361025741922296}
2023-01-04 07:09:51,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:51,550 INFO:     Epoch: 90
2023-01-04 07:09:53,102 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4264391988515854, 'Total loss': 0.4264391988515854} | train loss {'Reaction outcome loss': 0.2734087201554853, 'Total loss': 0.2734087201554853}
2023-01-04 07:09:53,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:53,103 INFO:     Epoch: 91
2023-01-04 07:09:54,645 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38452577690283457, 'Total loss': 0.38452577690283457} | train loss {'Reaction outcome loss': 0.2707420328517683, 'Total loss': 0.2707420328517683}
2023-01-04 07:09:54,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:54,645 INFO:     Epoch: 92
2023-01-04 07:09:56,197 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41935137907663983, 'Total loss': 0.41935137907663983} | train loss {'Reaction outcome loss': 0.27641483412430173, 'Total loss': 0.27641483412430173}
2023-01-04 07:09:56,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:56,197 INFO:     Epoch: 93
2023-01-04 07:09:57,722 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3897413372993469, 'Total loss': 0.3897413372993469} | train loss {'Reaction outcome loss': 0.2620346271550612, 'Total loss': 0.2620346271550612}
2023-01-04 07:09:57,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:57,723 INFO:     Epoch: 94
2023-01-04 07:09:59,252 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.400849253932635, 'Total loss': 0.400849253932635} | train loss {'Reaction outcome loss': 0.2716035132938559, 'Total loss': 0.2716035132938559}
2023-01-04 07:09:59,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:09:59,252 INFO:     Epoch: 95
2023-01-04 07:10:00,801 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39022150735060374, 'Total loss': 0.39022150735060374} | train loss {'Reaction outcome loss': 0.2680360188284075, 'Total loss': 0.2680360188284075}
2023-01-04 07:10:00,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:00,801 INFO:     Epoch: 96
2023-01-04 07:10:02,354 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39905442396799723, 'Total loss': 0.39905442396799723} | train loss {'Reaction outcome loss': 0.2637915855764482, 'Total loss': 0.2637915855764482}
2023-01-04 07:10:02,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:02,355 INFO:     Epoch: 97
2023-01-04 07:10:03,902 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3974234034617742, 'Total loss': 0.3974234034617742} | train loss {'Reaction outcome loss': 0.2646733892254451, 'Total loss': 0.2646733892254451}
2023-01-04 07:10:03,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:03,903 INFO:     Epoch: 98
2023-01-04 07:10:05,462 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3898212422927221, 'Total loss': 0.3898212422927221} | train loss {'Reaction outcome loss': 0.2636349271001153, 'Total loss': 0.2636349271001153}
2023-01-04 07:10:05,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:05,463 INFO:     Epoch: 99
2023-01-04 07:10:06,998 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.382251567641894, 'Total loss': 0.382251567641894} | train loss {'Reaction outcome loss': 0.26888931913819125, 'Total loss': 0.26888931913819125}
2023-01-04 07:10:06,998 INFO:     Found new best model at epoch 99
2023-01-04 07:10:06,999 INFO:     Best model found after epoch 100 of 100.
2023-01-04 07:10:06,999 INFO:   Done with stage: TRAINING
2023-01-04 07:10:06,999 INFO:   Starting stage: EVALUATION
2023-01-04 07:10:07,119 INFO:   Done with stage: EVALUATION
2023-01-04 07:10:07,119 INFO:   Leaving out SEQ value Fold_6
2023-01-04 07:10:07,132 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:10:07,132 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:10:07,778 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:10:07,778 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:10:07,846 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:10:07,846 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:10:07,847 INFO:     No hyperparam tuning for this model
2023-01-04 07:10:07,847 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:10:07,847 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:10:07,847 INFO:     None feature selector for col prot
2023-01-04 07:10:07,847 INFO:     None feature selector for col prot
2023-01-04 07:10:07,848 INFO:     None feature selector for col prot
2023-01-04 07:10:07,848 INFO:     None feature selector for col chem
2023-01-04 07:10:07,848 INFO:     None feature selector for col chem
2023-01-04 07:10:07,848 INFO:     None feature selector for col chem
2023-01-04 07:10:07,848 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:10:07,848 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:10:07,849 INFO:     Number of params in model 70111
2023-01-04 07:10:07,852 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:10:07,852 INFO:   Starting stage: TRAINING
2023-01-04 07:10:07,897 INFO:     Val loss before train {'Reaction outcome loss': 0.9838276108105978, 'Total loss': 0.9838276108105978}
2023-01-04 07:10:07,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:07,898 INFO:     Epoch: 0
2023-01-04 07:10:09,447 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7033250351746877, 'Total loss': 0.7033250351746877} | train loss {'Reaction outcome loss': 0.8510483696624853, 'Total loss': 0.8510483696624853}
2023-01-04 07:10:09,447 INFO:     Found new best model at epoch 0
2023-01-04 07:10:09,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:09,448 INFO:     Epoch: 1
2023-01-04 07:10:10,992 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6072374681631724, 'Total loss': 0.6072374681631724} | train loss {'Reaction outcome loss': 0.7011347794230434, 'Total loss': 0.7011347794230434}
2023-01-04 07:10:10,992 INFO:     Found new best model at epoch 1
2023-01-04 07:10:10,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:10,993 INFO:     Epoch: 2
2023-01-04 07:10:12,555 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5569111665089925, 'Total loss': 0.5569111665089925} | train loss {'Reaction outcome loss': 0.6196269451959423, 'Total loss': 0.6196269451959423}
2023-01-04 07:10:12,555 INFO:     Found new best model at epoch 2
2023-01-04 07:10:12,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:12,556 INFO:     Epoch: 3
2023-01-04 07:10:14,110 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5265505055586497, 'Total loss': 0.5265505055586497} | train loss {'Reaction outcome loss': 0.5779425231874853, 'Total loss': 0.5779425231874853}
2023-01-04 07:10:14,110 INFO:     Found new best model at epoch 3
2023-01-04 07:10:14,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:14,110 INFO:     Epoch: 4
2023-01-04 07:10:15,632 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5016224215428035, 'Total loss': 0.5016224215428035} | train loss {'Reaction outcome loss': 0.5571321768726668, 'Total loss': 0.5571321768726668}
2023-01-04 07:10:15,632 INFO:     Found new best model at epoch 4
2023-01-04 07:10:15,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:15,633 INFO:     Epoch: 5
2023-01-04 07:10:17,176 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5099917630354563, 'Total loss': 0.5099917630354563} | train loss {'Reaction outcome loss': 0.5305160037174389, 'Total loss': 0.5305160037174389}
2023-01-04 07:10:17,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:17,176 INFO:     Epoch: 6
2023-01-04 07:10:18,732 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5049148499965668, 'Total loss': 0.5049148499965668} | train loss {'Reaction outcome loss': 0.5141526665960344, 'Total loss': 0.5141526665960344}
2023-01-04 07:10:18,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:18,732 INFO:     Epoch: 7
2023-01-04 07:10:20,284 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4956537067890167, 'Total loss': 0.4956537067890167} | train loss {'Reaction outcome loss': 0.5255681049024713, 'Total loss': 0.5255681049024713}
2023-01-04 07:10:20,284 INFO:     Found new best model at epoch 7
2023-01-04 07:10:20,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:20,285 INFO:     Epoch: 8
2023-01-04 07:10:21,832 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5064500113328297, 'Total loss': 0.5064500113328297} | train loss {'Reaction outcome loss': 0.5113164502452465, 'Total loss': 0.5113164502452465}
2023-01-04 07:10:21,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:21,832 INFO:     Epoch: 9
2023-01-04 07:10:23,381 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4817286749680837, 'Total loss': 0.4817286749680837} | train loss {'Reaction outcome loss': 0.48911476947967825, 'Total loss': 0.48911476947967825}
2023-01-04 07:10:23,381 INFO:     Found new best model at epoch 9
2023-01-04 07:10:23,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:23,382 INFO:     Epoch: 10
2023-01-04 07:10:24,906 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4885693927605947, 'Total loss': 0.4885693927605947} | train loss {'Reaction outcome loss': 0.47984042451919423, 'Total loss': 0.47984042451919423}
2023-01-04 07:10:24,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:24,906 INFO:     Epoch: 11
2023-01-04 07:10:26,443 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5123689313729604, 'Total loss': 0.5123689313729604} | train loss {'Reaction outcome loss': 0.4739944294730473, 'Total loss': 0.4739944294730473}
2023-01-04 07:10:26,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:26,444 INFO:     Epoch: 12
2023-01-04 07:10:27,994 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5138950030008952, 'Total loss': 0.5138950030008952} | train loss {'Reaction outcome loss': 0.4673311508031211, 'Total loss': 0.4673311508031211}
2023-01-04 07:10:27,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:27,995 INFO:     Epoch: 13
2023-01-04 07:10:29,547 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4746079425017039, 'Total loss': 0.4746079425017039} | train loss {'Reaction outcome loss': 0.4612719613680805, 'Total loss': 0.4612719613680805}
2023-01-04 07:10:29,548 INFO:     Found new best model at epoch 13
2023-01-04 07:10:29,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:29,548 INFO:     Epoch: 14
2023-01-04 07:10:31,100 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47281087438265484, 'Total loss': 0.47281087438265484} | train loss {'Reaction outcome loss': 0.46791030488152435, 'Total loss': 0.46791030488152435}
2023-01-04 07:10:31,100 INFO:     Found new best model at epoch 14
2023-01-04 07:10:31,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:31,101 INFO:     Epoch: 15
2023-01-04 07:10:32,661 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5108748237291972, 'Total loss': 0.5108748237291972} | train loss {'Reaction outcome loss': 0.4820359317126913, 'Total loss': 0.4820359317126913}
2023-01-04 07:10:32,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:32,662 INFO:     Epoch: 16
2023-01-04 07:10:34,193 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4762076199054718, 'Total loss': 0.4762076199054718} | train loss {'Reaction outcome loss': 0.46982862036405265, 'Total loss': 0.46982862036405265}
2023-01-04 07:10:34,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:34,194 INFO:     Epoch: 17
2023-01-04 07:10:35,731 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47816435297330223, 'Total loss': 0.47816435297330223} | train loss {'Reaction outcome loss': 0.44670158249420533, 'Total loss': 0.44670158249420533}
2023-01-04 07:10:35,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:35,731 INFO:     Epoch: 18
2023-01-04 07:10:37,276 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44728735983371737, 'Total loss': 0.44728735983371737} | train loss {'Reaction outcome loss': 0.4396804561872251, 'Total loss': 0.4396804561872251}
2023-01-04 07:10:37,277 INFO:     Found new best model at epoch 18
2023-01-04 07:10:37,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:37,277 INFO:     Epoch: 19
2023-01-04 07:10:38,826 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45902976592381795, 'Total loss': 0.45902976592381795} | train loss {'Reaction outcome loss': 0.4334424387553699, 'Total loss': 0.4334424387553699}
2023-01-04 07:10:38,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:38,826 INFO:     Epoch: 20
2023-01-04 07:10:40,390 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4489258845647176, 'Total loss': 0.4489258845647176} | train loss {'Reaction outcome loss': 0.4255253977114436, 'Total loss': 0.4255253977114436}
2023-01-04 07:10:40,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:40,390 INFO:     Epoch: 21
2023-01-04 07:10:41,968 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46680522163709004, 'Total loss': 0.46680522163709004} | train loss {'Reaction outcome loss': 0.4198736755378364, 'Total loss': 0.4198736755378364}
2023-01-04 07:10:41,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:41,968 INFO:     Epoch: 22
2023-01-04 07:10:43,490 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4488596796989441, 'Total loss': 0.4488596796989441} | train loss {'Reaction outcome loss': 0.42207799295462883, 'Total loss': 0.42207799295462883}
2023-01-04 07:10:43,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:43,490 INFO:     Epoch: 23
2023-01-04 07:10:45,016 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44014359414577486, 'Total loss': 0.44014359414577486} | train loss {'Reaction outcome loss': 0.41535425439908885, 'Total loss': 0.41535425439908885}
2023-01-04 07:10:45,017 INFO:     Found new best model at epoch 23
2023-01-04 07:10:45,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:45,017 INFO:     Epoch: 24
2023-01-04 07:10:46,563 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4516657491525014, 'Total loss': 0.4516657491525014} | train loss {'Reaction outcome loss': 0.41652756411096326, 'Total loss': 0.41652756411096326}
2023-01-04 07:10:46,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:46,563 INFO:     Epoch: 25
2023-01-04 07:10:48,129 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4346042588353157, 'Total loss': 0.4346042588353157} | train loss {'Reaction outcome loss': 0.4195700145556011, 'Total loss': 0.4195700145556011}
2023-01-04 07:10:48,130 INFO:     Found new best model at epoch 25
2023-01-04 07:10:48,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:48,130 INFO:     Epoch: 26
2023-01-04 07:10:49,708 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43923646410306294, 'Total loss': 0.43923646410306294} | train loss {'Reaction outcome loss': 0.4098034704616968, 'Total loss': 0.4098034704616968}
2023-01-04 07:10:49,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:49,708 INFO:     Epoch: 27
2023-01-04 07:10:51,268 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45180286169052125, 'Total loss': 0.45180286169052125} | train loss {'Reaction outcome loss': 0.4049162041071964, 'Total loss': 0.4049162041071964}
2023-01-04 07:10:51,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:51,269 INFO:     Epoch: 28
2023-01-04 07:10:52,726 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47253041962782544, 'Total loss': 0.47253041962782544} | train loss {'Reaction outcome loss': 0.4045138769931551, 'Total loss': 0.4045138769931551}
2023-01-04 07:10:52,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:52,726 INFO:     Epoch: 29
2023-01-04 07:10:53,753 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45635410249233244, 'Total loss': 0.45635410249233244} | train loss {'Reaction outcome loss': 0.4101205276784258, 'Total loss': 0.4101205276784258}
2023-01-04 07:10:53,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:53,753 INFO:     Epoch: 30
2023-01-04 07:10:54,773 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43810805479685466, 'Total loss': 0.43810805479685466} | train loss {'Reaction outcome loss': 0.39440416161348857, 'Total loss': 0.39440416161348857}
2023-01-04 07:10:54,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:54,774 INFO:     Epoch: 31
2023-01-04 07:10:55,794 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4419379711151123, 'Total loss': 0.4419379711151123} | train loss {'Reaction outcome loss': 0.40918062233190605, 'Total loss': 0.40918062233190605}
2023-01-04 07:10:55,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:55,795 INFO:     Epoch: 32
2023-01-04 07:10:56,834 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4346548855304718, 'Total loss': 0.4346548855304718} | train loss {'Reaction outcome loss': 0.42070387305094575, 'Total loss': 0.42070387305094575}
2023-01-04 07:10:56,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:56,834 INFO:     Epoch: 33
2023-01-04 07:10:58,341 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42013405362764994, 'Total loss': 0.42013405362764994} | train loss {'Reaction outcome loss': 0.388041782449337, 'Total loss': 0.388041782449337}
2023-01-04 07:10:58,342 INFO:     Found new best model at epoch 33
2023-01-04 07:10:58,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:58,343 INFO:     Epoch: 34
2023-01-04 07:10:59,886 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46015624006589256, 'Total loss': 0.46015624006589256} | train loss {'Reaction outcome loss': 0.3853647969663143, 'Total loss': 0.3853647969663143}
2023-01-04 07:10:59,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:10:59,886 INFO:     Epoch: 35
2023-01-04 07:11:01,423 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4279108832279841, 'Total loss': 0.4279108832279841} | train loss {'Reaction outcome loss': 0.3816033317621011, 'Total loss': 0.3816033317621011}
2023-01-04 07:11:01,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:01,423 INFO:     Epoch: 36
2023-01-04 07:11:02,983 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4320412496725718, 'Total loss': 0.4320412496725718} | train loss {'Reaction outcome loss': 0.37353281373140385, 'Total loss': 0.37353281373140385}
2023-01-04 07:11:02,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:02,983 INFO:     Epoch: 37
2023-01-04 07:11:04,533 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42210848728815714, 'Total loss': 0.42210848728815714} | train loss {'Reaction outcome loss': 0.36945417090116633, 'Total loss': 0.36945417090116633}
2023-01-04 07:11:04,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:04,534 INFO:     Epoch: 38
2023-01-04 07:11:06,060 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.436659703652064, 'Total loss': 0.436659703652064} | train loss {'Reaction outcome loss': 0.36563648935913556, 'Total loss': 0.36563648935913556}
2023-01-04 07:11:06,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:06,060 INFO:     Epoch: 39
2023-01-04 07:11:07,589 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4571864048639933, 'Total loss': 0.4571864048639933} | train loss {'Reaction outcome loss': 0.36651139641585556, 'Total loss': 0.36651139641585556}
2023-01-04 07:11:07,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:07,590 INFO:     Epoch: 40
2023-01-04 07:11:09,169 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4207968552907308, 'Total loss': 0.4207968552907308} | train loss {'Reaction outcome loss': 0.36699767216371093, 'Total loss': 0.36699767216371093}
2023-01-04 07:11:09,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:09,169 INFO:     Epoch: 41
2023-01-04 07:11:10,727 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42549031575520835, 'Total loss': 0.42549031575520835} | train loss {'Reaction outcome loss': 0.3575455907806484, 'Total loss': 0.3575455907806484}
2023-01-04 07:11:10,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:10,728 INFO:     Epoch: 42
2023-01-04 07:11:12,280 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4108882894118627, 'Total loss': 0.4108882894118627} | train loss {'Reaction outcome loss': 0.3566372727323998, 'Total loss': 0.3566372727323998}
2023-01-04 07:11:12,280 INFO:     Found new best model at epoch 42
2023-01-04 07:11:12,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:12,281 INFO:     Epoch: 43
2023-01-04 07:11:13,829 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4092026154200236, 'Total loss': 0.4092026154200236} | train loss {'Reaction outcome loss': 0.3489083732255613, 'Total loss': 0.3489083732255613}
2023-01-04 07:11:13,829 INFO:     Found new best model at epoch 43
2023-01-04 07:11:13,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:13,830 INFO:     Epoch: 44
2023-01-04 07:11:15,362 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4405294279257456, 'Total loss': 0.4405294279257456} | train loss {'Reaction outcome loss': 0.3457317521552677, 'Total loss': 0.3457317521552677}
2023-01-04 07:11:15,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:15,363 INFO:     Epoch: 45
2023-01-04 07:11:16,889 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4015291839838028, 'Total loss': 0.4015291839838028} | train loss {'Reaction outcome loss': 0.3516069048934657, 'Total loss': 0.3516069048934657}
2023-01-04 07:11:16,890 INFO:     Found new best model at epoch 45
2023-01-04 07:11:16,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:16,891 INFO:     Epoch: 46
2023-01-04 07:11:18,458 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44356353183587394, 'Total loss': 0.44356353183587394} | train loss {'Reaction outcome loss': 0.3546355248199425, 'Total loss': 0.3546355248199425}
2023-01-04 07:11:18,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:18,458 INFO:     Epoch: 47
2023-01-04 07:11:20,008 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42849165995915733, 'Total loss': 0.42849165995915733} | train loss {'Reaction outcome loss': 0.36879457962577755, 'Total loss': 0.36879457962577755}
2023-01-04 07:11:20,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:20,008 INFO:     Epoch: 48
2023-01-04 07:11:21,553 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4107030898332596, 'Total loss': 0.4107030898332596} | train loss {'Reaction outcome loss': 0.34617110219667246, 'Total loss': 0.34617110219667246}
2023-01-04 07:11:21,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:21,553 INFO:     Epoch: 49
2023-01-04 07:11:23,091 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44916235307852426, 'Total loss': 0.44916235307852426} | train loss {'Reaction outcome loss': 0.33754727206584334, 'Total loss': 0.33754727206584334}
2023-01-04 07:11:23,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:23,091 INFO:     Epoch: 50
2023-01-04 07:11:24,596 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42719823817412056, 'Total loss': 0.42719823817412056} | train loss {'Reaction outcome loss': 0.34698712313210295, 'Total loss': 0.34698712313210295}
2023-01-04 07:11:24,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:24,596 INFO:     Epoch: 51
2023-01-04 07:11:26,108 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40211092631022133, 'Total loss': 0.40211092631022133} | train loss {'Reaction outcome loss': 0.3282090565999565, 'Total loss': 0.3282090565999565}
2023-01-04 07:11:26,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:26,108 INFO:     Epoch: 52
2023-01-04 07:11:27,660 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41019028425216675, 'Total loss': 0.41019028425216675} | train loss {'Reaction outcome loss': 0.321051223271027, 'Total loss': 0.321051223271027}
2023-01-04 07:11:27,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:27,660 INFO:     Epoch: 53
2023-01-04 07:11:29,201 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4108658850193024, 'Total loss': 0.4108658850193024} | train loss {'Reaction outcome loss': 0.3283144936397456, 'Total loss': 0.3283144936397456}
2023-01-04 07:11:29,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:29,201 INFO:     Epoch: 54
2023-01-04 07:11:30,736 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45475483536720274, 'Total loss': 0.45475483536720274} | train loss {'Reaction outcome loss': 0.3388572845091719, 'Total loss': 0.3388572845091719}
2023-01-04 07:11:30,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:30,736 INFO:     Epoch: 55
2023-01-04 07:11:32,285 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40986529489358264, 'Total loss': 0.40986529489358264} | train loss {'Reaction outcome loss': 0.32013962537630636, 'Total loss': 0.32013962537630636}
2023-01-04 07:11:32,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:32,285 INFO:     Epoch: 56
2023-01-04 07:11:33,818 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3945288320382436, 'Total loss': 0.3945288320382436} | train loss {'Reaction outcome loss': 0.3188839448646278, 'Total loss': 0.3188839448646278}
2023-01-04 07:11:33,819 INFO:     Found new best model at epoch 56
2023-01-04 07:11:33,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:33,820 INFO:     Epoch: 57
2023-01-04 07:11:35,336 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.412426499525706, 'Total loss': 0.412426499525706} | train loss {'Reaction outcome loss': 0.3149206552323818, 'Total loss': 0.3149206552323818}
2023-01-04 07:11:35,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:35,336 INFO:     Epoch: 58
2023-01-04 07:11:36,902 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42073971827824913, 'Total loss': 0.42073971827824913} | train loss {'Reaction outcome loss': 0.31289398851800215, 'Total loss': 0.31289398851800215}
2023-01-04 07:11:36,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:36,902 INFO:     Epoch: 59
2023-01-04 07:11:38,455 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4325186242659887, 'Total loss': 0.4325186242659887} | train loss {'Reaction outcome loss': 0.30884148644806364, 'Total loss': 0.30884148644806364}
2023-01-04 07:11:38,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:38,455 INFO:     Epoch: 60
2023-01-04 07:11:40,015 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41707000335057576, 'Total loss': 0.41707000335057576} | train loss {'Reaction outcome loss': 0.3077118747366341, 'Total loss': 0.3077118747366341}
2023-01-04 07:11:40,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:40,016 INFO:     Epoch: 61
2023-01-04 07:11:41,592 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4133295367161433, 'Total loss': 0.4133295367161433} | train loss {'Reaction outcome loss': 0.30749440739822126, 'Total loss': 0.30749440739822126}
2023-01-04 07:11:41,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:41,592 INFO:     Epoch: 62
2023-01-04 07:11:43,110 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4212178111076355, 'Total loss': 0.4212178111076355} | train loss {'Reaction outcome loss': 0.3053575685261276, 'Total loss': 0.3053575685261276}
2023-01-04 07:11:43,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:43,111 INFO:     Epoch: 63
2023-01-04 07:11:44,650 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3989220956961314, 'Total loss': 0.3989220956961314} | train loss {'Reaction outcome loss': 0.30385945760138816, 'Total loss': 0.30385945760138816}
2023-01-04 07:11:44,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:44,651 INFO:     Epoch: 64
2023-01-04 07:11:46,211 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4155001481374105, 'Total loss': 0.4155001481374105} | train loss {'Reaction outcome loss': 0.30220185959225765, 'Total loss': 0.30220185959225765}
2023-01-04 07:11:46,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:46,211 INFO:     Epoch: 65
2023-01-04 07:11:47,722 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4384246567885081, 'Total loss': 0.4384246567885081} | train loss {'Reaction outcome loss': 0.2992472975258378, 'Total loss': 0.2992472975258378}
2023-01-04 07:11:47,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:47,723 INFO:     Epoch: 66
2023-01-04 07:11:49,285 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41552181740601857, 'Total loss': 0.41552181740601857} | train loss {'Reaction outcome loss': 0.30895483696130926, 'Total loss': 0.30895483696130926}
2023-01-04 07:11:49,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:49,286 INFO:     Epoch: 67
2023-01-04 07:11:50,857 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4135580142339071, 'Total loss': 0.4135580142339071} | train loss {'Reaction outcome loss': 0.2988941508608506, 'Total loss': 0.2988941508608506}
2023-01-04 07:11:50,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:50,857 INFO:     Epoch: 68
2023-01-04 07:11:52,370 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40625426967938744, 'Total loss': 0.40625426967938744} | train loss {'Reaction outcome loss': 0.29627642870975146, 'Total loss': 0.29627642870975146}
2023-01-04 07:11:52,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:52,371 INFO:     Epoch: 69
2023-01-04 07:11:53,939 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4104335308074951, 'Total loss': 0.4104335308074951} | train loss {'Reaction outcome loss': 0.29726787931893184, 'Total loss': 0.29726787931893184}
2023-01-04 07:11:53,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:53,939 INFO:     Epoch: 70
2023-01-04 07:11:55,530 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45625886718432107, 'Total loss': 0.45625886718432107} | train loss {'Reaction outcome loss': 0.3006050146819241, 'Total loss': 0.3006050146819241}
2023-01-04 07:11:55,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:55,530 INFO:     Epoch: 71
2023-01-04 07:11:57,129 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3985723594824473, 'Total loss': 0.3985723594824473} | train loss {'Reaction outcome loss': 0.3316783335674014, 'Total loss': 0.3316783335674014}
2023-01-04 07:11:57,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:57,129 INFO:     Epoch: 72
2023-01-04 07:11:58,724 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4205782065788905, 'Total loss': 0.4205782065788905} | train loss {'Reaction outcome loss': 0.2936347595119066, 'Total loss': 0.2936347595119066}
2023-01-04 07:11:58,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:11:58,724 INFO:     Epoch: 73
2023-01-04 07:12:00,336 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41334253052870434, 'Total loss': 0.41334253052870434} | train loss {'Reaction outcome loss': 0.2883567431940785, 'Total loss': 0.2883567431940785}
2023-01-04 07:12:00,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:00,336 INFO:     Epoch: 74
2023-01-04 07:12:01,880 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42440141836802164, 'Total loss': 0.42440141836802164} | train loss {'Reaction outcome loss': 0.2887230914950018, 'Total loss': 0.2887230914950018}
2023-01-04 07:12:01,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:01,880 INFO:     Epoch: 75
2023-01-04 07:12:03,425 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4265752017498016, 'Total loss': 0.4265752017498016} | train loss {'Reaction outcome loss': 0.287880019333713, 'Total loss': 0.287880019333713}
2023-01-04 07:12:03,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:03,425 INFO:     Epoch: 76
2023-01-04 07:12:04,988 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4096457491318385, 'Total loss': 0.4096457491318385} | train loss {'Reaction outcome loss': 0.28613852348813007, 'Total loss': 0.28613852348813007}
2023-01-04 07:12:04,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:04,989 INFO:     Epoch: 77
2023-01-04 07:12:06,552 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40958172082901, 'Total loss': 0.40958172082901} | train loss {'Reaction outcome loss': 0.282119590387953, 'Total loss': 0.282119590387953}
2023-01-04 07:12:06,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:06,553 INFO:     Epoch: 78
2023-01-04 07:12:08,110 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4317817986011505, 'Total loss': 0.4317817986011505} | train loss {'Reaction outcome loss': 0.28614591297641245, 'Total loss': 0.28614591297641245}
2023-01-04 07:12:08,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:08,110 INFO:     Epoch: 79
2023-01-04 07:12:09,670 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39932293196519214, 'Total loss': 0.39932293196519214} | train loss {'Reaction outcome loss': 0.28511941485424136, 'Total loss': 0.28511941485424136}
2023-01-04 07:12:09,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:09,672 INFO:     Epoch: 80
2023-01-04 07:12:11,168 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40793040990829466, 'Total loss': 0.40793040990829466} | train loss {'Reaction outcome loss': 0.28645020907603885, 'Total loss': 0.28645020907603885}
2023-01-04 07:12:11,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:11,168 INFO:     Epoch: 81
2023-01-04 07:12:12,704 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41745033164819084, 'Total loss': 0.41745033164819084} | train loss {'Reaction outcome loss': 0.27786670134746994, 'Total loss': 0.27786670134746994}
2023-01-04 07:12:12,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:12,704 INFO:     Epoch: 82
2023-01-04 07:12:14,256 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4124872416257858, 'Total loss': 0.4124872416257858} | train loss {'Reaction outcome loss': 0.27958043910347036, 'Total loss': 0.27958043910347036}
2023-01-04 07:12:14,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:14,256 INFO:     Epoch: 83
2023-01-04 07:12:15,789 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41314226686954497, 'Total loss': 0.41314226686954497} | train loss {'Reaction outcome loss': 0.2753786009280188, 'Total loss': 0.2753786009280188}
2023-01-04 07:12:15,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:15,790 INFO:     Epoch: 84
2023-01-04 07:12:17,337 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43695049385229745, 'Total loss': 0.43695049385229745} | train loss {'Reaction outcome loss': 0.2795768837491725, 'Total loss': 0.2795768837491725}
2023-01-04 07:12:17,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:17,337 INFO:     Epoch: 85
2023-01-04 07:12:18,876 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4074334591627121, 'Total loss': 0.4074334591627121} | train loss {'Reaction outcome loss': 0.2771359661027141, 'Total loss': 0.2771359661027141}
2023-01-04 07:12:18,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:18,876 INFO:     Epoch: 86
2023-01-04 07:12:20,384 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4129319022099177, 'Total loss': 0.4129319022099177} | train loss {'Reaction outcome loss': 0.28935502583508554, 'Total loss': 0.28935502583508554}
2023-01-04 07:12:20,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:20,384 INFO:     Epoch: 87
2023-01-04 07:12:21,925 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40040127038955686, 'Total loss': 0.40040127038955686} | train loss {'Reaction outcome loss': 0.2764508822431747, 'Total loss': 0.2764508822431747}
2023-01-04 07:12:21,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:21,925 INFO:     Epoch: 88
2023-01-04 07:12:23,489 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4132353484630585, 'Total loss': 0.4132353484630585} | train loss {'Reaction outcome loss': 0.2780139859009912, 'Total loss': 0.2780139859009912}
2023-01-04 07:12:23,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:23,489 INFO:     Epoch: 89
2023-01-04 07:12:25,048 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4051326632499695, 'Total loss': 0.4051326632499695} | train loss {'Reaction outcome loss': 0.30147490677410277, 'Total loss': 0.30147490677410277}
2023-01-04 07:12:25,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:25,048 INFO:     Epoch: 90
2023-01-04 07:12:26,590 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41599358022212984, 'Total loss': 0.41599358022212984} | train loss {'Reaction outcome loss': 0.291503456265976, 'Total loss': 0.291503456265976}
2023-01-04 07:12:26,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:26,590 INFO:     Epoch: 91
2023-01-04 07:12:28,166 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4089198648929596, 'Total loss': 0.4089198648929596} | train loss {'Reaction outcome loss': 0.2796071838165187, 'Total loss': 0.2796071838165187}
2023-01-04 07:12:28,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:28,167 INFO:     Epoch: 92
2023-01-04 07:12:29,652 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41387199858824414, 'Total loss': 0.41387199858824414} | train loss {'Reaction outcome loss': 0.27422942845758214, 'Total loss': 0.27422942845758214}
2023-01-04 07:12:29,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:29,652 INFO:     Epoch: 93
2023-01-04 07:12:31,204 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4358213682969411, 'Total loss': 0.4358213682969411} | train loss {'Reaction outcome loss': 0.2715973983741487, 'Total loss': 0.2715973983741487}
2023-01-04 07:12:31,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:31,204 INFO:     Epoch: 94
2023-01-04 07:12:32,776 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40133749147256215, 'Total loss': 0.40133749147256215} | train loss {'Reaction outcome loss': 0.2662111830912814, 'Total loss': 0.2662111830912814}
2023-01-04 07:12:32,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:32,777 INFO:     Epoch: 95
2023-01-04 07:12:34,353 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42594521840413413, 'Total loss': 0.42594521840413413} | train loss {'Reaction outcome loss': 0.27002364974738896, 'Total loss': 0.27002364974738896}
2023-01-04 07:12:34,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:34,353 INFO:     Epoch: 96
2023-01-04 07:12:35,929 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40526364346345267, 'Total loss': 0.40526364346345267} | train loss {'Reaction outcome loss': 0.2816935456829977, 'Total loss': 0.2816935456829977}
2023-01-04 07:12:35,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:35,930 INFO:     Epoch: 97
2023-01-04 07:12:37,474 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4083356817563375, 'Total loss': 0.4083356817563375} | train loss {'Reaction outcome loss': 0.264198713235838, 'Total loss': 0.264198713235838}
2023-01-04 07:12:37,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:37,474 INFO:     Epoch: 98
2023-01-04 07:12:38,983 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4212777813275655, 'Total loss': 0.4212777813275655} | train loss {'Reaction outcome loss': 0.260256524346229, 'Total loss': 0.260256524346229}
2023-01-04 07:12:38,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:38,983 INFO:     Epoch: 99
2023-01-04 07:12:40,540 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4410815795262655, 'Total loss': 0.4410815795262655} | train loss {'Reaction outcome loss': 0.26217034756057506, 'Total loss': 0.26217034756057506}
2023-01-04 07:12:40,540 INFO:     Best model found after epoch 57 of 100.
2023-01-04 07:12:40,541 INFO:   Done with stage: TRAINING
2023-01-04 07:12:40,541 INFO:   Starting stage: EVALUATION
2023-01-04 07:12:40,667 INFO:   Done with stage: EVALUATION
2023-01-04 07:12:40,667 INFO:   Leaving out SEQ value Fold_7
2023-01-04 07:12:40,679 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:12:40,679 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:12:41,319 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:12:41,320 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:12:41,389 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:12:41,389 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:12:41,389 INFO:     No hyperparam tuning for this model
2023-01-04 07:12:41,389 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:12:41,389 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:12:41,390 INFO:     None feature selector for col prot
2023-01-04 07:12:41,390 INFO:     None feature selector for col prot
2023-01-04 07:12:41,390 INFO:     None feature selector for col prot
2023-01-04 07:12:41,391 INFO:     None feature selector for col chem
2023-01-04 07:12:41,391 INFO:     None feature selector for col chem
2023-01-04 07:12:41,391 INFO:     None feature selector for col chem
2023-01-04 07:12:41,391 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:12:41,391 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:12:41,392 INFO:     Number of params in model 70111
2023-01-04 07:12:41,395 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:12:41,395 INFO:   Starting stage: TRAINING
2023-01-04 07:12:41,438 INFO:     Val loss before train {'Reaction outcome loss': 1.0223804434140524, 'Total loss': 1.0223804434140524}
2023-01-04 07:12:41,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:41,439 INFO:     Epoch: 0
2023-01-04 07:12:43,011 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7857912063598633, 'Total loss': 0.7857912063598633} | train loss {'Reaction outcome loss': 0.840009947941787, 'Total loss': 0.840009947941787}
2023-01-04 07:12:43,011 INFO:     Found new best model at epoch 0
2023-01-04 07:12:43,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:43,012 INFO:     Epoch: 1
2023-01-04 07:12:44,556 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6848839024702708, 'Total loss': 0.6848839024702708} | train loss {'Reaction outcome loss': 0.6726396924789078, 'Total loss': 0.6726396924789078}
2023-01-04 07:12:44,557 INFO:     Found new best model at epoch 1
2023-01-04 07:12:44,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:44,558 INFO:     Epoch: 2
2023-01-04 07:12:46,082 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5929499616225561, 'Total loss': 0.5929499616225561} | train loss {'Reaction outcome loss': 0.5815011867038582, 'Total loss': 0.5815011867038582}
2023-01-04 07:12:46,083 INFO:     Found new best model at epoch 2
2023-01-04 07:12:46,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:46,083 INFO:     Epoch: 3
2023-01-04 07:12:47,615 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.576991452773412, 'Total loss': 0.576991452773412} | train loss {'Reaction outcome loss': 0.5419890879218102, 'Total loss': 0.5419890879218102}
2023-01-04 07:12:47,615 INFO:     Found new best model at epoch 3
2023-01-04 07:12:47,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:47,616 INFO:     Epoch: 4
2023-01-04 07:12:49,202 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5716542442639668, 'Total loss': 0.5716542442639668} | train loss {'Reaction outcome loss': 0.5074703866081056, 'Total loss': 0.5074703866081056}
2023-01-04 07:12:49,202 INFO:     Found new best model at epoch 4
2023-01-04 07:12:49,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:49,203 INFO:     Epoch: 5
2023-01-04 07:12:50,788 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5532085835933686, 'Total loss': 0.5532085835933686} | train loss {'Reaction outcome loss': 0.49723503046054934, 'Total loss': 0.49723503046054934}
2023-01-04 07:12:50,789 INFO:     Found new best model at epoch 5
2023-01-04 07:12:50,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:50,790 INFO:     Epoch: 6
2023-01-04 07:12:52,369 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5374653518199921, 'Total loss': 0.5374653518199921} | train loss {'Reaction outcome loss': 0.4828803352471711, 'Total loss': 0.4828803352471711}
2023-01-04 07:12:52,369 INFO:     Found new best model at epoch 6
2023-01-04 07:12:52,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:52,370 INFO:     Epoch: 7
2023-01-04 07:12:53,926 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5252025196949641, 'Total loss': 0.5252025196949641} | train loss {'Reaction outcome loss': 0.4765487335313557, 'Total loss': 0.4765487335313557}
2023-01-04 07:12:53,926 INFO:     Found new best model at epoch 7
2023-01-04 07:12:53,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:53,927 INFO:     Epoch: 8
2023-01-04 07:12:55,447 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5443225105603536, 'Total loss': 0.5443225105603536} | train loss {'Reaction outcome loss': 0.4680447725282199, 'Total loss': 0.4680447725282199}
2023-01-04 07:12:55,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:55,447 INFO:     Epoch: 9
2023-01-04 07:12:56,959 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5439599573612213, 'Total loss': 0.5439599573612213} | train loss {'Reaction outcome loss': 0.4842901011739952, 'Total loss': 0.4842901011739952}
2023-01-04 07:12:56,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:56,959 INFO:     Epoch: 10
2023-01-04 07:12:58,506 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.520489776134491, 'Total loss': 0.520489776134491} | train loss {'Reaction outcome loss': 0.47372084542892984, 'Total loss': 0.47372084542892984}
2023-01-04 07:12:58,506 INFO:     Found new best model at epoch 10
2023-01-04 07:12:58,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:12:58,506 INFO:     Epoch: 11
2023-01-04 07:13:00,068 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5006333132584889, 'Total loss': 0.5006333132584889} | train loss {'Reaction outcome loss': 0.44852023183003714, 'Total loss': 0.44852023183003714}
2023-01-04 07:13:00,069 INFO:     Found new best model at epoch 11
2023-01-04 07:13:00,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:00,069 INFO:     Epoch: 12
2023-01-04 07:13:01,614 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4823915104071299, 'Total loss': 0.4823915104071299} | train loss {'Reaction outcome loss': 0.44287109113149886, 'Total loss': 0.44287109113149886}
2023-01-04 07:13:01,614 INFO:     Found new best model at epoch 12
2023-01-04 07:13:01,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:01,615 INFO:     Epoch: 13
2023-01-04 07:13:03,178 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.505764490365982, 'Total loss': 0.505764490365982} | train loss {'Reaction outcome loss': 0.43384891344138177, 'Total loss': 0.43384891344138177}
2023-01-04 07:13:03,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:03,179 INFO:     Epoch: 14
2023-01-04 07:13:04,705 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48860374887784325, 'Total loss': 0.48860374887784325} | train loss {'Reaction outcome loss': 0.42851630177946115, 'Total loss': 0.42851630177946115}
2023-01-04 07:13:04,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:04,705 INFO:     Epoch: 15
2023-01-04 07:13:06,228 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4919365723927816, 'Total loss': 0.4919365723927816} | train loss {'Reaction outcome loss': 0.4243491125913958, 'Total loss': 0.4243491125913958}
2023-01-04 07:13:06,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:06,228 INFO:     Epoch: 16
2023-01-04 07:13:07,782 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48790136774381004, 'Total loss': 0.48790136774381004} | train loss {'Reaction outcome loss': 0.4225852257855561, 'Total loss': 0.4225852257855561}
2023-01-04 07:13:07,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:07,783 INFO:     Epoch: 17
2023-01-04 07:13:09,327 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46329809427261354, 'Total loss': 0.46329809427261354} | train loss {'Reaction outcome loss': 0.41499313679093536, 'Total loss': 0.41499313679093536}
2023-01-04 07:13:09,327 INFO:     Found new best model at epoch 17
2023-01-04 07:13:09,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:09,328 INFO:     Epoch: 18
2023-01-04 07:13:10,898 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46421673794587454, 'Total loss': 0.46421673794587454} | train loss {'Reaction outcome loss': 0.4102974460815397, 'Total loss': 0.4102974460815397}
2023-01-04 07:13:10,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:10,898 INFO:     Epoch: 19
2023-01-04 07:13:12,462 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4945152044296265, 'Total loss': 0.4945152044296265} | train loss {'Reaction outcome loss': 0.40525677066762, 'Total loss': 0.40525677066762}
2023-01-04 07:13:12,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:12,462 INFO:     Epoch: 20
2023-01-04 07:13:13,993 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49023449222246807, 'Total loss': 0.49023449222246807} | train loss {'Reaction outcome loss': 0.39864284733809746, 'Total loss': 0.39864284733809746}
2023-01-04 07:13:13,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:13,993 INFO:     Epoch: 21
2023-01-04 07:13:15,547 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48154053688049314, 'Total loss': 0.48154053688049314} | train loss {'Reaction outcome loss': 0.3957221068600463, 'Total loss': 0.3957221068600463}
2023-01-04 07:13:15,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:15,547 INFO:     Epoch: 22
2023-01-04 07:13:17,143 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46027133961518607, 'Total loss': 0.46027133961518607} | train loss {'Reaction outcome loss': 0.3906052477106931, 'Total loss': 0.3906052477106931}
2023-01-04 07:13:17,143 INFO:     Found new best model at epoch 22
2023-01-04 07:13:17,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:17,144 INFO:     Epoch: 23
2023-01-04 07:13:18,729 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44830464919408164, 'Total loss': 0.44830464919408164} | train loss {'Reaction outcome loss': 0.38410549804541294, 'Total loss': 0.38410549804541294}
2023-01-04 07:13:18,729 INFO:     Found new best model at epoch 23
2023-01-04 07:13:18,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:18,730 INFO:     Epoch: 24
2023-01-04 07:13:20,292 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45434276858965555, 'Total loss': 0.45434276858965555} | train loss {'Reaction outcome loss': 0.38528727706305793, 'Total loss': 0.38528727706305793}
2023-01-04 07:13:20,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:20,292 INFO:     Epoch: 25
2023-01-04 07:13:21,861 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4676850954691569, 'Total loss': 0.4676850954691569} | train loss {'Reaction outcome loss': 0.3761981327518605, 'Total loss': 0.3761981327518605}
2023-01-04 07:13:21,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:21,863 INFO:     Epoch: 26
2023-01-04 07:13:23,362 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4704586605230967, 'Total loss': 0.4704586605230967} | train loss {'Reaction outcome loss': 0.37618480849525204, 'Total loss': 0.37618480849525204}
2023-01-04 07:13:23,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:23,362 INFO:     Epoch: 27
2023-01-04 07:13:24,927 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4489193360010783, 'Total loss': 0.4489193360010783} | train loss {'Reaction outcome loss': 0.372996317537795, 'Total loss': 0.372996317537795}
2023-01-04 07:13:24,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:24,927 INFO:     Epoch: 28
2023-01-04 07:13:26,500 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4502069532871246, 'Total loss': 0.4502069532871246} | train loss {'Reaction outcome loss': 0.36413563098134205, 'Total loss': 0.36413563098134205}
2023-01-04 07:13:26,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:26,500 INFO:     Epoch: 29
2023-01-04 07:13:28,089 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4652094314495722, 'Total loss': 0.4652094314495722} | train loss {'Reaction outcome loss': 0.364974049203, 'Total loss': 0.364974049203}
2023-01-04 07:13:28,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:28,090 INFO:     Epoch: 30
2023-01-04 07:13:29,676 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48401026129722596, 'Total loss': 0.48401026129722596} | train loss {'Reaction outcome loss': 0.3668970473758552, 'Total loss': 0.3668970473758552}
2023-01-04 07:13:29,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:29,676 INFO:     Epoch: 31
2023-01-04 07:13:31,232 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45280053416887917, 'Total loss': 0.45280053416887917} | train loss {'Reaction outcome loss': 0.3828296734802965, 'Total loss': 0.3828296734802965}
2023-01-04 07:13:31,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:31,232 INFO:     Epoch: 32
2023-01-04 07:13:32,710 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43678195079167687, 'Total loss': 0.43678195079167687} | train loss {'Reaction outcome loss': 0.35523421457038645, 'Total loss': 0.35523421457038645}
2023-01-04 07:13:32,710 INFO:     Found new best model at epoch 32
2023-01-04 07:13:32,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:32,711 INFO:     Epoch: 33
2023-01-04 07:13:34,264 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.436981209119161, 'Total loss': 0.436981209119161} | train loss {'Reaction outcome loss': 0.3524158725488013, 'Total loss': 0.3524158725488013}
2023-01-04 07:13:34,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:34,265 INFO:     Epoch: 34
2023-01-04 07:13:35,833 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.467355606953303, 'Total loss': 0.467355606953303} | train loss {'Reaction outcome loss': 0.3599897506397953, 'Total loss': 0.3599897506397953}
2023-01-04 07:13:35,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:35,834 INFO:     Epoch: 35
2023-01-04 07:13:37,439 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45723611414432525, 'Total loss': 0.45723611414432525} | train loss {'Reaction outcome loss': 0.3479916212297436, 'Total loss': 0.3479916212297436}
2023-01-04 07:13:37,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:37,439 INFO:     Epoch: 36
2023-01-04 07:13:39,070 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42862511475880943, 'Total loss': 0.42862511475880943} | train loss {'Reaction outcome loss': 0.3425692139270182, 'Total loss': 0.3425692139270182}
2023-01-04 07:13:39,070 INFO:     Found new best model at epoch 36
2023-01-04 07:13:39,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:39,071 INFO:     Epoch: 37
2023-01-04 07:13:40,660 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4590867976347605, 'Total loss': 0.4590867976347605} | train loss {'Reaction outcome loss': 0.34836235415676364, 'Total loss': 0.34836235415676364}
2023-01-04 07:13:40,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:40,661 INFO:     Epoch: 38
2023-01-04 07:13:42,230 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43509645064671837, 'Total loss': 0.43509645064671837} | train loss {'Reaction outcome loss': 0.37300411846217274, 'Total loss': 0.37300411846217274}
2023-01-04 07:13:42,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:42,230 INFO:     Epoch: 39
2023-01-04 07:13:43,827 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43117433885733286, 'Total loss': 0.43117433885733286} | train loss {'Reaction outcome loss': 0.33442243212914985, 'Total loss': 0.33442243212914985}
2023-01-04 07:13:43,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:43,827 INFO:     Epoch: 40
2023-01-04 07:13:45,416 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4322522431612015, 'Total loss': 0.4322522431612015} | train loss {'Reaction outcome loss': 0.33149535711044853, 'Total loss': 0.33149535711044853}
2023-01-04 07:13:45,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:45,416 INFO:     Epoch: 41
2023-01-04 07:13:47,001 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4517305682102839, 'Total loss': 0.4517305682102839} | train loss {'Reaction outcome loss': 0.3335025082409814, 'Total loss': 0.3335025082409814}
2023-01-04 07:13:47,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:47,001 INFO:     Epoch: 42
2023-01-04 07:13:48,567 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4518114417791367, 'Total loss': 0.4518114417791367} | train loss {'Reaction outcome loss': 0.33122264439415355, 'Total loss': 0.33122264439415355}
2023-01-04 07:13:48,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:48,568 INFO:     Epoch: 43
2023-01-04 07:13:50,096 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44468455016613007, 'Total loss': 0.44468455016613007} | train loss {'Reaction outcome loss': 0.3256944645891317, 'Total loss': 0.3256944645891317}
2023-01-04 07:13:50,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:50,096 INFO:     Epoch: 44
2023-01-04 07:13:51,665 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4329801768064499, 'Total loss': 0.4329801768064499} | train loss {'Reaction outcome loss': 0.3221401971482471, 'Total loss': 0.3221401971482471}
2023-01-04 07:13:51,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:51,666 INFO:     Epoch: 45
2023-01-04 07:13:53,266 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4367032359043757, 'Total loss': 0.4367032359043757} | train loss {'Reaction outcome loss': 0.3277348532911687, 'Total loss': 0.3277348532911687}
2023-01-04 07:13:53,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:53,266 INFO:     Epoch: 46
2023-01-04 07:13:54,841 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4317668636639913, 'Total loss': 0.4317668636639913} | train loss {'Reaction outcome loss': 0.3200641370949861, 'Total loss': 0.3200641370949861}
2023-01-04 07:13:54,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:54,841 INFO:     Epoch: 47
2023-01-04 07:13:56,393 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43045311272144315, 'Total loss': 0.43045311272144315} | train loss {'Reaction outcome loss': 0.3172338783745848, 'Total loss': 0.3172338783745848}
2023-01-04 07:13:56,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:56,394 INFO:     Epoch: 48
2023-01-04 07:13:57,999 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4270201702912649, 'Total loss': 0.4270201702912649} | train loss {'Reaction outcome loss': 0.31617637845498603, 'Total loss': 0.31617637845498603}
2023-01-04 07:13:58,000 INFO:     Found new best model at epoch 48
2023-01-04 07:13:58,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:58,000 INFO:     Epoch: 49
2023-01-04 07:13:59,566 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45664793650309243, 'Total loss': 0.45664793650309243} | train loss {'Reaction outcome loss': 0.3148156559428848, 'Total loss': 0.3148156559428848}
2023-01-04 07:13:59,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:13:59,566 INFO:     Epoch: 50
2023-01-04 07:14:01,090 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4342508693536123, 'Total loss': 0.4342508693536123} | train loss {'Reaction outcome loss': 0.3118757808486776, 'Total loss': 0.3118757808486776}
2023-01-04 07:14:01,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:01,090 INFO:     Epoch: 51
2023-01-04 07:14:02,625 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45295466283957164, 'Total loss': 0.45295466283957164} | train loss {'Reaction outcome loss': 0.3101603609604248, 'Total loss': 0.3101603609604248}
2023-01-04 07:14:02,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:02,626 INFO:     Epoch: 52
2023-01-04 07:14:04,179 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4328541467587153, 'Total loss': 0.4328541467587153} | train loss {'Reaction outcome loss': 0.3122232120516381, 'Total loss': 0.3122232120516381}
2023-01-04 07:14:04,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:04,179 INFO:     Epoch: 53
2023-01-04 07:14:05,751 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44061086277167, 'Total loss': 0.44061086277167} | train loss {'Reaction outcome loss': 0.30773722075779614, 'Total loss': 0.30773722075779614}
2023-01-04 07:14:05,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:05,752 INFO:     Epoch: 54
2023-01-04 07:14:07,340 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46195546388626096, 'Total loss': 0.46195546388626096} | train loss {'Reaction outcome loss': 0.30620165796869475, 'Total loss': 0.30620165796869475}
2023-01-04 07:14:07,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:07,340 INFO:     Epoch: 55
2023-01-04 07:14:08,884 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4613524854183197, 'Total loss': 0.4613524854183197} | train loss {'Reaction outcome loss': 0.3078117106532496, 'Total loss': 0.3078117106532496}
2023-01-04 07:14:08,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:08,884 INFO:     Epoch: 56
2023-01-04 07:14:10,428 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4422798156738281, 'Total loss': 0.4422798156738281} | train loss {'Reaction outcome loss': 0.2998839337648689, 'Total loss': 0.2998839337648689}
2023-01-04 07:14:10,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:10,428 INFO:     Epoch: 57
2023-01-04 07:14:11,968 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4014957676331202, 'Total loss': 0.4014957676331202} | train loss {'Reaction outcome loss': 0.30864544779710146, 'Total loss': 0.30864544779710146}
2023-01-04 07:14:11,968 INFO:     Found new best model at epoch 57
2023-01-04 07:14:11,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:11,969 INFO:     Epoch: 58
2023-01-04 07:14:13,512 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44893086353937783, 'Total loss': 0.44893086353937783} | train loss {'Reaction outcome loss': 0.29843832948582544, 'Total loss': 0.29843832948582544}
2023-01-04 07:14:13,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:13,512 INFO:     Epoch: 59
2023-01-04 07:14:15,060 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4439317762851715, 'Total loss': 0.4439317762851715} | train loss {'Reaction outcome loss': 0.29606396782713523, 'Total loss': 0.29606396782713523}
2023-01-04 07:14:15,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:15,061 INFO:     Epoch: 60
2023-01-04 07:14:16,643 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4403306027253469, 'Total loss': 0.4403306027253469} | train loss {'Reaction outcome loss': 0.29287173589314014, 'Total loss': 0.29287173589314014}
2023-01-04 07:14:16,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:16,643 INFO:     Epoch: 61
2023-01-04 07:14:18,148 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42979434231917063, 'Total loss': 0.42979434231917063} | train loss {'Reaction outcome loss': 0.2878771386454321, 'Total loss': 0.2878771386454321}
2023-01-04 07:14:18,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:18,148 INFO:     Epoch: 62
2023-01-04 07:14:19,727 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45293369591236116, 'Total loss': 0.45293369591236116} | train loss {'Reaction outcome loss': 0.2924736438831989, 'Total loss': 0.2924736438831989}
2023-01-04 07:14:19,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:19,727 INFO:     Epoch: 63
2023-01-04 07:14:21,311 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.449137153228124, 'Total loss': 0.449137153228124} | train loss {'Reaction outcome loss': 0.3058649415447228, 'Total loss': 0.3058649415447228}
2023-01-04 07:14:21,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:21,311 INFO:     Epoch: 64
2023-01-04 07:14:22,871 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.434173783659935, 'Total loss': 0.434173783659935} | train loss {'Reaction outcome loss': 0.3535482399975476, 'Total loss': 0.3535482399975476}
2023-01-04 07:14:22,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:22,871 INFO:     Epoch: 65
2023-01-04 07:14:24,445 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4418964604536692, 'Total loss': 0.4418964604536692} | train loss {'Reaction outcome loss': 0.3069066616031257, 'Total loss': 0.3069066616031257}
2023-01-04 07:14:24,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:24,445 INFO:     Epoch: 66
2023-01-04 07:14:26,016 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4373028854529063, 'Total loss': 0.4373028854529063} | train loss {'Reaction outcome loss': 0.2949900321845485, 'Total loss': 0.2949900321845485}
2023-01-04 07:14:26,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:26,016 INFO:     Epoch: 67
2023-01-04 07:14:27,517 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43205280005931856, 'Total loss': 0.43205280005931856} | train loss {'Reaction outcome loss': 0.28889680921312666, 'Total loss': 0.28889680921312666}
2023-01-04 07:14:27,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:27,518 INFO:     Epoch: 68
2023-01-04 07:14:29,078 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4224043647448222, 'Total loss': 0.4224043647448222} | train loss {'Reaction outcome loss': 0.2846222089374087, 'Total loss': 0.2846222089374087}
2023-01-04 07:14:29,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:29,078 INFO:     Epoch: 69
2023-01-04 07:14:30,628 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44356606105963386, 'Total loss': 0.44356606105963386} | train loss {'Reaction outcome loss': 0.2835785211091338, 'Total loss': 0.2835785211091338}
2023-01-04 07:14:30,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:30,629 INFO:     Epoch: 70
2023-01-04 07:14:32,180 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43177716235319774, 'Total loss': 0.43177716235319774} | train loss {'Reaction outcome loss': 0.28612602427850675, 'Total loss': 0.28612602427850675}
2023-01-04 07:14:32,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:32,180 INFO:     Epoch: 71
2023-01-04 07:14:33,745 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4635512669881185, 'Total loss': 0.4635512669881185} | train loss {'Reaction outcome loss': 0.28259287086193974, 'Total loss': 0.28259287086193974}
2023-01-04 07:14:33,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:33,746 INFO:     Epoch: 72
2023-01-04 07:14:35,264 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45616323351860044, 'Total loss': 0.45616323351860044} | train loss {'Reaction outcome loss': 0.2828856072240118, 'Total loss': 0.2828856072240118}
2023-01-04 07:14:35,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:35,264 INFO:     Epoch: 73
2023-01-04 07:14:36,790 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4332195977369944, 'Total loss': 0.4332195977369944} | train loss {'Reaction outcome loss': 0.2838694277367946, 'Total loss': 0.2838694277367946}
2023-01-04 07:14:36,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:36,791 INFO:     Epoch: 74
2023-01-04 07:14:38,361 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4362389345963796, 'Total loss': 0.4362389345963796} | train loss {'Reaction outcome loss': 0.2806185924657283, 'Total loss': 0.2806185924657283}
2023-01-04 07:14:38,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:38,361 INFO:     Epoch: 75
2023-01-04 07:14:39,912 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48253713647524515, 'Total loss': 0.48253713647524515} | train loss {'Reaction outcome loss': 0.28213802747347433, 'Total loss': 0.28213802747347433}
2023-01-04 07:14:39,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:39,912 INFO:     Epoch: 76
2023-01-04 07:14:41,490 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4485723674297333, 'Total loss': 0.4485723674297333} | train loss {'Reaction outcome loss': 0.2794906939080924, 'Total loss': 0.2794906939080924}
2023-01-04 07:14:41,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:41,490 INFO:     Epoch: 77
2023-01-04 07:14:43,049 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44126360019048055, 'Total loss': 0.44126360019048055} | train loss {'Reaction outcome loss': 0.2795050975151041, 'Total loss': 0.2795050975151041}
2023-01-04 07:14:43,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:43,049 INFO:     Epoch: 78
2023-01-04 07:14:44,576 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4248175879319509, 'Total loss': 0.4248175879319509} | train loss {'Reaction outcome loss': 0.27373976238321623, 'Total loss': 0.27373976238321623}
2023-01-04 07:14:44,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:44,577 INFO:     Epoch: 79
2023-01-04 07:14:46,097 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40861500302950543, 'Total loss': 0.40861500302950543} | train loss {'Reaction outcome loss': 0.27491988992129546, 'Total loss': 0.27491988992129546}
2023-01-04 07:14:46,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:46,098 INFO:     Epoch: 80
2023-01-04 07:14:47,654 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47253804008165995, 'Total loss': 0.47253804008165995} | train loss {'Reaction outcome loss': 0.27903075867494487, 'Total loss': 0.27903075867494487}
2023-01-04 07:14:47,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:47,654 INFO:     Epoch: 81
2023-01-04 07:14:49,209 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48241239190101626, 'Total loss': 0.48241239190101626} | train loss {'Reaction outcome loss': 0.2703326941557242, 'Total loss': 0.2703326941557242}
2023-01-04 07:14:49,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:49,209 INFO:     Epoch: 82
2023-01-04 07:14:50,765 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44704861640930177, 'Total loss': 0.44704861640930177} | train loss {'Reaction outcome loss': 0.27419742775142053, 'Total loss': 0.27419742775142053}
2023-01-04 07:14:50,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:50,765 INFO:     Epoch: 83
2023-01-04 07:14:52,321 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4528189092874527, 'Total loss': 0.4528189092874527} | train loss {'Reaction outcome loss': 0.2686164605214456, 'Total loss': 0.2686164605214456}
2023-01-04 07:14:52,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:52,321 INFO:     Epoch: 84
2023-01-04 07:14:53,846 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45362218817075095, 'Total loss': 0.45362218817075095} | train loss {'Reaction outcome loss': 0.26704837939114834, 'Total loss': 0.26704837939114834}
2023-01-04 07:14:53,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:53,846 INFO:     Epoch: 85
2023-01-04 07:14:55,370 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43577079971631366, 'Total loss': 0.43577079971631366} | train loss {'Reaction outcome loss': 0.2738858897346949, 'Total loss': 0.2738858897346949}
2023-01-04 07:14:55,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:55,371 INFO:     Epoch: 86
2023-01-04 07:14:56,920 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4860513945420583, 'Total loss': 0.4860513945420583} | train loss {'Reaction outcome loss': 0.2986771206277004, 'Total loss': 0.2986771206277004}
2023-01-04 07:14:56,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:56,921 INFO:     Epoch: 87
2023-01-04 07:14:58,481 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4625394990046819, 'Total loss': 0.4625394990046819} | train loss {'Reaction outcome loss': 0.29300737935388327, 'Total loss': 0.29300737935388327}
2023-01-04 07:14:58,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:14:58,483 INFO:     Epoch: 88
2023-01-04 07:15:00,061 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46820880969365436, 'Total loss': 0.46820880969365436} | train loss {'Reaction outcome loss': 0.26874132739781553, 'Total loss': 0.26874132739781553}
2023-01-04 07:15:00,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:00,061 INFO:     Epoch: 89
2023-01-04 07:15:01,634 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46420076688130696, 'Total loss': 0.46420076688130696} | train loss {'Reaction outcome loss': 0.2642822990647814, 'Total loss': 0.2642822990647814}
2023-01-04 07:15:01,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:01,634 INFO:     Epoch: 90
2023-01-04 07:15:03,153 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4366690287987391, 'Total loss': 0.4366690287987391} | train loss {'Reaction outcome loss': 0.2617532662337961, 'Total loss': 0.2617532662337961}
2023-01-04 07:15:03,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:03,153 INFO:     Epoch: 91
2023-01-04 07:15:04,655 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4539025564988454, 'Total loss': 0.4539025564988454} | train loss {'Reaction outcome loss': 0.26440164677130623, 'Total loss': 0.26440164677130623}
2023-01-04 07:15:04,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:04,656 INFO:     Epoch: 92
2023-01-04 07:15:06,206 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46579155226548513, 'Total loss': 0.46579155226548513} | train loss {'Reaction outcome loss': 0.26271029956075403, 'Total loss': 0.26271029956075403}
2023-01-04 07:15:06,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:06,206 INFO:     Epoch: 93
2023-01-04 07:15:07,761 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4568065841992696, 'Total loss': 0.4568065841992696} | train loss {'Reaction outcome loss': 0.25883659369013173, 'Total loss': 0.25883659369013173}
2023-01-04 07:15:07,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:07,762 INFO:     Epoch: 94
2023-01-04 07:15:09,328 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48198966185251874, 'Total loss': 0.48198966185251874} | train loss {'Reaction outcome loss': 0.2594224820259378, 'Total loss': 0.2594224820259378}
2023-01-04 07:15:09,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:09,328 INFO:     Epoch: 95
2023-01-04 07:15:10,889 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4527710884809494, 'Total loss': 0.4527710884809494} | train loss {'Reaction outcome loss': 0.2595237321557774, 'Total loss': 0.2595237321557774}
2023-01-04 07:15:10,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:10,889 INFO:     Epoch: 96
2023-01-04 07:15:12,439 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.437913978099823, 'Total loss': 0.437913978099823} | train loss {'Reaction outcome loss': 0.262117891886231, 'Total loss': 0.262117891886231}
2023-01-04 07:15:12,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:12,440 INFO:     Epoch: 97
2023-01-04 07:15:13,964 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4298015058040619, 'Total loss': 0.4298015058040619} | train loss {'Reaction outcome loss': 0.25747734498493274, 'Total loss': 0.25747734498493274}
2023-01-04 07:15:13,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:13,964 INFO:     Epoch: 98
2023-01-04 07:15:15,524 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4157861004273097, 'Total loss': 0.4157861004273097} | train loss {'Reaction outcome loss': 0.2571575249827035, 'Total loss': 0.2571575249827035}
2023-01-04 07:15:15,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:15,524 INFO:     Epoch: 99
2023-01-04 07:15:17,107 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43396489322185516, 'Total loss': 0.43396489322185516} | train loss {'Reaction outcome loss': 0.2521159700387954, 'Total loss': 0.2521159700387954}
2023-01-04 07:15:17,108 INFO:     Best model found after epoch 58 of 100.
2023-01-04 07:15:17,109 INFO:   Done with stage: TRAINING
2023-01-04 07:15:17,109 INFO:   Starting stage: EVALUATION
2023-01-04 07:15:17,236 INFO:   Done with stage: EVALUATION
2023-01-04 07:15:17,236 INFO:   Leaving out SEQ value Fold_8
2023-01-04 07:15:17,248 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 07:15:17,248 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:15:17,883 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:15:17,883 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:15:17,952 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:15:17,953 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:15:17,953 INFO:     No hyperparam tuning for this model
2023-01-04 07:15:17,953 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:15:17,953 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:15:17,953 INFO:     None feature selector for col prot
2023-01-04 07:15:17,954 INFO:     None feature selector for col prot
2023-01-04 07:15:17,954 INFO:     None feature selector for col prot
2023-01-04 07:15:17,954 INFO:     None feature selector for col chem
2023-01-04 07:15:17,954 INFO:     None feature selector for col chem
2023-01-04 07:15:17,954 INFO:     None feature selector for col chem
2023-01-04 07:15:17,954 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:15:17,954 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:15:17,955 INFO:     Number of params in model 70111
2023-01-04 07:15:17,959 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:15:17,959 INFO:   Starting stage: TRAINING
2023-01-04 07:15:18,001 INFO:     Val loss before train {'Reaction outcome loss': 1.0389718810717266, 'Total loss': 1.0389718810717266}
2023-01-04 07:15:18,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:18,001 INFO:     Epoch: 0
2023-01-04 07:15:19,558 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8279746611913045, 'Total loss': 0.8279746611913045} | train loss {'Reaction outcome loss': 0.8368375373410655, 'Total loss': 0.8368375373410655}
2023-01-04 07:15:19,558 INFO:     Found new best model at epoch 0
2023-01-04 07:15:19,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:19,559 INFO:     Epoch: 1
2023-01-04 07:15:21,091 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.645702721675237, 'Total loss': 0.645702721675237} | train loss {'Reaction outcome loss': 0.6635045925557832, 'Total loss': 0.6635045925557832}
2023-01-04 07:15:21,091 INFO:     Found new best model at epoch 1
2023-01-04 07:15:21,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:21,092 INFO:     Epoch: 2
2023-01-04 07:15:22,605 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5658869663874309, 'Total loss': 0.5658869663874309} | train loss {'Reaction outcome loss': 0.5625119602287209, 'Total loss': 0.5625119602287209}
2023-01-04 07:15:22,605 INFO:     Found new best model at epoch 2
2023-01-04 07:15:22,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:22,606 INFO:     Epoch: 3
2023-01-04 07:15:24,164 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5994254450003306, 'Total loss': 0.5994254450003306} | train loss {'Reaction outcome loss': 0.5275309938432533, 'Total loss': 0.5275309938432533}
2023-01-04 07:15:24,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:24,164 INFO:     Epoch: 4
2023-01-04 07:15:25,727 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.538605268796285, 'Total loss': 0.538605268796285} | train loss {'Reaction outcome loss': 0.5087094062413925, 'Total loss': 0.5087094062413925}
2023-01-04 07:15:25,728 INFO:     Found new best model at epoch 4
2023-01-04 07:15:25,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:25,728 INFO:     Epoch: 5
2023-01-04 07:15:27,289 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5259455462296804, 'Total loss': 0.5259455462296804} | train loss {'Reaction outcome loss': 0.4924936248705937, 'Total loss': 0.4924936248705937}
2023-01-04 07:15:27,289 INFO:     Found new best model at epoch 5
2023-01-04 07:15:27,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:27,290 INFO:     Epoch: 6
2023-01-04 07:15:28,830 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5453869124253591, 'Total loss': 0.5453869124253591} | train loss {'Reaction outcome loss': 0.48057793653928316, 'Total loss': 0.48057793653928316}
2023-01-04 07:15:28,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:28,830 INFO:     Epoch: 7
2023-01-04 07:15:30,330 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5063946803410848, 'Total loss': 0.5063946803410848} | train loss {'Reaction outcome loss': 0.47283014420406283, 'Total loss': 0.47283014420406283}
2023-01-04 07:15:30,330 INFO:     Found new best model at epoch 7
2023-01-04 07:15:30,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:30,331 INFO:     Epoch: 8
2023-01-04 07:15:31,841 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4947635402282079, 'Total loss': 0.4947635402282079} | train loss {'Reaction outcome loss': 0.46662596604981266, 'Total loss': 0.46662596604981266}
2023-01-04 07:15:31,841 INFO:     Found new best model at epoch 8
2023-01-04 07:15:31,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:31,842 INFO:     Epoch: 9
2023-01-04 07:15:33,378 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5027772227923075, 'Total loss': 0.5027772227923075} | train loss {'Reaction outcome loss': 0.46244254080585506, 'Total loss': 0.46244254080585506}
2023-01-04 07:15:33,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:33,378 INFO:     Epoch: 10
2023-01-04 07:15:34,905 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5108809014161427, 'Total loss': 0.5108809014161427} | train loss {'Reaction outcome loss': 0.45936540222211636, 'Total loss': 0.45936540222211636}
2023-01-04 07:15:34,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:34,907 INFO:     Epoch: 11
2023-01-04 07:15:36,437 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5304169476032257, 'Total loss': 0.5304169476032257} | train loss {'Reaction outcome loss': 0.4463895387374438, 'Total loss': 0.4463895387374438}
2023-01-04 07:15:36,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:36,437 INFO:     Epoch: 12
2023-01-04 07:15:37,980 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48047355314095813, 'Total loss': 0.48047355314095813} | train loss {'Reaction outcome loss': 0.4395857311976262, 'Total loss': 0.4395857311976262}
2023-01-04 07:15:37,981 INFO:     Found new best model at epoch 12
2023-01-04 07:15:37,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:37,981 INFO:     Epoch: 13
2023-01-04 07:15:39,480 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4932517230510712, 'Total loss': 0.4932517230510712} | train loss {'Reaction outcome loss': 0.4333266120799732, 'Total loss': 0.4333266120799732}
2023-01-04 07:15:39,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:39,480 INFO:     Epoch: 14
2023-01-04 07:15:41,014 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5094406604766846, 'Total loss': 0.5094406604766846} | train loss {'Reaction outcome loss': 0.42703122091599, 'Total loss': 0.42703122091599}
2023-01-04 07:15:41,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:41,015 INFO:     Epoch: 15
2023-01-04 07:15:42,576 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49806396961212157, 'Total loss': 0.49806396961212157} | train loss {'Reaction outcome loss': 0.42581047407000056, 'Total loss': 0.42581047407000056}
2023-01-04 07:15:42,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:42,576 INFO:     Epoch: 16
2023-01-04 07:15:44,124 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47163122296333315, 'Total loss': 0.47163122296333315} | train loss {'Reaction outcome loss': 0.420651661443623, 'Total loss': 0.420651661443623}
2023-01-04 07:15:44,124 INFO:     Found new best model at epoch 16
2023-01-04 07:15:44,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:44,125 INFO:     Epoch: 17
2023-01-04 07:15:45,664 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5062041580677032, 'Total loss': 0.5062041580677032} | train loss {'Reaction outcome loss': 0.4161201448012621, 'Total loss': 0.4161201448012621}
2023-01-04 07:15:45,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:45,664 INFO:     Epoch: 18
2023-01-04 07:15:47,219 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47180433869361876, 'Total loss': 0.47180433869361876} | train loss {'Reaction outcome loss': 0.41164383797091003, 'Total loss': 0.41164383797091003}
2023-01-04 07:15:47,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:47,219 INFO:     Epoch: 19
2023-01-04 07:15:48,704 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4985813061396281, 'Total loss': 0.4985813061396281} | train loss {'Reaction outcome loss': 0.4110371497197029, 'Total loss': 0.4110371497197029}
2023-01-04 07:15:48,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:48,704 INFO:     Epoch: 20
2023-01-04 07:15:50,238 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45423910617828367, 'Total loss': 0.45423910617828367} | train loss {'Reaction outcome loss': 0.4056547163497834, 'Total loss': 0.4056547163497834}
2023-01-04 07:15:50,238 INFO:     Found new best model at epoch 20
2023-01-04 07:15:50,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:50,239 INFO:     Epoch: 21
2023-01-04 07:15:51,766 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4768142580986023, 'Total loss': 0.4768142580986023} | train loss {'Reaction outcome loss': 0.3997843281089605, 'Total loss': 0.3997843281089605}
2023-01-04 07:15:51,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:51,767 INFO:     Epoch: 22
2023-01-04 07:15:53,285 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4386034727096558, 'Total loss': 0.4386034727096558} | train loss {'Reaction outcome loss': 0.39442385760419096, 'Total loss': 0.39442385760419096}
2023-01-04 07:15:53,286 INFO:     Found new best model at epoch 22
2023-01-04 07:15:53,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:53,286 INFO:     Epoch: 23
2023-01-04 07:15:54,818 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44844186504681904, 'Total loss': 0.44844186504681904} | train loss {'Reaction outcome loss': 0.3915819097787906, 'Total loss': 0.3915819097787906}
2023-01-04 07:15:54,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:54,818 INFO:     Epoch: 24
2023-01-04 07:15:56,342 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44837591449419656, 'Total loss': 0.44837591449419656} | train loss {'Reaction outcome loss': 0.38728899282195195, 'Total loss': 0.38728899282195195}
2023-01-04 07:15:56,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:56,343 INFO:     Epoch: 25
2023-01-04 07:15:57,815 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4718992094198863, 'Total loss': 0.4718992094198863} | train loss {'Reaction outcome loss': 0.3826636085798452, 'Total loss': 0.3826636085798452}
2023-01-04 07:15:57,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:57,815 INFO:     Epoch: 26
2023-01-04 07:15:59,339 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46729540526866914, 'Total loss': 0.46729540526866914} | train loss {'Reaction outcome loss': 0.3800087114557242, 'Total loss': 0.3800087114557242}
2023-01-04 07:15:59,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:15:59,339 INFO:     Epoch: 27
2023-01-04 07:16:00,874 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4564237594604492, 'Total loss': 0.4564237594604492} | train loss {'Reaction outcome loss': 0.3786142304703429, 'Total loss': 0.3786142304703429}
2023-01-04 07:16:00,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:00,874 INFO:     Epoch: 28
2023-01-04 07:16:02,417 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46476929982503257, 'Total loss': 0.46476929982503257} | train loss {'Reaction outcome loss': 0.37184169406801354, 'Total loss': 0.37184169406801354}
2023-01-04 07:16:02,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:02,417 INFO:     Epoch: 29
2023-01-04 07:16:03,952 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4416797896226247, 'Total loss': 0.4416797896226247} | train loss {'Reaction outcome loss': 0.37084079765793165, 'Total loss': 0.37084079765793165}
2023-01-04 07:16:03,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:03,952 INFO:     Epoch: 30
2023-01-04 07:16:05,490 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44247839599847794, 'Total loss': 0.44247839599847794} | train loss {'Reaction outcome loss': 0.371571163500185, 'Total loss': 0.371571163500185}
2023-01-04 07:16:05,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:05,490 INFO:     Epoch: 31
2023-01-04 07:16:06,973 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46682732701301577, 'Total loss': 0.46682732701301577} | train loss {'Reaction outcome loss': 0.3675356653310877, 'Total loss': 0.3675356653310877}
2023-01-04 07:16:06,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:06,973 INFO:     Epoch: 32
2023-01-04 07:16:08,504 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46378360986709594, 'Total loss': 0.46378360986709594} | train loss {'Reaction outcome loss': 0.3622452980760253, 'Total loss': 0.3622452980760253}
2023-01-04 07:16:08,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:08,504 INFO:     Epoch: 33
2023-01-04 07:16:10,039 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4605654795964559, 'Total loss': 0.4605654795964559} | train loss {'Reaction outcome loss': 0.35701225583369917, 'Total loss': 0.35701225583369917}
2023-01-04 07:16:10,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:10,041 INFO:     Epoch: 34
2023-01-04 07:16:11,569 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4410497725009918, 'Total loss': 0.4410497725009918} | train loss {'Reaction outcome loss': 0.35917303866737493, 'Total loss': 0.35917303866737493}
2023-01-04 07:16:11,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:11,570 INFO:     Epoch: 35
2023-01-04 07:16:13,109 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41986661901076633, 'Total loss': 0.41986661901076633} | train loss {'Reaction outcome loss': 0.3559546447990142, 'Total loss': 0.3559546447990142}
2023-01-04 07:16:13,109 INFO:     Found new best model at epoch 35
2023-01-04 07:16:13,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:13,109 INFO:     Epoch: 36
2023-01-04 07:16:14,630 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47321366568406426, 'Total loss': 0.47321366568406426} | train loss {'Reaction outcome loss': 0.35055747404421644, 'Total loss': 0.35055747404421644}
2023-01-04 07:16:14,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:14,631 INFO:     Epoch: 37
2023-01-04 07:16:16,123 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49681870539983114, 'Total loss': 0.49681870539983114} | train loss {'Reaction outcome loss': 0.34445249753229784, 'Total loss': 0.34445249753229784}
2023-01-04 07:16:16,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:16,124 INFO:     Epoch: 38
2023-01-04 07:16:17,680 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43017855783303577, 'Total loss': 0.43017855783303577} | train loss {'Reaction outcome loss': 0.34320631530477014, 'Total loss': 0.34320631530477014}
2023-01-04 07:16:17,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:17,680 INFO:     Epoch: 39
2023-01-04 07:16:19,225 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44440071980158485, 'Total loss': 0.44440071980158485} | train loss {'Reaction outcome loss': 0.3411434082648693, 'Total loss': 0.3411434082648693}
2023-01-04 07:16:19,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:19,225 INFO:     Epoch: 40
2023-01-04 07:16:20,756 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4348040496309598, 'Total loss': 0.4348040496309598} | train loss {'Reaction outcome loss': 0.3350301931847583, 'Total loss': 0.3350301931847583}
2023-01-04 07:16:20,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:20,757 INFO:     Epoch: 41
2023-01-04 07:16:22,285 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4438025772571564, 'Total loss': 0.4438025772571564} | train loss {'Reaction outcome loss': 0.33812224646627687, 'Total loss': 0.33812224646627687}
2023-01-04 07:16:22,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:22,285 INFO:     Epoch: 42
2023-01-04 07:16:23,795 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4353656182686488, 'Total loss': 0.4353656182686488} | train loss {'Reaction outcome loss': 0.3306196023038019, 'Total loss': 0.3306196023038019}
2023-01-04 07:16:23,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:23,795 INFO:     Epoch: 43
2023-01-04 07:16:25,297 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44215184648831685, 'Total loss': 0.44215184648831685} | train loss {'Reaction outcome loss': 0.3322277254128194, 'Total loss': 0.3322277254128194}
2023-01-04 07:16:25,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:25,297 INFO:     Epoch: 44
2023-01-04 07:16:26,843 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4157332373162111, 'Total loss': 0.4157332373162111} | train loss {'Reaction outcome loss': 0.33061424236157877, 'Total loss': 0.33061424236157877}
2023-01-04 07:16:26,843 INFO:     Found new best model at epoch 44
2023-01-04 07:16:26,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:26,844 INFO:     Epoch: 45
2023-01-04 07:16:28,382 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43475053310394285, 'Total loss': 0.43475053310394285} | train loss {'Reaction outcome loss': 0.32653247240262157, 'Total loss': 0.32653247240262157}
2023-01-04 07:16:28,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:28,383 INFO:     Epoch: 46
2023-01-04 07:16:29,925 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5051346302032471, 'Total loss': 0.5051346302032471} | train loss {'Reaction outcome loss': 0.32367747118730683, 'Total loss': 0.32367747118730683}
2023-01-04 07:16:29,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:29,925 INFO:     Epoch: 47
2023-01-04 07:16:31,470 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48318148652712506, 'Total loss': 0.48318148652712506} | train loss {'Reaction outcome loss': 0.3259332895606429, 'Total loss': 0.3259332895606429}
2023-01-04 07:16:31,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:31,470 INFO:     Epoch: 48
2023-01-04 07:16:32,977 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41627849340438844, 'Total loss': 0.41627849340438844} | train loss {'Reaction outcome loss': 0.32100419560959054, 'Total loss': 0.32100419560959054}
2023-01-04 07:16:32,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:32,977 INFO:     Epoch: 49
2023-01-04 07:16:34,486 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4446890076001485, 'Total loss': 0.4446890076001485} | train loss {'Reaction outcome loss': 0.3175192513254099, 'Total loss': 0.3175192513254099}
2023-01-04 07:16:34,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:34,486 INFO:     Epoch: 50
2023-01-04 07:16:36,020 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42395551403363546, 'Total loss': 0.42395551403363546} | train loss {'Reaction outcome loss': 0.31599403350126176, 'Total loss': 0.31599403350126176}
2023-01-04 07:16:36,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:36,020 INFO:     Epoch: 51
2023-01-04 07:16:37,552 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41422507067521414, 'Total loss': 0.41422507067521414} | train loss {'Reaction outcome loss': 0.31199899145262144, 'Total loss': 0.31199899145262144}
2023-01-04 07:16:37,552 INFO:     Found new best model at epoch 51
2023-01-04 07:16:37,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:37,553 INFO:     Epoch: 52
2023-01-04 07:16:39,102 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43973588943481445, 'Total loss': 0.43973588943481445} | train loss {'Reaction outcome loss': 0.31238837673878056, 'Total loss': 0.31238837673878056}
2023-01-04 07:16:39,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:39,102 INFO:     Epoch: 53
2023-01-04 07:16:40,635 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4177502950032552, 'Total loss': 0.4177502950032552} | train loss {'Reaction outcome loss': 0.30784623657827415, 'Total loss': 0.30784623657827415}
2023-01-04 07:16:40,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:40,636 INFO:     Epoch: 54
2023-01-04 07:16:42,152 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4370227446158727, 'Total loss': 0.4370227446158727} | train loss {'Reaction outcome loss': 0.3094138674192376, 'Total loss': 0.3094138674192376}
2023-01-04 07:16:42,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:42,153 INFO:     Epoch: 55
2023-01-04 07:16:43,681 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4220470900336901, 'Total loss': 0.4220470900336901} | train loss {'Reaction outcome loss': 0.30406897910785324, 'Total loss': 0.30406897910785324}
2023-01-04 07:16:43,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:43,682 INFO:     Epoch: 56
2023-01-04 07:16:45,238 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4289386014143626, 'Total loss': 0.4289386014143626} | train loss {'Reaction outcome loss': 0.3020056517242075, 'Total loss': 0.3020056517242075}
2023-01-04 07:16:45,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:45,239 INFO:     Epoch: 57
2023-01-04 07:16:46,822 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4355775733788808, 'Total loss': 0.4355775733788808} | train loss {'Reaction outcome loss': 0.29759247055202176, 'Total loss': 0.29759247055202176}
2023-01-04 07:16:46,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:46,823 INFO:     Epoch: 58
2023-01-04 07:16:48,375 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4593059519926707, 'Total loss': 0.4593059519926707} | train loss {'Reaction outcome loss': 0.2976749435394675, 'Total loss': 0.2976749435394675}
2023-01-04 07:16:48,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:48,376 INFO:     Epoch: 59
2023-01-04 07:16:49,928 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4464391360680262, 'Total loss': 0.4464391360680262} | train loss {'Reaction outcome loss': 0.3009352307671156, 'Total loss': 0.3009352307671156}
2023-01-04 07:16:49,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:49,928 INFO:     Epoch: 60
2023-01-04 07:16:51,441 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4353114187717438, 'Total loss': 0.4353114187717438} | train loss {'Reaction outcome loss': 0.2977638194412539, 'Total loss': 0.2977638194412539}
2023-01-04 07:16:51,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:51,441 INFO:     Epoch: 61
2023-01-04 07:16:52,961 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4357789436976115, 'Total loss': 0.4357789436976115} | train loss {'Reaction outcome loss': 0.2929248995806053, 'Total loss': 0.2929248995806053}
2023-01-04 07:16:52,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:52,962 INFO:     Epoch: 62
2023-01-04 07:16:54,483 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4235776742299398, 'Total loss': 0.4235776742299398} | train loss {'Reaction outcome loss': 0.29582929354665916, 'Total loss': 0.29582929354665916}
2023-01-04 07:16:54,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:54,483 INFO:     Epoch: 63
2023-01-04 07:16:56,012 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4399480760097504, 'Total loss': 0.4399480760097504} | train loss {'Reaction outcome loss': 0.2958439921503102, 'Total loss': 0.2958439921503102}
2023-01-04 07:16:56,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:56,013 INFO:     Epoch: 64
2023-01-04 07:16:57,554 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4410620927810669, 'Total loss': 0.4410620927810669} | train loss {'Reaction outcome loss': 0.2866206749072878, 'Total loss': 0.2866206749072878}
2023-01-04 07:16:57,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:57,554 INFO:     Epoch: 65
2023-01-04 07:16:59,087 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4007306794325511, 'Total loss': 0.4007306794325511} | train loss {'Reaction outcome loss': 0.28735123904960935, 'Total loss': 0.28735123904960935}
2023-01-04 07:16:59,088 INFO:     Found new best model at epoch 65
2023-01-04 07:16:59,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:16:59,089 INFO:     Epoch: 66
2023-01-04 07:17:00,593 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4038010835647583, 'Total loss': 0.4038010835647583} | train loss {'Reaction outcome loss': 0.2862679158804781, 'Total loss': 0.2862679158804781}
2023-01-04 07:17:00,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:00,593 INFO:     Epoch: 67
2023-01-04 07:17:02,119 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.458919761578242, 'Total loss': 0.458919761578242} | train loss {'Reaction outcome loss': 0.287591478736191, 'Total loss': 0.287591478736191}
2023-01-04 07:17:02,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:02,119 INFO:     Epoch: 68
2023-01-04 07:17:03,649 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46840281089146935, 'Total loss': 0.46840281089146935} | train loss {'Reaction outcome loss': 0.2842300347710922, 'Total loss': 0.2842300347710922}
2023-01-04 07:17:03,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:03,649 INFO:     Epoch: 69
2023-01-04 07:17:05,191 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4141356150309245, 'Total loss': 0.4141356150309245} | train loss {'Reaction outcome loss': 0.2876160665527805, 'Total loss': 0.2876160665527805}
2023-01-04 07:17:05,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:05,191 INFO:     Epoch: 70
2023-01-04 07:17:06,757 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44271469314893086, 'Total loss': 0.44271469314893086} | train loss {'Reaction outcome loss': 0.2873588237133655, 'Total loss': 0.2873588237133655}
2023-01-04 07:17:06,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:06,757 INFO:     Epoch: 71
2023-01-04 07:17:08,304 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41438294450442, 'Total loss': 0.41438294450442} | train loss {'Reaction outcome loss': 0.27940527230992424, 'Total loss': 0.27940527230992424}
2023-01-04 07:17:08,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:08,305 INFO:     Epoch: 72
2023-01-04 07:17:09,823 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4217928911248843, 'Total loss': 0.4217928911248843} | train loss {'Reaction outcome loss': 0.2776405114830632, 'Total loss': 0.2776405114830632}
2023-01-04 07:17:09,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:09,824 INFO:     Epoch: 73
2023-01-04 07:17:11,333 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4813058058420817, 'Total loss': 0.4813058058420817} | train loss {'Reaction outcome loss': 0.2802996695614778, 'Total loss': 0.2802996695614778}
2023-01-04 07:17:11,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:11,334 INFO:     Epoch: 74
2023-01-04 07:17:12,894 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.421836194396019, 'Total loss': 0.421836194396019} | train loss {'Reaction outcome loss': 0.27685443606677945, 'Total loss': 0.27685443606677945}
2023-01-04 07:17:12,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:12,894 INFO:     Epoch: 75
2023-01-04 07:17:14,454 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40208330055077873, 'Total loss': 0.40208330055077873} | train loss {'Reaction outcome loss': 0.27965972949187834, 'Total loss': 0.27965972949187834}
2023-01-04 07:17:14,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:14,454 INFO:     Epoch: 76
2023-01-04 07:17:16,074 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4028583337863286, 'Total loss': 0.4028583337863286} | train loss {'Reaction outcome loss': 0.27060899379980435, 'Total loss': 0.27060899379980435}
2023-01-04 07:17:16,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:16,074 INFO:     Epoch: 77
2023-01-04 07:17:17,690 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44026046196619667, 'Total loss': 0.44026046196619667} | train loss {'Reaction outcome loss': 0.27915022687324675, 'Total loss': 0.27915022687324675}
2023-01-04 07:17:17,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:17,691 INFO:     Epoch: 78
2023-01-04 07:17:19,240 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.433875331779321, 'Total loss': 0.433875331779321} | train loss {'Reaction outcome loss': 0.27291347511494773, 'Total loss': 0.27291347511494773}
2023-01-04 07:17:19,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:19,240 INFO:     Epoch: 79
2023-01-04 07:17:20,816 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4535066505273183, 'Total loss': 0.4535066505273183} | train loss {'Reaction outcome loss': 0.274568695015523, 'Total loss': 0.274568695015523}
2023-01-04 07:17:20,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:20,816 INFO:     Epoch: 80
2023-01-04 07:17:22,433 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4510259668032328, 'Total loss': 0.4510259668032328} | train loss {'Reaction outcome loss': 0.26995197417480604, 'Total loss': 0.26995197417480604}
2023-01-04 07:17:22,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:22,433 INFO:     Epoch: 81
2023-01-04 07:17:24,045 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48296724955240883, 'Total loss': 0.48296724955240883} | train loss {'Reaction outcome loss': 0.26924233599787667, 'Total loss': 0.26924233599787667}
2023-01-04 07:17:24,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:24,045 INFO:     Epoch: 82
2023-01-04 07:17:25,646 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4519192745288213, 'Total loss': 0.4519192745288213} | train loss {'Reaction outcome loss': 0.26227557006882224, 'Total loss': 0.26227557006882224}
2023-01-04 07:17:25,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:25,646 INFO:     Epoch: 83
2023-01-04 07:17:27,251 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4244211147228877, 'Total loss': 0.4244211147228877} | train loss {'Reaction outcome loss': 0.2660768707675157, 'Total loss': 0.2660768707675157}
2023-01-04 07:17:27,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:27,251 INFO:     Epoch: 84
2023-01-04 07:17:28,791 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4233794848124186, 'Total loss': 0.4233794848124186} | train loss {'Reaction outcome loss': 0.2684982852948891, 'Total loss': 0.2684982852948891}
2023-01-04 07:17:28,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:28,791 INFO:     Epoch: 85
2023-01-04 07:17:30,396 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4345543613036474, 'Total loss': 0.4345543613036474} | train loss {'Reaction outcome loss': 0.2622358172913611, 'Total loss': 0.2622358172913611}
2023-01-04 07:17:30,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:30,397 INFO:     Epoch: 86
2023-01-04 07:17:32,009 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44696416954199475, 'Total loss': 0.44696416954199475} | train loss {'Reaction outcome loss': 0.26260549736110284, 'Total loss': 0.26260549736110284}
2023-01-04 07:17:32,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:32,010 INFO:     Epoch: 87
2023-01-04 07:17:33,611 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44617095291614534, 'Total loss': 0.44617095291614534} | train loss {'Reaction outcome loss': 0.25869568048433944, 'Total loss': 0.25869568048433944}
2023-01-04 07:17:33,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:33,612 INFO:     Epoch: 88
2023-01-04 07:17:35,203 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4489107032616933, 'Total loss': 0.4489107032616933} | train loss {'Reaction outcome loss': 0.26260228605169955, 'Total loss': 0.26260228605169955}
2023-01-04 07:17:35,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:35,203 INFO:     Epoch: 89
2023-01-04 07:17:36,770 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4497443253795306, 'Total loss': 0.4497443253795306} | train loss {'Reaction outcome loss': 0.2609145585925151, 'Total loss': 0.2609145585925151}
2023-01-04 07:17:36,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:36,770 INFO:     Epoch: 90
2023-01-04 07:17:38,326 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45828720132509865, 'Total loss': 0.45828720132509865} | train loss {'Reaction outcome loss': 0.2610578881542543, 'Total loss': 0.2610578881542543}
2023-01-04 07:17:38,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:38,326 INFO:     Epoch: 91
2023-01-04 07:17:39,941 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4629749407370885, 'Total loss': 0.4629749407370885} | train loss {'Reaction outcome loss': 0.2599349194666842, 'Total loss': 0.2599349194666842}
2023-01-04 07:17:39,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:39,941 INFO:     Epoch: 92
2023-01-04 07:17:41,550 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44493704835573833, 'Total loss': 0.44493704835573833} | train loss {'Reaction outcome loss': 0.25449918581670894, 'Total loss': 0.25449918581670894}
2023-01-04 07:17:41,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:41,550 INFO:     Epoch: 93
2023-01-04 07:17:43,141 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44610233704249064, 'Total loss': 0.44610233704249064} | train loss {'Reaction outcome loss': 0.2576224549567743, 'Total loss': 0.2576224549567743}
2023-01-04 07:17:43,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:43,142 INFO:     Epoch: 94
2023-01-04 07:17:44,753 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46241671641667687, 'Total loss': 0.46241671641667687} | train loss {'Reaction outcome loss': 0.2562562164751601, 'Total loss': 0.2562562164751601}
2023-01-04 07:17:44,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:44,753 INFO:     Epoch: 95
2023-01-04 07:17:46,339 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4285272344946861, 'Total loss': 0.4285272344946861} | train loss {'Reaction outcome loss': 0.25551466128000844, 'Total loss': 0.25551466128000844}
2023-01-04 07:17:46,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:46,339 INFO:     Epoch: 96
2023-01-04 07:17:47,901 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48233959873517357, 'Total loss': 0.48233959873517357} | train loss {'Reaction outcome loss': 0.25658742271554774, 'Total loss': 0.25658742271554774}
2023-01-04 07:17:47,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:47,901 INFO:     Epoch: 97
2023-01-04 07:17:49,515 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42111140489578247, 'Total loss': 0.42111140489578247} | train loss {'Reaction outcome loss': 0.25210335933954725, 'Total loss': 0.25210335933954725}
2023-01-04 07:17:49,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:49,515 INFO:     Epoch: 98
2023-01-04 07:17:51,126 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43375682830810547, 'Total loss': 0.43375682830810547} | train loss {'Reaction outcome loss': 0.25449546519325766, 'Total loss': 0.25449546519325766}
2023-01-04 07:17:51,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:51,126 INFO:     Epoch: 99
2023-01-04 07:17:52,733 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4689460019270579, 'Total loss': 0.4689460019270579} | train loss {'Reaction outcome loss': 0.2535954981687523, 'Total loss': 0.2535954981687523}
2023-01-04 07:17:52,733 INFO:     Best model found after epoch 66 of 100.
2023-01-04 07:17:52,733 INFO:   Done with stage: TRAINING
2023-01-04 07:17:52,733 INFO:   Starting stage: EVALUATION
2023-01-04 07:17:52,870 INFO:   Done with stage: EVALUATION
2023-01-04 07:17:52,870 INFO:   Leaving out SEQ value Fold_9
2023-01-04 07:17:52,883 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:17:52,883 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:17:53,534 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:17:53,535 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:17:53,604 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:17:53,604 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:17:53,604 INFO:     No hyperparam tuning for this model
2023-01-04 07:17:53,604 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:17:53,604 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:17:53,605 INFO:     None feature selector for col prot
2023-01-04 07:17:53,605 INFO:     None feature selector for col prot
2023-01-04 07:17:53,605 INFO:     None feature selector for col prot
2023-01-04 07:17:53,606 INFO:     None feature selector for col chem
2023-01-04 07:17:53,606 INFO:     None feature selector for col chem
2023-01-04 07:17:53,606 INFO:     None feature selector for col chem
2023-01-04 07:17:53,606 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:17:53,606 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:17:53,607 INFO:     Number of params in model 70111
2023-01-04 07:17:53,610 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:17:53,610 INFO:   Starting stage: TRAINING
2023-01-04 07:17:53,653 INFO:     Val loss before train {'Reaction outcome loss': 1.0001137971878051, 'Total loss': 1.0001137971878051}
2023-01-04 07:17:53,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:53,653 INFO:     Epoch: 0
2023-01-04 07:17:55,239 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6763356328010559, 'Total loss': 0.6763356328010559} | train loss {'Reaction outcome loss': 0.8320856181823689, 'Total loss': 0.8320856181823689}
2023-01-04 07:17:55,239 INFO:     Found new best model at epoch 0
2023-01-04 07:17:55,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:55,240 INFO:     Epoch: 1
2023-01-04 07:17:56,815 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5414399564266205, 'Total loss': 0.5414399564266205} | train loss {'Reaction outcome loss': 0.6792533375538777, 'Total loss': 0.6792533375538777}
2023-01-04 07:17:56,815 INFO:     Found new best model at epoch 1
2023-01-04 07:17:56,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:56,816 INFO:     Epoch: 2
2023-01-04 07:17:58,444 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5000188410282135, 'Total loss': 0.5000188410282135} | train loss {'Reaction outcome loss': 0.5959982963791792, 'Total loss': 0.5959982963791792}
2023-01-04 07:17:58,444 INFO:     Found new best model at epoch 2
2023-01-04 07:17:58,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:17:58,444 INFO:     Epoch: 3
2023-01-04 07:18:00,057 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5255283276240031, 'Total loss': 0.5255283276240031} | train loss {'Reaction outcome loss': 0.5551596974238645, 'Total loss': 0.5551596974238645}
2023-01-04 07:18:00,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:00,057 INFO:     Epoch: 4
2023-01-04 07:18:01,690 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45897265871365867, 'Total loss': 0.45897265871365867} | train loss {'Reaction outcome loss': 0.5309558767096504, 'Total loss': 0.5309558767096504}
2023-01-04 07:18:01,691 INFO:     Found new best model at epoch 4
2023-01-04 07:18:01,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:01,692 INFO:     Epoch: 5
2023-01-04 07:18:03,301 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45514581302801765, 'Total loss': 0.45514581302801765} | train loss {'Reaction outcome loss': 0.5229522820184196, 'Total loss': 0.5229522820184196}
2023-01-04 07:18:03,301 INFO:     Found new best model at epoch 5
2023-01-04 07:18:03,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:03,302 INFO:     Epoch: 6
2023-01-04 07:18:04,812 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4550202389558156, 'Total loss': 0.4550202389558156} | train loss {'Reaction outcome loss': 0.5154726957173451, 'Total loss': 0.5154726957173451}
2023-01-04 07:18:04,812 INFO:     Found new best model at epoch 6
2023-01-04 07:18:04,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:04,813 INFO:     Epoch: 7
2023-01-04 07:18:06,423 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44168696403503416, 'Total loss': 0.44168696403503416} | train loss {'Reaction outcome loss': 0.4937413415797325, 'Total loss': 0.4937413415797325}
2023-01-04 07:18:06,423 INFO:     Found new best model at epoch 7
2023-01-04 07:18:06,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:06,424 INFO:     Epoch: 8
2023-01-04 07:18:08,054 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45945743719736737, 'Total loss': 0.45945743719736737} | train loss {'Reaction outcome loss': 0.48397623270453105, 'Total loss': 0.48397623270453105}
2023-01-04 07:18:08,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:08,054 INFO:     Epoch: 9
2023-01-04 07:18:09,688 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4110089123249054, 'Total loss': 0.4110089123249054} | train loss {'Reaction outcome loss': 0.4749919967658386, 'Total loss': 0.4749919967658386}
2023-01-04 07:18:09,688 INFO:     Found new best model at epoch 9
2023-01-04 07:18:09,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:09,689 INFO:     Epoch: 10
2023-01-04 07:18:11,319 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4266439974308014, 'Total loss': 0.4266439974308014} | train loss {'Reaction outcome loss': 0.4728465886428898, 'Total loss': 0.4728465886428898}
2023-01-04 07:18:11,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:11,319 INFO:     Epoch: 11
2023-01-04 07:18:12,905 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41730596820513405, 'Total loss': 0.41730596820513405} | train loss {'Reaction outcome loss': 0.46411289413331164, 'Total loss': 0.46411289413331164}
2023-01-04 07:18:12,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:12,905 INFO:     Epoch: 12
2023-01-04 07:18:14,443 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44169753591219585, 'Total loss': 0.44169753591219585} | train loss {'Reaction outcome loss': 0.4613955584675263, 'Total loss': 0.4613955584675263}
2023-01-04 07:18:14,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:14,443 INFO:     Epoch: 13
2023-01-04 07:18:15,995 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4118328879276911, 'Total loss': 0.4118328879276911} | train loss {'Reaction outcome loss': 0.4553693446290234, 'Total loss': 0.4553693446290234}
2023-01-04 07:18:15,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:15,995 INFO:     Epoch: 14
2023-01-04 07:18:17,538 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4105273216962814, 'Total loss': 0.4105273216962814} | train loss {'Reaction outcome loss': 0.45129720005206764, 'Total loss': 0.45129720005206764}
2023-01-04 07:18:17,538 INFO:     Found new best model at epoch 14
2023-01-04 07:18:17,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:17,539 INFO:     Epoch: 15
2023-01-04 07:18:19,093 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42594051559766133, 'Total loss': 0.42594051559766133} | train loss {'Reaction outcome loss': 0.4522669091820717, 'Total loss': 0.4522669091820717}
2023-01-04 07:18:19,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:19,095 INFO:     Epoch: 16
2023-01-04 07:18:20,646 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4059007316827774, 'Total loss': 0.4059007316827774} | train loss {'Reaction outcome loss': 0.46107608523553884, 'Total loss': 0.46107608523553884}
2023-01-04 07:18:20,646 INFO:     Found new best model at epoch 16
2023-01-04 07:18:20,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:20,647 INFO:     Epoch: 17
2023-01-04 07:18:22,171 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3958327134450277, 'Total loss': 0.3958327134450277} | train loss {'Reaction outcome loss': 0.44002824838178745, 'Total loss': 0.44002824838178745}
2023-01-04 07:18:22,171 INFO:     Found new best model at epoch 17
2023-01-04 07:18:22,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:22,172 INFO:     Epoch: 18
2023-01-04 07:18:23,681 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39964378078778584, 'Total loss': 0.39964378078778584} | train loss {'Reaction outcome loss': 0.43322691567194904, 'Total loss': 0.43322691567194904}
2023-01-04 07:18:23,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:23,681 INFO:     Epoch: 19
2023-01-04 07:18:25,227 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3996952255566915, 'Total loss': 0.3996952255566915} | train loss {'Reaction outcome loss': 0.4268784850187924, 'Total loss': 0.4268784850187924}
2023-01-04 07:18:25,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:25,228 INFO:     Epoch: 20
2023-01-04 07:18:26,765 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39068201382954915, 'Total loss': 0.39068201382954915} | train loss {'Reaction outcome loss': 0.42352073133477697, 'Total loss': 0.42352073133477697}
2023-01-04 07:18:26,765 INFO:     Found new best model at epoch 20
2023-01-04 07:18:26,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:26,766 INFO:     Epoch: 21
2023-01-04 07:18:28,308 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4164352873961131, 'Total loss': 0.4164352873961131} | train loss {'Reaction outcome loss': 0.41982522564670205, 'Total loss': 0.41982522564670205}
2023-01-04 07:18:28,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:28,308 INFO:     Epoch: 22
2023-01-04 07:18:29,850 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3766161719957987, 'Total loss': 0.3766161719957987} | train loss {'Reaction outcome loss': 0.41685675019803253, 'Total loss': 0.41685675019803253}
2023-01-04 07:18:29,850 INFO:     Found new best model at epoch 22
2023-01-04 07:18:29,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:29,851 INFO:     Epoch: 23
2023-01-04 07:18:31,365 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3833106497923533, 'Total loss': 0.3833106497923533} | train loss {'Reaction outcome loss': 0.41712539167939755, 'Total loss': 0.41712539167939755}
2023-01-04 07:18:31,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:31,365 INFO:     Epoch: 24
2023-01-04 07:18:32,878 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38696896433830263, 'Total loss': 0.38696896433830263} | train loss {'Reaction outcome loss': 0.42098552923973487, 'Total loss': 0.42098552923973487}
2023-01-04 07:18:32,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:32,878 INFO:     Epoch: 25
2023-01-04 07:18:34,426 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40670566260814667, 'Total loss': 0.40670566260814667} | train loss {'Reaction outcome loss': 0.4125676215018915, 'Total loss': 0.4125676215018915}
2023-01-04 07:18:34,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:34,427 INFO:     Epoch: 26
2023-01-04 07:18:35,973 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3725701093673706, 'Total loss': 0.3725701093673706} | train loss {'Reaction outcome loss': 0.4230956158099234, 'Total loss': 0.4230956158099234}
2023-01-04 07:18:35,973 INFO:     Found new best model at epoch 26
2023-01-04 07:18:35,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:35,974 INFO:     Epoch: 27
2023-01-04 07:18:37,514 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37266588111718496, 'Total loss': 0.37266588111718496} | train loss {'Reaction outcome loss': 0.4004567173188147, 'Total loss': 0.4004567173188147}
2023-01-04 07:18:37,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:37,515 INFO:     Epoch: 28
2023-01-04 07:18:39,064 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36850331823031107, 'Total loss': 0.36850331823031107} | train loss {'Reaction outcome loss': 0.4040720279250915, 'Total loss': 0.4040720279250915}
2023-01-04 07:18:39,064 INFO:     Found new best model at epoch 28
2023-01-04 07:18:39,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:39,065 INFO:     Epoch: 29
2023-01-04 07:18:40,605 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38756929139296215, 'Total loss': 0.38756929139296215} | train loss {'Reaction outcome loss': 0.3902751799720083, 'Total loss': 0.3902751799720083}
2023-01-04 07:18:40,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:40,605 INFO:     Epoch: 30
2023-01-04 07:18:42,131 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38160020808378853, 'Total loss': 0.38160020808378853} | train loss {'Reaction outcome loss': 0.3837619864291586, 'Total loss': 0.3837619864291586}
2023-01-04 07:18:42,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:42,131 INFO:     Epoch: 31
2023-01-04 07:18:43,706 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3684910813967387, 'Total loss': 0.3684910813967387} | train loss {'Reaction outcome loss': 0.384759214478528, 'Total loss': 0.384759214478528}
2023-01-04 07:18:43,706 INFO:     Found new best model at epoch 31
2023-01-04 07:18:43,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:43,707 INFO:     Epoch: 32
2023-01-04 07:18:45,296 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39516563614209493, 'Total loss': 0.39516563614209493} | train loss {'Reaction outcome loss': 0.3773223447640413, 'Total loss': 0.3773223447640413}
2023-01-04 07:18:45,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:45,296 INFO:     Epoch: 33
2023-01-04 07:18:46,883 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3616396466890971, 'Total loss': 0.3616396466890971} | train loss {'Reaction outcome loss': 0.3771223769509706, 'Total loss': 0.3771223769509706}
2023-01-04 07:18:46,883 INFO:     Found new best model at epoch 33
2023-01-04 07:18:46,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:46,884 INFO:     Epoch: 34
2023-01-04 07:18:48,433 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38262953559557594, 'Total loss': 0.38262953559557594} | train loss {'Reaction outcome loss': 0.3715583099646197, 'Total loss': 0.3715583099646197}
2023-01-04 07:18:48,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:48,433 INFO:     Epoch: 35
2023-01-04 07:18:49,962 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3700472344954809, 'Total loss': 0.3700472344954809} | train loss {'Reaction outcome loss': 0.3693388715737324, 'Total loss': 0.3693388715737324}
2023-01-04 07:18:49,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:49,962 INFO:     Epoch: 36
2023-01-04 07:18:51,525 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36403578221797944, 'Total loss': 0.36403578221797944} | train loss {'Reaction outcome loss': 0.36436413698222325, 'Total loss': 0.36436413698222325}
2023-01-04 07:18:51,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:51,525 INFO:     Epoch: 37
2023-01-04 07:18:53,102 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3603997011979421, 'Total loss': 0.3603997011979421} | train loss {'Reaction outcome loss': 0.3631348647582142, 'Total loss': 0.3631348647582142}
2023-01-04 07:18:53,102 INFO:     Found new best model at epoch 37
2023-01-04 07:18:53,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:53,103 INFO:     Epoch: 38
2023-01-04 07:18:54,687 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37996907035509747, 'Total loss': 0.37996907035509747} | train loss {'Reaction outcome loss': 0.3583423499413597, 'Total loss': 0.3583423499413597}
2023-01-04 07:18:54,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:54,688 INFO:     Epoch: 39
2023-01-04 07:18:56,246 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35953433911005656, 'Total loss': 0.35953433911005656} | train loss {'Reaction outcome loss': 0.35640685844734526, 'Total loss': 0.35640685844734526}
2023-01-04 07:18:56,246 INFO:     Found new best model at epoch 39
2023-01-04 07:18:56,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:56,247 INFO:     Epoch: 40
2023-01-04 07:18:57,782 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.34724307159582773, 'Total loss': 0.34724307159582773} | train loss {'Reaction outcome loss': 0.3573485743726833, 'Total loss': 0.3573485743726833}
2023-01-04 07:18:57,782 INFO:     Found new best model at epoch 40
2023-01-04 07:18:57,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:57,783 INFO:     Epoch: 41
2023-01-04 07:18:59,276 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3589981238047282, 'Total loss': 0.3589981238047282} | train loss {'Reaction outcome loss': 0.3456298538308213, 'Total loss': 0.3456298538308213}
2023-01-04 07:18:59,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:18:59,276 INFO:     Epoch: 42
2023-01-04 07:19:00,827 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35465791722138723, 'Total loss': 0.35465791722138723} | train loss {'Reaction outcome loss': 0.34895145177733206, 'Total loss': 0.34895145177733206}
2023-01-04 07:19:00,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:00,828 INFO:     Epoch: 43
2023-01-04 07:19:02,379 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34887987077236177, 'Total loss': 0.34887987077236177} | train loss {'Reaction outcome loss': 0.3565394185679379, 'Total loss': 0.3565394185679379}
2023-01-04 07:19:02,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:02,379 INFO:     Epoch: 44
2023-01-04 07:19:03,923 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3396518071492513, 'Total loss': 0.3396518071492513} | train loss {'Reaction outcome loss': 0.3444074976284975, 'Total loss': 0.3444074976284975}
2023-01-04 07:19:03,923 INFO:     Found new best model at epoch 44
2023-01-04 07:19:03,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:03,924 INFO:     Epoch: 45
2023-01-04 07:19:05,501 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3366364190975825, 'Total loss': 0.3366364190975825} | train loss {'Reaction outcome loss': 0.3378453632138427, 'Total loss': 0.3378453632138427}
2023-01-04 07:19:05,502 INFO:     Found new best model at epoch 45
2023-01-04 07:19:05,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:05,502 INFO:     Epoch: 46
2023-01-04 07:19:07,029 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3657393574714661, 'Total loss': 0.3657393574714661} | train loss {'Reaction outcome loss': 0.3353061940642479, 'Total loss': 0.3353061940642479}
2023-01-04 07:19:07,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:07,030 INFO:     Epoch: 47
2023-01-04 07:19:08,552 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3548251211643219, 'Total loss': 0.3548251211643219} | train loss {'Reaction outcome loss': 0.33473881307071535, 'Total loss': 0.33473881307071535}
2023-01-04 07:19:08,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:08,552 INFO:     Epoch: 48
2023-01-04 07:19:10,107 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3518382638692856, 'Total loss': 0.3518382638692856} | train loss {'Reaction outcome loss': 0.335152481081963, 'Total loss': 0.335152481081963}
2023-01-04 07:19:10,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:10,107 INFO:     Epoch: 49
2023-01-04 07:19:11,656 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3442140499750773, 'Total loss': 0.3442140499750773} | train loss {'Reaction outcome loss': 0.33112453355494403, 'Total loss': 0.33112453355494403}
2023-01-04 07:19:11,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:11,656 INFO:     Epoch: 50
2023-01-04 07:19:13,216 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3383368730545044, 'Total loss': 0.3383368730545044} | train loss {'Reaction outcome loss': 0.3291593708799801, 'Total loss': 0.3291593708799801}
2023-01-04 07:19:13,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:13,217 INFO:     Epoch: 51
2023-01-04 07:19:14,764 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.33345984121163685, 'Total loss': 0.33345984121163685} | train loss {'Reaction outcome loss': 0.32693299203031306, 'Total loss': 0.32693299203031306}
2023-01-04 07:19:14,764 INFO:     Found new best model at epoch 51
2023-01-04 07:19:14,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:14,765 INFO:     Epoch: 52
2023-01-04 07:19:16,290 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36694814761479694, 'Total loss': 0.36694814761479694} | train loss {'Reaction outcome loss': 0.33038159071103385, 'Total loss': 0.33038159071103385}
2023-01-04 07:19:16,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:16,291 INFO:     Epoch: 53
2023-01-04 07:19:17,814 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.34989407608906425, 'Total loss': 0.34989407608906425} | train loss {'Reaction outcome loss': 0.3233760933010448, 'Total loss': 0.3233760933010448}
2023-01-04 07:19:17,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:17,814 INFO:     Epoch: 54
2023-01-04 07:19:19,365 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3502801418304443, 'Total loss': 0.3502801418304443} | train loss {'Reaction outcome loss': 0.31975548088751343, 'Total loss': 0.31975548088751343}
2023-01-04 07:19:19,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:19,365 INFO:     Epoch: 55
2023-01-04 07:19:20,926 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3475917289654414, 'Total loss': 0.3475917289654414} | train loss {'Reaction outcome loss': 0.3188593471760227, 'Total loss': 0.3188593471760227}
2023-01-04 07:19:20,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:20,926 INFO:     Epoch: 56
2023-01-04 07:19:22,483 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3246148814757665, 'Total loss': 0.3246148814757665} | train loss {'Reaction outcome loss': 0.3229978602055622, 'Total loss': 0.3229978602055622}
2023-01-04 07:19:22,484 INFO:     Found new best model at epoch 56
2023-01-04 07:19:22,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:22,484 INFO:     Epoch: 57
2023-01-04 07:19:24,034 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.33668041924635567, 'Total loss': 0.33668041924635567} | train loss {'Reaction outcome loss': 0.3146613547038557, 'Total loss': 0.3146613547038557}
2023-01-04 07:19:24,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:24,035 INFO:     Epoch: 58
2023-01-04 07:19:25,559 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36551095644632975, 'Total loss': 0.36551095644632975} | train loss {'Reaction outcome loss': 0.311699413233947, 'Total loss': 0.311699413233947}
2023-01-04 07:19:25,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:25,560 INFO:     Epoch: 59
2023-01-04 07:19:27,076 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35694340070088704, 'Total loss': 0.35694340070088704} | train loss {'Reaction outcome loss': 0.31102395312189113, 'Total loss': 0.31102395312189113}
2023-01-04 07:19:27,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:27,076 INFO:     Epoch: 60
2023-01-04 07:19:28,619 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35015076994895933, 'Total loss': 0.35015076994895933} | train loss {'Reaction outcome loss': 0.31637510438652144, 'Total loss': 0.31637510438652144}
2023-01-04 07:19:28,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:28,619 INFO:     Epoch: 61
2023-01-04 07:19:30,169 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.33011111815770466, 'Total loss': 0.33011111815770466} | train loss {'Reaction outcome loss': 0.3452846917586968, 'Total loss': 0.3452846917586968}
2023-01-04 07:19:30,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:30,170 INFO:     Epoch: 62
2023-01-04 07:19:31,728 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3133641575773557, 'Total loss': 0.3133641575773557} | train loss {'Reaction outcome loss': 0.3101716619136784, 'Total loss': 0.3101716619136784}
2023-01-04 07:19:31,728 INFO:     Found new best model at epoch 62
2023-01-04 07:19:31,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:31,729 INFO:     Epoch: 63
2023-01-04 07:19:33,284 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35195688605308534, 'Total loss': 0.35195688605308534} | train loss {'Reaction outcome loss': 0.3049499677811358, 'Total loss': 0.3049499677811358}
2023-01-04 07:19:33,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:33,285 INFO:     Epoch: 64
2023-01-04 07:19:34,824 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3437064876159032, 'Total loss': 0.3437064876159032} | train loss {'Reaction outcome loss': 0.3009990310107452, 'Total loss': 0.3009990310107452}
2023-01-04 07:19:34,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:34,824 INFO:     Epoch: 65
2023-01-04 07:19:36,356 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3376945386330287, 'Total loss': 0.3376945386330287} | train loss {'Reaction outcome loss': 0.3093383285517305, 'Total loss': 0.3093383285517305}
2023-01-04 07:19:36,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:36,357 INFO:     Epoch: 66
2023-01-04 07:19:37,920 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3510029226541519, 'Total loss': 0.3510029226541519} | train loss {'Reaction outcome loss': 0.2999245609811413, 'Total loss': 0.2999245609811413}
2023-01-04 07:19:37,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:37,921 INFO:     Epoch: 67
2023-01-04 07:19:39,475 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.317290590206782, 'Total loss': 0.317290590206782} | train loss {'Reaction outcome loss': 0.30283245854197827, 'Total loss': 0.30283245854197827}
2023-01-04 07:19:39,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:39,475 INFO:     Epoch: 68
2023-01-04 07:19:41,038 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35264496703942616, 'Total loss': 0.35264496703942616} | train loss {'Reaction outcome loss': 0.2973310672340618, 'Total loss': 0.2973310672340618}
2023-01-04 07:19:41,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:41,038 INFO:     Epoch: 69
2023-01-04 07:19:42,595 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.33608220318953197, 'Total loss': 0.33608220318953197} | train loss {'Reaction outcome loss': 0.30145973807700194, 'Total loss': 0.30145973807700194}
2023-01-04 07:19:42,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:42,595 INFO:     Epoch: 70
2023-01-04 07:19:44,126 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3433142731587092, 'Total loss': 0.3433142731587092} | train loss {'Reaction outcome loss': 0.3015292743085951, 'Total loss': 0.3015292743085951}
2023-01-04 07:19:44,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:44,127 INFO:     Epoch: 71
2023-01-04 07:19:45,663 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.33717026114463805, 'Total loss': 0.33717026114463805} | train loss {'Reaction outcome loss': 0.2989060270281144, 'Total loss': 0.2989060270281144}
2023-01-04 07:19:45,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:45,664 INFO:     Epoch: 72
2023-01-04 07:19:47,264 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.326131871342659, 'Total loss': 0.326131871342659} | train loss {'Reaction outcome loss': 0.2918899834983749, 'Total loss': 0.2918899834983749}
2023-01-04 07:19:47,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:47,265 INFO:     Epoch: 73
2023-01-04 07:19:48,853 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3436717470486959, 'Total loss': 0.3436717470486959} | train loss {'Reaction outcome loss': 0.2904983994119085, 'Total loss': 0.2904983994119085}
2023-01-04 07:19:48,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:48,854 INFO:     Epoch: 74
2023-01-04 07:19:50,445 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3323913226524989, 'Total loss': 0.3323913226524989} | train loss {'Reaction outcome loss': 0.29218165727629175, 'Total loss': 0.29218165727629175}
2023-01-04 07:19:50,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:50,446 INFO:     Epoch: 75
2023-01-04 07:19:52,044 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3383546238144239, 'Total loss': 0.3383546238144239} | train loss {'Reaction outcome loss': 0.29847323504425044, 'Total loss': 0.29847323504425044}
2023-01-04 07:19:52,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:52,045 INFO:     Epoch: 76
2023-01-04 07:19:53,620 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.322482851644357, 'Total loss': 0.322482851644357} | train loss {'Reaction outcome loss': 0.29780334199144354, 'Total loss': 0.29780334199144354}
2023-01-04 07:19:53,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:53,620 INFO:     Epoch: 77
2023-01-04 07:19:55,150 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36365053951740267, 'Total loss': 0.36365053951740267} | train loss {'Reaction outcome loss': 0.31375503028823953, 'Total loss': 0.31375503028823953}
2023-01-04 07:19:55,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:55,151 INFO:     Epoch: 78
2023-01-04 07:19:56,739 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3343041370312373, 'Total loss': 0.3343041370312373} | train loss {'Reaction outcome loss': 0.28837364672453725, 'Total loss': 0.28837364672453725}
2023-01-04 07:19:56,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:56,740 INFO:     Epoch: 79
2023-01-04 07:19:58,336 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.33966004351774853, 'Total loss': 0.33966004351774853} | train loss {'Reaction outcome loss': 0.2959494753317088, 'Total loss': 0.2959494753317088}
2023-01-04 07:19:58,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:58,336 INFO:     Epoch: 80
2023-01-04 07:19:59,939 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.32809604207674664, 'Total loss': 0.32809604207674664} | train loss {'Reaction outcome loss': 0.283890722045739, 'Total loss': 0.283890722045739}
2023-01-04 07:19:59,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:19:59,939 INFO:     Epoch: 81
2023-01-04 07:20:01,530 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3486818879842758, 'Total loss': 0.3486818879842758} | train loss {'Reaction outcome loss': 0.28309987280247867, 'Total loss': 0.28309987280247867}
2023-01-04 07:20:01,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:01,531 INFO:     Epoch: 82
2023-01-04 07:20:03,042 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.32865734497706095, 'Total loss': 0.32865734497706095} | train loss {'Reaction outcome loss': 0.2818273575972273, 'Total loss': 0.2818273575972273}
2023-01-04 07:20:03,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:03,043 INFO:     Epoch: 83
2023-01-04 07:20:04,602 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.33281395534674324, 'Total loss': 0.33281395534674324} | train loss {'Reaction outcome loss': 0.2812194762041738, 'Total loss': 0.2812194762041738}
2023-01-04 07:20:04,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:04,602 INFO:     Epoch: 84
2023-01-04 07:20:06,177 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3397763818502426, 'Total loss': 0.3397763818502426} | train loss {'Reaction outcome loss': 0.27898445699711505, 'Total loss': 0.27898445699711505}
2023-01-04 07:20:06,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:06,177 INFO:     Epoch: 85
2023-01-04 07:20:07,788 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33766179382801054, 'Total loss': 0.33766179382801054} | train loss {'Reaction outcome loss': 0.28089199452728464, 'Total loss': 0.28089199452728464}
2023-01-04 07:20:07,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:07,789 INFO:     Epoch: 86
2023-01-04 07:20:09,371 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34372150103251137, 'Total loss': 0.34372150103251137} | train loss {'Reaction outcome loss': 0.288036885826538, 'Total loss': 0.288036885826538}
2023-01-04 07:20:09,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:09,372 INFO:     Epoch: 87
2023-01-04 07:20:10,952 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33161047101020813, 'Total loss': 0.33161047101020813} | train loss {'Reaction outcome loss': 0.2750462029103089, 'Total loss': 0.2750462029103089}
2023-01-04 07:20:10,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:10,952 INFO:     Epoch: 88
2023-01-04 07:20:12,486 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.32411664923032124, 'Total loss': 0.32411664923032124} | train loss {'Reaction outcome loss': 0.2771541095506214, 'Total loss': 0.2771541095506214}
2023-01-04 07:20:12,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:12,487 INFO:     Epoch: 89
2023-01-04 07:20:14,092 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3326481690009435, 'Total loss': 0.3326481690009435} | train loss {'Reaction outcome loss': 0.2762289319889269, 'Total loss': 0.2762289319889269}
2023-01-04 07:20:14,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:14,092 INFO:     Epoch: 90
2023-01-04 07:20:15,683 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3278007437785467, 'Total loss': 0.3278007437785467} | train loss {'Reaction outcome loss': 0.2859154513858232, 'Total loss': 0.2859154513858232}
2023-01-04 07:20:15,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:15,684 INFO:     Epoch: 91
2023-01-04 07:20:17,258 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3119789580504099, 'Total loss': 0.3119789580504099} | train loss {'Reaction outcome loss': 0.27695871232941316, 'Total loss': 0.27695871232941316}
2023-01-04 07:20:17,258 INFO:     Found new best model at epoch 91
2023-01-04 07:20:17,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:17,259 INFO:     Epoch: 92
2023-01-04 07:20:18,825 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3335142552852631, 'Total loss': 0.3335142552852631} | train loss {'Reaction outcome loss': 0.2727028465478856, 'Total loss': 0.2727028465478856}
2023-01-04 07:20:18,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:18,825 INFO:     Epoch: 93
2023-01-04 07:20:20,373 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34933603505293526, 'Total loss': 0.34933603505293526} | train loss {'Reaction outcome loss': 0.27254591885592666, 'Total loss': 0.27254591885592666}
2023-01-04 07:20:20,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:20,374 INFO:     Epoch: 94
2023-01-04 07:20:21,925 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.34634935756524404, 'Total loss': 0.34634935756524404} | train loss {'Reaction outcome loss': 0.2787451538918675, 'Total loss': 0.2787451538918675}
2023-01-04 07:20:21,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:21,925 INFO:     Epoch: 95
2023-01-04 07:20:23,501 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3364774356285731, 'Total loss': 0.3364774356285731} | train loss {'Reaction outcome loss': 0.3007403623947091, 'Total loss': 0.3007403623947091}
2023-01-04 07:20:23,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:23,501 INFO:     Epoch: 96
2023-01-04 07:20:25,075 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3282959709564845, 'Total loss': 0.3282959709564845} | train loss {'Reaction outcome loss': 0.2726710817828923, 'Total loss': 0.2726710817828923}
2023-01-04 07:20:25,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:25,075 INFO:     Epoch: 97
2023-01-04 07:20:26,681 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3354222516218821, 'Total loss': 0.3354222516218821} | train loss {'Reaction outcome loss': 0.2701257624196486, 'Total loss': 0.2701257624196486}
2023-01-04 07:20:26,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:26,682 INFO:     Epoch: 98
2023-01-04 07:20:28,251 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.32805510858694714, 'Total loss': 0.32805510858694714} | train loss {'Reaction outcome loss': 0.2687250681848272, 'Total loss': 0.2687250681848272}
2023-01-04 07:20:28,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:28,251 INFO:     Epoch: 99
2023-01-04 07:20:29,788 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3302335689465205, 'Total loss': 0.3302335689465205} | train loss {'Reaction outcome loss': 0.2651875107000798, 'Total loss': 0.2651875107000798}
2023-01-04 07:20:29,788 INFO:     Best model found after epoch 92 of 100.
2023-01-04 07:20:29,788 INFO:   Done with stage: TRAINING
2023-01-04 07:20:29,788 INFO:   Starting stage: EVALUATION
2023-01-04 07:20:29,914 INFO:   Done with stage: EVALUATION
2023-01-04 07:20:29,922 INFO:   Leaving out SEQ value Fold_0
2023-01-04 07:20:29,935 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:20:29,935 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:20:30,572 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:20:30,572 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:20:30,641 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:20:30,641 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:20:30,641 INFO:     No hyperparam tuning for this model
2023-01-04 07:20:30,641 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:20:30,641 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:20:30,642 INFO:     None feature selector for col prot
2023-01-04 07:20:30,642 INFO:     None feature selector for col prot
2023-01-04 07:20:30,642 INFO:     None feature selector for col prot
2023-01-04 07:20:30,642 INFO:     None feature selector for col chem
2023-01-04 07:20:30,642 INFO:     None feature selector for col chem
2023-01-04 07:20:30,643 INFO:     None feature selector for col chem
2023-01-04 07:20:30,643 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:20:30,643 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:20:30,644 INFO:     Number of params in model 70111
2023-01-04 07:20:30,647 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:20:30,647 INFO:   Starting stage: TRAINING
2023-01-04 07:20:30,689 INFO:     Val loss before train {'Reaction outcome loss': 1.0772900740305582, 'Total loss': 1.0772900740305582}
2023-01-04 07:20:30,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:30,689 INFO:     Epoch: 0
2023-01-04 07:20:32,249 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7471868892510732, 'Total loss': 0.7471868892510732} | train loss {'Reaction outcome loss': 0.831557742819406, 'Total loss': 0.831557742819406}
2023-01-04 07:20:32,249 INFO:     Found new best model at epoch 0
2023-01-04 07:20:32,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:32,250 INFO:     Epoch: 1
2023-01-04 07:20:33,832 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6099115431308746, 'Total loss': 0.6099115431308746} | train loss {'Reaction outcome loss': 0.6618544229114786, 'Total loss': 0.6618544229114786}
2023-01-04 07:20:33,832 INFO:     Found new best model at epoch 1
2023-01-04 07:20:33,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:33,833 INFO:     Epoch: 2
2023-01-04 07:20:35,396 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5596430798371633, 'Total loss': 0.5596430798371633} | train loss {'Reaction outcome loss': 0.5803681843809908, 'Total loss': 0.5803681843809908}
2023-01-04 07:20:35,396 INFO:     Found new best model at epoch 2
2023-01-04 07:20:35,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:35,396 INFO:     Epoch: 3
2023-01-04 07:20:36,952 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5330467005570729, 'Total loss': 0.5330467005570729} | train loss {'Reaction outcome loss': 0.5435846810215625, 'Total loss': 0.5435846810215625}
2023-01-04 07:20:36,953 INFO:     Found new best model at epoch 3
2023-01-04 07:20:36,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:36,954 INFO:     Epoch: 4
2023-01-04 07:20:38,473 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5144184738397598, 'Total loss': 0.5144184738397598} | train loss {'Reaction outcome loss': 0.5222978349032718, 'Total loss': 0.5222978349032718}
2023-01-04 07:20:38,473 INFO:     Found new best model at epoch 4
2023-01-04 07:20:38,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:38,474 INFO:     Epoch: 5
2023-01-04 07:20:39,672 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5060814062754313, 'Total loss': 0.5060814062754313} | train loss {'Reaction outcome loss': 0.5057262369580027, 'Total loss': 0.5057262369580027}
2023-01-04 07:20:39,672 INFO:     Found new best model at epoch 5
2023-01-04 07:20:39,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:39,673 INFO:     Epoch: 6
2023-01-04 07:20:40,700 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.51797762910525, 'Total loss': 0.51797762910525} | train loss {'Reaction outcome loss': 0.5068264467223291, 'Total loss': 0.5068264467223291}
2023-01-04 07:20:40,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:40,700 INFO:     Epoch: 7
2023-01-04 07:20:41,722 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4896081745624542, 'Total loss': 0.4896081745624542} | train loss {'Reaction outcome loss': 0.509319734044265, 'Total loss': 0.509319734044265}
2023-01-04 07:20:41,722 INFO:     Found new best model at epoch 7
2023-01-04 07:20:41,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:41,723 INFO:     Epoch: 8
2023-01-04 07:20:42,748 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47811126013596855, 'Total loss': 0.47811126013596855} | train loss {'Reaction outcome loss': 0.4843302511650583, 'Total loss': 0.4843302511650583}
2023-01-04 07:20:42,748 INFO:     Found new best model at epoch 8
2023-01-04 07:20:42,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:42,749 INFO:     Epoch: 9
2023-01-04 07:20:43,867 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.467225972811381, 'Total loss': 0.467225972811381} | train loss {'Reaction outcome loss': 0.4807603960667831, 'Total loss': 0.4807603960667831}
2023-01-04 07:20:43,868 INFO:     Found new best model at epoch 9
2023-01-04 07:20:43,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:43,869 INFO:     Epoch: 10
2023-01-04 07:20:45,422 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46809364557266236, 'Total loss': 0.46809364557266236} | train loss {'Reaction outcome loss': 0.46425170689969714, 'Total loss': 0.46425170689969714}
2023-01-04 07:20:45,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:45,423 INFO:     Epoch: 11
2023-01-04 07:20:47,015 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4754040718078613, 'Total loss': 0.4754040718078613} | train loss {'Reaction outcome loss': 0.45815614789751347, 'Total loss': 0.45815614789751347}
2023-01-04 07:20:47,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:47,015 INFO:     Epoch: 12
2023-01-04 07:20:48,588 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47145261665185295, 'Total loss': 0.47145261665185295} | train loss {'Reaction outcome loss': 0.45402658281892544, 'Total loss': 0.45402658281892544}
2023-01-04 07:20:48,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:48,589 INFO:     Epoch: 13
2023-01-04 07:20:50,164 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5203139066696167, 'Total loss': 0.5203139066696167} | train loss {'Reaction outcome loss': 0.45291635277356795, 'Total loss': 0.45291635277356795}
2023-01-04 07:20:50,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:50,164 INFO:     Epoch: 14
2023-01-04 07:20:51,733 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43565786480903623, 'Total loss': 0.43565786480903623} | train loss {'Reaction outcome loss': 0.44467420564910426, 'Total loss': 0.44467420564910426}
2023-01-04 07:20:51,733 INFO:     Found new best model at epoch 14
2023-01-04 07:20:51,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:51,734 INFO:     Epoch: 15
2023-01-04 07:20:53,269 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4504020700852076, 'Total loss': 0.4504020700852076} | train loss {'Reaction outcome loss': 0.4410692700252369, 'Total loss': 0.4410692700252369}
2023-01-04 07:20:53,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:53,270 INFO:     Epoch: 16
2023-01-04 07:20:54,795 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45523320833841957, 'Total loss': 0.45523320833841957} | train loss {'Reaction outcome loss': 0.4399408099875934, 'Total loss': 0.4399408099875934}
2023-01-04 07:20:54,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:54,795 INFO:     Epoch: 17
2023-01-04 07:20:56,352 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42789669235547384, 'Total loss': 0.42789669235547384} | train loss {'Reaction outcome loss': 0.43825355135629873, 'Total loss': 0.43825355135629873}
2023-01-04 07:20:56,353 INFO:     Found new best model at epoch 17
2023-01-04 07:20:56,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:56,354 INFO:     Epoch: 18
2023-01-04 07:20:57,908 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4451641043027242, 'Total loss': 0.4451641043027242} | train loss {'Reaction outcome loss': 0.4263305495209668, 'Total loss': 0.4263305495209668}
2023-01-04 07:20:57,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:57,909 INFO:     Epoch: 19
2023-01-04 07:20:59,498 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4274178793032964, 'Total loss': 0.4274178793032964} | train loss {'Reaction outcome loss': 0.42286230515953543, 'Total loss': 0.42286230515953543}
2023-01-04 07:20:59,498 INFO:     Found new best model at epoch 19
2023-01-04 07:20:59,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:20:59,499 INFO:     Epoch: 20
2023-01-04 07:21:01,074 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45514091749986013, 'Total loss': 0.45514091749986013} | train loss {'Reaction outcome loss': 0.41669203431440005, 'Total loss': 0.41669203431440005}
2023-01-04 07:21:01,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:01,074 INFO:     Epoch: 21
2023-01-04 07:21:02,594 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4535709549983343, 'Total loss': 0.4535709549983343} | train loss {'Reaction outcome loss': 0.41293885135024355, 'Total loss': 0.41293885135024355}
2023-01-04 07:21:02,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:02,594 INFO:     Epoch: 22
2023-01-04 07:21:04,132 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4230886737505595, 'Total loss': 0.4230886737505595} | train loss {'Reaction outcome loss': 0.41477398504165636, 'Total loss': 0.41477398504165636}
2023-01-04 07:21:04,133 INFO:     Found new best model at epoch 22
2023-01-04 07:21:04,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:04,133 INFO:     Epoch: 23
2023-01-04 07:21:05,697 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4266660749912262, 'Total loss': 0.4266660749912262} | train loss {'Reaction outcome loss': 0.41693022436853766, 'Total loss': 0.41693022436853766}
2023-01-04 07:21:05,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:05,697 INFO:     Epoch: 24
2023-01-04 07:21:07,264 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4428082446257273, 'Total loss': 0.4428082446257273} | train loss {'Reaction outcome loss': 0.4261722531223643, 'Total loss': 0.4261722531223643}
2023-01-04 07:21:07,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:07,264 INFO:     Epoch: 25
2023-01-04 07:21:08,815 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42260852456092834, 'Total loss': 0.42260852456092834} | train loss {'Reaction outcome loss': 0.40600350620629994, 'Total loss': 0.40600350620629994}
2023-01-04 07:21:08,815 INFO:     Found new best model at epoch 25
2023-01-04 07:21:08,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:08,816 INFO:     Epoch: 26
2023-01-04 07:21:10,382 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4351589411497116, 'Total loss': 0.4351589411497116} | train loss {'Reaction outcome loss': 0.40220131638689316, 'Total loss': 0.40220131638689316}
2023-01-04 07:21:10,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:10,382 INFO:     Epoch: 27
2023-01-04 07:21:11,874 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43668486873308815, 'Total loss': 0.43668486873308815} | train loss {'Reaction outcome loss': 0.3967771215441947, 'Total loss': 0.3967771215441947}
2023-01-04 07:21:11,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:11,874 INFO:     Epoch: 28
2023-01-04 07:21:13,498 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4497425218423208, 'Total loss': 0.4497425218423208} | train loss {'Reaction outcome loss': 0.3945341034373943, 'Total loss': 0.3945341034373943}
2023-01-04 07:21:13,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:13,499 INFO:     Epoch: 29
2023-01-04 07:21:15,132 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.419707848628362, 'Total loss': 0.419707848628362} | train loss {'Reaction outcome loss': 0.38664195255420264, 'Total loss': 0.38664195255420264}
2023-01-04 07:21:15,132 INFO:     Found new best model at epoch 29
2023-01-04 07:21:15,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:15,133 INFO:     Epoch: 30
2023-01-04 07:21:16,756 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4450640181700389, 'Total loss': 0.4450640181700389} | train loss {'Reaction outcome loss': 0.38650209067787544, 'Total loss': 0.38650209067787544}
2023-01-04 07:21:16,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:16,756 INFO:     Epoch: 31
2023-01-04 07:21:18,392 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44145655433336894, 'Total loss': 0.44145655433336894} | train loss {'Reaction outcome loss': 0.3821603366430255, 'Total loss': 0.3821603366430255}
2023-01-04 07:21:18,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:18,392 INFO:     Epoch: 32
2023-01-04 07:21:20,028 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46095864673455555, 'Total loss': 0.46095864673455555} | train loss {'Reaction outcome loss': 0.3766602871912545, 'Total loss': 0.3766602871912545}
2023-01-04 07:21:20,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:20,029 INFO:     Epoch: 33
2023-01-04 07:21:21,562 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4044446935256322, 'Total loss': 0.4044446935256322} | train loss {'Reaction outcome loss': 0.37593808829568437, 'Total loss': 0.37593808829568437}
2023-01-04 07:21:21,562 INFO:     Found new best model at epoch 33
2023-01-04 07:21:21,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:21,563 INFO:     Epoch: 34
2023-01-04 07:21:23,189 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45435735682646433, 'Total loss': 0.45435735682646433} | train loss {'Reaction outcome loss': 0.3708620013642138, 'Total loss': 0.3708620013642138}
2023-01-04 07:21:23,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:23,189 INFO:     Epoch: 35
2023-01-04 07:21:24,817 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41224979956944785, 'Total loss': 0.41224979956944785} | train loss {'Reaction outcome loss': 0.38566738886562973, 'Total loss': 0.38566738886562973}
2023-01-04 07:21:24,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:24,817 INFO:     Epoch: 36
2023-01-04 07:21:26,452 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4298319230477015, 'Total loss': 0.4298319230477015} | train loss {'Reaction outcome loss': 0.3605334956398861, 'Total loss': 0.3605334956398861}
2023-01-04 07:21:26,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:26,452 INFO:     Epoch: 37
2023-01-04 07:21:28,079 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40208538820346196, 'Total loss': 0.40208538820346196} | train loss {'Reaction outcome loss': 0.36087724098098883, 'Total loss': 0.36087724098098883}
2023-01-04 07:21:28,079 INFO:     Found new best model at epoch 37
2023-01-04 07:21:28,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:28,080 INFO:     Epoch: 38
2023-01-04 07:21:29,620 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4031301915645599, 'Total loss': 0.4031301915645599} | train loss {'Reaction outcome loss': 0.3532777886272292, 'Total loss': 0.3532777886272292}
2023-01-04 07:21:29,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:29,620 INFO:     Epoch: 39
2023-01-04 07:21:31,178 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4231477876504262, 'Total loss': 0.4231477876504262} | train loss {'Reaction outcome loss': 0.3479664938227422, 'Total loss': 0.3479664938227422}
2023-01-04 07:21:31,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:31,179 INFO:     Epoch: 40
2023-01-04 07:21:32,755 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4059734712044398, 'Total loss': 0.4059734712044398} | train loss {'Reaction outcome loss': 0.34760603912012733, 'Total loss': 0.34760603912012733}
2023-01-04 07:21:32,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:32,756 INFO:     Epoch: 41
2023-01-04 07:21:34,337 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4015913546085358, 'Total loss': 0.4015913546085358} | train loss {'Reaction outcome loss': 0.3425263505685481, 'Total loss': 0.3425263505685481}
2023-01-04 07:21:34,337 INFO:     Found new best model at epoch 41
2023-01-04 07:21:34,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:34,338 INFO:     Epoch: 42
2023-01-04 07:21:35,900 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4035950432221095, 'Total loss': 0.4035950432221095} | train loss {'Reaction outcome loss': 0.3426095476994912, 'Total loss': 0.3426095476994912}
2023-01-04 07:21:35,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:35,901 INFO:     Epoch: 43
2023-01-04 07:21:37,472 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44401945372422535, 'Total loss': 0.44401945372422535} | train loss {'Reaction outcome loss': 0.34594051224058087, 'Total loss': 0.34594051224058087}
2023-01-04 07:21:37,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:37,472 INFO:     Epoch: 44
2023-01-04 07:21:39,019 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4219702839851379, 'Total loss': 0.4219702839851379} | train loss {'Reaction outcome loss': 0.3318234109041362, 'Total loss': 0.3318234109041362}
2023-01-04 07:21:39,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:39,019 INFO:     Epoch: 45
2023-01-04 07:21:40,555 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4172193785508474, 'Total loss': 0.4172193785508474} | train loss {'Reaction outcome loss': 0.33389656619840313, 'Total loss': 0.33389656619840313}
2023-01-04 07:21:40,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:40,555 INFO:     Epoch: 46
2023-01-04 07:21:42,139 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42578553160031635, 'Total loss': 0.42578553160031635} | train loss {'Reaction outcome loss': 0.3255422888094841, 'Total loss': 0.3255422888094841}
2023-01-04 07:21:42,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:42,139 INFO:     Epoch: 47
2023-01-04 07:21:43,730 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3761577904224396, 'Total loss': 0.3761577904224396} | train loss {'Reaction outcome loss': 0.3233753730866896, 'Total loss': 0.3233753730866896}
2023-01-04 07:21:43,730 INFO:     Found new best model at epoch 47
2023-01-04 07:21:43,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:43,731 INFO:     Epoch: 48
2023-01-04 07:21:45,306 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41474006573359173, 'Total loss': 0.41474006573359173} | train loss {'Reaction outcome loss': 0.32465417471299274, 'Total loss': 0.32465417471299274}
2023-01-04 07:21:45,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:45,306 INFO:     Epoch: 49
2023-01-04 07:21:46,915 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3867204189300537, 'Total loss': 0.3867204189300537} | train loss {'Reaction outcome loss': 0.31621697736461984, 'Total loss': 0.31621697736461984}
2023-01-04 07:21:46,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:46,916 INFO:     Epoch: 50
2023-01-04 07:21:48,413 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3907819310824076, 'Total loss': 0.3907819310824076} | train loss {'Reaction outcome loss': 0.31187862150735507, 'Total loss': 0.31187862150735507}
2023-01-04 07:21:48,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:48,414 INFO:     Epoch: 51
2023-01-04 07:21:49,971 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3948115274310112, 'Total loss': 0.3948115274310112} | train loss {'Reaction outcome loss': 0.31271591216099676, 'Total loss': 0.31271591216099676}
2023-01-04 07:21:49,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:49,971 INFO:     Epoch: 52
2023-01-04 07:21:51,560 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38876592690745987, 'Total loss': 0.38876592690745987} | train loss {'Reaction outcome loss': 0.31072191327162413, 'Total loss': 0.31072191327162413}
2023-01-04 07:21:51,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:51,560 INFO:     Epoch: 53
2023-01-04 07:21:53,134 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39593335092067716, 'Total loss': 0.39593335092067716} | train loss {'Reaction outcome loss': 0.31417788829708443, 'Total loss': 0.31417788829708443}
2023-01-04 07:21:53,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:53,134 INFO:     Epoch: 54
2023-01-04 07:21:54,720 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42258465190728506, 'Total loss': 0.42258465190728506} | train loss {'Reaction outcome loss': 0.31472821825224423, 'Total loss': 0.31472821825224423}
2023-01-04 07:21:54,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:54,721 INFO:     Epoch: 55
2023-01-04 07:21:56,306 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.409830304980278, 'Total loss': 0.409830304980278} | train loss {'Reaction outcome loss': 0.3087944926106169, 'Total loss': 0.3087944926106169}
2023-01-04 07:21:56,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:56,307 INFO:     Epoch: 56
2023-01-04 07:21:57,838 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41310794750849406, 'Total loss': 0.41310794750849406} | train loss {'Reaction outcome loss': 0.3031518840748965, 'Total loss': 0.3031518840748965}
2023-01-04 07:21:57,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:57,838 INFO:     Epoch: 57
2023-01-04 07:21:59,435 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42357866168022157, 'Total loss': 0.42357866168022157} | train loss {'Reaction outcome loss': 0.3003543351753277, 'Total loss': 0.3003543351753277}
2023-01-04 07:21:59,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:21:59,435 INFO:     Epoch: 58
2023-01-04 07:22:01,026 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3838037490844727, 'Total loss': 0.3838037490844727} | train loss {'Reaction outcome loss': 0.3037536913230408, 'Total loss': 0.3037536913230408}
2023-01-04 07:22:01,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:01,026 INFO:     Epoch: 59
2023-01-04 07:22:02,635 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3902044584353765, 'Total loss': 0.3902044584353765} | train loss {'Reaction outcome loss': 0.29524958166091336, 'Total loss': 0.29524958166091336}
2023-01-04 07:22:02,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:02,635 INFO:     Epoch: 60
2023-01-04 07:22:04,236 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4017746498187383, 'Total loss': 0.4017746498187383} | train loss {'Reaction outcome loss': 0.2968045169615399, 'Total loss': 0.2968045169615399}
2023-01-04 07:22:04,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:04,236 INFO:     Epoch: 61
2023-01-04 07:22:05,817 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.404119743903478, 'Total loss': 0.404119743903478} | train loss {'Reaction outcome loss': 0.2951800482536572, 'Total loss': 0.2951800482536572}
2023-01-04 07:22:05,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:05,817 INFO:     Epoch: 62
2023-01-04 07:22:07,361 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39885015885035197, 'Total loss': 0.39885015885035197} | train loss {'Reaction outcome loss': 0.3082675910115039, 'Total loss': 0.3082675910115039}
2023-01-04 07:22:07,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:07,362 INFO:     Epoch: 63
2023-01-04 07:22:08,967 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3886133521795273, 'Total loss': 0.3886133521795273} | train loss {'Reaction outcome loss': 0.29117069919996447, 'Total loss': 0.29117069919996447}
2023-01-04 07:22:08,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:08,967 INFO:     Epoch: 64
2023-01-04 07:22:10,583 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39043208460013074, 'Total loss': 0.39043208460013074} | train loss {'Reaction outcome loss': 0.2926958680652298, 'Total loss': 0.2926958680652298}
2023-01-04 07:22:10,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:10,583 INFO:     Epoch: 65
2023-01-04 07:22:12,207 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3969072600205739, 'Total loss': 0.3969072600205739} | train loss {'Reaction outcome loss': 0.285806324545537, 'Total loss': 0.285806324545537}
2023-01-04 07:22:12,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:12,208 INFO:     Epoch: 66
2023-01-04 07:22:13,808 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3867465302348137, 'Total loss': 0.3867465302348137} | train loss {'Reaction outcome loss': 0.28465158986807143, 'Total loss': 0.28465158986807143}
2023-01-04 07:22:13,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:13,808 INFO:     Epoch: 67
2023-01-04 07:22:15,379 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4294989844163259, 'Total loss': 0.4294989844163259} | train loss {'Reaction outcome loss': 0.28678614978053846, 'Total loss': 0.28678614978053846}
2023-01-04 07:22:15,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:15,379 INFO:     Epoch: 68
2023-01-04 07:22:16,941 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3965569297472636, 'Total loss': 0.3965569297472636} | train loss {'Reaction outcome loss': 0.28324265076050814, 'Total loss': 0.28324265076050814}
2023-01-04 07:22:16,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:16,941 INFO:     Epoch: 69
2023-01-04 07:22:18,538 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3919152975082397, 'Total loss': 0.3919152975082397} | train loss {'Reaction outcome loss': 0.2843508361433835, 'Total loss': 0.2843508361433835}
2023-01-04 07:22:18,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:18,539 INFO:     Epoch: 70
2023-01-04 07:22:20,126 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36608055283625923, 'Total loss': 0.36608055283625923} | train loss {'Reaction outcome loss': 0.2827706828804525, 'Total loss': 0.2827706828804525}
2023-01-04 07:22:20,126 INFO:     Found new best model at epoch 70
2023-01-04 07:22:20,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:20,127 INFO:     Epoch: 71
2023-01-04 07:22:21,722 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41501700977484385, 'Total loss': 0.41501700977484385} | train loss {'Reaction outcome loss': 0.2842324691223505, 'Total loss': 0.2842324691223505}
2023-01-04 07:22:21,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:21,723 INFO:     Epoch: 72
2023-01-04 07:22:23,332 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4206414024035136, 'Total loss': 0.4206414024035136} | train loss {'Reaction outcome loss': 0.28053959015169705, 'Total loss': 0.28053959015169705}
2023-01-04 07:22:23,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:23,333 INFO:     Epoch: 73
2023-01-04 07:22:24,850 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38100144068400066, 'Total loss': 0.38100144068400066} | train loss {'Reaction outcome loss': 0.28083233008299535, 'Total loss': 0.28083233008299535}
2023-01-04 07:22:24,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:24,851 INFO:     Epoch: 74
2023-01-04 07:22:26,444 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4289410442113876, 'Total loss': 0.4289410442113876} | train loss {'Reaction outcome loss': 0.30470339488238096, 'Total loss': 0.30470339488238096}
2023-01-04 07:22:26,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:26,444 INFO:     Epoch: 75
2023-01-04 07:22:28,067 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44535629947980243, 'Total loss': 0.44535629947980243} | train loss {'Reaction outcome loss': 0.3197026786704858, 'Total loss': 0.3197026786704858}
2023-01-04 07:22:28,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:28,067 INFO:     Epoch: 76
2023-01-04 07:22:29,650 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38061639269193015, 'Total loss': 0.38061639269193015} | train loss {'Reaction outcome loss': 0.28066447863629024, 'Total loss': 0.28066447863629024}
2023-01-04 07:22:29,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:29,650 INFO:     Epoch: 77
2023-01-04 07:22:31,244 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4090164800484975, 'Total loss': 0.4090164800484975} | train loss {'Reaction outcome loss': 0.27839601314896584, 'Total loss': 0.27839601314896584}
2023-01-04 07:22:31,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:31,244 INFO:     Epoch: 78
2023-01-04 07:22:32,871 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43306995630264283, 'Total loss': 0.43306995630264283} | train loss {'Reaction outcome loss': 0.27337905217933917, 'Total loss': 0.27337905217933917}
2023-01-04 07:22:32,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:32,871 INFO:     Epoch: 79
2023-01-04 07:22:34,400 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42456329862276715, 'Total loss': 0.42456329862276715} | train loss {'Reaction outcome loss': 0.2733813837285329, 'Total loss': 0.2733813837285329}
2023-01-04 07:22:34,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:34,400 INFO:     Epoch: 80
2023-01-04 07:22:36,016 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3984458933273951, 'Total loss': 0.3984458933273951} | train loss {'Reaction outcome loss': 0.2741158426961983, 'Total loss': 0.2741158426961983}
2023-01-04 07:22:36,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:36,016 INFO:     Epoch: 81
2023-01-04 07:22:37,644 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4410073031981786, 'Total loss': 0.4410073031981786} | train loss {'Reaction outcome loss': 0.26806748990286683, 'Total loss': 0.26806748990286683}
2023-01-04 07:22:37,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:37,645 INFO:     Epoch: 82
2023-01-04 07:22:39,257 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4153613289197286, 'Total loss': 0.4153613289197286} | train loss {'Reaction outcome loss': 0.2657749267817817, 'Total loss': 0.2657749267817817}
2023-01-04 07:22:39,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:39,257 INFO:     Epoch: 83
2023-01-04 07:22:40,861 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4326583743095398, 'Total loss': 0.4326583743095398} | train loss {'Reaction outcome loss': 0.2672635081895957, 'Total loss': 0.2672635081895957}
2023-01-04 07:22:40,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:40,861 INFO:     Epoch: 84
2023-01-04 07:22:42,421 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41536993682384493, 'Total loss': 0.41536993682384493} | train loss {'Reaction outcome loss': 0.2677376556912086, 'Total loss': 0.2677376556912086}
2023-01-04 07:22:42,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:42,421 INFO:     Epoch: 85
2023-01-04 07:22:43,987 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3994591494401296, 'Total loss': 0.3994591494401296} | train loss {'Reaction outcome loss': 0.26713280297859665, 'Total loss': 0.26713280297859665}
2023-01-04 07:22:43,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:43,988 INFO:     Epoch: 86
2023-01-04 07:22:45,607 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4286030404269695, 'Total loss': 0.4286030404269695} | train loss {'Reaction outcome loss': 0.2745012112123811, 'Total loss': 0.2745012112123811}
2023-01-04 07:22:45,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:45,607 INFO:     Epoch: 87
2023-01-04 07:22:47,233 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41223508020242056, 'Total loss': 0.41223508020242056} | train loss {'Reaction outcome loss': 0.297702399647746, 'Total loss': 0.297702399647746}
2023-01-04 07:22:47,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:47,233 INFO:     Epoch: 88
2023-01-04 07:22:48,815 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4089572444558144, 'Total loss': 0.4089572444558144} | train loss {'Reaction outcome loss': 0.27328324210247956, 'Total loss': 0.27328324210247956}
2023-01-04 07:22:48,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:48,815 INFO:     Epoch: 89
2023-01-04 07:22:50,393 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4183010831475258, 'Total loss': 0.4183010831475258} | train loss {'Reaction outcome loss': 0.27032416809073556, 'Total loss': 0.27032416809073556}
2023-01-04 07:22:50,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:50,393 INFO:     Epoch: 90
2023-01-04 07:22:51,933 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39340308085083964, 'Total loss': 0.39340308085083964} | train loss {'Reaction outcome loss': 0.2643116420755784, 'Total loss': 0.2643116420755784}
2023-01-04 07:22:51,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:51,934 INFO:     Epoch: 91
2023-01-04 07:22:53,509 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39909027020136517, 'Total loss': 0.39909027020136517} | train loss {'Reaction outcome loss': 0.26927365691981453, 'Total loss': 0.26927365691981453}
2023-01-04 07:22:53,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:53,509 INFO:     Epoch: 92
2023-01-04 07:22:55,097 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41616257429122927, 'Total loss': 0.41616257429122927} | train loss {'Reaction outcome loss': 0.27731069986834156, 'Total loss': 0.27731069986834156}
2023-01-04 07:22:55,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:55,098 INFO:     Epoch: 93
2023-01-04 07:22:56,687 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4102414111296336, 'Total loss': 0.4102414111296336} | train loss {'Reaction outcome loss': 0.2666028482608322, 'Total loss': 0.2666028482608322}
2023-01-04 07:22:56,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:56,687 INFO:     Epoch: 94
2023-01-04 07:22:58,260 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3927307506402334, 'Total loss': 0.3927307506402334} | train loss {'Reaction outcome loss': 0.2650392061484573, 'Total loss': 0.2650392061484573}
2023-01-04 07:22:58,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:58,260 INFO:     Epoch: 95
2023-01-04 07:22:59,844 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4489124019940694, 'Total loss': 0.4489124019940694} | train loss {'Reaction outcome loss': 0.2648336014582141, 'Total loss': 0.2648336014582141}
2023-01-04 07:22:59,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:22:59,844 INFO:     Epoch: 96
2023-01-04 07:23:01,371 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.403948641816775, 'Total loss': 0.403948641816775} | train loss {'Reaction outcome loss': 0.26015920330351894, 'Total loss': 0.26015920330351894}
2023-01-04 07:23:01,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:01,372 INFO:     Epoch: 97
2023-01-04 07:23:02,971 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3941399842500687, 'Total loss': 0.3941399842500687} | train loss {'Reaction outcome loss': 0.25519146259361203, 'Total loss': 0.25519146259361203}
2023-01-04 07:23:02,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:02,971 INFO:     Epoch: 98
2023-01-04 07:23:04,562 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40982416172822317, 'Total loss': 0.40982416172822317} | train loss {'Reaction outcome loss': 0.2569001761519863, 'Total loss': 0.2569001761519863}
2023-01-04 07:23:04,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:04,562 INFO:     Epoch: 99
2023-01-04 07:23:06,144 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3800406833489736, 'Total loss': 0.3800406833489736} | train loss {'Reaction outcome loss': 0.25996828754095064, 'Total loss': 0.25996828754095064}
2023-01-04 07:23:06,144 INFO:     Best model found after epoch 71 of 100.
2023-01-04 07:23:06,144 INFO:   Done with stage: TRAINING
2023-01-04 07:23:06,145 INFO:   Starting stage: EVALUATION
2023-01-04 07:23:06,274 INFO:   Done with stage: EVALUATION
2023-01-04 07:23:06,274 INFO:   Leaving out SEQ value Fold_1
2023-01-04 07:23:06,287 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:23:06,287 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:23:06,930 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:23:06,930 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:23:07,000 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:23:07,001 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:23:07,001 INFO:     No hyperparam tuning for this model
2023-01-04 07:23:07,001 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:23:07,001 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:23:07,001 INFO:     None feature selector for col prot
2023-01-04 07:23:07,002 INFO:     None feature selector for col prot
2023-01-04 07:23:07,002 INFO:     None feature selector for col prot
2023-01-04 07:23:07,002 INFO:     None feature selector for col chem
2023-01-04 07:23:07,002 INFO:     None feature selector for col chem
2023-01-04 07:23:07,002 INFO:     None feature selector for col chem
2023-01-04 07:23:07,002 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:23:07,002 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:23:07,003 INFO:     Number of params in model 70111
2023-01-04 07:23:07,007 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:23:07,007 INFO:   Starting stage: TRAINING
2023-01-04 07:23:07,049 INFO:     Val loss before train {'Reaction outcome loss': 1.01741534670194, 'Total loss': 1.01741534670194}
2023-01-04 07:23:07,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:07,049 INFO:     Epoch: 0
2023-01-04 07:23:08,638 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7941537499427795, 'Total loss': 0.7941537499427795} | train loss {'Reaction outcome loss': 0.851635196286699, 'Total loss': 0.851635196286699}
2023-01-04 07:23:08,638 INFO:     Found new best model at epoch 0
2023-01-04 07:23:08,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:08,639 INFO:     Epoch: 1
2023-01-04 07:23:10,136 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6417015671730042, 'Total loss': 0.6417015671730042} | train loss {'Reaction outcome loss': 0.7109971673808236, 'Total loss': 0.7109971673808236}
2023-01-04 07:23:10,137 INFO:     Found new best model at epoch 1
2023-01-04 07:23:10,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:10,137 INFO:     Epoch: 2
2023-01-04 07:23:11,723 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5846568385759989, 'Total loss': 0.5846568385759989} | train loss {'Reaction outcome loss': 0.5993354835048101, 'Total loss': 0.5993354835048101}
2023-01-04 07:23:11,723 INFO:     Found new best model at epoch 2
2023-01-04 07:23:11,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:11,724 INFO:     Epoch: 3
2023-01-04 07:23:13,286 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5705514132976532, 'Total loss': 0.5705514132976532} | train loss {'Reaction outcome loss': 0.5510564419994319, 'Total loss': 0.5510564419994319}
2023-01-04 07:23:13,286 INFO:     Found new best model at epoch 3
2023-01-04 07:23:13,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:13,287 INFO:     Epoch: 4
2023-01-04 07:23:14,920 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5676207105318706, 'Total loss': 0.5676207105318706} | train loss {'Reaction outcome loss': 0.5279444578927064, 'Total loss': 0.5279444578927064}
2023-01-04 07:23:14,921 INFO:     Found new best model at epoch 4
2023-01-04 07:23:14,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:14,922 INFO:     Epoch: 5
2023-01-04 07:23:16,504 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5315623740355174, 'Total loss': 0.5315623740355174} | train loss {'Reaction outcome loss': 0.5118235277718075, 'Total loss': 0.5118235277718075}
2023-01-04 07:23:16,504 INFO:     Found new best model at epoch 5
2023-01-04 07:23:16,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:16,505 INFO:     Epoch: 6
2023-01-04 07:23:18,070 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5686922967433929, 'Total loss': 0.5686922967433929} | train loss {'Reaction outcome loss': 0.5051929187839446, 'Total loss': 0.5051929187839446}
2023-01-04 07:23:18,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:18,070 INFO:     Epoch: 7
2023-01-04 07:23:19,571 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5116055637598038, 'Total loss': 0.5116055637598038} | train loss {'Reaction outcome loss': 0.5045919073880583, 'Total loss': 0.5045919073880583}
2023-01-04 07:23:19,571 INFO:     Found new best model at epoch 7
2023-01-04 07:23:19,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:19,572 INFO:     Epoch: 8
2023-01-04 07:23:21,141 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5400486449400584, 'Total loss': 0.5400486449400584} | train loss {'Reaction outcome loss': 0.4856553650933547, 'Total loss': 0.4856553650933547}
2023-01-04 07:23:21,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:21,142 INFO:     Epoch: 9
2023-01-04 07:23:22,722 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5239968617757161, 'Total loss': 0.5239968617757161} | train loss {'Reaction outcome loss': 0.4723994120199611, 'Total loss': 0.4723994120199611}
2023-01-04 07:23:22,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:22,722 INFO:     Epoch: 10
2023-01-04 07:23:24,300 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5331239064534505, 'Total loss': 0.5331239064534505} | train loss {'Reaction outcome loss': 0.4713556689844615, 'Total loss': 0.4713556689844615}
2023-01-04 07:23:24,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:24,300 INFO:     Epoch: 11
2023-01-04 07:23:25,877 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5006086389223735, 'Total loss': 0.5006086389223735} | train loss {'Reaction outcome loss': 0.46312951507127803, 'Total loss': 0.46312951507127803}
2023-01-04 07:23:25,878 INFO:     Found new best model at epoch 11
2023-01-04 07:23:25,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:25,879 INFO:     Epoch: 12
2023-01-04 07:23:27,440 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.523438588778178, 'Total loss': 0.523438588778178} | train loss {'Reaction outcome loss': 0.45795678908842197, 'Total loss': 0.45795678908842197}
2023-01-04 07:23:27,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:27,440 INFO:     Epoch: 13
2023-01-04 07:23:28,985 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.511035007238388, 'Total loss': 0.511035007238388} | train loss {'Reaction outcome loss': 0.4543129495712861, 'Total loss': 0.4543129495712861}
2023-01-04 07:23:28,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:28,985 INFO:     Epoch: 14
2023-01-04 07:23:30,588 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48592525521914165, 'Total loss': 0.48592525521914165} | train loss {'Reaction outcome loss': 0.4494872481386731, 'Total loss': 0.4494872481386731}
2023-01-04 07:23:30,588 INFO:     Found new best model at epoch 14
2023-01-04 07:23:30,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:30,588 INFO:     Epoch: 15
2023-01-04 07:23:32,222 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5086749931176503, 'Total loss': 0.5086749931176503} | train loss {'Reaction outcome loss': 0.4537674911536168, 'Total loss': 0.4537674911536168}
2023-01-04 07:23:32,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:32,223 INFO:     Epoch: 16
2023-01-04 07:23:33,853 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5029435972372691, 'Total loss': 0.5029435972372691} | train loss {'Reaction outcome loss': 0.4686336449306944, 'Total loss': 0.4686336449306944}
2023-01-04 07:23:33,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:33,853 INFO:     Epoch: 17
2023-01-04 07:23:35,473 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48318312466144564, 'Total loss': 0.48318312466144564} | train loss {'Reaction outcome loss': 0.44447558870593057, 'Total loss': 0.44447558870593057}
2023-01-04 07:23:35,473 INFO:     Found new best model at epoch 17
2023-01-04 07:23:35,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:35,474 INFO:     Epoch: 18
2023-01-04 07:23:37,056 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5130126317342122, 'Total loss': 0.5130126317342122} | train loss {'Reaction outcome loss': 0.4355864651042266, 'Total loss': 0.4355864651042266}
2023-01-04 07:23:37,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:37,057 INFO:     Epoch: 19
2023-01-04 07:23:38,657 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4977375686168671, 'Total loss': 0.4977375686168671} | train loss {'Reaction outcome loss': 0.4287375419576099, 'Total loss': 0.4287375419576099}
2023-01-04 07:23:38,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:38,657 INFO:     Epoch: 20
2023-01-04 07:23:40,277 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49125221570332844, 'Total loss': 0.49125221570332844} | train loss {'Reaction outcome loss': 0.4283624811340933, 'Total loss': 0.4283624811340933}
2023-01-04 07:23:40,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:40,278 INFO:     Epoch: 21
2023-01-04 07:23:41,891 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5122094601392746, 'Total loss': 0.5122094601392746} | train loss {'Reaction outcome loss': 0.4229118576158594, 'Total loss': 0.4229118576158594}
2023-01-04 07:23:41,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:41,892 INFO:     Epoch: 22
2023-01-04 07:23:43,514 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48499529163042704, 'Total loss': 0.48499529163042704} | train loss {'Reaction outcome loss': 0.42468022860154725, 'Total loss': 0.42468022860154725}
2023-01-04 07:23:43,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:43,515 INFO:     Epoch: 23
2023-01-04 07:23:45,142 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49727019866307576, 'Total loss': 0.49727019866307576} | train loss {'Reaction outcome loss': 0.4200498276606094, 'Total loss': 0.4200498276606094}
2023-01-04 07:23:45,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:45,143 INFO:     Epoch: 24
2023-01-04 07:23:46,676 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47087889512379966, 'Total loss': 0.47087889512379966} | train loss {'Reaction outcome loss': 0.4125478393735661, 'Total loss': 0.4125478393735661}
2023-01-04 07:23:46,677 INFO:     Found new best model at epoch 24
2023-01-04 07:23:46,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:46,677 INFO:     Epoch: 25
2023-01-04 07:23:48,295 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4718911329905192, 'Total loss': 0.4718911329905192} | train loss {'Reaction outcome loss': 0.41346641111633053, 'Total loss': 0.41346641111633053}
2023-01-04 07:23:48,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:48,295 INFO:     Epoch: 26
2023-01-04 07:23:49,925 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5278091847896575, 'Total loss': 0.5278091847896575} | train loss {'Reaction outcome loss': 0.4133525875707467, 'Total loss': 0.4133525875707467}
2023-01-04 07:23:49,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:49,925 INFO:     Epoch: 27
2023-01-04 07:23:51,553 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4891787072022756, 'Total loss': 0.4891787072022756} | train loss {'Reaction outcome loss': 0.41311234687927406, 'Total loss': 0.41311234687927406}
2023-01-04 07:23:51,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:51,554 INFO:     Epoch: 28
2023-01-04 07:23:53,183 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5062587161858877, 'Total loss': 0.5062587161858877} | train loss {'Reaction outcome loss': 0.39833529849968635, 'Total loss': 0.39833529849968635}
2023-01-04 07:23:53,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:53,183 INFO:     Epoch: 29
2023-01-04 07:23:54,785 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4866499572992325, 'Total loss': 0.4866499572992325} | train loss {'Reaction outcome loss': 0.3973662797631561, 'Total loss': 0.3973662797631561}
2023-01-04 07:23:54,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:54,785 INFO:     Epoch: 30
2023-01-04 07:23:56,371 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4911714593569438, 'Total loss': 0.4911714593569438} | train loss {'Reaction outcome loss': 0.3986773488746173, 'Total loss': 0.3986773488746173}
2023-01-04 07:23:56,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:56,372 INFO:     Epoch: 31
2023-01-04 07:23:57,994 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4770485540231069, 'Total loss': 0.4770485540231069} | train loss {'Reaction outcome loss': 0.39480143639704457, 'Total loss': 0.39480143639704457}
2023-01-04 07:23:57,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:57,995 INFO:     Epoch: 32
2023-01-04 07:23:59,613 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5165903707345326, 'Total loss': 0.5165903707345326} | train loss {'Reaction outcome loss': 0.39000699218477297, 'Total loss': 0.39000699218477297}
2023-01-04 07:23:59,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:23:59,613 INFO:     Epoch: 33
2023-01-04 07:24:01,220 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47888154288132984, 'Total loss': 0.47888154288132984} | train loss {'Reaction outcome loss': 0.3862302256545619, 'Total loss': 0.3862302256545619}
2023-01-04 07:24:01,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:01,221 INFO:     Epoch: 34
2023-01-04 07:24:02,853 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48766723871231077, 'Total loss': 0.48766723871231077} | train loss {'Reaction outcome loss': 0.3821001308767692, 'Total loss': 0.3821001308767692}
2023-01-04 07:24:02,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:02,854 INFO:     Epoch: 35
2023-01-04 07:24:04,430 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46174234549204507, 'Total loss': 0.46174234549204507} | train loss {'Reaction outcome loss': 0.3801485368765999, 'Total loss': 0.3801485368765999}
2023-01-04 07:24:04,430 INFO:     Found new best model at epoch 35
2023-01-04 07:24:04,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:04,431 INFO:     Epoch: 36
2023-01-04 07:24:06,031 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.468577641248703, 'Total loss': 0.468577641248703} | train loss {'Reaction outcome loss': 0.3763693621773543, 'Total loss': 0.3763693621773543}
2023-01-04 07:24:06,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:06,031 INFO:     Epoch: 37
2023-01-04 07:24:07,652 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4864915450414022, 'Total loss': 0.4864915450414022} | train loss {'Reaction outcome loss': 0.38007577119962027, 'Total loss': 0.38007577119962027}
2023-01-04 07:24:07,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:07,652 INFO:     Epoch: 38
2023-01-04 07:24:09,286 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4801207661628723, 'Total loss': 0.4801207661628723} | train loss {'Reaction outcome loss': 0.38844523300244677, 'Total loss': 0.38844523300244677}
2023-01-04 07:24:09,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:09,286 INFO:     Epoch: 39
2023-01-04 07:24:10,913 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46857541302839917, 'Total loss': 0.46857541302839917} | train loss {'Reaction outcome loss': 0.3675583726035553, 'Total loss': 0.3675583726035553}
2023-01-04 07:24:10,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:10,913 INFO:     Epoch: 40
2023-01-04 07:24:12,520 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4539483726024628, 'Total loss': 0.4539483726024628} | train loss {'Reaction outcome loss': 0.36672454973871726, 'Total loss': 0.36672454973871726}
2023-01-04 07:24:12,520 INFO:     Found new best model at epoch 40
2023-01-04 07:24:12,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:12,521 INFO:     Epoch: 41
2023-01-04 07:24:14,057 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4565220286448797, 'Total loss': 0.4565220286448797} | train loss {'Reaction outcome loss': 0.3619157800963823, 'Total loss': 0.3619157800963823}
2023-01-04 07:24:14,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:14,057 INFO:     Epoch: 42
2023-01-04 07:24:15,680 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4438820282618205, 'Total loss': 0.4438820282618205} | train loss {'Reaction outcome loss': 0.3767257528244585, 'Total loss': 0.3767257528244585}
2023-01-04 07:24:15,681 INFO:     Found new best model at epoch 42
2023-01-04 07:24:15,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:15,682 INFO:     Epoch: 43
2023-01-04 07:24:17,302 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44880370299021405, 'Total loss': 0.44880370299021405} | train loss {'Reaction outcome loss': 0.36991345838570217, 'Total loss': 0.36991345838570217}
2023-01-04 07:24:17,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:17,303 INFO:     Epoch: 44
2023-01-04 07:24:18,926 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5075978994369507, 'Total loss': 0.5075978994369507} | train loss {'Reaction outcome loss': 0.35443797767874313, 'Total loss': 0.35443797767874313}
2023-01-04 07:24:18,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:18,926 INFO:     Epoch: 45
2023-01-04 07:24:20,554 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47279065450032554, 'Total loss': 0.47279065450032554} | train loss {'Reaction outcome loss': 0.350425038702678, 'Total loss': 0.350425038702678}
2023-01-04 07:24:20,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:20,554 INFO:     Epoch: 46
2023-01-04 07:24:22,149 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4587066948413849, 'Total loss': 0.4587066948413849} | train loss {'Reaction outcome loss': 0.34735347550747026, 'Total loss': 0.34735347550747026}
2023-01-04 07:24:22,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:22,149 INFO:     Epoch: 47
2023-01-04 07:24:23,727 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4531379401683807, 'Total loss': 0.4531379401683807} | train loss {'Reaction outcome loss': 0.3479229119194328, 'Total loss': 0.3479229119194328}
2023-01-04 07:24:23,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:23,728 INFO:     Epoch: 48
2023-01-04 07:24:25,352 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4763143241405487, 'Total loss': 0.4763143241405487} | train loss {'Reaction outcome loss': 0.3466836476455564, 'Total loss': 0.3466836476455564}
2023-01-04 07:24:25,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:25,352 INFO:     Epoch: 49
2023-01-04 07:24:26,971 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47274841864903766, 'Total loss': 0.47274841864903766} | train loss {'Reaction outcome loss': 0.34434758869232746, 'Total loss': 0.34434758869232746}
2023-01-04 07:24:26,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:26,973 INFO:     Epoch: 50
2023-01-04 07:24:28,602 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4759376625219981, 'Total loss': 0.4759376625219981} | train loss {'Reaction outcome loss': 0.34107497464055603, 'Total loss': 0.34107497464055603}
2023-01-04 07:24:28,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:28,602 INFO:     Epoch: 51
2023-01-04 07:24:30,232 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.453085000316302, 'Total loss': 0.453085000316302} | train loss {'Reaction outcome loss': 0.3488251454588296, 'Total loss': 0.3488251454588296}
2023-01-04 07:24:30,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:30,233 INFO:     Epoch: 52
2023-01-04 07:24:31,804 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4668384929498037, 'Total loss': 0.4668384929498037} | train loss {'Reaction outcome loss': 0.34172286116180645, 'Total loss': 0.34172286116180645}
2023-01-04 07:24:31,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:31,804 INFO:     Epoch: 53
2023-01-04 07:24:33,418 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46111995180447896, 'Total loss': 0.46111995180447896} | train loss {'Reaction outcome loss': 0.33000666334165557, 'Total loss': 0.33000666334165557}
2023-01-04 07:24:33,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:33,419 INFO:     Epoch: 54
2023-01-04 07:24:35,040 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42689511080582937, 'Total loss': 0.42689511080582937} | train loss {'Reaction outcome loss': 0.3288476729522581, 'Total loss': 0.3288476729522581}
2023-01-04 07:24:35,040 INFO:     Found new best model at epoch 54
2023-01-04 07:24:35,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:35,041 INFO:     Epoch: 55
2023-01-04 07:24:36,670 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45389264822006226, 'Total loss': 0.45389264822006226} | train loss {'Reaction outcome loss': 0.33432369115020055, 'Total loss': 0.33432369115020055}
2023-01-04 07:24:36,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:36,670 INFO:     Epoch: 56
2023-01-04 07:24:38,300 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4503218988577525, 'Total loss': 0.4503218988577525} | train loss {'Reaction outcome loss': 0.36964634441487165, 'Total loss': 0.36964634441487165}
2023-01-04 07:24:38,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:38,300 INFO:     Epoch: 57
2023-01-04 07:24:39,929 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44270124236742653, 'Total loss': 0.44270124236742653} | train loss {'Reaction outcome loss': 0.3822112501855346, 'Total loss': 0.3822112501855346}
2023-01-04 07:24:39,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:39,929 INFO:     Epoch: 58
2023-01-04 07:24:41,462 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4877922942241033, 'Total loss': 0.4877922942241033} | train loss {'Reaction outcome loss': 0.349819253898138, 'Total loss': 0.349819253898138}
2023-01-04 07:24:41,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:41,462 INFO:     Epoch: 59
2023-01-04 07:24:43,073 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4547541469335556, 'Total loss': 0.4547541469335556} | train loss {'Reaction outcome loss': 0.33299940399339667, 'Total loss': 0.33299940399339667}
2023-01-04 07:24:43,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:43,073 INFO:     Epoch: 60
2023-01-04 07:24:44,691 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4483739107847214, 'Total loss': 0.4483739107847214} | train loss {'Reaction outcome loss': 0.3236198622752902, 'Total loss': 0.3236198622752902}
2023-01-04 07:24:44,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:44,691 INFO:     Epoch: 61
2023-01-04 07:24:46,306 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4502785414457321, 'Total loss': 0.4502785414457321} | train loss {'Reaction outcome loss': 0.31987979484087636, 'Total loss': 0.31987979484087636}
2023-01-04 07:24:46,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:46,307 INFO:     Epoch: 62
2023-01-04 07:24:47,929 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44983586072921755, 'Total loss': 0.44983586072921755} | train loss {'Reaction outcome loss': 0.3220155818425406, 'Total loss': 0.3220155818425406}
2023-01-04 07:24:47,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:47,929 INFO:     Epoch: 63
2023-01-04 07:24:49,507 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4366520444552104, 'Total loss': 0.4366520444552104} | train loss {'Reaction outcome loss': 0.31875687651336193, 'Total loss': 0.31875687651336193}
2023-01-04 07:24:49,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:49,507 INFO:     Epoch: 64
2023-01-04 07:24:51,100 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4266107310851415, 'Total loss': 0.4266107310851415} | train loss {'Reaction outcome loss': 0.32191078313558863, 'Total loss': 0.32191078313558863}
2023-01-04 07:24:51,100 INFO:     Found new best model at epoch 64
2023-01-04 07:24:51,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:51,101 INFO:     Epoch: 65
2023-01-04 07:24:52,727 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4739858567714691, 'Total loss': 0.4739858567714691} | train loss {'Reaction outcome loss': 0.3128478307330954, 'Total loss': 0.3128478307330954}
2023-01-04 07:24:52,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:52,727 INFO:     Epoch: 66
2023-01-04 07:24:54,340 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4502522269884745, 'Total loss': 0.4502522269884745} | train loss {'Reaction outcome loss': 0.30877994983524515, 'Total loss': 0.30877994983524515}
2023-01-04 07:24:54,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:54,340 INFO:     Epoch: 67
2023-01-04 07:24:55,946 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4340586523214976, 'Total loss': 0.4340586523214976} | train loss {'Reaction outcome loss': 0.30887163166915055, 'Total loss': 0.30887163166915055}
2023-01-04 07:24:55,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:55,946 INFO:     Epoch: 68
2023-01-04 07:24:57,533 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4331780393918355, 'Total loss': 0.4331780393918355} | train loss {'Reaction outcome loss': 0.30562915825926146, 'Total loss': 0.30562915825926146}
2023-01-04 07:24:57,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:57,534 INFO:     Epoch: 69
2023-01-04 07:24:59,097 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4459373871485392, 'Total loss': 0.4459373871485392} | train loss {'Reaction outcome loss': 0.3087590946410985, 'Total loss': 0.3087590946410985}
2023-01-04 07:24:59,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:24:59,098 INFO:     Epoch: 70
2023-01-04 07:25:00,663 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4528294364611308, 'Total loss': 0.4528294364611308} | train loss {'Reaction outcome loss': 0.308182122111775, 'Total loss': 0.308182122111775}
2023-01-04 07:25:00,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:00,663 INFO:     Epoch: 71
2023-01-04 07:25:02,229 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45490370988845824, 'Total loss': 0.45490370988845824} | train loss {'Reaction outcome loss': 0.3043703415795513, 'Total loss': 0.3043703415795513}
2023-01-04 07:25:02,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:02,230 INFO:     Epoch: 72
2023-01-04 07:25:03,796 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45644187529881797, 'Total loss': 0.45644187529881797} | train loss {'Reaction outcome loss': 0.3066824120941801, 'Total loss': 0.3066824120941801}
2023-01-04 07:25:03,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:03,797 INFO:     Epoch: 73
2023-01-04 07:25:05,376 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4473337729771932, 'Total loss': 0.4473337729771932} | train loss {'Reaction outcome loss': 0.32347137140549015, 'Total loss': 0.32347137140549015}
2023-01-04 07:25:05,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:05,376 INFO:     Epoch: 74
2023-01-04 07:25:06,946 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47435330351193744, 'Total loss': 0.47435330351193744} | train loss {'Reaction outcome loss': 0.29814459802920296, 'Total loss': 0.29814459802920296}
2023-01-04 07:25:06,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:06,946 INFO:     Epoch: 75
2023-01-04 07:25:08,436 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4410034010807673, 'Total loss': 0.4410034010807673} | train loss {'Reaction outcome loss': 0.2955857527314051, 'Total loss': 0.2955857527314051}
2023-01-04 07:25:08,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:08,436 INFO:     Epoch: 76
2023-01-04 07:25:10,010 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43834815323352816, 'Total loss': 0.43834815323352816} | train loss {'Reaction outcome loss': 0.294878409155965, 'Total loss': 0.294878409155965}
2023-01-04 07:25:10,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:10,010 INFO:     Epoch: 77
2023-01-04 07:25:11,597 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4335622807343801, 'Total loss': 0.4335622807343801} | train loss {'Reaction outcome loss': 0.2970513527732006, 'Total loss': 0.2970513527732006}
2023-01-04 07:25:11,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:11,597 INFO:     Epoch: 78
2023-01-04 07:25:13,166 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42969049712022145, 'Total loss': 0.42969049712022145} | train loss {'Reaction outcome loss': 0.29594098534716584, 'Total loss': 0.29594098534716584}
2023-01-04 07:25:13,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:13,166 INFO:     Epoch: 79
2023-01-04 07:25:14,731 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4595144152641296, 'Total loss': 0.4595144152641296} | train loss {'Reaction outcome loss': 0.29032176422238676, 'Total loss': 0.29032176422238676}
2023-01-04 07:25:14,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:14,731 INFO:     Epoch: 80
2023-01-04 07:25:16,287 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.439119391143322, 'Total loss': 0.439119391143322} | train loss {'Reaction outcome loss': 0.2904038052951944, 'Total loss': 0.2904038052951944}
2023-01-04 07:25:16,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:16,288 INFO:     Epoch: 81
2023-01-04 07:25:17,785 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42924343744913734, 'Total loss': 0.42924343744913734} | train loss {'Reaction outcome loss': 0.2955389798359871, 'Total loss': 0.2955389798359871}
2023-01-04 07:25:17,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:17,785 INFO:     Epoch: 82
2023-01-04 07:25:19,376 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4225118666887283, 'Total loss': 0.4225118666887283} | train loss {'Reaction outcome loss': 0.28445750447555335, 'Total loss': 0.28445750447555335}
2023-01-04 07:25:19,376 INFO:     Found new best model at epoch 82
2023-01-04 07:25:19,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:19,377 INFO:     Epoch: 83
2023-01-04 07:25:20,982 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4574211815992991, 'Total loss': 0.4574211815992991} | train loss {'Reaction outcome loss': 0.28183888956614217, 'Total loss': 0.28183888956614217}
2023-01-04 07:25:20,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:20,983 INFO:     Epoch: 84
2023-01-04 07:25:22,559 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4323554754257202, 'Total loss': 0.4323554754257202} | train loss {'Reaction outcome loss': 0.28806499227125576, 'Total loss': 0.28806499227125576}
2023-01-04 07:25:22,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:22,559 INFO:     Epoch: 85
2023-01-04 07:25:24,134 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45836455523967745, 'Total loss': 0.45836455523967745} | train loss {'Reaction outcome loss': 0.29836127505489235, 'Total loss': 0.29836127505489235}
2023-01-04 07:25:24,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:24,134 INFO:     Epoch: 86
2023-01-04 07:25:25,703 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4518016815185547, 'Total loss': 0.4518016815185547} | train loss {'Reaction outcome loss': 0.28887954468466004, 'Total loss': 0.28887954468466004}
2023-01-04 07:25:25,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:25,703 INFO:     Epoch: 87
2023-01-04 07:25:27,244 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45253435770670575, 'Total loss': 0.45253435770670575} | train loss {'Reaction outcome loss': 0.2861376437535712, 'Total loss': 0.2861376437535712}
2023-01-04 07:25:27,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:27,244 INFO:     Epoch: 88
2023-01-04 07:25:28,814 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45204702218373616, 'Total loss': 0.45204702218373616} | train loss {'Reaction outcome loss': 0.28059556486213283, 'Total loss': 0.28059556486213283}
2023-01-04 07:25:28,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:28,816 INFO:     Epoch: 89
2023-01-04 07:25:30,395 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4573580404122671, 'Total loss': 0.4573580404122671} | train loss {'Reaction outcome loss': 0.277441898630797, 'Total loss': 0.277441898630797}
2023-01-04 07:25:30,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:30,395 INFO:     Epoch: 90
2023-01-04 07:25:31,977 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44450095693270364, 'Total loss': 0.44450095693270364} | train loss {'Reaction outcome loss': 0.2845915660491564, 'Total loss': 0.2845915660491564}
2023-01-04 07:25:31,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:31,977 INFO:     Epoch: 91
2023-01-04 07:25:33,559 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4756945550441742, 'Total loss': 0.4756945550441742} | train loss {'Reaction outcome loss': 0.2751770334341901, 'Total loss': 0.2751770334341901}
2023-01-04 07:25:33,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:33,560 INFO:     Epoch: 92
2023-01-04 07:25:35,097 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4770760993162791, 'Total loss': 0.4770760993162791} | train loss {'Reaction outcome loss': 0.2759618310078952, 'Total loss': 0.2759618310078952}
2023-01-04 07:25:35,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:35,098 INFO:     Epoch: 93
2023-01-04 07:25:36,626 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4250314116477966, 'Total loss': 0.4250314116477966} | train loss {'Reaction outcome loss': 0.2741096249053531, 'Total loss': 0.2741096249053531}
2023-01-04 07:25:36,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:36,626 INFO:     Epoch: 94
2023-01-04 07:25:38,184 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4483711928129196, 'Total loss': 0.4483711928129196} | train loss {'Reaction outcome loss': 0.27293034502730257, 'Total loss': 0.27293034502730257}
2023-01-04 07:25:38,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:38,184 INFO:     Epoch: 95
2023-01-04 07:25:39,743 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43699894547462464, 'Total loss': 0.43699894547462464} | train loss {'Reaction outcome loss': 0.2744115364056189, 'Total loss': 0.2744115364056189}
2023-01-04 07:25:39,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:39,743 INFO:     Epoch: 96
2023-01-04 07:25:41,311 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4459130803743998, 'Total loss': 0.4459130803743998} | train loss {'Reaction outcome loss': 0.2742885915970386, 'Total loss': 0.2742885915970386}
2023-01-04 07:25:41,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:41,311 INFO:     Epoch: 97
2023-01-04 07:25:42,863 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4374613523483276, 'Total loss': 0.4374613523483276} | train loss {'Reaction outcome loss': 0.2749979755658453, 'Total loss': 0.2749979755658453}
2023-01-04 07:25:42,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:42,864 INFO:     Epoch: 98
2023-01-04 07:25:44,412 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4410560806592306, 'Total loss': 0.4410560806592306} | train loss {'Reaction outcome loss': 0.2660207177244086, 'Total loss': 0.2660207177244086}
2023-01-04 07:25:44,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:44,412 INFO:     Epoch: 99
2023-01-04 07:25:45,958 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4469329019387563, 'Total loss': 0.4469329019387563} | train loss {'Reaction outcome loss': 0.265883080681543, 'Total loss': 0.265883080681543}
2023-01-04 07:25:45,958 INFO:     Best model found after epoch 83 of 100.
2023-01-04 07:25:45,958 INFO:   Done with stage: TRAINING
2023-01-04 07:25:45,958 INFO:   Starting stage: EVALUATION
2023-01-04 07:25:46,085 INFO:   Done with stage: EVALUATION
2023-01-04 07:25:46,085 INFO:   Leaving out SEQ value Fold_2
2023-01-04 07:25:46,098 INFO:   examples: 20,544| examples in train: 17,236 | examples in val: 908| examples in test: 2,400
2023-01-04 07:25:46,098 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:25:46,741 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:25:46,741 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:25:46,809 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:25:46,809 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:25:46,809 INFO:     No hyperparam tuning for this model
2023-01-04 07:25:46,809 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:25:46,810 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:25:46,810 INFO:     None feature selector for col prot
2023-01-04 07:25:46,810 INFO:     None feature selector for col prot
2023-01-04 07:25:46,810 INFO:     None feature selector for col prot
2023-01-04 07:25:46,811 INFO:     None feature selector for col chem
2023-01-04 07:25:46,811 INFO:     None feature selector for col chem
2023-01-04 07:25:46,811 INFO:     None feature selector for col chem
2023-01-04 07:25:46,811 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:25:46,811 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:25:46,812 INFO:     Number of params in model 70111
2023-01-04 07:25:46,815 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:25:46,815 INFO:   Starting stage: TRAINING
2023-01-04 07:25:46,859 INFO:     Val loss before train {'Reaction outcome loss': 1.0425387620925903, 'Total loss': 1.0425387620925903}
2023-01-04 07:25:46,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:46,859 INFO:     Epoch: 0
2023-01-04 07:25:48,384 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7445261240005493, 'Total loss': 0.7445261240005493} | train loss {'Reaction outcome loss': 0.8322397459436346, 'Total loss': 0.8322397459436346}
2023-01-04 07:25:48,384 INFO:     Found new best model at epoch 0
2023-01-04 07:25:48,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:48,385 INFO:     Epoch: 1
2023-01-04 07:25:49,905 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6001278499762217, 'Total loss': 0.6001278499762217} | train loss {'Reaction outcome loss': 0.6849938959987075, 'Total loss': 0.6849938959987075}
2023-01-04 07:25:49,905 INFO:     Found new best model at epoch 1
2023-01-04 07:25:49,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:49,906 INFO:     Epoch: 2
2023-01-04 07:25:51,428 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5347340087095896, 'Total loss': 0.5347340087095896} | train loss {'Reaction outcome loss': 0.5911145060702606, 'Total loss': 0.5911145060702606}
2023-01-04 07:25:51,428 INFO:     Found new best model at epoch 2
2023-01-04 07:25:51,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:51,429 INFO:     Epoch: 3
2023-01-04 07:25:52,909 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5344158271948497, 'Total loss': 0.5344158271948497} | train loss {'Reaction outcome loss': 0.5386560355071668, 'Total loss': 0.5386560355071668}
2023-01-04 07:25:52,909 INFO:     Found new best model at epoch 3
2023-01-04 07:25:52,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:52,910 INFO:     Epoch: 4
2023-01-04 07:25:54,408 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5848439892133077, 'Total loss': 0.5848439892133077} | train loss {'Reaction outcome loss': 0.5088606338810038, 'Total loss': 0.5088606338810038}
2023-01-04 07:25:54,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:54,408 INFO:     Epoch: 5
2023-01-04 07:25:55,923 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46700819209218025, 'Total loss': 0.46700819209218025} | train loss {'Reaction outcome loss': 0.49686766769047136, 'Total loss': 0.49686766769047136}
2023-01-04 07:25:55,923 INFO:     Found new best model at epoch 5
2023-01-04 07:25:55,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:55,924 INFO:     Epoch: 6
2023-01-04 07:25:57,435 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4664010723431905, 'Total loss': 0.4664010723431905} | train loss {'Reaction outcome loss': 0.4844134886507635, 'Total loss': 0.4844134886507635}
2023-01-04 07:25:57,435 INFO:     Found new best model at epoch 6
2023-01-04 07:25:57,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:57,436 INFO:     Epoch: 7
2023-01-04 07:25:58,957 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45277223189671834, 'Total loss': 0.45277223189671834} | train loss {'Reaction outcome loss': 0.47225934051805074, 'Total loss': 0.47225934051805074}
2023-01-04 07:25:58,957 INFO:     Found new best model at epoch 7
2023-01-04 07:25:58,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:25:58,958 INFO:     Epoch: 8
2023-01-04 07:26:00,470 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4512167513370514, 'Total loss': 0.4512167513370514} | train loss {'Reaction outcome loss': 0.4653407898214128, 'Total loss': 0.4653407898214128}
2023-01-04 07:26:00,470 INFO:     Found new best model at epoch 8
2023-01-04 07:26:00,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:00,471 INFO:     Epoch: 9
2023-01-04 07:26:01,951 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43708360294500986, 'Total loss': 0.43708360294500986} | train loss {'Reaction outcome loss': 0.4573832061003756, 'Total loss': 0.4573832061003756}
2023-01-04 07:26:01,952 INFO:     Found new best model at epoch 9
2023-01-04 07:26:01,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:01,952 INFO:     Epoch: 10
2023-01-04 07:26:03,069 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5160573939482371, 'Total loss': 0.5160573939482371} | train loss {'Reaction outcome loss': 0.4499249318683589, 'Total loss': 0.4499249318683589}
2023-01-04 07:26:03,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:03,070 INFO:     Epoch: 11
2023-01-04 07:26:04,070 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4550800999005636, 'Total loss': 0.4550800999005636} | train loss {'Reaction outcome loss': 0.4465447877844175, 'Total loss': 0.4465447877844175}
2023-01-04 07:26:04,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:04,071 INFO:     Epoch: 12
2023-01-04 07:26:05,065 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46809119582176206, 'Total loss': 0.46809119582176206} | train loss {'Reaction outcome loss': 0.43917524842200456, 'Total loss': 0.43917524842200456}
2023-01-04 07:26:05,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:05,065 INFO:     Epoch: 13
2023-01-04 07:26:06,062 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4561606456836065, 'Total loss': 0.4561606456836065} | train loss {'Reaction outcome loss': 0.43328338944249684, 'Total loss': 0.43328338944249684}
2023-01-04 07:26:06,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:06,062 INFO:     Epoch: 14
2023-01-04 07:26:07,338 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4451974093914032, 'Total loss': 0.4451974093914032} | train loss {'Reaction outcome loss': 0.4322952167855369, 'Total loss': 0.4322952167855369}
2023-01-04 07:26:07,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:07,339 INFO:     Epoch: 15
2023-01-04 07:26:08,834 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4270912637313207, 'Total loss': 0.4270912637313207} | train loss {'Reaction outcome loss': 0.42692007339662974, 'Total loss': 0.42692007339662974}
2023-01-04 07:26:08,834 INFO:     Found new best model at epoch 15
2023-01-04 07:26:08,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:08,835 INFO:     Epoch: 16
2023-01-04 07:26:10,356 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4647585054238637, 'Total loss': 0.4647585054238637} | train loss {'Reaction outcome loss': 0.42470456389365374, 'Total loss': 0.42470456389365374}
2023-01-04 07:26:10,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:10,357 INFO:     Epoch: 17
2023-01-04 07:26:11,873 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5010376930236816, 'Total loss': 0.5010376930236816} | train loss {'Reaction outcome loss': 0.4204124497042762, 'Total loss': 0.4204124497042762}
2023-01-04 07:26:11,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:11,873 INFO:     Epoch: 18
2023-01-04 07:26:13,433 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43783456881841026, 'Total loss': 0.43783456881841026} | train loss {'Reaction outcome loss': 0.4092003415028254, 'Total loss': 0.4092003415028254}
2023-01-04 07:26:13,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:13,434 INFO:     Epoch: 19
2023-01-04 07:26:14,988 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42655421296755475, 'Total loss': 0.42655421296755475} | train loss {'Reaction outcome loss': 0.4122098439269596, 'Total loss': 0.4122098439269596}
2023-01-04 07:26:14,988 INFO:     Found new best model at epoch 19
2023-01-04 07:26:14,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:14,989 INFO:     Epoch: 20
2023-01-04 07:26:16,517 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43115637501080833, 'Total loss': 0.43115637501080833} | train loss {'Reaction outcome loss': 0.40474028167901216, 'Total loss': 0.40474028167901216}
2023-01-04 07:26:16,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:16,517 INFO:     Epoch: 21
2023-01-04 07:26:18,057 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42440546651681266, 'Total loss': 0.42440546651681266} | train loss {'Reaction outcome loss': 0.4013467123111089, 'Total loss': 0.4013467123111089}
2023-01-04 07:26:18,057 INFO:     Found new best model at epoch 21
2023-01-04 07:26:18,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:18,058 INFO:     Epoch: 22
2023-01-04 07:26:19,649 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.446923898657163, 'Total loss': 0.446923898657163} | train loss {'Reaction outcome loss': 0.4003716001907984, 'Total loss': 0.4003716001907984}
2023-01-04 07:26:19,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:19,650 INFO:     Epoch: 23
2023-01-04 07:26:21,248 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4099627236525218, 'Total loss': 0.4099627236525218} | train loss {'Reaction outcome loss': 0.3970568770059833, 'Total loss': 0.3970568770059833}
2023-01-04 07:26:21,248 INFO:     Found new best model at epoch 23
2023-01-04 07:26:21,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:21,249 INFO:     Epoch: 24
2023-01-04 07:26:22,845 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42625869711240133, 'Total loss': 0.42625869711240133} | train loss {'Reaction outcome loss': 0.3920075254859748, 'Total loss': 0.3920075254859748}
2023-01-04 07:26:22,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:22,845 INFO:     Epoch: 25
2023-01-04 07:26:24,400 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.421031187971433, 'Total loss': 0.421031187971433} | train loss {'Reaction outcome loss': 0.38379382587693356, 'Total loss': 0.38379382587693356}
2023-01-04 07:26:24,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:24,400 INFO:     Epoch: 26
2023-01-04 07:26:25,892 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3931521440545718, 'Total loss': 0.3931521440545718} | train loss {'Reaction outcome loss': 0.38272925791917023, 'Total loss': 0.38272925791917023}
2023-01-04 07:26:25,892 INFO:     Found new best model at epoch 26
2023-01-04 07:26:25,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:25,893 INFO:     Epoch: 27
2023-01-04 07:26:27,402 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4411226431528727, 'Total loss': 0.4411226431528727} | train loss {'Reaction outcome loss': 0.38156460922349383, 'Total loss': 0.38156460922349383}
2023-01-04 07:26:27,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:27,402 INFO:     Epoch: 28
2023-01-04 07:26:28,961 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3816652501622836, 'Total loss': 0.3816652501622836} | train loss {'Reaction outcome loss': 0.3810692459896759, 'Total loss': 0.3810692459896759}
2023-01-04 07:26:28,961 INFO:     Found new best model at epoch 28
2023-01-04 07:26:28,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:28,962 INFO:     Epoch: 29
2023-01-04 07:26:30,506 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4115159203608831, 'Total loss': 0.4115159203608831} | train loss {'Reaction outcome loss': 0.3705951229565673, 'Total loss': 0.3705951229565673}
2023-01-04 07:26:30,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:30,507 INFO:     Epoch: 30
2023-01-04 07:26:32,066 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4004779815673828, 'Total loss': 0.4004779815673828} | train loss {'Reaction outcome loss': 0.3704658183234709, 'Total loss': 0.3704658183234709}
2023-01-04 07:26:32,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:32,066 INFO:     Epoch: 31
2023-01-04 07:26:33,620 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3976383050282796, 'Total loss': 0.3976383050282796} | train loss {'Reaction outcome loss': 0.36814199716404633, 'Total loss': 0.36814199716404633}
2023-01-04 07:26:33,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:33,620 INFO:     Epoch: 32
2023-01-04 07:26:35,120 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42031050225098926, 'Total loss': 0.42031050225098926} | train loss {'Reaction outcome loss': 0.3671043052165597, 'Total loss': 0.3671043052165597}
2023-01-04 07:26:35,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:35,120 INFO:     Epoch: 33
2023-01-04 07:26:36,593 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38703261216481527, 'Total loss': 0.38703261216481527} | train loss {'Reaction outcome loss': 0.3578442882608484, 'Total loss': 0.3578442882608484}
2023-01-04 07:26:36,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:36,593 INFO:     Epoch: 34
2023-01-04 07:26:38,102 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3811819283912579, 'Total loss': 0.3811819283912579} | train loss {'Reaction outcome loss': 0.3580069217416975, 'Total loss': 0.3580069217416975}
2023-01-04 07:26:38,102 INFO:     Found new best model at epoch 34
2023-01-04 07:26:38,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:38,103 INFO:     Epoch: 35
2023-01-04 07:26:39,622 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.372792320450147, 'Total loss': 0.372792320450147} | train loss {'Reaction outcome loss': 0.3544366808953109, 'Total loss': 0.3544366808953109}
2023-01-04 07:26:39,623 INFO:     Found new best model at epoch 35
2023-01-04 07:26:39,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:39,624 INFO:     Epoch: 36
2023-01-04 07:26:41,128 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39227459331353504, 'Total loss': 0.39227459331353504} | train loss {'Reaction outcome loss': 0.35047573830794404, 'Total loss': 0.35047573830794404}
2023-01-04 07:26:41,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:41,129 INFO:     Epoch: 37
2023-01-04 07:26:42,650 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37357089668512344, 'Total loss': 0.37357089668512344} | train loss {'Reaction outcome loss': 0.346522632572386, 'Total loss': 0.346522632572386}
2023-01-04 07:26:42,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:42,650 INFO:     Epoch: 38
2023-01-04 07:26:44,143 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4064817557732264, 'Total loss': 0.4064817557732264} | train loss {'Reaction outcome loss': 0.34870251585487966, 'Total loss': 0.34870251585487966}
2023-01-04 07:26:44,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:44,143 INFO:     Epoch: 39
2023-01-04 07:26:45,634 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4134619027376175, 'Total loss': 0.4134619027376175} | train loss {'Reaction outcome loss': 0.34166436316790405, 'Total loss': 0.34166436316790405}
2023-01-04 07:26:45,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:45,635 INFO:     Epoch: 40
2023-01-04 07:26:47,154 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37236998975276947, 'Total loss': 0.37236998975276947} | train loss {'Reaction outcome loss': 0.33491388457240884, 'Total loss': 0.33491388457240884}
2023-01-04 07:26:47,154 INFO:     Found new best model at epoch 40
2023-01-04 07:26:47,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:47,155 INFO:     Epoch: 41
2023-01-04 07:26:48,697 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4186094582080841, 'Total loss': 0.4186094582080841} | train loss {'Reaction outcome loss': 0.33577312941628473, 'Total loss': 0.33577312941628473}
2023-01-04 07:26:48,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:48,697 INFO:     Epoch: 42
2023-01-04 07:26:50,219 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.34790998169531423, 'Total loss': 0.34790998169531423} | train loss {'Reaction outcome loss': 0.33432220427526366, 'Total loss': 0.33432220427526366}
2023-01-04 07:26:50,219 INFO:     Found new best model at epoch 42
2023-01-04 07:26:50,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:50,220 INFO:     Epoch: 43
2023-01-04 07:26:51,768 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3556673139333725, 'Total loss': 0.3556673139333725} | train loss {'Reaction outcome loss': 0.3305305619206693, 'Total loss': 0.3305305619206693}
2023-01-04 07:26:51,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:51,769 INFO:     Epoch: 44
2023-01-04 07:26:53,308 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4179721603790919, 'Total loss': 0.4179721603790919} | train loss {'Reaction outcome loss': 0.327953470705284, 'Total loss': 0.327953470705284}
2023-01-04 07:26:53,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:53,308 INFO:     Epoch: 45
2023-01-04 07:26:54,828 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3590157796939214, 'Total loss': 0.3590157796939214} | train loss {'Reaction outcome loss': 0.3269477455152406, 'Total loss': 0.3269477455152406}
2023-01-04 07:26:54,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:54,828 INFO:     Epoch: 46
2023-01-04 07:26:56,341 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3620441337426504, 'Total loss': 0.3620441337426504} | train loss {'Reaction outcome loss': 0.3213101485537158, 'Total loss': 0.3213101485537158}
2023-01-04 07:26:56,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:56,341 INFO:     Epoch: 47
2023-01-04 07:26:57,862 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.394533367951711, 'Total loss': 0.394533367951711} | train loss {'Reaction outcome loss': 0.3254752133455541, 'Total loss': 0.3254752133455541}
2023-01-04 07:26:57,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:57,863 INFO:     Epoch: 48
2023-01-04 07:26:59,393 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3784522871176402, 'Total loss': 0.3784522871176402} | train loss {'Reaction outcome loss': 0.31475455231136745, 'Total loss': 0.31475455231136745}
2023-01-04 07:26:59,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:26:59,393 INFO:     Epoch: 49
2023-01-04 07:27:00,906 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4123706032832464, 'Total loss': 0.4123706032832464} | train loss {'Reaction outcome loss': 0.3151414870801899, 'Total loss': 0.3151414870801899}
2023-01-04 07:27:00,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:00,906 INFO:     Epoch: 50
2023-01-04 07:27:02,389 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3668506979942322, 'Total loss': 0.3668506979942322} | train loss {'Reaction outcome loss': 0.31458922187211336, 'Total loss': 0.31458922187211336}
2023-01-04 07:27:02,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:02,390 INFO:     Epoch: 51
2023-01-04 07:27:03,872 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3888204256693522, 'Total loss': 0.3888204256693522} | train loss {'Reaction outcome loss': 0.3152311924982954, 'Total loss': 0.3152311924982954}
2023-01-04 07:27:03,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:03,872 INFO:     Epoch: 52
2023-01-04 07:27:05,383 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38849928180376686, 'Total loss': 0.38849928180376686} | train loss {'Reaction outcome loss': 0.3097448643434931, 'Total loss': 0.3097448643434931}
2023-01-04 07:27:05,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:05,383 INFO:     Epoch: 53
2023-01-04 07:27:06,908 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3804058397809664, 'Total loss': 0.3804058397809664} | train loss {'Reaction outcome loss': 0.30827274667444055, 'Total loss': 0.30827274667444055}
2023-01-04 07:27:06,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:06,909 INFO:     Epoch: 54
2023-01-04 07:27:08,416 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4094545394182205, 'Total loss': 0.4094545394182205} | train loss {'Reaction outcome loss': 0.30690209025310144, 'Total loss': 0.30690209025310144}
2023-01-04 07:27:08,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:08,416 INFO:     Epoch: 55
2023-01-04 07:27:09,926 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3714424769083659, 'Total loss': 0.3714424769083659} | train loss {'Reaction outcome loss': 0.30772434953186245, 'Total loss': 0.30772434953186245}
2023-01-04 07:27:09,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:09,926 INFO:     Epoch: 56
2023-01-04 07:27:11,408 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39511110285917916, 'Total loss': 0.39511110285917916} | train loss {'Reaction outcome loss': 0.2986567801071538, 'Total loss': 0.2986567801071538}
2023-01-04 07:27:11,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:11,410 INFO:     Epoch: 57
2023-01-04 07:27:12,882 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4238330841064453, 'Total loss': 0.4238330841064453} | train loss {'Reaction outcome loss': 0.2970450102455086, 'Total loss': 0.2970450102455086}
2023-01-04 07:27:12,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:12,882 INFO:     Epoch: 58
2023-01-04 07:27:14,401 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3862998073299726, 'Total loss': 0.3862998073299726} | train loss {'Reaction outcome loss': 0.2976882786938438, 'Total loss': 0.2976882786938438}
2023-01-04 07:27:14,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:14,402 INFO:     Epoch: 59
2023-01-04 07:27:15,921 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3685341993967692, 'Total loss': 0.3685341993967692} | train loss {'Reaction outcome loss': 0.29652567565165183, 'Total loss': 0.29652567565165183}
2023-01-04 07:27:15,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:15,921 INFO:     Epoch: 60
2023-01-04 07:27:17,430 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36545695960521696, 'Total loss': 0.36545695960521696} | train loss {'Reaction outcome loss': 0.29659546461922154, 'Total loss': 0.29659546461922154}
2023-01-04 07:27:17,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:17,431 INFO:     Epoch: 61
2023-01-04 07:27:18,945 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3605346530675888, 'Total loss': 0.3605346530675888} | train loss {'Reaction outcome loss': 0.28915801539465236, 'Total loss': 0.28915801539465236}
2023-01-04 07:27:18,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:18,945 INFO:     Epoch: 62
2023-01-04 07:27:20,426 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3721582680940628, 'Total loss': 0.3721582680940628} | train loss {'Reaction outcome loss': 0.2934422171226254, 'Total loss': 0.2934422171226254}
2023-01-04 07:27:20,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:20,427 INFO:     Epoch: 63
2023-01-04 07:27:21,915 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3559502931932608, 'Total loss': 0.3559502931932608} | train loss {'Reaction outcome loss': 0.2934542461677834, 'Total loss': 0.2934542461677834}
2023-01-04 07:27:21,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:21,916 INFO:     Epoch: 64
2023-01-04 07:27:23,503 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41158974965413414, 'Total loss': 0.41158974965413414} | train loss {'Reaction outcome loss': 0.2868285645903261, 'Total loss': 0.2868285645903261}
2023-01-04 07:27:23,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:23,503 INFO:     Epoch: 65
2023-01-04 07:27:25,101 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3883252412080765, 'Total loss': 0.3883252412080765} | train loss {'Reaction outcome loss': 0.29039166489685025, 'Total loss': 0.29039166489685025}
2023-01-04 07:27:25,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:25,101 INFO:     Epoch: 66
2023-01-04 07:27:26,701 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4076732744773229, 'Total loss': 0.4076732744773229} | train loss {'Reaction outcome loss': 0.28335340776377255, 'Total loss': 0.28335340776377255}
2023-01-04 07:27:26,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:26,701 INFO:     Epoch: 67
2023-01-04 07:27:28,298 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3711118494470914, 'Total loss': 0.3711118494470914} | train loss {'Reaction outcome loss': 0.2854741245646168, 'Total loss': 0.2854741245646168}
2023-01-04 07:27:28,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:28,298 INFO:     Epoch: 68
2023-01-04 07:27:29,812 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3513673981030782, 'Total loss': 0.3513673981030782} | train loss {'Reaction outcome loss': 0.279677835824313, 'Total loss': 0.279677835824313}
2023-01-04 07:27:29,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:29,813 INFO:     Epoch: 69
2023-01-04 07:27:31,390 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3716419701774915, 'Total loss': 0.3716419701774915} | train loss {'Reaction outcome loss': 0.27870106912321513, 'Total loss': 0.27870106912321513}
2023-01-04 07:27:31,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:31,390 INFO:     Epoch: 70
2023-01-04 07:27:32,986 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3446297104159991, 'Total loss': 0.3446297104159991} | train loss {'Reaction outcome loss': 0.2777527167565293, 'Total loss': 0.2777527167565293}
2023-01-04 07:27:32,986 INFO:     Found new best model at epoch 70
2023-01-04 07:27:32,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:32,987 INFO:     Epoch: 71
2023-01-04 07:27:34,573 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3487310846646627, 'Total loss': 0.3487310846646627} | train loss {'Reaction outcome loss': 0.27848920082604445, 'Total loss': 0.27848920082604445}
2023-01-04 07:27:34,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:34,573 INFO:     Epoch: 72
2023-01-04 07:27:36,168 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37065273225307466, 'Total loss': 0.37065273225307466} | train loss {'Reaction outcome loss': 0.2770960383393146, 'Total loss': 0.2770960383393146}
2023-01-04 07:27:36,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:36,168 INFO:     Epoch: 73
2023-01-04 07:27:37,717 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3800833870967229, 'Total loss': 0.3800833870967229} | train loss {'Reaction outcome loss': 0.27441906241907016, 'Total loss': 0.27441906241907016}
2023-01-04 07:27:37,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:37,717 INFO:     Epoch: 74
2023-01-04 07:27:39,255 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.355743674437205, 'Total loss': 0.355743674437205} | train loss {'Reaction outcome loss': 0.2744859300829746, 'Total loss': 0.2744859300829746}
2023-01-04 07:27:39,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:39,255 INFO:     Epoch: 75
2023-01-04 07:27:40,850 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41624248524506885, 'Total loss': 0.41624248524506885} | train loss {'Reaction outcome loss': 0.26820778396946415, 'Total loss': 0.26820778396946415}
2023-01-04 07:27:40,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:40,851 INFO:     Epoch: 76
2023-01-04 07:27:42,435 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39273312588532766, 'Total loss': 0.39273312588532766} | train loss {'Reaction outcome loss': 0.27211893536150455, 'Total loss': 0.27211893536150455}
2023-01-04 07:27:42,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:42,436 INFO:     Epoch: 77
2023-01-04 07:27:44,004 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36148658792177835, 'Total loss': 0.36148658792177835} | train loss {'Reaction outcome loss': 0.2713535120089849, 'Total loss': 0.2713535120089849}
2023-01-04 07:27:44,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:44,004 INFO:     Epoch: 78
2023-01-04 07:27:45,563 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35326942801475525, 'Total loss': 0.35326942801475525} | train loss {'Reaction outcome loss': 0.271108013846808, 'Total loss': 0.271108013846808}
2023-01-04 07:27:45,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:45,563 INFO:     Epoch: 79
2023-01-04 07:27:47,096 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3585066775480906, 'Total loss': 0.3585066775480906} | train loss {'Reaction outcome loss': 0.27142464839335945, 'Total loss': 0.27142464839335945}
2023-01-04 07:27:47,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:47,097 INFO:     Epoch: 80
2023-01-04 07:27:48,635 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3525097966194153, 'Total loss': 0.3525097966194153} | train loss {'Reaction outcome loss': 0.2706761412460495, 'Total loss': 0.2706761412460495}
2023-01-04 07:27:48,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:48,635 INFO:     Epoch: 81
2023-01-04 07:27:50,216 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3697762280702591, 'Total loss': 0.3697762280702591} | train loss {'Reaction outcome loss': 0.26467141205513917, 'Total loss': 0.26467141205513917}
2023-01-04 07:27:50,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:50,216 INFO:     Epoch: 82
2023-01-04 07:27:51,794 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4203826238711675, 'Total loss': 0.4203826238711675} | train loss {'Reaction outcome loss': 0.268986004287446, 'Total loss': 0.268986004287446}
2023-01-04 07:27:51,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:51,794 INFO:     Epoch: 83
2023-01-04 07:27:53,373 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3594947189092636, 'Total loss': 0.3594947189092636} | train loss {'Reaction outcome loss': 0.26199716561370423, 'Total loss': 0.26199716561370423}
2023-01-04 07:27:53,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:53,374 INFO:     Epoch: 84
2023-01-04 07:27:54,948 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38182998498280846, 'Total loss': 0.38182998498280846} | train loss {'Reaction outcome loss': 0.26273204582156956, 'Total loss': 0.26273204582156956}
2023-01-04 07:27:54,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:54,948 INFO:     Epoch: 85
2023-01-04 07:27:56,484 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39447184006373087, 'Total loss': 0.39447184006373087} | train loss {'Reaction outcome loss': 0.26026339703411966, 'Total loss': 0.26026339703411966}
2023-01-04 07:27:56,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:56,484 INFO:     Epoch: 86
2023-01-04 07:27:58,001 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37151473263899487, 'Total loss': 0.37151473263899487} | train loss {'Reaction outcome loss': 0.25656366480721365, 'Total loss': 0.25656366480721365}
2023-01-04 07:27:58,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:58,001 INFO:     Epoch: 87
2023-01-04 07:27:59,527 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33845658116042615, 'Total loss': 0.33845658116042615} | train loss {'Reaction outcome loss': 0.2554931960448071, 'Total loss': 0.2554931960448071}
2023-01-04 07:27:59,527 INFO:     Found new best model at epoch 87
2023-01-04 07:27:59,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:27:59,528 INFO:     Epoch: 88
2023-01-04 07:28:01,101 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3581703320145607, 'Total loss': 0.3581703320145607} | train loss {'Reaction outcome loss': 0.2603940784931183, 'Total loss': 0.2603940784931183}
2023-01-04 07:28:01,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:01,101 INFO:     Epoch: 89
2023-01-04 07:28:02,678 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3797138571739197, 'Total loss': 0.3797138571739197} | train loss {'Reaction outcome loss': 0.2561171935664283, 'Total loss': 0.2561171935664283}
2023-01-04 07:28:02,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:02,678 INFO:     Epoch: 90
2023-01-04 07:28:04,235 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36783871203660967, 'Total loss': 0.36783871203660967} | train loss {'Reaction outcome loss': 0.2583535568995608, 'Total loss': 0.2583535568995608}
2023-01-04 07:28:04,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:04,235 INFO:     Epoch: 91
2023-01-04 07:28:05,771 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4070413460334142, 'Total loss': 0.4070413460334142} | train loss {'Reaction outcome loss': 0.25958826999973367, 'Total loss': 0.25958826999973367}
2023-01-04 07:28:05,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:05,772 INFO:     Epoch: 92
2023-01-04 07:28:07,296 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37999510069688164, 'Total loss': 0.37999510069688164} | train loss {'Reaction outcome loss': 0.25665025225392096, 'Total loss': 0.25665025225392096}
2023-01-04 07:28:07,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:07,296 INFO:     Epoch: 93
2023-01-04 07:28:08,864 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.32055125925689937, 'Total loss': 0.32055125925689937} | train loss {'Reaction outcome loss': 0.2538977280811027, 'Total loss': 0.2538977280811027}
2023-01-04 07:28:08,865 INFO:     Found new best model at epoch 93
2023-01-04 07:28:08,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:08,865 INFO:     Epoch: 94
2023-01-04 07:28:10,422 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3506560360391935, 'Total loss': 0.3506560360391935} | train loss {'Reaction outcome loss': 0.25353222100271117, 'Total loss': 0.25353222100271117}
2023-01-04 07:28:10,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:10,422 INFO:     Epoch: 95
2023-01-04 07:28:11,990 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.34351737846930824, 'Total loss': 0.34351737846930824} | train loss {'Reaction outcome loss': 0.25612615977448444, 'Total loss': 0.25612615977448444}
2023-01-04 07:28:11,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:11,990 INFO:     Epoch: 96
2023-01-04 07:28:13,552 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3404751737912496, 'Total loss': 0.3404751737912496} | train loss {'Reaction outcome loss': 0.2527910132926923, 'Total loss': 0.2527910132926923}
2023-01-04 07:28:13,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:13,552 INFO:     Epoch: 97
2023-01-04 07:28:15,070 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3546799778938293, 'Total loss': 0.3546799778938293} | train loss {'Reaction outcome loss': 0.25068308254358945, 'Total loss': 0.25068308254358945}
2023-01-04 07:28:15,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:15,070 INFO:     Epoch: 98
2023-01-04 07:28:16,588 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3755041847626368, 'Total loss': 0.3755041847626368} | train loss {'Reaction outcome loss': 0.24932015389204026, 'Total loss': 0.24932015389204026}
2023-01-04 07:28:16,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:16,588 INFO:     Epoch: 99
2023-01-04 07:28:18,112 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3368860512971878, 'Total loss': 0.3368860512971878} | train loss {'Reaction outcome loss': 0.24988303741923085, 'Total loss': 0.24988303741923085}
2023-01-04 07:28:18,113 INFO:     Best model found after epoch 94 of 100.
2023-01-04 07:28:18,113 INFO:   Done with stage: TRAINING
2023-01-04 07:28:18,113 INFO:   Starting stage: EVALUATION
2023-01-04 07:28:18,262 INFO:   Done with stage: EVALUATION
2023-01-04 07:28:18,262 INFO:   Leaving out SEQ value Fold_3
2023-01-04 07:28:18,275 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 07:28:18,275 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:28:18,919 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:28:18,919 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:28:18,988 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:28:18,988 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:28:18,988 INFO:     No hyperparam tuning for this model
2023-01-04 07:28:18,988 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:28:18,988 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:28:18,989 INFO:     None feature selector for col prot
2023-01-04 07:28:18,989 INFO:     None feature selector for col prot
2023-01-04 07:28:18,989 INFO:     None feature selector for col prot
2023-01-04 07:28:18,990 INFO:     None feature selector for col chem
2023-01-04 07:28:18,990 INFO:     None feature selector for col chem
2023-01-04 07:28:18,990 INFO:     None feature selector for col chem
2023-01-04 07:28:18,990 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:28:18,990 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:28:18,991 INFO:     Number of params in model 70111
2023-01-04 07:28:18,994 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:28:18,994 INFO:   Starting stage: TRAINING
2023-01-04 07:28:19,036 INFO:     Val loss before train {'Reaction outcome loss': 1.0095893065134685, 'Total loss': 1.0095893065134685}
2023-01-04 07:28:19,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:19,037 INFO:     Epoch: 0
2023-01-04 07:28:20,592 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7599785625934601, 'Total loss': 0.7599785625934601} | train loss {'Reaction outcome loss': 0.834773662107768, 'Total loss': 0.834773662107768}
2023-01-04 07:28:20,592 INFO:     Found new best model at epoch 0
2023-01-04 07:28:20,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:20,593 INFO:     Epoch: 1
2023-01-04 07:28:22,127 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6423650940259298, 'Total loss': 0.6423650940259298} | train loss {'Reaction outcome loss': 0.6877258257333175, 'Total loss': 0.6877258257333175}
2023-01-04 07:28:22,129 INFO:     Found new best model at epoch 1
2023-01-04 07:28:22,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:22,129 INFO:     Epoch: 2
2023-01-04 07:28:23,659 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5692350735267003, 'Total loss': 0.5692350735267003} | train loss {'Reaction outcome loss': 0.5986629749064917, 'Total loss': 0.5986629749064917}
2023-01-04 07:28:23,659 INFO:     Found new best model at epoch 2
2023-01-04 07:28:23,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:23,660 INFO:     Epoch: 3
2023-01-04 07:28:25,188 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5261587997277578, 'Total loss': 0.5261587997277578} | train loss {'Reaction outcome loss': 0.55833416391205, 'Total loss': 0.55833416391205}
2023-01-04 07:28:25,188 INFO:     Found new best model at epoch 3
2023-01-04 07:28:25,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:25,188 INFO:     Epoch: 4
2023-01-04 07:28:26,744 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.524017318089803, 'Total loss': 0.524017318089803} | train loss {'Reaction outcome loss': 0.5329210646314062, 'Total loss': 0.5329210646314062}
2023-01-04 07:28:26,744 INFO:     Found new best model at epoch 4
2023-01-04 07:28:26,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:26,745 INFO:     Epoch: 5
2023-01-04 07:28:28,309 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5288691997528077, 'Total loss': 0.5288691997528077} | train loss {'Reaction outcome loss': 0.5198475773081238, 'Total loss': 0.5198475773081238}
2023-01-04 07:28:28,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:28,310 INFO:     Epoch: 6
2023-01-04 07:28:29,863 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5208629051844279, 'Total loss': 0.5208629051844279} | train loss {'Reaction outcome loss': 0.5025872030865142, 'Total loss': 0.5025872030865142}
2023-01-04 07:28:29,863 INFO:     Found new best model at epoch 6
2023-01-04 07:28:29,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:29,864 INFO:     Epoch: 7
2023-01-04 07:28:31,415 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5172475258509318, 'Total loss': 0.5172475258509318} | train loss {'Reaction outcome loss': 0.4943043433211662, 'Total loss': 0.4943043433211662}
2023-01-04 07:28:31,415 INFO:     Found new best model at epoch 7
2023-01-04 07:28:31,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:31,416 INFO:     Epoch: 8
2023-01-04 07:28:32,913 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47024640838305154, 'Total loss': 0.47024640838305154} | train loss {'Reaction outcome loss': 0.4876117372250819, 'Total loss': 0.4876117372250819}
2023-01-04 07:28:32,913 INFO:     Found new best model at epoch 8
2023-01-04 07:28:32,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:32,914 INFO:     Epoch: 9
2023-01-04 07:28:34,441 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47846884926160177, 'Total loss': 0.47846884926160177} | train loss {'Reaction outcome loss': 0.48230323784953943, 'Total loss': 0.48230323784953943}
2023-01-04 07:28:34,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:34,441 INFO:     Epoch: 10
2023-01-04 07:28:35,999 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47933985888957975, 'Total loss': 0.47933985888957975} | train loss {'Reaction outcome loss': 0.4730131519692285, 'Total loss': 0.4730131519692285}
2023-01-04 07:28:35,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:36,000 INFO:     Epoch: 11
2023-01-04 07:28:37,567 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4628923137982686, 'Total loss': 0.4628923137982686} | train loss {'Reaction outcome loss': 0.46459409496286413, 'Total loss': 0.46459409496286413}
2023-01-04 07:28:37,567 INFO:     Found new best model at epoch 11
2023-01-04 07:28:37,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:37,568 INFO:     Epoch: 12
2023-01-04 07:28:39,124 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44946901003519696, 'Total loss': 0.44946901003519696} | train loss {'Reaction outcome loss': 0.45557794471581775, 'Total loss': 0.45557794471581775}
2023-01-04 07:28:39,124 INFO:     Found new best model at epoch 12
2023-01-04 07:28:39,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:39,125 INFO:     Epoch: 13
2023-01-04 07:28:40,694 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4540429040789604, 'Total loss': 0.4540429040789604} | train loss {'Reaction outcome loss': 0.45050967165402006, 'Total loss': 0.45050967165402006}
2023-01-04 07:28:40,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:40,695 INFO:     Epoch: 14
2023-01-04 07:28:42,189 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4797614316145579, 'Total loss': 0.4797614316145579} | train loss {'Reaction outcome loss': 0.4517150865424247, 'Total loss': 0.4517150865424247}
2023-01-04 07:28:42,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:42,189 INFO:     Epoch: 15
2023-01-04 07:28:43,764 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45614175299803417, 'Total loss': 0.45614175299803417} | train loss {'Reaction outcome loss': 0.44615260372450066, 'Total loss': 0.44615260372450066}
2023-01-04 07:28:43,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:43,764 INFO:     Epoch: 16
2023-01-04 07:28:45,325 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44720312505960463, 'Total loss': 0.44720312505960463} | train loss {'Reaction outcome loss': 0.440436000652584, 'Total loss': 0.440436000652584}
2023-01-04 07:28:45,325 INFO:     Found new best model at epoch 16
2023-01-04 07:28:45,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:45,326 INFO:     Epoch: 17
2023-01-04 07:28:46,887 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46924114028612773, 'Total loss': 0.46924114028612773} | train loss {'Reaction outcome loss': 0.4303060146151008, 'Total loss': 0.4303060146151008}
2023-01-04 07:28:46,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:46,887 INFO:     Epoch: 18
2023-01-04 07:28:48,449 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45355098843574526, 'Total loss': 0.45355098843574526} | train loss {'Reaction outcome loss': 0.43139094791132887, 'Total loss': 0.43139094791132887}
2023-01-04 07:28:48,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:48,449 INFO:     Epoch: 19
2023-01-04 07:28:50,030 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4471436341603597, 'Total loss': 0.4471436341603597} | train loss {'Reaction outcome loss': 0.4270226653569784, 'Total loss': 0.4270226653569784}
2023-01-04 07:28:50,030 INFO:     Found new best model at epoch 19
2023-01-04 07:28:50,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:50,031 INFO:     Epoch: 20
2023-01-04 07:28:51,525 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4193071852127711, 'Total loss': 0.4193071852127711} | train loss {'Reaction outcome loss': 0.41963597406179476, 'Total loss': 0.41963597406179476}
2023-01-04 07:28:51,525 INFO:     Found new best model at epoch 20
2023-01-04 07:28:51,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:51,526 INFO:     Epoch: 21
2023-01-04 07:28:53,092 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4244963695605596, 'Total loss': 0.4244963695605596} | train loss {'Reaction outcome loss': 0.42039627611855446, 'Total loss': 0.42039627611855446}
2023-01-04 07:28:53,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:53,093 INFO:     Epoch: 22
2023-01-04 07:28:54,660 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45924931168556216, 'Total loss': 0.45924931168556216} | train loss {'Reaction outcome loss': 0.4094075924638427, 'Total loss': 0.4094075924638427}
2023-01-04 07:28:54,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:54,660 INFO:     Epoch: 23
2023-01-04 07:28:56,203 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4393022874991099, 'Total loss': 0.4393022874991099} | train loss {'Reaction outcome loss': 0.40625958919743477, 'Total loss': 0.40625958919743477}
2023-01-04 07:28:56,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:56,204 INFO:     Epoch: 24
2023-01-04 07:28:57,762 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45624731878439584, 'Total loss': 0.45624731878439584} | train loss {'Reaction outcome loss': 0.3996492152139817, 'Total loss': 0.3996492152139817}
2023-01-04 07:28:57,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:57,762 INFO:     Epoch: 25
2023-01-04 07:28:59,290 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4264515548944473, 'Total loss': 0.4264515548944473} | train loss {'Reaction outcome loss': 0.40020539797160215, 'Total loss': 0.40020539797160215}
2023-01-04 07:28:59,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:28:59,291 INFO:     Epoch: 26
2023-01-04 07:29:00,778 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.421765144666036, 'Total loss': 0.421765144666036} | train loss {'Reaction outcome loss': 0.39745996324788957, 'Total loss': 0.39745996324788957}
2023-01-04 07:29:00,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:00,779 INFO:     Epoch: 27
2023-01-04 07:29:02,320 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45375582079092663, 'Total loss': 0.45375582079092663} | train loss {'Reaction outcome loss': 0.3920146330863565, 'Total loss': 0.3920146330863565}
2023-01-04 07:29:02,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:02,320 INFO:     Epoch: 28
2023-01-04 07:29:03,887 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4159002552429835, 'Total loss': 0.4159002552429835} | train loss {'Reaction outcome loss': 0.38862276208269725, 'Total loss': 0.38862276208269725}
2023-01-04 07:29:03,887 INFO:     Found new best model at epoch 28
2023-01-04 07:29:03,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:03,888 INFO:     Epoch: 29
2023-01-04 07:29:05,473 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4393703043460846, 'Total loss': 0.4393703043460846} | train loss {'Reaction outcome loss': 0.3840048032038378, 'Total loss': 0.3840048032038378}
2023-01-04 07:29:05,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:05,473 INFO:     Epoch: 30
2023-01-04 07:29:07,056 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4227233539024989, 'Total loss': 0.4227233539024989} | train loss {'Reaction outcome loss': 0.3832904200850826, 'Total loss': 0.3832904200850826}
2023-01-04 07:29:07,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:07,056 INFO:     Epoch: 31
2023-01-04 07:29:08,623 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44217673142751057, 'Total loss': 0.44217673142751057} | train loss {'Reaction outcome loss': 0.37462937873498203, 'Total loss': 0.37462937873498203}
2023-01-04 07:29:08,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:08,623 INFO:     Epoch: 32
2023-01-04 07:29:10,138 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4136202891667684, 'Total loss': 0.4136202891667684} | train loss {'Reaction outcome loss': 0.3722870243992998, 'Total loss': 0.3722870243992998}
2023-01-04 07:29:10,138 INFO:     Found new best model at epoch 32
2023-01-04 07:29:10,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:10,139 INFO:     Epoch: 33
2023-01-04 07:29:11,707 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42443859577178955, 'Total loss': 0.42443859577178955} | train loss {'Reaction outcome loss': 0.36921039815896595, 'Total loss': 0.36921039815896595}
2023-01-04 07:29:11,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:11,708 INFO:     Epoch: 34
2023-01-04 07:29:13,234 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4411212384700775, 'Total loss': 0.4411212384700775} | train loss {'Reaction outcome loss': 0.36900897654312437, 'Total loss': 0.36900897654312437}
2023-01-04 07:29:13,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:13,234 INFO:     Epoch: 35
2023-01-04 07:29:14,768 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44291741053263345, 'Total loss': 0.44291741053263345} | train loss {'Reaction outcome loss': 0.3642909870152072, 'Total loss': 0.3642909870152072}
2023-01-04 07:29:14,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:14,769 INFO:     Epoch: 36
2023-01-04 07:29:16,285 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4315042426188787, 'Total loss': 0.4315042426188787} | train loss {'Reaction outcome loss': 0.36305701658948436, 'Total loss': 0.36305701658948436}
2023-01-04 07:29:16,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:16,285 INFO:     Epoch: 37
2023-01-04 07:29:17,798 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45129642486572263, 'Total loss': 0.45129642486572263} | train loss {'Reaction outcome loss': 0.3586364180777536, 'Total loss': 0.3586364180777536}
2023-01-04 07:29:17,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:17,798 INFO:     Epoch: 38
2023-01-04 07:29:19,316 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4140214666724205, 'Total loss': 0.4140214666724205} | train loss {'Reaction outcome loss': 0.35891796757668365, 'Total loss': 0.35891796757668365}
2023-01-04 07:29:19,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:19,316 INFO:     Epoch: 39
2023-01-04 07:29:20,874 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4065081020196279, 'Total loss': 0.4065081020196279} | train loss {'Reaction outcome loss': 0.34871835643664384, 'Total loss': 0.34871835643664384}
2023-01-04 07:29:20,875 INFO:     Found new best model at epoch 39
2023-01-04 07:29:20,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:20,875 INFO:     Epoch: 40
2023-01-04 07:29:22,404 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4365458826224009, 'Total loss': 0.4365458826224009} | train loss {'Reaction outcome loss': 0.34816220233510264, 'Total loss': 0.34816220233510264}
2023-01-04 07:29:22,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:22,404 INFO:     Epoch: 41
2023-01-04 07:29:23,946 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4321817179520925, 'Total loss': 0.4321817179520925} | train loss {'Reaction outcome loss': 0.34246894133178307, 'Total loss': 0.34246894133178307}
2023-01-04 07:29:23,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:23,947 INFO:     Epoch: 42
2023-01-04 07:29:25,490 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4373399366935094, 'Total loss': 0.4373399366935094} | train loss {'Reaction outcome loss': 0.3458742766262411, 'Total loss': 0.3458742766262411}
2023-01-04 07:29:25,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:25,490 INFO:     Epoch: 43
2023-01-04 07:29:27,016 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4360229939222336, 'Total loss': 0.4360229939222336} | train loss {'Reaction outcome loss': 0.34330528586993725, 'Total loss': 0.34330528586993725}
2023-01-04 07:29:27,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:27,016 INFO:     Epoch: 44
2023-01-04 07:29:28,520 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4087416132291158, 'Total loss': 0.4087416132291158} | train loss {'Reaction outcome loss': 0.33840777574878034, 'Total loss': 0.33840777574878034}
2023-01-04 07:29:28,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:28,520 INFO:     Epoch: 45
2023-01-04 07:29:30,060 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4233743409315745, 'Total loss': 0.4233743409315745} | train loss {'Reaction outcome loss': 0.33397163221469295, 'Total loss': 0.33397163221469295}
2023-01-04 07:29:30,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:30,061 INFO:     Epoch: 46
2023-01-04 07:29:31,597 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42027072608470917, 'Total loss': 0.42027072608470917} | train loss {'Reaction outcome loss': 0.3337502937231745, 'Total loss': 0.3337502937231745}
2023-01-04 07:29:31,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:31,597 INFO:     Epoch: 47
2023-01-04 07:29:33,123 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4186818202336629, 'Total loss': 0.4186818202336629} | train loss {'Reaction outcome loss': 0.3339965594557179, 'Total loss': 0.3339965594557179}
2023-01-04 07:29:33,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:33,123 INFO:     Epoch: 48
2023-01-04 07:29:34,671 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4188162217537562, 'Total loss': 0.4188162217537562} | train loss {'Reaction outcome loss': 0.3255764032294462, 'Total loss': 0.3255764032294462}
2023-01-04 07:29:34,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:34,671 INFO:     Epoch: 49
2023-01-04 07:29:36,179 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41583962241808575, 'Total loss': 0.41583962241808575} | train loss {'Reaction outcome loss': 0.3275652118709498, 'Total loss': 0.3275652118709498}
2023-01-04 07:29:36,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:36,179 INFO:     Epoch: 50
2023-01-04 07:29:37,712 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43198166688283285, 'Total loss': 0.43198166688283285} | train loss {'Reaction outcome loss': 0.323775301185938, 'Total loss': 0.323775301185938}
2023-01-04 07:29:37,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:37,712 INFO:     Epoch: 51
2023-01-04 07:29:39,299 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4462160428365072, 'Total loss': 0.4462160428365072} | train loss {'Reaction outcome loss': 0.32183129916260966, 'Total loss': 0.32183129916260966}
2023-01-04 07:29:39,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:39,299 INFO:     Epoch: 52
2023-01-04 07:29:40,873 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4149869774778684, 'Total loss': 0.4149869774778684} | train loss {'Reaction outcome loss': 0.3188334312631097, 'Total loss': 0.3188334312631097}
2023-01-04 07:29:40,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:40,873 INFO:     Epoch: 53
2023-01-04 07:29:42,442 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3928494967520237, 'Total loss': 0.3928494967520237} | train loss {'Reaction outcome loss': 0.3229482123839768, 'Total loss': 0.3229482123839768}
2023-01-04 07:29:42,443 INFO:     Found new best model at epoch 53
2023-01-04 07:29:42,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:42,444 INFO:     Epoch: 54
2023-01-04 07:29:43,992 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4325935304164886, 'Total loss': 0.4325935304164886} | train loss {'Reaction outcome loss': 0.313420801290444, 'Total loss': 0.313420801290444}
2023-01-04 07:29:43,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:43,993 INFO:     Epoch: 55
2023-01-04 07:29:45,499 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42706941862901054, 'Total loss': 0.42706941862901054} | train loss {'Reaction outcome loss': 0.3134419763317475, 'Total loss': 0.3134419763317475}
2023-01-04 07:29:45,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:45,499 INFO:     Epoch: 56
2023-01-04 07:29:47,010 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4361091693242391, 'Total loss': 0.4361091693242391} | train loss {'Reaction outcome loss': 0.31659696496777484, 'Total loss': 0.31659696496777484}
2023-01-04 07:29:47,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:47,010 INFO:     Epoch: 57
2023-01-04 07:29:48,541 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42070322136084237, 'Total loss': 0.42070322136084237} | train loss {'Reaction outcome loss': 0.30922609139165597, 'Total loss': 0.30922609139165597}
2023-01-04 07:29:48,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:48,541 INFO:     Epoch: 58
2023-01-04 07:29:50,064 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4068776826063792, 'Total loss': 0.4068776826063792} | train loss {'Reaction outcome loss': 0.31054747800578125, 'Total loss': 0.31054747800578125}
2023-01-04 07:29:50,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:50,064 INFO:     Epoch: 59
2023-01-04 07:29:51,597 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40170765270789466, 'Total loss': 0.40170765270789466} | train loss {'Reaction outcome loss': 0.3044426462207085, 'Total loss': 0.3044426462207085}
2023-01-04 07:29:51,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:51,597 INFO:     Epoch: 60
2023-01-04 07:29:53,122 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4203169246514638, 'Total loss': 0.4203169246514638} | train loss {'Reaction outcome loss': 0.2988670078880621, 'Total loss': 0.2988670078880621}
2023-01-04 07:29:53,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:53,122 INFO:     Epoch: 61
2023-01-04 07:29:54,606 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45665011604626976, 'Total loss': 0.45665011604626976} | train loss {'Reaction outcome loss': 0.30507077470476374, 'Total loss': 0.30507077470476374}
2023-01-04 07:29:54,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:54,607 INFO:     Epoch: 62
2023-01-04 07:29:56,132 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4288306107123693, 'Total loss': 0.4288306107123693} | train loss {'Reaction outcome loss': 0.29774468411237764, 'Total loss': 0.29774468411237764}
2023-01-04 07:29:56,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:56,132 INFO:     Epoch: 63
2023-01-04 07:29:57,673 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4173133651415507, 'Total loss': 0.4173133651415507} | train loss {'Reaction outcome loss': 0.3021048305781333, 'Total loss': 0.3021048305781333}
2023-01-04 07:29:57,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:57,673 INFO:     Epoch: 64
2023-01-04 07:29:59,212 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42875323494275414, 'Total loss': 0.42875323494275414} | train loss {'Reaction outcome loss': 0.2993792529617037, 'Total loss': 0.2993792529617037}
2023-01-04 07:29:59,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:29:59,212 INFO:     Epoch: 65
2023-01-04 07:30:00,752 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42696371773878733, 'Total loss': 0.42696371773878733} | train loss {'Reaction outcome loss': 0.3039110800176313, 'Total loss': 0.3039110800176313}
2023-01-04 07:30:00,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:00,753 INFO:     Epoch: 66
2023-01-04 07:30:02,289 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4512653797864914, 'Total loss': 0.4512653797864914} | train loss {'Reaction outcome loss': 0.298479565429491, 'Total loss': 0.298479565429491}
2023-01-04 07:30:02,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:02,289 INFO:     Epoch: 67
2023-01-04 07:30:03,764 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4601089855035146, 'Total loss': 0.4601089855035146} | train loss {'Reaction outcome loss': 0.2936560473380945, 'Total loss': 0.2936560473380945}
2023-01-04 07:30:03,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:03,764 INFO:     Epoch: 68
2023-01-04 07:30:05,303 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39257159531116487, 'Total loss': 0.39257159531116487} | train loss {'Reaction outcome loss': 0.29564726849652884, 'Total loss': 0.29564726849652884}
2023-01-04 07:30:05,304 INFO:     Found new best model at epoch 68
2023-01-04 07:30:05,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:05,304 INFO:     Epoch: 69
2023-01-04 07:30:06,844 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4366174320379893, 'Total loss': 0.4366174320379893} | train loss {'Reaction outcome loss': 0.29069800159105885, 'Total loss': 0.29069800159105885}
2023-01-04 07:30:06,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:06,845 INFO:     Epoch: 70
2023-01-04 07:30:08,386 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4135112911462784, 'Total loss': 0.4135112911462784} | train loss {'Reaction outcome loss': 0.2884209394291207, 'Total loss': 0.2884209394291207}
2023-01-04 07:30:08,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:08,386 INFO:     Epoch: 71
2023-01-04 07:30:09,933 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4394882147510846, 'Total loss': 0.4394882147510846} | train loss {'Reaction outcome loss': 0.29226395793450183, 'Total loss': 0.29226395793450183}
2023-01-04 07:30:09,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:09,933 INFO:     Epoch: 72
2023-01-04 07:30:11,462 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41343224545319873, 'Total loss': 0.41343224545319873} | train loss {'Reaction outcome loss': 0.28342564193866193, 'Total loss': 0.28342564193866193}
2023-01-04 07:30:11,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:11,462 INFO:     Epoch: 73
2023-01-04 07:30:12,935 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4239771445592245, 'Total loss': 0.4239771445592245} | train loss {'Reaction outcome loss': 0.2846892956139404, 'Total loss': 0.2846892956139404}
2023-01-04 07:30:12,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:12,936 INFO:     Epoch: 74
2023-01-04 07:30:14,477 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4434840604662895, 'Total loss': 0.4434840604662895} | train loss {'Reaction outcome loss': 0.2907456799031614, 'Total loss': 0.2907456799031614}
2023-01-04 07:30:14,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:14,477 INFO:     Epoch: 75
2023-01-04 07:30:16,028 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3984195202589035, 'Total loss': 0.3984195202589035} | train loss {'Reaction outcome loss': 0.28898357976596434, 'Total loss': 0.28898357976596434}
2023-01-04 07:30:16,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:16,028 INFO:     Epoch: 76
2023-01-04 07:30:17,572 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.430439829826355, 'Total loss': 0.430439829826355} | train loss {'Reaction outcome loss': 0.280838895875674, 'Total loss': 0.280838895875674}
2023-01-04 07:30:17,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:17,572 INFO:     Epoch: 77
2023-01-04 07:30:19,124 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41719059844811757, 'Total loss': 0.41719059844811757} | train loss {'Reaction outcome loss': 0.2885878819412801, 'Total loss': 0.2885878819412801}
2023-01-04 07:30:19,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:19,125 INFO:     Epoch: 78
2023-01-04 07:30:20,669 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4375214139620463, 'Total loss': 0.4375214139620463} | train loss {'Reaction outcome loss': 0.282503835884206, 'Total loss': 0.282503835884206}
2023-01-04 07:30:20,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:20,669 INFO:     Epoch: 79
2023-01-04 07:30:22,137 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4236181269089381, 'Total loss': 0.4236181269089381} | train loss {'Reaction outcome loss': 0.28204291147408467, 'Total loss': 0.28204291147408467}
2023-01-04 07:30:22,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:22,137 INFO:     Epoch: 80
2023-01-04 07:30:23,662 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4357892672220866, 'Total loss': 0.4357892672220866} | train loss {'Reaction outcome loss': 0.27538966270156834, 'Total loss': 0.27538966270156834}
2023-01-04 07:30:23,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:23,662 INFO:     Epoch: 81
2023-01-04 07:30:25,203 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4004429111878077, 'Total loss': 0.4004429111878077} | train loss {'Reaction outcome loss': 0.27475356489365355, 'Total loss': 0.27475356489365355}
2023-01-04 07:30:25,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:25,204 INFO:     Epoch: 82
2023-01-04 07:30:26,742 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4385127087434133, 'Total loss': 0.4385127087434133} | train loss {'Reaction outcome loss': 0.2741217338804142, 'Total loss': 0.2741217338804142}
2023-01-04 07:30:26,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:26,742 INFO:     Epoch: 83
2023-01-04 07:30:28,288 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4016935467720032, 'Total loss': 0.4016935467720032} | train loss {'Reaction outcome loss': 0.27259930471579236, 'Total loss': 0.27259930471579236}
2023-01-04 07:30:28,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:28,288 INFO:     Epoch: 84
2023-01-04 07:30:29,846 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4175323486328125, 'Total loss': 0.4175323486328125} | train loss {'Reaction outcome loss': 0.2728850785711091, 'Total loss': 0.2728850785711091}
2023-01-04 07:30:29,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:29,847 INFO:     Epoch: 85
2023-01-04 07:30:31,341 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4560864746570587, 'Total loss': 0.4560864746570587} | train loss {'Reaction outcome loss': 0.2686147296275848, 'Total loss': 0.2686147296275848}
2023-01-04 07:30:31,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:31,342 INFO:     Epoch: 86
2023-01-04 07:30:32,894 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43418042560418446, 'Total loss': 0.43418042560418446} | train loss {'Reaction outcome loss': 0.2742905442640458, 'Total loss': 0.2742905442640458}
2023-01-04 07:30:32,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:32,894 INFO:     Epoch: 87
2023-01-04 07:30:34,446 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38580387979745867, 'Total loss': 0.38580387979745867} | train loss {'Reaction outcome loss': 0.27064106594293547, 'Total loss': 0.27064106594293547}
2023-01-04 07:30:34,446 INFO:     Found new best model at epoch 87
2023-01-04 07:30:34,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:34,447 INFO:     Epoch: 88
2023-01-04 07:30:35,991 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42118300596872965, 'Total loss': 0.42118300596872965} | train loss {'Reaction outcome loss': 0.26833391735405276, 'Total loss': 0.26833391735405276}
2023-01-04 07:30:35,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:35,992 INFO:     Epoch: 89
2023-01-04 07:30:37,537 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41400205890337627, 'Total loss': 0.41400205890337627} | train loss {'Reaction outcome loss': 0.27112386645851555, 'Total loss': 0.27112386645851555}
2023-01-04 07:30:37,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:37,538 INFO:     Epoch: 90
2023-01-04 07:30:39,088 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44363328218460085, 'Total loss': 0.44363328218460085} | train loss {'Reaction outcome loss': 0.26700970415885633, 'Total loss': 0.26700970415885633}
2023-01-04 07:30:39,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:39,088 INFO:     Epoch: 91
2023-01-04 07:30:40,567 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44164273341496785, 'Total loss': 0.44164273341496785} | train loss {'Reaction outcome loss': 0.26845572834268155, 'Total loss': 0.26845572834268155}
2023-01-04 07:30:40,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:40,568 INFO:     Epoch: 92
2023-01-04 07:30:42,112 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4211240619421005, 'Total loss': 0.4211240619421005} | train loss {'Reaction outcome loss': 0.26844910504944597, 'Total loss': 0.26844910504944597}
2023-01-04 07:30:42,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:42,113 INFO:     Epoch: 93
2023-01-04 07:30:43,665 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4566789627075195, 'Total loss': 0.4566789627075195} | train loss {'Reaction outcome loss': 0.262133658287071, 'Total loss': 0.262133658287071}
2023-01-04 07:30:43,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:43,666 INFO:     Epoch: 94
2023-01-04 07:30:45,207 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45473516881465914, 'Total loss': 0.45473516881465914} | train loss {'Reaction outcome loss': 0.2635429745519554, 'Total loss': 0.2635429745519554}
2023-01-04 07:30:45,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:45,207 INFO:     Epoch: 95
2023-01-04 07:30:46,762 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4425249814987183, 'Total loss': 0.4425249814987183} | train loss {'Reaction outcome loss': 0.2630167709110857, 'Total loss': 0.2630167709110857}
2023-01-04 07:30:46,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:46,762 INFO:     Epoch: 96
2023-01-04 07:30:48,298 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40563463469346367, 'Total loss': 0.40563463469346367} | train loss {'Reaction outcome loss': 0.26585738444120893, 'Total loss': 0.26585738444120893}
2023-01-04 07:30:48,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:48,298 INFO:     Epoch: 97
2023-01-04 07:30:49,786 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42607579231262205, 'Total loss': 0.42607579231262205} | train loss {'Reaction outcome loss': 0.26386290818671165, 'Total loss': 0.26386290818671165}
2023-01-04 07:30:49,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:49,786 INFO:     Epoch: 98
2023-01-04 07:30:51,338 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44735495845476786, 'Total loss': 0.44735495845476786} | train loss {'Reaction outcome loss': 0.25791522387019444, 'Total loss': 0.25791522387019444}
2023-01-04 07:30:51,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:51,339 INFO:     Epoch: 99
2023-01-04 07:30:52,908 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4700871527194977, 'Total loss': 0.4700871527194977} | train loss {'Reaction outcome loss': 0.26221684885003194, 'Total loss': 0.26221684885003194}
2023-01-04 07:30:52,909 INFO:     Best model found after epoch 88 of 100.
2023-01-04 07:30:52,909 INFO:   Done with stage: TRAINING
2023-01-04 07:30:52,909 INFO:   Starting stage: EVALUATION
2023-01-04 07:30:53,048 INFO:   Done with stage: EVALUATION
2023-01-04 07:30:53,048 INFO:   Leaving out SEQ value Fold_4
2023-01-04 07:30:53,060 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:30:53,060 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:30:53,703 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:30:53,703 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:30:53,772 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:30:53,772 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:30:53,772 INFO:     No hyperparam tuning for this model
2023-01-04 07:30:53,772 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:30:53,772 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:30:53,773 INFO:     None feature selector for col prot
2023-01-04 07:30:53,773 INFO:     None feature selector for col prot
2023-01-04 07:30:53,773 INFO:     None feature selector for col prot
2023-01-04 07:30:53,774 INFO:     None feature selector for col chem
2023-01-04 07:30:53,774 INFO:     None feature selector for col chem
2023-01-04 07:30:53,774 INFO:     None feature selector for col chem
2023-01-04 07:30:53,774 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:30:53,774 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:30:53,775 INFO:     Number of params in model 70111
2023-01-04 07:30:53,778 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:30:53,778 INFO:   Starting stage: TRAINING
2023-01-04 07:30:53,821 INFO:     Val loss before train {'Reaction outcome loss': 0.9421151479085287, 'Total loss': 0.9421151479085287}
2023-01-04 07:30:53,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:53,821 INFO:     Epoch: 0
2023-01-04 07:30:55,361 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6543220957120259, 'Total loss': 0.6543220957120259} | train loss {'Reaction outcome loss': 0.8215782498929015, 'Total loss': 0.8215782498929015}
2023-01-04 07:30:55,362 INFO:     Found new best model at epoch 0
2023-01-04 07:30:55,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:55,362 INFO:     Epoch: 1
2023-01-04 07:30:56,937 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5415646106004715, 'Total loss': 0.5415646106004715} | train loss {'Reaction outcome loss': 0.6397534958542446, 'Total loss': 0.6397534958542446}
2023-01-04 07:30:56,938 INFO:     Found new best model at epoch 1
2023-01-04 07:30:56,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:56,939 INFO:     Epoch: 2
2023-01-04 07:30:58,466 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5474460661411286, 'Total loss': 0.5474460661411286} | train loss {'Reaction outcome loss': 0.5525526471058095, 'Total loss': 0.5525526471058095}
2023-01-04 07:30:58,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:30:58,466 INFO:     Epoch: 3
2023-01-04 07:31:00,041 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5198613166809082, 'Total loss': 0.5198613166809082} | train loss {'Reaction outcome loss': 0.520248254639623, 'Total loss': 0.520248254639623}
2023-01-04 07:31:00,041 INFO:     Found new best model at epoch 3
2023-01-04 07:31:00,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:00,042 INFO:     Epoch: 4
2023-01-04 07:31:01,617 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5185274501641591, 'Total loss': 0.5185274501641591} | train loss {'Reaction outcome loss': 0.497577736459578, 'Total loss': 0.497577736459578}
2023-01-04 07:31:01,618 INFO:     Found new best model at epoch 4
2023-01-04 07:31:01,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:01,618 INFO:     Epoch: 5
2023-01-04 07:31:03,184 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5259812533855438, 'Total loss': 0.5259812533855438} | train loss {'Reaction outcome loss': 0.48701209067434503, 'Total loss': 0.48701209067434503}
2023-01-04 07:31:03,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:03,185 INFO:     Epoch: 6
2023-01-04 07:31:04,764 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4965312659740448, 'Total loss': 0.4965312659740448} | train loss {'Reaction outcome loss': 0.48305255473604886, 'Total loss': 0.48305255473604886}
2023-01-04 07:31:04,764 INFO:     Found new best model at epoch 6
2023-01-04 07:31:04,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:04,765 INFO:     Epoch: 7
2023-01-04 07:31:06,305 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4759890377521515, 'Total loss': 0.4759890377521515} | train loss {'Reaction outcome loss': 0.46494657327623473, 'Total loss': 0.46494657327623473}
2023-01-04 07:31:06,305 INFO:     Found new best model at epoch 7
2023-01-04 07:31:06,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:06,306 INFO:     Epoch: 8
2023-01-04 07:31:07,847 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45018608967463175, 'Total loss': 0.45018608967463175} | train loss {'Reaction outcome loss': 0.46386219575746823, 'Total loss': 0.46386219575746823}
2023-01-04 07:31:07,847 INFO:     Found new best model at epoch 8
2023-01-04 07:31:07,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:07,848 INFO:     Epoch: 9
2023-01-04 07:31:09,424 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49347116947174074, 'Total loss': 0.49347116947174074} | train loss {'Reaction outcome loss': 0.45749599454195605, 'Total loss': 0.45749599454195605}
2023-01-04 07:31:09,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:09,424 INFO:     Epoch: 10
2023-01-04 07:31:10,995 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47919897039731346, 'Total loss': 0.47919897039731346} | train loss {'Reaction outcome loss': 0.45374937782037084, 'Total loss': 0.45374937782037084}
2023-01-04 07:31:10,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:10,995 INFO:     Epoch: 11
2023-01-04 07:31:12,575 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49415934284528096, 'Total loss': 0.49415934284528096} | train loss {'Reaction outcome loss': 0.4618048012641299, 'Total loss': 0.4618048012641299}
2023-01-04 07:31:12,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:12,575 INFO:     Epoch: 12
2023-01-04 07:31:14,171 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47540401220321654, 'Total loss': 0.47540401220321654} | train loss {'Reaction outcome loss': 0.4344030378683322, 'Total loss': 0.4344030378683322}
2023-01-04 07:31:14,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:14,171 INFO:     Epoch: 13
2023-01-04 07:31:15,736 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.444534832239151, 'Total loss': 0.444534832239151} | train loss {'Reaction outcome loss': 0.43927209564223985, 'Total loss': 0.43927209564223985}
2023-01-04 07:31:15,737 INFO:     Found new best model at epoch 13
2023-01-04 07:31:15,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:15,738 INFO:     Epoch: 14
2023-01-04 07:31:17,295 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4454149623711904, 'Total loss': 0.4454149623711904} | train loss {'Reaction outcome loss': 0.4306082473932833, 'Total loss': 0.4306082473932833}
2023-01-04 07:31:17,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:17,295 INFO:     Epoch: 15
2023-01-04 07:31:18,903 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.447614190975825, 'Total loss': 0.447614190975825} | train loss {'Reaction outcome loss': 0.43763672808806103, 'Total loss': 0.43763672808806103}
2023-01-04 07:31:18,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:18,903 INFO:     Epoch: 16
2023-01-04 07:31:20,487 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4684189945459366, 'Total loss': 0.4684189945459366} | train loss {'Reaction outcome loss': 0.42980568073487474, 'Total loss': 0.42980568073487474}
2023-01-04 07:31:20,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:20,488 INFO:     Epoch: 17
2023-01-04 07:31:22,089 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42771241863568626, 'Total loss': 0.42771241863568626} | train loss {'Reaction outcome loss': 0.4137208168766043, 'Total loss': 0.4137208168766043}
2023-01-04 07:31:22,089 INFO:     Found new best model at epoch 17
2023-01-04 07:31:22,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:22,090 INFO:     Epoch: 18
2023-01-04 07:31:23,688 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44007533192634585, 'Total loss': 0.44007533192634585} | train loss {'Reaction outcome loss': 0.41107544910324656, 'Total loss': 0.41107544910324656}
2023-01-04 07:31:23,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:23,688 INFO:     Epoch: 19
2023-01-04 07:31:25,193 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44834483961264293, 'Total loss': 0.44834483961264293} | train loss {'Reaction outcome loss': 0.4106103669042911, 'Total loss': 0.4106103669042911}
2023-01-04 07:31:25,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:25,193 INFO:     Epoch: 20
2023-01-04 07:31:26,765 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4539138893286387, 'Total loss': 0.4539138893286387} | train loss {'Reaction outcome loss': 0.4038880086752571, 'Total loss': 0.4038880086752571}
2023-01-04 07:31:26,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:26,767 INFO:     Epoch: 21
2023-01-04 07:31:28,324 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43991032242774963, 'Total loss': 0.43991032242774963} | train loss {'Reaction outcome loss': 0.40127352795874077, 'Total loss': 0.40127352795874077}
2023-01-04 07:31:28,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:28,325 INFO:     Epoch: 22
2023-01-04 07:31:29,877 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.433051136136055, 'Total loss': 0.433051136136055} | train loss {'Reaction outcome loss': 0.397870047239585, 'Total loss': 0.397870047239585}
2023-01-04 07:31:29,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:29,877 INFO:     Epoch: 23
2023-01-04 07:31:31,425 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4255547513564428, 'Total loss': 0.4255547513564428} | train loss {'Reaction outcome loss': 0.39380304033672303, 'Total loss': 0.39380304033672303}
2023-01-04 07:31:31,425 INFO:     Found new best model at epoch 23
2023-01-04 07:31:31,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:31,426 INFO:     Epoch: 24
2023-01-04 07:31:32,996 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44058805306752524, 'Total loss': 0.44058805306752524} | train loss {'Reaction outcome loss': 0.39039425292909413, 'Total loss': 0.39039425292909413}
2023-01-04 07:31:32,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:32,997 INFO:     Epoch: 25
2023-01-04 07:31:34,504 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43267221947511036, 'Total loss': 0.43267221947511036} | train loss {'Reaction outcome loss': 0.3845135883644959, 'Total loss': 0.3845135883644959}
2023-01-04 07:31:34,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:34,504 INFO:     Epoch: 26
2023-01-04 07:31:36,101 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.498295271396637, 'Total loss': 0.498295271396637} | train loss {'Reaction outcome loss': 0.3886335307489271, 'Total loss': 0.3886335307489271}
2023-01-04 07:31:36,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:36,101 INFO:     Epoch: 27
2023-01-04 07:31:37,674 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4172159214814504, 'Total loss': 0.4172159214814504} | train loss {'Reaction outcome loss': 0.41069902891151444, 'Total loss': 0.41069902891151444}
2023-01-04 07:31:37,675 INFO:     Found new best model at epoch 27
2023-01-04 07:31:37,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:37,675 INFO:     Epoch: 28
2023-01-04 07:31:39,238 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4191528956095378, 'Total loss': 0.4191528956095378} | train loss {'Reaction outcome loss': 0.37712634796432964, 'Total loss': 0.37712634796432964}
2023-01-04 07:31:39,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:39,238 INFO:     Epoch: 29
2023-01-04 07:31:40,786 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4284006734689077, 'Total loss': 0.4284006734689077} | train loss {'Reaction outcome loss': 0.36987463471503335, 'Total loss': 0.36987463471503335}
2023-01-04 07:31:40,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:40,787 INFO:     Epoch: 30
2023-01-04 07:31:42,360 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43975977698961893, 'Total loss': 0.43975977698961893} | train loss {'Reaction outcome loss': 0.3685359853333321, 'Total loss': 0.3685359853333321}
2023-01-04 07:31:42,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:42,360 INFO:     Epoch: 31
2023-01-04 07:31:43,871 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4256089429060618, 'Total loss': 0.4256089429060618} | train loss {'Reaction outcome loss': 0.3690182800958122, 'Total loss': 0.3690182800958122}
2023-01-04 07:31:43,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:43,871 INFO:     Epoch: 32
2023-01-04 07:31:45,442 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4277021537224452, 'Total loss': 0.4277021537224452} | train loss {'Reaction outcome loss': 0.362126348182505, 'Total loss': 0.362126348182505}
2023-01-04 07:31:45,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:45,443 INFO:     Epoch: 33
2023-01-04 07:31:46,992 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41803414225578306, 'Total loss': 0.41803414225578306} | train loss {'Reaction outcome loss': 0.37325958834718104, 'Total loss': 0.37325958834718104}
2023-01-04 07:31:46,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:46,992 INFO:     Epoch: 34
2023-01-04 07:31:48,552 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4081231574217478, 'Total loss': 0.4081231574217478} | train loss {'Reaction outcome loss': 0.3704353926591136, 'Total loss': 0.3704353926591136}
2023-01-04 07:31:48,552 INFO:     Found new best model at epoch 34
2023-01-04 07:31:48,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:48,553 INFO:     Epoch: 35
2023-01-04 07:31:50,103 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4042196353276571, 'Total loss': 0.4042196353276571} | train loss {'Reaction outcome loss': 0.35492556989597884, 'Total loss': 0.35492556989597884}
2023-01-04 07:31:50,103 INFO:     Found new best model at epoch 35
2023-01-04 07:31:50,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:50,104 INFO:     Epoch: 36
2023-01-04 07:31:51,637 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4142978012561798, 'Total loss': 0.4142978012561798} | train loss {'Reaction outcome loss': 0.3559303236720355, 'Total loss': 0.3559303236720355}
2023-01-04 07:31:51,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:51,637 INFO:     Epoch: 37
2023-01-04 07:31:53,157 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4212638477484385, 'Total loss': 0.4212638477484385} | train loss {'Reaction outcome loss': 0.3676272759456997, 'Total loss': 0.3676272759456997}
2023-01-04 07:31:53,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:53,157 INFO:     Epoch: 38
2023-01-04 07:31:54,718 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39845244884490966, 'Total loss': 0.39845244884490966} | train loss {'Reaction outcome loss': 0.3473981239333533, 'Total loss': 0.3473981239333533}
2023-01-04 07:31:54,719 INFO:     Found new best model at epoch 38
2023-01-04 07:31:54,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:54,719 INFO:     Epoch: 39
2023-01-04 07:31:56,281 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4581311047077179, 'Total loss': 0.4581311047077179} | train loss {'Reaction outcome loss': 0.3485065682426743, 'Total loss': 0.3485065682426743}
2023-01-04 07:31:56,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:56,281 INFO:     Epoch: 40
2023-01-04 07:31:57,837 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3946608205636342, 'Total loss': 0.3946608205636342} | train loss {'Reaction outcome loss': 0.3511889367197738, 'Total loss': 0.3511889367197738}
2023-01-04 07:31:57,839 INFO:     Found new best model at epoch 40
2023-01-04 07:31:57,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:57,839 INFO:     Epoch: 41
2023-01-04 07:31:59,391 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4426175107558568, 'Total loss': 0.4426175107558568} | train loss {'Reaction outcome loss': 0.33890634900392574, 'Total loss': 0.33890634900392574}
2023-01-04 07:31:59,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:31:59,391 INFO:     Epoch: 42
2023-01-04 07:32:00,925 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4306430876255035, 'Total loss': 0.4306430876255035} | train loss {'Reaction outcome loss': 0.33896882300251635, 'Total loss': 0.33896882300251635}
2023-01-04 07:32:00,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:00,925 INFO:     Epoch: 43
2023-01-04 07:32:02,433 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40287624994913734, 'Total loss': 0.40287624994913734} | train loss {'Reaction outcome loss': 0.3355256783452469, 'Total loss': 0.3355256783452469}
2023-01-04 07:32:02,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:02,434 INFO:     Epoch: 44
2023-01-04 07:32:03,999 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4316764314969381, 'Total loss': 0.4316764314969381} | train loss {'Reaction outcome loss': 0.32882850075605125, 'Total loss': 0.32882850075605125}
2023-01-04 07:32:04,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:04,000 INFO:     Epoch: 45
2023-01-04 07:32:05,567 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3823678731918335, 'Total loss': 0.3823678731918335} | train loss {'Reaction outcome loss': 0.3356269603136225, 'Total loss': 0.3356269603136225}
2023-01-04 07:32:05,567 INFO:     Found new best model at epoch 45
2023-01-04 07:32:05,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:05,568 INFO:     Epoch: 46
2023-01-04 07:32:07,133 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43227095703283946, 'Total loss': 0.43227095703283946} | train loss {'Reaction outcome loss': 0.3474244619517223, 'Total loss': 0.3474244619517223}
2023-01-04 07:32:07,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:07,133 INFO:     Epoch: 47
2023-01-04 07:32:08,693 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40452080915371574, 'Total loss': 0.40452080915371574} | train loss {'Reaction outcome loss': 0.3557368856989711, 'Total loss': 0.3557368856989711}
2023-01-04 07:32:08,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:08,693 INFO:     Epoch: 48
2023-01-04 07:32:10,231 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4220877041419347, 'Total loss': 0.4220877041419347} | train loss {'Reaction outcome loss': 0.33499095170502213, 'Total loss': 0.33499095170502213}
2023-01-04 07:32:10,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:10,231 INFO:     Epoch: 49
2023-01-04 07:32:11,774 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43357853293418885, 'Total loss': 0.43357853293418885} | train loss {'Reaction outcome loss': 0.35092311687227606, 'Total loss': 0.35092311687227606}
2023-01-04 07:32:11,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:11,774 INFO:     Epoch: 50
2023-01-04 07:32:13,347 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4203744779030482, 'Total loss': 0.4203744779030482} | train loss {'Reaction outcome loss': 0.3335929219543502, 'Total loss': 0.3335929219543502}
2023-01-04 07:32:13,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:13,347 INFO:     Epoch: 51
2023-01-04 07:32:14,912 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4224950442711512, 'Total loss': 0.4224950442711512} | train loss {'Reaction outcome loss': 0.3291035915684441, 'Total loss': 0.3291035915684441}
2023-01-04 07:32:14,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:14,912 INFO:     Epoch: 52
2023-01-04 07:32:16,488 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41380643645922344, 'Total loss': 0.41380643645922344} | train loss {'Reaction outcome loss': 0.326605629067922, 'Total loss': 0.326605629067922}
2023-01-04 07:32:16,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:16,489 INFO:     Epoch: 53
2023-01-04 07:32:18,065 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4046596517165502, 'Total loss': 0.4046596517165502} | train loss {'Reaction outcome loss': 0.31651745507606655, 'Total loss': 0.31651745507606655}
2023-01-04 07:32:18,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:18,065 INFO:     Epoch: 54
2023-01-04 07:32:19,580 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40829214950402576, 'Total loss': 0.40829214950402576} | train loss {'Reaction outcome loss': 0.31706910557451023, 'Total loss': 0.31706910557451023}
2023-01-04 07:32:19,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:19,580 INFO:     Epoch: 55
2023-01-04 07:32:21,122 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4387885262568792, 'Total loss': 0.4387885262568792} | train loss {'Reaction outcome loss': 0.3142331078128916, 'Total loss': 0.3142331078128916}
2023-01-04 07:32:21,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:21,122 INFO:     Epoch: 56
2023-01-04 07:32:22,708 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4056448976198832, 'Total loss': 0.4056448976198832} | train loss {'Reaction outcome loss': 0.31553401592848956, 'Total loss': 0.31553401592848956}
2023-01-04 07:32:22,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:22,708 INFO:     Epoch: 57
2023-01-04 07:32:24,289 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3943786323070526, 'Total loss': 0.3943786323070526} | train loss {'Reaction outcome loss': 0.33284270089306106, 'Total loss': 0.33284270089306106}
2023-01-04 07:32:24,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:24,290 INFO:     Epoch: 58
2023-01-04 07:32:25,868 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41265290677547456, 'Total loss': 0.41265290677547456} | train loss {'Reaction outcome loss': 0.3150885883664739, 'Total loss': 0.3150885883664739}
2023-01-04 07:32:25,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:25,868 INFO:     Epoch: 59
2023-01-04 07:32:27,444 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3776342858870824, 'Total loss': 0.3776342858870824} | train loss {'Reaction outcome loss': 0.32466550347010564, 'Total loss': 0.32466550347010564}
2023-01-04 07:32:27,444 INFO:     Found new best model at epoch 59
2023-01-04 07:32:27,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:27,445 INFO:     Epoch: 60
2023-01-04 07:32:28,949 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3940733333428701, 'Total loss': 0.3940733333428701} | train loss {'Reaction outcome loss': 0.3024698771687458, 'Total loss': 0.3024698771687458}
2023-01-04 07:32:28,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:28,950 INFO:     Epoch: 61
2023-01-04 07:32:30,518 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3781226694583893, 'Total loss': 0.3781226694583893} | train loss {'Reaction outcome loss': 0.3050629063897456, 'Total loss': 0.3050629063897456}
2023-01-04 07:32:30,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:30,518 INFO:     Epoch: 62
2023-01-04 07:32:32,093 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37471807599067686, 'Total loss': 0.37471807599067686} | train loss {'Reaction outcome loss': 0.3014682711766817, 'Total loss': 0.3014682711766817}
2023-01-04 07:32:32,093 INFO:     Found new best model at epoch 62
2023-01-04 07:32:32,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:32,094 INFO:     Epoch: 63
2023-01-04 07:32:33,661 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3746170168121656, 'Total loss': 0.3746170168121656} | train loss {'Reaction outcome loss': 0.30088731278205605, 'Total loss': 0.30088731278205605}
2023-01-04 07:32:33,661 INFO:     Found new best model at epoch 63
2023-01-04 07:32:33,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:33,662 INFO:     Epoch: 64
2023-01-04 07:32:35,256 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42530470391114555, 'Total loss': 0.42530470391114555} | train loss {'Reaction outcome loss': 0.29583051018720574, 'Total loss': 0.29583051018720574}
2023-01-04 07:32:35,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:35,257 INFO:     Epoch: 65
2023-01-04 07:32:36,839 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3998614077766736, 'Total loss': 0.3998614077766736} | train loss {'Reaction outcome loss': 0.2938349827936229, 'Total loss': 0.2938349827936229}
2023-01-04 07:32:36,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:36,840 INFO:     Epoch: 66
2023-01-04 07:32:38,381 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3744422247012456, 'Total loss': 0.3744422247012456} | train loss {'Reaction outcome loss': 0.29692698695251474, 'Total loss': 0.29692698695251474}
2023-01-04 07:32:38,381 INFO:     Found new best model at epoch 66
2023-01-04 07:32:38,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:38,382 INFO:     Epoch: 67
2023-01-04 07:32:40,004 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44418658713499704, 'Total loss': 0.44418658713499704} | train loss {'Reaction outcome loss': 0.29295912327970786, 'Total loss': 0.29295912327970786}
2023-01-04 07:32:40,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:40,004 INFO:     Epoch: 68
2023-01-04 07:32:41,630 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38079703350861865, 'Total loss': 0.38079703350861865} | train loss {'Reaction outcome loss': 0.2918685850020046, 'Total loss': 0.2918685850020046}
2023-01-04 07:32:41,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:41,630 INFO:     Epoch: 69
2023-01-04 07:32:43,261 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42690874338150026, 'Total loss': 0.42690874338150026} | train loss {'Reaction outcome loss': 0.2909784760603266, 'Total loss': 0.2909784760603266}
2023-01-04 07:32:43,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:43,261 INFO:     Epoch: 70
2023-01-04 07:32:44,886 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3944298913081487, 'Total loss': 0.3944298913081487} | train loss {'Reaction outcome loss': 0.28708455547609407, 'Total loss': 0.28708455547609407}
2023-01-04 07:32:44,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:44,886 INFO:     Epoch: 71
2023-01-04 07:32:46,468 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3902158389488856, 'Total loss': 0.3902158389488856} | train loss {'Reaction outcome loss': 0.2881141959865024, 'Total loss': 0.2881141959865024}
2023-01-04 07:32:46,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:46,468 INFO:     Epoch: 72
2023-01-04 07:32:48,037 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3732068528731664, 'Total loss': 0.3732068528731664} | train loss {'Reaction outcome loss': 0.285254196407049, 'Total loss': 0.285254196407049}
2023-01-04 07:32:48,038 INFO:     Found new best model at epoch 72
2023-01-04 07:32:48,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:48,038 INFO:     Epoch: 73
2023-01-04 07:32:49,657 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3770727088054021, 'Total loss': 0.3770727088054021} | train loss {'Reaction outcome loss': 0.28311064040737116, 'Total loss': 0.28311064040737116}
2023-01-04 07:32:49,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:49,657 INFO:     Epoch: 74
2023-01-04 07:32:51,230 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4320853551228841, 'Total loss': 0.4320853551228841} | train loss {'Reaction outcome loss': 0.2946972560569428, 'Total loss': 0.2946972560569428}
2023-01-04 07:32:51,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:51,231 INFO:     Epoch: 75
2023-01-04 07:32:52,791 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3907195180654526, 'Total loss': 0.3907195180654526} | train loss {'Reaction outcome loss': 0.34503100149036536, 'Total loss': 0.34503100149036536}
2023-01-04 07:32:52,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:52,791 INFO:     Epoch: 76
2023-01-04 07:32:54,346 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4310763011376063, 'Total loss': 0.4310763011376063} | train loss {'Reaction outcome loss': 0.2877596874250625, 'Total loss': 0.2877596874250625}
2023-01-04 07:32:54,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:54,346 INFO:     Epoch: 77
2023-01-04 07:32:55,872 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38436378637949625, 'Total loss': 0.38436378637949625} | train loss {'Reaction outcome loss': 0.27552164260118117, 'Total loss': 0.27552164260118117}
2023-01-04 07:32:55,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:55,872 INFO:     Epoch: 78
2023-01-04 07:32:57,389 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38485934734344485, 'Total loss': 0.38485934734344485} | train loss {'Reaction outcome loss': 0.27916405860172666, 'Total loss': 0.27916405860172666}
2023-01-04 07:32:57,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:57,390 INFO:     Epoch: 79
2023-01-04 07:32:58,953 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39672645926475525, 'Total loss': 0.39672645926475525} | train loss {'Reaction outcome loss': 0.2745450864199286, 'Total loss': 0.2745450864199286}
2023-01-04 07:32:58,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:32:58,953 INFO:     Epoch: 80
2023-01-04 07:33:00,523 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3803970019022624, 'Total loss': 0.3803970019022624} | train loss {'Reaction outcome loss': 0.2750658925546357, 'Total loss': 0.2750658925546357}
2023-01-04 07:33:00,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:00,524 INFO:     Epoch: 81
2023-01-04 07:33:02,072 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4432200054327647, 'Total loss': 0.4432200054327647} | train loss {'Reaction outcome loss': 0.2862545463485994, 'Total loss': 0.2862545463485994}
2023-01-04 07:33:02,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:02,072 INFO:     Epoch: 82
2023-01-04 07:33:03,627 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40077462991078694, 'Total loss': 0.40077462991078694} | train loss {'Reaction outcome loss': 0.2969102720203607, 'Total loss': 0.2969102720203607}
2023-01-04 07:33:03,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:03,627 INFO:     Epoch: 83
2023-01-04 07:33:05,135 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36841147343317665, 'Total loss': 0.36841147343317665} | train loss {'Reaction outcome loss': 0.2994061669240287, 'Total loss': 0.2994061669240287}
2023-01-04 07:33:05,135 INFO:     Found new best model at epoch 83
2023-01-04 07:33:05,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:05,136 INFO:     Epoch: 84
2023-01-04 07:33:06,711 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3980660696824392, 'Total loss': 0.3980660696824392} | train loss {'Reaction outcome loss': 0.27746450612102164, 'Total loss': 0.27746450612102164}
2023-01-04 07:33:06,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:06,712 INFO:     Epoch: 85
2023-01-04 07:33:08,264 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37802911599477135, 'Total loss': 0.37802911599477135} | train loss {'Reaction outcome loss': 0.27020895308764326, 'Total loss': 0.27020895308764326}
2023-01-04 07:33:08,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:08,265 INFO:     Epoch: 86
2023-01-04 07:33:09,822 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38351086477438606, 'Total loss': 0.38351086477438606} | train loss {'Reaction outcome loss': 0.26947348927944037, 'Total loss': 0.26947348927944037}
2023-01-04 07:33:09,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:09,822 INFO:     Epoch: 87
2023-01-04 07:33:11,378 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3633036231001218, 'Total loss': 0.3633036231001218} | train loss {'Reaction outcome loss': 0.2736285579337256, 'Total loss': 0.2736285579337256}
2023-01-04 07:33:11,379 INFO:     Found new best model at epoch 87
2023-01-04 07:33:11,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:11,379 INFO:     Epoch: 88
2023-01-04 07:33:12,933 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3950516323248545, 'Total loss': 0.3950516323248545} | train loss {'Reaction outcome loss': 0.264451712135401, 'Total loss': 0.264451712135401}
2023-01-04 07:33:12,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:12,934 INFO:     Epoch: 89
2023-01-04 07:33:14,421 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38910301427046456, 'Total loss': 0.38910301427046456} | train loss {'Reaction outcome loss': 0.2654338233658801, 'Total loss': 0.2654338233658801}
2023-01-04 07:33:14,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:14,422 INFO:     Epoch: 90
2023-01-04 07:33:16,006 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37181095282236737, 'Total loss': 0.37181095282236737} | train loss {'Reaction outcome loss': 0.27865871384172985, 'Total loss': 0.27865871384172985}
2023-01-04 07:33:16,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:16,006 INFO:     Epoch: 91
2023-01-04 07:33:17,579 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38064090013504026, 'Total loss': 0.38064090013504026} | train loss {'Reaction outcome loss': 0.259457566311882, 'Total loss': 0.259457566311882}
2023-01-04 07:33:17,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:17,579 INFO:     Epoch: 92
2023-01-04 07:33:19,144 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37580370008945463, 'Total loss': 0.37580370008945463} | train loss {'Reaction outcome loss': 0.26124953737456486, 'Total loss': 0.26124953737456486}
2023-01-04 07:33:19,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:19,145 INFO:     Epoch: 93
2023-01-04 07:33:20,729 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40841691692670185, 'Total loss': 0.40841691692670185} | train loss {'Reaction outcome loss': 0.27314597268359386, 'Total loss': 0.27314597268359386}
2023-01-04 07:33:20,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:20,729 INFO:     Epoch: 94
2023-01-04 07:33:22,336 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3739821970462799, 'Total loss': 0.3739821970462799} | train loss {'Reaction outcome loss': 0.3124339789328456, 'Total loss': 0.3124339789328456}
2023-01-04 07:33:22,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:22,337 INFO:     Epoch: 95
2023-01-04 07:33:23,856 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.379144952694575, 'Total loss': 0.379144952694575} | train loss {'Reaction outcome loss': 0.2576969106894862, 'Total loss': 0.2576969106894862}
2023-01-04 07:33:23,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:23,856 INFO:     Epoch: 96
2023-01-04 07:33:25,434 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3838293433189392, 'Total loss': 0.3838293433189392} | train loss {'Reaction outcome loss': 0.2569007826264103, 'Total loss': 0.2569007826264103}
2023-01-04 07:33:25,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:25,434 INFO:     Epoch: 97
2023-01-04 07:33:27,036 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.353595599035422, 'Total loss': 0.353595599035422} | train loss {'Reaction outcome loss': 0.2583276176858066, 'Total loss': 0.2583276176858066}
2023-01-04 07:33:27,036 INFO:     Found new best model at epoch 97
2023-01-04 07:33:27,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:27,037 INFO:     Epoch: 98
2023-01-04 07:33:28,613 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4043418337901433, 'Total loss': 0.4043418337901433} | train loss {'Reaction outcome loss': 0.25323925021658017, 'Total loss': 0.25323925021658017}
2023-01-04 07:33:28,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:28,613 INFO:     Epoch: 99
2023-01-04 07:33:30,194 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40697158376375836, 'Total loss': 0.40697158376375836} | train loss {'Reaction outcome loss': 0.25779339495668374, 'Total loss': 0.25779339495668374}
2023-01-04 07:33:30,195 INFO:     Best model found after epoch 98 of 100.
2023-01-04 07:33:30,195 INFO:   Done with stage: TRAINING
2023-01-04 07:33:30,195 INFO:   Starting stage: EVALUATION
2023-01-04 07:33:30,323 INFO:   Done with stage: EVALUATION
2023-01-04 07:33:30,324 INFO:   Leaving out SEQ value Fold_5
2023-01-04 07:33:30,336 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:33:30,336 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:33:30,985 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:33:30,985 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:33:31,054 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:33:31,055 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:33:31,055 INFO:     No hyperparam tuning for this model
2023-01-04 07:33:31,055 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:33:31,055 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:33:31,056 INFO:     None feature selector for col prot
2023-01-04 07:33:31,056 INFO:     None feature selector for col prot
2023-01-04 07:33:31,056 INFO:     None feature selector for col prot
2023-01-04 07:33:31,056 INFO:     None feature selector for col chem
2023-01-04 07:33:31,056 INFO:     None feature selector for col chem
2023-01-04 07:33:31,056 INFO:     None feature selector for col chem
2023-01-04 07:33:31,056 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:33:31,057 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:33:31,057 INFO:     Number of params in model 70111
2023-01-04 07:33:31,061 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:33:31,061 INFO:   Starting stage: TRAINING
2023-01-04 07:33:31,103 INFO:     Val loss before train {'Reaction outcome loss': 0.9595596512158712, 'Total loss': 0.9595596512158712}
2023-01-04 07:33:31,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:31,104 INFO:     Epoch: 0
2023-01-04 07:33:32,617 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7548565109570821, 'Total loss': 0.7548565109570821} | train loss {'Reaction outcome loss': 0.8468945236147746, 'Total loss': 0.8468945236147746}
2023-01-04 07:33:32,617 INFO:     Found new best model at epoch 0
2023-01-04 07:33:32,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:32,618 INFO:     Epoch: 1
2023-01-04 07:33:34,188 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6213564356168111, 'Total loss': 0.6213564356168111} | train loss {'Reaction outcome loss': 0.6936599434339914, 'Total loss': 0.6936599434339914}
2023-01-04 07:33:34,188 INFO:     Found new best model at epoch 1
2023-01-04 07:33:34,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:34,189 INFO:     Epoch: 2
2023-01-04 07:33:35,776 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.555505516131719, 'Total loss': 0.555505516131719} | train loss {'Reaction outcome loss': 0.6028296634338904, 'Total loss': 0.6028296634338904}
2023-01-04 07:33:35,777 INFO:     Found new best model at epoch 2
2023-01-04 07:33:35,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:35,778 INFO:     Epoch: 3
2023-01-04 07:33:37,373 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5575755993525188, 'Total loss': 0.5575755993525188} | train loss {'Reaction outcome loss': 0.5602051120089448, 'Total loss': 0.5602051120089448}
2023-01-04 07:33:37,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:37,373 INFO:     Epoch: 4
2023-01-04 07:33:38,966 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5210158407688141, 'Total loss': 0.5210158407688141} | train loss {'Reaction outcome loss': 0.5297879417413387, 'Total loss': 0.5297879417413387}
2023-01-04 07:33:38,966 INFO:     Found new best model at epoch 4
2023-01-04 07:33:38,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:38,967 INFO:     Epoch: 5
2023-01-04 07:33:40,554 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5100962420304617, 'Total loss': 0.5100962420304617} | train loss {'Reaction outcome loss': 0.511608598386005, 'Total loss': 0.511608598386005}
2023-01-04 07:33:40,554 INFO:     Found new best model at epoch 5
2023-01-04 07:33:40,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:40,555 INFO:     Epoch: 6
2023-01-04 07:33:42,095 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5282128433386485, 'Total loss': 0.5282128433386485} | train loss {'Reaction outcome loss': 0.49929399176946154, 'Total loss': 0.49929399176946154}
2023-01-04 07:33:42,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:42,096 INFO:     Epoch: 7
2023-01-04 07:33:43,689 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5058789610862732, 'Total loss': 0.5058789610862732} | train loss {'Reaction outcome loss': 0.49351692745003145, 'Total loss': 0.49351692745003145}
2023-01-04 07:33:43,689 INFO:     Found new best model at epoch 7
2023-01-04 07:33:43,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:43,690 INFO:     Epoch: 8
2023-01-04 07:33:45,289 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5117784082889557, 'Total loss': 0.5117784082889557} | train loss {'Reaction outcome loss': 0.482387345439444, 'Total loss': 0.482387345439444}
2023-01-04 07:33:45,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:45,289 INFO:     Epoch: 9
2023-01-04 07:33:46,883 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5158922334512075, 'Total loss': 0.5158922334512075} | train loss {'Reaction outcome loss': 0.4797119447502537, 'Total loss': 0.4797119447502537}
2023-01-04 07:33:46,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:46,883 INFO:     Epoch: 10
2023-01-04 07:33:48,468 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49008007645606994, 'Total loss': 0.49008007645606994} | train loss {'Reaction outcome loss': 0.46987294727106294, 'Total loss': 0.46987294727106294}
2023-01-04 07:33:48,468 INFO:     Found new best model at epoch 10
2023-01-04 07:33:48,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:48,468 INFO:     Epoch: 11
2023-01-04 07:33:50,001 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49120221734046937, 'Total loss': 0.49120221734046937} | train loss {'Reaction outcome loss': 0.4704571016285943, 'Total loss': 0.4704571016285943}
2023-01-04 07:33:50,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:50,001 INFO:     Epoch: 12
2023-01-04 07:33:51,542 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4807430624961853, 'Total loss': 0.4807430624961853} | train loss {'Reaction outcome loss': 0.4611710818632897, 'Total loss': 0.4611710818632897}
2023-01-04 07:33:51,542 INFO:     Found new best model at epoch 12
2023-01-04 07:33:51,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:51,543 INFO:     Epoch: 13
2023-01-04 07:33:53,105 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4679990977048874, 'Total loss': 0.4679990977048874} | train loss {'Reaction outcome loss': 0.4574363762750063, 'Total loss': 0.4574363762750063}
2023-01-04 07:33:53,105 INFO:     Found new best model at epoch 13
2023-01-04 07:33:53,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:53,106 INFO:     Epoch: 14
2023-01-04 07:33:54,645 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4784767985343933, 'Total loss': 0.4784767985343933} | train loss {'Reaction outcome loss': 0.4495229923868201, 'Total loss': 0.4495229923868201}
2023-01-04 07:33:54,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:54,646 INFO:     Epoch: 15
2023-01-04 07:33:56,185 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4841227144002914, 'Total loss': 0.4841227144002914} | train loss {'Reaction outcome loss': 0.46218247409316077, 'Total loss': 0.46218247409316077}
2023-01-04 07:33:56,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:56,185 INFO:     Epoch: 16
2023-01-04 07:33:57,730 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4691064655780792, 'Total loss': 0.4691064655780792} | train loss {'Reaction outcome loss': 0.4708706258215766, 'Total loss': 0.4708706258215766}
2023-01-04 07:33:57,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:57,731 INFO:     Epoch: 17
2023-01-04 07:33:59,238 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4613047997156779, 'Total loss': 0.4613047997156779} | train loss {'Reaction outcome loss': 0.4563660656736381, 'Total loss': 0.4563660656736381}
2023-01-04 07:33:59,238 INFO:     Found new best model at epoch 17
2023-01-04 07:33:59,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:33:59,239 INFO:     Epoch: 18
2023-01-04 07:34:00,765 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.496357262134552, 'Total loss': 0.496357262134552} | train loss {'Reaction outcome loss': 0.4390729495283702, 'Total loss': 0.4390729495283702}
2023-01-04 07:34:00,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:00,765 INFO:     Epoch: 19
2023-01-04 07:34:02,402 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49358972112337746, 'Total loss': 0.49358972112337746} | train loss {'Reaction outcome loss': 0.4334393551754951, 'Total loss': 0.4334393551754951}
2023-01-04 07:34:02,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:02,403 INFO:     Epoch: 20
2023-01-04 07:34:03,988 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46996161341667175, 'Total loss': 0.46996161341667175} | train loss {'Reaction outcome loss': 0.42871914296478464, 'Total loss': 0.42871914296478464}
2023-01-04 07:34:03,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:03,989 INFO:     Epoch: 21
2023-01-04 07:34:05,546 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4863771835962931, 'Total loss': 0.4863771835962931} | train loss {'Reaction outcome loss': 0.42490934038372585, 'Total loss': 0.42490934038372585}
2023-01-04 07:34:05,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:05,547 INFO:     Epoch: 22
2023-01-04 07:34:07,091 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4941732664903005, 'Total loss': 0.4941732664903005} | train loss {'Reaction outcome loss': 0.43452348149773, 'Total loss': 0.43452348149773}
2023-01-04 07:34:07,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:07,092 INFO:     Epoch: 23
2023-01-04 07:34:08,582 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48195587793986, 'Total loss': 0.48195587793986} | train loss {'Reaction outcome loss': 0.45289085642265936, 'Total loss': 0.45289085642265936}
2023-01-04 07:34:08,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:08,582 INFO:     Epoch: 24
2023-01-04 07:34:10,139 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4640756666660309, 'Total loss': 0.4640756666660309} | train loss {'Reaction outcome loss': 0.42346487137188704, 'Total loss': 0.42346487137188704}
2023-01-04 07:34:10,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:10,139 INFO:     Epoch: 25
2023-01-04 07:34:11,704 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4837793926397959, 'Total loss': 0.4837793926397959} | train loss {'Reaction outcome loss': 0.41504505692400795, 'Total loss': 0.41504505692400795}
2023-01-04 07:34:11,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:11,704 INFO:     Epoch: 26
2023-01-04 07:34:13,268 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45855635503927866, 'Total loss': 0.45855635503927866} | train loss {'Reaction outcome loss': 0.4113500453599229, 'Total loss': 0.4113500453599229}
2023-01-04 07:34:13,269 INFO:     Found new best model at epoch 26
2023-01-04 07:34:13,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:13,270 INFO:     Epoch: 27
2023-01-04 07:34:14,824 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44418497532606127, 'Total loss': 0.44418497532606127} | train loss {'Reaction outcome loss': 0.4111536438374416, 'Total loss': 0.4111536438374416}
2023-01-04 07:34:14,824 INFO:     Found new best model at epoch 27
2023-01-04 07:34:14,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:14,825 INFO:     Epoch: 28
2023-01-04 07:34:16,382 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4570431818564733, 'Total loss': 0.4570431818564733} | train loss {'Reaction outcome loss': 0.409916219502296, 'Total loss': 0.409916219502296}
2023-01-04 07:34:16,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:16,382 INFO:     Epoch: 29
2023-01-04 07:34:17,877 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4480417976776759, 'Total loss': 0.4480417976776759} | train loss {'Reaction outcome loss': 0.3989199043750979, 'Total loss': 0.3989199043750979}
2023-01-04 07:34:17,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:17,878 INFO:     Epoch: 30
2023-01-04 07:34:19,450 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4516989976167679, 'Total loss': 0.4516989976167679} | train loss {'Reaction outcome loss': 0.3936184194154929, 'Total loss': 0.3936184194154929}
2023-01-04 07:34:19,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:19,450 INFO:     Epoch: 31
2023-01-04 07:34:21,028 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47016178965568545, 'Total loss': 0.47016178965568545} | train loss {'Reaction outcome loss': 0.3891463864025697, 'Total loss': 0.3891463864025697}
2023-01-04 07:34:21,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:21,028 INFO:     Epoch: 32
2023-01-04 07:34:22,578 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45649763345718386, 'Total loss': 0.45649763345718386} | train loss {'Reaction outcome loss': 0.3856240680569486, 'Total loss': 0.3856240680569486}
2023-01-04 07:34:22,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:22,578 INFO:     Epoch: 33
2023-01-04 07:34:24,120 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45832143624623617, 'Total loss': 0.45832143624623617} | train loss {'Reaction outcome loss': 0.3851757297795131, 'Total loss': 0.3851757297795131}
2023-01-04 07:34:24,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:24,120 INFO:     Epoch: 34
2023-01-04 07:34:25,666 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46099145809809366, 'Total loss': 0.46099145809809366} | train loss {'Reaction outcome loss': 0.392711969146478, 'Total loss': 0.392711969146478}
2023-01-04 07:34:25,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:25,667 INFO:     Epoch: 35
2023-01-04 07:34:27,145 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4523261974255244, 'Total loss': 0.4523261974255244} | train loss {'Reaction outcome loss': 0.42343889682355884, 'Total loss': 0.42343889682355884}
2023-01-04 07:34:27,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:27,145 INFO:     Epoch: 36
2023-01-04 07:34:28,689 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44464497566223143, 'Total loss': 0.44464497566223143} | train loss {'Reaction outcome loss': 0.3824545180330566, 'Total loss': 0.3824545180330566}
2023-01-04 07:34:28,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:28,690 INFO:     Epoch: 37
2023-01-04 07:34:30,225 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4280490030845006, 'Total loss': 0.4280490030845006} | train loss {'Reaction outcome loss': 0.3721816221764986, 'Total loss': 0.3721816221764986}
2023-01-04 07:34:30,225 INFO:     Found new best model at epoch 37
2023-01-04 07:34:30,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:30,226 INFO:     Epoch: 38
2023-01-04 07:34:31,773 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4552185247341792, 'Total loss': 0.4552185247341792} | train loss {'Reaction outcome loss': 0.39012955955189205, 'Total loss': 0.39012955955189205}
2023-01-04 07:34:31,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:31,773 INFO:     Epoch: 39
2023-01-04 07:34:33,310 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45672590136528013, 'Total loss': 0.45672590136528013} | train loss {'Reaction outcome loss': 0.39196928622929944, 'Total loss': 0.39196928622929944}
2023-01-04 07:34:33,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:33,310 INFO:     Epoch: 40
2023-01-04 07:34:34,848 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4264224807421366, 'Total loss': 0.4264224807421366} | train loss {'Reaction outcome loss': 0.3781467580061028, 'Total loss': 0.3781467580061028}
2023-01-04 07:34:34,848 INFO:     Found new best model at epoch 40
2023-01-04 07:34:34,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:34,848 INFO:     Epoch: 41
2023-01-04 07:34:36,333 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4271920065085093, 'Total loss': 0.4271920065085093} | train loss {'Reaction outcome loss': 0.363577285458408, 'Total loss': 0.363577285458408}
2023-01-04 07:34:36,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:36,333 INFO:     Epoch: 42
2023-01-04 07:34:37,873 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45929456551869713, 'Total loss': 0.45929456551869713} | train loss {'Reaction outcome loss': 0.35830657636119134, 'Total loss': 0.35830657636119134}
2023-01-04 07:34:37,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:37,874 INFO:     Epoch: 43
2023-01-04 07:34:39,413 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42014759381612143, 'Total loss': 0.42014759381612143} | train loss {'Reaction outcome loss': 0.35312625277530996, 'Total loss': 0.35312625277530996}
2023-01-04 07:34:39,413 INFO:     Found new best model at epoch 43
2023-01-04 07:34:39,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:39,414 INFO:     Epoch: 44
2023-01-04 07:34:40,971 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4084620426098506, 'Total loss': 0.4084620426098506} | train loss {'Reaction outcome loss': 0.350820895054958, 'Total loss': 0.350820895054958}
2023-01-04 07:34:40,971 INFO:     Found new best model at epoch 44
2023-01-04 07:34:40,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:40,971 INFO:     Epoch: 45
2023-01-04 07:34:42,510 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43763608833154044, 'Total loss': 0.43763608833154044} | train loss {'Reaction outcome loss': 0.3511631907760233, 'Total loss': 0.3511631907760233}
2023-01-04 07:34:42,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:42,511 INFO:     Epoch: 46
2023-01-04 07:34:44,061 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4228534827629725, 'Total loss': 0.4228534827629725} | train loss {'Reaction outcome loss': 0.3495679936317754, 'Total loss': 0.3495679936317754}
2023-01-04 07:34:44,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:44,061 INFO:     Epoch: 47
2023-01-04 07:34:45,573 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4246243218580882, 'Total loss': 0.4246243218580882} | train loss {'Reaction outcome loss': 0.3466508056942299, 'Total loss': 0.3466508056942299}
2023-01-04 07:34:45,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:45,573 INFO:     Epoch: 48
2023-01-04 07:34:47,133 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.398123055199782, 'Total loss': 0.398123055199782} | train loss {'Reaction outcome loss': 0.3464944950655859, 'Total loss': 0.3464944950655859}
2023-01-04 07:34:47,133 INFO:     Found new best model at epoch 48
2023-01-04 07:34:47,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:47,134 INFO:     Epoch: 49
2023-01-04 07:34:48,683 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4210620363553365, 'Total loss': 0.4210620363553365} | train loss {'Reaction outcome loss': 0.3437405757190984, 'Total loss': 0.3437405757190984}
2023-01-04 07:34:48,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:48,684 INFO:     Epoch: 50
2023-01-04 07:34:50,221 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43549395898977916, 'Total loss': 0.43549395898977916} | train loss {'Reaction outcome loss': 0.3473093623052473, 'Total loss': 0.3473093623052473}
2023-01-04 07:34:50,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:50,221 INFO:     Epoch: 51
2023-01-04 07:34:51,762 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43255749543507893, 'Total loss': 0.43255749543507893} | train loss {'Reaction outcome loss': 0.3678241026236851, 'Total loss': 0.3678241026236851}
2023-01-04 07:34:51,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:51,762 INFO:     Epoch: 52
2023-01-04 07:34:53,280 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4378264943758647, 'Total loss': 0.4378264943758647} | train loss {'Reaction outcome loss': 0.33741950325125086, 'Total loss': 0.33741950325125086}
2023-01-04 07:34:53,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:53,280 INFO:     Epoch: 53
2023-01-04 07:34:54,793 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4297660648822784, 'Total loss': 0.4297660648822784} | train loss {'Reaction outcome loss': 0.33125337289116497, 'Total loss': 0.33125337289116497}
2023-01-04 07:34:54,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:54,794 INFO:     Epoch: 54
2023-01-04 07:34:56,348 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4289824197689692, 'Total loss': 0.4289824197689692} | train loss {'Reaction outcome loss': 0.3340330994485513, 'Total loss': 0.3340330994485513}
2023-01-04 07:34:56,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:56,348 INFO:     Epoch: 55
2023-01-04 07:34:57,903 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.434563277165095, 'Total loss': 0.434563277165095} | train loss {'Reaction outcome loss': 0.3425377812017214, 'Total loss': 0.3425377812017214}
2023-01-04 07:34:57,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:57,903 INFO:     Epoch: 56
2023-01-04 07:34:59,447 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4588461051384608, 'Total loss': 0.4588461051384608} | train loss {'Reaction outcome loss': 0.3369354607834332, 'Total loss': 0.3369354607834332}
2023-01-04 07:34:59,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:34:59,447 INFO:     Epoch: 57
2023-01-04 07:35:00,981 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41288515329360964, 'Total loss': 0.41288515329360964} | train loss {'Reaction outcome loss': 0.3495056091443352, 'Total loss': 0.3495056091443352}
2023-01-04 07:35:00,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:00,982 INFO:     Epoch: 58
2023-01-04 07:35:02,500 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43053900947173435, 'Total loss': 0.43053900947173435} | train loss {'Reaction outcome loss': 0.32592904114204907, 'Total loss': 0.32592904114204907}
2023-01-04 07:35:02,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:02,500 INFO:     Epoch: 59
2023-01-04 07:35:04,008 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4212599833806356, 'Total loss': 0.4212599833806356} | train loss {'Reaction outcome loss': 0.33196460007541423, 'Total loss': 0.33196460007541423}
2023-01-04 07:35:04,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:04,008 INFO:     Epoch: 60
2023-01-04 07:35:05,552 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4394312451283137, 'Total loss': 0.4394312451283137} | train loss {'Reaction outcome loss': 0.31868847697784286, 'Total loss': 0.31868847697784286}
2023-01-04 07:35:05,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:05,553 INFO:     Epoch: 61
2023-01-04 07:35:07,117 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42429283559322356, 'Total loss': 0.42429283559322356} | train loss {'Reaction outcome loss': 0.32206431697367394, 'Total loss': 0.32206431697367394}
2023-01-04 07:35:07,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:07,117 INFO:     Epoch: 62
2023-01-04 07:35:08,690 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42942504783471425, 'Total loss': 0.42942504783471425} | train loss {'Reaction outcome loss': 0.3117718597590599, 'Total loss': 0.3117718597590599}
2023-01-04 07:35:08,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:08,690 INFO:     Epoch: 63
2023-01-04 07:35:10,258 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4029105325539907, 'Total loss': 0.4029105325539907} | train loss {'Reaction outcome loss': 0.31643865057739656, 'Total loss': 0.31643865057739656}
2023-01-04 07:35:10,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:10,258 INFO:     Epoch: 64
2023-01-04 07:35:11,795 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4176657269398371, 'Total loss': 0.4176657269398371} | train loss {'Reaction outcome loss': 0.3301693102803783, 'Total loss': 0.3301693102803783}
2023-01-04 07:35:11,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:11,795 INFO:     Epoch: 65
2023-01-04 07:35:13,321 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4214634795983632, 'Total loss': 0.4214634795983632} | train loss {'Reaction outcome loss': 0.3266619037302376, 'Total loss': 0.3266619037302376}
2023-01-04 07:35:13,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:13,323 INFO:     Epoch: 66
2023-01-04 07:35:14,876 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4191841781139374, 'Total loss': 0.4191841781139374} | train loss {'Reaction outcome loss': 0.31067000018431473, 'Total loss': 0.31067000018431473}
2023-01-04 07:35:14,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:14,876 INFO:     Epoch: 67
2023-01-04 07:35:16,417 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39885356823603313, 'Total loss': 0.39885356823603313} | train loss {'Reaction outcome loss': 0.3094044930531063, 'Total loss': 0.3094044930531063}
2023-01-04 07:35:16,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:16,418 INFO:     Epoch: 68
2023-01-04 07:35:17,965 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42721822261810305, 'Total loss': 0.42721822261810305} | train loss {'Reaction outcome loss': 0.31881548178152763, 'Total loss': 0.31881548178152763}
2023-01-04 07:35:17,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:17,965 INFO:     Epoch: 69
2023-01-04 07:35:19,520 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.425621896982193, 'Total loss': 0.425621896982193} | train loss {'Reaction outcome loss': 0.34210592604991374, 'Total loss': 0.34210592604991374}
2023-01-04 07:35:19,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:19,521 INFO:     Epoch: 70
2023-01-04 07:35:21,027 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4076158086458842, 'Total loss': 0.4076158086458842} | train loss {'Reaction outcome loss': 0.30560291967307474, 'Total loss': 0.30560291967307474}
2023-01-04 07:35:21,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:21,028 INFO:     Epoch: 71
2023-01-04 07:35:22,570 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42217784325281776, 'Total loss': 0.42217784325281776} | train loss {'Reaction outcome loss': 0.30363755520817864, 'Total loss': 0.30363755520817864}
2023-01-04 07:35:22,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:22,571 INFO:     Epoch: 72
2023-01-04 07:35:24,141 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44207919438680016, 'Total loss': 0.44207919438680016} | train loss {'Reaction outcome loss': 0.306519677295633, 'Total loss': 0.306519677295633}
2023-01-04 07:35:24,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:24,141 INFO:     Epoch: 73
2023-01-04 07:35:25,695 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39741820593674976, 'Total loss': 0.39741820593674976} | train loss {'Reaction outcome loss': 0.3189236281939067, 'Total loss': 0.3189236281939067}
2023-01-04 07:35:25,695 INFO:     Found new best model at epoch 73
2023-01-04 07:35:25,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:25,696 INFO:     Epoch: 74
2023-01-04 07:35:27,242 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4151851534843445, 'Total loss': 0.4151851534843445} | train loss {'Reaction outcome loss': 0.30064538466602087, 'Total loss': 0.30064538466602087}
2023-01-04 07:35:27,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:27,242 INFO:     Epoch: 75
2023-01-04 07:35:28,793 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3978593572974205, 'Total loss': 0.3978593572974205} | train loss {'Reaction outcome loss': 0.3001109319901105, 'Total loss': 0.3001109319901105}
2023-01-04 07:35:28,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:28,793 INFO:     Epoch: 76
2023-01-04 07:35:30,284 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4294142564137777, 'Total loss': 0.4294142564137777} | train loss {'Reaction outcome loss': 0.2975251715144385, 'Total loss': 0.2975251715144385}
2023-01-04 07:35:30,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:30,284 INFO:     Epoch: 77
2023-01-04 07:35:31,838 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41463490227858224, 'Total loss': 0.41463490227858224} | train loss {'Reaction outcome loss': 0.3098832235226165, 'Total loss': 0.3098832235226165}
2023-01-04 07:35:31,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:31,839 INFO:     Epoch: 78
2023-01-04 07:35:33,391 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.427928360303243, 'Total loss': 0.427928360303243} | train loss {'Reaction outcome loss': 0.34161647428265784, 'Total loss': 0.34161647428265784}
2023-01-04 07:35:33,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:33,391 INFO:     Epoch: 79
2023-01-04 07:35:34,958 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4163660998145739, 'Total loss': 0.4163660998145739} | train loss {'Reaction outcome loss': 0.3033809795894701, 'Total loss': 0.3033809795894701}
2023-01-04 07:35:34,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:34,958 INFO:     Epoch: 80
2023-01-04 07:35:36,511 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4280218958854675, 'Total loss': 0.4280218958854675} | train loss {'Reaction outcome loss': 0.2970506638407444, 'Total loss': 0.2970506638407444}
2023-01-04 07:35:36,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:36,512 INFO:     Epoch: 81
2023-01-04 07:35:38,085 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40001325408617655, 'Total loss': 0.40001325408617655} | train loss {'Reaction outcome loss': 0.29503027585999825, 'Total loss': 0.29503027585999825}
2023-01-04 07:35:38,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:38,085 INFO:     Epoch: 82
2023-01-04 07:35:39,585 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42358285387357075, 'Total loss': 0.42358285387357075} | train loss {'Reaction outcome loss': 0.29989046878788783, 'Total loss': 0.29989046878788783}
2023-01-04 07:35:39,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:39,586 INFO:     Epoch: 83
2023-01-04 07:35:41,138 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4014739692211151, 'Total loss': 0.4014739692211151} | train loss {'Reaction outcome loss': 0.3348672344303771, 'Total loss': 0.3348672344303771}
2023-01-04 07:35:41,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:41,138 INFO:     Epoch: 84
2023-01-04 07:35:42,719 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41370747486750287, 'Total loss': 0.41370747486750287} | train loss {'Reaction outcome loss': 0.2962039474826441, 'Total loss': 0.2962039474826441}
2023-01-04 07:35:42,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:42,719 INFO:     Epoch: 85
2023-01-04 07:35:44,280 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41109934747219085, 'Total loss': 0.41109934747219085} | train loss {'Reaction outcome loss': 0.28943643209767406, 'Total loss': 0.28943643209767406}
2023-01-04 07:35:44,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:44,281 INFO:     Epoch: 86
2023-01-04 07:35:45,876 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40031385819117227, 'Total loss': 0.40031385819117227} | train loss {'Reaction outcome loss': 0.28390865858375985, 'Total loss': 0.28390865858375985}
2023-01-04 07:35:45,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:45,876 INFO:     Epoch: 87
2023-01-04 07:35:47,426 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38962152004241946, 'Total loss': 0.38962152004241946} | train loss {'Reaction outcome loss': 0.2845079562748256, 'Total loss': 0.2845079562748256}
2023-01-04 07:35:47,426 INFO:     Found new best model at epoch 87
2023-01-04 07:35:47,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:47,427 INFO:     Epoch: 88
2023-01-04 07:35:48,729 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41588508486747744, 'Total loss': 0.41588508486747744} | train loss {'Reaction outcome loss': 0.3039409094869726, 'Total loss': 0.3039409094869726}
2023-01-04 07:35:48,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:48,729 INFO:     Epoch: 89
2023-01-04 07:35:49,758 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4389395852883657, 'Total loss': 0.4389395852883657} | train loss {'Reaction outcome loss': 0.29150956944710965, 'Total loss': 0.29150956944710965}
2023-01-04 07:35:49,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:49,758 INFO:     Epoch: 90
2023-01-04 07:35:50,779 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4435334920883179, 'Total loss': 0.4435334920883179} | train loss {'Reaction outcome loss': 0.28440659395351575, 'Total loss': 0.28440659395351575}
2023-01-04 07:35:50,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:50,780 INFO:     Epoch: 91
2023-01-04 07:35:51,806 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4035327181220055, 'Total loss': 0.4035327181220055} | train loss {'Reaction outcome loss': 0.29486478662685206, 'Total loss': 0.29486478662685206}
2023-01-04 07:35:51,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:51,806 INFO:     Epoch: 92
2023-01-04 07:35:52,832 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38529266516367594, 'Total loss': 0.38529266516367594} | train loss {'Reaction outcome loss': 0.3098964687382829, 'Total loss': 0.3098964687382829}
2023-01-04 07:35:52,832 INFO:     Found new best model at epoch 92
2023-01-04 07:35:52,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:52,832 INFO:     Epoch: 93
2023-01-04 07:35:54,339 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45506784816582996, 'Total loss': 0.45506784816582996} | train loss {'Reaction outcome loss': 0.28014929136396316, 'Total loss': 0.28014929136396316}
2023-01-04 07:35:54,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:54,339 INFO:     Epoch: 94
2023-01-04 07:35:55,907 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48688338150580723, 'Total loss': 0.48688338150580723} | train loss {'Reaction outcome loss': 0.2999347954502572, 'Total loss': 0.2999347954502572}
2023-01-04 07:35:55,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:55,907 INFO:     Epoch: 95
2023-01-04 07:35:57,463 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43155940373738605, 'Total loss': 0.43155940373738605} | train loss {'Reaction outcome loss': 0.3322094732993455, 'Total loss': 0.3322094732993455}
2023-01-04 07:35:57,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:57,463 INFO:     Epoch: 96
2023-01-04 07:35:59,042 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4235759476820628, 'Total loss': 0.4235759476820628} | train loss {'Reaction outcome loss': 0.28326671262798103, 'Total loss': 0.28326671262798103}
2023-01-04 07:35:59,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:35:59,043 INFO:     Epoch: 97
2023-01-04 07:36:00,620 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4049552212158839, 'Total loss': 0.4049552212158839} | train loss {'Reaction outcome loss': 0.29657838784399815, 'Total loss': 0.29657838784399815}
2023-01-04 07:36:00,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:00,620 INFO:     Epoch: 98
2023-01-04 07:36:02,144 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40964134633541105, 'Total loss': 0.40964134633541105} | train loss {'Reaction outcome loss': 0.2787044248602731, 'Total loss': 0.2787044248602731}
2023-01-04 07:36:02,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:02,144 INFO:     Epoch: 99
2023-01-04 07:36:03,699 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43462528934081396, 'Total loss': 0.43462528934081396} | train loss {'Reaction outcome loss': 0.27746631570693536, 'Total loss': 0.27746631570693536}
2023-01-04 07:36:03,700 INFO:     Best model found after epoch 93 of 100.
2023-01-04 07:36:03,700 INFO:   Done with stage: TRAINING
2023-01-04 07:36:03,700 INFO:   Starting stage: EVALUATION
2023-01-04 07:36:03,829 INFO:   Done with stage: EVALUATION
2023-01-04 07:36:03,829 INFO:   Leaving out SEQ value Fold_6
2023-01-04 07:36:03,841 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:36:03,842 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:36:04,493 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:36:04,493 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:36:04,563 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:36:04,563 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:36:04,563 INFO:     No hyperparam tuning for this model
2023-01-04 07:36:04,563 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:36:04,563 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:36:04,564 INFO:     None feature selector for col prot
2023-01-04 07:36:04,564 INFO:     None feature selector for col prot
2023-01-04 07:36:04,564 INFO:     None feature selector for col prot
2023-01-04 07:36:04,564 INFO:     None feature selector for col chem
2023-01-04 07:36:04,565 INFO:     None feature selector for col chem
2023-01-04 07:36:04,565 INFO:     None feature selector for col chem
2023-01-04 07:36:04,565 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:36:04,565 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:36:04,566 INFO:     Number of params in model 70111
2023-01-04 07:36:04,569 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:36:04,569 INFO:   Starting stage: TRAINING
2023-01-04 07:36:04,611 INFO:     Val loss before train {'Reaction outcome loss': 1.0036873380343119, 'Total loss': 1.0036873380343119}
2023-01-04 07:36:04,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:04,611 INFO:     Epoch: 0
2023-01-04 07:36:06,185 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7653879702091217, 'Total loss': 0.7653879702091217} | train loss {'Reaction outcome loss': 0.837394845712444, 'Total loss': 0.837394845712444}
2023-01-04 07:36:06,185 INFO:     Found new best model at epoch 0
2023-01-04 07:36:06,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:06,186 INFO:     Epoch: 1
2023-01-04 07:36:07,736 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6369138459364573, 'Total loss': 0.6369138459364573} | train loss {'Reaction outcome loss': 0.6875569509423297, 'Total loss': 0.6875569509423297}
2023-01-04 07:36:07,736 INFO:     Found new best model at epoch 1
2023-01-04 07:36:07,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:07,737 INFO:     Epoch: 2
2023-01-04 07:36:09,326 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5649838626384736, 'Total loss': 0.5649838626384736} | train loss {'Reaction outcome loss': 0.5991535018859566, 'Total loss': 0.5991535018859566}
2023-01-04 07:36:09,327 INFO:     Found new best model at epoch 2
2023-01-04 07:36:09,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:09,327 INFO:     Epoch: 3
2023-01-04 07:36:10,850 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5281954348087311, 'Total loss': 0.5281954348087311} | train loss {'Reaction outcome loss': 0.547716893741618, 'Total loss': 0.547716893741618}
2023-01-04 07:36:10,851 INFO:     Found new best model at epoch 3
2023-01-04 07:36:10,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:10,851 INFO:     Epoch: 4
2023-01-04 07:36:12,389 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.521648766597112, 'Total loss': 0.521648766597112} | train loss {'Reaction outcome loss': 0.5269204924503962, 'Total loss': 0.5269204924503962}
2023-01-04 07:36:12,389 INFO:     Found new best model at epoch 4
2023-01-04 07:36:12,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:12,389 INFO:     Epoch: 5
2023-01-04 07:36:13,952 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4897726893424988, 'Total loss': 0.4897726893424988} | train loss {'Reaction outcome loss': 0.5214522436693094, 'Total loss': 0.5214522436693094}
2023-01-04 07:36:13,953 INFO:     Found new best model at epoch 5
2023-01-04 07:36:13,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:13,953 INFO:     Epoch: 6
2023-01-04 07:36:15,520 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5141538461049397, 'Total loss': 0.5141538461049397} | train loss {'Reaction outcome loss': 0.5315667859993983, 'Total loss': 0.5315667859993983}
2023-01-04 07:36:15,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:15,521 INFO:     Epoch: 7
2023-01-04 07:36:17,103 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49035222133000694, 'Total loss': 0.49035222133000694} | train loss {'Reaction outcome loss': 0.5081575129255382, 'Total loss': 0.5081575129255382}
2023-01-04 07:36:17,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:17,103 INFO:     Epoch: 8
2023-01-04 07:36:18,673 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4572723597288132, 'Total loss': 0.4572723597288132} | train loss {'Reaction outcome loss': 0.47935940657971776, 'Total loss': 0.47935940657971776}
2023-01-04 07:36:18,674 INFO:     Found new best model at epoch 8
2023-01-04 07:36:18,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:18,674 INFO:     Epoch: 9
2023-01-04 07:36:20,221 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47192881306012474, 'Total loss': 0.47192881306012474} | train loss {'Reaction outcome loss': 0.481222014280333, 'Total loss': 0.481222014280333}
2023-01-04 07:36:20,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:20,223 INFO:     Epoch: 10
2023-01-04 07:36:21,753 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47309443553288777, 'Total loss': 0.47309443553288777} | train loss {'Reaction outcome loss': 0.4865002762256325, 'Total loss': 0.4865002762256325}
2023-01-04 07:36:21,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:21,753 INFO:     Epoch: 11
2023-01-04 07:36:23,346 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4624251256386439, 'Total loss': 0.4624251256386439} | train loss {'Reaction outcome loss': 0.4634821975225772, 'Total loss': 0.4634821975225772}
2023-01-04 07:36:23,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:23,346 INFO:     Epoch: 12
2023-01-04 07:36:24,936 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4700212876001994, 'Total loss': 0.4700212876001994} | train loss {'Reaction outcome loss': 0.4563622279227644, 'Total loss': 0.4563622279227644}
2023-01-04 07:36:24,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:24,936 INFO:     Epoch: 13
2023-01-04 07:36:26,508 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4496471703052521, 'Total loss': 0.4496471703052521} | train loss {'Reaction outcome loss': 0.45362738641383854, 'Total loss': 0.45362738641383854}
2023-01-04 07:36:26,509 INFO:     Found new best model at epoch 13
2023-01-04 07:36:26,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:26,510 INFO:     Epoch: 14
2023-01-04 07:36:28,083 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4475845257441203, 'Total loss': 0.4475845257441203} | train loss {'Reaction outcome loss': 0.4481106618608254, 'Total loss': 0.4481106618608254}
2023-01-04 07:36:28,084 INFO:     Found new best model at epoch 14
2023-01-04 07:36:28,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:28,084 INFO:     Epoch: 15
2023-01-04 07:36:29,636 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.450974178314209, 'Total loss': 0.450974178314209} | train loss {'Reaction outcome loss': 0.4441030965983004, 'Total loss': 0.4441030965983004}
2023-01-04 07:36:29,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:29,637 INFO:     Epoch: 16
2023-01-04 07:36:31,172 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46094763080279033, 'Total loss': 0.46094763080279033} | train loss {'Reaction outcome loss': 0.44049478823947774, 'Total loss': 0.44049478823947774}
2023-01-04 07:36:31,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:31,173 INFO:     Epoch: 17
2023-01-04 07:36:32,740 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45707880159219105, 'Total loss': 0.45707880159219105} | train loss {'Reaction outcome loss': 0.43675700739781925, 'Total loss': 0.43675700739781925}
2023-01-04 07:36:32,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:32,740 INFO:     Epoch: 18
2023-01-04 07:36:34,315 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44060018261273703, 'Total loss': 0.44060018261273703} | train loss {'Reaction outcome loss': 0.43368415474770183, 'Total loss': 0.43368415474770183}
2023-01-04 07:36:34,315 INFO:     Found new best model at epoch 18
2023-01-04 07:36:34,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:34,316 INFO:     Epoch: 19
2023-01-04 07:36:35,877 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43345070878664654, 'Total loss': 0.43345070878664654} | train loss {'Reaction outcome loss': 0.42340408047944633, 'Total loss': 0.42340408047944633}
2023-01-04 07:36:35,877 INFO:     Found new best model at epoch 19
2023-01-04 07:36:35,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:35,878 INFO:     Epoch: 20
2023-01-04 07:36:37,434 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4280369997024536, 'Total loss': 0.4280369997024536} | train loss {'Reaction outcome loss': 0.4263932664399508, 'Total loss': 0.4263932664399508}
2023-01-04 07:36:37,434 INFO:     Found new best model at epoch 20
2023-01-04 07:36:37,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:37,435 INFO:     Epoch: 21
2023-01-04 07:36:38,952 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44322928388913474, 'Total loss': 0.44322928388913474} | train loss {'Reaction outcome loss': 0.4320943378235983, 'Total loss': 0.4320943378235983}
2023-01-04 07:36:38,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:38,953 INFO:     Epoch: 22
2023-01-04 07:36:40,517 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43632817069689434, 'Total loss': 0.43632817069689434} | train loss {'Reaction outcome loss': 0.4296872432375718, 'Total loss': 0.4296872432375718}
2023-01-04 07:36:40,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:40,517 INFO:     Epoch: 23
2023-01-04 07:36:42,079 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43806698819001516, 'Total loss': 0.43806698819001516} | train loss {'Reaction outcome loss': 0.412978235252566, 'Total loss': 0.412978235252566}
2023-01-04 07:36:42,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:42,080 INFO:     Epoch: 24
2023-01-04 07:36:43,672 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41758812268575035, 'Total loss': 0.41758812268575035} | train loss {'Reaction outcome loss': 0.4118326323794832, 'Total loss': 0.4118326323794832}
2023-01-04 07:36:43,672 INFO:     Found new best model at epoch 24
2023-01-04 07:36:43,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:43,673 INFO:     Epoch: 25
2023-01-04 07:36:45,236 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4247046808401744, 'Total loss': 0.4247046808401744} | train loss {'Reaction outcome loss': 0.4043289933596616, 'Total loss': 0.4043289933596616}
2023-01-04 07:36:45,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:45,236 INFO:     Epoch: 26
2023-01-04 07:36:46,799 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4276990870634715, 'Total loss': 0.4276990870634715} | train loss {'Reaction outcome loss': 0.399015051919918, 'Total loss': 0.399015051919918}
2023-01-04 07:36:46,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:46,800 INFO:     Epoch: 27
2023-01-04 07:36:48,314 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43211359679698946, 'Total loss': 0.43211359679698946} | train loss {'Reaction outcome loss': 0.3996946942907411, 'Total loss': 0.3996946942907411}
2023-01-04 07:36:48,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:48,315 INFO:     Epoch: 28
2023-01-04 07:36:49,929 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43672094742457074, 'Total loss': 0.43672094742457074} | train loss {'Reaction outcome loss': 0.3970973499767158, 'Total loss': 0.3970973499767158}
2023-01-04 07:36:49,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:49,929 INFO:     Epoch: 29
2023-01-04 07:36:51,513 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4100618869066238, 'Total loss': 0.4100618869066238} | train loss {'Reaction outcome loss': 0.4098577194077813, 'Total loss': 0.4098577194077813}
2023-01-04 07:36:51,513 INFO:     Found new best model at epoch 29
2023-01-04 07:36:51,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:51,514 INFO:     Epoch: 30
2023-01-04 07:36:53,108 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39942064583301545, 'Total loss': 0.39942064583301545} | train loss {'Reaction outcome loss': 0.41626730523463606, 'Total loss': 0.41626730523463606}
2023-01-04 07:36:53,108 INFO:     Found new best model at epoch 30
2023-01-04 07:36:53,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:53,109 INFO:     Epoch: 31
2023-01-04 07:36:54,667 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42622649371623994, 'Total loss': 0.42622649371623994} | train loss {'Reaction outcome loss': 0.391106951585375, 'Total loss': 0.391106951585375}
2023-01-04 07:36:54,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:54,668 INFO:     Epoch: 32
2023-01-04 07:36:56,203 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39962064822514853, 'Total loss': 0.39962064822514853} | train loss {'Reaction outcome loss': 0.3873183940658751, 'Total loss': 0.3873183940658751}
2023-01-04 07:36:56,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:56,204 INFO:     Epoch: 33
2023-01-04 07:36:57,774 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39787624577681224, 'Total loss': 0.39787624577681224} | train loss {'Reaction outcome loss': 0.382991316575077, 'Total loss': 0.382991316575077}
2023-01-04 07:36:57,774 INFO:     Found new best model at epoch 33
2023-01-04 07:36:57,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:57,775 INFO:     Epoch: 34
2023-01-04 07:36:59,370 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40788839558760326, 'Total loss': 0.40788839558760326} | train loss {'Reaction outcome loss': 0.37986074993091606, 'Total loss': 0.37986074993091606}
2023-01-04 07:36:59,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:36:59,370 INFO:     Epoch: 35
2023-01-04 07:37:00,979 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40536148150761925, 'Total loss': 0.40536148150761925} | train loss {'Reaction outcome loss': 0.3756122470300213, 'Total loss': 0.3756122470300213}
2023-01-04 07:37:00,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:00,980 INFO:     Epoch: 36
2023-01-04 07:37:02,584 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38917887906233467, 'Total loss': 0.38917887906233467} | train loss {'Reaction outcome loss': 0.3734703787966915, 'Total loss': 0.3734703787966915}
2023-01-04 07:37:02,584 INFO:     Found new best model at epoch 36
2023-01-04 07:37:02,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:02,585 INFO:     Epoch: 37
2023-01-04 07:37:04,200 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39107550581296285, 'Total loss': 0.39107550581296285} | train loss {'Reaction outcome loss': 0.3773049296190341, 'Total loss': 0.3773049296190341}
2023-01-04 07:37:04,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:04,201 INFO:     Epoch: 38
2023-01-04 07:37:05,730 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40035347988208136, 'Total loss': 0.40035347988208136} | train loss {'Reaction outcome loss': 0.37359128217044135, 'Total loss': 0.37359128217044135}
2023-01-04 07:37:05,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:05,730 INFO:     Epoch: 39
2023-01-04 07:37:07,306 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38590581317742667, 'Total loss': 0.38590581317742667} | train loss {'Reaction outcome loss': 0.3658413241692883, 'Total loss': 0.3658413241692883}
2023-01-04 07:37:07,307 INFO:     Found new best model at epoch 39
2023-01-04 07:37:07,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:07,307 INFO:     Epoch: 40
2023-01-04 07:37:08,938 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38346164325873056, 'Total loss': 0.38346164325873056} | train loss {'Reaction outcome loss': 0.36432594090254733, 'Total loss': 0.36432594090254733}
2023-01-04 07:37:08,938 INFO:     Found new best model at epoch 40
2023-01-04 07:37:08,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:08,939 INFO:     Epoch: 41
2023-01-04 07:37:10,551 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39456234077612556, 'Total loss': 0.39456234077612556} | train loss {'Reaction outcome loss': 0.36150878608105297, 'Total loss': 0.36150878608105297}
2023-01-04 07:37:10,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:10,551 INFO:     Epoch: 42
2023-01-04 07:37:12,167 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38513972957928977, 'Total loss': 0.38513972957928977} | train loss {'Reaction outcome loss': 0.35955960792151914, 'Total loss': 0.35955960792151914}
2023-01-04 07:37:12,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:12,168 INFO:     Epoch: 43
2023-01-04 07:37:13,777 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39756159285704296, 'Total loss': 0.39756159285704296} | train loss {'Reaction outcome loss': 0.3565448993189341, 'Total loss': 0.3565448993189341}
2023-01-04 07:37:13,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:13,777 INFO:     Epoch: 44
2023-01-04 07:37:15,334 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3853944847981135, 'Total loss': 0.3853944847981135} | train loss {'Reaction outcome loss': 0.35196961066010746, 'Total loss': 0.35196961066010746}
2023-01-04 07:37:15,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:15,335 INFO:     Epoch: 45
2023-01-04 07:37:16,878 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4006346732378006, 'Total loss': 0.4006346732378006} | train loss {'Reaction outcome loss': 0.34968020629299723, 'Total loss': 0.34968020629299723}
2023-01-04 07:37:16,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:16,878 INFO:     Epoch: 46
2023-01-04 07:37:18,432 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3726450602213542, 'Total loss': 0.3726450602213542} | train loss {'Reaction outcome loss': 0.3472368089124506, 'Total loss': 0.3472368089124506}
2023-01-04 07:37:18,432 INFO:     Found new best model at epoch 46
2023-01-04 07:37:18,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:18,433 INFO:     Epoch: 47
2023-01-04 07:37:19,985 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3800936092933019, 'Total loss': 0.3800936092933019} | train loss {'Reaction outcome loss': 0.34693778201640735, 'Total loss': 0.34693778201640735}
2023-01-04 07:37:19,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:19,986 INFO:     Epoch: 48
2023-01-04 07:37:21,536 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38582615156968436, 'Total loss': 0.38582615156968436} | train loss {'Reaction outcome loss': 0.3440238591519765, 'Total loss': 0.3440238591519765}
2023-01-04 07:37:21,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:21,536 INFO:     Epoch: 49
2023-01-04 07:37:23,113 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36501211325327554, 'Total loss': 0.36501211325327554} | train loss {'Reaction outcome loss': 0.3407470235952001, 'Total loss': 0.3407470235952001}
2023-01-04 07:37:23,113 INFO:     Found new best model at epoch 49
2023-01-04 07:37:23,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:23,114 INFO:     Epoch: 50
2023-01-04 07:37:24,607 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3698633035024007, 'Total loss': 0.3698633035024007} | train loss {'Reaction outcome loss': 0.3375596473637995, 'Total loss': 0.3375596473637995}
2023-01-04 07:37:24,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:24,607 INFO:     Epoch: 51
2023-01-04 07:37:26,164 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39927831093470256, 'Total loss': 0.39927831093470256} | train loss {'Reaction outcome loss': 0.33772817501127406, 'Total loss': 0.33772817501127406}
2023-01-04 07:37:26,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:26,164 INFO:     Epoch: 52
2023-01-04 07:37:27,742 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3820720414320628, 'Total loss': 0.3820720414320628} | train loss {'Reaction outcome loss': 0.3300177129719447, 'Total loss': 0.3300177129719447}
2023-01-04 07:37:27,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:27,742 INFO:     Epoch: 53
2023-01-04 07:37:29,300 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37994572321573894, 'Total loss': 0.37994572321573894} | train loss {'Reaction outcome loss': 0.3302880432895398, 'Total loss': 0.3302880432895398}
2023-01-04 07:37:29,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:29,301 INFO:     Epoch: 54
2023-01-04 07:37:30,849 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3769956568876902, 'Total loss': 0.3769956568876902} | train loss {'Reaction outcome loss': 0.3303607175855533, 'Total loss': 0.3303607175855533}
2023-01-04 07:37:30,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:30,851 INFO:     Epoch: 55
2023-01-04 07:37:32,416 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39063223004341124, 'Total loss': 0.39063223004341124} | train loss {'Reaction outcome loss': 0.3463053762331939, 'Total loss': 0.3463053762331939}
2023-01-04 07:37:32,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:32,416 INFO:     Epoch: 56
2023-01-04 07:37:33,921 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39414421021938323, 'Total loss': 0.39414421021938323} | train loss {'Reaction outcome loss': 0.32778722768455115, 'Total loss': 0.32778722768455115}
2023-01-04 07:37:33,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:33,921 INFO:     Epoch: 57
2023-01-04 07:37:35,487 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3712246676286062, 'Total loss': 0.3712246676286062} | train loss {'Reaction outcome loss': 0.32833145205201447, 'Total loss': 0.32833145205201447}
2023-01-04 07:37:35,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:35,487 INFO:     Epoch: 58
2023-01-04 07:37:37,072 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36984146932760875, 'Total loss': 0.36984146932760875} | train loss {'Reaction outcome loss': 0.3373291083490071, 'Total loss': 0.3373291083490071}
2023-01-04 07:37:37,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:37,073 INFO:     Epoch: 59
2023-01-04 07:37:38,630 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3733344336350759, 'Total loss': 0.3733344336350759} | train loss {'Reaction outcome loss': 0.32122804931566573, 'Total loss': 0.32122804931566573}
2023-01-04 07:37:38,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:38,630 INFO:     Epoch: 60
2023-01-04 07:37:40,195 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37397920389970146, 'Total loss': 0.37397920389970146} | train loss {'Reaction outcome loss': 0.3166594673488019, 'Total loss': 0.3166594673488019}
2023-01-04 07:37:40,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:40,196 INFO:     Epoch: 61
2023-01-04 07:37:41,739 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37914274434248607, 'Total loss': 0.37914274434248607} | train loss {'Reaction outcome loss': 0.3364273088079864, 'Total loss': 0.3364273088079864}
2023-01-04 07:37:41,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:41,739 INFO:     Epoch: 62
2023-01-04 07:37:43,271 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3756900931398074, 'Total loss': 0.3756900931398074} | train loss {'Reaction outcome loss': 0.3267635448860676, 'Total loss': 0.3267635448860676}
2023-01-04 07:37:43,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:43,271 INFO:     Epoch: 63
2023-01-04 07:37:44,855 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36369659900665285, 'Total loss': 0.36369659900665285} | train loss {'Reaction outcome loss': 0.3126646657474339, 'Total loss': 0.3126646657474339}
2023-01-04 07:37:44,855 INFO:     Found new best model at epoch 63
2023-01-04 07:37:44,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:44,856 INFO:     Epoch: 64
2023-01-04 07:37:46,432 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37813287576039634, 'Total loss': 0.37813287576039634} | train loss {'Reaction outcome loss': 0.3090566652894452, 'Total loss': 0.3090566652894452}
2023-01-04 07:37:46,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:46,432 INFO:     Epoch: 65
2023-01-04 07:37:48,005 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37367198467254636, 'Total loss': 0.37367198467254636} | train loss {'Reaction outcome loss': 0.30758181089818803, 'Total loss': 0.30758181089818803}
2023-01-04 07:37:48,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:48,005 INFO:     Epoch: 66
2023-01-04 07:37:49,582 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3750231752792994, 'Total loss': 0.3750231752792994} | train loss {'Reaction outcome loss': 0.30956312006827025, 'Total loss': 0.30956312006827025}
2023-01-04 07:37:49,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:49,583 INFO:     Epoch: 67
2023-01-04 07:37:51,109 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4238647202650706, 'Total loss': 0.4238647202650706} | train loss {'Reaction outcome loss': 0.30296731148711475, 'Total loss': 0.30296731148711475}
2023-01-04 07:37:51,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:51,109 INFO:     Epoch: 68
2023-01-04 07:37:52,639 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36708722710609437, 'Total loss': 0.36708722710609437} | train loss {'Reaction outcome loss': 0.30643947281456296, 'Total loss': 0.30643947281456296}
2023-01-04 07:37:52,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:52,639 INFO:     Epoch: 69
2023-01-04 07:37:54,208 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37413848042488096, 'Total loss': 0.37413848042488096} | train loss {'Reaction outcome loss': 0.30199177353326534, 'Total loss': 0.30199177353326534}
2023-01-04 07:37:54,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:54,209 INFO:     Epoch: 70
2023-01-04 07:37:55,796 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3848016053438187, 'Total loss': 0.3848016053438187} | train loss {'Reaction outcome loss': 0.30243689813553076, 'Total loss': 0.30243689813553076}
2023-01-04 07:37:55,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:55,797 INFO:     Epoch: 71
2023-01-04 07:37:57,365 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3648104111353556, 'Total loss': 0.3648104111353556} | train loss {'Reaction outcome loss': 0.29913823516150273, 'Total loss': 0.29913823516150273}
2023-01-04 07:37:57,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:57,366 INFO:     Epoch: 72
2023-01-04 07:37:58,929 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37792925387620924, 'Total loss': 0.37792925387620924} | train loss {'Reaction outcome loss': 0.2947619202870714, 'Total loss': 0.2947619202870714}
2023-01-04 07:37:58,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:37:58,930 INFO:     Epoch: 73
2023-01-04 07:38:00,447 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40122683346271515, 'Total loss': 0.40122683346271515} | train loss {'Reaction outcome loss': 0.29921001800592395, 'Total loss': 0.29921001800592395}
2023-01-04 07:38:00,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:00,447 INFO:     Epoch: 74
2023-01-04 07:38:01,990 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37403169174989065, 'Total loss': 0.37403169174989065} | train loss {'Reaction outcome loss': 0.29966023886589793, 'Total loss': 0.29966023886589793}
2023-01-04 07:38:01,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:01,991 INFO:     Epoch: 75
2023-01-04 07:38:03,588 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3600455055634181, 'Total loss': 0.3600455055634181} | train loss {'Reaction outcome loss': 0.29381852806545794, 'Total loss': 0.29381852806545794}
2023-01-04 07:38:03,589 INFO:     Found new best model at epoch 75
2023-01-04 07:38:03,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:03,589 INFO:     Epoch: 76
2023-01-04 07:38:05,147 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3702819004654884, 'Total loss': 0.3702819004654884} | train loss {'Reaction outcome loss': 0.29685992244091153, 'Total loss': 0.29685992244091153}
2023-01-04 07:38:05,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:05,147 INFO:     Epoch: 77
2023-01-04 07:38:06,707 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3523652970790863, 'Total loss': 0.3523652970790863} | train loss {'Reaction outcome loss': 0.30190291263810964, 'Total loss': 0.30190291263810964}
2023-01-04 07:38:06,709 INFO:     Found new best model at epoch 77
2023-01-04 07:38:06,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:06,709 INFO:     Epoch: 78
2023-01-04 07:38:08,255 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36775031089782717, 'Total loss': 0.36775031089782717} | train loss {'Reaction outcome loss': 0.2910372315825004, 'Total loss': 0.2910372315825004}
2023-01-04 07:38:08,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:08,255 INFO:     Epoch: 79
2023-01-04 07:38:09,786 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3971963624159495, 'Total loss': 0.3971963624159495} | train loss {'Reaction outcome loss': 0.2890196635397961, 'Total loss': 0.2890196635397961}
2023-01-04 07:38:09,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:09,786 INFO:     Epoch: 80
2023-01-04 07:38:11,338 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36315489510695137, 'Total loss': 0.36315489510695137} | train loss {'Reaction outcome loss': 0.28625758226722164, 'Total loss': 0.28625758226722164}
2023-01-04 07:38:11,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:11,339 INFO:     Epoch: 81
2023-01-04 07:38:12,899 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39661515355110166, 'Total loss': 0.39661515355110166} | train loss {'Reaction outcome loss': 0.2895503326224676, 'Total loss': 0.2895503326224676}
2023-01-04 07:38:12,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:12,900 INFO:     Epoch: 82
2023-01-04 07:38:14,446 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3760682284832001, 'Total loss': 0.3760682284832001} | train loss {'Reaction outcome loss': 0.28901633082389616, 'Total loss': 0.28901633082389616}
2023-01-04 07:38:14,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:14,446 INFO:     Epoch: 83
2023-01-04 07:38:15,990 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37043987611929574, 'Total loss': 0.37043987611929574} | train loss {'Reaction outcome loss': 0.2846476097415755, 'Total loss': 0.2846476097415755}
2023-01-04 07:38:15,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:15,990 INFO:     Epoch: 84
2023-01-04 07:38:17,551 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.380216325322787, 'Total loss': 0.380216325322787} | train loss {'Reaction outcome loss': 0.2811376951226587, 'Total loss': 0.2811376951226587}
2023-01-04 07:38:17,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:17,551 INFO:     Epoch: 85
2023-01-04 07:38:19,036 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.389959380030632, 'Total loss': 0.389959380030632} | train loss {'Reaction outcome loss': 0.27938224537491263, 'Total loss': 0.27938224537491263}
2023-01-04 07:38:19,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:19,036 INFO:     Epoch: 86
2023-01-04 07:38:20,598 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35524420291185377, 'Total loss': 0.35524420291185377} | train loss {'Reaction outcome loss': 0.2778029990099046, 'Total loss': 0.2778029990099046}
2023-01-04 07:38:20,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:20,599 INFO:     Epoch: 87
2023-01-04 07:38:22,158 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.372652941942215, 'Total loss': 0.372652941942215} | train loss {'Reaction outcome loss': 0.2775779415937048, 'Total loss': 0.2775779415937048}
2023-01-04 07:38:22,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:22,158 INFO:     Epoch: 88
2023-01-04 07:38:23,724 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35224822064240774, 'Total loss': 0.35224822064240774} | train loss {'Reaction outcome loss': 0.2755228421141299, 'Total loss': 0.2755228421141299}
2023-01-04 07:38:23,724 INFO:     Found new best model at epoch 88
2023-01-04 07:38:23,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:23,725 INFO:     Epoch: 89
2023-01-04 07:38:25,299 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.34329121162494025, 'Total loss': 0.34329121162494025} | train loss {'Reaction outcome loss': 0.2778323137486502, 'Total loss': 0.2778323137486502}
2023-01-04 07:38:25,300 INFO:     Found new best model at epoch 89
2023-01-04 07:38:25,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:25,301 INFO:     Epoch: 90
2023-01-04 07:38:26,849 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3846804102261861, 'Total loss': 0.3846804102261861} | train loss {'Reaction outcome loss': 0.26920125876463513, 'Total loss': 0.26920125876463513}
2023-01-04 07:38:26,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:26,849 INFO:     Epoch: 91
2023-01-04 07:38:28,342 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3768664121627808, 'Total loss': 0.3768664121627808} | train loss {'Reaction outcome loss': 0.2719856385897467, 'Total loss': 0.2719856385897467}
2023-01-04 07:38:28,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:28,343 INFO:     Epoch: 92
2023-01-04 07:38:29,903 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39011746644973755, 'Total loss': 0.39011746644973755} | train loss {'Reaction outcome loss': 0.28261636861640477, 'Total loss': 0.28261636861640477}
2023-01-04 07:38:29,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:29,903 INFO:     Epoch: 93
2023-01-04 07:38:31,479 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.363430384794871, 'Total loss': 0.363430384794871} | train loss {'Reaction outcome loss': 0.2906039465029818, 'Total loss': 0.2906039465029818}
2023-01-04 07:38:31,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:31,479 INFO:     Epoch: 94
2023-01-04 07:38:33,044 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3508127083381017, 'Total loss': 0.3508127083381017} | train loss {'Reaction outcome loss': 0.2712735378358891, 'Total loss': 0.2712735378358891}
2023-01-04 07:38:33,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:33,044 INFO:     Epoch: 95
2023-01-04 07:38:34,601 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3635232592622439, 'Total loss': 0.3635232592622439} | train loss {'Reaction outcome loss': 0.28552630827492237, 'Total loss': 0.28552630827492237}
2023-01-04 07:38:34,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:34,601 INFO:     Epoch: 96
2023-01-04 07:38:36,142 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.367050235470136, 'Total loss': 0.367050235470136} | train loss {'Reaction outcome loss': 0.2669331081265557, 'Total loss': 0.2669331081265557}
2023-01-04 07:38:36,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:36,142 INFO:     Epoch: 97
2023-01-04 07:38:37,685 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3812094738086065, 'Total loss': 0.3812094738086065} | train loss {'Reaction outcome loss': 0.2666251937710289, 'Total loss': 0.2666251937710289}
2023-01-04 07:38:37,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:37,685 INFO:     Epoch: 98
2023-01-04 07:38:39,242 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36554289758205416, 'Total loss': 0.36554289758205416} | train loss {'Reaction outcome loss': 0.2773734427401391, 'Total loss': 0.2773734427401391}
2023-01-04 07:38:39,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:39,242 INFO:     Epoch: 99
2023-01-04 07:38:40,834 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3876255651315053, 'Total loss': 0.3876255651315053} | train loss {'Reaction outcome loss': 0.2604770578686114, 'Total loss': 0.2604770578686114}
2023-01-04 07:38:40,834 INFO:     Best model found after epoch 90 of 100.
2023-01-04 07:38:40,834 INFO:   Done with stage: TRAINING
2023-01-04 07:38:40,835 INFO:   Starting stage: EVALUATION
2023-01-04 07:38:40,963 INFO:   Done with stage: EVALUATION
2023-01-04 07:38:40,963 INFO:   Leaving out SEQ value Fold_7
2023-01-04 07:38:40,976 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 07:38:40,976 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:38:41,628 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:38:41,628 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:38:41,698 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:38:41,698 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:38:41,698 INFO:     No hyperparam tuning for this model
2023-01-04 07:38:41,698 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:38:41,698 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:38:41,699 INFO:     None feature selector for col prot
2023-01-04 07:38:41,699 INFO:     None feature selector for col prot
2023-01-04 07:38:41,699 INFO:     None feature selector for col prot
2023-01-04 07:38:41,700 INFO:     None feature selector for col chem
2023-01-04 07:38:41,700 INFO:     None feature selector for col chem
2023-01-04 07:38:41,700 INFO:     None feature selector for col chem
2023-01-04 07:38:41,700 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:38:41,700 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:38:41,701 INFO:     Number of params in model 70111
2023-01-04 07:38:41,704 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:38:41,704 INFO:   Starting stage: TRAINING
2023-01-04 07:38:41,748 INFO:     Val loss before train {'Reaction outcome loss': 0.9627119660377502, 'Total loss': 0.9627119660377502}
2023-01-04 07:38:41,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:41,749 INFO:     Epoch: 0
2023-01-04 07:38:43,333 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7376550495624542, 'Total loss': 0.7376550495624542} | train loss {'Reaction outcome loss': 0.8383923359080773, 'Total loss': 0.8383923359080773}
2023-01-04 07:38:43,334 INFO:     Found new best model at epoch 0
2023-01-04 07:38:43,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:43,335 INFO:     Epoch: 1
2023-01-04 07:38:44,882 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6310492793718974, 'Total loss': 0.6310492793718974} | train loss {'Reaction outcome loss': 0.6728592400946772, 'Total loss': 0.6728592400946772}
2023-01-04 07:38:44,882 INFO:     Found new best model at epoch 1
2023-01-04 07:38:44,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:44,882 INFO:     Epoch: 2
2023-01-04 07:38:46,447 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5628932853539784, 'Total loss': 0.5628932853539784} | train loss {'Reaction outcome loss': 0.578474245777199, 'Total loss': 0.578474245777199}
2023-01-04 07:38:46,447 INFO:     Found new best model at epoch 2
2023-01-04 07:38:46,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:46,448 INFO:     Epoch: 3
2023-01-04 07:38:48,050 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5259857316811879, 'Total loss': 0.5259857316811879} | train loss {'Reaction outcome loss': 0.5378477912302052, 'Total loss': 0.5378477912302052}
2023-01-04 07:38:48,050 INFO:     Found new best model at epoch 3
2023-01-04 07:38:48,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:48,051 INFO:     Epoch: 4
2023-01-04 07:38:49,621 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5389617005983989, 'Total loss': 0.5389617005983989} | train loss {'Reaction outcome loss': 0.5123048087965281, 'Total loss': 0.5123048087965281}
2023-01-04 07:38:49,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:49,622 INFO:     Epoch: 5
2023-01-04 07:38:51,187 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49485662976900735, 'Total loss': 0.49485662976900735} | train loss {'Reaction outcome loss': 0.4915222771976829, 'Total loss': 0.4915222771976829}
2023-01-04 07:38:51,187 INFO:     Found new best model at epoch 5
2023-01-04 07:38:51,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:51,188 INFO:     Epoch: 6
2023-01-04 07:38:52,782 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48211208581924436, 'Total loss': 0.48211208581924436} | train loss {'Reaction outcome loss': 0.4812825882155112, 'Total loss': 0.4812825882155112}
2023-01-04 07:38:52,782 INFO:     Found new best model at epoch 6
2023-01-04 07:38:52,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:52,783 INFO:     Epoch: 7
2023-01-04 07:38:54,328 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4904194096724192, 'Total loss': 0.4904194096724192} | train loss {'Reaction outcome loss': 0.4714161752040636, 'Total loss': 0.4714161752040636}
2023-01-04 07:38:54,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:54,328 INFO:     Epoch: 8
2023-01-04 07:38:55,856 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46230277717113494, 'Total loss': 0.46230277717113494} | train loss {'Reaction outcome loss': 0.4674499401762167, 'Total loss': 0.4674499401762167}
2023-01-04 07:38:55,856 INFO:     Found new best model at epoch 8
2023-01-04 07:38:55,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:55,857 INFO:     Epoch: 9
2023-01-04 07:38:57,421 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4780034283796946, 'Total loss': 0.4780034283796946} | train loss {'Reaction outcome loss': 0.45695063052194645, 'Total loss': 0.45695063052194645}
2023-01-04 07:38:57,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:57,421 INFO:     Epoch: 10
2023-01-04 07:38:59,043 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4554779678583145, 'Total loss': 0.4554779678583145} | train loss {'Reaction outcome loss': 0.44937767217520774, 'Total loss': 0.44937767217520774}
2023-01-04 07:38:59,043 INFO:     Found new best model at epoch 10
2023-01-04 07:38:59,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:38:59,044 INFO:     Epoch: 11
2023-01-04 07:39:00,648 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4684804807106654, 'Total loss': 0.4684804807106654} | train loss {'Reaction outcome loss': 0.44866301081671184, 'Total loss': 0.44866301081671184}
2023-01-04 07:39:00,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:00,648 INFO:     Epoch: 12
2023-01-04 07:39:02,229 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45982212324937183, 'Total loss': 0.45982212324937183} | train loss {'Reaction outcome loss': 0.4384018158008906, 'Total loss': 0.4384018158008906}
2023-01-04 07:39:02,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:02,230 INFO:     Epoch: 13
2023-01-04 07:39:03,763 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4995466281970342, 'Total loss': 0.4995466281970342} | train loss {'Reaction outcome loss': 0.4377631080279712, 'Total loss': 0.4377631080279712}
2023-01-04 07:39:03,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:03,763 INFO:     Epoch: 14
2023-01-04 07:39:05,296 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4447130382061005, 'Total loss': 0.4447130382061005} | train loss {'Reaction outcome loss': 0.43400348365199265, 'Total loss': 0.43400348365199265}
2023-01-04 07:39:05,296 INFO:     Found new best model at epoch 14
2023-01-04 07:39:05,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:05,297 INFO:     Epoch: 15
2023-01-04 07:39:06,876 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48153644998868306, 'Total loss': 0.48153644998868306} | train loss {'Reaction outcome loss': 0.43052191991991084, 'Total loss': 0.43052191991991084}
2023-01-04 07:39:06,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:06,876 INFO:     Epoch: 16
2023-01-04 07:39:08,434 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47214208245277406, 'Total loss': 0.47214208245277406} | train loss {'Reaction outcome loss': 0.42687051052005714, 'Total loss': 0.42687051052005714}
2023-01-04 07:39:08,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:08,434 INFO:     Epoch: 17
2023-01-04 07:39:10,004 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4492931326230367, 'Total loss': 0.4492931326230367} | train loss {'Reaction outcome loss': 0.4175224401567817, 'Total loss': 0.4175224401567817}
2023-01-04 07:39:10,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:10,004 INFO:     Epoch: 18
2023-01-04 07:39:11,579 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47045141061147056, 'Total loss': 0.47045141061147056} | train loss {'Reaction outcome loss': 0.4189129073159359, 'Total loss': 0.4189129073159359}
2023-01-04 07:39:11,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:11,579 INFO:     Epoch: 19
2023-01-04 07:39:13,087 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.454787274201711, 'Total loss': 0.454787274201711} | train loss {'Reaction outcome loss': 0.40885296956188844, 'Total loss': 0.40885296956188844}
2023-01-04 07:39:13,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:13,088 INFO:     Epoch: 20
2023-01-04 07:39:14,661 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4313720613718033, 'Total loss': 0.4313720613718033} | train loss {'Reaction outcome loss': 0.40722490365647235, 'Total loss': 0.40722490365647235}
2023-01-04 07:39:14,661 INFO:     Found new best model at epoch 20
2023-01-04 07:39:14,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:14,662 INFO:     Epoch: 21
2023-01-04 07:39:16,246 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4401833434899648, 'Total loss': 0.4401833434899648} | train loss {'Reaction outcome loss': 0.40319528352697837, 'Total loss': 0.40319528352697837}
2023-01-04 07:39:16,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:16,246 INFO:     Epoch: 22
2023-01-04 07:39:17,818 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4289178967475891, 'Total loss': 0.4289178967475891} | train loss {'Reaction outcome loss': 0.4016276432288683, 'Total loss': 0.4016276432288683}
2023-01-04 07:39:17,818 INFO:     Found new best model at epoch 22
2023-01-04 07:39:17,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:17,819 INFO:     Epoch: 23
2023-01-04 07:39:19,407 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.452394437789917, 'Total loss': 0.452394437789917} | train loss {'Reaction outcome loss': 0.3972672243141956, 'Total loss': 0.3972672243141956}
2023-01-04 07:39:19,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:19,408 INFO:     Epoch: 24
2023-01-04 07:39:20,971 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44243606527646384, 'Total loss': 0.44243606527646384} | train loss {'Reaction outcome loss': 0.3970657002032879, 'Total loss': 0.3970657002032879}
2023-01-04 07:39:20,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:20,971 INFO:     Epoch: 25
2023-01-04 07:39:22,482 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47169366578261057, 'Total loss': 0.47169366578261057} | train loss {'Reaction outcome loss': 0.39090991275727965, 'Total loss': 0.39090991275727965}
2023-01-04 07:39:22,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:22,483 INFO:     Epoch: 26
2023-01-04 07:39:24,066 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4646169205506643, 'Total loss': 0.4646169205506643} | train loss {'Reaction outcome loss': 0.3864531110340077, 'Total loss': 0.3864531110340077}
2023-01-04 07:39:24,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:24,066 INFO:     Epoch: 27
2023-01-04 07:39:25,642 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4213853324453036, 'Total loss': 0.4213853324453036} | train loss {'Reaction outcome loss': 0.38308165940567046, 'Total loss': 0.38308165940567046}
2023-01-04 07:39:25,643 INFO:     Found new best model at epoch 27
2023-01-04 07:39:25,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:25,644 INFO:     Epoch: 28
2023-01-04 07:39:27,221 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44112919171651205, 'Total loss': 0.44112919171651205} | train loss {'Reaction outcome loss': 0.3797053243386616, 'Total loss': 0.3797053243386616}
2023-01-04 07:39:27,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:27,222 INFO:     Epoch: 29
2023-01-04 07:39:28,779 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4435845603545507, 'Total loss': 0.4435845603545507} | train loss {'Reaction outcome loss': 0.3786753822212185, 'Total loss': 0.3786753822212185}
2023-01-04 07:39:28,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:28,779 INFO:     Epoch: 30
2023-01-04 07:39:30,312 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45036279360453285, 'Total loss': 0.45036279360453285} | train loss {'Reaction outcome loss': 0.37286885373213663, 'Total loss': 0.37286885373213663}
2023-01-04 07:39:30,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:30,312 INFO:     Epoch: 31
2023-01-04 07:39:31,838 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4234134634335836, 'Total loss': 0.4234134634335836} | train loss {'Reaction outcome loss': 0.3693201927609392, 'Total loss': 0.3693201927609392}
2023-01-04 07:39:31,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:31,838 INFO:     Epoch: 32
2023-01-04 07:39:33,386 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4240926106770833, 'Total loss': 0.4240926106770833} | train loss {'Reaction outcome loss': 0.3649238419823268, 'Total loss': 0.3649238419823268}
2023-01-04 07:39:33,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:33,386 INFO:     Epoch: 33
2023-01-04 07:39:34,936 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4292249192794164, 'Total loss': 0.4292249192794164} | train loss {'Reaction outcome loss': 0.36346784874205124, 'Total loss': 0.36346784874205124}
2023-01-04 07:39:34,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:34,936 INFO:     Epoch: 34
2023-01-04 07:39:36,480 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4496298889319102, 'Total loss': 0.4496298889319102} | train loss {'Reaction outcome loss': 0.3602351768998032, 'Total loss': 0.3602351768998032}
2023-01-04 07:39:36,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:36,480 INFO:     Epoch: 35
2023-01-04 07:39:38,027 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.427110947171847, 'Total loss': 0.427110947171847} | train loss {'Reaction outcome loss': 0.35543793854085115, 'Total loss': 0.35543793854085115}
2023-01-04 07:39:38,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:38,028 INFO:     Epoch: 36
2023-01-04 07:39:39,557 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42197627226511636, 'Total loss': 0.42197627226511636} | train loss {'Reaction outcome loss': 0.3557015469412081, 'Total loss': 0.3557015469412081}
2023-01-04 07:39:39,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:39,557 INFO:     Epoch: 37
2023-01-04 07:39:41,108 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4298433701197306, 'Total loss': 0.4298433701197306} | train loss {'Reaction outcome loss': 0.3522381827719375, 'Total loss': 0.3522381827719375}
2023-01-04 07:39:41,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:41,109 INFO:     Epoch: 38
2023-01-04 07:39:42,715 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4041287730137507, 'Total loss': 0.4041287730137507} | train loss {'Reaction outcome loss': 0.34929155838080694, 'Total loss': 0.34929155838080694}
2023-01-04 07:39:42,715 INFO:     Found new best model at epoch 38
2023-01-04 07:39:42,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:42,716 INFO:     Epoch: 39
2023-01-04 07:39:44,331 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45283896923065187, 'Total loss': 0.45283896923065187} | train loss {'Reaction outcome loss': 0.34355944177196346, 'Total loss': 0.34355944177196346}
2023-01-04 07:39:44,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:44,332 INFO:     Epoch: 40
2023-01-04 07:39:45,944 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43522102733453116, 'Total loss': 0.43522102733453116} | train loss {'Reaction outcome loss': 0.34174260037147614, 'Total loss': 0.34174260037147614}
2023-01-04 07:39:45,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:45,945 INFO:     Epoch: 41
2023-01-04 07:39:47,550 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4383448859055837, 'Total loss': 0.4383448859055837} | train loss {'Reaction outcome loss': 0.3415688909724731, 'Total loss': 0.3415688909724731}
2023-01-04 07:39:47,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:47,551 INFO:     Epoch: 42
2023-01-04 07:39:49,101 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42513016760349276, 'Total loss': 0.42513016760349276} | train loss {'Reaction outcome loss': 0.3352412989746362, 'Total loss': 0.3352412989746362}
2023-01-04 07:39:49,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:49,101 INFO:     Epoch: 43
2023-01-04 07:39:50,656 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4410401612520218, 'Total loss': 0.4410401612520218} | train loss {'Reaction outcome loss': 0.32987780987355686, 'Total loss': 0.32987780987355686}
2023-01-04 07:39:50,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:50,657 INFO:     Epoch: 44
2023-01-04 07:39:52,277 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43891313473383586, 'Total loss': 0.43891313473383586} | train loss {'Reaction outcome loss': 0.33176771346950357, 'Total loss': 0.33176771346950357}
2023-01-04 07:39:52,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:52,278 INFO:     Epoch: 45
2023-01-04 07:39:53,898 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41480927069981893, 'Total loss': 0.41480927069981893} | train loss {'Reaction outcome loss': 0.3295867814941312, 'Total loss': 0.3295867814941312}
2023-01-04 07:39:53,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:53,898 INFO:     Epoch: 46
2023-01-04 07:39:55,509 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46516141494115193, 'Total loss': 0.46516141494115193} | train loss {'Reaction outcome loss': 0.3265864288010752, 'Total loss': 0.3265864288010752}
2023-01-04 07:39:55,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:55,510 INFO:     Epoch: 47
2023-01-04 07:39:57,142 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42779779235521953, 'Total loss': 0.42779779235521953} | train loss {'Reaction outcome loss': 0.3223032115652673, 'Total loss': 0.3223032115652673}
2023-01-04 07:39:57,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:57,142 INFO:     Epoch: 48
2023-01-04 07:39:58,657 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4334023932615916, 'Total loss': 0.4334023932615916} | train loss {'Reaction outcome loss': 0.3214699074706661, 'Total loss': 0.3214699074706661}
2023-01-04 07:39:58,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:39:58,658 INFO:     Epoch: 49
2023-01-04 07:40:00,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4321169247229894, 'Total loss': 0.4321169247229894} | train loss {'Reaction outcome loss': 0.31630262802439046, 'Total loss': 0.31630262802439046}
2023-01-04 07:40:00,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:00,233 INFO:     Epoch: 50
2023-01-04 07:40:01,825 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4351711412270864, 'Total loss': 0.4351711412270864} | train loss {'Reaction outcome loss': 0.31753921363543086, 'Total loss': 0.31753921363543086}
2023-01-04 07:40:01,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:01,826 INFO:     Epoch: 51
2023-01-04 07:40:03,409 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40382737418015796, 'Total loss': 0.40382737418015796} | train loss {'Reaction outcome loss': 0.31145587672449193, 'Total loss': 0.31145587672449193}
2023-01-04 07:40:03,409 INFO:     Found new best model at epoch 51
2023-01-04 07:40:03,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:03,410 INFO:     Epoch: 52
2023-01-04 07:40:04,996 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40567377110322317, 'Total loss': 0.40567377110322317} | train loss {'Reaction outcome loss': 0.31243114939988303, 'Total loss': 0.31243114939988303}
2023-01-04 07:40:04,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:04,996 INFO:     Epoch: 53
2023-01-04 07:40:06,537 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42169352173805236, 'Total loss': 0.42169352173805236} | train loss {'Reaction outcome loss': 0.3133158060564031, 'Total loss': 0.3133158060564031}
2023-01-04 07:40:06,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:06,537 INFO:     Epoch: 54
2023-01-04 07:40:08,071 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4426536997159322, 'Total loss': 0.4426536997159322} | train loss {'Reaction outcome loss': 0.3113233357237565, 'Total loss': 0.3113233357237565}
2023-01-04 07:40:08,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:08,071 INFO:     Epoch: 55
2023-01-04 07:40:09,649 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43426570991675056, 'Total loss': 0.43426570991675056} | train loss {'Reaction outcome loss': 0.30703487747520314, 'Total loss': 0.30703487747520314}
2023-01-04 07:40:09,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:09,649 INFO:     Epoch: 56
2023-01-04 07:40:11,234 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4666857530673345, 'Total loss': 0.4666857530673345} | train loss {'Reaction outcome loss': 0.3042208513897249, 'Total loss': 0.3042208513897249}
2023-01-04 07:40:11,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:11,234 INFO:     Epoch: 57
2023-01-04 07:40:12,811 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42854950030644734, 'Total loss': 0.42854950030644734} | train loss {'Reaction outcome loss': 0.3039660697688587, 'Total loss': 0.3039660697688587}
2023-01-04 07:40:12,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:12,811 INFO:     Epoch: 58
2023-01-04 07:40:14,396 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43701845010121665, 'Total loss': 0.43701845010121665} | train loss {'Reaction outcome loss': 0.3053738960075034, 'Total loss': 0.3053738960075034}
2023-01-04 07:40:14,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:14,397 INFO:     Epoch: 59
2023-01-04 07:40:15,952 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4378042628367742, 'Total loss': 0.4378042628367742} | train loss {'Reaction outcome loss': 0.2992260340695347, 'Total loss': 0.2992260340695347}
2023-01-04 07:40:15,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:15,952 INFO:     Epoch: 60
2023-01-04 07:40:17,494 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41932943363984426, 'Total loss': 0.41932943363984426} | train loss {'Reaction outcome loss': 0.2934003935770438, 'Total loss': 0.2934003935770438}
2023-01-04 07:40:17,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:17,494 INFO:     Epoch: 61
2023-01-04 07:40:19,088 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4628012458483378, 'Total loss': 0.4628012458483378} | train loss {'Reaction outcome loss': 0.29569021390502204, 'Total loss': 0.29569021390502204}
2023-01-04 07:40:19,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:19,088 INFO:     Epoch: 62
2023-01-04 07:40:20,677 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4032993157704671, 'Total loss': 0.4032993157704671} | train loss {'Reaction outcome loss': 0.2959277677460698, 'Total loss': 0.2959277677460698}
2023-01-04 07:40:20,677 INFO:     Found new best model at epoch 62
2023-01-04 07:40:20,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:20,677 INFO:     Epoch: 63
2023-01-04 07:40:22,259 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45334559082984927, 'Total loss': 0.45334559082984927} | train loss {'Reaction outcome loss': 0.2947222586680836, 'Total loss': 0.2947222586680836}
2023-01-04 07:40:22,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:22,259 INFO:     Epoch: 64
2023-01-04 07:40:23,842 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4662555356820424, 'Total loss': 0.4662555356820424} | train loss {'Reaction outcome loss': 0.29296694717467475, 'Total loss': 0.29296694717467475}
2023-01-04 07:40:23,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:23,843 INFO:     Epoch: 65
2023-01-04 07:40:25,383 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4222234716018041, 'Total loss': 0.4222234716018041} | train loss {'Reaction outcome loss': 0.2900091807495816, 'Total loss': 0.2900091807495816}
2023-01-04 07:40:25,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:25,383 INFO:     Epoch: 66
2023-01-04 07:40:26,914 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4413098643223445, 'Total loss': 0.4413098643223445} | train loss {'Reaction outcome loss': 0.2876683425978633, 'Total loss': 0.2876683425978633}
2023-01-04 07:40:26,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:26,914 INFO:     Epoch: 67
2023-01-04 07:40:28,499 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42952969868977864, 'Total loss': 0.42952969868977864} | train loss {'Reaction outcome loss': 0.28179619258895033, 'Total loss': 0.28179619258895033}
2023-01-04 07:40:28,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:28,499 INFO:     Epoch: 68
2023-01-04 07:40:30,069 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46670305728912354, 'Total loss': 0.46670305728912354} | train loss {'Reaction outcome loss': 0.28654138001509094, 'Total loss': 0.28654138001509094}
2023-01-04 07:40:30,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:30,070 INFO:     Epoch: 69
2023-01-04 07:40:31,647 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45578776399294535, 'Total loss': 0.45578776399294535} | train loss {'Reaction outcome loss': 0.28231014346280253, 'Total loss': 0.28231014346280253}
2023-01-04 07:40:31,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:31,647 INFO:     Epoch: 70
2023-01-04 07:40:33,228 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4458467761675517, 'Total loss': 0.4458467761675517} | train loss {'Reaction outcome loss': 0.2811750776608498, 'Total loss': 0.2811750776608498}
2023-01-04 07:40:33,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:33,229 INFO:     Epoch: 71
2023-01-04 07:40:34,736 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4301527361075083, 'Total loss': 0.4301527361075083} | train loss {'Reaction outcome loss': 0.2817630947631404, 'Total loss': 0.2817630947631404}
2023-01-04 07:40:34,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:34,736 INFO:     Epoch: 72
2023-01-04 07:40:36,320 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49491134881973264, 'Total loss': 0.49491134881973264} | train loss {'Reaction outcome loss': 0.27957952635813277, 'Total loss': 0.27957952635813277}
2023-01-04 07:40:36,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:36,321 INFO:     Epoch: 73
2023-01-04 07:40:37,923 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46519695917765297, 'Total loss': 0.46519695917765297} | train loss {'Reaction outcome loss': 0.28184752228135235, 'Total loss': 0.28184752228135235}
2023-01-04 07:40:37,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:37,923 INFO:     Epoch: 74
2023-01-04 07:40:39,531 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.458926323056221, 'Total loss': 0.458926323056221} | train loss {'Reaction outcome loss': 0.27640156127808324, 'Total loss': 0.27640156127808324}
2023-01-04 07:40:39,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:39,531 INFO:     Epoch: 75
2023-01-04 07:40:41,110 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41043852766354877, 'Total loss': 0.41043852766354877} | train loss {'Reaction outcome loss': 0.28035145862169214, 'Total loss': 0.28035145862169214}
2023-01-04 07:40:41,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:41,110 INFO:     Epoch: 76
2023-01-04 07:40:42,696 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4372570445140203, 'Total loss': 0.4372570445140203} | train loss {'Reaction outcome loss': 0.27418399935702553, 'Total loss': 0.27418399935702553}
2023-01-04 07:40:42,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:42,696 INFO:     Epoch: 77
2023-01-04 07:40:44,233 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45602789521217346, 'Total loss': 0.45602789521217346} | train loss {'Reaction outcome loss': 0.2739727153889969, 'Total loss': 0.2739727153889969}
2023-01-04 07:40:44,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:44,233 INFO:     Epoch: 78
2023-01-04 07:40:45,825 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4257278581460317, 'Total loss': 0.4257278581460317} | train loss {'Reaction outcome loss': 0.27955864568910016, 'Total loss': 0.27955864568910016}
2023-01-04 07:40:45,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:45,826 INFO:     Epoch: 79
2023-01-04 07:40:47,413 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4482831468184789, 'Total loss': 0.4482831468184789} | train loss {'Reaction outcome loss': 0.2696746540413867, 'Total loss': 0.2696746540413867}
2023-01-04 07:40:47,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:47,414 INFO:     Epoch: 80
2023-01-04 07:40:49,004 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4497891237338384, 'Total loss': 0.4497891237338384} | train loss {'Reaction outcome loss': 0.27339458271914874, 'Total loss': 0.27339458271914874}
2023-01-04 07:40:49,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:49,005 INFO:     Epoch: 81
2023-01-04 07:40:50,589 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41434911688168846, 'Total loss': 0.41434911688168846} | train loss {'Reaction outcome loss': 0.27388640213421533, 'Total loss': 0.27388640213421533}
2023-01-04 07:40:50,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:50,589 INFO:     Epoch: 82
2023-01-04 07:40:52,133 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4343734085559845, 'Total loss': 0.4343734085559845} | train loss {'Reaction outcome loss': 0.2683049637810848, 'Total loss': 0.2683049637810848}
2023-01-04 07:40:52,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:52,134 INFO:     Epoch: 83
2023-01-04 07:40:53,672 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4135020097096761, 'Total loss': 0.4135020097096761} | train loss {'Reaction outcome loss': 0.2663317012603963, 'Total loss': 0.2663317012603963}
2023-01-04 07:40:53,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:53,673 INFO:     Epoch: 84
2023-01-04 07:40:55,255 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44299723505973815, 'Total loss': 0.44299723505973815} | train loss {'Reaction outcome loss': 0.26789618251233327, 'Total loss': 0.26789618251233327}
2023-01-04 07:40:55,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:55,255 INFO:     Epoch: 85
2023-01-04 07:40:56,845 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.501803336540858, 'Total loss': 0.501803336540858} | train loss {'Reaction outcome loss': 0.2643873597283441, 'Total loss': 0.2643873597283441}
2023-01-04 07:40:56,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:56,845 INFO:     Epoch: 86
2023-01-04 07:40:58,421 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4459958990414937, 'Total loss': 0.4459958990414937} | train loss {'Reaction outcome loss': 0.26569923285112484, 'Total loss': 0.26569923285112484}
2023-01-04 07:40:58,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:40:58,421 INFO:     Epoch: 87
2023-01-04 07:41:00,004 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43940440366665523, 'Total loss': 0.43940440366665523} | train loss {'Reaction outcome loss': 0.26490345825895073, 'Total loss': 0.26490345825895073}
2023-01-04 07:41:00,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:00,004 INFO:     Epoch: 88
2023-01-04 07:41:01,552 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41692752490441004, 'Total loss': 0.41692752490441004} | train loss {'Reaction outcome loss': 0.26532025783178176, 'Total loss': 0.26532025783178176}
2023-01-04 07:41:01,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:01,552 INFO:     Epoch: 89
2023-01-04 07:41:03,097 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44078886657953265, 'Total loss': 0.44078886657953265} | train loss {'Reaction outcome loss': 0.2624534334086339, 'Total loss': 0.2624534334086339}
2023-01-04 07:41:03,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:03,097 INFO:     Epoch: 90
2023-01-04 07:41:04,695 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43443531592686974, 'Total loss': 0.43443531592686974} | train loss {'Reaction outcome loss': 0.2605514291014912, 'Total loss': 0.2605514291014912}
2023-01-04 07:41:04,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:04,695 INFO:     Epoch: 91
2023-01-04 07:41:06,276 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42864686250686646, 'Total loss': 0.42864686250686646} | train loss {'Reaction outcome loss': 0.2603390723574463, 'Total loss': 0.2603390723574463}
2023-01-04 07:41:06,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:06,277 INFO:     Epoch: 92
2023-01-04 07:41:07,863 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43009917934735614, 'Total loss': 0.43009917934735614} | train loss {'Reaction outcome loss': 0.25798644351399763, 'Total loss': 0.25798644351399763}
2023-01-04 07:41:07,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:07,863 INFO:     Epoch: 93
2023-01-04 07:41:09,467 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4222216089566549, 'Total loss': 0.4222216089566549} | train loss {'Reaction outcome loss': 0.2579744751649213, 'Total loss': 0.2579744751649213}
2023-01-04 07:41:09,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:09,467 INFO:     Epoch: 94
2023-01-04 07:41:11,020 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46219393809636433, 'Total loss': 0.46219393809636433} | train loss {'Reaction outcome loss': 0.25473307651410465, 'Total loss': 0.25473307651410465}
2023-01-04 07:41:11,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:11,020 INFO:     Epoch: 95
2023-01-04 07:41:12,059 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4450258880853653, 'Total loss': 0.4450258880853653} | train loss {'Reaction outcome loss': 0.26090653321372903, 'Total loss': 0.26090653321372903}
2023-01-04 07:41:12,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:12,059 INFO:     Epoch: 96
2023-01-04 07:41:13,085 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4155150105555852, 'Total loss': 0.4155150105555852} | train loss {'Reaction outcome loss': 0.25758043930795216, 'Total loss': 0.25758043930795216}
2023-01-04 07:41:13,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:13,086 INFO:     Epoch: 97
2023-01-04 07:41:14,108 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4248246361811956, 'Total loss': 0.4248246361811956} | train loss {'Reaction outcome loss': 0.2519032639663142, 'Total loss': 0.2519032639663142}
2023-01-04 07:41:14,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:14,108 INFO:     Epoch: 98
2023-01-04 07:41:15,129 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42722685933113097, 'Total loss': 0.42722685933113097} | train loss {'Reaction outcome loss': 0.2517440642637036, 'Total loss': 0.2517440642637036}
2023-01-04 07:41:15,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:15,130 INFO:     Epoch: 99
2023-01-04 07:41:16,590 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4472605635722478, 'Total loss': 0.4472605635722478} | train loss {'Reaction outcome loss': 0.25520731467713303, 'Total loss': 0.25520731467713303}
2023-01-04 07:41:16,590 INFO:     Best model found after epoch 63 of 100.
2023-01-04 07:41:16,590 INFO:   Done with stage: TRAINING
2023-01-04 07:41:16,590 INFO:   Starting stage: EVALUATION
2023-01-04 07:41:16,710 INFO:   Done with stage: EVALUATION
2023-01-04 07:41:16,710 INFO:   Leaving out SEQ value Fold_8
2023-01-04 07:41:16,723 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 07:41:16,723 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:41:17,382 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:41:17,382 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:41:17,452 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:41:17,452 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:41:17,452 INFO:     No hyperparam tuning for this model
2023-01-04 07:41:17,452 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:41:17,452 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:41:17,453 INFO:     None feature selector for col prot
2023-01-04 07:41:17,453 INFO:     None feature selector for col prot
2023-01-04 07:41:17,453 INFO:     None feature selector for col prot
2023-01-04 07:41:17,453 INFO:     None feature selector for col chem
2023-01-04 07:41:17,453 INFO:     None feature selector for col chem
2023-01-04 07:41:17,454 INFO:     None feature selector for col chem
2023-01-04 07:41:17,454 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:41:17,454 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:41:17,455 INFO:     Number of params in model 70111
2023-01-04 07:41:17,458 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:41:17,458 INFO:   Starting stage: TRAINING
2023-01-04 07:41:17,500 INFO:     Val loss before train {'Reaction outcome loss': 0.960400418440501, 'Total loss': 0.960400418440501}
2023-01-04 07:41:17,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:17,500 INFO:     Epoch: 0
2023-01-04 07:41:19,078 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7455315947532654, 'Total loss': 0.7455315947532654} | train loss {'Reaction outcome loss': 0.8555223807315964, 'Total loss': 0.8555223807315964}
2023-01-04 07:41:19,078 INFO:     Found new best model at epoch 0
2023-01-04 07:41:19,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:19,079 INFO:     Epoch: 1
2023-01-04 07:41:20,659 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6242820938428243, 'Total loss': 0.6242820938428243} | train loss {'Reaction outcome loss': 0.6995319409921281, 'Total loss': 0.6995319409921281}
2023-01-04 07:41:20,659 INFO:     Found new best model at epoch 1
2023-01-04 07:41:20,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:20,660 INFO:     Epoch: 2
2023-01-04 07:41:22,248 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5555825452009837, 'Total loss': 0.5555825452009837} | train loss {'Reaction outcome loss': 0.6118813677815323, 'Total loss': 0.6118813677815323}
2023-01-04 07:41:22,248 INFO:     Found new best model at epoch 2
2023-01-04 07:41:22,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:22,249 INFO:     Epoch: 3
2023-01-04 07:41:23,831 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5299909631411235, 'Total loss': 0.5299909631411235} | train loss {'Reaction outcome loss': 0.5680769958435844, 'Total loss': 0.5680769958435844}
2023-01-04 07:41:23,831 INFO:     Found new best model at epoch 3
2023-01-04 07:41:23,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:23,832 INFO:     Epoch: 4
2023-01-04 07:41:25,371 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5075255036354065, 'Total loss': 0.5075255036354065} | train loss {'Reaction outcome loss': 0.5372104178912372, 'Total loss': 0.5372104178912372}
2023-01-04 07:41:25,372 INFO:     Found new best model at epoch 4
2023-01-04 07:41:25,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:25,373 INFO:     Epoch: 5
2023-01-04 07:41:26,955 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5223590652147929, 'Total loss': 0.5223590652147929} | train loss {'Reaction outcome loss': 0.5196556253661317, 'Total loss': 0.5196556253661317}
2023-01-04 07:41:26,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:26,955 INFO:     Epoch: 6
2023-01-04 07:41:28,533 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4983633150657018, 'Total loss': 0.4983633150657018} | train loss {'Reaction outcome loss': 0.5092645674298386, 'Total loss': 0.5092645674298386}
2023-01-04 07:41:28,533 INFO:     Found new best model at epoch 6
2023-01-04 07:41:28,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:28,534 INFO:     Epoch: 7
2023-01-04 07:41:30,130 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.467695806423823, 'Total loss': 0.467695806423823} | train loss {'Reaction outcome loss': 0.49424540259562677, 'Total loss': 0.49424540259562677}
2023-01-04 07:41:30,130 INFO:     Found new best model at epoch 7
2023-01-04 07:41:30,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:30,131 INFO:     Epoch: 8
2023-01-04 07:41:31,718 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46703256567319235, 'Total loss': 0.46703256567319235} | train loss {'Reaction outcome loss': 0.48670065994727485, 'Total loss': 0.48670065994727485}
2023-01-04 07:41:31,718 INFO:     Found new best model at epoch 8
2023-01-04 07:41:31,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:31,719 INFO:     Epoch: 9
2023-01-04 07:41:33,285 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4641796350479126, 'Total loss': 0.4641796350479126} | train loss {'Reaction outcome loss': 0.4792193421280341, 'Total loss': 0.4792193421280341}
2023-01-04 07:41:33,285 INFO:     Found new best model at epoch 9
2023-01-04 07:41:33,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:33,286 INFO:     Epoch: 10
2023-01-04 07:41:34,818 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4757972717285156, 'Total loss': 0.4757972717285156} | train loss {'Reaction outcome loss': 0.47211789713654706, 'Total loss': 0.47211789713654706}
2023-01-04 07:41:34,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:34,818 INFO:     Epoch: 11
2023-01-04 07:41:36,421 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4685396154721578, 'Total loss': 0.4685396154721578} | train loss {'Reaction outcome loss': 0.46444217155986744, 'Total loss': 0.46444217155986744}
2023-01-04 07:41:36,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:36,421 INFO:     Epoch: 12
2023-01-04 07:41:38,058 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4630407989025116, 'Total loss': 0.4630407989025116} | train loss {'Reaction outcome loss': 0.4599522089699976, 'Total loss': 0.4599522089699976}
2023-01-04 07:41:38,059 INFO:     Found new best model at epoch 12
2023-01-04 07:41:38,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:38,060 INFO:     Epoch: 13
2023-01-04 07:41:39,695 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4438909709453583, 'Total loss': 0.4438909709453583} | train loss {'Reaction outcome loss': 0.45454556018867215, 'Total loss': 0.45454556018867215}
2023-01-04 07:41:39,695 INFO:     Found new best model at epoch 13
2023-01-04 07:41:39,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:39,696 INFO:     Epoch: 14
2023-01-04 07:41:41,330 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44897381265958153, 'Total loss': 0.44897381265958153} | train loss {'Reaction outcome loss': 0.44481170371121015, 'Total loss': 0.44481170371121015}
2023-01-04 07:41:41,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:41,330 INFO:     Epoch: 15
2023-01-04 07:41:42,913 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4369086960951487, 'Total loss': 0.4369086960951487} | train loss {'Reaction outcome loss': 0.4436882058097998, 'Total loss': 0.4436882058097998}
2023-01-04 07:41:42,913 INFO:     Found new best model at epoch 15
2023-01-04 07:41:42,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:42,914 INFO:     Epoch: 16
2023-01-04 07:41:44,502 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44390417138735455, 'Total loss': 0.44390417138735455} | train loss {'Reaction outcome loss': 0.4420963788828695, 'Total loss': 0.4420963788828695}
2023-01-04 07:41:44,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:44,503 INFO:     Epoch: 17
2023-01-04 07:41:46,129 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42544593612353004, 'Total loss': 0.42544593612353004} | train loss {'Reaction outcome loss': 0.43558488915328086, 'Total loss': 0.43558488915328086}
2023-01-04 07:41:46,130 INFO:     Found new best model at epoch 17
2023-01-04 07:41:46,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:46,130 INFO:     Epoch: 18
2023-01-04 07:41:47,757 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45049697160720825, 'Total loss': 0.45049697160720825} | train loss {'Reaction outcome loss': 0.42840226653573316, 'Total loss': 0.42840226653573316}
2023-01-04 07:41:47,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:47,758 INFO:     Epoch: 19
2023-01-04 07:41:49,387 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43342965642611186, 'Total loss': 0.43342965642611186} | train loss {'Reaction outcome loss': 0.42674211194799266, 'Total loss': 0.42674211194799266}
2023-01-04 07:41:49,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:49,387 INFO:     Epoch: 20
2023-01-04 07:41:51,015 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4249651183684667, 'Total loss': 0.4249651183684667} | train loss {'Reaction outcome loss': 0.42162944623924764, 'Total loss': 0.42162944623924764}
2023-01-04 07:41:51,015 INFO:     Found new best model at epoch 20
2023-01-04 07:41:51,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:51,016 INFO:     Epoch: 21
2023-01-04 07:41:52,573 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4475911160310109, 'Total loss': 0.4475911160310109} | train loss {'Reaction outcome loss': 0.41801654985880593, 'Total loss': 0.41801654985880593}
2023-01-04 07:41:52,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:52,573 INFO:     Epoch: 22
2023-01-04 07:41:54,208 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42877239485581714, 'Total loss': 0.42877239485581714} | train loss {'Reaction outcome loss': 0.41134273935956644, 'Total loss': 0.41134273935956644}
2023-01-04 07:41:54,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:54,208 INFO:     Epoch: 23
2023-01-04 07:41:55,843 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4105036993821462, 'Total loss': 0.4105036993821462} | train loss {'Reaction outcome loss': 0.4081948395778126, 'Total loss': 0.4081948395778126}
2023-01-04 07:41:55,844 INFO:     Found new best model at epoch 23
2023-01-04 07:41:55,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:55,844 INFO:     Epoch: 24
2023-01-04 07:41:57,460 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4261541684468587, 'Total loss': 0.4261541684468587} | train loss {'Reaction outcome loss': 0.4037990301632279, 'Total loss': 0.4037990301632279}
2023-01-04 07:41:57,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:57,461 INFO:     Epoch: 25
2023-01-04 07:41:59,083 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4081564635038376, 'Total loss': 0.4081564635038376} | train loss {'Reaction outcome loss': 0.40644128548001557, 'Total loss': 0.40644128548001557}
2023-01-04 07:41:59,083 INFO:     Found new best model at epoch 25
2023-01-04 07:41:59,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:41:59,084 INFO:     Epoch: 26
2023-01-04 07:42:00,665 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.405165833234787, 'Total loss': 0.405165833234787} | train loss {'Reaction outcome loss': 0.3979587169491857, 'Total loss': 0.3979587169491857}
2023-01-04 07:42:00,665 INFO:     Found new best model at epoch 26
2023-01-04 07:42:00,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:00,666 INFO:     Epoch: 27
2023-01-04 07:42:02,256 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41860995690027875, 'Total loss': 0.41860995690027875} | train loss {'Reaction outcome loss': 0.3938704894230254, 'Total loss': 0.3938704894230254}
2023-01-04 07:42:02,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:02,256 INFO:     Epoch: 28
2023-01-04 07:42:03,882 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.396227369705836, 'Total loss': 0.396227369705836} | train loss {'Reaction outcome loss': 0.3884726612953072, 'Total loss': 0.3884726612953072}
2023-01-04 07:42:03,882 INFO:     Found new best model at epoch 28
2023-01-04 07:42:03,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:03,883 INFO:     Epoch: 29
2023-01-04 07:42:05,512 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4257129748662313, 'Total loss': 0.4257129748662313} | train loss {'Reaction outcome loss': 0.38154482526792083, 'Total loss': 0.38154482526792083}
2023-01-04 07:42:05,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:05,512 INFO:     Epoch: 30
2023-01-04 07:42:07,141 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40131083925565086, 'Total loss': 0.40131083925565086} | train loss {'Reaction outcome loss': 0.38234510270051575, 'Total loss': 0.38234510270051575}
2023-01-04 07:42:07,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:07,141 INFO:     Epoch: 31
2023-01-04 07:42:08,771 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39946279923121136, 'Total loss': 0.39946279923121136} | train loss {'Reaction outcome loss': 0.37663224032854775, 'Total loss': 0.37663224032854775}
2023-01-04 07:42:08,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:08,772 INFO:     Epoch: 32
2023-01-04 07:42:10,353 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3983256717522939, 'Total loss': 0.3983256717522939} | train loss {'Reaction outcome loss': 0.3753337094607336, 'Total loss': 0.3753337094607336}
2023-01-04 07:42:10,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:10,354 INFO:     Epoch: 33
2023-01-04 07:42:11,939 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41099034349123637, 'Total loss': 0.41099034349123637} | train loss {'Reaction outcome loss': 0.37195315480985364, 'Total loss': 0.37195315480985364}
2023-01-04 07:42:11,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:11,939 INFO:     Epoch: 34
2023-01-04 07:42:13,569 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4044424474239349, 'Total loss': 0.4044424474239349} | train loss {'Reaction outcome loss': 0.36682340677572073, 'Total loss': 0.36682340677572073}
2023-01-04 07:42:13,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:13,570 INFO:     Epoch: 35
2023-01-04 07:42:15,204 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39040975968043007, 'Total loss': 0.39040975968043007} | train loss {'Reaction outcome loss': 0.36629889897383505, 'Total loss': 0.36629889897383505}
2023-01-04 07:42:15,204 INFO:     Found new best model at epoch 35
2023-01-04 07:42:15,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:15,205 INFO:     Epoch: 36
2023-01-04 07:42:16,835 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3854918787876765, 'Total loss': 0.3854918787876765} | train loss {'Reaction outcome loss': 0.3602352027482074, 'Total loss': 0.3602352027482074}
2023-01-04 07:42:16,835 INFO:     Found new best model at epoch 36
2023-01-04 07:42:16,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:16,836 INFO:     Epoch: 37
2023-01-04 07:42:18,463 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3814085284868876, 'Total loss': 0.3814085284868876} | train loss {'Reaction outcome loss': 0.3603549282527142, 'Total loss': 0.3603549282527142}
2023-01-04 07:42:18,464 INFO:     Found new best model at epoch 37
2023-01-04 07:42:18,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:18,464 INFO:     Epoch: 38
2023-01-04 07:42:20,008 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39999450743198395, 'Total loss': 0.39999450743198395} | train loss {'Reaction outcome loss': 0.3553400452279012, 'Total loss': 0.3553400452279012}
2023-01-04 07:42:20,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:20,009 INFO:     Epoch: 39
2023-01-04 07:42:21,643 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3910270313421885, 'Total loss': 0.3910270313421885} | train loss {'Reaction outcome loss': 0.34947001651628784, 'Total loss': 0.34947001651628784}
2023-01-04 07:42:21,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:21,643 INFO:     Epoch: 40
2023-01-04 07:42:23,271 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3681056042512258, 'Total loss': 0.3681056042512258} | train loss {'Reaction outcome loss': 0.3501449518900916, 'Total loss': 0.3501449518900916}
2023-01-04 07:42:23,271 INFO:     Found new best model at epoch 40
2023-01-04 07:42:23,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:23,272 INFO:     Epoch: 41
2023-01-04 07:42:24,897 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38229728043079375, 'Total loss': 0.38229728043079375} | train loss {'Reaction outcome loss': 0.3457841813187737, 'Total loss': 0.3457841813187737}
2023-01-04 07:42:24,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:24,897 INFO:     Epoch: 42
2023-01-04 07:42:26,521 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.393290905157725, 'Total loss': 0.393290905157725} | train loss {'Reaction outcome loss': 0.3388650085682903, 'Total loss': 0.3388650085682903}
2023-01-04 07:42:26,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:26,522 INFO:     Epoch: 43
2023-01-04 07:42:28,103 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3876861761013667, 'Total loss': 0.3876861761013667} | train loss {'Reaction outcome loss': 0.3385949984784591, 'Total loss': 0.3385949984784591}
2023-01-04 07:42:28,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:28,103 INFO:     Epoch: 44
2023-01-04 07:42:29,682 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36701907714207965, 'Total loss': 0.36701907714207965} | train loss {'Reaction outcome loss': 0.3381498467836139, 'Total loss': 0.3381498467836139}
2023-01-04 07:42:29,682 INFO:     Found new best model at epoch 44
2023-01-04 07:42:29,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:29,683 INFO:     Epoch: 45
2023-01-04 07:42:31,319 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3575710475444794, 'Total loss': 0.3575710475444794} | train loss {'Reaction outcome loss': 0.33313483457057486, 'Total loss': 0.33313483457057486}
2023-01-04 07:42:31,319 INFO:     Found new best model at epoch 45
2023-01-04 07:42:31,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:31,320 INFO:     Epoch: 46
2023-01-04 07:42:32,943 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3852534398436546, 'Total loss': 0.3852534398436546} | train loss {'Reaction outcome loss': 0.32771101741906966, 'Total loss': 0.32771101741906966}
2023-01-04 07:42:32,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:32,944 INFO:     Epoch: 47
2023-01-04 07:42:34,569 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37570047279198965, 'Total loss': 0.37570047279198965} | train loss {'Reaction outcome loss': 0.3292433897080404, 'Total loss': 0.3292433897080404}
2023-01-04 07:42:34,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:34,569 INFO:     Epoch: 48
2023-01-04 07:42:36,194 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3698874811331431, 'Total loss': 0.3698874811331431} | train loss {'Reaction outcome loss': 0.32458413284715765, 'Total loss': 0.32458413284715765}
2023-01-04 07:42:36,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:36,194 INFO:     Epoch: 49
2023-01-04 07:42:37,781 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.414686393737793, 'Total loss': 0.414686393737793} | train loss {'Reaction outcome loss': 0.322833744089526, 'Total loss': 0.322833744089526}
2023-01-04 07:42:37,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:37,781 INFO:     Epoch: 50
2023-01-04 07:42:39,374 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37566949129104615, 'Total loss': 0.37566949129104615} | train loss {'Reaction outcome loss': 0.326111305518486, 'Total loss': 0.326111305518486}
2023-01-04 07:42:39,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:39,374 INFO:     Epoch: 51
2023-01-04 07:42:41,001 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36764081567525864, 'Total loss': 0.36764081567525864} | train loss {'Reaction outcome loss': 0.3222337218559606, 'Total loss': 0.3222337218559606}
2023-01-04 07:42:41,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:41,002 INFO:     Epoch: 52
2023-01-04 07:42:42,629 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3732359617948532, 'Total loss': 0.3732359617948532} | train loss {'Reaction outcome loss': 0.3141997362140714, 'Total loss': 0.3141997362140714}
2023-01-04 07:42:42,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:42,629 INFO:     Epoch: 53
2023-01-04 07:42:44,240 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.33611622601747515, 'Total loss': 0.33611622601747515} | train loss {'Reaction outcome loss': 0.31590115284338754, 'Total loss': 0.31590115284338754}
2023-01-04 07:42:44,240 INFO:     Found new best model at epoch 53
2023-01-04 07:42:44,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:44,240 INFO:     Epoch: 54
2023-01-04 07:42:45,857 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3815870036681493, 'Total loss': 0.3815870036681493} | train loss {'Reaction outcome loss': 0.311560843583694, 'Total loss': 0.311560843583694}
2023-01-04 07:42:45,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:45,857 INFO:     Epoch: 55
2023-01-04 07:42:47,420 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3662014196316401, 'Total loss': 0.3662014196316401} | train loss {'Reaction outcome loss': 0.3149793001449926, 'Total loss': 0.3149793001449926}
2023-01-04 07:42:47,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:47,420 INFO:     Epoch: 56
2023-01-04 07:42:49,045 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39030741651852924, 'Total loss': 0.39030741651852924} | train loss {'Reaction outcome loss': 0.31221214660345864, 'Total loss': 0.31221214660345864}
2023-01-04 07:42:49,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:49,047 INFO:     Epoch: 57
2023-01-04 07:42:50,665 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3791397879521052, 'Total loss': 0.3791397879521052} | train loss {'Reaction outcome loss': 0.30747187129534537, 'Total loss': 0.30747187129534537}
2023-01-04 07:42:50,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:50,665 INFO:     Epoch: 58
2023-01-04 07:42:52,297 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.365222755074501, 'Total loss': 0.365222755074501} | train loss {'Reaction outcome loss': 0.3084562638713995, 'Total loss': 0.3084562638713995}
2023-01-04 07:42:52,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:52,297 INFO:     Epoch: 59
2023-01-04 07:42:53,930 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3582341889540354, 'Total loss': 0.3582341889540354} | train loss {'Reaction outcome loss': 0.30630531630038355, 'Total loss': 0.30630531630038355}
2023-01-04 07:42:53,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:53,930 INFO:     Epoch: 60
2023-01-04 07:42:55,506 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3687042752901713, 'Total loss': 0.3687042752901713} | train loss {'Reaction outcome loss': 0.3001910297448885, 'Total loss': 0.3001910297448885}
2023-01-04 07:42:55,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:55,507 INFO:     Epoch: 61
2023-01-04 07:42:57,087 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36492775281270345, 'Total loss': 0.36492775281270345} | train loss {'Reaction outcome loss': 0.30004463960762917, 'Total loss': 0.30004463960762917}
2023-01-04 07:42:57,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:57,087 INFO:     Epoch: 62
2023-01-04 07:42:58,719 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3738224079211553, 'Total loss': 0.3738224079211553} | train loss {'Reaction outcome loss': 0.30024962729710536, 'Total loss': 0.30024962729710536}
2023-01-04 07:42:58,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:42:58,719 INFO:     Epoch: 63
2023-01-04 07:43:00,340 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38092989921569825, 'Total loss': 0.38092989921569825} | train loss {'Reaction outcome loss': 0.2976972307162595, 'Total loss': 0.2976972307162595}
2023-01-04 07:43:00,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:00,340 INFO:     Epoch: 64
2023-01-04 07:43:01,957 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3603669414917628, 'Total loss': 0.3603669414917628} | train loss {'Reaction outcome loss': 0.29246289252105173, 'Total loss': 0.29246289252105173}
2023-01-04 07:43:01,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:01,957 INFO:     Epoch: 65
2023-01-04 07:43:03,583 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3669286519289017, 'Total loss': 0.3669286519289017} | train loss {'Reaction outcome loss': 0.29552783106961406, 'Total loss': 0.29552783106961406}
2023-01-04 07:43:03,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:03,584 INFO:     Epoch: 66
2023-01-04 07:43:05,149 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3849662452936172, 'Total loss': 0.3849662452936172} | train loss {'Reaction outcome loss': 0.29251056406579723, 'Total loss': 0.29251056406579723}
2023-01-04 07:43:05,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:05,149 INFO:     Epoch: 67
2023-01-04 07:43:06,755 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38509917358557383, 'Total loss': 0.38509917358557383} | train loss {'Reaction outcome loss': 0.2954276889992965, 'Total loss': 0.2954276889992965}
2023-01-04 07:43:06,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:06,755 INFO:     Epoch: 68
2023-01-04 07:43:08,385 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3549091383814812, 'Total loss': 0.3549091383814812} | train loss {'Reaction outcome loss': 0.2910626187974365, 'Total loss': 0.2910626187974365}
2023-01-04 07:43:08,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:08,386 INFO:     Epoch: 69
2023-01-04 07:43:10,017 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36096626420815786, 'Total loss': 0.36096626420815786} | train loss {'Reaction outcome loss': 0.2908604479115793, 'Total loss': 0.2908604479115793}
2023-01-04 07:43:10,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:10,017 INFO:     Epoch: 70
2023-01-04 07:43:11,649 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36809910635153453, 'Total loss': 0.36809910635153453} | train loss {'Reaction outcome loss': 0.28967088208086655, 'Total loss': 0.28967088208086655}
2023-01-04 07:43:11,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:11,649 INFO:     Epoch: 71
2023-01-04 07:43:13,245 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3602105071147283, 'Total loss': 0.3602105071147283} | train loss {'Reaction outcome loss': 0.28850102916844056, 'Total loss': 0.28850102916844056}
2023-01-04 07:43:13,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:13,246 INFO:     Epoch: 72
2023-01-04 07:43:14,829 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3669627358516057, 'Total loss': 0.3669627358516057} | train loss {'Reaction outcome loss': 0.2917761347031335, 'Total loss': 0.2917761347031335}
2023-01-04 07:43:14,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:14,829 INFO:     Epoch: 73
2023-01-04 07:43:16,450 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37089014748732246, 'Total loss': 0.37089014748732246} | train loss {'Reaction outcome loss': 0.2823099289425659, 'Total loss': 0.2823099289425659}
2023-01-04 07:43:16,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:16,451 INFO:     Epoch: 74
2023-01-04 07:43:18,084 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3706221352020899, 'Total loss': 0.3706221352020899} | train loss {'Reaction outcome loss': 0.28133756097150625, 'Total loss': 0.28133756097150625}
2023-01-04 07:43:18,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:18,085 INFO:     Epoch: 75
2023-01-04 07:43:19,717 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3448936104774475, 'Total loss': 0.3448936104774475} | train loss {'Reaction outcome loss': 0.28408132805505815, 'Total loss': 0.28408132805505815}
2023-01-04 07:43:19,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:19,718 INFO:     Epoch: 76
2023-01-04 07:43:21,332 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3682719628016154, 'Total loss': 0.3682719628016154} | train loss {'Reaction outcome loss': 0.2821587227849754, 'Total loss': 0.2821587227849754}
2023-01-04 07:43:21,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:21,332 INFO:     Epoch: 77
2023-01-04 07:43:22,911 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3454351802666982, 'Total loss': 0.3454351802666982} | train loss {'Reaction outcome loss': 0.27732233791897876, 'Total loss': 0.27732233791897876}
2023-01-04 07:43:22,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:22,911 INFO:     Epoch: 78
2023-01-04 07:43:24,453 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36927392731110253, 'Total loss': 0.36927392731110253} | train loss {'Reaction outcome loss': 0.27757324784025816, 'Total loss': 0.27757324784025816}
2023-01-04 07:43:24,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:24,453 INFO:     Epoch: 79
2023-01-04 07:43:26,087 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34280787110328675, 'Total loss': 0.34280787110328675} | train loss {'Reaction outcome loss': 0.27450656457820954, 'Total loss': 0.27450656457820954}
2023-01-04 07:43:26,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:26,088 INFO:     Epoch: 80
2023-01-04 07:43:27,713 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36473973393440245, 'Total loss': 0.36473973393440245} | train loss {'Reaction outcome loss': 0.2761366694950455, 'Total loss': 0.2761366694950455}
2023-01-04 07:43:27,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:27,713 INFO:     Epoch: 81
2023-01-04 07:43:29,332 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3628331243991852, 'Total loss': 0.3628331243991852} | train loss {'Reaction outcome loss': 0.27353204310693463, 'Total loss': 0.27353204310693463}
2023-01-04 07:43:29,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:29,332 INFO:     Epoch: 82
2023-01-04 07:43:30,947 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35989388028780617, 'Total loss': 0.35989388028780617} | train loss {'Reaction outcome loss': 0.27400438496943846, 'Total loss': 0.27400438496943846}
2023-01-04 07:43:30,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:30,947 INFO:     Epoch: 83
2023-01-04 07:43:32,509 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3576510449250539, 'Total loss': 0.3576510449250539} | train loss {'Reaction outcome loss': 0.27748854108665827, 'Total loss': 0.27748854108665827}
2023-01-04 07:43:32,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:32,509 INFO:     Epoch: 84
2023-01-04 07:43:34,112 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3638664444287618, 'Total loss': 0.3638664444287618} | train loss {'Reaction outcome loss': 0.27359513218921444, 'Total loss': 0.27359513218921444}
2023-01-04 07:43:34,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:34,113 INFO:     Epoch: 85
2023-01-04 07:43:35,731 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.34598565598328906, 'Total loss': 0.34598565598328906} | train loss {'Reaction outcome loss': 0.27266719009364127, 'Total loss': 0.27266719009364127}
2023-01-04 07:43:35,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:35,731 INFO:     Epoch: 86
2023-01-04 07:43:37,351 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37582372426986693, 'Total loss': 0.37582372426986693} | train loss {'Reaction outcome loss': 0.2697053811771775, 'Total loss': 0.2697053811771775}
2023-01-04 07:43:37,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:37,351 INFO:     Epoch: 87
2023-01-04 07:43:38,968 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36425839364528656, 'Total loss': 0.36425839364528656} | train loss {'Reaction outcome loss': 0.2667293394058405, 'Total loss': 0.2667293394058405}
2023-01-04 07:43:38,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:38,969 INFO:     Epoch: 88
2023-01-04 07:43:40,548 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35822088420391085, 'Total loss': 0.35822088420391085} | train loss {'Reaction outcome loss': 0.2672325031098906, 'Total loss': 0.2672325031098906}
2023-01-04 07:43:40,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:40,548 INFO:     Epoch: 89
2023-01-04 07:43:42,103 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35623607138792673, 'Total loss': 0.35623607138792673} | train loss {'Reaction outcome loss': 0.26553953026122135, 'Total loss': 0.26553953026122135}
2023-01-04 07:43:42,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:42,103 INFO:     Epoch: 90
2023-01-04 07:43:43,664 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37163254419962566, 'Total loss': 0.37163254419962566} | train loss {'Reaction outcome loss': 0.267225560083286, 'Total loss': 0.267225560083286}
2023-01-04 07:43:43,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:43,664 INFO:     Epoch: 91
2023-01-04 07:43:45,249 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3501856287320455, 'Total loss': 0.3501856287320455} | train loss {'Reaction outcome loss': 0.2642022649007799, 'Total loss': 0.2642022649007799}
2023-01-04 07:43:45,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:45,249 INFO:     Epoch: 92
2023-01-04 07:43:46,805 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3793035219113032, 'Total loss': 0.3793035219113032} | train loss {'Reaction outcome loss': 0.2645964206394736, 'Total loss': 0.2645964206394736}
2023-01-04 07:43:46,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:46,805 INFO:     Epoch: 93
2023-01-04 07:43:48,361 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34820407927036284, 'Total loss': 0.34820407927036284} | train loss {'Reaction outcome loss': 0.26377194998819475, 'Total loss': 0.26377194998819475}
2023-01-04 07:43:48,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:48,361 INFO:     Epoch: 94
2023-01-04 07:43:49,894 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3735795627037684, 'Total loss': 0.3735795627037684} | train loss {'Reaction outcome loss': 0.26450671675188014, 'Total loss': 0.26450671675188014}
2023-01-04 07:43:49,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:49,895 INFO:     Epoch: 95
2023-01-04 07:43:51,415 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35496905545393626, 'Total loss': 0.35496905545393626} | train loss {'Reaction outcome loss': 0.2624154208691972, 'Total loss': 0.2624154208691972}
2023-01-04 07:43:51,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:51,415 INFO:     Epoch: 96
2023-01-04 07:43:52,966 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38202244937419894, 'Total loss': 0.38202244937419894} | train loss {'Reaction outcome loss': 0.2605169803872436, 'Total loss': 0.2605169803872436}
2023-01-04 07:43:52,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:52,966 INFO:     Epoch: 97
2023-01-04 07:43:54,552 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37695635159810387, 'Total loss': 0.37695635159810387} | train loss {'Reaction outcome loss': 0.26369736147271167, 'Total loss': 0.26369736147271167}
2023-01-04 07:43:54,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:54,553 INFO:     Epoch: 98
2023-01-04 07:43:56,186 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3524007851878802, 'Total loss': 0.3524007851878802} | train loss {'Reaction outcome loss': 0.2533295057740883, 'Total loss': 0.2533295057740883}
2023-01-04 07:43:56,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:56,187 INFO:     Epoch: 99
2023-01-04 07:43:57,820 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3497444530328115, 'Total loss': 0.3497444530328115} | train loss {'Reaction outcome loss': 0.258689329189514, 'Total loss': 0.258689329189514}
2023-01-04 07:43:57,820 INFO:     Best model found after epoch 54 of 100.
2023-01-04 07:43:57,820 INFO:   Done with stage: TRAINING
2023-01-04 07:43:57,820 INFO:   Starting stage: EVALUATION
2023-01-04 07:43:57,941 INFO:   Done with stage: EVALUATION
2023-01-04 07:43:57,941 INFO:   Leaving out SEQ value Fold_9
2023-01-04 07:43:57,953 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 07:43:57,953 INFO:   Starting stage: FEATURE SCALING
2023-01-04 07:43:58,599 INFO:   Done with stage: FEATURE SCALING
2023-01-04 07:43:58,599 INFO:   Starting stage: SCALING TARGETS
2023-01-04 07:43:58,669 INFO:   Done with stage: SCALING TARGETS
2023-01-04 07:43:58,669 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:43:58,669 INFO:     No hyperparam tuning for this model
2023-01-04 07:43:58,669 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 07:43:58,669 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 07:43:58,670 INFO:     None feature selector for col prot
2023-01-04 07:43:58,670 INFO:     None feature selector for col prot
2023-01-04 07:43:58,670 INFO:     None feature selector for col prot
2023-01-04 07:43:58,671 INFO:     None feature selector for col chem
2023-01-04 07:43:58,671 INFO:     None feature selector for col chem
2023-01-04 07:43:58,671 INFO:     None feature selector for col chem
2023-01-04 07:43:58,671 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 07:43:58,671 INFO:   Starting stage: BUILD MODEL
2023-01-04 07:43:58,672 INFO:     Number of params in model 70111
2023-01-04 07:43:58,675 INFO:   Done with stage: BUILD MODEL
2023-01-04 07:43:58,675 INFO:   Starting stage: TRAINING
2023-01-04 07:43:58,720 INFO:     Val loss before train {'Reaction outcome loss': 0.9762831091880798, 'Total loss': 0.9762831091880798}
2023-01-04 07:43:58,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:43:58,720 INFO:     Epoch: 0
2023-01-04 07:44:00,266 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7358448167641958, 'Total loss': 0.7358448167641958} | train loss {'Reaction outcome loss': 0.8737764543165332, 'Total loss': 0.8737764543165332}
2023-01-04 07:44:00,266 INFO:     Found new best model at epoch 0
2023-01-04 07:44:00,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:00,267 INFO:     Epoch: 1
2023-01-04 07:44:01,886 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5874946177005768, 'Total loss': 0.5874946177005768} | train loss {'Reaction outcome loss': 0.7107157936130745, 'Total loss': 0.7107157936130745}
2023-01-04 07:44:01,886 INFO:     Found new best model at epoch 1
2023-01-04 07:44:01,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:01,887 INFO:     Epoch: 2
2023-01-04 07:44:03,498 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5383082429567972, 'Total loss': 0.5383082429567972} | train loss {'Reaction outcome loss': 0.6217182849439374, 'Total loss': 0.6217182849439374}
2023-01-04 07:44:03,499 INFO:     Found new best model at epoch 2
2023-01-04 07:44:03,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:03,499 INFO:     Epoch: 3
2023-01-04 07:44:05,123 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49358596801757815, 'Total loss': 0.49358596801757815} | train loss {'Reaction outcome loss': 0.5811168950968895, 'Total loss': 0.5811168950968895}
2023-01-04 07:44:05,123 INFO:     Found new best model at epoch 3
2023-01-04 07:44:05,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:05,124 INFO:     Epoch: 4
2023-01-04 07:44:06,719 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46624239583810173, 'Total loss': 0.46624239583810173} | train loss {'Reaction outcome loss': 0.5478654362740454, 'Total loss': 0.5478654362740454}
2023-01-04 07:44:06,719 INFO:     Found new best model at epoch 4
2023-01-04 07:44:06,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:06,720 INFO:     Epoch: 5
2023-01-04 07:44:08,304 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4699955523014069, 'Total loss': 0.4699955523014069} | train loss {'Reaction outcome loss': 0.5255220411210388, 'Total loss': 0.5255220411210388}
2023-01-04 07:44:08,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:08,305 INFO:     Epoch: 6
2023-01-04 07:44:09,887 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45823113322257997, 'Total loss': 0.45823113322257997} | train loss {'Reaction outcome loss': 0.5191136157491069, 'Total loss': 0.5191136157491069}
2023-01-04 07:44:09,887 INFO:     Found new best model at epoch 6
2023-01-04 07:44:09,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:09,888 INFO:     Epoch: 7
2023-01-04 07:44:11,512 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44566485087076824, 'Total loss': 0.44566485087076824} | train loss {'Reaction outcome loss': 0.5167101039068376, 'Total loss': 0.5167101039068376}
2023-01-04 07:44:11,512 INFO:     Found new best model at epoch 7
2023-01-04 07:44:11,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:11,512 INFO:     Epoch: 8
2023-01-04 07:44:13,116 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43561440308888755, 'Total loss': 0.43561440308888755} | train loss {'Reaction outcome loss': 0.4936837254402538, 'Total loss': 0.4936837254402538}
2023-01-04 07:44:13,117 INFO:     Found new best model at epoch 8
2023-01-04 07:44:13,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:13,117 INFO:     Epoch: 9
2023-01-04 07:44:14,734 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4339675188064575, 'Total loss': 0.4339675188064575} | train loss {'Reaction outcome loss': 0.4837993561573651, 'Total loss': 0.4837993561573651}
2023-01-04 07:44:14,734 INFO:     Found new best model at epoch 9
2023-01-04 07:44:14,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:14,735 INFO:     Epoch: 10
2023-01-04 07:44:16,363 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4100024292866389, 'Total loss': 0.4100024292866389} | train loss {'Reaction outcome loss': 0.4827289306896104, 'Total loss': 0.4827289306896104}
2023-01-04 07:44:16,363 INFO:     Found new best model at epoch 10
2023-01-04 07:44:16,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:16,364 INFO:     Epoch: 11
2023-01-04 07:44:17,892 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4274255077044169, 'Total loss': 0.4274255077044169} | train loss {'Reaction outcome loss': 0.48068257553529914, 'Total loss': 0.48068257553529914}
2023-01-04 07:44:17,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:17,892 INFO:     Epoch: 12
2023-01-04 07:44:19,497 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4050178746382395, 'Total loss': 0.4050178746382395} | train loss {'Reaction outcome loss': 0.4793613303884648, 'Total loss': 0.4793613303884648}
2023-01-04 07:44:19,497 INFO:     Found new best model at epoch 12
2023-01-04 07:44:19,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:19,498 INFO:     Epoch: 13
2023-01-04 07:44:21,127 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4348598778247833, 'Total loss': 0.4348598778247833} | train loss {'Reaction outcome loss': 0.4668756661450733, 'Total loss': 0.4668756661450733}
2023-01-04 07:44:21,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:21,129 INFO:     Epoch: 14
2023-01-04 07:44:22,755 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3937534103790919, 'Total loss': 0.3937534103790919} | train loss {'Reaction outcome loss': 0.45893337774306425, 'Total loss': 0.45893337774306425}
2023-01-04 07:44:22,755 INFO:     Found new best model at epoch 14
2023-01-04 07:44:22,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:22,756 INFO:     Epoch: 15
2023-01-04 07:44:24,385 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3919972320397695, 'Total loss': 0.3919972320397695} | train loss {'Reaction outcome loss': 0.45433838575474406, 'Total loss': 0.45433838575474406}
2023-01-04 07:44:24,386 INFO:     Found new best model at epoch 15
2023-01-04 07:44:24,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:24,386 INFO:     Epoch: 16
2023-01-04 07:44:25,953 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3960992515087128, 'Total loss': 0.3960992515087128} | train loss {'Reaction outcome loss': 0.4501593171794345, 'Total loss': 0.4501593171794345}
2023-01-04 07:44:25,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:25,953 INFO:     Epoch: 17
2023-01-04 07:44:27,528 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4207493980725606, 'Total loss': 0.4207493980725606} | train loss {'Reaction outcome loss': 0.4443987281900237, 'Total loss': 0.4443987281900237}
2023-01-04 07:44:27,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:27,529 INFO:     Epoch: 18
2023-01-04 07:44:29,146 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3943915049235026, 'Total loss': 0.3943915049235026} | train loss {'Reaction outcome loss': 0.44213925954291894, 'Total loss': 0.44213925954291894}
2023-01-04 07:44:29,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:29,146 INFO:     Epoch: 19
2023-01-04 07:44:30,772 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.407070588072141, 'Total loss': 0.407070588072141} | train loss {'Reaction outcome loss': 0.4392616314192613, 'Total loss': 0.4392616314192613}
2023-01-04 07:44:30,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:30,773 INFO:     Epoch: 20
2023-01-04 07:44:32,376 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4310434341430664, 'Total loss': 0.4310434341430664} | train loss {'Reaction outcome loss': 0.439867550905362, 'Total loss': 0.439867550905362}
2023-01-04 07:44:32,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:32,376 INFO:     Epoch: 21
2023-01-04 07:44:34,001 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3993064731359482, 'Total loss': 0.3993064731359482} | train loss {'Reaction outcome loss': 0.4298842896051887, 'Total loss': 0.4298842896051887}
2023-01-04 07:44:34,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:34,001 INFO:     Epoch: 22
2023-01-04 07:44:35,554 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3832689613103867, 'Total loss': 0.3832689613103867} | train loss {'Reaction outcome loss': 0.4237555345162695, 'Total loss': 0.4237555345162695}
2023-01-04 07:44:35,555 INFO:     Found new best model at epoch 22
2023-01-04 07:44:35,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:35,555 INFO:     Epoch: 23
2023-01-04 07:44:37,112 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39045928915341693, 'Total loss': 0.39045928915341693} | train loss {'Reaction outcome loss': 0.42244366275659506, 'Total loss': 0.42244366275659506}
2023-01-04 07:44:37,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:37,112 INFO:     Epoch: 24
2023-01-04 07:44:38,739 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36608998477458954, 'Total loss': 0.36608998477458954} | train loss {'Reaction outcome loss': 0.4201361197924268, 'Total loss': 0.4201361197924268}
2023-01-04 07:44:38,740 INFO:     Found new best model at epoch 24
2023-01-04 07:44:38,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:38,740 INFO:     Epoch: 25
2023-01-04 07:44:40,356 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3621068447828293, 'Total loss': 0.3621068447828293} | train loss {'Reaction outcome loss': 0.4186189266434614, 'Total loss': 0.4186189266434614}
2023-01-04 07:44:40,357 INFO:     Found new best model at epoch 25
2023-01-04 07:44:40,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:40,358 INFO:     Epoch: 26
2023-01-04 07:44:41,914 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3599077150225639, 'Total loss': 0.3599077150225639} | train loss {'Reaction outcome loss': 0.40872983305134636, 'Total loss': 0.40872983305134636}
2023-01-04 07:44:41,914 INFO:     Found new best model at epoch 26
2023-01-04 07:44:41,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:41,915 INFO:     Epoch: 27
2023-01-04 07:44:43,449 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3843684295813243, 'Total loss': 0.3843684295813243} | train loss {'Reaction outcome loss': 0.4085721263155636, 'Total loss': 0.4085721263155636}
2023-01-04 07:44:43,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:43,449 INFO:     Epoch: 28
2023-01-04 07:44:44,977 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3697702596584956, 'Total loss': 0.3697702596584956} | train loss {'Reaction outcome loss': 0.39929687304970685, 'Total loss': 0.39929687304970685}
2023-01-04 07:44:44,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:44,978 INFO:     Epoch: 29
2023-01-04 07:44:46,543 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3723324070374171, 'Total loss': 0.3723324070374171} | train loss {'Reaction outcome loss': 0.3946703454307483, 'Total loss': 0.3946703454307483}
2023-01-04 07:44:46,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:46,543 INFO:     Epoch: 30
2023-01-04 07:44:48,154 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.35561089317003886, 'Total loss': 0.35561089317003886} | train loss {'Reaction outcome loss': 0.39111436300943064, 'Total loss': 0.39111436300943064}
2023-01-04 07:44:48,155 INFO:     Found new best model at epoch 30
2023-01-04 07:44:48,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:48,155 INFO:     Epoch: 31
2023-01-04 07:44:49,770 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3531302640835444, 'Total loss': 0.3531302640835444} | train loss {'Reaction outcome loss': 0.3929643479810245, 'Total loss': 0.3929643479810245}
2023-01-04 07:44:49,770 INFO:     Found new best model at epoch 31
2023-01-04 07:44:49,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:49,771 INFO:     Epoch: 32
2023-01-04 07:44:51,387 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3446227014064789, 'Total loss': 0.3446227014064789} | train loss {'Reaction outcome loss': 0.39303551266557013, 'Total loss': 0.39303551266557013}
2023-01-04 07:44:51,388 INFO:     Found new best model at epoch 32
2023-01-04 07:44:51,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:51,389 INFO:     Epoch: 33
2023-01-04 07:44:52,950 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3717278440793355, 'Total loss': 0.3717278440793355} | train loss {'Reaction outcome loss': 0.385107997782525, 'Total loss': 0.385107997782525}
2023-01-04 07:44:52,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:52,950 INFO:     Epoch: 34
2023-01-04 07:44:54,444 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3649316449960073, 'Total loss': 0.3649316449960073} | train loss {'Reaction outcome loss': 0.3847529556386281, 'Total loss': 0.3847529556386281}
2023-01-04 07:44:54,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:54,444 INFO:     Epoch: 35
2023-01-04 07:44:56,030 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.33331931829452516, 'Total loss': 0.33331931829452516} | train loss {'Reaction outcome loss': 0.3919495366854539, 'Total loss': 0.3919495366854539}
2023-01-04 07:44:56,031 INFO:     Found new best model at epoch 35
2023-01-04 07:44:56,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:56,031 INFO:     Epoch: 36
2023-01-04 07:44:57,620 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3782515694697698, 'Total loss': 0.3782515694697698} | train loss {'Reaction outcome loss': 0.389639661822846, 'Total loss': 0.389639661822846}
2023-01-04 07:44:57,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:57,621 INFO:     Epoch: 37
2023-01-04 07:44:59,214 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.34822018146514894, 'Total loss': 0.34822018146514894} | train loss {'Reaction outcome loss': 0.3843616797735128, 'Total loss': 0.3843616797735128}
2023-01-04 07:44:59,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:44:59,214 INFO:     Epoch: 38
2023-01-04 07:45:00,808 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3688751031955083, 'Total loss': 0.3688751031955083} | train loss {'Reaction outcome loss': 0.3695050616686627, 'Total loss': 0.3695050616686627}
2023-01-04 07:45:00,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:00,808 INFO:     Epoch: 39
2023-01-04 07:45:02,365 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3236423820257187, 'Total loss': 0.3236423820257187} | train loss {'Reaction outcome loss': 0.36710955081777513, 'Total loss': 0.36710955081777513}
2023-01-04 07:45:02,365 INFO:     Found new best model at epoch 39
2023-01-04 07:45:02,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:02,366 INFO:     Epoch: 40
2023-01-04 07:45:03,889 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.33592241406440737, 'Total loss': 0.33592241406440737} | train loss {'Reaction outcome loss': 0.36138419277225353, 'Total loss': 0.36138419277225353}
2023-01-04 07:45:03,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:03,889 INFO:     Epoch: 41
2023-01-04 07:45:05,437 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3453452974557877, 'Total loss': 0.3453452974557877} | train loss {'Reaction outcome loss': 0.359532126568058, 'Total loss': 0.359532126568058}
2023-01-04 07:45:05,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:05,437 INFO:     Epoch: 42
2023-01-04 07:45:06,980 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3434391587972641, 'Total loss': 0.3434391587972641} | train loss {'Reaction outcome loss': 0.3774549075118873, 'Total loss': 0.3774549075118873}
2023-01-04 07:45:06,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:06,980 INFO:     Epoch: 43
2023-01-04 07:45:08,542 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3549358735481898, 'Total loss': 0.3549358735481898} | train loss {'Reaction outcome loss': 0.35990215200876846, 'Total loss': 0.35990215200876846}
2023-01-04 07:45:08,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:08,542 INFO:     Epoch: 44
2023-01-04 07:45:10,103 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36520863672097525, 'Total loss': 0.36520863672097525} | train loss {'Reaction outcome loss': 0.3832975137924802, 'Total loss': 0.3832975137924802}
2023-01-04 07:45:10,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:10,104 INFO:     Epoch: 45
2023-01-04 07:45:11,630 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36549995144208275, 'Total loss': 0.36549995144208275} | train loss {'Reaction outcome loss': 0.3850989217289548, 'Total loss': 0.3850989217289548}
2023-01-04 07:45:11,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:11,630 INFO:     Epoch: 46
2023-01-04 07:45:13,156 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.33219720448056855, 'Total loss': 0.33219720448056855} | train loss {'Reaction outcome loss': 0.3674986257261691, 'Total loss': 0.3674986257261691}
2023-01-04 07:45:13,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:13,157 INFO:     Epoch: 47
2023-01-04 07:45:14,705 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35916611552238464, 'Total loss': 0.35916611552238464} | train loss {'Reaction outcome loss': 0.3530181018176718, 'Total loss': 0.3530181018176718}
2023-01-04 07:45:14,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:14,706 INFO:     Epoch: 48
2023-01-04 07:45:16,266 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3463692178328832, 'Total loss': 0.3463692178328832} | train loss {'Reaction outcome loss': 0.3519889583888774, 'Total loss': 0.3519889583888774}
2023-01-04 07:45:16,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:16,267 INFO:     Epoch: 49
2023-01-04 07:45:17,829 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37888645033041635, 'Total loss': 0.37888645033041635} | train loss {'Reaction outcome loss': 0.35637808491246425, 'Total loss': 0.35637808491246425}
2023-01-04 07:45:17,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:17,829 INFO:     Epoch: 50
2023-01-04 07:45:19,409 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3511791462699572, 'Total loss': 0.3511791462699572} | train loss {'Reaction outcome loss': 0.37389107017762674, 'Total loss': 0.37389107017762674}
2023-01-04 07:45:19,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:19,409 INFO:     Epoch: 51
2023-01-04 07:45:20,940 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3400287995735804, 'Total loss': 0.3400287995735804} | train loss {'Reaction outcome loss': 0.35066312494640495, 'Total loss': 0.35066312494640495}
2023-01-04 07:45:20,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:20,940 INFO:     Epoch: 52
2023-01-04 07:45:22,478 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.33713634411493937, 'Total loss': 0.33713634411493937} | train loss {'Reaction outcome loss': 0.34374213472440623, 'Total loss': 0.34374213472440623}
2023-01-04 07:45:22,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:22,478 INFO:     Epoch: 53
2023-01-04 07:45:24,108 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3370238055785497, 'Total loss': 0.3370238055785497} | train loss {'Reaction outcome loss': 0.3378058196976781, 'Total loss': 0.3378058196976781}
2023-01-04 07:45:24,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:24,108 INFO:     Epoch: 54
2023-01-04 07:45:25,669 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3230191071828206, 'Total loss': 0.3230191071828206} | train loss {'Reaction outcome loss': 0.3356634307930253, 'Total loss': 0.3356634307930253}
2023-01-04 07:45:25,669 INFO:     Found new best model at epoch 54
2023-01-04 07:45:25,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:25,670 INFO:     Epoch: 55
2023-01-04 07:45:27,223 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3339645187060038, 'Total loss': 0.3339645187060038} | train loss {'Reaction outcome loss': 0.335202897224825, 'Total loss': 0.335202897224825}
2023-01-04 07:45:27,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:27,224 INFO:     Epoch: 56
2023-01-04 07:45:28,763 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3193327248096466, 'Total loss': 0.3193327248096466} | train loss {'Reaction outcome loss': 0.33463673622927803, 'Total loss': 0.33463673622927803}
2023-01-04 07:45:28,763 INFO:     Found new best model at epoch 56
2023-01-04 07:45:28,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:28,764 INFO:     Epoch: 57
2023-01-04 07:45:30,279 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.32033449212710063, 'Total loss': 0.32033449212710063} | train loss {'Reaction outcome loss': 0.33389347137763514, 'Total loss': 0.33389347137763514}
2023-01-04 07:45:30,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:30,279 INFO:     Epoch: 58
2023-01-04 07:45:31,813 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3159776215751966, 'Total loss': 0.3159776215751966} | train loss {'Reaction outcome loss': 0.3282390583333546, 'Total loss': 0.3282390583333546}
2023-01-04 07:45:31,813 INFO:     Found new best model at epoch 58
2023-01-04 07:45:31,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:31,813 INFO:     Epoch: 59
2023-01-04 07:45:33,369 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33612458904584247, 'Total loss': 0.33612458904584247} | train loss {'Reaction outcome loss': 0.3317720012712306, 'Total loss': 0.3317720012712306}
2023-01-04 07:45:33,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:33,370 INFO:     Epoch: 60
2023-01-04 07:45:34,955 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3283056030670802, 'Total loss': 0.3283056030670802} | train loss {'Reaction outcome loss': 0.3323801177945258, 'Total loss': 0.3323801177945258}
2023-01-04 07:45:34,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:34,956 INFO:     Epoch: 61
2023-01-04 07:45:36,539 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.33292600413163503, 'Total loss': 0.33292600413163503} | train loss {'Reaction outcome loss': 0.32905954164385365, 'Total loss': 0.32905954164385365}
2023-01-04 07:45:36,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:36,539 INFO:     Epoch: 62
2023-01-04 07:45:38,109 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.33676715691884357, 'Total loss': 0.33676715691884357} | train loss {'Reaction outcome loss': 0.3676441401568835, 'Total loss': 0.3676441401568835}
2023-01-04 07:45:38,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:38,110 INFO:     Epoch: 63
2023-01-04 07:45:39,628 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.32939223647117616, 'Total loss': 0.32939223647117616} | train loss {'Reaction outcome loss': 0.3274712082018833, 'Total loss': 0.3274712082018833}
2023-01-04 07:45:39,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:39,628 INFO:     Epoch: 64
2023-01-04 07:45:41,144 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3176379958788554, 'Total loss': 0.3176379958788554} | train loss {'Reaction outcome loss': 0.3221835341855826, 'Total loss': 0.3221835341855826}
2023-01-04 07:45:41,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:41,144 INFO:     Epoch: 65
2023-01-04 07:45:42,697 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.31914625962575277, 'Total loss': 0.31914625962575277} | train loss {'Reaction outcome loss': 0.3154007136949129, 'Total loss': 0.3154007136949129}
2023-01-04 07:45:42,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:42,697 INFO:     Epoch: 66
2023-01-04 07:45:44,243 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.34190253019332884, 'Total loss': 0.34190253019332884} | train loss {'Reaction outcome loss': 0.312703323954997, 'Total loss': 0.312703323954997}
2023-01-04 07:45:44,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:44,243 INFO:     Epoch: 67
2023-01-04 07:45:45,781 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.31745540301005043, 'Total loss': 0.31745540301005043} | train loss {'Reaction outcome loss': 0.31304472813085804, 'Total loss': 0.31304472813085804}
2023-01-04 07:45:45,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:45,782 INFO:     Epoch: 68
2023-01-04 07:45:47,328 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.31521380742390953, 'Total loss': 0.31521380742390953} | train loss {'Reaction outcome loss': 0.31564942345400027, 'Total loss': 0.31564942345400027}
2023-01-04 07:45:47,328 INFO:     Found new best model at epoch 68
2023-01-04 07:45:47,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:47,329 INFO:     Epoch: 69
2023-01-04 07:45:48,844 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.32209011216958366, 'Total loss': 0.32209011216958366} | train loss {'Reaction outcome loss': 0.3056175310866556, 'Total loss': 0.3056175310866556}
2023-01-04 07:45:48,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:48,844 INFO:     Epoch: 70
2023-01-04 07:45:50,361 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.33871989846229555, 'Total loss': 0.33871989846229555} | train loss {'Reaction outcome loss': 0.32390012130465196, 'Total loss': 0.32390012130465196}
2023-01-04 07:45:50,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:50,361 INFO:     Epoch: 71
2023-01-04 07:45:51,901 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3250910848379135, 'Total loss': 0.3250910848379135} | train loss {'Reaction outcome loss': 0.3375525195421516, 'Total loss': 0.3375525195421516}
2023-01-04 07:45:51,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:51,901 INFO:     Epoch: 72
2023-01-04 07:45:53,432 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35935471852620443, 'Total loss': 0.35935471852620443} | train loss {'Reaction outcome loss': 0.33303278079952375, 'Total loss': 0.33303278079952375}
2023-01-04 07:45:53,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:53,432 INFO:     Epoch: 73
2023-01-04 07:45:54,971 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.32289874404668806, 'Total loss': 0.32289874404668806} | train loss {'Reaction outcome loss': 0.3101278164498238, 'Total loss': 0.3101278164498238}
2023-01-04 07:45:54,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:54,971 INFO:     Epoch: 74
2023-01-04 07:45:56,505 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.30617553095022837, 'Total loss': 0.30617553095022837} | train loss {'Reaction outcome loss': 0.30520508241286315, 'Total loss': 0.30520508241286315}
2023-01-04 07:45:56,505 INFO:     Found new best model at epoch 74
2023-01-04 07:45:56,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:56,506 INFO:     Epoch: 75
2023-01-04 07:45:58,054 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3108219792445501, 'Total loss': 0.3108219792445501} | train loss {'Reaction outcome loss': 0.30357263078643143, 'Total loss': 0.30357263078643143}
2023-01-04 07:45:58,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:58,055 INFO:     Epoch: 76
2023-01-04 07:45:59,595 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3305048724015554, 'Total loss': 0.3305048724015554} | train loss {'Reaction outcome loss': 0.2998236118667368, 'Total loss': 0.2998236118667368}
2023-01-04 07:45:59,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:45:59,595 INFO:     Epoch: 77
2023-01-04 07:46:01,154 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3032965322335561, 'Total loss': 0.3032965322335561} | train loss {'Reaction outcome loss': 0.31830389031033585, 'Total loss': 0.31830389031033585}
2023-01-04 07:46:01,155 INFO:     Found new best model at epoch 77
2023-01-04 07:46:01,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:01,155 INFO:     Epoch: 78
2023-01-04 07:46:02,718 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3237506369749705, 'Total loss': 0.3237506369749705} | train loss {'Reaction outcome loss': 0.3200395152755622, 'Total loss': 0.3200395152755622}
2023-01-04 07:46:02,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:02,719 INFO:     Epoch: 79
2023-01-04 07:46:04,277 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.30616122906406723, 'Total loss': 0.30616122906406723} | train loss {'Reaction outcome loss': 0.3258407103383671, 'Total loss': 0.3258407103383671}
2023-01-04 07:46:04,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:04,278 INFO:     Epoch: 80
2023-01-04 07:46:05,811 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3086351901292801, 'Total loss': 0.3086351901292801} | train loss {'Reaction outcome loss': 0.30252385418862104, 'Total loss': 0.30252385418862104}
2023-01-04 07:46:05,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:05,811 INFO:     Epoch: 81
2023-01-04 07:46:07,339 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3136553366978963, 'Total loss': 0.3136553366978963} | train loss {'Reaction outcome loss': 0.2985101200410745, 'Total loss': 0.2985101200410745}
2023-01-04 07:46:07,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:07,339 INFO:     Epoch: 82
2023-01-04 07:46:08,895 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3193444112936656, 'Total loss': 0.3193444112936656} | train loss {'Reaction outcome loss': 0.2962153009712642, 'Total loss': 0.2962153009712642}
2023-01-04 07:46:08,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:08,895 INFO:     Epoch: 83
2023-01-04 07:46:10,460 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3152384176850319, 'Total loss': 0.3152384176850319} | train loss {'Reaction outcome loss': 0.2954948006140446, 'Total loss': 0.2954948006140446}
2023-01-04 07:46:10,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:10,460 INFO:     Epoch: 84
2023-01-04 07:46:12,025 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3360993335644404, 'Total loss': 0.3360993335644404} | train loss {'Reaction outcome loss': 0.29411808555216895, 'Total loss': 0.29411808555216895}
2023-01-04 07:46:12,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:12,025 INFO:     Epoch: 85
2023-01-04 07:46:13,579 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3032384286324183, 'Total loss': 0.3032384286324183} | train loss {'Reaction outcome loss': 0.3478315766694942, 'Total loss': 0.3478315766694942}
2023-01-04 07:46:13,579 INFO:     Found new best model at epoch 85
2023-01-04 07:46:13,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:13,580 INFO:     Epoch: 86
2023-01-04 07:46:15,088 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.2985262582699458, 'Total loss': 0.2985262582699458} | train loss {'Reaction outcome loss': 0.2939181347863506, 'Total loss': 0.2939181347863506}
2023-01-04 07:46:15,088 INFO:     Found new best model at epoch 86
2023-01-04 07:46:15,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:15,089 INFO:     Epoch: 87
2023-01-04 07:46:16,616 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3229884554942449, 'Total loss': 0.3229884554942449} | train loss {'Reaction outcome loss': 0.2878548562440446, 'Total loss': 0.2878548562440446}
2023-01-04 07:46:16,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:16,617 INFO:     Epoch: 88
2023-01-04 07:46:18,169 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3145759324232737, 'Total loss': 0.3145759324232737} | train loss {'Reaction outcome loss': 0.2944170842082172, 'Total loss': 0.2944170842082172}
2023-01-04 07:46:18,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:18,170 INFO:     Epoch: 89
2023-01-04 07:46:19,713 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3207637349764506, 'Total loss': 0.3207637349764506} | train loss {'Reaction outcome loss': 0.31267207442917844, 'Total loss': 0.31267207442917844}
2023-01-04 07:46:19,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:19,714 INFO:     Epoch: 90
2023-01-04 07:46:21,254 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3395533581574758, 'Total loss': 0.3395533581574758} | train loss {'Reaction outcome loss': 0.29903890599877964, 'Total loss': 0.29903890599877964}
2023-01-04 07:46:21,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:21,255 INFO:     Epoch: 91
2023-01-04 07:46:22,816 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3126834144194921, 'Total loss': 0.3126834144194921} | train loss {'Reaction outcome loss': 0.2910930297086083, 'Total loss': 0.2910930297086083}
2023-01-04 07:46:22,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:22,817 INFO:     Epoch: 92
2023-01-04 07:46:24,335 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.31852687398592633, 'Total loss': 0.31852687398592633} | train loss {'Reaction outcome loss': 0.288411100084583, 'Total loss': 0.288411100084583}
2023-01-04 07:46:24,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:24,336 INFO:     Epoch: 93
2023-01-04 07:46:25,865 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3405351459980011, 'Total loss': 0.3405351459980011} | train loss {'Reaction outcome loss': 0.3040703439699533, 'Total loss': 0.3040703439699533}
2023-01-04 07:46:25,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:25,865 INFO:     Epoch: 94
2023-01-04 07:46:27,442 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.32601639529069265, 'Total loss': 0.32601639529069265} | train loss {'Reaction outcome loss': 0.2902712755013203, 'Total loss': 0.2902712755013203}
2023-01-04 07:46:27,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:27,443 INFO:     Epoch: 95
2023-01-04 07:46:29,009 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3237319737672806, 'Total loss': 0.3237319737672806} | train loss {'Reaction outcome loss': 0.2859548538981471, 'Total loss': 0.2859548538981471}
2023-01-04 07:46:29,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:29,011 INFO:     Epoch: 96
2023-01-04 07:46:30,555 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.31826186130444206, 'Total loss': 0.31826186130444206} | train loss {'Reaction outcome loss': 0.28170753145536437, 'Total loss': 0.28170753145536437}
2023-01-04 07:46:30,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:30,555 INFO:     Epoch: 97
2023-01-04 07:46:32,129 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.33178122142950695, 'Total loss': 0.33178122142950695} | train loss {'Reaction outcome loss': 0.28404602678357693, 'Total loss': 0.28404602678357693}
2023-01-04 07:46:32,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:32,129 INFO:     Epoch: 98
2023-01-04 07:46:33,664 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.31462471981843315, 'Total loss': 0.31462471981843315} | train loss {'Reaction outcome loss': 0.28568722356104065, 'Total loss': 0.28568722356104065}
2023-01-04 07:46:33,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 07:46:33,664 INFO:     Epoch: 99
2023-01-04 07:46:35,194 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3275610109170278, 'Total loss': 0.3275610109170278} | train loss {'Reaction outcome loss': 0.2896011814043142, 'Total loss': 0.2896011814043142}
2023-01-04 07:46:35,195 INFO:     Best model found after epoch 87 of 100.
2023-01-04 07:46:35,195 INFO:   Done with stage: TRAINING
2023-01-04 07:46:35,195 INFO:   Starting stage: EVALUATION
2023-01-04 07:46:35,321 INFO:   Done with stage: EVALUATION
2023-01-04 07:46:35,322 INFO: Done with stage: RUNNING SPLITS
2023-01-04 07:46:35,322 INFO: Starting stage: COMPUTE METRICS
2023-01-04 07:46:36,496 INFO: Done with stage: COMPUTE METRICS
2023-01-04 07:46:36,496 INFO: Starting stage: EXPORT RESULTS
2023-01-04 07:46:36,513 INFO:   Final results averaged over 50 folds: 
2023-01-04 07:46:36,517 INFO:   
                     mae  neg-spearman     rmse  spearman
dataset_split                                           
test           0.207484           NaN  0.34764       NaN
2023-01-04 07:46:38,206 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-04 07:46:38,217 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-04 07:46:38,219 DEBUG:   interactive is False
2023-01-04 07:46:38,219 DEBUG:   platform is linux
2023-01-04 07:46:38,219 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-04 07:46:38,397 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-04 07:46:38,401 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-04 07:46:38,845 DEBUG:   Loaded backend agg version unknown.
2023-01-04 07:46:38,847 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 07:46:38,847 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,847 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,847 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,847 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,847 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,847 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 07:46:38,847 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,848 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 07:46:38,849 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,850 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,850 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,850 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 07:46:38,850 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,850 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 07:46:38,886 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 07:46:38,887 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,888 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 07:46:38,889 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,889 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 07:46:38,898 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 07:46:38,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 07:46:38,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,900 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 07:46:38,901 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 07:46:38,901 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 07:46:38,901 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 07:46:39,199 INFO: Done with stage: EXPORT RESULTS
2023-01-04 07:46:39,200 INFO: Starting stage: SAVE MODEL
2023-01-04 07:46:39,269 INFO: Done with stage: SAVE MODEL
2023-01-04 07:46:39,269 INFO: Wall time for program:  7803.98 seconds
