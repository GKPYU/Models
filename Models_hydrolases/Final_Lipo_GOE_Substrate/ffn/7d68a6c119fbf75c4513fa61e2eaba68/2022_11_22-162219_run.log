2022-11-22 20:09:37,978 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/7d68a6c119fbf75c4513fa61e2eaba68/2022_11_22-162219",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "jtvae",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-22 20:09:37,989 INFO: Starting stage: BUILD FEATURIZERS
2022-11-22 20:09:37,995 INFO:   Creating esm representation model
2022-11-22 20:09:37,995 INFO:   Done esm representation model
2022-11-22 20:09:37,996 INFO: Done with stage: BUILD FEATURIZERS
2022-11-22 20:09:37,996 INFO: Starting stage: BUILDING DATASET
2022-11-22 20:09:38,066 INFO: Done with stage: BUILDING DATASET
2022-11-22 20:09:38,066 INFO: Starting stage: FEATURIZING DATA
2022-11-22 20:09:38,066 INFO:   Featurizing proteins
2022-11-22 20:09:38,068 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-22 20:09:38,085 INFO:   Loaded feature cache of size 204
2022-11-22 20:09:38,087 INFO:   Starting to pool ESM Embeddings
2022-11-22 20:09:38,196 INFO:   Featurizing molecules
2022-11-22 20:09:38,209 INFO: Done with stage: FEATURIZING DATA
2022-11-22 20:09:38,209 INFO: Starting stage: RUNNING SPLITS
2022-11-22 20:09:38,218 INFO:   Leaving out SEQ value Fold_0
2022-11-22 20:09:38,233 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-22 20:09:38,233 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:09:38,934 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:09:38,934 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:09:39,002 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:09:39,003 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:09:39,003 INFO:     No hyperparam tuning for this model
2022-11-22 20:09:39,003 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:09:39,003 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:09:39,004 INFO:     None feature selector for col prot
2022-11-22 20:09:39,004 INFO:     None feature selector for col prot
2022-11-22 20:09:39,004 INFO:     None feature selector for col prot
2022-11-22 20:09:39,005 INFO:     None feature selector for col chem
2022-11-22 20:09:39,005 INFO:     None feature selector for col chem
2022-11-22 20:09:39,005 INFO:     None feature selector for col chem
2022-11-22 20:09:39,005 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:09:39,005 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:09:39,006 INFO:     Number of params in model 126091
2022-11-22 20:09:39,007 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:09:39,007 INFO:   Starting stage: TRAINING
2022-11-22 20:09:40,663 INFO:     Val loss before train {'Reaction outcome loss': 1.0038483489391417, 'Total loss': 1.0038483489391417}
2022-11-22 20:09:40,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:40,664 INFO:     Epoch: 0
2022-11-22 20:09:41,426 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.852923818105875, 'Total loss': 0.852923818105875} | train loss {'Reaction outcome loss': 0.8704765906832257, 'Total loss': 0.8704765906832257}
2022-11-22 20:09:41,427 INFO:     Found new best model at epoch 0
2022-11-22 20:09:41,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:41,428 INFO:     Epoch: 1
2022-11-22 20:09:42,193 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8198613378890726, 'Total loss': 0.8198613378890726} | train loss {'Reaction outcome loss': 0.8326516607012905, 'Total loss': 0.8326516607012905}
2022-11-22 20:09:42,193 INFO:     Found new best model at epoch 1
2022-11-22 20:09:42,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:42,194 INFO:     Epoch: 2
2022-11-22 20:09:42,957 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.846328294554422, 'Total loss': 0.846328294554422} | train loss {'Reaction outcome loss': 0.8161425280277846, 'Total loss': 0.8161425280277846}
2022-11-22 20:09:42,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:42,958 INFO:     Epoch: 3
2022-11-22 20:09:43,716 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.830221181692079, 'Total loss': 0.830221181692079} | train loss {'Reaction outcome loss': 0.8117415908662999, 'Total loss': 0.8117415908662999}
2022-11-22 20:09:43,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:43,717 INFO:     Epoch: 4
2022-11-22 20:09:44,456 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.832108105337897, 'Total loss': 0.832108105337897} | train loss {'Reaction outcome loss': 0.8075733271534326, 'Total loss': 0.8075733271534326}
2022-11-22 20:09:44,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:44,457 INFO:     Epoch: 5
2022-11-22 20:09:45,178 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8127490593943485, 'Total loss': 0.8127490593943485} | train loss {'Reaction outcome loss': 0.7992748731716735, 'Total loss': 0.7992748731716735}
2022-11-22 20:09:45,178 INFO:     Found new best model at epoch 5
2022-11-22 20:09:45,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:45,179 INFO:     Epoch: 6
2022-11-22 20:09:45,951 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8194388830384542, 'Total loss': 0.8194388830384542} | train loss {'Reaction outcome loss': 0.7960365197209062, 'Total loss': 0.7960365197209062}
2022-11-22 20:09:45,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:45,952 INFO:     Epoch: 7
2022-11-22 20:09:46,723 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8443553683369659, 'Total loss': 0.8443553683369659} | train loss {'Reaction outcome loss': 0.7931660478476619, 'Total loss': 0.7931660478476619}
2022-11-22 20:09:46,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:46,723 INFO:     Epoch: 8
2022-11-22 20:09:47,448 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8254306399545004, 'Total loss': 0.8254306399545004} | train loss {'Reaction outcome loss': 0.7907272302469269, 'Total loss': 0.7907272302469269}
2022-11-22 20:09:47,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:47,449 INFO:     Epoch: 9
2022-11-22 20:09:48,208 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8225884832615076, 'Total loss': 0.8225884832615076} | train loss {'Reaction outcome loss': 0.7950840190541549, 'Total loss': 0.7950840190541549}
2022-11-22 20:09:48,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:48,208 INFO:     Epoch: 10
2022-11-22 20:09:48,952 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8348797975584518, 'Total loss': 0.8348797975584518} | train loss {'Reaction outcome loss': 0.7882315373567285, 'Total loss': 0.7882315373567285}
2022-11-22 20:09:48,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:48,953 INFO:     Epoch: 11
2022-11-22 20:09:49,706 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.816960408244022, 'Total loss': 0.816960408244022} | train loss {'Reaction outcome loss': 0.793264916685761, 'Total loss': 0.793264916685761}
2022-11-22 20:09:49,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:49,706 INFO:     Epoch: 12
2022-11-22 20:09:50,426 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8169682164524876, 'Total loss': 0.8169682164524876} | train loss {'Reaction outcome loss': 0.7890732958912849, 'Total loss': 0.7890732958912849}
2022-11-22 20:09:50,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:50,426 INFO:     Epoch: 13
2022-11-22 20:09:51,192 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8322854187599448, 'Total loss': 0.8322854187599448} | train loss {'Reaction outcome loss': 0.7928508622724502, 'Total loss': 0.7928508622724502}
2022-11-22 20:09:51,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:51,192 INFO:     Epoch: 14
2022-11-22 20:09:51,979 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8212588921535847, 'Total loss': 0.8212588921535847} | train loss {'Reaction outcome loss': 0.7907160916289345, 'Total loss': 0.7907160916289345}
2022-11-22 20:09:51,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:51,980 INFO:     Epoch: 15
2022-11-22 20:09:52,738 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8016649526219035, 'Total loss': 0.8016649526219035} | train loss {'Reaction outcome loss': 0.7882472783571384, 'Total loss': 0.7882472783571384}
2022-11-22 20:09:52,738 INFO:     Found new best model at epoch 15
2022-11-22 20:09:52,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:52,739 INFO:     Epoch: 16
2022-11-22 20:09:53,483 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8366427553254504, 'Total loss': 0.8366427553254504} | train loss {'Reaction outcome loss': 0.7892491828467025, 'Total loss': 0.7892491828467025}
2022-11-22 20:09:53,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:53,483 INFO:     Epoch: 17
2022-11-22 20:09:54,217 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8072856221088144, 'Total loss': 0.8072856221088144} | train loss {'Reaction outcome loss': 0.7916448442418067, 'Total loss': 0.7916448442418067}
2022-11-22 20:09:54,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:54,217 INFO:     Epoch: 18
2022-11-22 20:09:54,977 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8256628305413002, 'Total loss': 0.8256628305413002} | train loss {'Reaction outcome loss': 0.7882670905502116, 'Total loss': 0.7882670905502116}
2022-11-22 20:09:54,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:54,977 INFO:     Epoch: 19
2022-11-22 20:09:55,729 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8246920441472253, 'Total loss': 0.8246920441472253} | train loss {'Reaction outcome loss': 0.782505636698887, 'Total loss': 0.782505636698887}
2022-11-22 20:09:55,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:55,730 INFO:     Epoch: 20
2022-11-22 20:09:56,497 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8316418951333955, 'Total loss': 0.8316418951333955} | train loss {'Reaction outcome loss': 0.7893650789485603, 'Total loss': 0.7893650789485603}
2022-11-22 20:09:56,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:56,498 INFO:     Epoch: 21
2022-11-22 20:09:57,286 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8178314289381338, 'Total loss': 0.8178314289381338} | train loss {'Reaction outcome loss': 0.7921771650187305, 'Total loss': 0.7921771650187305}
2022-11-22 20:09:57,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:57,287 INFO:     Epoch: 22
2022-11-22 20:09:58,019 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8064831938854483, 'Total loss': 0.8064831938854483} | train loss {'Reaction outcome loss': 0.7852295213302628, 'Total loss': 0.7852295213302628}
2022-11-22 20:09:58,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:58,019 INFO:     Epoch: 23
2022-11-22 20:09:58,760 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.821863821772642, 'Total loss': 0.821863821772642} | train loss {'Reaction outcome loss': 0.7877556576592023, 'Total loss': 0.7877556576592023}
2022-11-22 20:09:58,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:58,760 INFO:     Epoch: 24
2022-11-22 20:09:59,495 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8073091707950415, 'Total loss': 0.8073091707950415} | train loss {'Reaction outcome loss': 0.7868849780471598, 'Total loss': 0.7868849780471598}
2022-11-22 20:09:59,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:09:59,496 INFO:     Epoch: 25
2022-11-22 20:10:00,214 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8267934336218723, 'Total loss': 0.8267934336218723} | train loss {'Reaction outcome loss': 0.7854535450212291, 'Total loss': 0.7854535450212291}
2022-11-22 20:10:00,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:00,214 INFO:     Epoch: 26
2022-11-22 20:10:00,944 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8146915976391282, 'Total loss': 0.8146915976391282} | train loss {'Reaction outcome loss': 0.7852644146588005, 'Total loss': 0.7852644146588005}
2022-11-22 20:10:00,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:00,945 INFO:     Epoch: 27
2022-11-22 20:10:01,711 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8064906250598819, 'Total loss': 0.8064906250598819} | train loss {'Reaction outcome loss': 0.7852991716783555, 'Total loss': 0.7852991716783555}
2022-11-22 20:10:01,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:01,711 INFO:     Epoch: 28
2022-11-22 20:10:02,435 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8106300588264022, 'Total loss': 0.8106300588264022} | train loss {'Reaction outcome loss': 0.7810785130399173, 'Total loss': 0.7810785130399173}
2022-11-22 20:10:02,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:02,435 INFO:     Epoch: 29
2022-11-22 20:10:03,155 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7994572118271229, 'Total loss': 0.7994572118271229} | train loss {'Reaction outcome loss': 0.7843806748507453, 'Total loss': 0.7843806748507453}
2022-11-22 20:10:03,155 INFO:     Found new best model at epoch 29
2022-11-22 20:10:03,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:03,156 INFO:     Epoch: 30
2022-11-22 20:10:03,871 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8070882045945456, 'Total loss': 0.8070882045945456} | train loss {'Reaction outcome loss': 0.780819946136631, 'Total loss': 0.780819946136631}
2022-11-22 20:10:03,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:03,872 INFO:     Epoch: 31
2022-11-22 20:10:04,611 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8280863685663357, 'Total loss': 0.8280863685663357} | train loss {'Reaction outcome loss': 0.7802001434515734, 'Total loss': 0.7802001434515734}
2022-11-22 20:10:04,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:04,612 INFO:     Epoch: 32
2022-11-22 20:10:05,354 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8260574645774309, 'Total loss': 0.8260574645774309} | train loss {'Reaction outcome loss': 0.7804573846400761, 'Total loss': 0.7804573846400761}
2022-11-22 20:10:05,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:05,354 INFO:     Epoch: 33
2022-11-22 20:10:06,128 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8676852597746738, 'Total loss': 0.8676852597746738} | train loss {'Reaction outcome loss': 0.780275760737599, 'Total loss': 0.780275760737599}
2022-11-22 20:10:06,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:06,128 INFO:     Epoch: 34
2022-11-22 20:10:06,867 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8029222072556962, 'Total loss': 0.8029222072556962} | train loss {'Reaction outcome loss': 0.7839331333754492, 'Total loss': 0.7839331333754492}
2022-11-22 20:10:06,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:06,867 INFO:     Epoch: 35
2022-11-22 20:10:07,600 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8210161037223284, 'Total loss': 0.8210161037223284} | train loss {'Reaction outcome loss': 0.7821622090261491, 'Total loss': 0.7821622090261491}
2022-11-22 20:10:07,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:07,600 INFO:     Epoch: 36
2022-11-22 20:10:08,351 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8013737485852352, 'Total loss': 0.8013737485852352} | train loss {'Reaction outcome loss': 0.7812464161485922, 'Total loss': 0.7812464161485922}
2022-11-22 20:10:08,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:08,351 INFO:     Epoch: 37
2022-11-22 20:10:09,115 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8114245298296906, 'Total loss': 0.8114245298296906} | train loss {'Reaction outcome loss': 0.7769585147988601, 'Total loss': 0.7769585147988601}
2022-11-22 20:10:09,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:09,115 INFO:     Epoch: 38
2022-11-22 20:10:09,812 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8200780492882396, 'Total loss': 0.8200780492882396} | train loss {'Reaction outcome loss': 0.7759717172775112, 'Total loss': 0.7759717172775112}
2022-11-22 20:10:09,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:09,813 INFO:     Epoch: 39
2022-11-22 20:10:10,569 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8042849489422732, 'Total loss': 0.8042849489422732} | train loss {'Reaction outcome loss': 0.7791720782635642, 'Total loss': 0.7791720782635642}
2022-11-22 20:10:10,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:10,569 INFO:     Epoch: 40
2022-11-22 20:10:11,335 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8139955623205318, 'Total loss': 0.8139955623205318} | train loss {'Reaction outcome loss': 0.7789758578187129, 'Total loss': 0.7789758578187129}
2022-11-22 20:10:11,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:11,337 INFO:     Epoch: 41
2022-11-22 20:10:12,072 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8004680296709371, 'Total loss': 0.8004680296709371} | train loss {'Reaction outcome loss': 0.7827539623516505, 'Total loss': 0.7827539623516505}
2022-11-22 20:10:12,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:12,072 INFO:     Epoch: 42
2022-11-22 20:10:12,831 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8032658093197401, 'Total loss': 0.8032658093197401} | train loss {'Reaction outcome loss': 0.7748489841574528, 'Total loss': 0.7748489841574528}
2022-11-22 20:10:12,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:12,831 INFO:     Epoch: 43
2022-11-22 20:10:13,614 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8115480410498243, 'Total loss': 0.8115480410498243} | train loss {'Reaction outcome loss': 0.7735144194276606, 'Total loss': 0.7735144194276606}
2022-11-22 20:10:13,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:13,614 INFO:     Epoch: 44
2022-11-22 20:10:14,341 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8042165151862211, 'Total loss': 0.8042165151862211} | train loss {'Reaction outcome loss': 0.7731493332835494, 'Total loss': 0.7731493332835494}
2022-11-22 20:10:14,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:14,342 INFO:     Epoch: 45
2022-11-22 20:10:15,053 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.812373734490816, 'Total loss': 0.812373734490816} | train loss {'Reaction outcome loss': 0.7764911305953245, 'Total loss': 0.7764911305953245}
2022-11-22 20:10:15,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:15,053 INFO:     Epoch: 46
2022-11-22 20:10:15,777 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8099063295264577, 'Total loss': 0.8099063295264577} | train loss {'Reaction outcome loss': 0.77107727271123, 'Total loss': 0.77107727271123}
2022-11-22 20:10:15,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:15,777 INFO:     Epoch: 47
2022-11-22 20:10:16,519 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8048450122045916, 'Total loss': 0.8048450122045916} | train loss {'Reaction outcome loss': 0.7814205011627713, 'Total loss': 0.7814205011627713}
2022-11-22 20:10:16,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:16,519 INFO:     Epoch: 48
2022-11-22 20:10:17,264 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8085705436939417, 'Total loss': 0.8085705436939417} | train loss {'Reaction outcome loss': 0.775327412686387, 'Total loss': 0.775327412686387}
2022-11-22 20:10:17,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:17,264 INFO:     Epoch: 49
2022-11-22 20:10:17,977 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8425359213074972, 'Total loss': 0.8425359213074972} | train loss {'Reaction outcome loss': 0.7722835960935374, 'Total loss': 0.7722835960935374}
2022-11-22 20:10:17,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:17,978 INFO:     Epoch: 50
2022-11-22 20:10:18,696 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.803521137597949, 'Total loss': 0.803521137597949} | train loss {'Reaction outcome loss': 0.7732025404445461, 'Total loss': 0.7732025404445461}
2022-11-22 20:10:18,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:18,696 INFO:     Epoch: 51
2022-11-22 20:10:19,398 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8295397065406622, 'Total loss': 0.8295397065406622} | train loss {'Reaction outcome loss': 0.77333814650774, 'Total loss': 0.77333814650774}
2022-11-22 20:10:19,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:19,398 INFO:     Epoch: 52
2022-11-22 20:10:20,109 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8016419985959696, 'Total loss': 0.8016419985959696} | train loss {'Reaction outcome loss': 0.7762361436349446, 'Total loss': 0.7762361436349446}
2022-11-22 20:10:20,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:20,110 INFO:     Epoch: 53
2022-11-22 20:10:20,844 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.836433375990668, 'Total loss': 0.836433375990668} | train loss {'Reaction outcome loss': 0.7742713551785125, 'Total loss': 0.7742713551785125}
2022-11-22 20:10:20,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:20,845 INFO:     Epoch: 54
2022-11-22 20:10:21,601 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7897941962231038, 'Total loss': 0.7897941962231038} | train loss {'Reaction outcome loss': 0.7753769068932924, 'Total loss': 0.7753769068932924}
2022-11-22 20:10:21,601 INFO:     Found new best model at epoch 54
2022-11-22 20:10:21,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:21,602 INFO:     Epoch: 55
2022-11-22 20:10:22,333 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.797819830650507, 'Total loss': 0.797819830650507} | train loss {'Reaction outcome loss': 0.7722783058148915, 'Total loss': 0.7722783058148915}
2022-11-22 20:10:22,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:22,334 INFO:     Epoch: 56
2022-11-22 20:10:23,094 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7990329605202342, 'Total loss': 0.7990329605202342} | train loss {'Reaction outcome loss': 0.769650180564552, 'Total loss': 0.769650180564552}
2022-11-22 20:10:23,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:23,094 INFO:     Epoch: 57
2022-11-22 20:10:23,801 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7964786041614621, 'Total loss': 0.7964786041614621} | train loss {'Reaction outcome loss': 0.7662984160859077, 'Total loss': 0.7662984160859077}
2022-11-22 20:10:23,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:23,801 INFO:     Epoch: 58
2022-11-22 20:10:24,561 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8117233923701352, 'Total loss': 0.8117233923701352} | train loss {'Reaction outcome loss': 0.7681374332455339, 'Total loss': 0.7681374332455339}
2022-11-22 20:10:24,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:24,561 INFO:     Epoch: 59
2022-11-22 20:10:25,314 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8018867553666581, 'Total loss': 0.8018867553666581} | train loss {'Reaction outcome loss': 0.7686478289180114, 'Total loss': 0.7686478289180114}
2022-11-22 20:10:25,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:25,314 INFO:     Epoch: 60
2022-11-22 20:10:26,088 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7854524705299112, 'Total loss': 0.7854524705299112} | train loss {'Reaction outcome loss': 0.7649961349661233, 'Total loss': 0.7649961349661233}
2022-11-22 20:10:26,088 INFO:     Found new best model at epoch 60
2022-11-22 20:10:26,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:26,089 INFO:     Epoch: 61
2022-11-22 20:10:26,815 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7840231047120205, 'Total loss': 0.7840231047120205} | train loss {'Reaction outcome loss': 0.7730078113372209, 'Total loss': 0.7730078113372209}
2022-11-22 20:10:26,815 INFO:     Found new best model at epoch 61
2022-11-22 20:10:26,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:26,816 INFO:     Epoch: 62
2022-11-22 20:10:27,546 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7990359587724819, 'Total loss': 0.7990359587724819} | train loss {'Reaction outcome loss': 0.760879399590805, 'Total loss': 0.760879399590805}
2022-11-22 20:10:27,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:27,546 INFO:     Epoch: 63
2022-11-22 20:10:28,280 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7984950597896132, 'Total loss': 0.7984950597896132} | train loss {'Reaction outcome loss': 0.7609304366175269, 'Total loss': 0.7609304366175269}
2022-11-22 20:10:28,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:28,280 INFO:     Epoch: 64
2022-11-22 20:10:29,011 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8276247188102367, 'Total loss': 0.8276247188102367} | train loss {'Reaction outcome loss': 0.7634019394878482, 'Total loss': 0.7634019394878482}
2022-11-22 20:10:29,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:29,012 INFO:     Epoch: 65
2022-11-22 20:10:29,728 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7859164240748383, 'Total loss': 0.7859164240748383} | train loss {'Reaction outcome loss': 0.761741086718489, 'Total loss': 0.761741086718489}
2022-11-22 20:10:29,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:29,728 INFO:     Epoch: 66
2022-11-22 20:10:30,467 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7736501367979272, 'Total loss': 0.7736501367979272} | train loss {'Reaction outcome loss': 0.7642036726484533, 'Total loss': 0.7642036726484533}
2022-11-22 20:10:30,468 INFO:     Found new best model at epoch 66
2022-11-22 20:10:30,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:30,469 INFO:     Epoch: 67
2022-11-22 20:10:31,239 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7836620343285937, 'Total loss': 0.7836620343285937} | train loss {'Reaction outcome loss': 0.7531517316572002, 'Total loss': 0.7531517316572002}
2022-11-22 20:10:31,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:31,239 INFO:     Epoch: 68
2022-11-22 20:10:31,954 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8056631739749465, 'Total loss': 0.8056631739749465} | train loss {'Reaction outcome loss': 0.7558952595611088, 'Total loss': 0.7558952595611088}
2022-11-22 20:10:31,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:31,954 INFO:     Epoch: 69
2022-11-22 20:10:32,726 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7929354455581931, 'Total loss': 0.7929354455581931} | train loss {'Reaction outcome loss': 0.7506190901164149, 'Total loss': 0.7506190901164149}
2022-11-22 20:10:32,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:32,727 INFO:     Epoch: 70
2022-11-22 20:10:33,458 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8009493614352027, 'Total loss': 0.8009493614352027} | train loss {'Reaction outcome loss': 0.7523949083368309, 'Total loss': 0.7523949083368309}
2022-11-22 20:10:33,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:33,459 INFO:     Epoch: 71
2022-11-22 20:10:34,211 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7870329867961795, 'Total loss': 0.7870329867961795} | train loss {'Reaction outcome loss': 0.7481727711245661, 'Total loss': 0.7481727711245661}
2022-11-22 20:10:34,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:34,211 INFO:     Epoch: 72
2022-11-22 20:10:34,992 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7712276480918707, 'Total loss': 0.7712276480918707} | train loss {'Reaction outcome loss': 0.7462220380052191, 'Total loss': 0.7462220380052191}
2022-11-22 20:10:34,992 INFO:     Found new best model at epoch 72
2022-11-22 20:10:34,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:34,993 INFO:     Epoch: 73
2022-11-22 20:10:35,686 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8317725457424341, 'Total loss': 0.8317725457424341} | train loss {'Reaction outcome loss': 0.7515073516329781, 'Total loss': 0.7515073516329781}
2022-11-22 20:10:35,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:35,686 INFO:     Epoch: 74
2022-11-22 20:10:36,430 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7676447491313136, 'Total loss': 0.7676447491313136} | train loss {'Reaction outcome loss': 0.7449282146379596, 'Total loss': 0.7449282146379596}
2022-11-22 20:10:36,430 INFO:     Found new best model at epoch 74
2022-11-22 20:10:36,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:36,431 INFO:     Epoch: 75
2022-11-22 20:10:37,209 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7892543853715409, 'Total loss': 0.7892543853715409} | train loss {'Reaction outcome loss': 0.7400842824431716, 'Total loss': 0.7400842824431716}
2022-11-22 20:10:37,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:37,209 INFO:     Epoch: 76
2022-11-22 20:10:37,960 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7695963354997857, 'Total loss': 0.7695963354997857} | train loss {'Reaction outcome loss': 0.7376972911421393, 'Total loss': 0.7376972911421393}
2022-11-22 20:10:37,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:37,960 INFO:     Epoch: 77
2022-11-22 20:10:38,718 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7759633022685384, 'Total loss': 0.7759633022685384} | train loss {'Reaction outcome loss': 0.7422818943369583, 'Total loss': 0.7422818943369583}
2022-11-22 20:10:38,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:38,719 INFO:     Epoch: 78
2022-11-22 20:10:39,487 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7534396925637888, 'Total loss': 0.7534396925637888} | train loss {'Reaction outcome loss': 0.7362984076875155, 'Total loss': 0.7362984076875155}
2022-11-22 20:10:39,487 INFO:     Found new best model at epoch 78
2022-11-22 20:10:39,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:39,488 INFO:     Epoch: 79
2022-11-22 20:10:40,262 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8024722102076508, 'Total loss': 0.8024722102076508} | train loss {'Reaction outcome loss': 0.7317194038482963, 'Total loss': 0.7317194038482963}
2022-11-22 20:10:40,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:40,263 INFO:     Epoch: 80
2022-11-22 20:10:41,075 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7724301274432692, 'Total loss': 0.7724301274432692} | train loss {'Reaction outcome loss': 0.7339503757777761, 'Total loss': 0.7339503757777761}
2022-11-22 20:10:41,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:41,076 INFO:     Epoch: 81
2022-11-22 20:10:41,837 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7839065138683763, 'Total loss': 0.7839065138683763} | train loss {'Reaction outcome loss': 0.7318139989845088, 'Total loss': 0.7318139989845088}
2022-11-22 20:10:41,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:41,838 INFO:     Epoch: 82
2022-11-22 20:10:42,585 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7803488713364268, 'Total loss': 0.7803488713364268} | train loss {'Reaction outcome loss': 0.7286626733839512, 'Total loss': 0.7286626733839512}
2022-11-22 20:10:42,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:42,586 INFO:     Epoch: 83
2022-11-22 20:10:43,325 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7484753623951313, 'Total loss': 0.7484753623951313} | train loss {'Reaction outcome loss': 0.7305836125475461, 'Total loss': 0.7305836125475461}
2022-11-22 20:10:43,325 INFO:     Found new best model at epoch 83
2022-11-22 20:10:43,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:43,326 INFO:     Epoch: 84
2022-11-22 20:10:44,067 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.759622955738112, 'Total loss': 0.759622955738112} | train loss {'Reaction outcome loss': 0.7323548507983567, 'Total loss': 0.7323548507983567}
2022-11-22 20:10:44,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:44,067 INFO:     Epoch: 85
2022-11-22 20:10:44,800 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7621046082918034, 'Total loss': 0.7621046082918034} | train loss {'Reaction outcome loss': 0.7226373383500537, 'Total loss': 0.7226373383500537}
2022-11-22 20:10:44,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:44,801 INFO:     Epoch: 86
2022-11-22 20:10:45,539 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.735370030929876, 'Total loss': 0.735370030929876} | train loss {'Reaction outcome loss': 0.7341576795108983, 'Total loss': 0.7341576795108983}
2022-11-22 20:10:45,539 INFO:     Found new best model at epoch 86
2022-11-22 20:10:45,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:45,540 INFO:     Epoch: 87
2022-11-22 20:10:46,303 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7630651406077451, 'Total loss': 0.7630651406077451} | train loss {'Reaction outcome loss': 0.7257927947479194, 'Total loss': 0.7257927947479194}
2022-11-22 20:10:46,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:46,303 INFO:     Epoch: 88
2022-11-22 20:10:47,067 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7802076634279517, 'Total loss': 0.7802076634279517} | train loss {'Reaction outcome loss': 0.7236594703109538, 'Total loss': 0.7236594703109538}
2022-11-22 20:10:47,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:47,067 INFO:     Epoch: 89
2022-11-22 20:10:47,800 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8069264736286429, 'Total loss': 0.8069264736286429} | train loss {'Reaction outcome loss': 0.7166020153243033, 'Total loss': 0.7166020153243033}
2022-11-22 20:10:47,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:47,800 INFO:     Epoch: 90
2022-11-22 20:10:48,548 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.773818235757739, 'Total loss': 0.773818235757739} | train loss {'Reaction outcome loss': 0.7211989459932827, 'Total loss': 0.7211989459932827}
2022-11-22 20:10:48,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:48,549 INFO:     Epoch: 91
2022-11-22 20:10:49,296 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7530403795630433, 'Total loss': 0.7530403795630433} | train loss {'Reaction outcome loss': 0.7197536734528229, 'Total loss': 0.7197536734528229}
2022-11-22 20:10:49,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:49,296 INFO:     Epoch: 92
2022-11-22 20:10:50,043 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.763298498336659, 'Total loss': 0.763298498336659} | train loss {'Reaction outcome loss': 0.7193530283746172, 'Total loss': 0.7193530283746172}
2022-11-22 20:10:50,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:50,043 INFO:     Epoch: 93
2022-11-22 20:10:50,795 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.793547777935516, 'Total loss': 0.793547777935516} | train loss {'Reaction outcome loss': 0.7195810239578857, 'Total loss': 0.7195810239578857}
2022-11-22 20:10:50,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:50,796 INFO:     Epoch: 94
2022-11-22 20:10:51,553 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7397645462390988, 'Total loss': 0.7397645462390988} | train loss {'Reaction outcome loss': 0.72437926308542, 'Total loss': 0.72437926308542}
2022-11-22 20:10:51,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:51,553 INFO:     Epoch: 95
2022-11-22 20:10:52,347 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7337177250274393, 'Total loss': 0.7337177250274393} | train loss {'Reaction outcome loss': 0.7142600114228296, 'Total loss': 0.7142600114228296}
2022-11-22 20:10:52,347 INFO:     Found new best model at epoch 95
2022-11-22 20:10:52,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:52,348 INFO:     Epoch: 96
2022-11-22 20:10:53,078 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7228806088137072, 'Total loss': 0.7228806088137072} | train loss {'Reaction outcome loss': 0.7172267803403197, 'Total loss': 0.7172267803403197}
2022-11-22 20:10:53,078 INFO:     Found new best model at epoch 96
2022-11-22 20:10:53,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:53,079 INFO:     Epoch: 97
2022-11-22 20:10:53,841 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7799910036630409, 'Total loss': 0.7799910036630409} | train loss {'Reaction outcome loss': 0.721317353185083, 'Total loss': 0.721317353185083}
2022-11-22 20:10:53,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:53,842 INFO:     Epoch: 98
2022-11-22 20:10:54,569 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7575917070688203, 'Total loss': 0.7575917070688203} | train loss {'Reaction outcome loss': 0.7087189137447075, 'Total loss': 0.7087189137447075}
2022-11-22 20:10:54,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:54,570 INFO:     Epoch: 99
2022-11-22 20:10:55,302 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7382344922354055, 'Total loss': 0.7382344922354055} | train loss {'Reaction outcome loss': 0.7113215873842357, 'Total loss': 0.7113215873842357}
2022-11-22 20:10:55,302 INFO:     Best model found after epoch 97 of 100.
2022-11-22 20:10:55,302 INFO:   Done with stage: TRAINING
2022-11-22 20:10:55,302 INFO:   Starting stage: EVALUATION
2022-11-22 20:10:55,433 INFO:   Done with stage: EVALUATION
2022-11-22 20:10:55,433 INFO:   Leaving out SEQ value Fold_1
2022-11-22 20:10:55,448 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:10:55,448 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:10:56,158 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:10:56,158 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:10:56,229 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:10:56,229 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:10:56,229 INFO:     No hyperparam tuning for this model
2022-11-22 20:10:56,229 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:10:56,229 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:10:56,230 INFO:     None feature selector for col prot
2022-11-22 20:10:56,230 INFO:     None feature selector for col prot
2022-11-22 20:10:56,230 INFO:     None feature selector for col prot
2022-11-22 20:10:56,231 INFO:     None feature selector for col chem
2022-11-22 20:10:56,231 INFO:     None feature selector for col chem
2022-11-22 20:10:56,231 INFO:     None feature selector for col chem
2022-11-22 20:10:56,231 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:10:56,231 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:10:56,233 INFO:     Number of params in model 126091
2022-11-22 20:10:56,236 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:10:56,236 INFO:   Starting stage: TRAINING
2022-11-22 20:10:56,286 INFO:     Val loss before train {'Reaction outcome loss': 1.0050287476994775, 'Total loss': 1.0050287476994775}
2022-11-22 20:10:56,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:56,286 INFO:     Epoch: 0
2022-11-22 20:10:57,077 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.857953742146492, 'Total loss': 0.857953742146492} | train loss {'Reaction outcome loss': 0.8727144668942038, 'Total loss': 0.8727144668942038}
2022-11-22 20:10:57,077 INFO:     Found new best model at epoch 0
2022-11-22 20:10:57,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:57,078 INFO:     Epoch: 1
2022-11-22 20:10:57,917 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8433866744691675, 'Total loss': 0.8433866744691675} | train loss {'Reaction outcome loss': 0.8333501750037737, 'Total loss': 0.8333501750037737}
2022-11-22 20:10:57,917 INFO:     Found new best model at epoch 1
2022-11-22 20:10:57,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:57,918 INFO:     Epoch: 2
2022-11-22 20:10:58,769 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8693839690902017, 'Total loss': 0.8693839690902017} | train loss {'Reaction outcome loss': 0.8310455530278595, 'Total loss': 0.8310455530278595}
2022-11-22 20:10:58,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:58,770 INFO:     Epoch: 3
2022-11-22 20:10:59,560 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8347724696451967, 'Total loss': 0.8347724696451967} | train loss {'Reaction outcome loss': 0.8261739875864886, 'Total loss': 0.8261739875864886}
2022-11-22 20:10:59,560 INFO:     Found new best model at epoch 3
2022-11-22 20:10:59,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:10:59,561 INFO:     Epoch: 4
2022-11-22 20:11:00,338 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8352170573039488, 'Total loss': 0.8352170573039488} | train loss {'Reaction outcome loss': 0.8051012338173051, 'Total loss': 0.8051012338173051}
2022-11-22 20:11:00,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:00,338 INFO:     Epoch: 5
2022-11-22 20:11:01,185 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8214398161931471, 'Total loss': 0.8214398161931471} | train loss {'Reaction outcome loss': 0.8058319824185931, 'Total loss': 0.8058319824185931}
2022-11-22 20:11:01,186 INFO:     Found new best model at epoch 5
2022-11-22 20:11:01,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:01,187 INFO:     Epoch: 6
2022-11-22 20:11:01,948 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8200097050179135, 'Total loss': 0.8200097050179135} | train loss {'Reaction outcome loss': 0.8009461892640543, 'Total loss': 0.8009461892640543}
2022-11-22 20:11:01,949 INFO:     Found new best model at epoch 6
2022-11-22 20:11:01,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:01,950 INFO:     Epoch: 7
2022-11-22 20:11:02,716 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8180271807042035, 'Total loss': 0.8180271807042035} | train loss {'Reaction outcome loss': 0.7981367480417012, 'Total loss': 0.7981367480417012}
2022-11-22 20:11:02,716 INFO:     Found new best model at epoch 7
2022-11-22 20:11:02,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:02,718 INFO:     Epoch: 8
2022-11-22 20:11:03,502 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8502492200244557, 'Total loss': 0.8502492200244557} | train loss {'Reaction outcome loss': 0.7951167305471444, 'Total loss': 0.7951167305471444}
2022-11-22 20:11:03,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:03,503 INFO:     Epoch: 9
2022-11-22 20:11:04,276 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8110782273791053, 'Total loss': 0.8110782273791053} | train loss {'Reaction outcome loss': 0.7929835470340513, 'Total loss': 0.7929835470340513}
2022-11-22 20:11:04,276 INFO:     Found new best model at epoch 9
2022-11-22 20:11:04,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:04,277 INFO:     Epoch: 10
2022-11-22 20:11:05,028 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.845161920921369, 'Total loss': 0.845161920921369} | train loss {'Reaction outcome loss': 0.7938862996786712, 'Total loss': 0.7938862996786712}
2022-11-22 20:11:05,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:05,028 INFO:     Epoch: 11
2022-11-22 20:11:05,753 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8007919029756025, 'Total loss': 0.8007919029756025} | train loss {'Reaction outcome loss': 0.7921508744901974, 'Total loss': 0.7921508744901974}
2022-11-22 20:11:05,754 INFO:     Found new best model at epoch 11
2022-11-22 20:11:05,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:05,754 INFO:     Epoch: 12
2022-11-22 20:11:06,511 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8387148210948164, 'Total loss': 0.8387148210948164} | train loss {'Reaction outcome loss': 0.7823978955386138, 'Total loss': 0.7823978955386138}
2022-11-22 20:11:06,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:06,511 INFO:     Epoch: 13
2022-11-22 20:11:07,241 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8447312678803097, 'Total loss': 0.8447312678803097} | train loss {'Reaction outcome loss': 0.789575057111771, 'Total loss': 0.789575057111771}
2022-11-22 20:11:07,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:07,242 INFO:     Epoch: 14
2022-11-22 20:11:08,035 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8156025253913619, 'Total loss': 0.8156025253913619} | train loss {'Reaction outcome loss': 0.7892966005000991, 'Total loss': 0.7892966005000991}
2022-11-22 20:11:08,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:08,035 INFO:     Epoch: 15
2022-11-22 20:11:08,774 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8172981454567476, 'Total loss': 0.8172981454567476} | train loss {'Reaction outcome loss': 0.7876867635047388, 'Total loss': 0.7876867635047388}
2022-11-22 20:11:08,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:08,774 INFO:     Epoch: 16
2022-11-22 20:11:09,548 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8011272332885049, 'Total loss': 0.8011272332885049} | train loss {'Reaction outcome loss': 0.7910348493077977, 'Total loss': 0.7910348493077977}
2022-11-22 20:11:09,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:09,548 INFO:     Epoch: 17
2022-11-22 20:11:10,289 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8009669597853314, 'Total loss': 0.8009669597853314} | train loss {'Reaction outcome loss': 0.7936464257327168, 'Total loss': 0.7936464257327168}
2022-11-22 20:11:10,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:10,290 INFO:     Epoch: 18
2022-11-22 20:11:11,022 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8020552295175466, 'Total loss': 0.8020552295175466} | train loss {'Reaction outcome loss': 0.7914757782872389, 'Total loss': 0.7914757782872389}
2022-11-22 20:11:11,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:11,022 INFO:     Epoch: 19
2022-11-22 20:11:11,773 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8328533074395224, 'Total loss': 0.8328533074395224} | train loss {'Reaction outcome loss': 0.7869582423555707, 'Total loss': 0.7869582423555707}
2022-11-22 20:11:11,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:11,774 INFO:     Epoch: 20
2022-11-22 20:11:12,547 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8094321340322495, 'Total loss': 0.8094321340322495} | train loss {'Reaction outcome loss': 0.806651006584708, 'Total loss': 0.806651006584708}
2022-11-22 20:11:12,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:12,549 INFO:     Epoch: 21
2022-11-22 20:11:13,285 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8179635459726508, 'Total loss': 0.8179635459726508} | train loss {'Reaction outcome loss': 0.7846522063378863, 'Total loss': 0.7846522063378863}
2022-11-22 20:11:13,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:13,285 INFO:     Epoch: 22
2022-11-22 20:11:14,056 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7977503734556112, 'Total loss': 0.7977503734556112} | train loss {'Reaction outcome loss': 0.7707556742224616, 'Total loss': 0.7707556742224616}
2022-11-22 20:11:14,056 INFO:     Found new best model at epoch 22
2022-11-22 20:11:14,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:14,058 INFO:     Epoch: 23
2022-11-22 20:11:14,763 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8290316103534265, 'Total loss': 0.8290316103534265} | train loss {'Reaction outcome loss': 0.7865171609861166, 'Total loss': 0.7865171609861166}
2022-11-22 20:11:14,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:14,763 INFO:     Epoch: 24
2022-11-22 20:11:15,552 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7958996038545262, 'Total loss': 0.7958996038545262} | train loss {'Reaction outcome loss': 0.7748676765302898, 'Total loss': 0.7748676765302898}
2022-11-22 20:11:15,552 INFO:     Found new best model at epoch 24
2022-11-22 20:11:15,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:15,553 INFO:     Epoch: 25
2022-11-22 20:11:16,327 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7937367131764238, 'Total loss': 0.7937367131764238} | train loss {'Reaction outcome loss': 0.7746392256817837, 'Total loss': 0.7746392256817837}
2022-11-22 20:11:16,327 INFO:     Found new best model at epoch 25
2022-11-22 20:11:16,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:16,328 INFO:     Epoch: 26
2022-11-22 20:11:17,081 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8062120784412731, 'Total loss': 0.8062120784412731} | train loss {'Reaction outcome loss': 0.773143344562546, 'Total loss': 0.773143344562546}
2022-11-22 20:11:17,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:17,082 INFO:     Epoch: 27
2022-11-22 20:11:17,833 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8173059103163806, 'Total loss': 0.8173059103163806} | train loss {'Reaction outcome loss': 0.773478885411251, 'Total loss': 0.773478885411251}
2022-11-22 20:11:17,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:17,833 INFO:     Epoch: 28
2022-11-22 20:11:18,610 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.790679388425567, 'Total loss': 0.790679388425567} | train loss {'Reaction outcome loss': 0.776762329253108, 'Total loss': 0.776762329253108}
2022-11-22 20:11:18,610 INFO:     Found new best model at epoch 28
2022-11-22 20:11:18,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:18,611 INFO:     Epoch: 29
2022-11-22 20:11:19,364 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8050131689418446, 'Total loss': 0.8050131689418446} | train loss {'Reaction outcome loss': 0.7718525753330122, 'Total loss': 0.7718525753330122}
2022-11-22 20:11:19,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:19,364 INFO:     Epoch: 30
2022-11-22 20:11:20,132 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7983732988888567, 'Total loss': 0.7983732988888567} | train loss {'Reaction outcome loss': 0.7698152667507228, 'Total loss': 0.7698152667507228}
2022-11-22 20:11:20,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:20,132 INFO:     Epoch: 31
2022-11-22 20:11:20,876 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8108127049424432, 'Total loss': 0.8108127049424432} | train loss {'Reaction outcome loss': 0.7717294674894588, 'Total loss': 0.7717294674894588}
2022-11-22 20:11:20,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:20,876 INFO:     Epoch: 32
2022-11-22 20:11:21,628 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8183151625774123, 'Total loss': 0.8183151625774123} | train loss {'Reaction outcome loss': 0.7742777570539158, 'Total loss': 0.7742777570539158}
2022-11-22 20:11:21,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:21,629 INFO:     Epoch: 33
2022-11-22 20:11:22,383 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7921265255321156, 'Total loss': 0.7921265255321156} | train loss {'Reaction outcome loss': 0.7734465005426754, 'Total loss': 0.7734465005426754}
2022-11-22 20:11:22,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:22,383 INFO:     Epoch: 34
2022-11-22 20:11:23,110 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8028741939501329, 'Total loss': 0.8028741939501329} | train loss {'Reaction outcome loss': 0.7698116381520684, 'Total loss': 0.7698116381520684}
2022-11-22 20:11:23,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:23,110 INFO:     Epoch: 35
2022-11-22 20:11:23,892 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7864291938868436, 'Total loss': 0.7864291938868436} | train loss {'Reaction outcome loss': 0.7630600503340423, 'Total loss': 0.7630600503340423}
2022-11-22 20:11:23,892 INFO:     Found new best model at epoch 35
2022-11-22 20:11:23,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:23,893 INFO:     Epoch: 36
2022-11-22 20:11:24,669 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8000916283239018, 'Total loss': 0.8000916283239018} | train loss {'Reaction outcome loss': 0.7584901895027171, 'Total loss': 0.7584901895027171}
2022-11-22 20:11:24,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:24,669 INFO:     Epoch: 37
2022-11-22 20:11:25,415 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8027557202360847, 'Total loss': 0.8027557202360847} | train loss {'Reaction outcome loss': 0.7546635390775889, 'Total loss': 0.7546635390775889}
2022-11-22 20:11:25,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:25,415 INFO:     Epoch: 38
2022-11-22 20:11:26,187 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7825146642598239, 'Total loss': 0.7825146642598239} | train loss {'Reaction outcome loss': 0.7591045723873594, 'Total loss': 0.7591045723873594}
2022-11-22 20:11:26,187 INFO:     Found new best model at epoch 38
2022-11-22 20:11:26,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:26,188 INFO:     Epoch: 39
2022-11-22 20:11:26,920 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8025337498296391, 'Total loss': 0.8025337498296391} | train loss {'Reaction outcome loss': 0.763945662902917, 'Total loss': 0.763945662902917}
2022-11-22 20:11:26,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:26,921 INFO:     Epoch: 40
2022-11-22 20:11:27,671 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7949203042821451, 'Total loss': 0.7949203042821451} | train loss {'Reaction outcome loss': 0.764994780604656, 'Total loss': 0.764994780604656}
2022-11-22 20:11:27,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:27,671 INFO:     Epoch: 41
2022-11-22 20:11:28,380 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8210790306329727, 'Total loss': 0.8210790306329727} | train loss {'Reaction outcome loss': 0.7597736314482052, 'Total loss': 0.7597736314482052}
2022-11-22 20:11:28,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:28,380 INFO:     Epoch: 42
2022-11-22 20:11:29,131 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7903579920530319, 'Total loss': 0.7903579920530319} | train loss {'Reaction outcome loss': 0.759791282869061, 'Total loss': 0.759791282869061}
2022-11-22 20:11:29,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:29,131 INFO:     Epoch: 43
2022-11-22 20:11:29,878 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7814427986741066, 'Total loss': 0.7814427986741066} | train loss {'Reaction outcome loss': 0.7559644223948722, 'Total loss': 0.7559644223948722}
2022-11-22 20:11:29,878 INFO:     Found new best model at epoch 43
2022-11-22 20:11:29,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:29,879 INFO:     Epoch: 44
2022-11-22 20:11:30,643 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7866934815591032, 'Total loss': 0.7866934815591032} | train loss {'Reaction outcome loss': 0.7460985714607393, 'Total loss': 0.7460985714607393}
2022-11-22 20:11:30,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:30,644 INFO:     Epoch: 45
2022-11-22 20:11:31,385 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8099173700267618, 'Total loss': 0.8099173700267618} | train loss {'Reaction outcome loss': 0.7490327003513754, 'Total loss': 0.7490327003513754}
2022-11-22 20:11:31,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:31,385 INFO:     Epoch: 46
2022-11-22 20:11:32,167 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7887694300575689, 'Total loss': 0.7887694300575689} | train loss {'Reaction outcome loss': 0.7460301398989643, 'Total loss': 0.7460301398989643}
2022-11-22 20:11:32,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:32,167 INFO:     Epoch: 47
2022-11-22 20:11:32,947 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7774923145771027, 'Total loss': 0.7774923145771027} | train loss {'Reaction outcome loss': 0.7361969912824361, 'Total loss': 0.7361969912824361}
2022-11-22 20:11:32,948 INFO:     Found new best model at epoch 47
2022-11-22 20:11:32,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:32,949 INFO:     Epoch: 48
2022-11-22 20:11:33,730 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7841420525854285, 'Total loss': 0.7841420525854285} | train loss {'Reaction outcome loss': 0.7340361684681433, 'Total loss': 0.7340361684681433}
2022-11-22 20:11:33,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:33,731 INFO:     Epoch: 49
2022-11-22 20:11:34,461 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7505917549133301, 'Total loss': 0.7505917549133301} | train loss {'Reaction outcome loss': 0.7412851019668193, 'Total loss': 0.7412851019668193}
2022-11-22 20:11:34,461 INFO:     Found new best model at epoch 49
2022-11-22 20:11:34,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:34,462 INFO:     Epoch: 50
2022-11-22 20:11:35,185 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.78712148219347, 'Total loss': 0.78712148219347} | train loss {'Reaction outcome loss': 0.7425970077997277, 'Total loss': 0.7425970077997277}
2022-11-22 20:11:35,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:35,185 INFO:     Epoch: 51
2022-11-22 20:11:35,880 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7641326419331811, 'Total loss': 0.7641326419331811} | train loss {'Reaction outcome loss': 0.7458296824804684, 'Total loss': 0.7458296824804684}
2022-11-22 20:11:35,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:35,881 INFO:     Epoch: 52
2022-11-22 20:11:36,656 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7987712716514414, 'Total loss': 0.7987712716514414} | train loss {'Reaction outcome loss': 0.7301315033001455, 'Total loss': 0.7301315033001455}
2022-11-22 20:11:36,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:36,656 INFO:     Epoch: 53
2022-11-22 20:11:37,403 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7887207276441834, 'Total loss': 0.7887207276441834} | train loss {'Reaction outcome loss': 0.7378361144891152, 'Total loss': 0.7378361144891152}
2022-11-22 20:11:37,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:37,404 INFO:     Epoch: 54
2022-11-22 20:11:38,186 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7789308096874844, 'Total loss': 0.7789308096874844} | train loss {'Reaction outcome loss': 0.7222965141901603, 'Total loss': 0.7222965141901603}
2022-11-22 20:11:38,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:38,187 INFO:     Epoch: 55
2022-11-22 20:11:38,927 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7708423855629835, 'Total loss': 0.7708423855629835} | train loss {'Reaction outcome loss': 0.7189281587658624, 'Total loss': 0.7189281587658624}
2022-11-22 20:11:38,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:38,927 INFO:     Epoch: 56
2022-11-22 20:11:39,665 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8039129342545163, 'Total loss': 0.8039129342545163} | train loss {'Reaction outcome loss': 0.7197805354711015, 'Total loss': 0.7197805354711015}
2022-11-22 20:11:39,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:39,665 INFO:     Epoch: 57
2022-11-22 20:11:40,406 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7549809339371595, 'Total loss': 0.7549809339371595} | train loss {'Reaction outcome loss': 0.7283755172240106, 'Total loss': 0.7283755172240106}
2022-11-22 20:11:40,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:40,406 INFO:     Epoch: 58
2022-11-22 20:11:41,156 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7647588666189801, 'Total loss': 0.7647588666189801} | train loss {'Reaction outcome loss': 0.7140004111205035, 'Total loss': 0.7140004111205035}
2022-11-22 20:11:41,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:41,157 INFO:     Epoch: 59
2022-11-22 20:11:41,889 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7813296094536781, 'Total loss': 0.7813296094536781} | train loss {'Reaction outcome loss': 0.7206503584799979, 'Total loss': 0.7206503584799979}
2022-11-22 20:11:41,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:41,889 INFO:     Epoch: 60
2022-11-22 20:11:42,604 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.786676210435954, 'Total loss': 0.786676210435954} | train loss {'Reaction outcome loss': 0.7110985468183211, 'Total loss': 0.7110985468183211}
2022-11-22 20:11:42,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:42,605 INFO:     Epoch: 61
2022-11-22 20:11:43,311 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7386344332586635, 'Total loss': 0.7386344332586635} | train loss {'Reaction outcome loss': 0.7142568747041679, 'Total loss': 0.7142568747041679}
2022-11-22 20:11:43,311 INFO:     Found new best model at epoch 61
2022-11-22 20:11:43,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:43,312 INFO:     Epoch: 62
2022-11-22 20:11:44,072 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7459636594761502, 'Total loss': 0.7459636594761502} | train loss {'Reaction outcome loss': 0.7144317150357281, 'Total loss': 0.7144317150357281}
2022-11-22 20:11:44,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:44,074 INFO:     Epoch: 63
2022-11-22 20:11:44,866 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7706810635599223, 'Total loss': 0.7706810635599223} | train loss {'Reaction outcome loss': 0.7178909394905152, 'Total loss': 0.7178909394905152}
2022-11-22 20:11:44,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:44,866 INFO:     Epoch: 64
2022-11-22 20:11:45,658 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7347206933931871, 'Total loss': 0.7347206933931871} | train loss {'Reaction outcome loss': 0.7148307497322801, 'Total loss': 0.7148307497322801}
2022-11-22 20:11:45,658 INFO:     Found new best model at epoch 64
2022-11-22 20:11:45,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:45,659 INFO:     Epoch: 65
2022-11-22 20:11:46,431 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7594351260499521, 'Total loss': 0.7594351260499521} | train loss {'Reaction outcome loss': 0.7076044361962963, 'Total loss': 0.7076044361962963}
2022-11-22 20:11:46,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:46,431 INFO:     Epoch: 66
2022-11-22 20:11:47,205 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.738486491821029, 'Total loss': 0.738486491821029} | train loss {'Reaction outcome loss': 0.7107148381451575, 'Total loss': 0.7107148381451575}
2022-11-22 20:11:47,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:47,205 INFO:     Epoch: 67
2022-11-22 20:11:48,000 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7634286596016451, 'Total loss': 0.7634286596016451} | train loss {'Reaction outcome loss': 0.7029273960860032, 'Total loss': 0.7029273960860032}
2022-11-22 20:11:48,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:48,001 INFO:     Epoch: 68
2022-11-22 20:11:48,774 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7729661085388877, 'Total loss': 0.7729661085388877} | train loss {'Reaction outcome loss': 0.7076654397856127, 'Total loss': 0.7076654397856127}
2022-11-22 20:11:48,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:48,774 INFO:     Epoch: 69
2022-11-22 20:11:49,533 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7532977814024145, 'Total loss': 0.7532977814024145} | train loss {'Reaction outcome loss': 0.7099288484224906, 'Total loss': 0.7099288484224906}
2022-11-22 20:11:49,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:49,534 INFO:     Epoch: 70
2022-11-22 20:11:50,276 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7522845606912266, 'Total loss': 0.7522845606912266} | train loss {'Reaction outcome loss': 0.7015553677854268, 'Total loss': 0.7015553677854268}
2022-11-22 20:11:50,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:50,277 INFO:     Epoch: 71
2022-11-22 20:11:51,004 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7794121612202037, 'Total loss': 0.7794121612202037} | train loss {'Reaction outcome loss': 0.7178315456338257, 'Total loss': 0.7178315456338257}
2022-11-22 20:11:51,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:51,004 INFO:     Epoch: 72
2022-11-22 20:11:51,723 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7446091134439815, 'Total loss': 0.7446091134439815} | train loss {'Reaction outcome loss': 0.7105864956070055, 'Total loss': 0.7105864956070055}
2022-11-22 20:11:51,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:51,723 INFO:     Epoch: 73
2022-11-22 20:11:52,445 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8156881867484613, 'Total loss': 0.8156881867484613} | train loss {'Reaction outcome loss': 0.7127892370166083, 'Total loss': 0.7127892370166083}
2022-11-22 20:11:52,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:52,445 INFO:     Epoch: 74
2022-11-22 20:11:53,173 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7366226220672781, 'Total loss': 0.7366226220672781} | train loss {'Reaction outcome loss': 0.7016975677794652, 'Total loss': 0.7016975677794652}
2022-11-22 20:11:53,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:53,173 INFO:     Epoch: 75
2022-11-22 20:11:53,909 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7544274533336813, 'Total loss': 0.7544274533336813} | train loss {'Reaction outcome loss': 0.718260939183988, 'Total loss': 0.718260939183988}
2022-11-22 20:11:53,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:53,910 INFO:     Epoch: 76
2022-11-22 20:11:54,642 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7370141460136934, 'Total loss': 0.7370141460136934} | train loss {'Reaction outcome loss': 0.7037050545456921, 'Total loss': 0.7037050545456921}
2022-11-22 20:11:54,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:54,642 INFO:     Epoch: 77
2022-11-22 20:11:55,419 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7451177659359846, 'Total loss': 0.7451177659359846} | train loss {'Reaction outcome loss': 0.704022306421025, 'Total loss': 0.704022306421025}
2022-11-22 20:11:55,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:55,419 INFO:     Epoch: 78
2022-11-22 20:11:56,196 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7671158334070985, 'Total loss': 0.7671158334070985} | train loss {'Reaction outcome loss': 0.7003925531981927, 'Total loss': 0.7003925531981927}
2022-11-22 20:11:56,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:56,196 INFO:     Epoch: 79
2022-11-22 20:11:56,987 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7422866374254227, 'Total loss': 0.7422866374254227} | train loss {'Reaction outcome loss': 0.7056091731859122, 'Total loss': 0.7056091731859122}
2022-11-22 20:11:56,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:56,987 INFO:     Epoch: 80
2022-11-22 20:11:57,778 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7677459513599222, 'Total loss': 0.7677459513599222} | train loss {'Reaction outcome loss': 0.7032856284848109, 'Total loss': 0.7032856284848109}
2022-11-22 20:11:57,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:57,778 INFO:     Epoch: 81
2022-11-22 20:11:58,526 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8761010020971298, 'Total loss': 0.8761010020971298} | train loss {'Reaction outcome loss': 0.7139511711684315, 'Total loss': 0.7139511711684315}
2022-11-22 20:11:58,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:58,527 INFO:     Epoch: 82
2022-11-22 20:11:59,345 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7523297775875438, 'Total loss': 0.7523297775875438} | train loss {'Reaction outcome loss': 0.7221283889733828, 'Total loss': 0.7221283889733828}
2022-11-22 20:11:59,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:11:59,346 INFO:     Epoch: 83
2022-11-22 20:12:00,176 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7312829596075144, 'Total loss': 0.7312829596075144} | train loss {'Reaction outcome loss': 0.7126694651026475, 'Total loss': 0.7126694651026475}
2022-11-22 20:12:00,176 INFO:     Found new best model at epoch 83
2022-11-22 20:12:00,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:00,177 INFO:     Epoch: 84
2022-11-22 20:12:01,042 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7949580076065931, 'Total loss': 0.7949580076065931} | train loss {'Reaction outcome loss': 0.7071632150455043, 'Total loss': 0.7071632150455043}
2022-11-22 20:12:01,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:01,042 INFO:     Epoch: 85
2022-11-22 20:12:01,818 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7541862292723223, 'Total loss': 0.7541862292723223} | train loss {'Reaction outcome loss': 0.704228639482004, 'Total loss': 0.704228639482004}
2022-11-22 20:12:01,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:01,818 INFO:     Epoch: 86
2022-11-22 20:12:02,656 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7805679745294831, 'Total loss': 0.7805679745294831} | train loss {'Reaction outcome loss': 0.6952630587238894, 'Total loss': 0.6952630587238894}
2022-11-22 20:12:02,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:02,657 INFO:     Epoch: 87
2022-11-22 20:12:03,485 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7471117966554381, 'Total loss': 0.7471117966554381} | train loss {'Reaction outcome loss': 0.6977018863566009, 'Total loss': 0.6977018863566009}
2022-11-22 20:12:03,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:03,485 INFO:     Epoch: 88
2022-11-22 20:12:04,286 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.75186368890784, 'Total loss': 0.75186368890784} | train loss {'Reaction outcome loss': 0.7043733783801528, 'Total loss': 0.7043733783801528}
2022-11-22 20:12:04,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:04,286 INFO:     Epoch: 89
2022-11-22 20:12:05,111 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7311922962015326, 'Total loss': 0.7311922962015326} | train loss {'Reaction outcome loss': 0.7018739374784323, 'Total loss': 0.7018739374784323}
2022-11-22 20:12:05,111 INFO:     Found new best model at epoch 89
2022-11-22 20:12:05,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:05,112 INFO:     Epoch: 90
2022-11-22 20:12:05,884 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7613571028817784, 'Total loss': 0.7613571028817784} | train loss {'Reaction outcome loss': 0.7154209792372669, 'Total loss': 0.7154209792372669}
2022-11-22 20:12:05,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:05,884 INFO:     Epoch: 91
2022-11-22 20:12:06,715 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7472315830263224, 'Total loss': 0.7472315830263224} | train loss {'Reaction outcome loss': 0.7044813606420509, 'Total loss': 0.7044813606420509}
2022-11-22 20:12:06,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:06,715 INFO:     Epoch: 92
2022-11-22 20:12:07,521 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7699284648353403, 'Total loss': 0.7699284648353403} | train loss {'Reaction outcome loss': 0.7101886453416183, 'Total loss': 0.7101886453416183}
2022-11-22 20:12:07,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:07,521 INFO:     Epoch: 93
2022-11-22 20:12:08,373 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7819827117703178, 'Total loss': 0.7819827117703178} | train loss {'Reaction outcome loss': 0.7134975752367182, 'Total loss': 0.7134975752367182}
2022-11-22 20:12:08,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:08,373 INFO:     Epoch: 94
2022-11-22 20:12:09,250 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7572656057097695, 'Total loss': 0.7572656057097695} | train loss {'Reaction outcome loss': 0.6961362925980256, 'Total loss': 0.6961362925980256}
2022-11-22 20:12:09,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:09,250 INFO:     Epoch: 95
2022-11-22 20:12:10,106 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7364171452142976, 'Total loss': 0.7364171452142976} | train loss {'Reaction outcome loss': 0.7099292079205455, 'Total loss': 0.7099292079205455}
2022-11-22 20:12:10,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:10,106 INFO:     Epoch: 96
2022-11-22 20:12:10,973 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7501182996413924, 'Total loss': 0.7501182996413924} | train loss {'Reaction outcome loss': 0.7017989947125014, 'Total loss': 0.7017989947125014}
2022-11-22 20:12:10,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:10,973 INFO:     Epoch: 97
2022-11-22 20:12:11,796 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7440406084060669, 'Total loss': 0.7440406084060669} | train loss {'Reaction outcome loss': 0.7153763682977391, 'Total loss': 0.7153763682977391}
2022-11-22 20:12:11,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:11,796 INFO:     Epoch: 98
2022-11-22 20:12:12,654 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7945020598444071, 'Total loss': 0.7945020598444071} | train loss {'Reaction outcome loss': 0.7060958101199224, 'Total loss': 0.7060958101199224}
2022-11-22 20:12:12,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:12,654 INFO:     Epoch: 99
2022-11-22 20:12:13,459 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7426950464194472, 'Total loss': 0.7426950464194472} | train loss {'Reaction outcome loss': 0.7053042780532528, 'Total loss': 0.7053042780532528}
2022-11-22 20:12:13,459 INFO:     Best model found after epoch 90 of 100.
2022-11-22 20:12:13,459 INFO:   Done with stage: TRAINING
2022-11-22 20:12:13,459 INFO:   Starting stage: EVALUATION
2022-11-22 20:12:13,578 INFO:   Done with stage: EVALUATION
2022-11-22 20:12:13,578 INFO:   Leaving out SEQ value Fold_2
2022-11-22 20:12:13,592 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:12:13,592 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:12:14,274 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:12:14,275 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:12:14,351 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:12:14,351 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:12:14,351 INFO:     No hyperparam tuning for this model
2022-11-22 20:12:14,352 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:12:14,352 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:12:14,353 INFO:     None feature selector for col prot
2022-11-22 20:12:14,353 INFO:     None feature selector for col prot
2022-11-22 20:12:14,353 INFO:     None feature selector for col prot
2022-11-22 20:12:14,354 INFO:     None feature selector for col chem
2022-11-22 20:12:14,354 INFO:     None feature selector for col chem
2022-11-22 20:12:14,354 INFO:     None feature selector for col chem
2022-11-22 20:12:14,354 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:12:14,354 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:12:14,355 INFO:     Number of params in model 126091
2022-11-22 20:12:14,359 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:12:14,359 INFO:   Starting stage: TRAINING
2022-11-22 20:12:14,411 INFO:     Val loss before train {'Reaction outcome loss': 0.9481659626418893, 'Total loss': 0.9481659626418893}
2022-11-22 20:12:14,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:14,411 INFO:     Epoch: 0
2022-11-22 20:12:15,274 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7953678870742972, 'Total loss': 0.7953678870742972} | train loss {'Reaction outcome loss': 0.8907542339393071, 'Total loss': 0.8907542339393071}
2022-11-22 20:12:15,274 INFO:     Found new best model at epoch 0
2022-11-22 20:12:15,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:15,276 INFO:     Epoch: 1
2022-11-22 20:12:16,104 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7855115322904154, 'Total loss': 0.7855115322904154} | train loss {'Reaction outcome loss': 0.8418428596185178, 'Total loss': 0.8418428596185178}
2022-11-22 20:12:16,104 INFO:     Found new best model at epoch 1
2022-11-22 20:12:16,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:16,105 INFO:     Epoch: 2
2022-11-22 20:12:16,945 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7821785326708447, 'Total loss': 0.7821785326708447} | train loss {'Reaction outcome loss': 0.8289099221326867, 'Total loss': 0.8289099221326867}
2022-11-22 20:12:16,945 INFO:     Found new best model at epoch 2
2022-11-22 20:12:16,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:16,946 INFO:     Epoch: 3
2022-11-22 20:12:17,743 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8120218420570547, 'Total loss': 0.8120218420570547} | train loss {'Reaction outcome loss': 0.8355397003037589, 'Total loss': 0.8355397003037589}
2022-11-22 20:12:17,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:17,744 INFO:     Epoch: 4
2022-11-22 20:12:18,530 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8179596120660956, 'Total loss': 0.8179596120660956} | train loss {'Reaction outcome loss': 0.8140802765379147, 'Total loss': 0.8140802765379147}
2022-11-22 20:12:18,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:18,530 INFO:     Epoch: 5
2022-11-22 20:12:19,359 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7524728768251159, 'Total loss': 0.7524728768251159} | train loss {'Reaction outcome loss': 0.8169307168649167, 'Total loss': 0.8169307168649167}
2022-11-22 20:12:19,359 INFO:     Found new best model at epoch 5
2022-11-22 20:12:19,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:19,360 INFO:     Epoch: 6
2022-11-22 20:12:20,160 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7550503862175074, 'Total loss': 0.7550503862175074} | train loss {'Reaction outcome loss': 0.810946845278448, 'Total loss': 0.810946845278448}
2022-11-22 20:12:20,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:20,160 INFO:     Epoch: 7
2022-11-22 20:12:20,951 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7516343505545096, 'Total loss': 0.7516343505545096} | train loss {'Reaction outcome loss': 0.8088349416547892, 'Total loss': 0.8088349416547892}
2022-11-22 20:12:20,952 INFO:     Found new best model at epoch 7
2022-11-22 20:12:20,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:20,953 INFO:     Epoch: 8
2022-11-22 20:12:21,756 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7527322261170908, 'Total loss': 0.7527322261170908} | train loss {'Reaction outcome loss': 0.8078839210831389, 'Total loss': 0.8078839210831389}
2022-11-22 20:12:21,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:21,757 INFO:     Epoch: 9
2022-11-22 20:12:22,591 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7637537196278572, 'Total loss': 0.7637537196278572} | train loss {'Reaction outcome loss': 0.8065467436702884, 'Total loss': 0.8065467436702884}
2022-11-22 20:12:22,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:22,591 INFO:     Epoch: 10
2022-11-22 20:12:23,421 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.776583036238497, 'Total loss': 0.776583036238497} | train loss {'Reaction outcome loss': 0.8047032664016801, 'Total loss': 0.8047032664016801}
2022-11-22 20:12:23,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:23,421 INFO:     Epoch: 11
2022-11-22 20:12:24,226 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7439155578613281, 'Total loss': 0.7439155578613281} | train loss {'Reaction outcome loss': 0.8022967409114449, 'Total loss': 0.8022967409114449}
2022-11-22 20:12:24,226 INFO:     Found new best model at epoch 11
2022-11-22 20:12:24,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:24,227 INFO:     Epoch: 12
2022-11-22 20:12:25,042 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7504232187162746, 'Total loss': 0.7504232187162746} | train loss {'Reaction outcome loss': 0.8009382893844527, 'Total loss': 0.8009382893844527}
2022-11-22 20:12:25,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:25,043 INFO:     Epoch: 13
2022-11-22 20:12:25,840 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7593340399590406, 'Total loss': 0.7593340399590406} | train loss {'Reaction outcome loss': 0.8008969476028365, 'Total loss': 0.8008969476028365}
2022-11-22 20:12:25,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:25,840 INFO:     Epoch: 14
2022-11-22 20:12:26,664 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.747189231894233, 'Total loss': 0.747189231894233} | train loss {'Reaction outcome loss': 0.8018756438274772, 'Total loss': 0.8018756438274772}
2022-11-22 20:12:26,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:26,665 INFO:     Epoch: 15
2022-11-22 20:12:27,477 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7629752931269732, 'Total loss': 0.7629752931269732} | train loss {'Reaction outcome loss': 0.7985786101039575, 'Total loss': 0.7985786101039575}
2022-11-22 20:12:27,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:27,478 INFO:     Epoch: 16
2022-11-22 20:12:28,286 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7424246167594736, 'Total loss': 0.7424246167594736} | train loss {'Reaction outcome loss': 0.7980192241620044, 'Total loss': 0.7980192241620044}
2022-11-22 20:12:28,286 INFO:     Found new best model at epoch 16
2022-11-22 20:12:28,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:28,287 INFO:     Epoch: 17
2022-11-22 20:12:29,050 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7656502236019481, 'Total loss': 0.7656502236019481} | train loss {'Reaction outcome loss': 0.7928016348760956, 'Total loss': 0.7928016348760956}
2022-11-22 20:12:29,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:29,051 INFO:     Epoch: 18
2022-11-22 20:12:29,850 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.73867547579787, 'Total loss': 0.73867547579787} | train loss {'Reaction outcome loss': 0.7947861344230418, 'Total loss': 0.7947861344230418}
2022-11-22 20:12:29,850 INFO:     Found new best model at epoch 18
2022-11-22 20:12:29,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:29,851 INFO:     Epoch: 19
2022-11-22 20:12:30,653 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7390792911702936, 'Total loss': 0.7390792911702936} | train loss {'Reaction outcome loss': 0.80135266537569, 'Total loss': 0.80135266537569}
2022-11-22 20:12:30,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:30,654 INFO:     Epoch: 20
2022-11-22 20:12:31,411 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7905902937054634, 'Total loss': 0.7905902937054634} | train loss {'Reaction outcome loss': 0.7910927390565677, 'Total loss': 0.7910927390565677}
2022-11-22 20:12:31,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:31,411 INFO:     Epoch: 21
2022-11-22 20:12:32,228 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7445901761000807, 'Total loss': 0.7445901761000807} | train loss {'Reaction outcome loss': 0.7962603988696118, 'Total loss': 0.7962603988696118}
2022-11-22 20:12:32,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:32,228 INFO:     Epoch: 22
2022-11-22 20:12:33,009 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7438442862846635, 'Total loss': 0.7438442862846635} | train loss {'Reaction outcome loss': 0.7958533238391488, 'Total loss': 0.7958533238391488}
2022-11-22 20:12:33,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:33,010 INFO:     Epoch: 23
2022-11-22 20:12:33,864 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7550518295981667, 'Total loss': 0.7550518295981667} | train loss {'Reaction outcome loss': 0.7977683033261981, 'Total loss': 0.7977683033261981}
2022-11-22 20:12:33,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:33,864 INFO:     Epoch: 24
2022-11-22 20:12:34,650 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7317465266043489, 'Total loss': 0.7317465266043489} | train loss {'Reaction outcome loss': 0.7888391092115519, 'Total loss': 0.7888391092115519}
2022-11-22 20:12:34,651 INFO:     Found new best model at epoch 24
2022-11-22 20:12:34,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:34,652 INFO:     Epoch: 25
2022-11-22 20:12:35,445 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7706199098717083, 'Total loss': 0.7706199098717083} | train loss {'Reaction outcome loss': 0.7913710500512804, 'Total loss': 0.7913710500512804}
2022-11-22 20:12:35,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:35,445 INFO:     Epoch: 26
2022-11-22 20:12:36,262 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7221495522694155, 'Total loss': 0.7221495522694155} | train loss {'Reaction outcome loss': 0.7918840264787479, 'Total loss': 0.7918840264787479}
2022-11-22 20:12:36,263 INFO:     Found new best model at epoch 26
2022-11-22 20:12:36,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:36,263 INFO:     Epoch: 27
2022-11-22 20:12:37,074 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7527429583397779, 'Total loss': 0.7527429583397779} | train loss {'Reaction outcome loss': 0.787857842931942, 'Total loss': 0.787857842931942}
2022-11-22 20:12:37,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:37,074 INFO:     Epoch: 28
2022-11-22 20:12:37,895 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7535057271068747, 'Total loss': 0.7535057271068747} | train loss {'Reaction outcome loss': 0.7952118798178069, 'Total loss': 0.7952118798178069}
2022-11-22 20:12:37,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:37,895 INFO:     Epoch: 29
2022-11-22 20:12:38,672 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7224012843587182, 'Total loss': 0.7224012843587182} | train loss {'Reaction outcome loss': 0.7926115792624805, 'Total loss': 0.7926115792624805}
2022-11-22 20:12:38,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:38,672 INFO:     Epoch: 30
2022-11-22 20:12:39,483 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7469196278940547, 'Total loss': 0.7469196278940547} | train loss {'Reaction outcome loss': 0.7963707725612484, 'Total loss': 0.7963707725612484}
2022-11-22 20:12:39,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:39,483 INFO:     Epoch: 31
2022-11-22 20:12:40,266 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7576891522515904, 'Total loss': 0.7576891522515904} | train loss {'Reaction outcome loss': 0.7905538149025976, 'Total loss': 0.7905538149025976}
2022-11-22 20:12:40,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:40,267 INFO:     Epoch: 32
2022-11-22 20:12:41,078 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7214058962735262, 'Total loss': 0.7214058962735262} | train loss {'Reaction outcome loss': 0.7918969367231642, 'Total loss': 0.7918969367231642}
2022-11-22 20:12:41,079 INFO:     Found new best model at epoch 32
2022-11-22 20:12:41,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:41,080 INFO:     Epoch: 33
2022-11-22 20:12:41,888 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7348584681749344, 'Total loss': 0.7348584681749344} | train loss {'Reaction outcome loss': 0.7905165943564201, 'Total loss': 0.7905165943564201}
2022-11-22 20:12:41,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:41,889 INFO:     Epoch: 34
2022-11-22 20:12:42,692 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7378323809667067, 'Total loss': 0.7378323809667067} | train loss {'Reaction outcome loss': 0.788946684039369, 'Total loss': 0.788946684039369}
2022-11-22 20:12:42,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:42,692 INFO:     Epoch: 35
2022-11-22 20:12:43,472 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.760962463915348, 'Total loss': 0.760962463915348} | train loss {'Reaction outcome loss': 0.7849971390500361, 'Total loss': 0.7849971390500361}
2022-11-22 20:12:43,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:43,472 INFO:     Epoch: 36
2022-11-22 20:12:44,248 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7318949130448428, 'Total loss': 0.7318949130448428} | train loss {'Reaction outcome loss': 0.7878180219202625, 'Total loss': 0.7878180219202625}
2022-11-22 20:12:44,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:44,248 INFO:     Epoch: 37
2022-11-22 20:12:44,999 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.761759566989812, 'Total loss': 0.761759566989812} | train loss {'Reaction outcome loss': 0.7903090431982157, 'Total loss': 0.7903090431982157}
2022-11-22 20:12:45,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:45,000 INFO:     Epoch: 38
2022-11-22 20:12:45,783 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7311367947946895, 'Total loss': 0.7311367947946895} | train loss {'Reaction outcome loss': 0.7861980075738868, 'Total loss': 0.7861980075738868}
2022-11-22 20:12:45,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:45,784 INFO:     Epoch: 39
2022-11-22 20:12:46,564 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7404311339963566, 'Total loss': 0.7404311339963566} | train loss {'Reaction outcome loss': 0.7828516315440742, 'Total loss': 0.7828516315440742}
2022-11-22 20:12:46,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:46,565 INFO:     Epoch: 40
2022-11-22 20:12:47,320 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.734056910330599, 'Total loss': 0.734056910330599} | train loss {'Reaction outcome loss': 0.7863029611353971, 'Total loss': 0.7863029611353971}
2022-11-22 20:12:47,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:47,321 INFO:     Epoch: 41
2022-11-22 20:12:48,121 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7688057652928613, 'Total loss': 0.7688057652928613} | train loss {'Reaction outcome loss': 0.7861380309474711, 'Total loss': 0.7861380309474711}
2022-11-22 20:12:48,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:48,121 INFO:     Epoch: 42
2022-11-22 20:12:48,895 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7324030311270193, 'Total loss': 0.7324030311270193} | train loss {'Reaction outcome loss': 0.7826455713534842, 'Total loss': 0.7826455713534842}
2022-11-22 20:12:48,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:48,895 INFO:     Epoch: 43
2022-11-22 20:12:49,687 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7431410889733921, 'Total loss': 0.7431410889733921} | train loss {'Reaction outcome loss': 0.7823477394726812, 'Total loss': 0.7823477394726812}
2022-11-22 20:12:49,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:49,687 INFO:     Epoch: 44
2022-11-22 20:12:50,451 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7326779192821546, 'Total loss': 0.7326779192821546} | train loss {'Reaction outcome loss': 0.7817617989316279, 'Total loss': 0.7817617989316279}
2022-11-22 20:12:50,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:50,452 INFO:     Epoch: 45
2022-11-22 20:12:51,270 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7366914193738591, 'Total loss': 0.7366914193738591} | train loss {'Reaction outcome loss': 0.7781655146151173, 'Total loss': 0.7781655146151173}
2022-11-22 20:12:51,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:51,270 INFO:     Epoch: 46
2022-11-22 20:12:52,079 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.748829111456871, 'Total loss': 0.748829111456871} | train loss {'Reaction outcome loss': 0.785542870419366, 'Total loss': 0.785542870419366}
2022-11-22 20:12:52,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:52,080 INFO:     Epoch: 47
2022-11-22 20:12:52,860 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7673494592308998, 'Total loss': 0.7673494592308998} | train loss {'Reaction outcome loss': 0.7816135468531628, 'Total loss': 0.7816135468531628}
2022-11-22 20:12:52,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:52,860 INFO:     Epoch: 48
2022-11-22 20:12:53,648 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7716693525964563, 'Total loss': 0.7716693525964563} | train loss {'Reaction outcome loss': 0.7826171834858097, 'Total loss': 0.7826171834858097}
2022-11-22 20:12:53,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:53,648 INFO:     Epoch: 49
2022-11-22 20:12:54,420 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7721032215790316, 'Total loss': 0.7721032215790316} | train loss {'Reaction outcome loss': 0.7856515958601115, 'Total loss': 0.7856515958601115}
2022-11-22 20:12:54,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:54,421 INFO:     Epoch: 50
2022-11-22 20:12:55,222 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7234758443453095, 'Total loss': 0.7234758443453095} | train loss {'Reaction outcome loss': 0.7760982299337582, 'Total loss': 0.7760982299337582}
2022-11-22 20:12:55,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:55,222 INFO:     Epoch: 51
2022-11-22 20:12:56,021 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7217886410653591, 'Total loss': 0.7217886410653591} | train loss {'Reaction outcome loss': 0.7776071426819782, 'Total loss': 0.7776071426819782}
2022-11-22 20:12:56,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:56,022 INFO:     Epoch: 52
2022-11-22 20:12:56,812 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7327356656843965, 'Total loss': 0.7327356656843965} | train loss {'Reaction outcome loss': 0.7754867281232561, 'Total loss': 0.7754867281232561}
2022-11-22 20:12:56,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:56,812 INFO:     Epoch: 53
2022-11-22 20:12:57,573 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7266589098355987, 'Total loss': 0.7266589098355987} | train loss {'Reaction outcome loss': 0.7681731014835591, 'Total loss': 0.7681731014835591}
2022-11-22 20:12:57,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:57,574 INFO:     Epoch: 54
2022-11-22 20:12:58,378 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7440190518444235, 'Total loss': 0.7440190518444235} | train loss {'Reaction outcome loss': 0.7717450784177197, 'Total loss': 0.7717450784177197}
2022-11-22 20:12:58,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:58,379 INFO:     Epoch: 55
2022-11-22 20:12:59,185 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7096960246562958, 'Total loss': 0.7096960246562958} | train loss {'Reaction outcome loss': 0.7737187637358296, 'Total loss': 0.7737187637358296}
2022-11-22 20:12:59,185 INFO:     Found new best model at epoch 55
2022-11-22 20:12:59,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:59,186 INFO:     Epoch: 56
2022-11-22 20:12:59,977 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7075006440281868, 'Total loss': 0.7075006440281868} | train loss {'Reaction outcome loss': 0.7733999400722738, 'Total loss': 0.7733999400722738}
2022-11-22 20:12:59,977 INFO:     Found new best model at epoch 56
2022-11-22 20:12:59,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:12:59,978 INFO:     Epoch: 57
2022-11-22 20:13:00,757 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7404003529386087, 'Total loss': 0.7404003529386087} | train loss {'Reaction outcome loss': 0.7654751630461946, 'Total loss': 0.7654751630461946}
2022-11-22 20:13:00,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:00,757 INFO:     Epoch: 58
2022-11-22 20:13:01,553 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.720466935499148, 'Total loss': 0.720466935499148} | train loss {'Reaction outcome loss': 0.7677323101734629, 'Total loss': 0.7677323101734629}
2022-11-22 20:13:01,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:01,554 INFO:     Epoch: 59
2022-11-22 20:13:02,348 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7141418389298699, 'Total loss': 0.7141418389298699} | train loss {'Reaction outcome loss': 0.7604694451604571, 'Total loss': 0.7604694451604571}
2022-11-22 20:13:02,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:02,348 INFO:     Epoch: 60
2022-11-22 20:13:03,103 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7003449211743745, 'Total loss': 0.7003449211743745} | train loss {'Reaction outcome loss': 0.7751937838233247, 'Total loss': 0.7751937838233247}
2022-11-22 20:13:03,104 INFO:     Found new best model at epoch 60
2022-11-22 20:13:03,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:03,104 INFO:     Epoch: 61
2022-11-22 20:13:03,846 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7044429338791154, 'Total loss': 0.7044429338791154} | train loss {'Reaction outcome loss': 0.7634547057200451, 'Total loss': 0.7634547057200451}
2022-11-22 20:13:03,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:03,846 INFO:     Epoch: 62
2022-11-22 20:13:04,616 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7119710706174374, 'Total loss': 0.7119710706174374} | train loss {'Reaction outcome loss': 0.7586778527619887, 'Total loss': 0.7586778527619887}
2022-11-22 20:13:04,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:04,617 INFO:     Epoch: 63
2022-11-22 20:13:05,340 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.704301020977172, 'Total loss': 0.704301020977172} | train loss {'Reaction outcome loss': 0.7592215889570665, 'Total loss': 0.7592215889570665}
2022-11-22 20:13:05,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:05,340 INFO:     Epoch: 64
2022-11-22 20:13:06,150 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.6933929527347739, 'Total loss': 0.6933929527347739} | train loss {'Reaction outcome loss': 0.7580353195569953, 'Total loss': 0.7580353195569953}
2022-11-22 20:13:06,150 INFO:     Found new best model at epoch 64
2022-11-22 20:13:06,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:06,151 INFO:     Epoch: 65
2022-11-22 20:13:06,901 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7030032974752513, 'Total loss': 0.7030032974752513} | train loss {'Reaction outcome loss': 0.7512955794529039, 'Total loss': 0.7512955794529039}
2022-11-22 20:13:06,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:06,902 INFO:     Epoch: 66
2022-11-22 20:13:07,668 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.6943031623959541, 'Total loss': 0.6943031623959541} | train loss {'Reaction outcome loss': 0.7547885852200644, 'Total loss': 0.7547885852200644}
2022-11-22 20:13:07,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:07,668 INFO:     Epoch: 67
2022-11-22 20:13:08,392 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.6729608970609579, 'Total loss': 0.6729608970609579} | train loss {'Reaction outcome loss': 0.7478111584575808, 'Total loss': 0.7478111584575808}
2022-11-22 20:13:08,392 INFO:     Found new best model at epoch 67
2022-11-22 20:13:08,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:08,393 INFO:     Epoch: 68
2022-11-22 20:13:09,137 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7011876593936573, 'Total loss': 0.7011876593936573} | train loss {'Reaction outcome loss': 0.7426730951484368, 'Total loss': 0.7426730951484368}
2022-11-22 20:13:09,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:09,137 INFO:     Epoch: 69
2022-11-22 20:13:09,855 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6824126020073891, 'Total loss': 0.6824126020073891} | train loss {'Reaction outcome loss': 0.7424933343517537, 'Total loss': 0.7424933343517537}
2022-11-22 20:13:09,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:09,855 INFO:     Epoch: 70
2022-11-22 20:13:10,622 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7106079249219461, 'Total loss': 0.7106079249219461} | train loss {'Reaction outcome loss': 0.7402383924747, 'Total loss': 0.7402383924747}
2022-11-22 20:13:10,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:10,622 INFO:     Epoch: 71
2022-11-22 20:13:11,349 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7034967575560916, 'Total loss': 0.7034967575560916} | train loss {'Reaction outcome loss': 0.7438567977778766, 'Total loss': 0.7438567977778766}
2022-11-22 20:13:11,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:11,350 INFO:     Epoch: 72
2022-11-22 20:13:12,105 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6987936828624118, 'Total loss': 0.6987936828624118} | train loss {'Reaction outcome loss': 0.7360025156517418, 'Total loss': 0.7360025156517418}
2022-11-22 20:13:12,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:12,105 INFO:     Epoch: 73
2022-11-22 20:13:12,844 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.6822011193091219, 'Total loss': 0.6822011193091219} | train loss {'Reaction outcome loss': 0.7260616223422849, 'Total loss': 0.7260616223422849}
2022-11-22 20:13:12,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:12,844 INFO:     Epoch: 74
2022-11-22 20:13:13,635 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.6911505406553095, 'Total loss': 0.6911505406553095} | train loss {'Reaction outcome loss': 0.7390238446848733, 'Total loss': 0.7390238446848733}
2022-11-22 20:13:13,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:13,635 INFO:     Epoch: 75
2022-11-22 20:13:14,403 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.667930120094256, 'Total loss': 0.667930120094256} | train loss {'Reaction outcome loss': 0.7306237158118462, 'Total loss': 0.7306237158118462}
2022-11-22 20:13:14,403 INFO:     Found new best model at epoch 75
2022-11-22 20:13:14,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:14,404 INFO:     Epoch: 76
2022-11-22 20:13:15,154 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.6680496477267959, 'Total loss': 0.6680496477267959} | train loss {'Reaction outcome loss': 0.7280744973494082, 'Total loss': 0.7280744973494082}
2022-11-22 20:13:15,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:15,154 INFO:     Epoch: 77
2022-11-22 20:13:15,919 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.6611355333165689, 'Total loss': 0.6611355333165689} | train loss {'Reaction outcome loss': 0.7257005206176212, 'Total loss': 0.7257005206176212}
2022-11-22 20:13:15,919 INFO:     Found new best model at epoch 77
2022-11-22 20:13:15,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:15,920 INFO:     Epoch: 78
2022-11-22 20:13:16,660 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6457851495255124, 'Total loss': 0.6457851495255124} | train loss {'Reaction outcome loss': 0.7294762999427562, 'Total loss': 0.7294762999427562}
2022-11-22 20:13:16,661 INFO:     Found new best model at epoch 78
2022-11-22 20:13:16,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:16,662 INFO:     Epoch: 79
2022-11-22 20:13:17,381 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6712935275652192, 'Total loss': 0.6712935275652192} | train loss {'Reaction outcome loss': 0.7204756590784812, 'Total loss': 0.7204756590784812}
2022-11-22 20:13:17,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:17,382 INFO:     Epoch: 80
2022-11-22 20:13:18,121 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.6622759354385462, 'Total loss': 0.6622759354385462} | train loss {'Reaction outcome loss': 0.7204666961212547, 'Total loss': 0.7204666961212547}
2022-11-22 20:13:18,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:18,121 INFO:     Epoch: 81
2022-11-22 20:13:18,839 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.695026112551039, 'Total loss': 0.695026112551039} | train loss {'Reaction outcome loss': 0.7255971352664792, 'Total loss': 0.7255971352664792}
2022-11-22 20:13:18,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:18,839 INFO:     Epoch: 82
2022-11-22 20:13:19,587 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.6669999117201025, 'Total loss': 0.6669999117201025} | train loss {'Reaction outcome loss': 0.7269667605964505, 'Total loss': 0.7269667605964505}
2022-11-22 20:13:19,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:19,588 INFO:     Epoch: 83
2022-11-22 20:13:20,354 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6917932121591135, 'Total loss': 0.6917932121591135} | train loss {'Reaction outcome loss': 0.7177757105048822, 'Total loss': 0.7177757105048822}
2022-11-22 20:13:20,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:20,354 INFO:     Epoch: 84
2022-11-22 20:13:21,155 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7070584730668501, 'Total loss': 0.7070584730668501} | train loss {'Reaction outcome loss': 0.7067679604705499, 'Total loss': 0.7067679604705499}
2022-11-22 20:13:21,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:21,156 INFO:     Epoch: 85
2022-11-22 20:13:21,895 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7048124000430107, 'Total loss': 0.7048124000430107} | train loss {'Reaction outcome loss': 0.7151473379256774, 'Total loss': 0.7151473379256774}
2022-11-22 20:13:21,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:21,895 INFO:     Epoch: 86
2022-11-22 20:13:22,628 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.658058877018365, 'Total loss': 0.658058877018365} | train loss {'Reaction outcome loss': 0.7080420155914462, 'Total loss': 0.7080420155914462}
2022-11-22 20:13:22,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:22,628 INFO:     Epoch: 87
2022-11-22 20:13:23,333 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6770917549729347, 'Total loss': 0.6770917549729347} | train loss {'Reaction outcome loss': 0.7118181574101351, 'Total loss': 0.7118181574101351}
2022-11-22 20:13:23,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:23,334 INFO:     Epoch: 88
2022-11-22 20:13:24,066 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7138138819824565, 'Total loss': 0.7138138819824565} | train loss {'Reaction outcome loss': 0.7166245550525432, 'Total loss': 0.7166245550525432}
2022-11-22 20:13:24,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:24,066 INFO:     Epoch: 89
2022-11-22 20:13:24,785 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6515143005685373, 'Total loss': 0.6515143005685373} | train loss {'Reaction outcome loss': 0.7187858236079313, 'Total loss': 0.7187858236079313}
2022-11-22 20:13:24,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:24,785 INFO:     Epoch: 90
2022-11-22 20:13:25,485 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6522001265124842, 'Total loss': 0.6522001265124842} | train loss {'Reaction outcome loss': 0.7134279647651984, 'Total loss': 0.7134279647651984}
2022-11-22 20:13:25,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:25,485 INFO:     Epoch: 91
2022-11-22 20:13:26,210 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.6776931401003491, 'Total loss': 0.6776931401003491} | train loss {'Reaction outcome loss': 0.7104356546183022, 'Total loss': 0.7104356546183022}
2022-11-22 20:13:26,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:26,210 INFO:     Epoch: 92
2022-11-22 20:13:26,923 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6640198616818949, 'Total loss': 0.6640198616818949} | train loss {'Reaction outcome loss': 0.7129860418183463, 'Total loss': 0.7129860418183463}
2022-11-22 20:13:26,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:26,923 INFO:     Epoch: 93
2022-11-22 20:13:27,645 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6921955834735524, 'Total loss': 0.6921955834735524} | train loss {'Reaction outcome loss': 0.705287611910275, 'Total loss': 0.705287611910275}
2022-11-22 20:13:27,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:27,645 INFO:     Epoch: 94
2022-11-22 20:13:28,346 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7038593034852635, 'Total loss': 0.7038593034852635} | train loss {'Reaction outcome loss': 0.7105619082645495, 'Total loss': 0.7105619082645495}
2022-11-22 20:13:28,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:28,346 INFO:     Epoch: 95
2022-11-22 20:13:29,078 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6725937764752995, 'Total loss': 0.6725937764752995} | train loss {'Reaction outcome loss': 0.714757500254378, 'Total loss': 0.714757500254378}
2022-11-22 20:13:29,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:29,078 INFO:     Epoch: 96
2022-11-22 20:13:29,826 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6828878345814619, 'Total loss': 0.6828878345814619} | train loss {'Reaction outcome loss': 0.7092214191446499, 'Total loss': 0.7092214191446499}
2022-11-22 20:13:29,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:29,826 INFO:     Epoch: 97
2022-11-22 20:13:30,542 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6922840015454725, 'Total loss': 0.6922840015454725} | train loss {'Reaction outcome loss': 0.715206160594006, 'Total loss': 0.715206160594006}
2022-11-22 20:13:30,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:30,543 INFO:     Epoch: 98
2022-11-22 20:13:31,268 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6612616249106147, 'Total loss': 0.6612616249106147} | train loss {'Reaction outcome loss': 0.7137857393342621, 'Total loss': 0.7137857393342621}
2022-11-22 20:13:31,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:31,269 INFO:     Epoch: 99
2022-11-22 20:13:31,972 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.661721183495088, 'Total loss': 0.661721183495088} | train loss {'Reaction outcome loss': 0.7150809437644725, 'Total loss': 0.7150809437644725}
2022-11-22 20:13:31,972 INFO:     Best model found after epoch 79 of 100.
2022-11-22 20:13:31,972 INFO:   Done with stage: TRAINING
2022-11-22 20:13:31,972 INFO:   Starting stage: EVALUATION
2022-11-22 20:13:32,096 INFO:   Done with stage: EVALUATION
2022-11-22 20:13:32,096 INFO:   Leaving out SEQ value Fold_3
2022-11-22 20:13:32,110 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:13:32,110 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:13:32,785 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:13:32,785 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:13:32,854 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:13:32,855 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:13:32,855 INFO:     No hyperparam tuning for this model
2022-11-22 20:13:32,855 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:13:32,855 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:13:32,856 INFO:     None feature selector for col prot
2022-11-22 20:13:32,856 INFO:     None feature selector for col prot
2022-11-22 20:13:32,856 INFO:     None feature selector for col prot
2022-11-22 20:13:32,857 INFO:     None feature selector for col chem
2022-11-22 20:13:32,857 INFO:     None feature selector for col chem
2022-11-22 20:13:32,857 INFO:     None feature selector for col chem
2022-11-22 20:13:32,857 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:13:32,857 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:13:32,859 INFO:     Number of params in model 126091
2022-11-22 20:13:32,862 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:13:32,862 INFO:   Starting stage: TRAINING
2022-11-22 20:13:32,911 INFO:     Val loss before train {'Reaction outcome loss': 0.9603982662612741, 'Total loss': 0.9603982662612741}
2022-11-22 20:13:32,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:32,912 INFO:     Epoch: 0
2022-11-22 20:13:33,682 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8303777738050981, 'Total loss': 0.8303777738050981} | train loss {'Reaction outcome loss': 0.8878810281656226, 'Total loss': 0.8878810281656226}
2022-11-22 20:13:33,682 INFO:     Found new best model at epoch 0
2022-11-22 20:13:33,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:33,684 INFO:     Epoch: 1
2022-11-22 20:13:34,430 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8034855276346207, 'Total loss': 0.8034855276346207} | train loss {'Reaction outcome loss': 0.8488545020015872, 'Total loss': 0.8488545020015872}
2022-11-22 20:13:34,430 INFO:     Found new best model at epoch 1
2022-11-22 20:13:34,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:34,431 INFO:     Epoch: 2
2022-11-22 20:13:35,157 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7874332551251758, 'Total loss': 0.7874332551251758} | train loss {'Reaction outcome loss': 0.8355892669181435, 'Total loss': 0.8355892669181435}
2022-11-22 20:13:35,157 INFO:     Found new best model at epoch 2
2022-11-22 20:13:35,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:35,158 INFO:     Epoch: 3
2022-11-22 20:13:35,925 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7905691313472661, 'Total loss': 0.7905691313472661} | train loss {'Reaction outcome loss': 0.8222761953363613, 'Total loss': 0.8222761953363613}
2022-11-22 20:13:35,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:35,926 INFO:     Epoch: 4
2022-11-22 20:13:36,682 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.786169285801324, 'Total loss': 0.786169285801324} | train loss {'Reaction outcome loss': 0.8247156259964924, 'Total loss': 0.8247156259964924}
2022-11-22 20:13:36,682 INFO:     Found new best model at epoch 4
2022-11-22 20:13:36,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:36,683 INFO:     Epoch: 5
2022-11-22 20:13:37,398 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8004488457332958, 'Total loss': 0.8004488457332958} | train loss {'Reaction outcome loss': 0.8180342207149583, 'Total loss': 0.8180342207149583}
2022-11-22 20:13:37,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:37,398 INFO:     Epoch: 6
2022-11-22 20:13:38,149 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.796158139678565, 'Total loss': 0.796158139678565} | train loss {'Reaction outcome loss': 0.8066314391943873, 'Total loss': 0.8066314391943873}
2022-11-22 20:13:38,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:38,149 INFO:     Epoch: 7
2022-11-22 20:13:38,904 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.765769783068787, 'Total loss': 0.765769783068787} | train loss {'Reaction outcome loss': 0.8161332930837358, 'Total loss': 0.8161332930837358}
2022-11-22 20:13:38,905 INFO:     Found new best model at epoch 7
2022-11-22 20:13:38,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:38,905 INFO:     Epoch: 8
2022-11-22 20:13:39,650 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7932296855883165, 'Total loss': 0.7932296855883165} | train loss {'Reaction outcome loss': 0.8062930968342995, 'Total loss': 0.8062930968342995}
2022-11-22 20:13:39,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:39,650 INFO:     Epoch: 9
2022-11-22 20:13:40,398 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7755055630748923, 'Total loss': 0.7755055630748923} | train loss {'Reaction outcome loss': 0.8076363865210086, 'Total loss': 0.8076363865210086}
2022-11-22 20:13:40,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:40,398 INFO:     Epoch: 10
2022-11-22 20:13:41,157 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8011284199627963, 'Total loss': 0.8011284199627963} | train loss {'Reaction outcome loss': 0.8097012916389776, 'Total loss': 0.8097012916389776}
2022-11-22 20:13:41,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:41,157 INFO:     Epoch: 11
2022-11-22 20:13:41,930 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8087115646763281, 'Total loss': 0.8087115646763281} | train loss {'Reaction outcome loss': 0.8033575222200277, 'Total loss': 0.8033575222200277}
2022-11-22 20:13:41,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:41,930 INFO:     Epoch: 12
2022-11-22 20:13:42,679 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7760995484211228, 'Total loss': 0.7760995484211228} | train loss {'Reaction outcome loss': 0.8062620778473056, 'Total loss': 0.8062620778473056}
2022-11-22 20:13:42,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:42,679 INFO:     Epoch: 13
2022-11-22 20:13:43,396 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7806307253512469, 'Total loss': 0.7806307253512469} | train loss {'Reaction outcome loss': 0.8043840590788394, 'Total loss': 0.8043840590788394}
2022-11-22 20:13:43,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:43,396 INFO:     Epoch: 14
2022-11-22 20:13:44,124 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7918715673414144, 'Total loss': 0.7918715673414144} | train loss {'Reaction outcome loss': 0.7999912326433221, 'Total loss': 0.7999912326433221}
2022-11-22 20:13:44,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:44,124 INFO:     Epoch: 15
2022-11-22 20:13:44,847 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7939386750486764, 'Total loss': 0.7939386750486764} | train loss {'Reaction outcome loss': 0.8050648370567633, 'Total loss': 0.8050648370567633}
2022-11-22 20:13:44,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:44,847 INFO:     Epoch: 16
2022-11-22 20:13:45,600 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7714366763830185, 'Total loss': 0.7714366763830185} | train loss {'Reaction outcome loss': 0.8044143519839462, 'Total loss': 0.8044143519839462}
2022-11-22 20:13:45,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:45,600 INFO:     Epoch: 17
2022-11-22 20:13:46,375 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8266312601891431, 'Total loss': 0.8266312601891431} | train loss {'Reaction outcome loss': 0.7993577482749005, 'Total loss': 0.7993577482749005}
2022-11-22 20:13:46,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:46,375 INFO:     Epoch: 18
2022-11-22 20:13:47,103 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7958766276186163, 'Total loss': 0.7958766276186163} | train loss {'Reaction outcome loss': 0.7938245859681343, 'Total loss': 0.7938245859681343}
2022-11-22 20:13:47,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:47,103 INFO:     Epoch: 19
2022-11-22 20:13:47,878 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8135325996713205, 'Total loss': 0.8135325996713205} | train loss {'Reaction outcome loss': 0.8021416670205642, 'Total loss': 0.8021416670205642}
2022-11-22 20:13:47,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:47,880 INFO:     Epoch: 20
2022-11-22 20:13:48,629 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8032901259985837, 'Total loss': 0.8032901259985837} | train loss {'Reaction outcome loss': 0.801050266562676, 'Total loss': 0.801050266562676}
2022-11-22 20:13:48,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:48,629 INFO:     Epoch: 21
2022-11-22 20:13:49,364 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.798640942031687, 'Total loss': 0.798640942031687} | train loss {'Reaction outcome loss': 0.7996391195423749, 'Total loss': 0.7996391195423749}
2022-11-22 20:13:49,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:49,364 INFO:     Epoch: 22
2022-11-22 20:13:50,101 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7836693769151514, 'Total loss': 0.7836693769151514} | train loss {'Reaction outcome loss': 0.8004875863084988, 'Total loss': 0.8004875863084988}
2022-11-22 20:13:50,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:50,101 INFO:     Epoch: 23
2022-11-22 20:13:50,830 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.794689807024869, 'Total loss': 0.794689807024869} | train loss {'Reaction outcome loss': 0.7964166053703853, 'Total loss': 0.7964166053703853}
2022-11-22 20:13:50,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:50,830 INFO:     Epoch: 24
2022-11-22 20:13:51,571 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7955417138609019, 'Total loss': 0.7955417138609019} | train loss {'Reaction outcome loss': 0.7986437433836412, 'Total loss': 0.7986437433836412}
2022-11-22 20:13:51,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:51,571 INFO:     Epoch: 25
2022-11-22 20:13:52,326 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.786849783225493, 'Total loss': 0.786849783225493} | train loss {'Reaction outcome loss': 0.7950961943791837, 'Total loss': 0.7950961943791837}
2022-11-22 20:13:52,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:52,327 INFO:     Epoch: 26
2022-11-22 20:13:53,076 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7633079219270836, 'Total loss': 0.7633079219270836} | train loss {'Reaction outcome loss': 0.8003934153488704, 'Total loss': 0.8003934153488704}
2022-11-22 20:13:53,076 INFO:     Found new best model at epoch 26
2022-11-22 20:13:53,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:53,077 INFO:     Epoch: 27
2022-11-22 20:13:53,819 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7621998861432076, 'Total loss': 0.7621998861432076} | train loss {'Reaction outcome loss': 0.7965965835415587, 'Total loss': 0.7965965835415587}
2022-11-22 20:13:53,819 INFO:     Found new best model at epoch 27
2022-11-22 20:13:53,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:53,820 INFO:     Epoch: 28
2022-11-22 20:13:54,578 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7681756493720141, 'Total loss': 0.7681756493720141} | train loss {'Reaction outcome loss': 0.7978355480700123, 'Total loss': 0.7978355480700123}
2022-11-22 20:13:54,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:54,579 INFO:     Epoch: 29
2022-11-22 20:13:55,280 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7741204865954139, 'Total loss': 0.7741204865954139} | train loss {'Reaction outcome loss': 0.7984514223069561, 'Total loss': 0.7984514223069561}
2022-11-22 20:13:55,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:55,281 INFO:     Epoch: 30
2022-11-22 20:13:56,032 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7552933699705384, 'Total loss': 0.7552933699705384} | train loss {'Reaction outcome loss': 0.7948288364069802, 'Total loss': 0.7948288364069802}
2022-11-22 20:13:56,032 INFO:     Found new best model at epoch 30
2022-11-22 20:13:56,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:56,033 INFO:     Epoch: 31
2022-11-22 20:13:56,766 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7707401784983549, 'Total loss': 0.7707401784983549} | train loss {'Reaction outcome loss': 0.7951223769966437, 'Total loss': 0.7951223769966437}
2022-11-22 20:13:56,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:56,767 INFO:     Epoch: 32
2022-11-22 20:13:57,479 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7984843260862611, 'Total loss': 0.7984843260862611} | train loss {'Reaction outcome loss': 0.7916599278547326, 'Total loss': 0.7916599278547326}
2022-11-22 20:13:57,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:57,479 INFO:     Epoch: 33
2022-11-22 20:13:58,199 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7708424812352116, 'Total loss': 0.7708424812352116} | train loss {'Reaction outcome loss': 0.796584223971075, 'Total loss': 0.796584223971075}
2022-11-22 20:13:58,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:58,199 INFO:     Epoch: 34
2022-11-22 20:13:58,955 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7912645875052973, 'Total loss': 0.7912645875052973} | train loss {'Reaction outcome loss': 0.7981725310792729, 'Total loss': 0.7981725310792729}
2022-11-22 20:13:58,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:58,955 INFO:     Epoch: 35
2022-11-22 20:13:59,686 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7678294710137628, 'Total loss': 0.7678294710137628} | train loss {'Reaction outcome loss': 0.7956062281618312, 'Total loss': 0.7956062281618312}
2022-11-22 20:13:59,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:13:59,686 INFO:     Epoch: 36
2022-11-22 20:14:00,416 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7692092420025305, 'Total loss': 0.7692092420025305} | train loss {'Reaction outcome loss': 0.7912729567410994, 'Total loss': 0.7912729567410994}
2022-11-22 20:14:00,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:00,416 INFO:     Epoch: 37
2022-11-22 20:14:01,159 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7600411418825388, 'Total loss': 0.7600411418825388} | train loss {'Reaction outcome loss': 0.7955101903604002, 'Total loss': 0.7955101903604002}
2022-11-22 20:14:01,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:01,159 INFO:     Epoch: 38
2022-11-22 20:14:01,893 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7911741002039476, 'Total loss': 0.7911741002039476} | train loss {'Reaction outcome loss': 0.7903371118769353, 'Total loss': 0.7903371118769353}
2022-11-22 20:14:01,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:01,893 INFO:     Epoch: 39
2022-11-22 20:14:02,665 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7505019537427209, 'Total loss': 0.7505019537427209} | train loss {'Reaction outcome loss': 0.791567077198807, 'Total loss': 0.791567077198807}
2022-11-22 20:14:02,665 INFO:     Found new best model at epoch 39
2022-11-22 20:14:02,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:02,666 INFO:     Epoch: 40
2022-11-22 20:14:03,404 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7950951683927666, 'Total loss': 0.7950951683927666} | train loss {'Reaction outcome loss': 0.7926008754847002, 'Total loss': 0.7926008754847002}
2022-11-22 20:14:03,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:03,404 INFO:     Epoch: 41
2022-11-22 20:14:04,146 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7747142416509715, 'Total loss': 0.7747142416509715} | train loss {'Reaction outcome loss': 0.7930754935254856, 'Total loss': 0.7930754935254856}
2022-11-22 20:14:04,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:04,147 INFO:     Epoch: 42
2022-11-22 20:14:04,871 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7870890985835682, 'Total loss': 0.7870890985835682} | train loss {'Reaction outcome loss': 0.7921670828546796, 'Total loss': 0.7921670828546796}
2022-11-22 20:14:04,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:04,871 INFO:     Epoch: 43
2022-11-22 20:14:05,602 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7816822061484511, 'Total loss': 0.7816822061484511} | train loss {'Reaction outcome loss': 0.7959513666070237, 'Total loss': 0.7959513666070237}
2022-11-22 20:14:05,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:05,603 INFO:     Epoch: 44
2022-11-22 20:14:06,341 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7679019102996046, 'Total loss': 0.7679019102996046} | train loss {'Reaction outcome loss': 0.7915277661109458, 'Total loss': 0.7915277661109458}
2022-11-22 20:14:06,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:06,341 INFO:     Epoch: 45
2022-11-22 20:14:07,085 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7618370205163956, 'Total loss': 0.7618370205163956} | train loss {'Reaction outcome loss': 0.7910751047183057, 'Total loss': 0.7910751047183057}
2022-11-22 20:14:07,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:07,086 INFO:     Epoch: 46
2022-11-22 20:14:07,793 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7594634399495341, 'Total loss': 0.7594634399495341} | train loss {'Reaction outcome loss': 0.7874230646357244, 'Total loss': 0.7874230646357244}
2022-11-22 20:14:07,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:07,793 INFO:     Epoch: 47
2022-11-22 20:14:08,476 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7914710518988696, 'Total loss': 0.7914710518988696} | train loss {'Reaction outcome loss': 0.791138792159606, 'Total loss': 0.791138792159606}
2022-11-22 20:14:08,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:08,477 INFO:     Epoch: 48
2022-11-22 20:14:09,231 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7663418000394647, 'Total loss': 0.7663418000394647} | train loss {'Reaction outcome loss': 0.7928306828956215, 'Total loss': 0.7928306828956215}
2022-11-22 20:14:09,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:09,232 INFO:     Epoch: 49
2022-11-22 20:14:09,986 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.804110203276981, 'Total loss': 0.804110203276981} | train loss {'Reaction outcome loss': 0.7913999769152428, 'Total loss': 0.7913999769152428}
2022-11-22 20:14:09,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:09,986 INFO:     Epoch: 50
2022-11-22 20:14:10,761 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7779540853066877, 'Total loss': 0.7779540853066877} | train loss {'Reaction outcome loss': 0.7904717034223129, 'Total loss': 0.7904717034223129}
2022-11-22 20:14:10,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:10,761 INFO:     Epoch: 51
2022-11-22 20:14:11,499 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.781492062590339, 'Total loss': 0.781492062590339} | train loss {'Reaction outcome loss': 0.7927387608557331, 'Total loss': 0.7927387608557331}
2022-11-22 20:14:11,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:11,499 INFO:     Epoch: 52
2022-11-22 20:14:12,276 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7875124277039007, 'Total loss': 0.7875124277039007} | train loss {'Reaction outcome loss': 0.7885922782883352, 'Total loss': 0.7885922782883352}
2022-11-22 20:14:12,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:12,276 INFO:     Epoch: 53
2022-11-22 20:14:13,014 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7766313451257619, 'Total loss': 0.7766313451257619} | train loss {'Reaction outcome loss': 0.7889980955999725, 'Total loss': 0.7889980955999725}
2022-11-22 20:14:13,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:13,015 INFO:     Epoch: 54
2022-11-22 20:14:13,779 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7893492850390348, 'Total loss': 0.7893492850390348} | train loss {'Reaction outcome loss': 0.7897237038125797, 'Total loss': 0.7897237038125797}
2022-11-22 20:14:13,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:13,779 INFO:     Epoch: 55
2022-11-22 20:14:14,517 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7844962172887542, 'Total loss': 0.7844962172887542} | train loss {'Reaction outcome loss': 0.7879734538039382, 'Total loss': 0.7879734538039382}
2022-11-22 20:14:14,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:14,517 INFO:     Epoch: 56
2022-11-22 20:14:15,247 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7784857015040788, 'Total loss': 0.7784857015040788} | train loss {'Reaction outcome loss': 0.7861814169251189, 'Total loss': 0.7861814169251189}
2022-11-22 20:14:15,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:15,247 INFO:     Epoch: 57
2022-11-22 20:14:16,052 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7757012884725224, 'Total loss': 0.7757012884725224} | train loss {'Reaction outcome loss': 0.7863073145856663, 'Total loss': 0.7863073145856663}
2022-11-22 20:14:16,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:16,052 INFO:     Epoch: 58
2022-11-22 20:14:16,845 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7832974717020988, 'Total loss': 0.7832974717020988} | train loss {'Reaction outcome loss': 0.7849743721436481, 'Total loss': 0.7849743721436481}
2022-11-22 20:14:16,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:16,845 INFO:     Epoch: 59
2022-11-22 20:14:17,579 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7796003513715484, 'Total loss': 0.7796003513715484} | train loss {'Reaction outcome loss': 0.7846084432942527, 'Total loss': 0.7846084432942527}
2022-11-22 20:14:17,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:17,580 INFO:     Epoch: 60
2022-11-22 20:14:18,304 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.754217687655579, 'Total loss': 0.754217687655579} | train loss {'Reaction outcome loss': 0.787017695271239, 'Total loss': 0.787017695271239}
2022-11-22 20:14:18,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:18,305 INFO:     Epoch: 61
2022-11-22 20:14:19,062 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7672151245854117, 'Total loss': 0.7672151245854117} | train loss {'Reaction outcome loss': 0.7813178762489436, 'Total loss': 0.7813178762489436}
2022-11-22 20:14:19,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:19,064 INFO:     Epoch: 62
2022-11-22 20:14:19,799 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7592519013719126, 'Total loss': 0.7592519013719126} | train loss {'Reaction outcome loss': 0.7903954265068989, 'Total loss': 0.7903954265068989}
2022-11-22 20:14:19,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:19,799 INFO:     Epoch: 63
2022-11-22 20:14:20,534 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7737812494689768, 'Total loss': 0.7737812494689768} | train loss {'Reaction outcome loss': 0.7858473130634853, 'Total loss': 0.7858473130634853}
2022-11-22 20:14:20,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:20,535 INFO:     Epoch: 64
2022-11-22 20:14:21,238 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7767412080006166, 'Total loss': 0.7767412080006166} | train loss {'Reaction outcome loss': 0.7810616245075148, 'Total loss': 0.7810616245075148}
2022-11-22 20:14:21,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:21,239 INFO:     Epoch: 65
2022-11-22 20:14:21,976 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8013504350727255, 'Total loss': 0.8013504350727255} | train loss {'Reaction outcome loss': 0.7828666103129485, 'Total loss': 0.7828666103129485}
2022-11-22 20:14:21,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:21,976 INFO:     Epoch: 66
2022-11-22 20:14:22,758 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7890892990610816, 'Total loss': 0.7890892990610816} | train loss {'Reaction outcome loss': 0.7864176801272801, 'Total loss': 0.7864176801272801}
2022-11-22 20:14:22,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:22,758 INFO:     Epoch: 67
2022-11-22 20:14:23,465 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.772749585184184, 'Total loss': 0.772749585184184} | train loss {'Reaction outcome loss': 0.7804814420184311, 'Total loss': 0.7804814420184311}
2022-11-22 20:14:23,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:23,465 INFO:     Epoch: 68
2022-11-22 20:14:24,236 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7484982745213942, 'Total loss': 0.7484982745213942} | train loss {'Reaction outcome loss': 0.7836769953065988, 'Total loss': 0.7836769953065988}
2022-11-22 20:14:24,236 INFO:     Found new best model at epoch 68
2022-11-22 20:14:24,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:24,237 INFO:     Epoch: 69
2022-11-22 20:14:24,974 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7475537684830752, 'Total loss': 0.7475537684830752} | train loss {'Reaction outcome loss': 0.7775219807819445, 'Total loss': 0.7775219807819445}
2022-11-22 20:14:24,974 INFO:     Found new best model at epoch 69
2022-11-22 20:14:24,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:24,975 INFO:     Epoch: 70
2022-11-22 20:14:25,708 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7712859843264926, 'Total loss': 0.7712859843264926} | train loss {'Reaction outcome loss': 0.7793643059779186, 'Total loss': 0.7793643059779186}
2022-11-22 20:14:25,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:25,709 INFO:     Epoch: 71
2022-11-22 20:14:26,431 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7619994113391096, 'Total loss': 0.7619994113391096} | train loss {'Reaction outcome loss': 0.7766280479577123, 'Total loss': 0.7766280479577123}
2022-11-22 20:14:26,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:26,432 INFO:     Epoch: 72
2022-11-22 20:14:27,167 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7582114948467775, 'Total loss': 0.7582114948467775} | train loss {'Reaction outcome loss': 0.7736311798193016, 'Total loss': 0.7736311798193016}
2022-11-22 20:14:27,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:27,167 INFO:     Epoch: 73
2022-11-22 20:14:27,895 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7610118548301134, 'Total loss': 0.7610118548301134} | train loss {'Reaction outcome loss': 0.7703308453365248, 'Total loss': 0.7703308453365248}
2022-11-22 20:14:27,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:27,896 INFO:     Epoch: 74
2022-11-22 20:14:28,631 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7622899386015806, 'Total loss': 0.7622899386015806} | train loss {'Reaction outcome loss': 0.7728254289043193, 'Total loss': 0.7728254289043193}
2022-11-22 20:14:28,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:28,631 INFO:     Epoch: 75
2022-11-22 20:14:29,386 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7550756992264227, 'Total loss': 0.7550756992264227} | train loss {'Reaction outcome loss': 0.77395312883416, 'Total loss': 0.77395312883416}
2022-11-22 20:14:29,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:29,386 INFO:     Epoch: 76
2022-11-22 20:14:30,133 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7701646502722393, 'Total loss': 0.7701646502722393} | train loss {'Reaction outcome loss': 0.7747730918076574, 'Total loss': 0.7747730918076574}
2022-11-22 20:14:30,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:30,133 INFO:     Epoch: 77
2022-11-22 20:14:30,908 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7563336003910411, 'Total loss': 0.7563336003910411} | train loss {'Reaction outcome loss': 0.7782065134875629, 'Total loss': 0.7782065134875629}
2022-11-22 20:14:30,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:30,909 INFO:     Epoch: 78
2022-11-22 20:14:31,633 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7585638030008837, 'Total loss': 0.7585638030008837} | train loss {'Reaction outcome loss': 0.7745270840975703, 'Total loss': 0.7745270840975703}
2022-11-22 20:14:31,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:31,634 INFO:     Epoch: 79
2022-11-22 20:14:32,391 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7517462738535621, 'Total loss': 0.7517462738535621} | train loss {'Reaction outcome loss': 0.7726575878201699, 'Total loss': 0.7726575878201699}
2022-11-22 20:14:32,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:32,391 INFO:     Epoch: 80
2022-11-22 20:14:33,124 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7385473576459017, 'Total loss': 0.7385473576459017} | train loss {'Reaction outcome loss': 0.7642046354254898, 'Total loss': 0.7642046354254898}
2022-11-22 20:14:33,124 INFO:     Found new best model at epoch 80
2022-11-22 20:14:33,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:33,125 INFO:     Epoch: 81
2022-11-22 20:14:33,899 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7542580250989307, 'Total loss': 0.7542580250989307} | train loss {'Reaction outcome loss': 0.7706864236568918, 'Total loss': 0.7706864236568918}
2022-11-22 20:14:33,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:33,899 INFO:     Epoch: 82
2022-11-22 20:14:34,672 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7411389039321379, 'Total loss': 0.7411389039321379} | train loss {'Reaction outcome loss': 0.7673178249475907, 'Total loss': 0.7673178249475907}
2022-11-22 20:14:34,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:34,672 INFO:     Epoch: 83
2022-11-22 20:14:35,453 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7803790311921727, 'Total loss': 0.7803790311921727} | train loss {'Reaction outcome loss': 0.7648430509226662, 'Total loss': 0.7648430509226662}
2022-11-22 20:14:35,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:35,454 INFO:     Epoch: 84
2022-11-22 20:14:36,180 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7511786134405569, 'Total loss': 0.7511786134405569} | train loss {'Reaction outcome loss': 0.7707502855330097, 'Total loss': 0.7707502855330097}
2022-11-22 20:14:36,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:36,180 INFO:     Epoch: 85
2022-11-22 20:14:36,926 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7489973272789608, 'Total loss': 0.7489973272789608} | train loss {'Reaction outcome loss': 0.7586638181793447, 'Total loss': 0.7586638181793447}
2022-11-22 20:14:36,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:36,926 INFO:     Epoch: 86
2022-11-22 20:14:37,687 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7512718920003284, 'Total loss': 0.7512718920003284} | train loss {'Reaction outcome loss': 0.7567427281214266, 'Total loss': 0.7567427281214266}
2022-11-22 20:14:37,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:37,688 INFO:     Epoch: 87
2022-11-22 20:14:38,478 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7457035420970484, 'Total loss': 0.7457035420970484} | train loss {'Reaction outcome loss': 0.7550358773494253, 'Total loss': 0.7550358773494253}
2022-11-22 20:14:38,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:38,479 INFO:     Epoch: 88
2022-11-22 20:14:39,257 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7270450896837495, 'Total loss': 0.7270450896837495} | train loss {'Reaction outcome loss': 0.7593465009514166, 'Total loss': 0.7593465009514166}
2022-11-22 20:14:39,257 INFO:     Found new best model at epoch 88
2022-11-22 20:14:39,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:39,258 INFO:     Epoch: 89
2022-11-22 20:14:40,028 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7824538323012266, 'Total loss': 0.7824538323012266} | train loss {'Reaction outcome loss': 0.7519359979094291, 'Total loss': 0.7519359979094291}
2022-11-22 20:14:40,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:40,029 INFO:     Epoch: 90
2022-11-22 20:14:40,756 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7771078415892341, 'Total loss': 0.7771078415892341} | train loss {'Reaction outcome loss': 0.7590206615778865, 'Total loss': 0.7590206615778865}
2022-11-22 20:14:40,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:40,756 INFO:     Epoch: 91
2022-11-22 20:14:41,499 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7361037358641624, 'Total loss': 0.7361037358641624} | train loss {'Reaction outcome loss': 0.7571916259064966, 'Total loss': 0.7571916259064966}
2022-11-22 20:14:41,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:41,500 INFO:     Epoch: 92
2022-11-22 20:14:42,248 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7415761825713244, 'Total loss': 0.7415761825713244} | train loss {'Reaction outcome loss': 0.7483108740680072, 'Total loss': 0.7483108740680072}
2022-11-22 20:14:42,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:42,248 INFO:     Epoch: 93
2022-11-22 20:14:43,020 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7408998232673515, 'Total loss': 0.7408998232673515} | train loss {'Reaction outcome loss': 0.7472817791967976, 'Total loss': 0.7472817791967976}
2022-11-22 20:14:43,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:43,020 INFO:     Epoch: 94
2022-11-22 20:14:43,780 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7670930908484892, 'Total loss': 0.7670930908484892} | train loss {'Reaction outcome loss': 0.756974448476519, 'Total loss': 0.756974448476519}
2022-11-22 20:14:43,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:43,780 INFO:     Epoch: 95
2022-11-22 20:14:44,540 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7335183464668014, 'Total loss': 0.7335183464668014} | train loss {'Reaction outcome loss': 0.7461262108111868, 'Total loss': 0.7461262108111868}
2022-11-22 20:14:44,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:44,541 INFO:     Epoch: 96
2022-11-22 20:14:45,257 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.731770245866342, 'Total loss': 0.731770245866342} | train loss {'Reaction outcome loss': 0.7458340469671756, 'Total loss': 0.7458340469671756}
2022-11-22 20:14:45,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:45,257 INFO:     Epoch: 97
2022-11-22 20:14:46,032 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7013626240871169, 'Total loss': 0.7013626240871169} | train loss {'Reaction outcome loss': 0.7431531549108271, 'Total loss': 0.7431531549108271}
2022-11-22 20:14:46,033 INFO:     Found new best model at epoch 97
2022-11-22 20:14:46,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:46,033 INFO:     Epoch: 98
2022-11-22 20:14:46,773 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7472848201339896, 'Total loss': 0.7472848201339896} | train loss {'Reaction outcome loss': 0.7399252229807328, 'Total loss': 0.7399252229807328}
2022-11-22 20:14:46,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:46,774 INFO:     Epoch: 99
2022-11-22 20:14:47,518 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7303836894306269, 'Total loss': 0.7303836894306269} | train loss {'Reaction outcome loss': 0.7361953399619278, 'Total loss': 0.7361953399619278}
2022-11-22 20:14:47,518 INFO:     Best model found after epoch 98 of 100.
2022-11-22 20:14:47,519 INFO:   Done with stage: TRAINING
2022-11-22 20:14:47,519 INFO:   Starting stage: EVALUATION
2022-11-22 20:14:47,644 INFO:   Done with stage: EVALUATION
2022-11-22 20:14:47,644 INFO:   Leaving out SEQ value Fold_4
2022-11-22 20:14:47,657 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:14:47,657 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:14:48,339 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:14:48,339 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:14:48,409 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:14:48,409 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:14:48,409 INFO:     No hyperparam tuning for this model
2022-11-22 20:14:48,409 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:14:48,409 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:14:48,410 INFO:     None feature selector for col prot
2022-11-22 20:14:48,410 INFO:     None feature selector for col prot
2022-11-22 20:14:48,410 INFO:     None feature selector for col prot
2022-11-22 20:14:48,411 INFO:     None feature selector for col chem
2022-11-22 20:14:48,411 INFO:     None feature selector for col chem
2022-11-22 20:14:48,411 INFO:     None feature selector for col chem
2022-11-22 20:14:48,411 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:14:48,412 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:14:48,413 INFO:     Number of params in model 126091
2022-11-22 20:14:48,416 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:14:48,416 INFO:   Starting stage: TRAINING
2022-11-22 20:14:48,466 INFO:     Val loss before train {'Reaction outcome loss': 0.9764495654539629, 'Total loss': 0.9764495654539629}
2022-11-22 20:14:48,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:48,466 INFO:     Epoch: 0
2022-11-22 20:14:49,224 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8230208600447937, 'Total loss': 0.8230208600447937} | train loss {'Reaction outcome loss': 0.8741367600402054, 'Total loss': 0.8741367600402054}
2022-11-22 20:14:49,224 INFO:     Found new best model at epoch 0
2022-11-22 20:14:49,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:49,225 INFO:     Epoch: 1
2022-11-22 20:14:49,984 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8134080171585083, 'Total loss': 0.8134080171585083} | train loss {'Reaction outcome loss': 0.8345864828752012, 'Total loss': 0.8345864828752012}
2022-11-22 20:14:49,985 INFO:     Found new best model at epoch 1
2022-11-22 20:14:49,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:49,986 INFO:     Epoch: 2
2022-11-22 20:14:50,700 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.830538503148339, 'Total loss': 0.830538503148339} | train loss {'Reaction outcome loss': 0.8214955677791518, 'Total loss': 0.8214955677791518}
2022-11-22 20:14:50,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:50,701 INFO:     Epoch: 3
2022-11-22 20:14:51,462 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7788990099321712, 'Total loss': 0.7788990099321712} | train loss {'Reaction outcome loss': 0.8174433730086502, 'Total loss': 0.8174433730086502}
2022-11-22 20:14:51,462 INFO:     Found new best model at epoch 3
2022-11-22 20:14:51,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:51,463 INFO:     Epoch: 4
2022-11-22 20:14:52,213 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7920821817083792, 'Total loss': 0.7920821817083792} | train loss {'Reaction outcome loss': 0.8132503527767804, 'Total loss': 0.8132503527767804}
2022-11-22 20:14:52,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:52,213 INFO:     Epoch: 5
2022-11-22 20:14:52,942 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8000737591223284, 'Total loss': 0.8000737591223284} | train loss {'Reaction outcome loss': 0.8031042612328821, 'Total loss': 0.8031042612328821}
2022-11-22 20:14:52,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:52,942 INFO:     Epoch: 6
2022-11-22 20:14:53,685 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7848752080039545, 'Total loss': 0.7848752080039545} | train loss {'Reaction outcome loss': 0.799327786966246, 'Total loss': 0.799327786966246}
2022-11-22 20:14:53,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:53,685 INFO:     Epoch: 7
2022-11-22 20:14:54,438 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7704671865159815, 'Total loss': 0.7704671865159815} | train loss {'Reaction outcome loss': 0.7977902771258841, 'Total loss': 0.7977902771258841}
2022-11-22 20:14:54,439 INFO:     Found new best model at epoch 7
2022-11-22 20:14:54,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:54,440 INFO:     Epoch: 8
2022-11-22 20:14:55,158 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7505393407561562, 'Total loss': 0.7505393407561562} | train loss {'Reaction outcome loss': 0.796810129588964, 'Total loss': 0.796810129588964}
2022-11-22 20:14:55,158 INFO:     Found new best model at epoch 8
2022-11-22 20:14:55,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:55,159 INFO:     Epoch: 9
2022-11-22 20:14:55,945 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.763734417205507, 'Total loss': 0.763734417205507} | train loss {'Reaction outcome loss': 0.7995288729667663, 'Total loss': 0.7995288729667663}
2022-11-22 20:14:55,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:55,945 INFO:     Epoch: 10
2022-11-22 20:14:56,751 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7697096196087924, 'Total loss': 0.7697096196087924} | train loss {'Reaction outcome loss': 0.7994923670681156, 'Total loss': 0.7994923670681156}
2022-11-22 20:14:56,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:56,752 INFO:     Epoch: 11
2022-11-22 20:14:57,534 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7918870611624285, 'Total loss': 0.7918870611624285} | train loss {'Reaction outcome loss': 0.7899053801079186, 'Total loss': 0.7899053801079186}
2022-11-22 20:14:57,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:57,535 INFO:     Epoch: 12
2022-11-22 20:14:58,321 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7778825692155145, 'Total loss': 0.7778825692155145} | train loss {'Reaction outcome loss': 0.7918370878209873, 'Total loss': 0.7918370878209873}
2022-11-22 20:14:58,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:58,321 INFO:     Epoch: 13
2022-11-22 20:14:59,076 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7610271634026007, 'Total loss': 0.7610271634026007} | train loss {'Reaction outcome loss': 0.7846029884961186, 'Total loss': 0.7846029884961186}
2022-11-22 20:14:59,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:59,076 INFO:     Epoch: 14
2022-11-22 20:14:59,811 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7592517225579782, 'Total loss': 0.7592517225579782} | train loss {'Reaction outcome loss': 0.7871933074630036, 'Total loss': 0.7871933074630036}
2022-11-22 20:14:59,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:14:59,811 INFO:     Epoch: 15
2022-11-22 20:15:00,585 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7533970414237543, 'Total loss': 0.7533970414237543} | train loss {'Reaction outcome loss': 0.7870924085986858, 'Total loss': 0.7870924085986858}
2022-11-22 20:15:00,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:00,585 INFO:     Epoch: 16
2022-11-22 20:15:01,348 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7733411057428881, 'Total loss': 0.7733411057428881} | train loss {'Reaction outcome loss': 0.7873513435830876, 'Total loss': 0.7873513435830876}
2022-11-22 20:15:01,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:01,348 INFO:     Epoch: 17
2022-11-22 20:15:02,073 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7656598680398681, 'Total loss': 0.7656598680398681} | train loss {'Reaction outcome loss': 0.7860545634006967, 'Total loss': 0.7860545634006967}
2022-11-22 20:15:02,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:02,073 INFO:     Epoch: 18
2022-11-22 20:15:02,836 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8008086803284559, 'Total loss': 0.8008086803284559} | train loss {'Reaction outcome loss': 0.7877655821187156, 'Total loss': 0.7877655821187156}
2022-11-22 20:15:02,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:02,836 INFO:     Epoch: 19
2022-11-22 20:15:03,565 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7512587200511586, 'Total loss': 0.7512587200511586} | train loss {'Reaction outcome loss': 0.7815600206657332, 'Total loss': 0.7815600206657332}
2022-11-22 20:15:03,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:03,565 INFO:     Epoch: 20
2022-11-22 20:15:04,363 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.75944645838304, 'Total loss': 0.75944645838304} | train loss {'Reaction outcome loss': 0.7836672509203152, 'Total loss': 0.7836672509203152}
2022-11-22 20:15:04,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:04,363 INFO:     Epoch: 21
2022-11-22 20:15:05,110 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.767849551005797, 'Total loss': 0.767849551005797} | train loss {'Reaction outcome loss': 0.787397187096732, 'Total loss': 0.787397187096732}
2022-11-22 20:15:05,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:05,110 INFO:     Epoch: 22
2022-11-22 20:15:05,844 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7445831488479268, 'Total loss': 0.7445831488479268} | train loss {'Reaction outcome loss': 0.7842526947965427, 'Total loss': 0.7842526947965427}
2022-11-22 20:15:05,844 INFO:     Found new best model at epoch 22
2022-11-22 20:15:05,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:05,845 INFO:     Epoch: 23
2022-11-22 20:15:06,573 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7481249448927966, 'Total loss': 0.7481249448927966} | train loss {'Reaction outcome loss': 0.7817114799606557, 'Total loss': 0.7817114799606557}
2022-11-22 20:15:06,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:06,573 INFO:     Epoch: 24
2022-11-22 20:15:07,296 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7588871656493708, 'Total loss': 0.7588871656493708} | train loss {'Reaction outcome loss': 0.7812070994352808, 'Total loss': 0.7812070994352808}
2022-11-22 20:15:07,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:07,296 INFO:     Epoch: 25
2022-11-22 20:15:08,022 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.776485798033801, 'Total loss': 0.776485798033801} | train loss {'Reaction outcome loss': 0.782558172089713, 'Total loss': 0.782558172089713}
2022-11-22 20:15:08,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:08,023 INFO:     Epoch: 26
2022-11-22 20:15:08,788 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7470998665825888, 'Total loss': 0.7470998665825888} | train loss {'Reaction outcome loss': 0.7811816087182687, 'Total loss': 0.7811816087182687}
2022-11-22 20:15:08,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:08,789 INFO:     Epoch: 27
2022-11-22 20:15:09,537 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7676162801005624, 'Total loss': 0.7676162801005624} | train loss {'Reaction outcome loss': 0.7813450610151096, 'Total loss': 0.7813450610151096}
2022-11-22 20:15:09,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:09,537 INFO:     Epoch: 28
2022-11-22 20:15:10,301 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7459154372865503, 'Total loss': 0.7459154372865503} | train loss {'Reaction outcome loss': 0.7744674297011629, 'Total loss': 0.7744674297011629}
2022-11-22 20:15:10,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:10,302 INFO:     Epoch: 29
2022-11-22 20:15:11,027 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7658634985035117, 'Total loss': 0.7658634985035117} | train loss {'Reaction outcome loss': 0.7820765355411841, 'Total loss': 0.7820765355411841}
2022-11-22 20:15:11,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:11,027 INFO:     Epoch: 30
2022-11-22 20:15:11,755 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.787230754440481, 'Total loss': 0.787230754440481} | train loss {'Reaction outcome loss': 0.7736678953681674, 'Total loss': 0.7736678953681674}
2022-11-22 20:15:11,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:11,756 INFO:     Epoch: 31
2022-11-22 20:15:12,524 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7625171826644377, 'Total loss': 0.7625171826644377} | train loss {'Reaction outcome loss': 0.7777610745965218, 'Total loss': 0.7777610745965218}
2022-11-22 20:15:12,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:12,524 INFO:     Epoch: 32
2022-11-22 20:15:13,323 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7824850292368368, 'Total loss': 0.7824850292368368} | train loss {'Reaction outcome loss': 0.7779674377976632, 'Total loss': 0.7779674377976632}
2022-11-22 20:15:13,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:13,323 INFO:     Epoch: 33
2022-11-22 20:15:14,050 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7695020620118488, 'Total loss': 0.7695020620118488} | train loss {'Reaction outcome loss': 0.7756021336633332, 'Total loss': 0.7756021336633332}
2022-11-22 20:15:14,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:14,050 INFO:     Epoch: 34
2022-11-22 20:15:14,832 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7691967975009572, 'Total loss': 0.7691967975009572} | train loss {'Reaction outcome loss': 0.7741463155162578, 'Total loss': 0.7741463155162578}
2022-11-22 20:15:14,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:14,832 INFO:     Epoch: 35
2022-11-22 20:15:15,580 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7377563146027651, 'Total loss': 0.7377563146027651} | train loss {'Reaction outcome loss': 0.7808353075567557, 'Total loss': 0.7808353075567557}
2022-11-22 20:15:15,580 INFO:     Found new best model at epoch 35
2022-11-22 20:15:15,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:15,582 INFO:     Epoch: 36
2022-11-22 20:15:16,329 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7662450359626249, 'Total loss': 0.7662450359626249} | train loss {'Reaction outcome loss': 0.7759987565935874, 'Total loss': 0.7759987565935874}
2022-11-22 20:15:16,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:16,329 INFO:     Epoch: 37
2022-11-22 20:15:17,026 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7429456040263176, 'Total loss': 0.7429456040263176} | train loss {'Reaction outcome loss': 0.777603119490098, 'Total loss': 0.777603119490098}
2022-11-22 20:15:17,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:17,026 INFO:     Epoch: 38
2022-11-22 20:15:17,779 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7578730149702593, 'Total loss': 0.7578730149702593} | train loss {'Reaction outcome loss': 0.7764772233914355, 'Total loss': 0.7764772233914355}
2022-11-22 20:15:17,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:17,779 INFO:     Epoch: 39
2022-11-22 20:15:18,532 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7763849700039084, 'Total loss': 0.7763849700039084} | train loss {'Reaction outcome loss': 0.7706229029869547, 'Total loss': 0.7706229029869547}
2022-11-22 20:15:18,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:18,532 INFO:     Epoch: 40
2022-11-22 20:15:19,252 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8204157054424286, 'Total loss': 0.8204157054424286} | train loss {'Reaction outcome loss': 0.7701377414927191, 'Total loss': 0.7701377414927191}
2022-11-22 20:15:19,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:19,252 INFO:     Epoch: 41
2022-11-22 20:15:20,018 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7770567624406381, 'Total loss': 0.7770567624406381} | train loss {'Reaction outcome loss': 0.7780501467841012, 'Total loss': 0.7780501467841012}
2022-11-22 20:15:20,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:20,018 INFO:     Epoch: 42
2022-11-22 20:15:20,719 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.765687423673543, 'Total loss': 0.765687423673543} | train loss {'Reaction outcome loss': 0.7749076790955602, 'Total loss': 0.7749076790955602}
2022-11-22 20:15:20,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:20,720 INFO:     Epoch: 43
2022-11-22 20:15:21,446 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7469896403225985, 'Total loss': 0.7469896403225985} | train loss {'Reaction outcome loss': 0.7705350225069085, 'Total loss': 0.7705350225069085}
2022-11-22 20:15:21,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:21,447 INFO:     Epoch: 44
2022-11-22 20:15:22,202 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7595150247216225, 'Total loss': 0.7595150247216225} | train loss {'Reaction outcome loss': 0.7702421760072513, 'Total loss': 0.7702421760072513}
2022-11-22 20:15:22,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:22,202 INFO:     Epoch: 45
2022-11-22 20:15:22,915 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7978666255419905, 'Total loss': 0.7978666255419905} | train loss {'Reaction outcome loss': 0.7701372678182563, 'Total loss': 0.7701372678182563}
2022-11-22 20:15:22,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:22,916 INFO:     Epoch: 46
2022-11-22 20:15:23,624 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7442641261626374, 'Total loss': 0.7442641261626374} | train loss {'Reaction outcome loss': 0.7771178328261084, 'Total loss': 0.7771178328261084}
2022-11-22 20:15:23,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:23,624 INFO:     Epoch: 47
2022-11-22 20:15:24,377 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7877072122963992, 'Total loss': 0.7877072122963992} | train loss {'Reaction outcome loss': 0.7663859948819998, 'Total loss': 0.7663859948819998}
2022-11-22 20:15:24,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:24,377 INFO:     Epoch: 48
2022-11-22 20:15:25,104 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7540344853292812, 'Total loss': 0.7540344853292812} | train loss {'Reaction outcome loss': 0.7629895884163526, 'Total loss': 0.7629895884163526}
2022-11-22 20:15:25,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:25,104 INFO:     Epoch: 49
2022-11-22 20:15:25,847 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7351819849149748, 'Total loss': 0.7351819849149748} | train loss {'Reaction outcome loss': 0.7631864192534467, 'Total loss': 0.7631864192534467}
2022-11-22 20:15:25,848 INFO:     Found new best model at epoch 49
2022-11-22 20:15:25,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:25,848 INFO:     Epoch: 50
2022-11-22 20:15:26,574 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7374258271672509, 'Total loss': 0.7374258271672509} | train loss {'Reaction outcome loss': 0.7616099883098991, 'Total loss': 0.7616099883098991}
2022-11-22 20:15:26,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:26,574 INFO:     Epoch: 51
2022-11-22 20:15:27,314 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7577699429609559, 'Total loss': 0.7577699429609559} | train loss {'Reaction outcome loss': 0.7621437133574972, 'Total loss': 0.7621437133574972}
2022-11-22 20:15:27,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:27,315 INFO:     Epoch: 52
2022-11-22 20:15:28,042 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7505752125924284, 'Total loss': 0.7505752125924284} | train loss {'Reaction outcome loss': 0.7511572600627432, 'Total loss': 0.7511572600627432}
2022-11-22 20:15:28,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:28,043 INFO:     Epoch: 53
2022-11-22 20:15:28,747 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7426744631745599, 'Total loss': 0.7426744631745599} | train loss {'Reaction outcome loss': 0.7533985072252701, 'Total loss': 0.7533985072252701}
2022-11-22 20:15:28,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:28,747 INFO:     Epoch: 54
2022-11-22 20:15:29,458 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7170246974988417, 'Total loss': 0.7170246974988417} | train loss {'Reaction outcome loss': 0.7519946123872484, 'Total loss': 0.7519946123872484}
2022-11-22 20:15:29,458 INFO:     Found new best model at epoch 54
2022-11-22 20:15:29,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:29,459 INFO:     Epoch: 55
2022-11-22 20:15:30,196 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7320224994962866, 'Total loss': 0.7320224994962866} | train loss {'Reaction outcome loss': 0.7528446915198346, 'Total loss': 0.7528446915198346}
2022-11-22 20:15:30,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:30,196 INFO:     Epoch: 56
2022-11-22 20:15:30,928 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7232051396911795, 'Total loss': 0.7232051396911795} | train loss {'Reaction outcome loss': 0.7511723309147115, 'Total loss': 0.7511723309147115}
2022-11-22 20:15:30,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:30,928 INFO:     Epoch: 57
2022-11-22 20:15:31,647 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7140086239034479, 'Total loss': 0.7140086239034479} | train loss {'Reaction outcome loss': 0.7494521828330293, 'Total loss': 0.7494521828330293}
2022-11-22 20:15:31,647 INFO:     Found new best model at epoch 57
2022-11-22 20:15:31,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:31,648 INFO:     Epoch: 58
2022-11-22 20:15:32,380 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7240474264730107, 'Total loss': 0.7240474264730107} | train loss {'Reaction outcome loss': 0.7498555891367854, 'Total loss': 0.7498555891367854}
2022-11-22 20:15:32,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:32,380 INFO:     Epoch: 59
2022-11-22 20:15:33,124 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7441713962365281, 'Total loss': 0.7441713962365281} | train loss {'Reaction outcome loss': 0.7385710878031594, 'Total loss': 0.7385710878031594}
2022-11-22 20:15:33,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:33,124 INFO:     Epoch: 60
2022-11-22 20:15:33,856 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7491479543122378, 'Total loss': 0.7491479543122378} | train loss {'Reaction outcome loss': 0.7362484182630267, 'Total loss': 0.7362484182630267}
2022-11-22 20:15:33,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:33,857 INFO:     Epoch: 61
2022-11-22 20:15:34,563 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7333227070895109, 'Total loss': 0.7333227070895109} | train loss {'Reaction outcome loss': 0.7356426859388546, 'Total loss': 0.7356426859388546}
2022-11-22 20:15:34,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:34,564 INFO:     Epoch: 62
2022-11-22 20:15:35,294 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7110042748126116, 'Total loss': 0.7110042748126116} | train loss {'Reaction outcome loss': 0.7345792838505336, 'Total loss': 0.7345792838505336}
2022-11-22 20:15:35,294 INFO:     Found new best model at epoch 62
2022-11-22 20:15:35,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:35,295 INFO:     Epoch: 63
2022-11-22 20:15:36,045 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.714877764609727, 'Total loss': 0.714877764609727} | train loss {'Reaction outcome loss': 0.7306634275280699, 'Total loss': 0.7306634275280699}
2022-11-22 20:15:36,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:36,045 INFO:     Epoch: 64
2022-11-22 20:15:36,761 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7444274364547296, 'Total loss': 0.7444274364547296} | train loss {'Reaction outcome loss': 0.7199918403917429, 'Total loss': 0.7199918403917429}
2022-11-22 20:15:36,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:36,761 INFO:     Epoch: 65
2022-11-22 20:15:37,494 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7335740937428041, 'Total loss': 0.7335740937428041} | train loss {'Reaction outcome loss': 0.721973641794555, 'Total loss': 0.721973641794555}
2022-11-22 20:15:37,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:37,494 INFO:     Epoch: 66
2022-11-22 20:15:38,235 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7262339077212594, 'Total loss': 0.7262339077212594} | train loss {'Reaction outcome loss': 0.7193201397146497, 'Total loss': 0.7193201397146497}
2022-11-22 20:15:38,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:38,235 INFO:     Epoch: 67
2022-11-22 20:15:38,967 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.70274011248892, 'Total loss': 0.70274011248892} | train loss {'Reaction outcome loss': 0.7166025291900245, 'Total loss': 0.7166025291900245}
2022-11-22 20:15:38,967 INFO:     Found new best model at epoch 67
2022-11-22 20:15:38,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:38,968 INFO:     Epoch: 68
2022-11-22 20:15:39,714 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.6957133297215808, 'Total loss': 0.6957133297215808} | train loss {'Reaction outcome loss': 0.7106561030660357, 'Total loss': 0.7106561030660357}
2022-11-22 20:15:39,715 INFO:     Found new best model at epoch 68
2022-11-22 20:15:39,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:39,716 INFO:     Epoch: 69
2022-11-22 20:15:40,452 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7295048880306158, 'Total loss': 0.7295048880306158} | train loss {'Reaction outcome loss': 0.7094581433704921, 'Total loss': 0.7094581433704921}
2022-11-22 20:15:40,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:40,452 INFO:     Epoch: 70
2022-11-22 20:15:41,172 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.718773174692284, 'Total loss': 0.718773174692284} | train loss {'Reaction outcome loss': 0.7165554862849567, 'Total loss': 0.7165554862849567}
2022-11-22 20:15:41,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:41,172 INFO:     Epoch: 71
2022-11-22 20:15:41,887 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.6927504190667109, 'Total loss': 0.6927504190667109} | train loss {'Reaction outcome loss': 0.705694957412019, 'Total loss': 0.705694957412019}
2022-11-22 20:15:41,887 INFO:     Found new best model at epoch 71
2022-11-22 20:15:41,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:41,888 INFO:     Epoch: 72
2022-11-22 20:15:42,646 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7394580366936597, 'Total loss': 0.7394580366936597} | train loss {'Reaction outcome loss': 0.7167258462127374, 'Total loss': 0.7167258462127374}
2022-11-22 20:15:42,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:42,646 INFO:     Epoch: 73
2022-11-22 20:15:43,379 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7137161215597932, 'Total loss': 0.7137161215597932} | train loss {'Reaction outcome loss': 0.7060164207706646, 'Total loss': 0.7060164207706646}
2022-11-22 20:15:43,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:43,379 INFO:     Epoch: 74
2022-11-22 20:15:44,183 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7301340319893577, 'Total loss': 0.7301340319893577} | train loss {'Reaction outcome loss': 0.7046606661105642, 'Total loss': 0.7046606661105642}
2022-11-22 20:15:44,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:44,183 INFO:     Epoch: 75
2022-11-22 20:15:44,909 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7199575521729209, 'Total loss': 0.7199575521729209} | train loss {'Reaction outcome loss': 0.7083069572643358, 'Total loss': 0.7083069572643358}
2022-11-22 20:15:44,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:44,909 INFO:     Epoch: 76
2022-11-22 20:15:45,630 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7073990113355897, 'Total loss': 0.7073990113355897} | train loss {'Reaction outcome loss': 0.7034637494963043, 'Total loss': 0.7034637494963043}
2022-11-22 20:15:45,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:45,631 INFO:     Epoch: 77
2022-11-22 20:15:46,382 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.6907822672616352, 'Total loss': 0.6907822672616352} | train loss {'Reaction outcome loss': 0.701515677023907, 'Total loss': 0.701515677023907}
2022-11-22 20:15:46,382 INFO:     Found new best model at epoch 77
2022-11-22 20:15:46,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:46,383 INFO:     Epoch: 78
2022-11-22 20:15:47,107 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7025841813195836, 'Total loss': 0.7025841813195836} | train loss {'Reaction outcome loss': 0.6997932578836169, 'Total loss': 0.6997932578836169}
2022-11-22 20:15:47,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:47,108 INFO:     Epoch: 79
2022-11-22 20:15:47,881 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7546140331436287, 'Total loss': 0.7546140331436287} | train loss {'Reaction outcome loss': 0.7068576048831551, 'Total loss': 0.7068576048831551}
2022-11-22 20:15:47,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:47,881 INFO:     Epoch: 80
2022-11-22 20:15:48,594 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.6722505830905654, 'Total loss': 0.6722505830905654} | train loss {'Reaction outcome loss': 0.6969925606737332, 'Total loss': 0.6969925606737332}
2022-11-22 20:15:48,594 INFO:     Found new best model at epoch 80
2022-11-22 20:15:48,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:48,595 INFO:     Epoch: 81
2022-11-22 20:15:49,352 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6833364286205985, 'Total loss': 0.6833364286205985} | train loss {'Reaction outcome loss': 0.7017022154769119, 'Total loss': 0.7017022154769119}
2022-11-22 20:15:49,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:49,352 INFO:     Epoch: 82
2022-11-22 20:15:50,103 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.69559615037658, 'Total loss': 0.69559615037658} | train loss {'Reaction outcome loss': 0.6971042630623798, 'Total loss': 0.6971042630623798}
2022-11-22 20:15:50,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:50,103 INFO:     Epoch: 83
2022-11-22 20:15:50,843 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7151887193322182, 'Total loss': 0.7151887193322182} | train loss {'Reaction outcome loss': 0.6935945047407734, 'Total loss': 0.6935945047407734}
2022-11-22 20:15:50,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:50,844 INFO:     Epoch: 84
2022-11-22 20:15:51,628 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6676741702990099, 'Total loss': 0.6676741702990099} | train loss {'Reaction outcome loss': 0.6996097010009142, 'Total loss': 0.6996097010009142}
2022-11-22 20:15:51,629 INFO:     Found new best model at epoch 84
2022-11-22 20:15:51,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:51,631 INFO:     Epoch: 85
2022-11-22 20:15:52,383 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.699265679852529, 'Total loss': 0.699265679852529} | train loss {'Reaction outcome loss': 0.6878823512670945, 'Total loss': 0.6878823512670945}
2022-11-22 20:15:52,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:52,383 INFO:     Epoch: 86
2022-11-22 20:15:53,145 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6929568580605767, 'Total loss': 0.6929568580605767} | train loss {'Reaction outcome loss': 0.6891214611578961, 'Total loss': 0.6891214611578961}
2022-11-22 20:15:53,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:53,146 INFO:     Epoch: 87
2022-11-22 20:15:53,887 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6969347701153972, 'Total loss': 0.6969347701153972} | train loss {'Reaction outcome loss': 0.691103010274926, 'Total loss': 0.691103010274926}
2022-11-22 20:15:53,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:53,887 INFO:     Epoch: 88
2022-11-22 20:15:54,646 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7053120725534179, 'Total loss': 0.7053120725534179} | train loss {'Reaction outcome loss': 0.7016653860101895, 'Total loss': 0.7016653860101895}
2022-11-22 20:15:54,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:54,646 INFO:     Epoch: 89
2022-11-22 20:15:55,396 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6653293913060968, 'Total loss': 0.6653293913060968} | train loss {'Reaction outcome loss': 0.6932814584702861, 'Total loss': 0.6932814584702861}
2022-11-22 20:15:55,396 INFO:     Found new best model at epoch 89
2022-11-22 20:15:55,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:55,397 INFO:     Epoch: 90
2022-11-22 20:15:56,161 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7074814303354784, 'Total loss': 0.7074814303354784} | train loss {'Reaction outcome loss': 0.701172566048953, 'Total loss': 0.701172566048953}
2022-11-22 20:15:56,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:56,161 INFO:     Epoch: 91
2022-11-22 20:15:56,899 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.759842342951081, 'Total loss': 0.759842342951081} | train loss {'Reaction outcome loss': 0.6913827555520194, 'Total loss': 0.6913827555520194}
2022-11-22 20:15:56,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:56,900 INFO:     Epoch: 92
2022-11-22 20:15:57,650 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7108390954407778, 'Total loss': 0.7108390954407778} | train loss {'Reaction outcome loss': 0.6913931997454896, 'Total loss': 0.6913931997454896}
2022-11-22 20:15:57,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:57,651 INFO:     Epoch: 93
2022-11-22 20:15:58,390 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.757817271080884, 'Total loss': 0.757817271080884} | train loss {'Reaction outcome loss': 0.6958208647309517, 'Total loss': 0.6958208647309517}
2022-11-22 20:15:58,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:58,391 INFO:     Epoch: 94
2022-11-22 20:15:59,138 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6967428475618362, 'Total loss': 0.6967428475618362} | train loss {'Reaction outcome loss': 0.6893191044427911, 'Total loss': 0.6893191044427911}
2022-11-22 20:15:59,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:59,138 INFO:     Epoch: 95
2022-11-22 20:15:59,925 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7377595562826503, 'Total loss': 0.7377595562826503} | train loss {'Reaction outcome loss': 0.6967511192876465, 'Total loss': 0.6967511192876465}
2022-11-22 20:15:59,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:15:59,925 INFO:     Epoch: 96
2022-11-22 20:16:00,647 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6688408770344474, 'Total loss': 0.6688408770344474} | train loss {'Reaction outcome loss': 0.6890714246399549, 'Total loss': 0.6890714246399549}
2022-11-22 20:16:00,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:00,648 INFO:     Epoch: 97
2022-11-22 20:16:01,396 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6954450465061448, 'Total loss': 0.6954450465061448} | train loss {'Reaction outcome loss': 0.686581751704216, 'Total loss': 0.686581751704216}
2022-11-22 20:16:01,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:01,397 INFO:     Epoch: 98
2022-11-22 20:16:02,167 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6790835166519339, 'Total loss': 0.6790835166519339} | train loss {'Reaction outcome loss': 0.6938800854342324, 'Total loss': 0.6938800854342324}
2022-11-22 20:16:02,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:02,168 INFO:     Epoch: 99
2022-11-22 20:16:02,937 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6924596387384967, 'Total loss': 0.6924596387384967} | train loss {'Reaction outcome loss': 0.6872751263939605, 'Total loss': 0.6872751263939605}
2022-11-22 20:16:02,937 INFO:     Best model found after epoch 90 of 100.
2022-11-22 20:16:02,937 INFO:   Done with stage: TRAINING
2022-11-22 20:16:02,937 INFO:   Starting stage: EVALUATION
2022-11-22 20:16:03,062 INFO:   Done with stage: EVALUATION
2022-11-22 20:16:03,062 INFO:   Leaving out SEQ value Fold_5
2022-11-22 20:16:03,075 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:16:03,075 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:16:03,753 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:16:03,753 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:16:03,830 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:16:03,830 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:16:03,830 INFO:     No hyperparam tuning for this model
2022-11-22 20:16:03,830 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:16:03,830 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:16:03,831 INFO:     None feature selector for col prot
2022-11-22 20:16:03,831 INFO:     None feature selector for col prot
2022-11-22 20:16:03,831 INFO:     None feature selector for col prot
2022-11-22 20:16:03,832 INFO:     None feature selector for col chem
2022-11-22 20:16:03,832 INFO:     None feature selector for col chem
2022-11-22 20:16:03,832 INFO:     None feature selector for col chem
2022-11-22 20:16:03,832 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:16:03,832 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:16:03,833 INFO:     Number of params in model 126091
2022-11-22 20:16:03,837 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:16:03,837 INFO:   Starting stage: TRAINING
2022-11-22 20:16:03,887 INFO:     Val loss before train {'Reaction outcome loss': 1.0094841610301624, 'Total loss': 1.0094841610301624}
2022-11-22 20:16:03,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:03,888 INFO:     Epoch: 0
2022-11-22 20:16:04,704 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8620874441482804, 'Total loss': 0.8620874441482804} | train loss {'Reaction outcome loss': 0.8871787832333491, 'Total loss': 0.8871787832333491}
2022-11-22 20:16:04,704 INFO:     Found new best model at epoch 0
2022-11-22 20:16:04,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:04,705 INFO:     Epoch: 1
2022-11-22 20:16:05,564 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8380445431579243, 'Total loss': 0.8380445431579243} | train loss {'Reaction outcome loss': 0.847887924325611, 'Total loss': 0.847887924325611}
2022-11-22 20:16:05,564 INFO:     Found new best model at epoch 1
2022-11-22 20:16:05,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:05,565 INFO:     Epoch: 2
2022-11-22 20:16:06,391 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8842704445123672, 'Total loss': 0.8842704445123672} | train loss {'Reaction outcome loss': 0.8431010891792745, 'Total loss': 0.8431010891792745}
2022-11-22 20:16:06,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:06,392 INFO:     Epoch: 3
2022-11-22 20:16:07,144 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8176668923009526, 'Total loss': 0.8176668923009526} | train loss {'Reaction outcome loss': 0.8359081783758001, 'Total loss': 0.8359081783758001}
2022-11-22 20:16:07,144 INFO:     Found new best model at epoch 3
2022-11-22 20:16:07,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:07,145 INFO:     Epoch: 4
2022-11-22 20:16:07,947 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8104790591380813, 'Total loss': 0.8104790591380813} | train loss {'Reaction outcome loss': 0.8193369604616996, 'Total loss': 0.8193369604616996}
2022-11-22 20:16:07,947 INFO:     Found new best model at epoch 4
2022-11-22 20:16:07,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:07,948 INFO:     Epoch: 5
2022-11-22 20:16:08,699 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8124067431146448, 'Total loss': 0.8124067431146448} | train loss {'Reaction outcome loss': 0.8112556350375959, 'Total loss': 0.8112556350375959}
2022-11-22 20:16:08,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:08,700 INFO:     Epoch: 6
2022-11-22 20:16:09,449 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8200127970088612, 'Total loss': 0.8200127970088612} | train loss {'Reaction outcome loss': 0.8178682625293732, 'Total loss': 0.8178682625293732}
2022-11-22 20:16:09,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:09,450 INFO:     Epoch: 7
2022-11-22 20:16:10,229 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8249948173761368, 'Total loss': 0.8249948173761368} | train loss {'Reaction outcome loss': 0.8190443327552394, 'Total loss': 0.8190443327552394}
2022-11-22 20:16:10,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:10,230 INFO:     Epoch: 8
2022-11-22 20:16:10,950 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8199997632340952, 'Total loss': 0.8199997632340952} | train loss {'Reaction outcome loss': 0.8125639242923212, 'Total loss': 0.8125639242923212}
2022-11-22 20:16:10,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:10,951 INFO:     Epoch: 9
2022-11-22 20:16:11,679 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.805645876987414, 'Total loss': 0.805645876987414} | train loss {'Reaction outcome loss': 0.8075277775164075, 'Total loss': 0.8075277775164075}
2022-11-22 20:16:11,679 INFO:     Found new best model at epoch 9
2022-11-22 20:16:11,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:11,680 INFO:     Epoch: 10
2022-11-22 20:16:12,423 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8280825357545506, 'Total loss': 0.8280825357545506} | train loss {'Reaction outcome loss': 0.8045669193360728, 'Total loss': 0.8045669193360728}
2022-11-22 20:16:12,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:12,423 INFO:     Epoch: 11
2022-11-22 20:16:13,196 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8986564454707232, 'Total loss': 0.8986564454707232} | train loss {'Reaction outcome loss': 0.8021472994735849, 'Total loss': 0.8021472994735849}
2022-11-22 20:16:13,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:13,197 INFO:     Epoch: 12
2022-11-22 20:16:14,022 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8482392396439206, 'Total loss': 0.8482392396439206} | train loss {'Reaction outcome loss': 0.8093509091298107, 'Total loss': 0.8093509091298107}
2022-11-22 20:16:14,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:14,022 INFO:     Epoch: 13
2022-11-22 20:16:14,759 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7965046790513125, 'Total loss': 0.7965046790513125} | train loss {'Reaction outcome loss': 0.8081087910453317, 'Total loss': 0.8081087910453317}
2022-11-22 20:16:14,759 INFO:     Found new best model at epoch 13
2022-11-22 20:16:14,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:14,760 INFO:     Epoch: 14
2022-11-22 20:16:15,490 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8199920451099222, 'Total loss': 0.8199920451099222} | train loss {'Reaction outcome loss': 0.8005502920160409, 'Total loss': 0.8005502920160409}
2022-11-22 20:16:15,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:15,490 INFO:     Epoch: 15
2022-11-22 20:16:16,264 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8002247268503363, 'Total loss': 0.8002247268503363} | train loss {'Reaction outcome loss': 0.8049138873091594, 'Total loss': 0.8049138873091594}
2022-11-22 20:16:16,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:16,264 INFO:     Epoch: 16
2022-11-22 20:16:17,054 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8164632347497073, 'Total loss': 0.8164632347497073} | train loss {'Reaction outcome loss': 0.8009596460080339, 'Total loss': 0.8009596460080339}
2022-11-22 20:16:17,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:17,055 INFO:     Epoch: 17
2022-11-22 20:16:17,762 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8200766457752748, 'Total loss': 0.8200766457752748} | train loss {'Reaction outcome loss': 0.7966684840227428, 'Total loss': 0.7966684840227428}
2022-11-22 20:16:17,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:17,763 INFO:     Epoch: 18
2022-11-22 20:16:18,515 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7926939685236324, 'Total loss': 0.7926939685236324} | train loss {'Reaction outcome loss': 0.8041450337842408, 'Total loss': 0.8041450337842408}
2022-11-22 20:16:18,515 INFO:     Found new best model at epoch 18
2022-11-22 20:16:18,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:18,516 INFO:     Epoch: 19
2022-11-22 20:16:19,241 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8045053962956775, 'Total loss': 0.8045053962956775} | train loss {'Reaction outcome loss': 0.7974194480928212, 'Total loss': 0.7974194480928212}
2022-11-22 20:16:19,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:19,241 INFO:     Epoch: 20
2022-11-22 20:16:19,996 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7934723780913786, 'Total loss': 0.7934723780913786} | train loss {'Reaction outcome loss': 0.8025243544144186, 'Total loss': 0.8025243544144186}
2022-11-22 20:16:19,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:19,996 INFO:     Epoch: 21
2022-11-22 20:16:20,740 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7997849021445621, 'Total loss': 0.7997849021445621} | train loss {'Reaction outcome loss': 0.8007342005789522, 'Total loss': 0.8007342005789522}
2022-11-22 20:16:20,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:20,740 INFO:     Epoch: 22
2022-11-22 20:16:21,488 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8061455894600261, 'Total loss': 0.8061455894600261} | train loss {'Reaction outcome loss': 0.8101691949946678, 'Total loss': 0.8101691949946678}
2022-11-22 20:16:21,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:21,488 INFO:     Epoch: 23
2022-11-22 20:16:22,259 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8077356110919606, 'Total loss': 0.8077356110919606} | train loss {'Reaction outcome loss': 0.7976220517686987, 'Total loss': 0.7976220517686987}
2022-11-22 20:16:22,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:22,259 INFO:     Epoch: 24
2022-11-22 20:16:23,028 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7853913760998033, 'Total loss': 0.7853913760998033} | train loss {'Reaction outcome loss': 0.7920476151140112, 'Total loss': 0.7920476151140112}
2022-11-22 20:16:23,030 INFO:     Found new best model at epoch 24
2022-11-22 20:16:23,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:23,031 INFO:     Epoch: 25
2022-11-22 20:16:23,826 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8132288963957266, 'Total loss': 0.8132288963957266} | train loss {'Reaction outcome loss': 0.7978671699883002, 'Total loss': 0.7978671699883002}
2022-11-22 20:16:23,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:23,826 INFO:     Epoch: 26
2022-11-22 20:16:24,575 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.807539855892008, 'Total loss': 0.807539855892008} | train loss {'Reaction outcome loss': 0.8037902336371573, 'Total loss': 0.8037902336371573}
2022-11-22 20:16:24,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:24,575 INFO:     Epoch: 27
2022-11-22 20:16:25,321 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8028673407706347, 'Total loss': 0.8028673407706347} | train loss {'Reaction outcome loss': 0.797098712128425, 'Total loss': 0.797098712128425}
2022-11-22 20:16:25,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:25,322 INFO:     Epoch: 28
2022-11-22 20:16:26,045 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8323218463496729, 'Total loss': 0.8323218463496729} | train loss {'Reaction outcome loss': 0.7961247008339114, 'Total loss': 0.7961247008339114}
2022-11-22 20:16:26,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:26,045 INFO:     Epoch: 29
2022-11-22 20:16:26,856 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7810330113226717, 'Total loss': 0.7810330113226717} | train loss {'Reaction outcome loss': 0.7914399489126949, 'Total loss': 0.7914399489126949}
2022-11-22 20:16:26,856 INFO:     Found new best model at epoch 29
2022-11-22 20:16:26,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:26,857 INFO:     Epoch: 30
2022-11-22 20:16:27,625 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7968039106238972, 'Total loss': 0.7968039106238972} | train loss {'Reaction outcome loss': 0.7924441770774874, 'Total loss': 0.7924441770774874}
2022-11-22 20:16:27,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:27,626 INFO:     Epoch: 31
2022-11-22 20:16:28,352 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.783503074537624, 'Total loss': 0.783503074537624} | train loss {'Reaction outcome loss': 0.792658641331109, 'Total loss': 0.792658641331109}
2022-11-22 20:16:28,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:28,352 INFO:     Epoch: 32
2022-11-22 20:16:29,117 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8114541227167303, 'Total loss': 0.8114541227167303} | train loss {'Reaction outcome loss': 0.7942796709083835, 'Total loss': 0.7942796709083835}
2022-11-22 20:16:29,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:29,118 INFO:     Epoch: 33
2022-11-22 20:16:29,854 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8260465020483191, 'Total loss': 0.8260465020483191} | train loss {'Reaction outcome loss': 0.79725320257156, 'Total loss': 0.79725320257156}
2022-11-22 20:16:29,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:29,855 INFO:     Epoch: 34
2022-11-22 20:16:30,632 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8122935593128204, 'Total loss': 0.8122935593128204} | train loss {'Reaction outcome loss': 0.7940694005624486, 'Total loss': 0.7940694005624486}
2022-11-22 20:16:30,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:30,633 INFO:     Epoch: 35
2022-11-22 20:16:31,394 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8055297088893977, 'Total loss': 0.8055297088893977} | train loss {'Reaction outcome loss': 0.7934285809515942, 'Total loss': 0.7934285809515942}
2022-11-22 20:16:31,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:31,394 INFO:     Epoch: 36
2022-11-22 20:16:32,170 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.796854664656249, 'Total loss': 0.796854664656249} | train loss {'Reaction outcome loss': 0.794419826524943, 'Total loss': 0.794419826524943}
2022-11-22 20:16:32,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:32,170 INFO:     Epoch: 37
2022-11-22 20:16:32,917 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8192294321276925, 'Total loss': 0.8192294321276925} | train loss {'Reaction outcome loss': 0.7947256241732763, 'Total loss': 0.7947256241732763}
2022-11-22 20:16:32,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:32,918 INFO:     Epoch: 38
2022-11-22 20:16:33,680 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8372430923310193, 'Total loss': 0.8372430923310193} | train loss {'Reaction outcome loss': 0.7981326896169407, 'Total loss': 0.7981326896169407}
2022-11-22 20:16:33,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:33,681 INFO:     Epoch: 39
2022-11-22 20:16:34,402 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7942161072384227, 'Total loss': 0.7942161072384227} | train loss {'Reaction outcome loss': 0.7946210106616078, 'Total loss': 0.7946210106616078}
2022-11-22 20:16:34,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:34,402 INFO:     Epoch: 40
2022-11-22 20:16:35,153 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7848805311051282, 'Total loss': 0.7848805311051282} | train loss {'Reaction outcome loss': 0.7887564430292319, 'Total loss': 0.7887564430292319}
2022-11-22 20:16:35,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:35,153 INFO:     Epoch: 41
2022-11-22 20:16:35,917 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7996297126466577, 'Total loss': 0.7996297126466577} | train loss {'Reaction outcome loss': 0.7947804091671701, 'Total loss': 0.7947804091671701}
2022-11-22 20:16:35,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:35,918 INFO:     Epoch: 42
2022-11-22 20:16:36,672 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8188220072876323, 'Total loss': 0.8188220072876323} | train loss {'Reaction outcome loss': 0.7917892552821743, 'Total loss': 0.7917892552821743}
2022-11-22 20:16:36,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:36,672 INFO:     Epoch: 43
2022-11-22 20:16:37,392 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7907332452860746, 'Total loss': 0.7907332452860746} | train loss {'Reaction outcome loss': 0.7922386638066063, 'Total loss': 0.7922386638066063}
2022-11-22 20:16:37,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:37,393 INFO:     Epoch: 44
2022-11-22 20:16:38,124 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8005077926950022, 'Total loss': 0.8005077926950022} | train loss {'Reaction outcome loss': 0.7883984990689435, 'Total loss': 0.7883984990689435}
2022-11-22 20:16:38,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:38,124 INFO:     Epoch: 45
2022-11-22 20:16:38,886 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7909050265496428, 'Total loss': 0.7909050265496428} | train loss {'Reaction outcome loss': 0.7843104786643011, 'Total loss': 0.7843104786643011}
2022-11-22 20:16:38,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:38,887 INFO:     Epoch: 46
2022-11-22 20:16:39,618 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7883470329371366, 'Total loss': 0.7883470329371366} | train loss {'Reaction outcome loss': 0.790579033163395, 'Total loss': 0.790579033163395}
2022-11-22 20:16:39,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:39,618 INFO:     Epoch: 47
2022-11-22 20:16:40,398 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8214405619285323, 'Total loss': 0.8214405619285323} | train loss {'Reaction outcome loss': 0.7843428788035505, 'Total loss': 0.7843428788035505}
2022-11-22 20:16:40,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:40,399 INFO:     Epoch: 48
2022-11-22 20:16:41,186 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8033243112943389, 'Total loss': 0.8033243112943389} | train loss {'Reaction outcome loss': 0.8005134442798522, 'Total loss': 0.8005134442798522}
2022-11-22 20:16:41,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:41,187 INFO:     Epoch: 49
2022-11-22 20:16:41,924 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8057299181818962, 'Total loss': 0.8057299181818962} | train loss {'Reaction outcome loss': 0.7915774358187609, 'Total loss': 0.7915774358187609}
2022-11-22 20:16:41,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:41,925 INFO:     Epoch: 50
2022-11-22 20:16:42,649 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7977934804829684, 'Total loss': 0.7977934804829684} | train loss {'Reaction outcome loss': 0.7898104228230141, 'Total loss': 0.7898104228230141}
2022-11-22 20:16:42,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:42,649 INFO:     Epoch: 51
2022-11-22 20:16:43,382 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7943479344248772, 'Total loss': 0.7943479344248772} | train loss {'Reaction outcome loss': 0.7942322805101573, 'Total loss': 0.7942322805101573}
2022-11-22 20:16:43,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:43,382 INFO:     Epoch: 52
2022-11-22 20:16:44,115 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7796646451408212, 'Total loss': 0.7796646451408212} | train loss {'Reaction outcome loss': 0.793101723256864, 'Total loss': 0.793101723256864}
2022-11-22 20:16:44,115 INFO:     Found new best model at epoch 52
2022-11-22 20:16:44,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:44,116 INFO:     Epoch: 53
2022-11-22 20:16:44,873 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7939844036644156, 'Total loss': 0.7939844036644156} | train loss {'Reaction outcome loss': 0.791897425646724, 'Total loss': 0.791897425646724}
2022-11-22 20:16:44,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:44,873 INFO:     Epoch: 54
2022-11-22 20:16:45,628 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7982697879726236, 'Total loss': 0.7982697879726236} | train loss {'Reaction outcome loss': 0.7831477835352122, 'Total loss': 0.7831477835352122}
2022-11-22 20:16:45,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:45,629 INFO:     Epoch: 55
2022-11-22 20:16:46,415 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8010145303877917, 'Total loss': 0.8010145303877917} | train loss {'Reaction outcome loss': 0.7929222587390468, 'Total loss': 0.7929222587390468}
2022-11-22 20:16:46,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:46,415 INFO:     Epoch: 56
2022-11-22 20:16:47,178 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8517068827694113, 'Total loss': 0.8517068827694113} | train loss {'Reaction outcome loss': 0.7990504283654062, 'Total loss': 0.7990504283654062}
2022-11-22 20:16:47,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:47,178 INFO:     Epoch: 57
2022-11-22 20:16:47,928 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8131507567384026, 'Total loss': 0.8131507567384026} | train loss {'Reaction outcome loss': 0.7903233046835734, 'Total loss': 0.7903233046835734}
2022-11-22 20:16:47,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:47,928 INFO:     Epoch: 58
2022-11-22 20:16:48,699 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7843398147008636, 'Total loss': 0.7843398147008636} | train loss {'Reaction outcome loss': 0.7870100839176641, 'Total loss': 0.7870100839176641}
2022-11-22 20:16:48,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:48,699 INFO:     Epoch: 59
2022-11-22 20:16:49,442 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8643538938327269, 'Total loss': 0.8643538938327269} | train loss {'Reaction outcome loss': 0.7843372155780252, 'Total loss': 0.7843372155780252}
2022-11-22 20:16:49,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:49,442 INFO:     Epoch: 60
2022-11-22 20:16:50,167 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.823260290378874, 'Total loss': 0.823260290378874} | train loss {'Reaction outcome loss': 0.7757921475871854, 'Total loss': 0.7757921475871854}
2022-11-22 20:16:50,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:50,167 INFO:     Epoch: 61
2022-11-22 20:16:50,893 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.787650231610645, 'Total loss': 0.787650231610645} | train loss {'Reaction outcome loss': 0.7738802832389168, 'Total loss': 0.7738802832389168}
2022-11-22 20:16:50,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:50,894 INFO:     Epoch: 62
2022-11-22 20:16:51,671 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7786670510064472, 'Total loss': 0.7786670510064472} | train loss {'Reaction outcome loss': 0.7834541777126219, 'Total loss': 0.7834541777126219}
2022-11-22 20:16:51,671 INFO:     Found new best model at epoch 62
2022-11-22 20:16:51,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:51,672 INFO:     Epoch: 63
2022-11-22 20:16:52,456 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7723287181420759, 'Total loss': 0.7723287181420759} | train loss {'Reaction outcome loss': 0.7724588224702036, 'Total loss': 0.7724588224702036}
2022-11-22 20:16:52,456 INFO:     Found new best model at epoch 63
2022-11-22 20:16:52,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:52,457 INFO:     Epoch: 64
2022-11-22 20:16:53,258 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7700031447139654, 'Total loss': 0.7700031447139654} | train loss {'Reaction outcome loss': 0.7747846312127132, 'Total loss': 0.7747846312127132}
2022-11-22 20:16:53,258 INFO:     Found new best model at epoch 64
2022-11-22 20:16:53,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:53,259 INFO:     Epoch: 65
2022-11-22 20:16:54,010 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8155372027646411, 'Total loss': 0.8155372027646411} | train loss {'Reaction outcome loss': 0.7677198136866334, 'Total loss': 0.7677198136866334}
2022-11-22 20:16:54,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:54,011 INFO:     Epoch: 66
2022-11-22 20:16:54,762 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7806896824728359, 'Total loss': 0.7806896824728359} | train loss {'Reaction outcome loss': 0.7695490921798506, 'Total loss': 0.7695490921798506}
2022-11-22 20:16:54,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:54,763 INFO:     Epoch: 67
2022-11-22 20:16:55,528 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7786158235235647, 'Total loss': 0.7786158235235647} | train loss {'Reaction outcome loss': 0.7697547041935476, 'Total loss': 0.7697547041935476}
2022-11-22 20:16:55,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:55,528 INFO:     Epoch: 68
2022-11-22 20:16:56,253 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7797230597246777, 'Total loss': 0.7797230597246777} | train loss {'Reaction outcome loss': 0.7732945214881588, 'Total loss': 0.7732945214881588}
2022-11-22 20:16:56,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:56,254 INFO:     Epoch: 69
2022-11-22 20:16:57,043 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.792032658376477, 'Total loss': 0.792032658376477} | train loss {'Reaction outcome loss': 0.7761930571152613, 'Total loss': 0.7761930571152613}
2022-11-22 20:16:57,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:57,044 INFO:     Epoch: 70
2022-11-22 20:16:57,775 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7576600015163422, 'Total loss': 0.7576600015163422} | train loss {'Reaction outcome loss': 0.7775851908000374, 'Total loss': 0.7775851908000374}
2022-11-22 20:16:57,775 INFO:     Found new best model at epoch 70
2022-11-22 20:16:57,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:57,776 INFO:     Epoch: 71
2022-11-22 20:16:58,528 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.792790257117965, 'Total loss': 0.792790257117965} | train loss {'Reaction outcome loss': 0.7662254208736574, 'Total loss': 0.7662254208736574}
2022-11-22 20:16:58,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:58,528 INFO:     Epoch: 72
2022-11-22 20:16:59,382 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7621388367631219, 'Total loss': 0.7621388367631219} | train loss {'Reaction outcome loss': 0.7677879719599056, 'Total loss': 0.7677879719599056}
2022-11-22 20:16:59,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:16:59,382 INFO:     Epoch: 73
2022-11-22 20:17:00,174 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.775204790586775, 'Total loss': 0.775204790586775} | train loss {'Reaction outcome loss': 0.7735092002853208, 'Total loss': 0.7735092002853208}
2022-11-22 20:17:00,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:00,175 INFO:     Epoch: 74
2022-11-22 20:17:00,993 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7402301647446372, 'Total loss': 0.7402301647446372} | train loss {'Reaction outcome loss': 0.7548091464679734, 'Total loss': 0.7548091464679734}
2022-11-22 20:17:00,993 INFO:     Found new best model at epoch 74
2022-11-22 20:17:00,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:00,994 INFO:     Epoch: 75
2022-11-22 20:17:01,841 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7741695208982988, 'Total loss': 0.7741695208982988} | train loss {'Reaction outcome loss': 0.7528042613494734, 'Total loss': 0.7528042613494734}
2022-11-22 20:17:01,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:01,841 INFO:     Epoch: 76
2022-11-22 20:17:02,648 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7522535222497854, 'Total loss': 0.7522535222497854} | train loss {'Reaction outcome loss': 0.7500794719346622, 'Total loss': 0.7500794719346622}
2022-11-22 20:17:02,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:02,649 INFO:     Epoch: 77
2022-11-22 20:17:03,437 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.775579722090201, 'Total loss': 0.775579722090201} | train loss {'Reaction outcome loss': 0.7562459730184995, 'Total loss': 0.7562459730184995}
2022-11-22 20:17:03,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:03,437 INFO:     Epoch: 78
2022-11-22 20:17:04,235 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7326632934537801, 'Total loss': 0.7326632934537801} | train loss {'Reaction outcome loss': 0.7483113610792739, 'Total loss': 0.7483113610792739}
2022-11-22 20:17:04,235 INFO:     Found new best model at epoch 78
2022-11-22 20:17:04,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:04,236 INFO:     Epoch: 79
2022-11-22 20:17:05,076 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7471638416702097, 'Total loss': 0.7471638416702097} | train loss {'Reaction outcome loss': 0.7458762657971909, 'Total loss': 0.7458762657971909}
2022-11-22 20:17:05,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:05,076 INFO:     Epoch: 80
2022-11-22 20:17:05,881 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7411084845662117, 'Total loss': 0.7411084845662117} | train loss {'Reaction outcome loss': 0.7501295316315856, 'Total loss': 0.7501295316315856}
2022-11-22 20:17:05,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:05,882 INFO:     Epoch: 81
2022-11-22 20:17:06,686 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7402584904974158, 'Total loss': 0.7402584904974158} | train loss {'Reaction outcome loss': 0.7510696764175708, 'Total loss': 0.7510696764175708}
2022-11-22 20:17:06,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:06,686 INFO:     Epoch: 82
2022-11-22 20:17:07,455 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7749976475130428, 'Total loss': 0.7749976475130428} | train loss {'Reaction outcome loss': 0.744716534851051, 'Total loss': 0.744716534851051}
2022-11-22 20:17:07,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:07,455 INFO:     Epoch: 83
2022-11-22 20:17:08,268 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7589374557137489, 'Total loss': 0.7589374557137489} | train loss {'Reaction outcome loss': 0.7591384849567645, 'Total loss': 0.7591384849567645}
2022-11-22 20:17:08,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:08,269 INFO:     Epoch: 84
2022-11-22 20:17:09,145 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7543848136609251, 'Total loss': 0.7543848136609251} | train loss {'Reaction outcome loss': 0.7430739118020061, 'Total loss': 0.7430739118020061}
2022-11-22 20:17:09,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:09,146 INFO:     Epoch: 85
2022-11-22 20:17:10,049 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7624330595135689, 'Total loss': 0.7624330595135689} | train loss {'Reaction outcome loss': 0.7407564820065672, 'Total loss': 0.7407564820065672}
2022-11-22 20:17:10,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:10,049 INFO:     Epoch: 86
2022-11-22 20:17:10,866 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.783985816619613, 'Total loss': 0.783985816619613} | train loss {'Reaction outcome loss': 0.7336047789824727, 'Total loss': 0.7336047789824727}
2022-11-22 20:17:10,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:10,866 INFO:     Epoch: 87
2022-11-22 20:17:11,703 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7393919839100405, 'Total loss': 0.7393919839100405} | train loss {'Reaction outcome loss': 0.7434770542117748, 'Total loss': 0.7434770542117748}
2022-11-22 20:17:11,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:11,703 INFO:     Epoch: 88
2022-11-22 20:17:12,578 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7529917034235868, 'Total loss': 0.7529917034235868} | train loss {'Reaction outcome loss': 0.7352822184080055, 'Total loss': 0.7352822184080055}
2022-11-22 20:17:12,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:12,579 INFO:     Epoch: 89
2022-11-22 20:17:13,428 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7385224063288082, 'Total loss': 0.7385224063288082} | train loss {'Reaction outcome loss': 0.7344656566135314, 'Total loss': 0.7344656566135314}
2022-11-22 20:17:13,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:13,429 INFO:     Epoch: 90
2022-11-22 20:17:14,270 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7597475695339116, 'Total loss': 0.7597475695339116} | train loss {'Reaction outcome loss': 0.7338004780684405, 'Total loss': 0.7338004780684405}
2022-11-22 20:17:14,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:14,270 INFO:     Epoch: 91
2022-11-22 20:17:15,093 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7294764125888998, 'Total loss': 0.7294764125888998} | train loss {'Reaction outcome loss': 0.7325396979687667, 'Total loss': 0.7325396979687667}
2022-11-22 20:17:15,094 INFO:     Found new best model at epoch 91
2022-11-22 20:17:15,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:15,094 INFO:     Epoch: 92
2022-11-22 20:17:15,920 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.736494012854316, 'Total loss': 0.736494012854316} | train loss {'Reaction outcome loss': 0.7215506029484967, 'Total loss': 0.7215506029484967}
2022-11-22 20:17:15,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:15,920 INFO:     Epoch: 93
2022-11-22 20:17:16,766 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.768086539073424, 'Total loss': 0.768086539073424} | train loss {'Reaction outcome loss': 0.7334780531373584, 'Total loss': 0.7334780531373584}
2022-11-22 20:17:16,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:16,766 INFO:     Epoch: 94
2022-11-22 20:17:17,653 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7423219044100154, 'Total loss': 0.7423219044100154} | train loss {'Reaction outcome loss': 0.7527381342190963, 'Total loss': 0.7527381342190963}
2022-11-22 20:17:17,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:17,653 INFO:     Epoch: 95
2022-11-22 20:17:18,506 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7782996615225618, 'Total loss': 0.7782996615225618} | train loss {'Reaction outcome loss': 0.7286443327843901, 'Total loss': 0.7286443327843901}
2022-11-22 20:17:18,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:18,506 INFO:     Epoch: 96
2022-11-22 20:17:19,412 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7245394059202888, 'Total loss': 0.7245394059202888} | train loss {'Reaction outcome loss': 0.7322425956909473, 'Total loss': 0.7322425956909473}
2022-11-22 20:17:19,412 INFO:     Found new best model at epoch 96
2022-11-22 20:17:19,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:19,413 INFO:     Epoch: 97
2022-11-22 20:17:20,240 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7509738010439005, 'Total loss': 0.7509738010439005} | train loss {'Reaction outcome loss': 0.7280139681781351, 'Total loss': 0.7280139681781351}
2022-11-22 20:17:20,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:20,241 INFO:     Epoch: 98
2022-11-22 20:17:21,073 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7180260616269979, 'Total loss': 0.7180260616269979} | train loss {'Reaction outcome loss': 0.754142326623322, 'Total loss': 0.754142326623322}
2022-11-22 20:17:21,073 INFO:     Found new best model at epoch 98
2022-11-22 20:17:21,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:21,074 INFO:     Epoch: 99
2022-11-22 20:17:21,864 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7576664781028574, 'Total loss': 0.7576664781028574} | train loss {'Reaction outcome loss': 0.7407653568244656, 'Total loss': 0.7407653568244656}
2022-11-22 20:17:21,864 INFO:     Best model found after epoch 99 of 100.
2022-11-22 20:17:21,864 INFO:   Done with stage: TRAINING
2022-11-22 20:17:21,864 INFO:   Starting stage: EVALUATION
2022-11-22 20:17:21,983 INFO:   Done with stage: EVALUATION
2022-11-22 20:17:21,983 INFO:   Leaving out SEQ value Fold_6
2022-11-22 20:17:21,997 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 20:17:21,997 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:17:22,687 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:17:22,687 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:17:22,765 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:17:22,765 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:17:22,765 INFO:     No hyperparam tuning for this model
2022-11-22 20:17:22,765 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:17:22,765 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:17:22,766 INFO:     None feature selector for col prot
2022-11-22 20:17:22,766 INFO:     None feature selector for col prot
2022-11-22 20:17:22,766 INFO:     None feature selector for col prot
2022-11-22 20:17:22,767 INFO:     None feature selector for col chem
2022-11-22 20:17:22,767 INFO:     None feature selector for col chem
2022-11-22 20:17:22,767 INFO:     None feature selector for col chem
2022-11-22 20:17:22,767 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:17:22,767 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:17:22,768 INFO:     Number of params in model 126091
2022-11-22 20:17:22,772 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:17:22,772 INFO:   Starting stage: TRAINING
2022-11-22 20:17:22,823 INFO:     Val loss before train {'Reaction outcome loss': 1.0139235495166345, 'Total loss': 1.0139235495166345}
2022-11-22 20:17:22,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:22,824 INFO:     Epoch: 0
2022-11-22 20:17:23,658 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.863851395520297, 'Total loss': 0.863851395520297} | train loss {'Reaction outcome loss': 0.8830561815730987, 'Total loss': 0.8830561815730987}
2022-11-22 20:17:23,659 INFO:     Found new best model at epoch 0
2022-11-22 20:17:23,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:23,660 INFO:     Epoch: 1
2022-11-22 20:17:24,470 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8205020942471244, 'Total loss': 0.8205020942471244} | train loss {'Reaction outcome loss': 0.8451666391544765, 'Total loss': 0.8451666391544765}
2022-11-22 20:17:24,470 INFO:     Found new best model at epoch 1
2022-11-22 20:17:24,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:24,471 INFO:     Epoch: 2
2022-11-22 20:17:25,313 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8291037800637159, 'Total loss': 0.8291037800637159} | train loss {'Reaction outcome loss': 0.8424258134778468, 'Total loss': 0.8424258134778468}
2022-11-22 20:17:25,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:25,314 INFO:     Epoch: 3
2022-11-22 20:17:26,163 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.801697701215744, 'Total loss': 0.801697701215744} | train loss {'Reaction outcome loss': 0.8254431875482682, 'Total loss': 0.8254431875482682}
2022-11-22 20:17:26,163 INFO:     Found new best model at epoch 3
2022-11-22 20:17:26,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:26,164 INFO:     Epoch: 4
2022-11-22 20:17:27,014 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8367819250984625, 'Total loss': 0.8367819250984625} | train loss {'Reaction outcome loss': 0.8254878667573775, 'Total loss': 0.8254878667573775}
2022-11-22 20:17:27,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:27,015 INFO:     Epoch: 5
2022-11-22 20:17:27,820 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8049156259406697, 'Total loss': 0.8049156259406697} | train loss {'Reaction outcome loss': 0.8162727514582295, 'Total loss': 0.8162727514582295}
2022-11-22 20:17:27,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:27,821 INFO:     Epoch: 6
2022-11-22 20:17:28,631 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8224377591501583, 'Total loss': 0.8224377591501583} | train loss {'Reaction outcome loss': 0.8125719770548805, 'Total loss': 0.8125719770548805}
2022-11-22 20:17:28,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:28,632 INFO:     Epoch: 7
2022-11-22 20:17:29,503 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7909342240203511, 'Total loss': 0.7909342240203511} | train loss {'Reaction outcome loss': 0.8072967906632731, 'Total loss': 0.8072967906632731}
2022-11-22 20:17:29,503 INFO:     Found new best model at epoch 7
2022-11-22 20:17:29,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:29,504 INFO:     Epoch: 8
2022-11-22 20:17:30,355 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8101120333779942, 'Total loss': 0.8101120333779942} | train loss {'Reaction outcome loss': 0.8068991568420203, 'Total loss': 0.8068991568420203}
2022-11-22 20:17:30,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:30,355 INFO:     Epoch: 9
2022-11-22 20:17:31,181 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8021253198385239, 'Total loss': 0.8021253198385239} | train loss {'Reaction outcome loss': 0.8080109635428074, 'Total loss': 0.8080109635428074}
2022-11-22 20:17:31,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:31,181 INFO:     Epoch: 10
2022-11-22 20:17:31,964 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7975062660195611, 'Total loss': 0.7975062660195611} | train loss {'Reaction outcome loss': 0.8078200942085635, 'Total loss': 0.8078200942085635}
2022-11-22 20:17:31,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:31,964 INFO:     Epoch: 11
2022-11-22 20:17:32,766 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8310684487223625, 'Total loss': 0.8310684487223625} | train loss {'Reaction outcome loss': 0.8036679340706717, 'Total loss': 0.8036679340706717}
2022-11-22 20:17:32,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:32,766 INFO:     Epoch: 12
2022-11-22 20:17:33,547 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8922003622759472, 'Total loss': 0.8922003622759472} | train loss {'Reaction outcome loss': 0.7988325430741233, 'Total loss': 0.7988325430741233}
2022-11-22 20:17:33,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:33,548 INFO:     Epoch: 13
2022-11-22 20:17:34,376 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8499704504554922, 'Total loss': 0.8499704504554922} | train loss {'Reaction outcome loss': 0.8018123019606836, 'Total loss': 0.8018123019606836}
2022-11-22 20:17:34,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:34,376 INFO:     Epoch: 14
2022-11-22 20:17:35,145 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7966244010762735, 'Total loss': 0.7966244010762735} | train loss {'Reaction outcome loss': 0.8022766616796294, 'Total loss': 0.8022766616796294}
2022-11-22 20:17:35,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:35,145 INFO:     Epoch: 15
2022-11-22 20:17:35,912 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7915537533434954, 'Total loss': 0.7915537533434954} | train loss {'Reaction outcome loss': 0.7953136211201068, 'Total loss': 0.7953136211201068}
2022-11-22 20:17:35,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:35,913 INFO:     Epoch: 16
2022-11-22 20:17:36,704 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7935024100271139, 'Total loss': 0.7935024100271139} | train loss {'Reaction outcome loss': 0.7967380863283912, 'Total loss': 0.7967380863283912}
2022-11-22 20:17:36,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:36,704 INFO:     Epoch: 17
2022-11-22 20:17:37,564 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7900595055385069, 'Total loss': 0.7900595055385069} | train loss {'Reaction outcome loss': 0.791129702221482, 'Total loss': 0.791129702221482}
2022-11-22 20:17:37,564 INFO:     Found new best model at epoch 17
2022-11-22 20:17:37,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:37,565 INFO:     Epoch: 18
2022-11-22 20:17:38,371 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7830999432639643, 'Total loss': 0.7830999432639643} | train loss {'Reaction outcome loss': 0.7962368100641235, 'Total loss': 0.7962368100641235}
2022-11-22 20:17:38,371 INFO:     Found new best model at epoch 18
2022-11-22 20:17:38,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:38,372 INFO:     Epoch: 19
2022-11-22 20:17:39,199 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7791159674525261, 'Total loss': 0.7791159674525261} | train loss {'Reaction outcome loss': 0.790767217956243, 'Total loss': 0.790767217956243}
2022-11-22 20:17:39,199 INFO:     Found new best model at epoch 19
2022-11-22 20:17:39,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:39,200 INFO:     Epoch: 20
2022-11-22 20:17:39,995 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7809557860547846, 'Total loss': 0.7809557860547846} | train loss {'Reaction outcome loss': 0.7893488562155154, 'Total loss': 0.7893488562155154}
2022-11-22 20:17:39,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:39,995 INFO:     Epoch: 21
2022-11-22 20:17:40,787 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7813244536519051, 'Total loss': 0.7813244536519051} | train loss {'Reaction outcome loss': 0.7896787351177584, 'Total loss': 0.7896787351177584}
2022-11-22 20:17:40,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:40,787 INFO:     Epoch: 22
2022-11-22 20:17:41,609 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7863911295478995, 'Total loss': 0.7863911295478995} | train loss {'Reaction outcome loss': 0.7921263078047384, 'Total loss': 0.7921263078047384}
2022-11-22 20:17:41,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:41,609 INFO:     Epoch: 23
2022-11-22 20:17:42,368 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7965062016790564, 'Total loss': 0.7965062016790564} | train loss {'Reaction outcome loss': 0.7893744877749874, 'Total loss': 0.7893744877749874}
2022-11-22 20:17:42,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:42,369 INFO:     Epoch: 24
2022-11-22 20:17:43,133 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7816325249997053, 'Total loss': 0.7816325249997053} | train loss {'Reaction outcome loss': 0.7870103639941062, 'Total loss': 0.7870103639941062}
2022-11-22 20:17:43,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:43,133 INFO:     Epoch: 25
2022-11-22 20:17:43,901 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7845329676162113, 'Total loss': 0.7845329676162113} | train loss {'Reaction outcome loss': 0.7854183512108941, 'Total loss': 0.7854183512108941}
2022-11-22 20:17:43,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:43,901 INFO:     Epoch: 26
2022-11-22 20:17:44,675 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7725364064628427, 'Total loss': 0.7725364064628427} | train loss {'Reaction outcome loss': 0.791691867454398, 'Total loss': 0.791691867454398}
2022-11-22 20:17:44,676 INFO:     Found new best model at epoch 26
2022-11-22 20:17:44,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:44,677 INFO:     Epoch: 27
2022-11-22 20:17:45,465 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7758481678637591, 'Total loss': 0.7758481678637591} | train loss {'Reaction outcome loss': 0.7845578152806528, 'Total loss': 0.7845578152806528}
2022-11-22 20:17:45,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:45,465 INFO:     Epoch: 28
2022-11-22 20:17:46,255 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7994168570095842, 'Total loss': 0.7994168570095842} | train loss {'Reaction outcome loss': 0.7889929449846668, 'Total loss': 0.7889929449846668}
2022-11-22 20:17:46,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:46,256 INFO:     Epoch: 29
2022-11-22 20:17:47,047 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7752662978389047, 'Total loss': 0.7752662978389047} | train loss {'Reaction outcome loss': 0.784488160884188, 'Total loss': 0.784488160884188}
2022-11-22 20:17:47,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:47,047 INFO:     Epoch: 30
2022-11-22 20:17:47,842 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8130759258161891, 'Total loss': 0.8130759258161891} | train loss {'Reaction outcome loss': 0.7782698780778916, 'Total loss': 0.7782698780778916}
2022-11-22 20:17:47,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:47,842 INFO:     Epoch: 31
2022-11-22 20:17:48,631 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.776621248234402, 'Total loss': 0.776621248234402} | train loss {'Reaction outcome loss': 0.7852065322259741, 'Total loss': 0.7852065322259741}
2022-11-22 20:17:48,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:48,632 INFO:     Epoch: 32
2022-11-22 20:17:49,428 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7729287967085838, 'Total loss': 0.7729287967085838} | train loss {'Reaction outcome loss': 0.7830571866323871, 'Total loss': 0.7830571866323871}
2022-11-22 20:17:49,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:49,429 INFO:     Epoch: 33
2022-11-22 20:17:50,182 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8561104861172762, 'Total loss': 0.8561104861172762} | train loss {'Reaction outcome loss': 0.7763405153828282, 'Total loss': 0.7763405153828282}
2022-11-22 20:17:50,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:50,183 INFO:     Epoch: 34
2022-11-22 20:17:50,959 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7996387562968514, 'Total loss': 0.7996387562968514} | train loss {'Reaction outcome loss': 0.7755578043720415, 'Total loss': 0.7755578043720415}
2022-11-22 20:17:50,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:50,960 INFO:     Epoch: 35
2022-11-22 20:17:51,737 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8077633706006137, 'Total loss': 0.8077633706006137} | train loss {'Reaction outcome loss': 0.7792377870890402, 'Total loss': 0.7792377870890402}
2022-11-22 20:17:51,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:51,737 INFO:     Epoch: 36
2022-11-22 20:17:52,515 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7584584477272901, 'Total loss': 0.7584584477272901} | train loss {'Reaction outcome loss': 0.7693978030114405, 'Total loss': 0.7693978030114405}
2022-11-22 20:17:52,515 INFO:     Found new best model at epoch 36
2022-11-22 20:17:52,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:52,516 INFO:     Epoch: 37
2022-11-22 20:17:53,285 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.779028324240988, 'Total loss': 0.779028324240988} | train loss {'Reaction outcome loss': 0.7736101895570755, 'Total loss': 0.7736101895570755}
2022-11-22 20:17:53,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:53,286 INFO:     Epoch: 38
2022-11-22 20:17:54,019 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7641023776747964, 'Total loss': 0.7641023776747964} | train loss {'Reaction outcome loss': 0.770448439904759, 'Total loss': 0.770448439904759}
2022-11-22 20:17:54,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:54,019 INFO:     Epoch: 39
2022-11-22 20:17:54,792 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7704202688553117, 'Total loss': 0.7704202688553117} | train loss {'Reaction outcome loss': 0.765750038647844, 'Total loss': 0.765750038647844}
2022-11-22 20:17:54,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:54,792 INFO:     Epoch: 40
2022-11-22 20:17:55,587 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7668755020607602, 'Total loss': 0.7668755020607602} | train loss {'Reaction outcome loss': 0.7769739269729583, 'Total loss': 0.7769739269729583}
2022-11-22 20:17:55,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:55,587 INFO:     Epoch: 41
2022-11-22 20:17:56,365 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7823663502931595, 'Total loss': 0.7823663502931595} | train loss {'Reaction outcome loss': 0.7667115949574979, 'Total loss': 0.7667115949574979}
2022-11-22 20:17:56,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:56,367 INFO:     Epoch: 42
2022-11-22 20:17:57,134 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7666554227471352, 'Total loss': 0.7666554227471352} | train loss {'Reaction outcome loss': 0.7661000938425141, 'Total loss': 0.7661000938425141}
2022-11-22 20:17:57,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:57,134 INFO:     Epoch: 43
2022-11-22 20:17:57,928 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7418794388120825, 'Total loss': 0.7418794388120825} | train loss {'Reaction outcome loss': 0.7604170233732269, 'Total loss': 0.7604170233732269}
2022-11-22 20:17:57,928 INFO:     Found new best model at epoch 43
2022-11-22 20:17:57,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:57,929 INFO:     Epoch: 44
2022-11-22 20:17:58,739 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7776198630983179, 'Total loss': 0.7776198630983179} | train loss {'Reaction outcome loss': 0.7610689627547418, 'Total loss': 0.7610689627547418}
2022-11-22 20:17:58,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:58,739 INFO:     Epoch: 45
2022-11-22 20:17:59,580 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7517978447404775, 'Total loss': 0.7517978447404775} | train loss {'Reaction outcome loss': 0.750646397110916, 'Total loss': 0.750646397110916}
2022-11-22 20:17:59,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:17:59,580 INFO:     Epoch: 46
2022-11-22 20:18:00,373 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7321172072128816, 'Total loss': 0.7321172072128816} | train loss {'Reaction outcome loss': 0.7511003105150115, 'Total loss': 0.7511003105150115}
2022-11-22 20:18:00,373 INFO:     Found new best model at epoch 46
2022-11-22 20:18:00,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:00,374 INFO:     Epoch: 47
2022-11-22 20:18:01,197 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7484562573107806, 'Total loss': 0.7484562573107806} | train loss {'Reaction outcome loss': 0.7510058474877188, 'Total loss': 0.7510058474877188}
2022-11-22 20:18:01,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:01,197 INFO:     Epoch: 48
2022-11-22 20:18:01,996 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7491839907386086, 'Total loss': 0.7491839907386086} | train loss {'Reaction outcome loss': 0.7500377434395975, 'Total loss': 0.7500377434395975}
2022-11-22 20:18:01,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:01,996 INFO:     Epoch: 49
2022-11-22 20:18:02,851 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7769271006638353, 'Total loss': 0.7769271006638353} | train loss {'Reaction outcome loss': 0.7489951188045163, 'Total loss': 0.7489951188045163}
2022-11-22 20:18:02,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:02,852 INFO:     Epoch: 50
2022-11-22 20:18:03,668 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.773483591323549, 'Total loss': 0.773483591323549} | train loss {'Reaction outcome loss': 0.747872970036922, 'Total loss': 0.747872970036922}
2022-11-22 20:18:03,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:03,668 INFO:     Epoch: 51
2022-11-22 20:18:04,437 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7454984790899537, 'Total loss': 0.7454984790899537} | train loss {'Reaction outcome loss': 0.7522752697189008, 'Total loss': 0.7522752697189008}
2022-11-22 20:18:04,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:04,437 INFO:     Epoch: 52
2022-11-22 20:18:05,229 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.759491890668869, 'Total loss': 0.759491890668869} | train loss {'Reaction outcome loss': 0.7562557134416795, 'Total loss': 0.7562557134416795}
2022-11-22 20:18:05,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:05,229 INFO:     Epoch: 53
2022-11-22 20:18:06,018 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7451532279903238, 'Total loss': 0.7451532279903238} | train loss {'Reaction outcome loss': 0.7514544747048809, 'Total loss': 0.7514544747048809}
2022-11-22 20:18:06,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:06,018 INFO:     Epoch: 54
2022-11-22 20:18:06,810 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.75165925107219, 'Total loss': 0.75165925107219} | train loss {'Reaction outcome loss': 0.7446505352854729, 'Total loss': 0.7446505352854729}
2022-11-22 20:18:06,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:06,810 INFO:     Epoch: 55
2022-11-22 20:18:07,614 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7601142877882178, 'Total loss': 0.7601142877882178} | train loss {'Reaction outcome loss': 0.7441545085560891, 'Total loss': 0.7441545085560891}
2022-11-22 20:18:07,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:07,614 INFO:     Epoch: 56
2022-11-22 20:18:08,396 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7693654928695072, 'Total loss': 0.7693654928695072} | train loss {'Reaction outcome loss': 0.7387179296103216, 'Total loss': 0.7387179296103216}
2022-11-22 20:18:08,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:08,396 INFO:     Epoch: 57
2022-11-22 20:18:09,227 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7380144535140558, 'Total loss': 0.7380144535140558} | train loss {'Reaction outcome loss': 0.7442744196422638, 'Total loss': 0.7442744196422638}
2022-11-22 20:18:09,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:09,228 INFO:     Epoch: 58
2022-11-22 20:18:10,031 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7724192853678357, 'Total loss': 0.7724192853678357} | train loss {'Reaction outcome loss': 0.7388223166907987, 'Total loss': 0.7388223166907987}
2022-11-22 20:18:10,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:10,031 INFO:     Epoch: 59
2022-11-22 20:18:10,855 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7346469170667909, 'Total loss': 0.7346469170667909} | train loss {'Reaction outcome loss': 0.7435311618591508, 'Total loss': 0.7435311618591508}
2022-11-22 20:18:10,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:10,856 INFO:     Epoch: 60
2022-11-22 20:18:11,652 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7287799898873676, 'Total loss': 0.7287799898873676} | train loss {'Reaction outcome loss': 0.7401569558968467, 'Total loss': 0.7401569558968467}
2022-11-22 20:18:11,652 INFO:     Found new best model at epoch 60
2022-11-22 20:18:11,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:11,653 INFO:     Epoch: 61
2022-11-22 20:18:12,435 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7472495067525994, 'Total loss': 0.7472495067525994} | train loss {'Reaction outcome loss': 0.7419461059954858, 'Total loss': 0.7419461059954858}
2022-11-22 20:18:12,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:12,436 INFO:     Epoch: 62
2022-11-22 20:18:13,204 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8057780340313911, 'Total loss': 0.8057780340313911} | train loss {'Reaction outcome loss': 0.7330184071775405, 'Total loss': 0.7330184071775405}
2022-11-22 20:18:13,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:13,204 INFO:     Epoch: 63
2022-11-22 20:18:13,964 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.719333752989769, 'Total loss': 0.719333752989769} | train loss {'Reaction outcome loss': 0.7369831793851429, 'Total loss': 0.7369831793851429}
2022-11-22 20:18:13,964 INFO:     Found new best model at epoch 63
2022-11-22 20:18:13,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:13,965 INFO:     Epoch: 64
2022-11-22 20:18:14,740 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7389866222034801, 'Total loss': 0.7389866222034801} | train loss {'Reaction outcome loss': 0.7387387667211794, 'Total loss': 0.7387387667211794}
2022-11-22 20:18:14,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:14,740 INFO:     Epoch: 65
2022-11-22 20:18:15,505 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7626114968549121, 'Total loss': 0.7626114968549121} | train loss {'Reaction outcome loss': 0.7373385901052144, 'Total loss': 0.7373385901052144}
2022-11-22 20:18:15,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:15,506 INFO:     Epoch: 66
2022-11-22 20:18:16,310 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7676376036622308, 'Total loss': 0.7676376036622308} | train loss {'Reaction outcome loss': 0.7221389587728246, 'Total loss': 0.7221389587728246}
2022-11-22 20:18:16,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:16,311 INFO:     Epoch: 67
2022-11-22 20:18:17,077 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7089147039435126, 'Total loss': 0.7089147039435126} | train loss {'Reaction outcome loss': 0.7298562172199449, 'Total loss': 0.7298562172199449}
2022-11-22 20:18:17,077 INFO:     Found new best model at epoch 67
2022-11-22 20:18:17,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:17,078 INFO:     Epoch: 68
2022-11-22 20:18:17,905 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7319220162250779, 'Total loss': 0.7319220162250779} | train loss {'Reaction outcome loss': 0.7289142979969901, 'Total loss': 0.7289142979969901}
2022-11-22 20:18:17,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:17,905 INFO:     Epoch: 69
2022-11-22 20:18:18,675 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7267426320097663, 'Total loss': 0.7267426320097663} | train loss {'Reaction outcome loss': 0.7241940956202245, 'Total loss': 0.7241940956202245}
2022-11-22 20:18:18,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:18,675 INFO:     Epoch: 70
2022-11-22 20:18:19,413 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7320585271174257, 'Total loss': 0.7320585271174257} | train loss {'Reaction outcome loss': 0.7332705642667509, 'Total loss': 0.7332705642667509}
2022-11-22 20:18:19,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:19,413 INFO:     Epoch: 71
2022-11-22 20:18:20,177 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7113382565704259, 'Total loss': 0.7113382565704259} | train loss {'Reaction outcome loss': 0.7309689529600644, 'Total loss': 0.7309689529600644}
2022-11-22 20:18:20,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:20,177 INFO:     Epoch: 72
2022-11-22 20:18:20,934 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7180228632959452, 'Total loss': 0.7180228632959452} | train loss {'Reaction outcome loss': 0.7276223825831567, 'Total loss': 0.7276223825831567}
2022-11-22 20:18:20,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:20,934 INFO:     Epoch: 73
2022-11-22 20:18:21,663 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7105328088456934, 'Total loss': 0.7105328088456934} | train loss {'Reaction outcome loss': 0.7245297145939642, 'Total loss': 0.7245297145939642}
2022-11-22 20:18:21,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:21,663 INFO:     Epoch: 74
2022-11-22 20:18:22,411 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7401721104979515, 'Total loss': 0.7401721104979515} | train loss {'Reaction outcome loss': 0.7224147021770477, 'Total loss': 0.7224147021770477}
2022-11-22 20:18:22,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:22,411 INFO:     Epoch: 75
2022-11-22 20:18:23,189 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7153261568058621, 'Total loss': 0.7153261568058621} | train loss {'Reaction outcome loss': 0.7200539994143671, 'Total loss': 0.7200539994143671}
2022-11-22 20:18:23,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:23,190 INFO:     Epoch: 76
2022-11-22 20:18:23,993 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7441875392740424, 'Total loss': 0.7441875392740424} | train loss {'Reaction outcome loss': 0.7289569066657174, 'Total loss': 0.7289569066657174}
2022-11-22 20:18:23,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:23,994 INFO:     Epoch: 77
2022-11-22 20:18:24,833 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7221190611069853, 'Total loss': 0.7221190611069853} | train loss {'Reaction outcome loss': 0.7273980003571318, 'Total loss': 0.7273980003571318}
2022-11-22 20:18:24,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:24,833 INFO:     Epoch: 78
2022-11-22 20:18:25,607 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7126432433724403, 'Total loss': 0.7126432433724403} | train loss {'Reaction outcome loss': 0.7262022801704945, 'Total loss': 0.7262022801704945}
2022-11-22 20:18:25,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:25,608 INFO:     Epoch: 79
2022-11-22 20:18:26,362 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7311765111305497, 'Total loss': 0.7311765111305497} | train loss {'Reaction outcome loss': 0.7180457855424573, 'Total loss': 0.7180457855424573}
2022-11-22 20:18:26,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:26,363 INFO:     Epoch: 80
2022-11-22 20:18:27,128 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.6980430856347084, 'Total loss': 0.6980430856347084} | train loss {'Reaction outcome loss': 0.7207416924497774, 'Total loss': 0.7207416924497774}
2022-11-22 20:18:27,128 INFO:     Found new best model at epoch 80
2022-11-22 20:18:27,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:27,129 INFO:     Epoch: 81
2022-11-22 20:18:27,896 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7150222733616829, 'Total loss': 0.7150222733616829} | train loss {'Reaction outcome loss': 0.7333995108642886, 'Total loss': 0.7333995108642886}
2022-11-22 20:18:27,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:27,896 INFO:     Epoch: 82
2022-11-22 20:18:28,661 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7188113887201656, 'Total loss': 0.7188113887201656} | train loss {'Reaction outcome loss': 0.7139431293452939, 'Total loss': 0.7139431293452939}
2022-11-22 20:18:28,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:28,661 INFO:     Epoch: 83
2022-11-22 20:18:29,357 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7523130002346906, 'Total loss': 0.7523130002346906} | train loss {'Reaction outcome loss': 0.723816157468865, 'Total loss': 0.723816157468865}
2022-11-22 20:18:29,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:29,357 INFO:     Epoch: 84
2022-11-22 20:18:30,117 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6984324394301935, 'Total loss': 0.6984324394301935} | train loss {'Reaction outcome loss': 0.7245712179029661, 'Total loss': 0.7245712179029661}
2022-11-22 20:18:30,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:30,117 INFO:     Epoch: 85
2022-11-22 20:18:30,863 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7233165509321473, 'Total loss': 0.7233165509321473} | train loss {'Reaction outcome loss': 0.7248428275868777, 'Total loss': 0.7248428275868777}
2022-11-22 20:18:30,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:30,864 INFO:     Epoch: 86
2022-11-22 20:18:31,604 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7389017038724639, 'Total loss': 0.7389017038724639} | train loss {'Reaction outcome loss': 0.7208844346384848, 'Total loss': 0.7208844346384848}
2022-11-22 20:18:31,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:31,604 INFO:     Epoch: 87
2022-11-22 20:18:32,367 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7165892266414382, 'Total loss': 0.7165892266414382} | train loss {'Reaction outcome loss': 0.7288035948670679, 'Total loss': 0.7288035948670679}
2022-11-22 20:18:32,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:32,367 INFO:     Epoch: 88
2022-11-22 20:18:33,119 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.705532428893176, 'Total loss': 0.705532428893176} | train loss {'Reaction outcome loss': 0.7244043524166749, 'Total loss': 0.7244043524166749}
2022-11-22 20:18:33,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:33,120 INFO:     Epoch: 89
2022-11-22 20:18:33,872 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7042682008309797, 'Total loss': 0.7042682008309797} | train loss {'Reaction outcome loss': 0.7133560124183854, 'Total loss': 0.7133560124183854}
2022-11-22 20:18:33,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:33,872 INFO:     Epoch: 90
2022-11-22 20:18:34,645 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7240041250532324, 'Total loss': 0.7240041250532324} | train loss {'Reaction outcome loss': 0.722914446505808, 'Total loss': 0.722914446505808}
2022-11-22 20:18:34,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:34,645 INFO:     Epoch: 91
2022-11-22 20:18:35,388 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7231086038730361, 'Total loss': 0.7231086038730361} | train loss {'Reaction outcome loss': 0.7206446926199621, 'Total loss': 0.7206446926199621}
2022-11-22 20:18:35,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:35,388 INFO:     Epoch: 92
2022-11-22 20:18:36,147 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7081495211883024, 'Total loss': 0.7081495211883024} | train loss {'Reaction outcome loss': 0.7194180976479284, 'Total loss': 0.7194180976479284}
2022-11-22 20:18:36,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:36,147 INFO:     Epoch: 93
2022-11-22 20:18:36,913 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.71295127408071, 'Total loss': 0.71295127408071} | train loss {'Reaction outcome loss': 0.7202126002840458, 'Total loss': 0.7202126002840458}
2022-11-22 20:18:36,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:36,914 INFO:     Epoch: 94
2022-11-22 20:18:37,674 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7328317917206071, 'Total loss': 0.7328317917206071} | train loss {'Reaction outcome loss': 0.7151414812091859, 'Total loss': 0.7151414812091859}
2022-11-22 20:18:37,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:37,674 INFO:     Epoch: 95
2022-11-22 20:18:38,431 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7156916396184401, 'Total loss': 0.7156916396184401} | train loss {'Reaction outcome loss': 0.7222503572702408, 'Total loss': 0.7222503572702408}
2022-11-22 20:18:38,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:38,432 INFO:     Epoch: 96
2022-11-22 20:18:39,197 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7260733375495131, 'Total loss': 0.7260733375495131} | train loss {'Reaction outcome loss': 0.7211458286450755, 'Total loss': 0.7211458286450755}
2022-11-22 20:18:39,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:39,197 INFO:     Epoch: 97
2022-11-22 20:18:39,983 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7134981026703661, 'Total loss': 0.7134981026703661} | train loss {'Reaction outcome loss': 0.724985437227353, 'Total loss': 0.724985437227353}
2022-11-22 20:18:39,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:39,983 INFO:     Epoch: 98
2022-11-22 20:18:40,765 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7491139552809976, 'Total loss': 0.7491139552809976} | train loss {'Reaction outcome loss': 0.7153946829418982, 'Total loss': 0.7153946829418982}
2022-11-22 20:18:40,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:40,766 INFO:     Epoch: 99
2022-11-22 20:18:41,592 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6994925012642687, 'Total loss': 0.6994925012642687} | train loss {'Reaction outcome loss': 0.7202541884635726, 'Total loss': 0.7202541884635726}
2022-11-22 20:18:41,593 INFO:     Best model found after epoch 81 of 100.
2022-11-22 20:18:41,593 INFO:   Done with stage: TRAINING
2022-11-22 20:18:41,593 INFO:   Starting stage: EVALUATION
2022-11-22 20:18:41,707 INFO:   Done with stage: EVALUATION
2022-11-22 20:18:41,707 INFO:   Leaving out SEQ value Fold_7
2022-11-22 20:18:41,720 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:18:41,721 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:18:42,386 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:18:42,387 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:18:42,457 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:18:42,458 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:18:42,458 INFO:     No hyperparam tuning for this model
2022-11-22 20:18:42,458 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:18:42,458 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:18:42,459 INFO:     None feature selector for col prot
2022-11-22 20:18:42,459 INFO:     None feature selector for col prot
2022-11-22 20:18:42,459 INFO:     None feature selector for col prot
2022-11-22 20:18:42,459 INFO:     None feature selector for col chem
2022-11-22 20:18:42,459 INFO:     None feature selector for col chem
2022-11-22 20:18:42,460 INFO:     None feature selector for col chem
2022-11-22 20:18:42,460 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:18:42,460 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:18:42,461 INFO:     Number of params in model 126091
2022-11-22 20:18:42,464 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:18:42,464 INFO:   Starting stage: TRAINING
2022-11-22 20:18:42,514 INFO:     Val loss before train {'Reaction outcome loss': 1.0179858668283983, 'Total loss': 1.0179858668283983}
2022-11-22 20:18:42,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:42,514 INFO:     Epoch: 0
2022-11-22 20:18:43,248 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8395032286643982, 'Total loss': 0.8395032286643982} | train loss {'Reaction outcome loss': 0.8797951567510844, 'Total loss': 0.8797951567510844}
2022-11-22 20:18:43,248 INFO:     Found new best model at epoch 0
2022-11-22 20:18:43,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:43,249 INFO:     Epoch: 1
2022-11-22 20:18:43,975 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8223384903235869, 'Total loss': 0.8223384903235869} | train loss {'Reaction outcome loss': 0.8420174964647061, 'Total loss': 0.8420174964647061}
2022-11-22 20:18:43,975 INFO:     Found new best model at epoch 1
2022-11-22 20:18:43,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:43,976 INFO:     Epoch: 2
2022-11-22 20:18:44,732 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.811364857987924, 'Total loss': 0.811364857987924} | train loss {'Reaction outcome loss': 0.8240428921664774, 'Total loss': 0.8240428921664774}
2022-11-22 20:18:44,732 INFO:     Found new best model at epoch 2
2022-11-22 20:18:44,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:44,733 INFO:     Epoch: 3
2022-11-22 20:18:45,495 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8365298265760596, 'Total loss': 0.8365298265760596} | train loss {'Reaction outcome loss': 0.8262273914176925, 'Total loss': 0.8262273914176925}
2022-11-22 20:18:45,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:45,495 INFO:     Epoch: 4
2022-11-22 20:18:46,217 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8016686256636273, 'Total loss': 0.8016686256636273} | train loss {'Reaction outcome loss': 0.8244261819160419, 'Total loss': 0.8244261819160419}
2022-11-22 20:18:46,217 INFO:     Found new best model at epoch 4
2022-11-22 20:18:46,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:46,218 INFO:     Epoch: 5
2022-11-22 20:18:46,945 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8162331574342467, 'Total loss': 0.8162331574342467} | train loss {'Reaction outcome loss': 0.8132883195693676, 'Total loss': 0.8132883195693676}
2022-11-22 20:18:46,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:46,945 INFO:     Epoch: 6
2022-11-22 20:18:47,698 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8691788911819458, 'Total loss': 0.8691788911819458} | train loss {'Reaction outcome loss': 0.8075555950282556, 'Total loss': 0.8075555950282556}
2022-11-22 20:18:47,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:47,698 INFO:     Epoch: 7
2022-11-22 20:18:48,423 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.798632640730251, 'Total loss': 0.798632640730251} | train loss {'Reaction outcome loss': 0.8045960460235233, 'Total loss': 0.8045960460235233}
2022-11-22 20:18:48,423 INFO:     Found new best model at epoch 7
2022-11-22 20:18:48,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:48,424 INFO:     Epoch: 8
2022-11-22 20:18:49,205 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7891515371474352, 'Total loss': 0.7891515371474352} | train loss {'Reaction outcome loss': 0.8016433043458201, 'Total loss': 0.8016433043458201}
2022-11-22 20:18:49,206 INFO:     Found new best model at epoch 8
2022-11-22 20:18:49,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:49,207 INFO:     Epoch: 9
2022-11-22 20:18:49,968 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7946141389283267, 'Total loss': 0.7946141389283267} | train loss {'Reaction outcome loss': 0.8125503852299834, 'Total loss': 0.8125503852299834}
2022-11-22 20:18:49,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:49,968 INFO:     Epoch: 10
2022-11-22 20:18:50,728 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8025419590148059, 'Total loss': 0.8025419590148059} | train loss {'Reaction outcome loss': 0.8063319105172326, 'Total loss': 0.8063319105172326}
2022-11-22 20:18:50,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:50,728 INFO:     Epoch: 11
2022-11-22 20:18:51,518 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8096416159109636, 'Total loss': 0.8096416159109636} | train loss {'Reaction outcome loss': 0.798539150400683, 'Total loss': 0.798539150400683}
2022-11-22 20:18:51,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:51,519 INFO:     Epoch: 12
2022-11-22 20:18:52,243 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8140722987326708, 'Total loss': 0.8140722987326708} | train loss {'Reaction outcome loss': 0.8055182998238305, 'Total loss': 0.8055182998238305}
2022-11-22 20:18:52,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:52,243 INFO:     Epoch: 13
2022-11-22 20:18:52,969 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7905977856029164, 'Total loss': 0.7905977856029164} | train loss {'Reaction outcome loss': 0.7968350327630275, 'Total loss': 0.7968350327630275}
2022-11-22 20:18:52,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:52,969 INFO:     Epoch: 14
2022-11-22 20:18:53,713 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8623327308080413, 'Total loss': 0.8623327308080413} | train loss {'Reaction outcome loss': 0.7979015914293436, 'Total loss': 0.7979015914293436}
2022-11-22 20:18:53,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:53,714 INFO:     Epoch: 15
2022-11-22 20:18:54,465 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7907699299129572, 'Total loss': 0.7907699299129572} | train loss {'Reaction outcome loss': 0.808433694697102, 'Total loss': 0.808433694697102}
2022-11-22 20:18:54,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:54,465 INFO:     Epoch: 16
2022-11-22 20:18:55,218 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8005295836112716, 'Total loss': 0.8005295836112716} | train loss {'Reaction outcome loss': 0.7991758174741799, 'Total loss': 0.7991758174741799}
2022-11-22 20:18:55,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:55,218 INFO:     Epoch: 17
2022-11-22 20:18:55,953 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7969396371733058, 'Total loss': 0.7969396371733058} | train loss {'Reaction outcome loss': 0.8000414349168901, 'Total loss': 0.8000414349168901}
2022-11-22 20:18:55,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:55,953 INFO:     Epoch: 18
2022-11-22 20:18:56,701 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8017946325919845, 'Total loss': 0.8017946325919845} | train loss {'Reaction outcome loss': 0.8008145607917415, 'Total loss': 0.8008145607917415}
2022-11-22 20:18:56,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:56,701 INFO:     Epoch: 19
2022-11-22 20:18:57,497 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7909131646156311, 'Total loss': 0.7909131646156311} | train loss {'Reaction outcome loss': 0.7921823739764179, 'Total loss': 0.7921823739764179}
2022-11-22 20:18:57,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:57,497 INFO:     Epoch: 20
2022-11-22 20:18:58,246 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7921301715753295, 'Total loss': 0.7921301715753295} | train loss {'Reaction outcome loss': 0.7927859541978913, 'Total loss': 0.7927859541978913}
2022-11-22 20:18:58,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:58,247 INFO:     Epoch: 21
2022-11-22 20:18:58,986 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7873087498274717, 'Total loss': 0.7873087498274717} | train loss {'Reaction outcome loss': 0.7963605244693003, 'Total loss': 0.7963605244693003}
2022-11-22 20:18:58,987 INFO:     Found new best model at epoch 21
2022-11-22 20:18:58,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:58,988 INFO:     Epoch: 22
2022-11-22 20:18:59,748 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8027526621114124, 'Total loss': 0.8027526621114124} | train loss {'Reaction outcome loss': 0.7983499431175741, 'Total loss': 0.7983499431175741}
2022-11-22 20:18:59,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:18:59,749 INFO:     Epoch: 23
2022-11-22 20:19:00,524 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7946391586552967, 'Total loss': 0.7946391586552967} | train loss {'Reaction outcome loss': 0.7884967806126907, 'Total loss': 0.7884967806126907}
2022-11-22 20:19:00,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:00,524 INFO:     Epoch: 24
2022-11-22 20:19:01,267 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8389840424060822, 'Total loss': 0.8389840424060822} | train loss {'Reaction outcome loss': 0.7972251301110997, 'Total loss': 0.7972251301110997}
2022-11-22 20:19:01,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:01,268 INFO:     Epoch: 25
2022-11-22 20:19:02,054 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7992344254797156, 'Total loss': 0.7992344254797156} | train loss {'Reaction outcome loss': 0.7948670623756131, 'Total loss': 0.7948670623756131}
2022-11-22 20:19:02,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:02,054 INFO:     Epoch: 26
2022-11-22 20:19:02,834 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7821388651024211, 'Total loss': 0.7821388651024211} | train loss {'Reaction outcome loss': 0.7905711789242169, 'Total loss': 0.7905711789242169}
2022-11-22 20:19:02,834 INFO:     Found new best model at epoch 26
2022-11-22 20:19:02,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:02,835 INFO:     Epoch: 27
2022-11-22 20:19:03,571 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7827951569448818, 'Total loss': 0.7827951569448818} | train loss {'Reaction outcome loss': 0.7920241723900382, 'Total loss': 0.7920241723900382}
2022-11-22 20:19:03,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:03,572 INFO:     Epoch: 28
2022-11-22 20:19:04,325 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8160267793996767, 'Total loss': 0.8160267793996767} | train loss {'Reaction outcome loss': 0.7943610145978117, 'Total loss': 0.7943610145978117}
2022-11-22 20:19:04,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:04,326 INFO:     Epoch: 29
2022-11-22 20:19:05,075 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8145252804864537, 'Total loss': 0.8145252804864537} | train loss {'Reaction outcome loss': 0.7962872207406079, 'Total loss': 0.7962872207406079}
2022-11-22 20:19:05,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:05,076 INFO:     Epoch: 30
2022-11-22 20:19:05,854 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.81773095916618, 'Total loss': 0.81773095916618} | train loss {'Reaction outcome loss': 0.7962350412177653, 'Total loss': 0.7962350412177653}
2022-11-22 20:19:05,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:05,855 INFO:     Epoch: 31
2022-11-22 20:19:06,612 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7987333129752766, 'Total loss': 0.7987333129752766} | train loss {'Reaction outcome loss': 0.7968257897295933, 'Total loss': 0.7968257897295933}
2022-11-22 20:19:06,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:06,613 INFO:     Epoch: 32
2022-11-22 20:19:07,330 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.801610450853001, 'Total loss': 0.801610450853001} | train loss {'Reaction outcome loss': 0.7868798422185999, 'Total loss': 0.7868798422185999}
2022-11-22 20:19:07,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:07,331 INFO:     Epoch: 33
2022-11-22 20:19:08,054 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8075449412519281, 'Total loss': 0.8075449412519281} | train loss {'Reaction outcome loss': 0.7963135090434117, 'Total loss': 0.7963135090434117}
2022-11-22 20:19:08,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:08,054 INFO:     Epoch: 34
2022-11-22 20:19:08,787 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7787343683567914, 'Total loss': 0.7787343683567914} | train loss {'Reaction outcome loss': 0.7874638739264446, 'Total loss': 0.7874638739264446}
2022-11-22 20:19:08,788 INFO:     Found new best model at epoch 34
2022-11-22 20:19:08,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:08,788 INFO:     Epoch: 35
2022-11-22 20:19:09,553 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7922763973474503, 'Total loss': 0.7922763973474503} | train loss {'Reaction outcome loss': 0.7840065734709806, 'Total loss': 0.7840065734709806}
2022-11-22 20:19:09,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:09,553 INFO:     Epoch: 36
2022-11-22 20:19:10,300 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8007664199579846, 'Total loss': 0.8007664199579846} | train loss {'Reaction outcome loss': 0.7880641618057301, 'Total loss': 0.7880641618057301}
2022-11-22 20:19:10,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:10,300 INFO:     Epoch: 37
2022-11-22 20:19:11,046 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8100021867589517, 'Total loss': 0.8100021867589517} | train loss {'Reaction outcome loss': 0.7843677871049899, 'Total loss': 0.7843677871049899}
2022-11-22 20:19:11,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:11,046 INFO:     Epoch: 38
2022-11-22 20:19:11,801 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7653963047672402, 'Total loss': 0.7653963047672402} | train loss {'Reaction outcome loss': 0.7837124036149941, 'Total loss': 0.7837124036149941}
2022-11-22 20:19:11,801 INFO:     Found new best model at epoch 38
2022-11-22 20:19:11,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:11,802 INFO:     Epoch: 39
2022-11-22 20:19:12,529 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8022338551553813, 'Total loss': 0.8022338551553813} | train loss {'Reaction outcome loss': 0.7929971185531693, 'Total loss': 0.7929971185531693}
2022-11-22 20:19:12,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:12,530 INFO:     Epoch: 40
2022-11-22 20:19:13,251 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7741719145666469, 'Total loss': 0.7741719145666469} | train loss {'Reaction outcome loss': 0.7813616260463893, 'Total loss': 0.7813616260463893}
2022-11-22 20:19:13,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:13,251 INFO:     Epoch: 41
2022-11-22 20:19:14,013 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7868114791133187, 'Total loss': 0.7868114791133187} | train loss {'Reaction outcome loss': 0.7843381394801835, 'Total loss': 0.7843381394801835}
2022-11-22 20:19:14,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:14,013 INFO:     Epoch: 42
2022-11-22 20:19:14,761 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7888186248865995, 'Total loss': 0.7888186248865995} | train loss {'Reaction outcome loss': 0.7872626654773589, 'Total loss': 0.7872626654773589}
2022-11-22 20:19:14,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:14,761 INFO:     Epoch: 43
2022-11-22 20:19:15,503 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7765539850700985, 'Total loss': 0.7765539850700985} | train loss {'Reaction outcome loss': 0.7953332294578012, 'Total loss': 0.7953332294578012}
2022-11-22 20:19:15,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:15,504 INFO:     Epoch: 44
2022-11-22 20:19:16,259 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7764782803979787, 'Total loss': 0.7764782803979787} | train loss {'Reaction outcome loss': 0.7862658085610702, 'Total loss': 0.7862658085610702}
2022-11-22 20:19:16,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:16,259 INFO:     Epoch: 45
2022-11-22 20:19:17,000 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7872315909374844, 'Total loss': 0.7872315909374844} | train loss {'Reaction outcome loss': 0.7798783919408254, 'Total loss': 0.7798783919408254}
2022-11-22 20:19:17,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:17,000 INFO:     Epoch: 46
2022-11-22 20:19:17,724 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7904003452170979, 'Total loss': 0.7904003452170979} | train loss {'Reaction outcome loss': 0.7763090157798427, 'Total loss': 0.7763090157798427}
2022-11-22 20:19:17,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:17,725 INFO:     Epoch: 47
2022-11-22 20:19:18,513 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.785061853853139, 'Total loss': 0.785061853853139} | train loss {'Reaction outcome loss': 0.7800666706764746, 'Total loss': 0.7800666706764746}
2022-11-22 20:19:18,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:18,513 INFO:     Epoch: 48
2022-11-22 20:19:19,302 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7902434075420554, 'Total loss': 0.7902434075420554} | train loss {'Reaction outcome loss': 0.7828121121656074, 'Total loss': 0.7828121121656074}
2022-11-22 20:19:19,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:19,302 INFO:     Epoch: 49
2022-11-22 20:19:20,036 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8031350868669423, 'Total loss': 0.8031350868669423} | train loss {'Reaction outcome loss': 0.7790920870748126, 'Total loss': 0.7790920870748126}
2022-11-22 20:19:20,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:20,036 INFO:     Epoch: 50
2022-11-22 20:19:20,760 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7688858637755568, 'Total loss': 0.7688858637755568} | train loss {'Reaction outcome loss': 0.7808354558491031, 'Total loss': 0.7808354558491031}
2022-11-22 20:19:20,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:20,761 INFO:     Epoch: 51
2022-11-22 20:19:21,471 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7915092002261769, 'Total loss': 0.7915092002261769} | train loss {'Reaction outcome loss': 0.7788738457538821, 'Total loss': 0.7788738457538821}
2022-11-22 20:19:21,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:21,471 INFO:     Epoch: 52
2022-11-22 20:19:22,214 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7938532009720802, 'Total loss': 0.7938532009720802} | train loss {'Reaction outcome loss': 0.7818293096082896, 'Total loss': 0.7818293096082896}
2022-11-22 20:19:22,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:22,214 INFO:     Epoch: 53
2022-11-22 20:19:22,979 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7862231744961306, 'Total loss': 0.7862231744961306} | train loss {'Reaction outcome loss': 0.7746269857352562, 'Total loss': 0.7746269857352562}
2022-11-22 20:19:22,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:22,979 INFO:     Epoch: 54
2022-11-22 20:19:23,757 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7729601528156888, 'Total loss': 0.7729601528156888} | train loss {'Reaction outcome loss': 0.7710565948926726, 'Total loss': 0.7710565948926726}
2022-11-22 20:19:23,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:23,757 INFO:     Epoch: 55
2022-11-22 20:19:24,492 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7985644774003462, 'Total loss': 0.7985644774003462} | train loss {'Reaction outcome loss': 0.7906778232771375, 'Total loss': 0.7906778232771375}
2022-11-22 20:19:24,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:24,493 INFO:     Epoch: 56
2022-11-22 20:19:25,256 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.775022907013243, 'Total loss': 0.775022907013243} | train loss {'Reaction outcome loss': 0.7832659052963923, 'Total loss': 0.7832659052963923}
2022-11-22 20:19:25,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:25,256 INFO:     Epoch: 57
2022-11-22 20:19:26,041 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7773611301725561, 'Total loss': 0.7773611301725561} | train loss {'Reaction outcome loss': 0.7694534530131681, 'Total loss': 0.7694534530131681}
2022-11-22 20:19:26,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:26,041 INFO:     Epoch: 58
2022-11-22 20:19:26,742 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8029490201310678, 'Total loss': 0.8029490201310678} | train loss {'Reaction outcome loss': 0.7786328336487898, 'Total loss': 0.7786328336487898}
2022-11-22 20:19:26,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:26,742 INFO:     Epoch: 59
2022-11-22 20:19:27,477 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.817424547943202, 'Total loss': 0.817424547943202} | train loss {'Reaction outcome loss': 0.7767890254978226, 'Total loss': 0.7767890254978226}
2022-11-22 20:19:27,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:27,477 INFO:     Epoch: 60
2022-11-22 20:19:28,236 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8064515231685205, 'Total loss': 0.8064515231685205} | train loss {'Reaction outcome loss': 0.7830922423827986, 'Total loss': 0.7830922423827986}
2022-11-22 20:19:28,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:28,236 INFO:     Epoch: 61
2022-11-22 20:19:28,990 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8005955835635011, 'Total loss': 0.8005955835635011} | train loss {'Reaction outcome loss': 0.7760989443674261, 'Total loss': 0.7760989443674261}
2022-11-22 20:19:28,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:28,990 INFO:     Epoch: 62
2022-11-22 20:19:29,749 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.803643290292133, 'Total loss': 0.803643290292133} | train loss {'Reaction outcome loss': 0.7726867752760528, 'Total loss': 0.7726867752760528}
2022-11-22 20:19:29,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:29,750 INFO:     Epoch: 63
2022-11-22 20:19:30,487 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7783307819203897, 'Total loss': 0.7783307819203897} | train loss {'Reaction outcome loss': 0.7711494360496158, 'Total loss': 0.7711494360496158}
2022-11-22 20:19:30,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:30,487 INFO:     Epoch: 64
2022-11-22 20:19:31,289 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.787711269476197, 'Total loss': 0.787711269476197} | train loss {'Reaction outcome loss': 0.7747619606946644, 'Total loss': 0.7747619606946644}
2022-11-22 20:19:31,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:31,289 INFO:     Epoch: 65
2022-11-22 20:19:32,090 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7582888637076725, 'Total loss': 0.7582888637076725} | train loss {'Reaction outcome loss': 0.7758825587840216, 'Total loss': 0.7758825587840216}
2022-11-22 20:19:32,090 INFO:     Found new best model at epoch 65
2022-11-22 20:19:32,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:32,091 INFO:     Epoch: 66
2022-11-22 20:19:32,840 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7743826190179045, 'Total loss': 0.7743826190179045} | train loss {'Reaction outcome loss': 0.7632683679642465, 'Total loss': 0.7632683679642465}
2022-11-22 20:19:32,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:32,841 INFO:     Epoch: 67
2022-11-22 20:19:33,583 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7595084939490665, 'Total loss': 0.7595084939490665} | train loss {'Reaction outcome loss': 0.774256285868193, 'Total loss': 0.774256285868193}
2022-11-22 20:19:33,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:33,583 INFO:     Epoch: 68
2022-11-22 20:19:34,329 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7779200537638231, 'Total loss': 0.7779200537638231} | train loss {'Reaction outcome loss': 0.797267845224755, 'Total loss': 0.797267845224755}
2022-11-22 20:19:34,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:34,329 INFO:     Epoch: 69
2022-11-22 20:19:35,099 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7883352759209546, 'Total loss': 0.7883352759209546} | train loss {'Reaction outcome loss': 0.7967551118931789, 'Total loss': 0.7967551118931789}
2022-11-22 20:19:35,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:35,099 INFO:     Epoch: 70
2022-11-22 20:19:35,853 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7850106792016462, 'Total loss': 0.7850106792016462} | train loss {'Reaction outcome loss': 0.7847449962909405, 'Total loss': 0.7847449962909405}
2022-11-22 20:19:35,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:35,854 INFO:     Epoch: 71
2022-11-22 20:19:36,605 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7879852124235847, 'Total loss': 0.7879852124235847} | train loss {'Reaction outcome loss': 0.7705186936054153, 'Total loss': 0.7705186936054153}
2022-11-22 20:19:36,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:36,605 INFO:     Epoch: 72
2022-11-22 20:19:37,380 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7602845762263645, 'Total loss': 0.7602845762263645} | train loss {'Reaction outcome loss': 0.7701998854938307, 'Total loss': 0.7701998854938307}
2022-11-22 20:19:37,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:37,380 INFO:     Epoch: 73
2022-11-22 20:19:38,178 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7875588468529962, 'Total loss': 0.7875588468529962} | train loss {'Reaction outcome loss': 0.7768727800382776, 'Total loss': 0.7768727800382776}
2022-11-22 20:19:38,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:38,179 INFO:     Epoch: 74
2022-11-22 20:19:38,929 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7613095329566435, 'Total loss': 0.7613095329566435} | train loss {'Reaction outcome loss': 0.7643925137365395, 'Total loss': 0.7643925137365395}
2022-11-22 20:19:38,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:38,930 INFO:     Epoch: 75
2022-11-22 20:19:39,669 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7643923210826787, 'Total loss': 0.7643923210826787} | train loss {'Reaction outcome loss': 0.7677308697449533, 'Total loss': 0.7677308697449533}
2022-11-22 20:19:39,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:39,670 INFO:     Epoch: 76
2022-11-22 20:19:40,468 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7558810826052319, 'Total loss': 0.7558810826052319} | train loss {'Reaction outcome loss': 0.7609134925763134, 'Total loss': 0.7609134925763134}
2022-11-22 20:19:40,468 INFO:     Found new best model at epoch 76
2022-11-22 20:19:40,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:40,469 INFO:     Epoch: 77
2022-11-22 20:19:41,241 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7753070965409279, 'Total loss': 0.7753070965409279} | train loss {'Reaction outcome loss': 0.7631849586239711, 'Total loss': 0.7631849586239711}
2022-11-22 20:19:41,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:41,241 INFO:     Epoch: 78
2022-11-22 20:19:42,027 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7691503763198853, 'Total loss': 0.7691503763198853} | train loss {'Reaction outcome loss': 0.7662435250002363, 'Total loss': 0.7662435250002363}
2022-11-22 20:19:42,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:42,028 INFO:     Epoch: 79
2022-11-22 20:19:42,777 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7718163952231407, 'Total loss': 0.7718163952231407} | train loss {'Reaction outcome loss': 0.7510658654606777, 'Total loss': 0.7510658654606777}
2022-11-22 20:19:42,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:42,777 INFO:     Epoch: 80
2022-11-22 20:19:43,538 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7413366240533915, 'Total loss': 0.7413366240533915} | train loss {'Reaction outcome loss': 0.7503170188863267, 'Total loss': 0.7503170188863267}
2022-11-22 20:19:43,539 INFO:     Found new best model at epoch 80
2022-11-22 20:19:43,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:43,539 INFO:     Epoch: 81
2022-11-22 20:19:44,295 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7563927681608633, 'Total loss': 0.7563927681608633} | train loss {'Reaction outcome loss': 0.7584734747284337, 'Total loss': 0.7584734747284337}
2022-11-22 20:19:44,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:44,295 INFO:     Epoch: 82
2022-11-22 20:19:45,086 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7660407837141644, 'Total loss': 0.7660407837141644} | train loss {'Reaction outcome loss': 0.7569428881109967, 'Total loss': 0.7569428881109967}
2022-11-22 20:19:45,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:45,086 INFO:     Epoch: 83
2022-11-22 20:19:45,880 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7980632070790638, 'Total loss': 0.7980632070790638} | train loss {'Reaction outcome loss': 0.7494500933388467, 'Total loss': 0.7494500933388467}
2022-11-22 20:19:45,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:45,880 INFO:     Epoch: 84
2022-11-22 20:19:46,590 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.729317734864625, 'Total loss': 0.729317734864625} | train loss {'Reaction outcome loss': 0.7560579116769165, 'Total loss': 0.7560579116769165}
2022-11-22 20:19:46,590 INFO:     Found new best model at epoch 84
2022-11-22 20:19:46,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:46,591 INFO:     Epoch: 85
2022-11-22 20:19:47,323 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7428229695016687, 'Total loss': 0.7428229695016687} | train loss {'Reaction outcome loss': 0.7418517776829029, 'Total loss': 0.7418517776829029}
2022-11-22 20:19:47,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:47,323 INFO:     Epoch: 86
2022-11-22 20:19:48,076 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7726094729521058, 'Total loss': 0.7726094729521058} | train loss {'Reaction outcome loss': 0.7382597394800379, 'Total loss': 0.7382597394800379}
2022-11-22 20:19:48,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:48,077 INFO:     Epoch: 87
2022-11-22 20:19:48,878 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7496519142931158, 'Total loss': 0.7496519142931158} | train loss {'Reaction outcome loss': 0.7339739795879796, 'Total loss': 0.7339739795879796}
2022-11-22 20:19:48,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:48,878 INFO:     Epoch: 88
2022-11-22 20:19:49,598 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7353183715180918, 'Total loss': 0.7353183715180918} | train loss {'Reaction outcome loss': 0.7406343872006605, 'Total loss': 0.7406343872006605}
2022-11-22 20:19:49,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:49,598 INFO:     Epoch: 89
2022-11-22 20:19:50,345 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7583107257431204, 'Total loss': 0.7583107257431204} | train loss {'Reaction outcome loss': 0.7410016430293017, 'Total loss': 0.7410016430293017}
2022-11-22 20:19:50,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:50,345 INFO:     Epoch: 90
2022-11-22 20:19:51,105 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7141305634921248, 'Total loss': 0.7141305634921248} | train loss {'Reaction outcome loss': 0.7317272643992293, 'Total loss': 0.7317272643992293}
2022-11-22 20:19:51,105 INFO:     Found new best model at epoch 90
2022-11-22 20:19:51,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:51,106 INFO:     Epoch: 91
2022-11-22 20:19:51,830 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7249726524407213, 'Total loss': 0.7249726524407213} | train loss {'Reaction outcome loss': 0.7297512161948903, 'Total loss': 0.7297512161948903}
2022-11-22 20:19:51,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:51,830 INFO:     Epoch: 92
2022-11-22 20:19:52,595 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7343770929358222, 'Total loss': 0.7343770929358222} | train loss {'Reaction outcome loss': 0.7305701270035887, 'Total loss': 0.7305701270035887}
2022-11-22 20:19:52,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:52,596 INFO:     Epoch: 93
2022-11-22 20:19:53,339 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7608708962798119, 'Total loss': 0.7608708962798119} | train loss {'Reaction outcome loss': 0.7335309925590933, 'Total loss': 0.7335309925590933}
2022-11-22 20:19:53,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:53,339 INFO:     Epoch: 94
2022-11-22 20:19:54,060 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7080399935895746, 'Total loss': 0.7080399935895746} | train loss {'Reaction outcome loss': 0.7398474775103905, 'Total loss': 0.7398474775103905}
2022-11-22 20:19:54,060 INFO:     Found new best model at epoch 94
2022-11-22 20:19:54,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:54,061 INFO:     Epoch: 95
2022-11-22 20:19:54,768 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7518878680738535, 'Total loss': 0.7518878680738535} | train loss {'Reaction outcome loss': 0.7216516098512812, 'Total loss': 0.7216516098512812}
2022-11-22 20:19:54,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:54,768 INFO:     Epoch: 96
2022-11-22 20:19:55,502 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7244868874549866, 'Total loss': 0.7244868874549866} | train loss {'Reaction outcome loss': 0.7335298557271842, 'Total loss': 0.7335298557271842}
2022-11-22 20:19:55,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:55,503 INFO:     Epoch: 97
2022-11-22 20:19:56,257 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7252649637785825, 'Total loss': 0.7252649637785825} | train loss {'Reaction outcome loss': 0.7240069633206496, 'Total loss': 0.7240069633206496}
2022-11-22 20:19:56,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:56,258 INFO:     Epoch: 98
2022-11-22 20:19:57,026 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.779464374889027, 'Total loss': 0.779464374889027} | train loss {'Reaction outcome loss': 0.7300250654519811, 'Total loss': 0.7300250654519811}
2022-11-22 20:19:57,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:57,026 INFO:     Epoch: 99
2022-11-22 20:19:57,787 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7905692038210955, 'Total loss': 0.7905692038210955} | train loss {'Reaction outcome loss': 0.7322473612949554, 'Total loss': 0.7322473612949554}
2022-11-22 20:19:57,787 INFO:     Best model found after epoch 95 of 100.
2022-11-22 20:19:57,787 INFO:   Done with stage: TRAINING
2022-11-22 20:19:57,787 INFO:   Starting stage: EVALUATION
2022-11-22 20:19:57,906 INFO:   Done with stage: EVALUATION
2022-11-22 20:19:57,906 INFO:   Leaving out SEQ value Fold_8
2022-11-22 20:19:57,919 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:19:57,919 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:19:58,589 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:19:58,589 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:19:58,661 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:19:58,661 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:19:58,661 INFO:     No hyperparam tuning for this model
2022-11-22 20:19:58,661 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:19:58,661 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:19:58,662 INFO:     None feature selector for col prot
2022-11-22 20:19:58,662 INFO:     None feature selector for col prot
2022-11-22 20:19:58,662 INFO:     None feature selector for col prot
2022-11-22 20:19:58,663 INFO:     None feature selector for col chem
2022-11-22 20:19:58,663 INFO:     None feature selector for col chem
2022-11-22 20:19:58,663 INFO:     None feature selector for col chem
2022-11-22 20:19:58,663 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:19:58,663 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:19:58,665 INFO:     Number of params in model 126091
2022-11-22 20:19:58,668 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:19:58,668 INFO:   Starting stage: TRAINING
2022-11-22 20:19:58,718 INFO:     Val loss before train {'Reaction outcome loss': 0.9708566882393577, 'Total loss': 0.9708566882393577}
2022-11-22 20:19:58,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:58,718 INFO:     Epoch: 0
2022-11-22 20:19:59,454 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8592957095666365, 'Total loss': 0.8592957095666365} | train loss {'Reaction outcome loss': 0.8911370826877563, 'Total loss': 0.8911370826877563}
2022-11-22 20:19:59,454 INFO:     Found new best model at epoch 0
2022-11-22 20:19:59,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:19:59,455 INFO:     Epoch: 1
2022-11-22 20:20:00,187 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8170080510052767, 'Total loss': 0.8170080510052767} | train loss {'Reaction outcome loss': 0.861641423904944, 'Total loss': 0.861641423904944}
2022-11-22 20:20:00,187 INFO:     Found new best model at epoch 1
2022-11-22 20:20:00,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:00,188 INFO:     Epoch: 2
2022-11-22 20:20:00,929 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8089811957695268, 'Total loss': 0.8089811957695268} | train loss {'Reaction outcome loss': 0.8494362889031167, 'Total loss': 0.8494362889031167}
2022-11-22 20:20:00,930 INFO:     Found new best model at epoch 2
2022-11-22 20:20:00,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:00,931 INFO:     Epoch: 3
2022-11-22 20:20:01,661 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.79050866717642, 'Total loss': 0.79050866717642} | train loss {'Reaction outcome loss': 0.8425911584122461, 'Total loss': 0.8425911584122461}
2022-11-22 20:20:01,662 INFO:     Found new best model at epoch 3
2022-11-22 20:20:01,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:01,663 INFO:     Epoch: 4
2022-11-22 20:20:02,434 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7964803583242677, 'Total loss': 0.7964803583242677} | train loss {'Reaction outcome loss': 0.8376069272216032, 'Total loss': 0.8376069272216032}
2022-11-22 20:20:02,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:02,435 INFO:     Epoch: 5
2022-11-22 20:20:03,142 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7803294164213267, 'Total loss': 0.7803294164213267} | train loss {'Reaction outcome loss': 0.8301066189480244, 'Total loss': 0.8301066189480244}
2022-11-22 20:20:03,142 INFO:     Found new best model at epoch 5
2022-11-22 20:20:03,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:03,143 INFO:     Epoch: 6
2022-11-22 20:20:03,924 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8112349577925422, 'Total loss': 0.8112349577925422} | train loss {'Reaction outcome loss': 0.8340380827666294, 'Total loss': 0.8340380827666294}
2022-11-22 20:20:03,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:03,925 INFO:     Epoch: 7
2022-11-22 20:20:04,710 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8261858096176927, 'Total loss': 0.8261858096176927} | train loss {'Reaction outcome loss': 0.8314855309874423, 'Total loss': 0.8314855309874423}
2022-11-22 20:20:04,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:04,710 INFO:     Epoch: 8
2022-11-22 20:20:05,486 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7876540347933769, 'Total loss': 0.7876540347933769} | train loss {'Reaction outcome loss': 0.8370016418729234, 'Total loss': 0.8370016418729234}
2022-11-22 20:20:05,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:05,486 INFO:     Epoch: 9
2022-11-22 20:20:06,255 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7873283136974681, 'Total loss': 0.7873283136974681} | train loss {'Reaction outcome loss': 0.8241414147832615, 'Total loss': 0.8241414147832615}
2022-11-22 20:20:06,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:06,255 INFO:     Epoch: 10
2022-11-22 20:20:07,031 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8026984530416402, 'Total loss': 0.8026984530416402} | train loss {'Reaction outcome loss': 0.8206922126111955, 'Total loss': 0.8206922126111955}
2022-11-22 20:20:07,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:07,032 INFO:     Epoch: 11
2022-11-22 20:20:07,844 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7986137304793705, 'Total loss': 0.7986137304793705} | train loss {'Reaction outcome loss': 0.8166974297374004, 'Total loss': 0.8166974297374004}
2022-11-22 20:20:07,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:07,844 INFO:     Epoch: 12
2022-11-22 20:20:08,595 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8274764852090315, 'Total loss': 0.8274764852090315} | train loss {'Reaction outcome loss': 0.8174718308907288, 'Total loss': 0.8174718308907288}
2022-11-22 20:20:08,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:08,595 INFO:     Epoch: 13
2022-11-22 20:20:09,336 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8047572719779882, 'Total loss': 0.8047572719779882} | train loss {'Reaction outcome loss': 0.8237980863584681, 'Total loss': 0.8237980863584681}
2022-11-22 20:20:09,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:09,336 INFO:     Epoch: 14
2022-11-22 20:20:10,064 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7835006029768423, 'Total loss': 0.7835006029768423} | train loss {'Reaction outcome loss': 0.8183291965891958, 'Total loss': 0.8183291965891958}
2022-11-22 20:20:10,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:10,065 INFO:     Epoch: 15
2022-11-22 20:20:10,805 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.779236609285528, 'Total loss': 0.779236609285528} | train loss {'Reaction outcome loss': 0.8208018217974828, 'Total loss': 0.8208018217974828}
2022-11-22 20:20:10,806 INFO:     Found new best model at epoch 15
2022-11-22 20:20:10,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:10,807 INFO:     Epoch: 16
2022-11-22 20:20:11,552 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7885241440751336, 'Total loss': 0.7885241440751336} | train loss {'Reaction outcome loss': 0.8191364149333011, 'Total loss': 0.8191364149333011}
2022-11-22 20:20:11,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:11,552 INFO:     Epoch: 17
2022-11-22 20:20:12,278 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7930471788753163, 'Total loss': 0.7930471788753163} | train loss {'Reaction outcome loss': 0.8199068745862135, 'Total loss': 0.8199068745862135}
2022-11-22 20:20:12,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:12,279 INFO:     Epoch: 18
2022-11-22 20:20:13,013 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7909894917498935, 'Total loss': 0.7909894917498935} | train loss {'Reaction outcome loss': 0.8122635462023469, 'Total loss': 0.8122635462023469}
2022-11-22 20:20:13,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:13,013 INFO:     Epoch: 19
2022-11-22 20:20:13,763 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7655834128910844, 'Total loss': 0.7655834128910844} | train loss {'Reaction outcome loss': 0.8132493721570081, 'Total loss': 0.8132493721570081}
2022-11-22 20:20:13,763 INFO:     Found new best model at epoch 19
2022-11-22 20:20:13,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:13,764 INFO:     Epoch: 20
2022-11-22 20:20:14,510 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7723846730183471, 'Total loss': 0.7723846730183471} | train loss {'Reaction outcome loss': 0.8165928191742916, 'Total loss': 0.8165928191742916}
2022-11-22 20:20:14,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:14,510 INFO:     Epoch: 21
2022-11-22 20:20:15,262 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7637372084639289, 'Total loss': 0.7637372084639289} | train loss {'Reaction outcome loss': 0.8187309871559684, 'Total loss': 0.8187309871559684}
2022-11-22 20:20:15,262 INFO:     Found new best model at epoch 21
2022-11-22 20:20:15,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:15,263 INFO:     Epoch: 22
2022-11-22 20:20:16,031 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7673029913143679, 'Total loss': 0.7673029913143679} | train loss {'Reaction outcome loss': 0.8113175961471762, 'Total loss': 0.8113175961471762}
2022-11-22 20:20:16,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:16,031 INFO:     Epoch: 23
2022-11-22 20:20:16,808 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7671617445620623, 'Total loss': 0.7671617445620623} | train loss {'Reaction outcome loss': 0.8162961440530383, 'Total loss': 0.8162961440530383}
2022-11-22 20:20:16,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:16,809 INFO:     Epoch: 24
2022-11-22 20:20:17,565 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7675080400976267, 'Total loss': 0.7675080400976267} | train loss {'Reaction outcome loss': 0.8086023312589901, 'Total loss': 0.8086023312589901}
2022-11-22 20:20:17,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:17,566 INFO:     Epoch: 25
2022-11-22 20:20:18,347 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7751666361635382, 'Total loss': 0.7751666361635382} | train loss {'Reaction outcome loss': 0.8149962817367754, 'Total loss': 0.8149962817367754}
2022-11-22 20:20:18,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:18,347 INFO:     Epoch: 26
2022-11-22 20:20:19,109 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7781247740442102, 'Total loss': 0.7781247740442102} | train loss {'Reaction outcome loss': 0.8157275919972161, 'Total loss': 0.8157275919972161}
2022-11-22 20:20:19,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:19,110 INFO:     Epoch: 27
2022-11-22 20:20:19,865 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7822780541398309, 'Total loss': 0.7822780541398309} | train loss {'Reaction outcome loss': 0.8096204414541422, 'Total loss': 0.8096204414541422}
2022-11-22 20:20:19,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:19,865 INFO:     Epoch: 28
2022-11-22 20:20:20,651 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.767556639557535, 'Total loss': 0.767556639557535} | train loss {'Reaction outcome loss': 0.8050735787100155, 'Total loss': 0.8050735787100155}
2022-11-22 20:20:20,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:20,651 INFO:     Epoch: 29
2022-11-22 20:20:21,410 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7726272297176447, 'Total loss': 0.7726272297176447} | train loss {'Reaction outcome loss': 0.8029186893329929, 'Total loss': 0.8029186893329929}
2022-11-22 20:20:21,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:21,410 INFO:     Epoch: 30
2022-11-22 20:20:22,113 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7664160491390661, 'Total loss': 0.7664160491390661} | train loss {'Reaction outcome loss': 0.8166007387493304, 'Total loss': 0.8166007387493304}
2022-11-22 20:20:22,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:22,113 INFO:     Epoch: 31
2022-11-22 20:20:22,865 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8132507008585063, 'Total loss': 0.8132507008585063} | train loss {'Reaction outcome loss': 0.8123193022451902, 'Total loss': 0.8123193022451902}
2022-11-22 20:20:22,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:22,866 INFO:     Epoch: 32
2022-11-22 20:20:23,618 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7812010144645517, 'Total loss': 0.7812010144645517} | train loss {'Reaction outcome loss': 0.8065431742714002, 'Total loss': 0.8065431742714002}
2022-11-22 20:20:23,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:23,618 INFO:     Epoch: 33
2022-11-22 20:20:24,352 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7861661917783997, 'Total loss': 0.7861661917783997} | train loss {'Reaction outcome loss': 0.8117887549072142, 'Total loss': 0.8117887549072142}
2022-11-22 20:20:24,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:24,352 INFO:     Epoch: 34
2022-11-22 20:20:25,115 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7733171345158056, 'Total loss': 0.7733171345158056} | train loss {'Reaction outcome loss': 0.8057195652834317, 'Total loss': 0.8057195652834317}
2022-11-22 20:20:25,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:25,116 INFO:     Epoch: 35
2022-11-22 20:20:25,900 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7654585431922566, 'Total loss': 0.7654585431922566} | train loss {'Reaction outcome loss': 0.8037544256038511, 'Total loss': 0.8037544256038511}
2022-11-22 20:20:25,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:25,900 INFO:     Epoch: 36
2022-11-22 20:20:26,665 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7871215668591586, 'Total loss': 0.7871215668591586} | train loss {'Reaction outcome loss': 0.8096379565323896, 'Total loss': 0.8096379565323896}
2022-11-22 20:20:26,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:26,665 INFO:     Epoch: 37
2022-11-22 20:20:27,453 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.807737947864966, 'Total loss': 0.807737947864966} | train loss {'Reaction outcome loss': 0.8114599393688233, 'Total loss': 0.8114599393688233}
2022-11-22 20:20:27,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:27,453 INFO:     Epoch: 38
2022-11-22 20:20:28,195 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7787319042465903, 'Total loss': 0.7787319042465903} | train loss {'Reaction outcome loss': 0.8136736777147301, 'Total loss': 0.8136736777147301}
2022-11-22 20:20:28,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:28,196 INFO:     Epoch: 39
2022-11-22 20:20:28,939 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7850570096211, 'Total loss': 0.7850570096211} | train loss {'Reaction outcome loss': 0.803123135677716, 'Total loss': 0.803123135677716}
2022-11-22 20:20:28,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:28,939 INFO:     Epoch: 40
2022-11-22 20:20:29,683 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7739545337178491, 'Total loss': 0.7739545337178491} | train loss {'Reaction outcome loss': 0.8085283480192486, 'Total loss': 0.8085283480192486}
2022-11-22 20:20:29,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:29,684 INFO:     Epoch: 41
2022-11-22 20:20:30,492 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7847306904467669, 'Total loss': 0.7847306904467669} | train loss {'Reaction outcome loss': 0.8109495416585251, 'Total loss': 0.8109495416585251}
2022-11-22 20:20:30,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:30,492 INFO:     Epoch: 42
2022-11-22 20:20:31,230 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7771580381826921, 'Total loss': 0.7771580381826921} | train loss {'Reaction outcome loss': 0.8179819705756569, 'Total loss': 0.8179819705756569}
2022-11-22 20:20:31,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:31,230 INFO:     Epoch: 43
2022-11-22 20:20:32,015 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7649597051468763, 'Total loss': 0.7649597051468763} | train loss {'Reaction outcome loss': 0.8086323271154875, 'Total loss': 0.8086323271154875}
2022-11-22 20:20:32,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:32,017 INFO:     Epoch: 44
2022-11-22 20:20:32,746 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7619322694160722, 'Total loss': 0.7619322694160722} | train loss {'Reaction outcome loss': 0.8057698614684193, 'Total loss': 0.8057698614684193}
2022-11-22 20:20:32,746 INFO:     Found new best model at epoch 44
2022-11-22 20:20:32,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:32,747 INFO:     Epoch: 45
2022-11-22 20:20:33,466 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7711711715568196, 'Total loss': 0.7711711715568196} | train loss {'Reaction outcome loss': 0.8108379272555533, 'Total loss': 0.8108379272555533}
2022-11-22 20:20:33,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:33,467 INFO:     Epoch: 46
2022-11-22 20:20:34,234 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7630149566314437, 'Total loss': 0.7630149566314437} | train loss {'Reaction outcome loss': 0.8050896709988474, 'Total loss': 0.8050896709988474}
2022-11-22 20:20:34,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:34,234 INFO:     Epoch: 47
2022-11-22 20:20:35,032 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.75695385445248, 'Total loss': 0.75695385445248} | train loss {'Reaction outcome loss': 0.8063506909951508, 'Total loss': 0.8063506909951508}
2022-11-22 20:20:35,032 INFO:     Found new best model at epoch 47
2022-11-22 20:20:35,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:35,033 INFO:     Epoch: 48
2022-11-22 20:20:35,770 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7703615840185772, 'Total loss': 0.7703615840185772} | train loss {'Reaction outcome loss': 0.8047810890278232, 'Total loss': 0.8047810890278232}
2022-11-22 20:20:35,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:35,770 INFO:     Epoch: 49
2022-11-22 20:20:36,535 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7771327089179646, 'Total loss': 0.7771327089179646} | train loss {'Reaction outcome loss': 0.8023044525038617, 'Total loss': 0.8023044525038617}
2022-11-22 20:20:36,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:36,535 INFO:     Epoch: 50
2022-11-22 20:20:37,336 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7765617174181071, 'Total loss': 0.7765617174181071} | train loss {'Reaction outcome loss': 0.802113165558591, 'Total loss': 0.802113165558591}
2022-11-22 20:20:37,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:37,336 INFO:     Epoch: 51
2022-11-22 20:20:38,125 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7743367336013101, 'Total loss': 0.7743367336013101} | train loss {'Reaction outcome loss': 0.8103146308105484, 'Total loss': 0.8103146308105484}
2022-11-22 20:20:38,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:38,126 INFO:     Epoch: 52
2022-11-22 20:20:38,921 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7572028277949854, 'Total loss': 0.7572028277949854} | train loss {'Reaction outcome loss': 0.8054570001267228, 'Total loss': 0.8054570001267228}
2022-11-22 20:20:38,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:38,921 INFO:     Epoch: 53
2022-11-22 20:20:39,662 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7975753024220467, 'Total loss': 0.7975753024220467} | train loss {'Reaction outcome loss': 0.7968290208835109, 'Total loss': 0.7968290208835109}
2022-11-22 20:20:39,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:39,662 INFO:     Epoch: 54
2022-11-22 20:20:40,438 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7939645566723563, 'Total loss': 0.7939645566723563} | train loss {'Reaction outcome loss': 0.8057752973154971, 'Total loss': 0.8057752973154971}
2022-11-22 20:20:40,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:40,438 INFO:     Epoch: 55
2022-11-22 20:20:41,216 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8216572214256633, 'Total loss': 0.8216572214256633} | train loss {'Reaction outcome loss': 0.7964745442032332, 'Total loss': 0.7964745442032332}
2022-11-22 20:20:41,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:41,216 INFO:     Epoch: 56
2022-11-22 20:20:41,984 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7921000495553017, 'Total loss': 0.7921000495553017} | train loss {'Reaction outcome loss': 0.8106934571797065, 'Total loss': 0.8106934571797065}
2022-11-22 20:20:41,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:41,984 INFO:     Epoch: 57
2022-11-22 20:20:42,710 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7684901078993623, 'Total loss': 0.7684901078993623} | train loss {'Reaction outcome loss': 0.8028797561581801, 'Total loss': 0.8028797561581801}
2022-11-22 20:20:42,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:42,710 INFO:     Epoch: 58
2022-11-22 20:20:43,490 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7683151547204364, 'Total loss': 0.7683151547204364} | train loss {'Reaction outcome loss': 0.8012877764248172, 'Total loss': 0.8012877764248172}
2022-11-22 20:20:43,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:43,490 INFO:     Epoch: 59
2022-11-22 20:20:44,262 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7742699012160301, 'Total loss': 0.7742699012160301} | train loss {'Reaction outcome loss': 0.801329679681584, 'Total loss': 0.801329679681584}
2022-11-22 20:20:44,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:44,262 INFO:     Epoch: 60
2022-11-22 20:20:45,004 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7699473290280863, 'Total loss': 0.7699473290280863} | train loss {'Reaction outcome loss': 0.7925009641811432, 'Total loss': 0.7925009641811432}
2022-11-22 20:20:45,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:45,004 INFO:     Epoch: 61
2022-11-22 20:20:45,740 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7697379832917993, 'Total loss': 0.7697379832917993} | train loss {'Reaction outcome loss': 0.8018170369540149, 'Total loss': 0.8018170369540149}
2022-11-22 20:20:45,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:45,740 INFO:     Epoch: 62
2022-11-22 20:20:46,494 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7819070341912183, 'Total loss': 0.7819070341912183} | train loss {'Reaction outcome loss': 0.7920006395804013, 'Total loss': 0.7920006395804013}
2022-11-22 20:20:46,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:46,494 INFO:     Epoch: 63
2022-11-22 20:20:47,204 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7649602463299577, 'Total loss': 0.7649602463299577} | train loss {'Reaction outcome loss': 0.7952028274958433, 'Total loss': 0.7952028274958433}
2022-11-22 20:20:47,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:47,205 INFO:     Epoch: 64
2022-11-22 20:20:47,928 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7625235468149185, 'Total loss': 0.7625235468149185} | train loss {'Reaction outcome loss': 0.7959964102820346, 'Total loss': 0.7959964102820346}
2022-11-22 20:20:47,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:47,928 INFO:     Epoch: 65
2022-11-22 20:20:48,721 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7789183848283507, 'Total loss': 0.7789183848283507} | train loss {'Reaction outcome loss': 0.7899365831724545, 'Total loss': 0.7899365831724545}
2022-11-22 20:20:48,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:48,722 INFO:     Epoch: 66
2022-11-22 20:20:49,512 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7582111202857711, 'Total loss': 0.7582111202857711} | train loss {'Reaction outcome loss': 0.7931520940079863, 'Total loss': 0.7931520940079863}
2022-11-22 20:20:49,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:49,512 INFO:     Epoch: 67
2022-11-22 20:20:50,254 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7933717830614611, 'Total loss': 0.7933717830614611} | train loss {'Reaction outcome loss': 0.8050191658228515, 'Total loss': 0.8050191658228515}
2022-11-22 20:20:50,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:50,255 INFO:     Epoch: 68
2022-11-22 20:20:51,003 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.76136203719811, 'Total loss': 0.76136203719811} | train loss {'Reaction outcome loss': 0.7865582285562025, 'Total loss': 0.7865582285562025}
2022-11-22 20:20:51,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:51,003 INFO:     Epoch: 69
2022-11-22 20:20:51,739 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7591645636341788, 'Total loss': 0.7591645636341788} | train loss {'Reaction outcome loss': 0.7891822149637739, 'Total loss': 0.7891822149637739}
2022-11-22 20:20:51,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:51,739 INFO:     Epoch: 70
2022-11-22 20:20:52,476 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7522197189656171, 'Total loss': 0.7522197189656171} | train loss {'Reaction outcome loss': 0.7899589251410141, 'Total loss': 0.7899589251410141}
2022-11-22 20:20:52,477 INFO:     Found new best model at epoch 70
2022-11-22 20:20:52,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:52,478 INFO:     Epoch: 71
2022-11-22 20:20:53,198 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7565150647000833, 'Total loss': 0.7565150647000833} | train loss {'Reaction outcome loss': 0.7962290751427291, 'Total loss': 0.7962290751427291}
2022-11-22 20:20:53,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:53,198 INFO:     Epoch: 72
2022-11-22 20:20:53,908 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7830022478645499, 'Total loss': 0.7830022478645499} | train loss {'Reaction outcome loss': 0.7827464209394417, 'Total loss': 0.7827464209394417}
2022-11-22 20:20:53,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:53,909 INFO:     Epoch: 73
2022-11-22 20:20:54,622 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7607937590642408, 'Total loss': 0.7607937590642408} | train loss {'Reaction outcome loss': 0.7972575503322277, 'Total loss': 0.7972575503322277}
2022-11-22 20:20:54,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:54,622 INFO:     Epoch: 74
2022-11-22 20:20:55,338 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7470821338621053, 'Total loss': 0.7470821338621053} | train loss {'Reaction outcome loss': 0.7868833753020175, 'Total loss': 0.7868833753020175}
2022-11-22 20:20:55,338 INFO:     Found new best model at epoch 74
2022-11-22 20:20:55,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:55,339 INFO:     Epoch: 75
2022-11-22 20:20:56,078 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7856874912977219, 'Total loss': 0.7856874912977219} | train loss {'Reaction outcome loss': 0.782318036716718, 'Total loss': 0.782318036716718}
2022-11-22 20:20:56,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:56,078 INFO:     Epoch: 76
2022-11-22 20:20:56,794 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7913328287276354, 'Total loss': 0.7913328287276354} | train loss {'Reaction outcome loss': 0.7850425480770679, 'Total loss': 0.7850425480770679}
2022-11-22 20:20:56,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:56,794 INFO:     Epoch: 77
2022-11-22 20:20:57,538 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7413656447421421, 'Total loss': 0.7413656447421421} | train loss {'Reaction outcome loss': 0.7832041111310967, 'Total loss': 0.7832041111310967}
2022-11-22 20:20:57,538 INFO:     Found new best model at epoch 77
2022-11-22 20:20:57,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:57,539 INFO:     Epoch: 78
2022-11-22 20:20:58,269 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7524365647272631, 'Total loss': 0.7524365647272631} | train loss {'Reaction outcome loss': 0.784090244215027, 'Total loss': 0.784090244215027}
2022-11-22 20:20:58,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:58,269 INFO:     Epoch: 79
2022-11-22 20:20:58,993 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7453357943079688, 'Total loss': 0.7453357943079688} | train loss {'Reaction outcome loss': 0.7774605190585017, 'Total loss': 0.7774605190585017}
2022-11-22 20:20:58,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:58,994 INFO:     Epoch: 80
2022-11-22 20:20:59,726 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7536531456492164, 'Total loss': 0.7536531456492164} | train loss {'Reaction outcome loss': 0.7804307489983948, 'Total loss': 0.7804307489983948}
2022-11-22 20:20:59,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:20:59,726 INFO:     Epoch: 81
2022-11-22 20:21:00,452 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7510670870542526, 'Total loss': 0.7510670870542526} | train loss {'Reaction outcome loss': 0.782899848483352, 'Total loss': 0.782899848483352}
2022-11-22 20:21:00,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:00,452 INFO:     Epoch: 82
2022-11-22 20:21:01,209 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7746247744018381, 'Total loss': 0.7746247744018381} | train loss {'Reaction outcome loss': 0.7777862225466894, 'Total loss': 0.7777862225466894}
2022-11-22 20:21:01,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:01,210 INFO:     Epoch: 83
2022-11-22 20:21:01,983 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7479523020711812, 'Total loss': 0.7479523020711812} | train loss {'Reaction outcome loss': 0.7744506887699428, 'Total loss': 0.7744506887699428}
2022-11-22 20:21:01,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:01,984 INFO:     Epoch: 84
2022-11-22 20:21:02,756 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7396106997674162, 'Total loss': 0.7396106997674162} | train loss {'Reaction outcome loss': 0.7794471185066199, 'Total loss': 0.7794471185066199}
2022-11-22 20:21:02,756 INFO:     Found new best model at epoch 84
2022-11-22 20:21:02,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:02,757 INFO:     Epoch: 85
2022-11-22 20:21:03,511 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7245807017792355, 'Total loss': 0.7245807017792355} | train loss {'Reaction outcome loss': 0.7725621013023592, 'Total loss': 0.7725621013023592}
2022-11-22 20:21:03,512 INFO:     Found new best model at epoch 85
2022-11-22 20:21:03,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:03,513 INFO:     Epoch: 86
2022-11-22 20:21:04,333 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7380740270018578, 'Total loss': 0.7380740270018578} | train loss {'Reaction outcome loss': 0.7718477828299951, 'Total loss': 0.7718477828299951}
2022-11-22 20:21:04,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:04,333 INFO:     Epoch: 87
2022-11-22 20:21:05,123 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7404649528590116, 'Total loss': 0.7404649528590116} | train loss {'Reaction outcome loss': 0.7682881807448411, 'Total loss': 0.7682881807448411}
2022-11-22 20:21:05,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:05,123 INFO:     Epoch: 88
2022-11-22 20:21:05,984 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7409038225358183, 'Total loss': 0.7409038225358183} | train loss {'Reaction outcome loss': 0.7539038709270568, 'Total loss': 0.7539038709270568}
2022-11-22 20:21:05,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:05,984 INFO:     Epoch: 89
2022-11-22 20:21:06,794 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7234761694615538, 'Total loss': 0.7234761694615538} | train loss {'Reaction outcome loss': 0.7606919598482881, 'Total loss': 0.7606919598482881}
2022-11-22 20:21:06,794 INFO:     Found new best model at epoch 89
2022-11-22 20:21:06,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:06,796 INFO:     Epoch: 90
2022-11-22 20:21:07,612 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7467272268100218, 'Total loss': 0.7467272268100218} | train loss {'Reaction outcome loss': 0.765838445077541, 'Total loss': 0.765838445077541}
2022-11-22 20:21:07,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:07,612 INFO:     Epoch: 91
2022-11-22 20:21:08,363 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7277474924921989, 'Total loss': 0.7277474924921989} | train loss {'Reaction outcome loss': 0.7577457377905787, 'Total loss': 0.7577457377905787}
2022-11-22 20:21:08,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:08,363 INFO:     Epoch: 92
2022-11-22 20:21:09,088 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7697928364981305, 'Total loss': 0.7697928364981305} | train loss {'Reaction outcome loss': 0.7507749182975244, 'Total loss': 0.7507749182975244}
2022-11-22 20:21:09,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:09,088 INFO:     Epoch: 93
2022-11-22 20:21:09,821 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7237094085324894, 'Total loss': 0.7237094085324894} | train loss {'Reaction outcome loss': 0.757144962607125, 'Total loss': 0.757144962607125}
2022-11-22 20:21:09,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:09,822 INFO:     Epoch: 94
2022-11-22 20:21:10,627 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7396871434016661, 'Total loss': 0.7396871434016661} | train loss {'Reaction outcome loss': 0.7586711653572346, 'Total loss': 0.7586711653572346}
2022-11-22 20:21:10,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:10,627 INFO:     Epoch: 95
2022-11-22 20:21:11,400 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7287319641221653, 'Total loss': 0.7287319641221653} | train loss {'Reaction outcome loss': 0.7551070250238967, 'Total loss': 0.7551070250238967}
2022-11-22 20:21:11,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:11,400 INFO:     Epoch: 96
2022-11-22 20:21:12,184 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7192281186580658, 'Total loss': 0.7192281186580658} | train loss {'Reaction outcome loss': 0.7577915019110629, 'Total loss': 0.7577915019110629}
2022-11-22 20:21:12,184 INFO:     Found new best model at epoch 96
2022-11-22 20:21:12,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:12,185 INFO:     Epoch: 97
2022-11-22 20:21:12,954 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7279839569872076, 'Total loss': 0.7279839569872076} | train loss {'Reaction outcome loss': 0.7475985467569669, 'Total loss': 0.7475985467569669}
2022-11-22 20:21:12,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:12,954 INFO:     Epoch: 98
2022-11-22 20:21:13,746 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.704133390025659, 'Total loss': 0.704133390025659} | train loss {'Reaction outcome loss': 0.7527904899617438, 'Total loss': 0.7527904899617438}
2022-11-22 20:21:13,746 INFO:     Found new best model at epoch 98
2022-11-22 20:21:13,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:13,747 INFO:     Epoch: 99
2022-11-22 20:21:14,485 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7044290812178091, 'Total loss': 0.7044290812178091} | train loss {'Reaction outcome loss': 0.747512961930109, 'Total loss': 0.747512961930109}
2022-11-22 20:21:14,485 INFO:     Best model found after epoch 99 of 100.
2022-11-22 20:21:14,485 INFO:   Done with stage: TRAINING
2022-11-22 20:21:14,485 INFO:   Starting stage: EVALUATION
2022-11-22 20:21:14,605 INFO:   Done with stage: EVALUATION
2022-11-22 20:21:14,605 INFO:   Leaving out SEQ value Fold_9
2022-11-22 20:21:14,618 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:21:14,618 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:21:15,298 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:21:15,298 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:21:15,369 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:21:15,369 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:21:15,369 INFO:     No hyperparam tuning for this model
2022-11-22 20:21:15,369 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:21:15,369 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:21:15,370 INFO:     None feature selector for col prot
2022-11-22 20:21:15,370 INFO:     None feature selector for col prot
2022-11-22 20:21:15,370 INFO:     None feature selector for col prot
2022-11-22 20:21:15,371 INFO:     None feature selector for col chem
2022-11-22 20:21:15,371 INFO:     None feature selector for col chem
2022-11-22 20:21:15,371 INFO:     None feature selector for col chem
2022-11-22 20:21:15,371 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:21:15,371 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:21:15,372 INFO:     Number of params in model 126091
2022-11-22 20:21:15,376 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:21:15,376 INFO:   Starting stage: TRAINING
2022-11-22 20:21:15,426 INFO:     Val loss before train {'Reaction outcome loss': 1.0349344448609785, 'Total loss': 1.0349344448609785}
2022-11-22 20:21:15,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:15,426 INFO:     Epoch: 0
2022-11-22 20:21:16,183 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8613353805108503, 'Total loss': 0.8613353805108503} | train loss {'Reaction outcome loss': 0.8694902753781694, 'Total loss': 0.8694902753781694}
2022-11-22 20:21:16,183 INFO:     Found new best model at epoch 0
2022-11-22 20:21:16,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:16,184 INFO:     Epoch: 1
2022-11-22 20:21:16,947 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.859462669627233, 'Total loss': 0.859462669627233} | train loss {'Reaction outcome loss': 0.8310041807682408, 'Total loss': 0.8310041807682408}
2022-11-22 20:21:16,947 INFO:     Found new best model at epoch 1
2022-11-22 20:21:16,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:16,948 INFO:     Epoch: 2
2022-11-22 20:21:17,741 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8572932705283165, 'Total loss': 0.8572932705283165} | train loss {'Reaction outcome loss': 0.8249433881599411, 'Total loss': 0.8249433881599411}
2022-11-22 20:21:17,741 INFO:     Found new best model at epoch 2
2022-11-22 20:21:17,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:17,742 INFO:     Epoch: 3
2022-11-22 20:21:18,489 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8643292859196663, 'Total loss': 0.8643292859196663} | train loss {'Reaction outcome loss': 0.8216588447692423, 'Total loss': 0.8216588447692423}
2022-11-22 20:21:18,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:18,490 INFO:     Epoch: 4
2022-11-22 20:21:19,236 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.840574714270505, 'Total loss': 0.840574714270505} | train loss {'Reaction outcome loss': 0.8110636741164242, 'Total loss': 0.8110636741164242}
2022-11-22 20:21:19,237 INFO:     Found new best model at epoch 4
2022-11-22 20:21:19,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:19,237 INFO:     Epoch: 5
2022-11-22 20:21:19,989 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8519936982880939, 'Total loss': 0.8519936982880939} | train loss {'Reaction outcome loss': 0.8118728511487907, 'Total loss': 0.8118728511487907}
2022-11-22 20:21:19,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:19,989 INFO:     Epoch: 6
2022-11-22 20:21:20,744 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8385686400261793, 'Total loss': 0.8385686400261793} | train loss {'Reaction outcome loss': 0.8064698687931786, 'Total loss': 0.8064698687931786}
2022-11-22 20:21:20,744 INFO:     Found new best model at epoch 6
2022-11-22 20:21:20,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:20,745 INFO:     Epoch: 7
2022-11-22 20:21:21,523 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8248432224447076, 'Total loss': 0.8248432224447076} | train loss {'Reaction outcome loss': 0.8002462397944107, 'Total loss': 0.8002462397944107}
2022-11-22 20:21:21,523 INFO:     Found new best model at epoch 7
2022-11-22 20:21:21,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:21,524 INFO:     Epoch: 8
2022-11-22 20:21:22,292 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.836069480939345, 'Total loss': 0.836069480939345} | train loss {'Reaction outcome loss': 0.8064731314838657, 'Total loss': 0.8064731314838657}
2022-11-22 20:21:22,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:22,293 INFO:     Epoch: 9
2022-11-22 20:21:23,019 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8246543481945992, 'Total loss': 0.8246543481945992} | train loss {'Reaction outcome loss': 0.796384704137138, 'Total loss': 0.796384704137138}
2022-11-22 20:21:23,020 INFO:     Found new best model at epoch 9
2022-11-22 20:21:23,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:23,020 INFO:     Epoch: 10
2022-11-22 20:21:23,812 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8569674248045142, 'Total loss': 0.8569674248045142} | train loss {'Reaction outcome loss': 0.7958762786890331, 'Total loss': 0.7958762786890331}
2022-11-22 20:21:23,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:23,812 INFO:     Epoch: 11
2022-11-22 20:21:24,587 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8310440995476462, 'Total loss': 0.8310440995476462} | train loss {'Reaction outcome loss': 0.8034049618823326, 'Total loss': 0.8034049618823326}
2022-11-22 20:21:24,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:24,587 INFO:     Epoch: 12
2022-11-22 20:21:25,327 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8244379230520942, 'Total loss': 0.8244379230520942} | train loss {'Reaction outcome loss': 0.7997379418809404, 'Total loss': 0.7997379418809404}
2022-11-22 20:21:25,327 INFO:     Found new best model at epoch 12
2022-11-22 20:21:25,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:25,328 INFO:     Epoch: 13
2022-11-22 20:21:26,118 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8259537436745383, 'Total loss': 0.8259537436745383} | train loss {'Reaction outcome loss': 0.7916974063947616, 'Total loss': 0.7916974063947616}
2022-11-22 20:21:26,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:26,119 INFO:     Epoch: 14
2022-11-22 20:21:26,879 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8640313378789208, 'Total loss': 0.8640313378789208} | train loss {'Reaction outcome loss': 0.7940832726385912, 'Total loss': 0.7940832726385912}
2022-11-22 20:21:26,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:26,879 INFO:     Epoch: 15
2022-11-22 20:21:27,605 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8493865403262052, 'Total loss': 0.8493865403262052} | train loss {'Reaction outcome loss': 0.8114240146600283, 'Total loss': 0.8114240146600283}
2022-11-22 20:21:27,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:27,605 INFO:     Epoch: 16
2022-11-22 20:21:28,357 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8214668868617578, 'Total loss': 0.8214668868617578} | train loss {'Reaction outcome loss': 0.7965191240735382, 'Total loss': 0.7965191240735382}
2022-11-22 20:21:28,357 INFO:     Found new best model at epoch 16
2022-11-22 20:21:28,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:28,358 INFO:     Epoch: 17
2022-11-22 20:21:29,109 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8360975594683127, 'Total loss': 0.8360975594683127} | train loss {'Reaction outcome loss': 0.7877267963490505, 'Total loss': 0.7877267963490505}
2022-11-22 20:21:29,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:29,109 INFO:     Epoch: 18
2022-11-22 20:21:29,810 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8153508034619418, 'Total loss': 0.8153508034619418} | train loss {'Reaction outcome loss': 0.7904496225509566, 'Total loss': 0.7904496225509566}
2022-11-22 20:21:29,810 INFO:     Found new best model at epoch 18
2022-11-22 20:21:29,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:29,811 INFO:     Epoch: 19
2022-11-22 20:21:30,550 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8085575828498061, 'Total loss': 0.8085575828498061} | train loss {'Reaction outcome loss': 0.7878720655072073, 'Total loss': 0.7878720655072073}
2022-11-22 20:21:30,550 INFO:     Found new best model at epoch 19
2022-11-22 20:21:30,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:30,551 INFO:     Epoch: 20
2022-11-22 20:21:31,334 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8253187367861922, 'Total loss': 0.8253187367861922} | train loss {'Reaction outcome loss': 0.7908594073795596, 'Total loss': 0.7908594073795596}
2022-11-22 20:21:31,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:31,334 INFO:     Epoch: 21
2022-11-22 20:21:32,101 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8133863745765253, 'Total loss': 0.8133863745765253} | train loss {'Reaction outcome loss': 0.7899123758439593, 'Total loss': 0.7899123758439593}
2022-11-22 20:21:32,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:32,101 INFO:     Epoch: 22
2022-11-22 20:21:32,878 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8339823599566113, 'Total loss': 0.8339823599566113} | train loss {'Reaction outcome loss': 0.7845265452678387, 'Total loss': 0.7845265452678387}
2022-11-22 20:21:32,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:32,879 INFO:     Epoch: 23
2022-11-22 20:21:33,658 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.872267334298654, 'Total loss': 0.872267334298654} | train loss {'Reaction outcome loss': 0.7834535126201054, 'Total loss': 0.7834535126201054}
2022-11-22 20:21:33,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:33,658 INFO:     Epoch: 24
2022-11-22 20:21:34,444 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8231455277312886, 'Total loss': 0.8231455277312886} | train loss {'Reaction outcome loss': 0.7870789833276378, 'Total loss': 0.7870789833276378}
2022-11-22 20:21:34,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:34,445 INFO:     Epoch: 25
2022-11-22 20:21:35,239 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8394432833248918, 'Total loss': 0.8394432833248918} | train loss {'Reaction outcome loss': 0.7780530903232001, 'Total loss': 0.7780530903232001}
2022-11-22 20:21:35,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:35,240 INFO:     Epoch: 26
2022-11-22 20:21:35,967 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8204546794295311, 'Total loss': 0.8204546794295311} | train loss {'Reaction outcome loss': 0.7779273466783979, 'Total loss': 0.7779273466783979}
2022-11-22 20:21:35,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:35,967 INFO:     Epoch: 27
2022-11-22 20:21:36,755 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8254814879460768, 'Total loss': 0.8254814879460768} | train loss {'Reaction outcome loss': 0.7874237742983861, 'Total loss': 0.7874237742983861}
2022-11-22 20:21:36,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:36,755 INFO:     Epoch: 28
2022-11-22 20:21:37,469 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8135345618833195, 'Total loss': 0.8135345618833195} | train loss {'Reaction outcome loss': 0.785222258886345, 'Total loss': 0.785222258886345}
2022-11-22 20:21:37,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:37,469 INFO:     Epoch: 29
2022-11-22 20:21:38,213 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8307345854965124, 'Total loss': 0.8307345854965124} | train loss {'Reaction outcome loss': 0.7840655453291981, 'Total loss': 0.7840655453291981}
2022-11-22 20:21:38,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:38,214 INFO:     Epoch: 30
2022-11-22 20:21:38,993 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8119995580478148, 'Total loss': 0.8119995580478148} | train loss {'Reaction outcome loss': 0.7887382231019286, 'Total loss': 0.7887382231019286}
2022-11-22 20:21:38,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:38,994 INFO:     Epoch: 31
2022-11-22 20:21:39,745 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8057261597026478, 'Total loss': 0.8057261597026478} | train loss {'Reaction outcome loss': 0.7878537693245691, 'Total loss': 0.7878537693245691}
2022-11-22 20:21:39,745 INFO:     Found new best model at epoch 31
2022-11-22 20:21:39,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:39,746 INFO:     Epoch: 32
2022-11-22 20:21:40,507 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8324071412736719, 'Total loss': 0.8324071412736719} | train loss {'Reaction outcome loss': 0.7829253054732978, 'Total loss': 0.7829253054732978}
2022-11-22 20:21:40,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:40,507 INFO:     Epoch: 33
2022-11-22 20:21:41,251 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.827378467402675, 'Total loss': 0.827378467402675} | train loss {'Reaction outcome loss': 0.7831240930417289, 'Total loss': 0.7831240930417289}
2022-11-22 20:21:41,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:41,252 INFO:     Epoch: 34
2022-11-22 20:21:41,968 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8094665597785603, 'Total loss': 0.8094665597785603} | train loss {'Reaction outcome loss': 0.7839717229126919, 'Total loss': 0.7839717229126919}
2022-11-22 20:21:41,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:41,968 INFO:     Epoch: 35
2022-11-22 20:21:42,692 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8310239111835306, 'Total loss': 0.8310239111835306} | train loss {'Reaction outcome loss': 0.7874072969925066, 'Total loss': 0.7874072969925066}
2022-11-22 20:21:42,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:42,693 INFO:     Epoch: 36
2022-11-22 20:21:43,478 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8575814813375473, 'Total loss': 0.8575814813375473} | train loss {'Reaction outcome loss': 0.7846871516723865, 'Total loss': 0.7846871516723865}
2022-11-22 20:21:43,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:43,478 INFO:     Epoch: 37
2022-11-22 20:21:44,223 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8432607752355662, 'Total loss': 0.8432607752355662} | train loss {'Reaction outcome loss': 0.7839749938834776, 'Total loss': 0.7839749938834776}
2022-11-22 20:21:44,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:44,223 INFO:     Epoch: 38
2022-11-22 20:21:44,983 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8208966106176376, 'Total loss': 0.8208966106176376} | train loss {'Reaction outcome loss': 0.7912861186000499, 'Total loss': 0.7912861186000499}
2022-11-22 20:21:44,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:44,983 INFO:     Epoch: 39
2022-11-22 20:21:45,700 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8037832812829451, 'Total loss': 0.8037832812829451} | train loss {'Reaction outcome loss': 0.782242002274826, 'Total loss': 0.782242002274826}
2022-11-22 20:21:45,700 INFO:     Found new best model at epoch 39
2022-11-22 20:21:45,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:45,701 INFO:     Epoch: 40
2022-11-22 20:21:46,453 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8437884761528536, 'Total loss': 0.8437884761528536} | train loss {'Reaction outcome loss': 0.7788904413037937, 'Total loss': 0.7788904413037937}
2022-11-22 20:21:46,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:46,453 INFO:     Epoch: 41
2022-11-22 20:21:47,281 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8157030201771043, 'Total loss': 0.8157030201771043} | train loss {'Reaction outcome loss': 0.782843881471437, 'Total loss': 0.782843881471437}
2022-11-22 20:21:47,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:47,281 INFO:     Epoch: 42
2022-11-22 20:21:48,066 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8200810531323607, 'Total loss': 0.8200810531323607} | train loss {'Reaction outcome loss': 0.7839761816327148, 'Total loss': 0.7839761816327148}
2022-11-22 20:21:48,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:48,066 INFO:     Epoch: 43
2022-11-22 20:21:48,810 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8014216423034668, 'Total loss': 0.8014216423034668} | train loss {'Reaction outcome loss': 0.776892877074509, 'Total loss': 0.776892877074509}
2022-11-22 20:21:48,810 INFO:     Found new best model at epoch 43
2022-11-22 20:21:48,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:48,811 INFO:     Epoch: 44
2022-11-22 20:21:49,577 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8008854321458123, 'Total loss': 0.8008854321458123} | train loss {'Reaction outcome loss': 0.7846113307032025, 'Total loss': 0.7846113307032025}
2022-11-22 20:21:49,577 INFO:     Found new best model at epoch 44
2022-11-22 20:21:49,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:49,578 INFO:     Epoch: 45
2022-11-22 20:21:50,358 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8396485949104483, 'Total loss': 0.8396485949104483} | train loss {'Reaction outcome loss': 0.778097781213189, 'Total loss': 0.778097781213189}
2022-11-22 20:21:50,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:50,358 INFO:     Epoch: 46
2022-11-22 20:21:51,137 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8089607893065973, 'Total loss': 0.8089607893065973} | train loss {'Reaction outcome loss': 0.7779598023727355, 'Total loss': 0.7779598023727355}
2022-11-22 20:21:51,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:51,138 INFO:     Epoch: 47
2022-11-22 20:21:51,913 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8256966498765078, 'Total loss': 0.8256966498765078} | train loss {'Reaction outcome loss': 0.7790518136099283, 'Total loss': 0.7790518136099283}
2022-11-22 20:21:51,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:51,914 INFO:     Epoch: 48
2022-11-22 20:21:52,687 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7991198680617593, 'Total loss': 0.7991198680617593} | train loss {'Reaction outcome loss': 0.7782496662757658, 'Total loss': 0.7782496662757658}
2022-11-22 20:21:52,688 INFO:     Found new best model at epoch 48
2022-11-22 20:21:52,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:52,689 INFO:     Epoch: 49
2022-11-22 20:21:53,472 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8212359595027837, 'Total loss': 0.8212359595027837} | train loss {'Reaction outcome loss': 0.7762020464669838, 'Total loss': 0.7762020464669838}
2022-11-22 20:21:53,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:53,473 INFO:     Epoch: 50
2022-11-22 20:21:54,249 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8391974934122779, 'Total loss': 0.8391974934122779} | train loss {'Reaction outcome loss': 0.778453928618296, 'Total loss': 0.778453928618296}
2022-11-22 20:21:54,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:54,250 INFO:     Epoch: 51
2022-11-22 20:21:55,009 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8432297049598261, 'Total loss': 0.8432297049598261} | train loss {'Reaction outcome loss': 0.7856838792441827, 'Total loss': 0.7856838792441827}
2022-11-22 20:21:55,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:55,009 INFO:     Epoch: 52
2022-11-22 20:21:55,747 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8221679553389549, 'Total loss': 0.8221679553389549} | train loss {'Reaction outcome loss': 0.7827635963677395, 'Total loss': 0.7827635963677395}
2022-11-22 20:21:55,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:55,748 INFO:     Epoch: 53
2022-11-22 20:21:56,486 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8104263205419887, 'Total loss': 0.8104263205419887} | train loss {'Reaction outcome loss': 0.7845751562340539, 'Total loss': 0.7845751562340539}
2022-11-22 20:21:56,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:56,486 INFO:     Epoch: 54
2022-11-22 20:21:57,264 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8420176397670399, 'Total loss': 0.8420176397670399} | train loss {'Reaction outcome loss': 0.7866505230004005, 'Total loss': 0.7866505230004005}
2022-11-22 20:21:57,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:57,264 INFO:     Epoch: 55
2022-11-22 20:21:58,060 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8104813498529521, 'Total loss': 0.8104813498529521} | train loss {'Reaction outcome loss': 0.7772612944546982, 'Total loss': 0.7772612944546982}
2022-11-22 20:21:58,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:58,060 INFO:     Epoch: 56
2022-11-22 20:21:58,782 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.810944520614364, 'Total loss': 0.810944520614364} | train loss {'Reaction outcome loss': 0.7842804865557172, 'Total loss': 0.7842804865557172}
2022-11-22 20:21:58,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:58,782 INFO:     Epoch: 57
2022-11-22 20:21:59,567 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8073861836032434, 'Total loss': 0.8073861836032434} | train loss {'Reaction outcome loss': 0.7759949488467291, 'Total loss': 0.7759949488467291}
2022-11-22 20:21:59,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:21:59,567 INFO:     Epoch: 58
2022-11-22 20:22:00,378 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8061692078005184, 'Total loss': 0.8061692078005184} | train loss {'Reaction outcome loss': 0.7760849301571305, 'Total loss': 0.7760849301571305}
2022-11-22 20:22:00,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:00,379 INFO:     Epoch: 59
2022-11-22 20:22:01,207 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7965784262527119, 'Total loss': 0.7965784262527119} | train loss {'Reaction outcome loss': 0.7788669244963148, 'Total loss': 0.7788669244963148}
2022-11-22 20:22:01,207 INFO:     Found new best model at epoch 59
2022-11-22 20:22:01,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:01,208 INFO:     Epoch: 60
2022-11-22 20:22:01,994 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8196528628468513, 'Total loss': 0.8196528628468513} | train loss {'Reaction outcome loss': 0.7811904027153124, 'Total loss': 0.7811904027153124}
2022-11-22 20:22:01,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:01,995 INFO:     Epoch: 61
2022-11-22 20:22:02,799 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8285776525735855, 'Total loss': 0.8285776525735855} | train loss {'Reaction outcome loss': 0.7722599030083973, 'Total loss': 0.7722599030083973}
2022-11-22 20:22:02,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:02,799 INFO:     Epoch: 62
2022-11-22 20:22:03,607 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8146083693612706, 'Total loss': 0.8146083693612706} | train loss {'Reaction outcome loss': 0.7900295414422688, 'Total loss': 0.7900295414422688}
2022-11-22 20:22:03,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:03,607 INFO:     Epoch: 63
2022-11-22 20:22:04,408 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8054152171720158, 'Total loss': 0.8054152171720158} | train loss {'Reaction outcome loss': 0.7846961702533096, 'Total loss': 0.7846961702533096}
2022-11-22 20:22:04,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:04,408 INFO:     Epoch: 64
2022-11-22 20:22:05,223 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8242454542355104, 'Total loss': 0.8242454542355104} | train loss {'Reaction outcome loss': 0.7808978773563015, 'Total loss': 0.7808978773563015}
2022-11-22 20:22:05,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:05,224 INFO:     Epoch: 65
2022-11-22 20:22:06,094 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8104069063609297, 'Total loss': 0.8104069063609297} | train loss {'Reaction outcome loss': 0.7712400630418106, 'Total loss': 0.7712400630418106}
2022-11-22 20:22:06,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:06,094 INFO:     Epoch: 66
2022-11-22 20:22:07,028 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8475436561486938, 'Total loss': 0.8475436561486938} | train loss {'Reaction outcome loss': 0.7804552454214829, 'Total loss': 0.7804552454214829}
2022-11-22 20:22:07,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:07,028 INFO:     Epoch: 67
2022-11-22 20:22:07,931 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8077653375538912, 'Total loss': 0.8077653375538912} | train loss {'Reaction outcome loss': 0.7789039238985733, 'Total loss': 0.7789039238985733}
2022-11-22 20:22:07,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:07,931 INFO:     Epoch: 68
2022-11-22 20:22:08,791 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.797136930579489, 'Total loss': 0.797136930579489} | train loss {'Reaction outcome loss': 0.7791679617364397, 'Total loss': 0.7791679617364397}
2022-11-22 20:22:08,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:08,791 INFO:     Epoch: 69
2022-11-22 20:22:09,632 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8203214054757898, 'Total loss': 0.8203214054757898} | train loss {'Reaction outcome loss': 0.7773318551329949, 'Total loss': 0.7773318551329949}
2022-11-22 20:22:09,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:09,632 INFO:     Epoch: 70
2022-11-22 20:22:10,441 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7971016906879165, 'Total loss': 0.7971016906879165} | train loss {'Reaction outcome loss': 0.7776809145021535, 'Total loss': 0.7776809145021535}
2022-11-22 20:22:10,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:10,442 INFO:     Epoch: 71
2022-11-22 20:22:11,271 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7953940176151015, 'Total loss': 0.7953940176151015} | train loss {'Reaction outcome loss': 0.7845487004590903, 'Total loss': 0.7845487004590903}
2022-11-22 20:22:11,272 INFO:     Found new best model at epoch 71
2022-11-22 20:22:11,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:11,273 INFO:     Epoch: 72
2022-11-22 20:22:12,097 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8136590861461379, 'Total loss': 0.8136590861461379} | train loss {'Reaction outcome loss': 0.7799025442194842, 'Total loss': 0.7799025442194842}
2022-11-22 20:22:12,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:12,097 INFO:     Epoch: 73
2022-11-22 20:22:12,954 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8029395084489476, 'Total loss': 0.8029395084489476} | train loss {'Reaction outcome loss': 0.7689258619117351, 'Total loss': 0.7689258619117351}
2022-11-22 20:22:12,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:12,955 INFO:     Epoch: 74
2022-11-22 20:22:13,802 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8237573368982836, 'Total loss': 0.8237573368982836} | train loss {'Reaction outcome loss': 0.7714464296454843, 'Total loss': 0.7714464296454843}
2022-11-22 20:22:13,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:13,802 INFO:     Epoch: 75
2022-11-22 20:22:14,666 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7845463725653562, 'Total loss': 0.7845463725653562} | train loss {'Reaction outcome loss': 0.7708957071005091, 'Total loss': 0.7708957071005091}
2022-11-22 20:22:14,666 INFO:     Found new best model at epoch 75
2022-11-22 20:22:14,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:14,667 INFO:     Epoch: 76
2022-11-22 20:22:15,488 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7991265139796517, 'Total loss': 0.7991265139796517} | train loss {'Reaction outcome loss': 0.7831203602103569, 'Total loss': 0.7831203602103569}
2022-11-22 20:22:15,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:15,488 INFO:     Epoch: 77
2022-11-22 20:22:16,357 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7986489934000102, 'Total loss': 0.7986489934000102} | train loss {'Reaction outcome loss': 0.7698494742213473, 'Total loss': 0.7698494742213473}
2022-11-22 20:22:16,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:16,358 INFO:     Epoch: 78
2022-11-22 20:22:17,234 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8002025749195706, 'Total loss': 0.8002025749195706} | train loss {'Reaction outcome loss': 0.77075479862842, 'Total loss': 0.77075479862842}
2022-11-22 20:22:17,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:17,234 INFO:     Epoch: 79
2022-11-22 20:22:18,125 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7880332320928574, 'Total loss': 0.7880332320928574} | train loss {'Reaction outcome loss': 0.773757263837073, 'Total loss': 0.773757263837073}
2022-11-22 20:22:18,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:18,125 INFO:     Epoch: 80
2022-11-22 20:22:18,968 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8028640327128497, 'Total loss': 0.8028640327128497} | train loss {'Reaction outcome loss': 0.7755593429451529, 'Total loss': 0.7755593429451529}
2022-11-22 20:22:18,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:18,969 INFO:     Epoch: 81
2022-11-22 20:22:19,760 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7899024601687085, 'Total loss': 0.7899024601687085} | train loss {'Reaction outcome loss': 0.7675227302650691, 'Total loss': 0.7675227302650691}
2022-11-22 20:22:19,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:19,760 INFO:     Epoch: 82
2022-11-22 20:22:20,573 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7898233052004467, 'Total loss': 0.7898233052004467} | train loss {'Reaction outcome loss': 0.7756138201425915, 'Total loss': 0.7756138201425915}
2022-11-22 20:22:20,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:20,573 INFO:     Epoch: 83
2022-11-22 20:22:21,408 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7773671305992387, 'Total loss': 0.7773671305992387} | train loss {'Reaction outcome loss': 0.7607817348198369, 'Total loss': 0.7607817348198369}
2022-11-22 20:22:21,409 INFO:     Found new best model at epoch 83
2022-11-22 20:22:21,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:21,409 INFO:     Epoch: 84
2022-11-22 20:22:22,248 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7877078286626122, 'Total loss': 0.7877078286626122} | train loss {'Reaction outcome loss': 0.7679255894321179, 'Total loss': 0.7679255894321179}
2022-11-22 20:22:22,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:22,248 INFO:     Epoch: 85
2022-11-22 20:22:23,107 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7891311611641537, 'Total loss': 0.7891311611641537} | train loss {'Reaction outcome loss': 0.7699993018679291, 'Total loss': 0.7699993018679291}
2022-11-22 20:22:23,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:23,108 INFO:     Epoch: 86
2022-11-22 20:22:23,967 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7931650111621077, 'Total loss': 0.7931650111621077} | train loss {'Reaction outcome loss': 0.7647029537903635, 'Total loss': 0.7647029537903635}
2022-11-22 20:22:23,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:23,968 INFO:     Epoch: 87
2022-11-22 20:22:24,753 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.822764013978568, 'Total loss': 0.822764013978568} | train loss {'Reaction outcome loss': 0.7674512451718211, 'Total loss': 0.7674512451718211}
2022-11-22 20:22:24,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:24,753 INFO:     Epoch: 88
2022-11-22 20:22:25,610 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7700252255255525, 'Total loss': 0.7700252255255525} | train loss {'Reaction outcome loss': 0.768397400314026, 'Total loss': 0.768397400314026}
2022-11-22 20:22:25,611 INFO:     Found new best model at epoch 88
2022-11-22 20:22:25,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:25,612 INFO:     Epoch: 89
2022-11-22 20:22:26,481 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8005084883082997, 'Total loss': 0.8005084883082997} | train loss {'Reaction outcome loss': 0.7644804149021504, 'Total loss': 0.7644804149021504}
2022-11-22 20:22:26,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:26,482 INFO:     Epoch: 90
2022-11-22 20:22:27,345 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8007512458346107, 'Total loss': 0.8007512458346107} | train loss {'Reaction outcome loss': 0.7646320405517996, 'Total loss': 0.7646320405517996}
2022-11-22 20:22:27,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:27,345 INFO:     Epoch: 91
2022-11-22 20:22:28,179 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7718264067714865, 'Total loss': 0.7718264067714865} | train loss {'Reaction outcome loss': 0.7563796866277934, 'Total loss': 0.7563796866277934}
2022-11-22 20:22:28,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:28,180 INFO:     Epoch: 92
2022-11-22 20:22:29,008 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.795704959468408, 'Total loss': 0.795704959468408} | train loss {'Reaction outcome loss': 0.7586701502684157, 'Total loss': 0.7586701502684157}
2022-11-22 20:22:29,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:29,009 INFO:     Epoch: 93
2022-11-22 20:22:29,839 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8305951688777317, 'Total loss': 0.8305951688777317} | train loss {'Reaction outcome loss': 0.7441999716797338, 'Total loss': 0.7441999716797338}
2022-11-22 20:22:29,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:29,839 INFO:     Epoch: 94
2022-11-22 20:22:30,646 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7544145468961109, 'Total loss': 0.7544145468961109} | train loss {'Reaction outcome loss': 0.7554219091228145, 'Total loss': 0.7554219091228145}
2022-11-22 20:22:30,646 INFO:     Found new best model at epoch 94
2022-11-22 20:22:30,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:30,647 INFO:     Epoch: 95
2022-11-22 20:22:31,447 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7635470073331486, 'Total loss': 0.7635470073331486} | train loss {'Reaction outcome loss': 0.7499975796170563, 'Total loss': 0.7499975796170563}
2022-11-22 20:22:31,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:31,447 INFO:     Epoch: 96
2022-11-22 20:22:32,245 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7696645910089667, 'Total loss': 0.7696645910089667} | train loss {'Reaction outcome loss': 0.7606078497311364, 'Total loss': 0.7606078497311364}
2022-11-22 20:22:32,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:32,245 INFO:     Epoch: 97
2022-11-22 20:22:33,032 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7641354480927641, 'Total loss': 0.7641354480927641} | train loss {'Reaction outcome loss': 0.7457850335339303, 'Total loss': 0.7457850335339303}
2022-11-22 20:22:33,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:33,033 INFO:     Epoch: 98
2022-11-22 20:22:33,841 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7743038684129715, 'Total loss': 0.7743038684129715} | train loss {'Reaction outcome loss': 0.7479965455136318, 'Total loss': 0.7479965455136318}
2022-11-22 20:22:33,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:33,841 INFO:     Epoch: 99
2022-11-22 20:22:34,677 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7750130566683683, 'Total loss': 0.7750130566683683} | train loss {'Reaction outcome loss': 0.776547305014452, 'Total loss': 0.776547305014452}
2022-11-22 20:22:34,678 INFO:     Best model found after epoch 95 of 100.
2022-11-22 20:22:34,678 INFO:   Done with stage: TRAINING
2022-11-22 20:22:34,678 INFO:   Starting stage: EVALUATION
2022-11-22 20:22:34,797 INFO:   Done with stage: EVALUATION
2022-11-22 20:22:34,806 INFO:   Leaving out SEQ value Fold_0
2022-11-22 20:22:34,820 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-22 20:22:34,820 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:22:35,498 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:22:35,498 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:22:35,569 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:22:35,569 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:22:35,570 INFO:     No hyperparam tuning for this model
2022-11-22 20:22:35,570 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:22:35,570 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:22:35,570 INFO:     None feature selector for col prot
2022-11-22 20:22:35,571 INFO:     None feature selector for col prot
2022-11-22 20:22:35,571 INFO:     None feature selector for col prot
2022-11-22 20:22:35,571 INFO:     None feature selector for col chem
2022-11-22 20:22:35,571 INFO:     None feature selector for col chem
2022-11-22 20:22:35,571 INFO:     None feature selector for col chem
2022-11-22 20:22:35,572 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:22:35,572 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:22:35,573 INFO:     Number of params in model 126091
2022-11-22 20:22:35,576 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:22:35,576 INFO:   Starting stage: TRAINING
2022-11-22 20:22:35,627 INFO:     Val loss before train {'Reaction outcome loss': 0.9649772768796876, 'Total loss': 0.9649772768796876}
2022-11-22 20:22:35,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:35,627 INFO:     Epoch: 0
2022-11-22 20:22:36,414 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8533531468968059, 'Total loss': 0.8533531468968059} | train loss {'Reaction outcome loss': 0.8825510583296725, 'Total loss': 0.8825510583296725}
2022-11-22 20:22:36,415 INFO:     Found new best model at epoch 0
2022-11-22 20:22:36,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:36,416 INFO:     Epoch: 1
2022-11-22 20:22:37,252 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7700345627097196, 'Total loss': 0.7700345627097196} | train loss {'Reaction outcome loss': 0.843376802196228, 'Total loss': 0.843376802196228}
2022-11-22 20:22:37,252 INFO:     Found new best model at epoch 1
2022-11-22 20:22:37,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:37,253 INFO:     Epoch: 2
2022-11-22 20:22:38,071 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7705056071281433, 'Total loss': 0.7705056071281433} | train loss {'Reaction outcome loss': 0.830070357263824, 'Total loss': 0.830070357263824}
2022-11-22 20:22:38,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:38,071 INFO:     Epoch: 3
2022-11-22 20:22:38,826 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7683085979417313, 'Total loss': 0.7683085979417313} | train loss {'Reaction outcome loss': 0.8239556840417807, 'Total loss': 0.8239556840417807}
2022-11-22 20:22:38,826 INFO:     Found new best model at epoch 3
2022-11-22 20:22:38,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:38,827 INFO:     Epoch: 4
2022-11-22 20:22:39,610 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7725702427154364, 'Total loss': 0.7725702427154364} | train loss {'Reaction outcome loss': 0.8184470455832933, 'Total loss': 0.8184470455832933}
2022-11-22 20:22:39,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:39,610 INFO:     Epoch: 5
2022-11-22 20:22:40,406 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7604487773983978, 'Total loss': 0.7604487773983978} | train loss {'Reaction outcome loss': 0.8155549480100718, 'Total loss': 0.8155549480100718}
2022-11-22 20:22:40,407 INFO:     Found new best model at epoch 5
2022-11-22 20:22:40,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:40,407 INFO:     Epoch: 6
2022-11-22 20:22:41,158 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7946606493273447, 'Total loss': 0.7946606493273447} | train loss {'Reaction outcome loss': 0.8120840315710861, 'Total loss': 0.8120840315710861}
2022-11-22 20:22:41,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:41,158 INFO:     Epoch: 7
2022-11-22 20:22:41,950 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7353787685549537, 'Total loss': 0.7353787685549537} | train loss {'Reaction outcome loss': 0.8102049140773192, 'Total loss': 0.8102049140773192}
2022-11-22 20:22:41,950 INFO:     Found new best model at epoch 7
2022-11-22 20:22:41,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:41,951 INFO:     Epoch: 8
2022-11-22 20:22:42,725 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7278972378996915, 'Total loss': 0.7278972378996915} | train loss {'Reaction outcome loss': 0.8058790999920771, 'Total loss': 0.8058790999920771}
2022-11-22 20:22:42,726 INFO:     Found new best model at epoch 8
2022-11-22 20:22:42,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:42,727 INFO:     Epoch: 9
2022-11-22 20:22:43,533 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7490681874197583, 'Total loss': 0.7490681874197583} | train loss {'Reaction outcome loss': 0.8062359022260203, 'Total loss': 0.8062359022260203}
2022-11-22 20:22:43,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:43,533 INFO:     Epoch: 10
2022-11-22 20:22:44,312 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7531965901685316, 'Total loss': 0.7531965901685316} | train loss {'Reaction outcome loss': 0.8084477577435136, 'Total loss': 0.8084477577435136}
2022-11-22 20:22:44,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:44,313 INFO:     Epoch: 11
2022-11-22 20:22:45,068 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7522786938866903, 'Total loss': 0.7522786938866903} | train loss {'Reaction outcome loss': 0.7989708638976141, 'Total loss': 0.7989708638976141}
2022-11-22 20:22:45,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:45,069 INFO:     Epoch: 12
2022-11-22 20:22:45,874 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7483163517574931, 'Total loss': 0.7483163517574931} | train loss {'Reaction outcome loss': 0.798809379707148, 'Total loss': 0.798809379707148}
2022-11-22 20:22:45,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:45,874 INFO:     Epoch: 13
2022-11-22 20:22:46,653 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7396682542423869, 'Total loss': 0.7396682542423869} | train loss {'Reaction outcome loss': 0.8002336709587662, 'Total loss': 0.8002336709587662}
2022-11-22 20:22:46,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:46,654 INFO:     Epoch: 14
2022-11-22 20:22:47,428 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7424336734206177, 'Total loss': 0.7424336734206177} | train loss {'Reaction outcome loss': 0.8019958680549276, 'Total loss': 0.8019958680549276}
2022-11-22 20:22:47,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:47,428 INFO:     Epoch: 15
2022-11-22 20:22:48,200 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7401861548423767, 'Total loss': 0.7401861548423767} | train loss {'Reaction outcome loss': 0.7948746466587601, 'Total loss': 0.7948746466587601}
2022-11-22 20:22:48,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:48,200 INFO:     Epoch: 16
2022-11-22 20:22:49,028 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.74565804559131, 'Total loss': 0.74565804559131} | train loss {'Reaction outcome loss': 0.7988481306980667, 'Total loss': 0.7988481306980667}
2022-11-22 20:22:49,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:49,029 INFO:     Epoch: 17
2022-11-22 20:22:49,799 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7421360833700313, 'Total loss': 0.7421360833700313} | train loss {'Reaction outcome loss': 0.7947601289660843, 'Total loss': 0.7947601289660843}
2022-11-22 20:22:49,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:49,800 INFO:     Epoch: 18
2022-11-22 20:22:50,568 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7514123542364254, 'Total loss': 0.7514123542364254} | train loss {'Reaction outcome loss': 0.7956630310403957, 'Total loss': 0.7956630310403957}
2022-11-22 20:22:50,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:50,568 INFO:     Epoch: 19
2022-11-22 20:22:51,348 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7256976151189138, 'Total loss': 0.7256976151189138} | train loss {'Reaction outcome loss': 0.7967206860275425, 'Total loss': 0.7967206860275425}
2022-11-22 20:22:51,348 INFO:     Found new best model at epoch 19
2022-11-22 20:22:51,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:51,349 INFO:     Epoch: 20
2022-11-22 20:22:52,137 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7408201874688615, 'Total loss': 0.7408201874688615} | train loss {'Reaction outcome loss': 0.7909513543907998, 'Total loss': 0.7909513543907998}
2022-11-22 20:22:52,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:52,138 INFO:     Epoch: 21
2022-11-22 20:22:52,886 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7417164659777353, 'Total loss': 0.7417164659777353} | train loss {'Reaction outcome loss': 0.7918324265705705, 'Total loss': 0.7918324265705705}
2022-11-22 20:22:52,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:52,886 INFO:     Epoch: 22
2022-11-22 20:22:53,683 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.736575796160587, 'Total loss': 0.736575796160587} | train loss {'Reaction outcome loss': 0.7955782001401172, 'Total loss': 0.7955782001401172}
2022-11-22 20:22:53,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:53,683 INFO:     Epoch: 23
2022-11-22 20:22:54,485 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7223983407020569, 'Total loss': 0.7223983407020569} | train loss {'Reaction outcome loss': 0.7844575582217778, 'Total loss': 0.7844575582217778}
2022-11-22 20:22:54,485 INFO:     Found new best model at epoch 23
2022-11-22 20:22:54,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:54,486 INFO:     Epoch: 24
2022-11-22 20:22:55,272 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7344180400981459, 'Total loss': 0.7344180400981459} | train loss {'Reaction outcome loss': 0.7935637364416946, 'Total loss': 0.7935637364416946}
2022-11-22 20:22:55,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:55,273 INFO:     Epoch: 25
2022-11-22 20:22:56,063 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.736282768637635, 'Total loss': 0.736282768637635} | train loss {'Reaction outcome loss': 0.7884749932053648, 'Total loss': 0.7884749932053648}
2022-11-22 20:22:56,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:56,064 INFO:     Epoch: 26
2022-11-22 20:22:56,868 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7405056925707085, 'Total loss': 0.7405056925707085} | train loss {'Reaction outcome loss': 0.7921081112981333, 'Total loss': 0.7921081112981333}
2022-11-22 20:22:56,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:56,868 INFO:     Epoch: 27
2022-11-22 20:22:57,655 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7310310331887977, 'Total loss': 0.7310310331887977} | train loss {'Reaction outcome loss': 0.7882751824924484, 'Total loss': 0.7882751824924484}
2022-11-22 20:22:57,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:57,656 INFO:     Epoch: 28
2022-11-22 20:22:58,430 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7766800377258035, 'Total loss': 0.7766800377258035} | train loss {'Reaction outcome loss': 0.7948687354968899, 'Total loss': 0.7948687354968899}
2022-11-22 20:22:58,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:58,430 INFO:     Epoch: 29
2022-11-22 20:22:59,208 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7595722876315893, 'Total loss': 0.7595722876315893} | train loss {'Reaction outcome loss': 0.792794744296329, 'Total loss': 0.792794744296329}
2022-11-22 20:22:59,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:22:59,208 INFO:     Epoch: 30
2022-11-22 20:23:00,038 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.741064565126286, 'Total loss': 0.741064565126286} | train loss {'Reaction outcome loss': 0.7908020024436982, 'Total loss': 0.7908020024436982}
2022-11-22 20:23:00,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:00,038 INFO:     Epoch: 31
2022-11-22 20:23:00,864 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7340882226478221, 'Total loss': 0.7340882226478221} | train loss {'Reaction outcome loss': 0.7903017058294006, 'Total loss': 0.7903017058294006}
2022-11-22 20:23:00,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:00,864 INFO:     Epoch: 32
2022-11-22 20:23:01,693 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7272628816061242, 'Total loss': 0.7272628816061242} | train loss {'Reaction outcome loss': 0.7891783905617985, 'Total loss': 0.7891783905617985}
2022-11-22 20:23:01,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:01,694 INFO:     Epoch: 33
2022-11-22 20:23:02,490 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7266938208147536, 'Total loss': 0.7266938208147536} | train loss {'Reaction outcome loss': 0.7935125196176301, 'Total loss': 0.7935125196176301}
2022-11-22 20:23:02,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:02,490 INFO:     Epoch: 34
2022-11-22 20:23:03,313 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7395372993724291, 'Total loss': 0.7395372993724291} | train loss {'Reaction outcome loss': 0.7876615258156027, 'Total loss': 0.7876615258156027}
2022-11-22 20:23:03,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:03,314 INFO:     Epoch: 35
2022-11-22 20:23:04,095 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7517436146736145, 'Total loss': 0.7517436146736145} | train loss {'Reaction outcome loss': 0.7911176847087013, 'Total loss': 0.7911176847087013}
2022-11-22 20:23:04,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:04,095 INFO:     Epoch: 36
2022-11-22 20:23:04,934 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7265729079412859, 'Total loss': 0.7265729079412859} | train loss {'Reaction outcome loss': 0.7906416940345685, 'Total loss': 0.7906416940345685}
2022-11-22 20:23:04,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:04,935 INFO:     Epoch: 37
2022-11-22 20:23:05,701 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7667435109615326, 'Total loss': 0.7667435109615326} | train loss {'Reaction outcome loss': 0.7929979724648558, 'Total loss': 0.7929979724648558}
2022-11-22 20:23:05,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:05,702 INFO:     Epoch: 38
2022-11-22 20:23:06,523 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7272066529407057, 'Total loss': 0.7272066529407057} | train loss {'Reaction outcome loss': 0.7894704841046667, 'Total loss': 0.7894704841046667}
2022-11-22 20:23:06,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:06,523 INFO:     Epoch: 39
2022-11-22 20:23:07,311 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7623341949873192, 'Total loss': 0.7623341949873192} | train loss {'Reaction outcome loss': 0.7884867975005397, 'Total loss': 0.7884867975005397}
2022-11-22 20:23:07,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:07,312 INFO:     Epoch: 40
2022-11-22 20:23:08,051 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.743922948144203, 'Total loss': 0.743922948144203} | train loss {'Reaction outcome loss': 0.7922044873482896, 'Total loss': 0.7922044873482896}
2022-11-22 20:23:08,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:08,052 INFO:     Epoch: 41
2022-11-22 20:23:08,841 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7278492582398791, 'Total loss': 0.7278492582398791} | train loss {'Reaction outcome loss': 0.7910977678043852, 'Total loss': 0.7910977678043852}
2022-11-22 20:23:08,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:08,841 INFO:     Epoch: 42
2022-11-22 20:23:09,603 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7260737391405327, 'Total loss': 0.7260737391405327} | train loss {'Reaction outcome loss': 0.7907755681516703, 'Total loss': 0.7907755681516703}
2022-11-22 20:23:09,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:09,603 INFO:     Epoch: 43
2022-11-22 20:23:10,366 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7593204427597134, 'Total loss': 0.7593204427597134} | train loss {'Reaction outcome loss': 0.7871586536919629, 'Total loss': 0.7871586536919629}
2022-11-22 20:23:10,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:10,367 INFO:     Epoch: 44
2022-11-22 20:23:11,137 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7108783181323561, 'Total loss': 0.7108783181323561} | train loss {'Reaction outcome loss': 0.7954846576408103, 'Total loss': 0.7954846576408103}
2022-11-22 20:23:11,137 INFO:     Found new best model at epoch 44
2022-11-22 20:23:11,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:11,138 INFO:     Epoch: 45
2022-11-22 20:23:11,876 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7265997632991436, 'Total loss': 0.7265997632991436} | train loss {'Reaction outcome loss': 0.7925405583263915, 'Total loss': 0.7925405583263915}
2022-11-22 20:23:11,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:11,876 INFO:     Epoch: 46
2022-11-22 20:23:12,593 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7533218119033548, 'Total loss': 0.7533218119033548} | train loss {'Reaction outcome loss': 0.7905609258163122, 'Total loss': 0.7905609258163122}
2022-11-22 20:23:12,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:12,593 INFO:     Epoch: 47
2022-11-22 20:23:13,329 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7404196643552114, 'Total loss': 0.7404196643552114} | train loss {'Reaction outcome loss': 0.7915996597627554, 'Total loss': 0.7915996597627554}
2022-11-22 20:23:13,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:13,330 INFO:     Epoch: 48
2022-11-22 20:23:14,054 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7483367413975471, 'Total loss': 0.7483367413975471} | train loss {'Reaction outcome loss': 0.7897848397370719, 'Total loss': 0.7897848397370719}
2022-11-22 20:23:14,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:14,054 INFO:     Epoch: 49
2022-11-22 20:23:14,768 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7411711853603984, 'Total loss': 0.7411711853603984} | train loss {'Reaction outcome loss': 0.7864489771211098, 'Total loss': 0.7864489771211098}
2022-11-22 20:23:14,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:14,769 INFO:     Epoch: 50
2022-11-22 20:23:15,484 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7218390703201294, 'Total loss': 0.7218390703201294} | train loss {'Reaction outcome loss': 0.7906620719550569, 'Total loss': 0.7906620719550569}
2022-11-22 20:23:15,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:15,485 INFO:     Epoch: 51
2022-11-22 20:23:16,198 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7186667278062465, 'Total loss': 0.7186667278062465} | train loss {'Reaction outcome loss': 0.7882058541961168, 'Total loss': 0.7882058541961168}
2022-11-22 20:23:16,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:16,199 INFO:     Epoch: 52
2022-11-22 20:23:16,935 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7370540735333465, 'Total loss': 0.7370540735333465} | train loss {'Reaction outcome loss': 0.7885171496328504, 'Total loss': 0.7885171496328504}
2022-11-22 20:23:16,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:16,935 INFO:     Epoch: 53
2022-11-22 20:23:17,660 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7354930375897607, 'Total loss': 0.7354930375897607} | train loss {'Reaction outcome loss': 0.7897316012608171, 'Total loss': 0.7897316012608171}
2022-11-22 20:23:17,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:17,661 INFO:     Epoch: 54
2022-11-22 20:23:18,393 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7464402054631433, 'Total loss': 0.7464402054631433} | train loss {'Reaction outcome loss': 0.7891314046863666, 'Total loss': 0.7891314046863666}
2022-11-22 20:23:18,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:18,393 INFO:     Epoch: 55
2022-11-22 20:23:19,115 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7232447391332582, 'Total loss': 0.7232447391332582} | train loss {'Reaction outcome loss': 0.7870635611039621, 'Total loss': 0.7870635611039621}
2022-11-22 20:23:19,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:19,115 INFO:     Epoch: 56
2022-11-22 20:23:19,818 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7383428236772848, 'Total loss': 0.7383428236772848} | train loss {'Reaction outcome loss': 0.7902575099664461, 'Total loss': 0.7902575099664461}
2022-11-22 20:23:19,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:19,818 INFO:     Epoch: 57
2022-11-22 20:23:20,556 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7251477331616157, 'Total loss': 0.7251477331616157} | train loss {'Reaction outcome loss': 0.791185709061446, 'Total loss': 0.791185709061446}
2022-11-22 20:23:20,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:20,556 INFO:     Epoch: 58
2022-11-22 20:23:21,299 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.717211362927459, 'Total loss': 0.717211362927459} | train loss {'Reaction outcome loss': 0.787287702776277, 'Total loss': 0.787287702776277}
2022-11-22 20:23:21,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:21,299 INFO:     Epoch: 59
2022-11-22 20:23:22,020 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7406079644380614, 'Total loss': 0.7406079644380614} | train loss {'Reaction outcome loss': 0.7889280724549981, 'Total loss': 0.7889280724549981}
2022-11-22 20:23:22,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:22,021 INFO:     Epoch: 60
2022-11-22 20:23:22,738 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7326967376609181, 'Total loss': 0.7326967376609181} | train loss {'Reaction outcome loss': 0.7848239886907884, 'Total loss': 0.7848239886907884}
2022-11-22 20:23:22,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:22,738 INFO:     Epoch: 61
2022-11-22 20:23:23,458 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7120187920193339, 'Total loss': 0.7120187920193339} | train loss {'Reaction outcome loss': 0.7852425484500304, 'Total loss': 0.7852425484500304}
2022-11-22 20:23:23,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:23,459 INFO:     Epoch: 62
2022-11-22 20:23:24,180 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7426459706106852, 'Total loss': 0.7426459706106852} | train loss {'Reaction outcome loss': 0.784132931458116, 'Total loss': 0.784132931458116}
2022-11-22 20:23:24,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:24,181 INFO:     Epoch: 63
2022-11-22 20:23:24,941 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.755358895590139, 'Total loss': 0.755358895590139} | train loss {'Reaction outcome loss': 0.7901234051572933, 'Total loss': 0.7901234051572933}
2022-11-22 20:23:24,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:24,941 INFO:     Epoch: 64
2022-11-22 20:23:25,687 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7409582248953885, 'Total loss': 0.7409582248953885} | train loss {'Reaction outcome loss': 0.7902054968194215, 'Total loss': 0.7902054968194215}
2022-11-22 20:23:25,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:25,688 INFO:     Epoch: 65
2022-11-22 20:23:26,476 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.723048058360122, 'Total loss': 0.723048058360122} | train loss {'Reaction outcome loss': 0.7880577055024512, 'Total loss': 0.7880577055024512}
2022-11-22 20:23:26,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:26,477 INFO:     Epoch: 66
2022-11-22 20:23:27,245 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7191462114799855, 'Total loss': 0.7191462114799855} | train loss {'Reaction outcome loss': 0.7891303869922466, 'Total loss': 0.7891303869922466}
2022-11-22 20:23:27,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:27,245 INFO:     Epoch: 67
2022-11-22 20:23:28,008 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7108055207618448, 'Total loss': 0.7108055207618448} | train loss {'Reaction outcome loss': 0.7829759783214993, 'Total loss': 0.7829759783214993}
2022-11-22 20:23:28,009 INFO:     Found new best model at epoch 67
2022-11-22 20:23:28,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:28,010 INFO:     Epoch: 68
2022-11-22 20:23:28,808 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7454345399557158, 'Total loss': 0.7454345399557158} | train loss {'Reaction outcome loss': 0.7849702306490376, 'Total loss': 0.7849702306490376}
2022-11-22 20:23:28,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:28,808 INFO:     Epoch: 69
2022-11-22 20:23:29,570 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7431561593399492, 'Total loss': 0.7431561593399492} | train loss {'Reaction outcome loss': 0.7892858554061057, 'Total loss': 0.7892858554061057}
2022-11-22 20:23:29,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:29,570 INFO:     Epoch: 70
2022-11-22 20:23:30,294 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.716181744669759, 'Total loss': 0.716181744669759} | train loss {'Reaction outcome loss': 0.7834328316121435, 'Total loss': 0.7834328316121435}
2022-11-22 20:23:30,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:30,294 INFO:     Epoch: 71
2022-11-22 20:23:31,035 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7184350150962209, 'Total loss': 0.7184350150962209} | train loss {'Reaction outcome loss': 0.7833260321077496, 'Total loss': 0.7833260321077496}
2022-11-22 20:23:31,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:31,035 INFO:     Epoch: 72
2022-11-22 20:23:31,810 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7278594554856767, 'Total loss': 0.7278594554856767} | train loss {'Reaction outcome loss': 0.7743159819532324, 'Total loss': 0.7743159819532324}
2022-11-22 20:23:31,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:31,811 INFO:     Epoch: 73
2022-11-22 20:23:32,581 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7126121451688368, 'Total loss': 0.7126121451688368} | train loss {'Reaction outcome loss': 0.7718943817380034, 'Total loss': 0.7718943817380034}
2022-11-22 20:23:32,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:32,582 INFO:     Epoch: 74
2022-11-22 20:23:33,329 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.716355640527814, 'Total loss': 0.716355640527814} | train loss {'Reaction outcome loss': 0.7790728771882783, 'Total loss': 0.7790728771882783}
2022-11-22 20:23:33,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:33,329 INFO:     Epoch: 75
2022-11-22 20:23:34,080 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7048682168472645, 'Total loss': 0.7048682168472645} | train loss {'Reaction outcome loss': 0.7751480771435632, 'Total loss': 0.7751480771435632}
2022-11-22 20:23:34,080 INFO:     Found new best model at epoch 75
2022-11-22 20:23:34,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:34,081 INFO:     Epoch: 76
2022-11-22 20:23:34,842 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7092933627062066, 'Total loss': 0.7092933627062066} | train loss {'Reaction outcome loss': 0.7762424561957764, 'Total loss': 0.7762424561957764}
2022-11-22 20:23:34,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:34,843 INFO:     Epoch: 77
2022-11-22 20:23:35,549 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7031899046066196, 'Total loss': 0.7031899046066196} | train loss {'Reaction outcome loss': 0.7775105240413681, 'Total loss': 0.7775105240413681}
2022-11-22 20:23:35,549 INFO:     Found new best model at epoch 77
2022-11-22 20:23:35,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:35,550 INFO:     Epoch: 78
2022-11-22 20:23:36,267 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.713977096385734, 'Total loss': 0.713977096385734} | train loss {'Reaction outcome loss': 0.7776086906837337, 'Total loss': 0.7776086906837337}
2022-11-22 20:23:36,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:36,268 INFO:     Epoch: 79
2022-11-22 20:23:37,003 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7155525233856467, 'Total loss': 0.7155525233856467} | train loss {'Reaction outcome loss': 0.7707848103693974, 'Total loss': 0.7707848103693974}
2022-11-22 20:23:37,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:37,004 INFO:     Epoch: 80
2022-11-22 20:23:37,740 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7048539782679358, 'Total loss': 0.7048539782679358} | train loss {'Reaction outcome loss': 0.774230362088592, 'Total loss': 0.774230362088592}
2022-11-22 20:23:37,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:37,741 INFO:     Epoch: 81
2022-11-22 20:23:38,466 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7130893676779991, 'Total loss': 0.7130893676779991} | train loss {'Reaction outcome loss': 0.7688161842371701, 'Total loss': 0.7688161842371701}
2022-11-22 20:23:38,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:38,467 INFO:     Epoch: 82
2022-11-22 20:23:39,228 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7601764617964278, 'Total loss': 0.7601764617964278} | train loss {'Reaction outcome loss': 0.7666473403389071, 'Total loss': 0.7666473403389071}
2022-11-22 20:23:39,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:39,228 INFO:     Epoch: 83
2022-11-22 20:23:39,967 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.732459231171497, 'Total loss': 0.732459231171497} | train loss {'Reaction outcome loss': 0.760879947876734, 'Total loss': 0.760879947876734}
2022-11-22 20:23:39,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:39,967 INFO:     Epoch: 84
2022-11-22 20:23:40,680 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6943815295086351, 'Total loss': 0.6943815295086351} | train loss {'Reaction outcome loss': 0.7632041465598369, 'Total loss': 0.7632041465598369}
2022-11-22 20:23:40,680 INFO:     Found new best model at epoch 84
2022-11-22 20:23:40,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:40,681 INFO:     Epoch: 85
2022-11-22 20:23:41,472 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7374210808166238, 'Total loss': 0.7374210808166238} | train loss {'Reaction outcome loss': 0.7591080545397942, 'Total loss': 0.7591080545397942}
2022-11-22 20:23:41,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:41,472 INFO:     Epoch: 86
2022-11-22 20:23:42,188 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7155788582424785, 'Total loss': 0.7155788582424785} | train loss {'Reaction outcome loss': 0.7575027585765461, 'Total loss': 0.7575027585765461}
2022-11-22 20:23:42,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:42,189 INFO:     Epoch: 87
2022-11-22 20:23:42,971 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.69380545338919, 'Total loss': 0.69380545338919} | train loss {'Reaction outcome loss': 0.751651758397067, 'Total loss': 0.751651758397067}
2022-11-22 20:23:42,971 INFO:     Found new best model at epoch 87
2022-11-22 20:23:42,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:42,972 INFO:     Epoch: 88
2022-11-22 20:23:43,689 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7228194558343222, 'Total loss': 0.7228194558343222} | train loss {'Reaction outcome loss': 0.7550143850928962, 'Total loss': 0.7550143850928962}
2022-11-22 20:23:43,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:43,689 INFO:     Epoch: 89
2022-11-22 20:23:44,436 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6828307904476343, 'Total loss': 0.6828307904476343} | train loss {'Reaction outcome loss': 0.7492784672558553, 'Total loss': 0.7492784672558553}
2022-11-22 20:23:44,436 INFO:     Found new best model at epoch 89
2022-11-22 20:23:44,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:44,437 INFO:     Epoch: 90
2022-11-22 20:23:45,140 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7021382347095845, 'Total loss': 0.7021382347095845} | train loss {'Reaction outcome loss': 0.747312389774087, 'Total loss': 0.747312389774087}
2022-11-22 20:23:45,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:45,141 INFO:     Epoch: 91
2022-11-22 20:23:45,879 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.6893371745597484, 'Total loss': 0.6893371745597484} | train loss {'Reaction outcome loss': 0.7439403998753662, 'Total loss': 0.7439403998753662}
2022-11-22 20:23:45,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:45,879 INFO:     Epoch: 92
2022-11-22 20:23:46,617 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7055027866086294, 'Total loss': 0.7055027866086294} | train loss {'Reaction outcome loss': 0.7422527749352004, 'Total loss': 0.7422527749352004}
2022-11-22 20:23:46,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:46,617 INFO:     Epoch: 93
2022-11-22 20:23:47,363 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6965673565864563, 'Total loss': 0.6965673565864563} | train loss {'Reaction outcome loss': 0.7384417436005156, 'Total loss': 0.7384417436005156}
2022-11-22 20:23:47,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:47,364 INFO:     Epoch: 94
2022-11-22 20:23:48,093 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6781266809895982, 'Total loss': 0.6781266809895982} | train loss {'Reaction outcome loss': 0.7436895861056606, 'Total loss': 0.7436895861056606}
2022-11-22 20:23:48,093 INFO:     Found new best model at epoch 94
2022-11-22 20:23:48,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:48,094 INFO:     Epoch: 95
2022-11-22 20:23:48,828 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7049845734307932, 'Total loss': 0.7049845734307932} | train loss {'Reaction outcome loss': 0.7338621743299343, 'Total loss': 0.7338621743299343}
2022-11-22 20:23:48,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:48,828 INFO:     Epoch: 96
2022-11-22 20:23:49,539 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6655489178590996, 'Total loss': 0.6655489178590996} | train loss {'Reaction outcome loss': 0.7347940188131215, 'Total loss': 0.7347940188131215}
2022-11-22 20:23:49,539 INFO:     Found new best model at epoch 96
2022-11-22 20:23:49,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:49,540 INFO:     Epoch: 97
2022-11-22 20:23:50,276 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6750100698581961, 'Total loss': 0.6750100698581961} | train loss {'Reaction outcome loss': 0.7405689738905479, 'Total loss': 0.7405689738905479}
2022-11-22 20:23:50,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:50,277 INFO:     Epoch: 98
2022-11-22 20:23:51,030 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7710663385169451, 'Total loss': 0.7710663385169451} | train loss {'Reaction outcome loss': 0.7364259345050702, 'Total loss': 0.7364259345050702}
2022-11-22 20:23:51,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:51,030 INFO:     Epoch: 99
2022-11-22 20:23:51,807 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6905227667370508, 'Total loss': 0.6905227667370508} | train loss {'Reaction outcome loss': 0.733071668035209, 'Total loss': 0.733071668035209}
2022-11-22 20:23:51,807 INFO:     Best model found after epoch 97 of 100.
2022-11-22 20:23:51,807 INFO:   Done with stage: TRAINING
2022-11-22 20:23:51,807 INFO:   Starting stage: EVALUATION
2022-11-22 20:23:51,943 INFO:   Done with stage: EVALUATION
2022-11-22 20:23:51,943 INFO:   Leaving out SEQ value Fold_1
2022-11-22 20:23:51,956 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:23:51,957 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:23:52,625 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:23:52,625 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:23:52,694 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:23:52,694 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:23:52,694 INFO:     No hyperparam tuning for this model
2022-11-22 20:23:52,694 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:23:52,694 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:23:52,695 INFO:     None feature selector for col prot
2022-11-22 20:23:52,695 INFO:     None feature selector for col prot
2022-11-22 20:23:52,695 INFO:     None feature selector for col prot
2022-11-22 20:23:52,696 INFO:     None feature selector for col chem
2022-11-22 20:23:52,696 INFO:     None feature selector for col chem
2022-11-22 20:23:52,696 INFO:     None feature selector for col chem
2022-11-22 20:23:52,696 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:23:52,696 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:23:52,697 INFO:     Number of params in model 126091
2022-11-22 20:23:52,700 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:23:52,701 INFO:   Starting stage: TRAINING
2022-11-22 20:23:52,749 INFO:     Val loss before train {'Reaction outcome loss': 1.0259127738800915, 'Total loss': 1.0259127738800915}
2022-11-22 20:23:52,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:52,750 INFO:     Epoch: 0
2022-11-22 20:23:53,509 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8261712396686728, 'Total loss': 0.8261712396686728} | train loss {'Reaction outcome loss': 0.8783356863477452, 'Total loss': 0.8783356863477452}
2022-11-22 20:23:53,509 INFO:     Found new best model at epoch 0
2022-11-22 20:23:53,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:53,510 INFO:     Epoch: 1
2022-11-22 20:23:54,270 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8502646352757107, 'Total loss': 0.8502646352757107} | train loss {'Reaction outcome loss': 0.8554307930623954, 'Total loss': 0.8554307930623954}
2022-11-22 20:23:54,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:54,271 INFO:     Epoch: 2
2022-11-22 20:23:55,043 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8035789389501918, 'Total loss': 0.8035789389501918} | train loss {'Reaction outcome loss': 0.8423120681090877, 'Total loss': 0.8423120681090877}
2022-11-22 20:23:55,043 INFO:     Found new best model at epoch 2
2022-11-22 20:23:55,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:55,045 INFO:     Epoch: 3
2022-11-22 20:23:55,789 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8505705791440877, 'Total loss': 0.8505705791440877} | train loss {'Reaction outcome loss': 0.8322704786713789, 'Total loss': 0.8322704786713789}
2022-11-22 20:23:55,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:55,789 INFO:     Epoch: 4
2022-11-22 20:23:56,557 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8009556904435158, 'Total loss': 0.8009556904435158} | train loss {'Reaction outcome loss': 0.8278780918010333, 'Total loss': 0.8278780918010333}
2022-11-22 20:23:56,557 INFO:     Found new best model at epoch 4
2022-11-22 20:23:56,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:56,558 INFO:     Epoch: 5
2022-11-22 20:23:57,304 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7856580770828507, 'Total loss': 0.7856580770828507} | train loss {'Reaction outcome loss': 0.8229935444318331, 'Total loss': 0.8229935444318331}
2022-11-22 20:23:57,305 INFO:     Found new best model at epoch 5
2022-11-22 20:23:57,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:57,306 INFO:     Epoch: 6
2022-11-22 20:23:58,051 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7915900119326331, 'Total loss': 0.7915900119326331} | train loss {'Reaction outcome loss': 0.8135277805058098, 'Total loss': 0.8135277805058098}
2022-11-22 20:23:58,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:58,051 INFO:     Epoch: 7
2022-11-22 20:23:58,757 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7905351688916032, 'Total loss': 0.7905351688916032} | train loss {'Reaction outcome loss': 0.8152823726899228, 'Total loss': 0.8152823726899228}
2022-11-22 20:23:58,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:58,758 INFO:     Epoch: 8
2022-11-22 20:23:59,490 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8136382042007013, 'Total loss': 0.8136382042007013} | train loss {'Reaction outcome loss': 0.8135734462303671, 'Total loss': 0.8135734462303671}
2022-11-22 20:23:59,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:23:59,491 INFO:     Epoch: 9
2022-11-22 20:24:00,239 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7884142493659799, 'Total loss': 0.7884142493659799} | train loss {'Reaction outcome loss': 0.8084819275840573, 'Total loss': 0.8084819275840573}
2022-11-22 20:24:00,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:00,240 INFO:     Epoch: 10
2022-11-22 20:24:00,996 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.779073331843723, 'Total loss': 0.779073331843723} | train loss {'Reaction outcome loss': 0.8023886555119565, 'Total loss': 0.8023886555119565}
2022-11-22 20:24:00,996 INFO:     Found new best model at epoch 10
2022-11-22 20:24:00,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:00,997 INFO:     Epoch: 11
2022-11-22 20:24:01,755 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7782923484390433, 'Total loss': 0.7782923484390433} | train loss {'Reaction outcome loss': 0.8146464536305864, 'Total loss': 0.8146464536305864}
2022-11-22 20:24:01,755 INFO:     Found new best model at epoch 11
2022-11-22 20:24:01,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:01,756 INFO:     Epoch: 12
2022-11-22 20:24:02,544 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7732515815984119, 'Total loss': 0.7732515815984119} | train loss {'Reaction outcome loss': 0.8070441719732786, 'Total loss': 0.8070441719732786}
2022-11-22 20:24:02,544 INFO:     Found new best model at epoch 12
2022-11-22 20:24:02,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:02,545 INFO:     Epoch: 13
2022-11-22 20:24:03,268 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7841909229755402, 'Total loss': 0.7841909229755402} | train loss {'Reaction outcome loss': 0.7982274975612579, 'Total loss': 0.7982274975612579}
2022-11-22 20:24:03,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:03,268 INFO:     Epoch: 14
2022-11-22 20:24:04,008 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7903865440325304, 'Total loss': 0.7903865440325304} | train loss {'Reaction outcome loss': 0.8008307611894029, 'Total loss': 0.8008307611894029}
2022-11-22 20:24:04,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:04,009 INFO:     Epoch: 15
2022-11-22 20:24:04,738 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7857986891811545, 'Total loss': 0.7857986891811545} | train loss {'Reaction outcome loss': 0.8001765695660703, 'Total loss': 0.8001765695660703}
2022-11-22 20:24:04,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:04,738 INFO:     Epoch: 16
2022-11-22 20:24:05,464 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7976804375648499, 'Total loss': 0.7976804375648499} | train loss {'Reaction outcome loss': 0.7974503723233335, 'Total loss': 0.7974503723233335}
2022-11-22 20:24:05,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:05,465 INFO:     Epoch: 17
2022-11-22 20:24:06,192 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7804880487647924, 'Total loss': 0.7804880487647924} | train loss {'Reaction outcome loss': 0.8028078005622755, 'Total loss': 0.8028078005622755}
2022-11-22 20:24:06,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:06,192 INFO:     Epoch: 18
2022-11-22 20:24:06,925 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7689569517970085, 'Total loss': 0.7689569517970085} | train loss {'Reaction outcome loss': 0.7903709345259647, 'Total loss': 0.7903709345259647}
2022-11-22 20:24:06,925 INFO:     Found new best model at epoch 18
2022-11-22 20:24:06,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:06,926 INFO:     Epoch: 19
2022-11-22 20:24:07,658 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7795017354867675, 'Total loss': 0.7795017354867675} | train loss {'Reaction outcome loss': 0.7928613026132468, 'Total loss': 0.7928613026132468}
2022-11-22 20:24:07,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:07,658 INFO:     Epoch: 20
2022-11-22 20:24:08,363 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7739869268103079, 'Total loss': 0.7739869268103079} | train loss {'Reaction outcome loss': 0.7933379837617218, 'Total loss': 0.7933379837617218}
2022-11-22 20:24:08,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:08,364 INFO:     Epoch: 21
2022-11-22 20:24:09,114 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.771197878501632, 'Total loss': 0.771197878501632} | train loss {'Reaction outcome loss': 0.7972864486910554, 'Total loss': 0.7972864486910554}
2022-11-22 20:24:09,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:09,114 INFO:     Epoch: 22
2022-11-22 20:24:09,846 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.769496959718791, 'Total loss': 0.769496959718791} | train loss {'Reaction outcome loss': 0.8005511919979141, 'Total loss': 0.8005511919979141}
2022-11-22 20:24:09,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:09,847 INFO:     Epoch: 23
2022-11-22 20:24:10,593 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.793981246650219, 'Total loss': 0.793981246650219} | train loss {'Reaction outcome loss': 0.7961336532343737, 'Total loss': 0.7961336532343737}
2022-11-22 20:24:10,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:10,594 INFO:     Epoch: 24
2022-11-22 20:24:11,315 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7647689066149972, 'Total loss': 0.7647689066149972} | train loss {'Reaction outcome loss': 0.790010940087469, 'Total loss': 0.790010940087469}
2022-11-22 20:24:11,316 INFO:     Found new best model at epoch 24
2022-11-22 20:24:11,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:11,316 INFO:     Epoch: 25
2022-11-22 20:24:12,015 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7834962166168473, 'Total loss': 0.7834962166168473} | train loss {'Reaction outcome loss': 0.7949492916887105, 'Total loss': 0.7949492916887105}
2022-11-22 20:24:12,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:12,015 INFO:     Epoch: 26
2022-11-22 20:24:12,720 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7625749470158056, 'Total loss': 0.7625749470158056} | train loss {'Reaction outcome loss': 0.7984212914157492, 'Total loss': 0.7984212914157492}
2022-11-22 20:24:12,720 INFO:     Found new best model at epoch 26
2022-11-22 20:24:12,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:12,721 INFO:     Epoch: 27
2022-11-22 20:24:13,441 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.781607948243618, 'Total loss': 0.781607948243618} | train loss {'Reaction outcome loss': 0.786864013595861, 'Total loss': 0.786864013595861}
2022-11-22 20:24:13,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:13,442 INFO:     Epoch: 28
2022-11-22 20:24:14,178 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7653241469101473, 'Total loss': 0.7653241469101473} | train loss {'Reaction outcome loss': 0.7903576652530716, 'Total loss': 0.7903576652530716}
2022-11-22 20:24:14,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:14,178 INFO:     Epoch: 29
2022-11-22 20:24:14,903 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7735320329666138, 'Total loss': 0.7735320329666138} | train loss {'Reaction outcome loss': 0.7979219184230696, 'Total loss': 0.7979219184230696}
2022-11-22 20:24:14,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:14,904 INFO:     Epoch: 30
2022-11-22 20:24:15,694 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7724413323131475, 'Total loss': 0.7724413323131475} | train loss {'Reaction outcome loss': 0.7909101972937101, 'Total loss': 0.7909101972937101}
2022-11-22 20:24:15,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:15,694 INFO:     Epoch: 31
2022-11-22 20:24:16,410 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7785395885055716, 'Total loss': 0.7785395885055716} | train loss {'Reaction outcome loss': 0.7844646129953233, 'Total loss': 0.7844646129953233}
2022-11-22 20:24:16,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:16,411 INFO:     Epoch: 32
2022-11-22 20:24:17,148 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8465752628716555, 'Total loss': 0.8465752628716555} | train loss {'Reaction outcome loss': 0.7845970904416883, 'Total loss': 0.7845970904416883}
2022-11-22 20:24:17,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:17,148 INFO:     Epoch: 33
2022-11-22 20:24:17,878 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7842116498134353, 'Total loss': 0.7842116498134353} | train loss {'Reaction outcome loss': 0.7894380114942428, 'Total loss': 0.7894380114942428}
2022-11-22 20:24:17,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:17,878 INFO:     Epoch: 34
2022-11-22 20:24:18,615 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7980427437207915, 'Total loss': 0.7980427437207915} | train loss {'Reaction outcome loss': 0.7911545687358872, 'Total loss': 0.7911545687358872}
2022-11-22 20:24:18,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:18,615 INFO:     Epoch: 35
2022-11-22 20:24:19,359 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7645291299982504, 'Total loss': 0.7645291299982504} | train loss {'Reaction outcome loss': 0.7920484038499686, 'Total loss': 0.7920484038499686}
2022-11-22 20:24:19,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:19,359 INFO:     Epoch: 36
2022-11-22 20:24:20,084 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7535517859187993, 'Total loss': 0.7535517859187993} | train loss {'Reaction outcome loss': 0.786984022390022, 'Total loss': 0.786984022390022}
2022-11-22 20:24:20,085 INFO:     Found new best model at epoch 36
2022-11-22 20:24:20,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:20,086 INFO:     Epoch: 37
2022-11-22 20:24:20,825 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7692056901075623, 'Total loss': 0.7692056901075623} | train loss {'Reaction outcome loss': 0.7971555278127492, 'Total loss': 0.7971555278127492}
2022-11-22 20:24:20,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:20,825 INFO:     Epoch: 38
2022-11-22 20:24:21,522 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7744305716319517, 'Total loss': 0.7744305716319517} | train loss {'Reaction outcome loss': 0.7919218944393189, 'Total loss': 0.7919218944393189}
2022-11-22 20:24:21,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:21,523 INFO:     Epoch: 39
2022-11-22 20:24:22,239 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7831859216094017, 'Total loss': 0.7831859216094017} | train loss {'Reaction outcome loss': 0.7914005020852031, 'Total loss': 0.7914005020852031}
2022-11-22 20:24:22,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:22,239 INFO:     Epoch: 40
2022-11-22 20:24:22,989 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7760969420725649, 'Total loss': 0.7760969420725649} | train loss {'Reaction outcome loss': 0.797705312489498, 'Total loss': 0.797705312489498}
2022-11-22 20:24:22,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:22,989 INFO:     Epoch: 41
2022-11-22 20:24:23,771 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7825119183822111, 'Total loss': 0.7825119183822111} | train loss {'Reaction outcome loss': 0.7867874548985407, 'Total loss': 0.7867874548985407}
2022-11-22 20:24:23,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:23,771 INFO:     Epoch: 42
2022-11-22 20:24:24,548 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7704749730500308, 'Total loss': 0.7704749730500308} | train loss {'Reaction outcome loss': 0.794016281361522, 'Total loss': 0.794016281361522}
2022-11-22 20:24:24,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:24,549 INFO:     Epoch: 43
2022-11-22 20:24:25,324 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7452966658906504, 'Total loss': 0.7452966658906504} | train loss {'Reaction outcome loss': 0.7893713906950314, 'Total loss': 0.7893713906950314}
2022-11-22 20:24:25,325 INFO:     Found new best model at epoch 43
2022-11-22 20:24:25,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:25,325 INFO:     Epoch: 44
2022-11-22 20:24:26,077 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7726240794767033, 'Total loss': 0.7726240794767033} | train loss {'Reaction outcome loss': 0.7868904996859399, 'Total loss': 0.7868904996859399}
2022-11-22 20:24:26,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:26,078 INFO:     Epoch: 45
2022-11-22 20:24:26,828 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7917198132384907, 'Total loss': 0.7917198132384907} | train loss {'Reaction outcome loss': 0.784855782744373, 'Total loss': 0.784855782744373}
2022-11-22 20:24:26,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:26,828 INFO:     Epoch: 46
2022-11-22 20:24:27,606 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7796050039204684, 'Total loss': 0.7796050039204684} | train loss {'Reaction outcome loss': 0.7894574877945518, 'Total loss': 0.7894574877945518}
2022-11-22 20:24:27,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:27,606 INFO:     Epoch: 47
2022-11-22 20:24:28,364 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7475901943716136, 'Total loss': 0.7475901943716136} | train loss {'Reaction outcome loss': 0.7960229401405041, 'Total loss': 0.7960229401405041}
2022-11-22 20:24:28,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:28,365 INFO:     Epoch: 48
2022-11-22 20:24:29,133 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7674261236732657, 'Total loss': 0.7674261236732657} | train loss {'Reaction outcome loss': 0.7926801964338974, 'Total loss': 0.7926801964338974}
2022-11-22 20:24:29,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:29,134 INFO:     Epoch: 49
2022-11-22 20:24:29,893 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7372453673319384, 'Total loss': 0.7372453673319384} | train loss {'Reaction outcome loss': 0.7829216026101518, 'Total loss': 0.7829216026101518}
2022-11-22 20:24:29,893 INFO:     Found new best model at epoch 49
2022-11-22 20:24:29,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:29,894 INFO:     Epoch: 50
2022-11-22 20:24:30,652 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7587640265172179, 'Total loss': 0.7587640265172179} | train loss {'Reaction outcome loss': 0.7778107748340498, 'Total loss': 0.7778107748340498}
2022-11-22 20:24:30,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:30,652 INFO:     Epoch: 51
2022-11-22 20:24:31,370 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7398165149444883, 'Total loss': 0.7398165149444883} | train loss {'Reaction outcome loss': 0.7844055051866331, 'Total loss': 0.7844055051866331}
2022-11-22 20:24:31,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:31,370 INFO:     Epoch: 52
2022-11-22 20:24:32,105 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7666263465176929, 'Total loss': 0.7666263465176929} | train loss {'Reaction outcome loss': 0.77247175464203, 'Total loss': 0.77247175464203}
2022-11-22 20:24:32,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:32,106 INFO:     Epoch: 53
2022-11-22 20:24:32,830 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7711781392043288, 'Total loss': 0.7711781392043288} | train loss {'Reaction outcome loss': 0.7773164752644566, 'Total loss': 0.7773164752644566}
2022-11-22 20:24:32,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:32,830 INFO:     Epoch: 54
2022-11-22 20:24:33,602 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7565323994918303, 'Total loss': 0.7565323994918303} | train loss {'Reaction outcome loss': 0.7773879203900151, 'Total loss': 0.7773879203900151}
2022-11-22 20:24:33,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:33,602 INFO:     Epoch: 55
2022-11-22 20:24:34,340 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7806954885070975, 'Total loss': 0.7806954885070975} | train loss {'Reaction outcome loss': 0.7721313048108869, 'Total loss': 0.7721313048108869}
2022-11-22 20:24:34,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:34,340 INFO:     Epoch: 56
2022-11-22 20:24:35,058 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7505299191583287, 'Total loss': 0.7505299191583287} | train loss {'Reaction outcome loss': 0.7774551916822248, 'Total loss': 0.7774551916822248}
2022-11-22 20:24:35,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:35,058 INFO:     Epoch: 57
2022-11-22 20:24:35,803 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7454421811483123, 'Total loss': 0.7454421811483123} | train loss {'Reaction outcome loss': 0.7747845344456584, 'Total loss': 0.7747845344456584}
2022-11-22 20:24:35,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:35,804 INFO:     Epoch: 58
2022-11-22 20:24:36,554 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7258610346100547, 'Total loss': 0.7258610346100547} | train loss {'Reaction outcome loss': 0.7722862568431297, 'Total loss': 0.7722862568431297}
2022-11-22 20:24:36,554 INFO:     Found new best model at epoch 58
2022-11-22 20:24:36,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:36,555 INFO:     Epoch: 59
2022-11-22 20:24:37,361 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8004793470556085, 'Total loss': 0.8004793470556085} | train loss {'Reaction outcome loss': 0.7754040678985689, 'Total loss': 0.7754040678985689}
2022-11-22 20:24:37,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:37,362 INFO:     Epoch: 60
2022-11-22 20:24:38,119 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7544996264305982, 'Total loss': 0.7544996264305982} | train loss {'Reaction outcome loss': 0.7778112229849645, 'Total loss': 0.7778112229849645}
2022-11-22 20:24:38,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:38,119 INFO:     Epoch: 61
2022-11-22 20:24:38,907 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7291413294998083, 'Total loss': 0.7291413294998083} | train loss {'Reaction outcome loss': 0.7591147129593591, 'Total loss': 0.7591147129593591}
2022-11-22 20:24:38,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:38,907 INFO:     Epoch: 62
2022-11-22 20:24:39,666 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7362434200265191, 'Total loss': 0.7362434200265191} | train loss {'Reaction outcome loss': 0.7724005500314689, 'Total loss': 0.7724005500314689}
2022-11-22 20:24:39,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:39,666 INFO:     Epoch: 63
2022-11-22 20:24:40,378 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7934968823736365, 'Total loss': 0.7934968823736365} | train loss {'Reaction outcome loss': 0.7666947147865527, 'Total loss': 0.7666947147865527}
2022-11-22 20:24:40,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:40,378 INFO:     Epoch: 64
2022-11-22 20:24:41,157 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7185915126041933, 'Total loss': 0.7185915126041933} | train loss {'Reaction outcome loss': 0.7544681211473488, 'Total loss': 0.7544681211473488}
2022-11-22 20:24:41,158 INFO:     Found new best model at epoch 64
2022-11-22 20:24:41,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:41,159 INFO:     Epoch: 65
2022-11-22 20:24:41,917 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7291131649505008, 'Total loss': 0.7291131649505008} | train loss {'Reaction outcome loss': 0.7595438995824652, 'Total loss': 0.7595438995824652}
2022-11-22 20:24:41,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:41,918 INFO:     Epoch: 66
2022-11-22 20:24:42,671 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.728520124473355, 'Total loss': 0.728520124473355} | train loss {'Reaction outcome loss': 0.7589868457331831, 'Total loss': 0.7589868457331831}
2022-11-22 20:24:42,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:42,671 INFO:     Epoch: 67
2022-11-22 20:24:43,450 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7200286361304197, 'Total loss': 0.7200286361304197} | train loss {'Reaction outcome loss': 0.7526998320813121, 'Total loss': 0.7526998320813121}
2022-11-22 20:24:43,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:43,450 INFO:     Epoch: 68
2022-11-22 20:24:44,191 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7071213166822087, 'Total loss': 0.7071213166822087} | train loss {'Reaction outcome loss': 0.7582865642753207, 'Total loss': 0.7582865642753207}
2022-11-22 20:24:44,191 INFO:     Found new best model at epoch 68
2022-11-22 20:24:44,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:44,192 INFO:     Epoch: 69
2022-11-22 20:24:44,949 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7057983008298007, 'Total loss': 0.7057983008298007} | train loss {'Reaction outcome loss': 0.7443834878655098, 'Total loss': 0.7443834878655098}
2022-11-22 20:24:44,949 INFO:     Found new best model at epoch 69
2022-11-22 20:24:44,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:44,950 INFO:     Epoch: 70
2022-11-22 20:24:45,678 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7660100405866449, 'Total loss': 0.7660100405866449} | train loss {'Reaction outcome loss': 0.7477493866192184, 'Total loss': 0.7477493866192184}
2022-11-22 20:24:45,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:45,678 INFO:     Epoch: 71
2022-11-22 20:24:46,476 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.72875469381159, 'Total loss': 0.72875469381159} | train loss {'Reaction outcome loss': 0.7447544021856206, 'Total loss': 0.7447544021856206}
2022-11-22 20:24:46,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:46,477 INFO:     Epoch: 72
2022-11-22 20:24:47,245 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.700223258273168, 'Total loss': 0.700223258273168} | train loss {'Reaction outcome loss': 0.7337924720425355, 'Total loss': 0.7337924720425355}
2022-11-22 20:24:47,246 INFO:     Found new best model at epoch 72
2022-11-22 20:24:47,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:47,247 INFO:     Epoch: 73
2022-11-22 20:24:48,033 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7066339328885078, 'Total loss': 0.7066339328885078} | train loss {'Reaction outcome loss': 0.737807590469175, 'Total loss': 0.737807590469175}
2022-11-22 20:24:48,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:48,033 INFO:     Epoch: 74
2022-11-22 20:24:48,781 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7228031002662398, 'Total loss': 0.7228031002662398} | train loss {'Reaction outcome loss': 0.7347769556257889, 'Total loss': 0.7347769556257889}
2022-11-22 20:24:48,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:48,781 INFO:     Epoch: 75
2022-11-22 20:24:49,507 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7795733701099049, 'Total loss': 0.7795733701099049} | train loss {'Reaction outcome loss': 0.7330926022066279, 'Total loss': 0.7330926022066279}
2022-11-22 20:24:49,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:49,508 INFO:     Epoch: 76
2022-11-22 20:24:50,296 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7009105485948649, 'Total loss': 0.7009105485948649} | train loss {'Reaction outcome loss': 0.7402976290869568, 'Total loss': 0.7402976290869568}
2022-11-22 20:24:50,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:50,297 INFO:     Epoch: 77
2022-11-22 20:24:51,020 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7038425972515886, 'Total loss': 0.7038425972515886} | train loss {'Reaction outcome loss': 0.7299861099857551, 'Total loss': 0.7299861099857551}
2022-11-22 20:24:51,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:51,020 INFO:     Epoch: 78
2022-11-22 20:24:51,764 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7127087434584444, 'Total loss': 0.7127087434584444} | train loss {'Reaction outcome loss': 0.7298895780012192, 'Total loss': 0.7298895780012192}
2022-11-22 20:24:51,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:51,764 INFO:     Epoch: 79
2022-11-22 20:24:52,495 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.729361738670956, 'Total loss': 0.729361738670956} | train loss {'Reaction outcome loss': 0.7253458958405715, 'Total loss': 0.7253458958405715}
2022-11-22 20:24:52,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:52,495 INFO:     Epoch: 80
2022-11-22 20:24:53,233 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7133373604579405, 'Total loss': 0.7133373604579405} | train loss {'Reaction outcome loss': 0.7370570437145619, 'Total loss': 0.7370570437145619}
2022-11-22 20:24:53,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:53,233 INFO:     Epoch: 81
2022-11-22 20:24:53,995 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6788422194394198, 'Total loss': 0.6788422194394198} | train loss {'Reaction outcome loss': 0.7248145559056085, 'Total loss': 0.7248145559056085}
2022-11-22 20:24:53,995 INFO:     Found new best model at epoch 81
2022-11-22 20:24:53,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:53,996 INFO:     Epoch: 82
2022-11-22 20:24:54,744 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.6788008240136233, 'Total loss': 0.6788008240136233} | train loss {'Reaction outcome loss': 0.7270098043613227, 'Total loss': 0.7270098043613227}
2022-11-22 20:24:54,744 INFO:     Found new best model at epoch 82
2022-11-22 20:24:54,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:54,745 INFO:     Epoch: 83
2022-11-22 20:24:55,526 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6899276477369395, 'Total loss': 0.6899276477369395} | train loss {'Reaction outcome loss': 0.7224767770965089, 'Total loss': 0.7224767770965089}
2022-11-22 20:24:55,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:55,527 INFO:     Epoch: 84
2022-11-22 20:24:56,300 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7054400498216803, 'Total loss': 0.7054400498216803} | train loss {'Reaction outcome loss': 0.7215660742902563, 'Total loss': 0.7215660742902563}
2022-11-22 20:24:56,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:56,300 INFO:     Epoch: 85
2022-11-22 20:24:57,024 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6708007942546498, 'Total loss': 0.6708007942546498} | train loss {'Reaction outcome loss': 0.7274242165962211, 'Total loss': 0.7274242165962211}
2022-11-22 20:24:57,024 INFO:     Found new best model at epoch 85
2022-11-22 20:24:57,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:57,025 INFO:     Epoch: 86
2022-11-22 20:24:57,738 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7054893530227921, 'Total loss': 0.7054893530227921} | train loss {'Reaction outcome loss': 0.7160933329026226, 'Total loss': 0.7160933329026226}
2022-11-22 20:24:57,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:57,738 INFO:     Epoch: 87
2022-11-22 20:24:58,475 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7106917561455206, 'Total loss': 0.7106917561455206} | train loss {'Reaction outcome loss': 0.717691246827363, 'Total loss': 0.717691246827363}
2022-11-22 20:24:58,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:58,475 INFO:     Epoch: 88
2022-11-22 20:24:59,213 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.663817279718139, 'Total loss': 0.663817279718139} | train loss {'Reaction outcome loss': 0.7150817169592931, 'Total loss': 0.7150817169592931}
2022-11-22 20:24:59,214 INFO:     Found new best model at epoch 88
2022-11-22 20:24:59,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:59,214 INFO:     Epoch: 89
2022-11-22 20:24:59,976 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6884838119149208, 'Total loss': 0.6884838119149208} | train loss {'Reaction outcome loss': 0.7298161688483196, 'Total loss': 0.7298161688483196}
2022-11-22 20:24:59,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:24:59,977 INFO:     Epoch: 90
2022-11-22 20:25:00,713 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6709496507590468, 'Total loss': 0.6709496507590468} | train loss {'Reaction outcome loss': 0.7257689571814981, 'Total loss': 0.7257689571814981}
2022-11-22 20:25:00,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:00,713 INFO:     Epoch: 91
2022-11-22 20:25:01,475 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.6940142519094727, 'Total loss': 0.6940142519094727} | train loss {'Reaction outcome loss': 0.711937050467078, 'Total loss': 0.711937050467078}
2022-11-22 20:25:01,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:01,476 INFO:     Epoch: 92
2022-11-22 20:25:02,247 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6942842270840298, 'Total loss': 0.6942842270840298} | train loss {'Reaction outcome loss': 0.7216993314534547, 'Total loss': 0.7216993314534547}
2022-11-22 20:25:02,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:02,247 INFO:     Epoch: 93
2022-11-22 20:25:02,999 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7185496288267049, 'Total loss': 0.7185496288267049} | train loss {'Reaction outcome loss': 0.7247936101818857, 'Total loss': 0.7247936101818857}
2022-11-22 20:25:02,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:02,999 INFO:     Epoch: 94
2022-11-22 20:25:03,744 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7025598240169612, 'Total loss': 0.7025598240169612} | train loss {'Reaction outcome loss': 0.7262465629259102, 'Total loss': 0.7262465629259102}
2022-11-22 20:25:03,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:03,744 INFO:     Epoch: 95
2022-11-22 20:25:04,487 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6985376179218292, 'Total loss': 0.6985376179218292} | train loss {'Reaction outcome loss': 0.7241550331656267, 'Total loss': 0.7241550331656267}
2022-11-22 20:25:04,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:04,487 INFO:     Epoch: 96
2022-11-22 20:25:05,333 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7139216600493952, 'Total loss': 0.7139216600493952} | train loss {'Reaction outcome loss': 0.7196458709626062, 'Total loss': 0.7196458709626062}
2022-11-22 20:25:05,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:05,333 INFO:     Epoch: 97
2022-11-22 20:25:06,100 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6791427494450049, 'Total loss': 0.6791427494450049} | train loss {'Reaction outcome loss': 0.7249088148597763, 'Total loss': 0.7249088148597763}
2022-11-22 20:25:06,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:06,100 INFO:     Epoch: 98
2022-11-22 20:25:06,847 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7201206961816008, 'Total loss': 0.7201206961816008} | train loss {'Reaction outcome loss': 0.7328359995354042, 'Total loss': 0.7328359995354042}
2022-11-22 20:25:06,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:06,847 INFO:     Epoch: 99
2022-11-22 20:25:07,598 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6674802157689225, 'Total loss': 0.6674802157689225} | train loss {'Reaction outcome loss': 0.7235644515226727, 'Total loss': 0.7235644515226727}
2022-11-22 20:25:07,598 INFO:     Best model found after epoch 89 of 100.
2022-11-22 20:25:07,598 INFO:   Done with stage: TRAINING
2022-11-22 20:25:07,598 INFO:   Starting stage: EVALUATION
2022-11-22 20:25:07,716 INFO:   Done with stage: EVALUATION
2022-11-22 20:25:07,716 INFO:   Leaving out SEQ value Fold_2
2022-11-22 20:25:07,729 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:25:07,729 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:25:08,394 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:25:08,394 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:25:08,462 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:25:08,463 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:25:08,463 INFO:     No hyperparam tuning for this model
2022-11-22 20:25:08,463 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:25:08,463 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:25:08,464 INFO:     None feature selector for col prot
2022-11-22 20:25:08,464 INFO:     None feature selector for col prot
2022-11-22 20:25:08,464 INFO:     None feature selector for col prot
2022-11-22 20:25:08,464 INFO:     None feature selector for col chem
2022-11-22 20:25:08,464 INFO:     None feature selector for col chem
2022-11-22 20:25:08,465 INFO:     None feature selector for col chem
2022-11-22 20:25:08,465 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:25:08,465 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:25:08,466 INFO:     Number of params in model 126091
2022-11-22 20:25:08,469 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:25:08,469 INFO:   Starting stage: TRAINING
2022-11-22 20:25:08,518 INFO:     Val loss before train {'Reaction outcome loss': 1.0210385810245166, 'Total loss': 1.0210385810245166}
2022-11-22 20:25:08,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:08,519 INFO:     Epoch: 0
2022-11-22 20:25:09,314 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8863443840633739, 'Total loss': 0.8863443840633739} | train loss {'Reaction outcome loss': 0.8972705579533868, 'Total loss': 0.8972705579533868}
2022-11-22 20:25:09,314 INFO:     Found new best model at epoch 0
2022-11-22 20:25:09,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:09,315 INFO:     Epoch: 1
2022-11-22 20:25:10,084 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8690412532199513, 'Total loss': 0.8690412532199513} | train loss {'Reaction outcome loss': 0.8567529082298279, 'Total loss': 0.8567529082298279}
2022-11-22 20:25:10,084 INFO:     Found new best model at epoch 1
2022-11-22 20:25:10,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:10,085 INFO:     Epoch: 2
2022-11-22 20:25:10,870 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8609018163247542, 'Total loss': 0.8609018163247542} | train loss {'Reaction outcome loss': 0.8506918640769258, 'Total loss': 0.8506918640769258}
2022-11-22 20:25:10,870 INFO:     Found new best model at epoch 2
2022-11-22 20:25:10,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:10,871 INFO:     Epoch: 3
2022-11-22 20:25:11,592 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8594780923290686, 'Total loss': 0.8594780923290686} | train loss {'Reaction outcome loss': 0.8468500751621869, 'Total loss': 0.8468500751621869}
2022-11-22 20:25:11,592 INFO:     Found new best model at epoch 3
2022-11-22 20:25:11,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:11,593 INFO:     Epoch: 4
2022-11-22 20:25:12,320 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9097587324001573, 'Total loss': 0.9097587324001573} | train loss {'Reaction outcome loss': 0.8407234309887399, 'Total loss': 0.8407234309887399}
2022-11-22 20:25:12,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:12,322 INFO:     Epoch: 5
2022-11-22 20:25:13,079 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8693577511744066, 'Total loss': 0.8693577511744066} | train loss {'Reaction outcome loss': 0.8292086964967299, 'Total loss': 0.8292086964967299}
2022-11-22 20:25:13,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:13,079 INFO:     Epoch: 6
2022-11-22 20:25:13,816 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8514103306965395, 'Total loss': 0.8514103306965395} | train loss {'Reaction outcome loss': 0.8295942932975535, 'Total loss': 0.8295942932975535}
2022-11-22 20:25:13,816 INFO:     Found new best model at epoch 6
2022-11-22 20:25:13,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:13,817 INFO:     Epoch: 7
2022-11-22 20:25:14,615 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8544289510358464, 'Total loss': 0.8544289510358464} | train loss {'Reaction outcome loss': 0.8268362692424229, 'Total loss': 0.8268362692424229}
2022-11-22 20:25:14,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:14,615 INFO:     Epoch: 8
2022-11-22 20:25:15,372 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8687573278492148, 'Total loss': 0.8687573278492148} | train loss {'Reaction outcome loss': 0.8288740968217655, 'Total loss': 0.8288740968217655}
2022-11-22 20:25:15,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:15,372 INFO:     Epoch: 9
2022-11-22 20:25:16,159 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8270385990088637, 'Total loss': 0.8270385990088637} | train loss {'Reaction outcome loss': 0.8207646541449488, 'Total loss': 0.8207646541449488}
2022-11-22 20:25:16,159 INFO:     Found new best model at epoch 9
2022-11-22 20:25:16,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:16,160 INFO:     Epoch: 10
2022-11-22 20:25:16,948 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.9158373326063156, 'Total loss': 0.9158373326063156} | train loss {'Reaction outcome loss': 0.8206783646223497, 'Total loss': 0.8206783646223497}
2022-11-22 20:25:16,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:16,948 INFO:     Epoch: 11
2022-11-22 20:25:17,704 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8749211098660122, 'Total loss': 0.8749211098660122} | train loss {'Reaction outcome loss': 0.823669583578499, 'Total loss': 0.823669583578499}
2022-11-22 20:25:17,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:17,704 INFO:     Epoch: 12
2022-11-22 20:25:18,426 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8261585343967784, 'Total loss': 0.8261585343967784} | train loss {'Reaction outcome loss': 0.8263182576821775, 'Total loss': 0.8263182576821775}
2022-11-22 20:25:18,427 INFO:     Found new best model at epoch 12
2022-11-22 20:25:18,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:18,428 INFO:     Epoch: 13
2022-11-22 20:25:19,164 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8643738248131492, 'Total loss': 0.8643738248131492} | train loss {'Reaction outcome loss': 0.8218336426481909, 'Total loss': 0.8218336426481909}
2022-11-22 20:25:19,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:19,164 INFO:     Epoch: 14
2022-11-22 20:25:19,904 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8213172568516298, 'Total loss': 0.8213172568516298} | train loss {'Reaction outcome loss': 0.8184633309743843, 'Total loss': 0.8184633309743843}
2022-11-22 20:25:19,904 INFO:     Found new best model at epoch 14
2022-11-22 20:25:19,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:19,905 INFO:     Epoch: 15
2022-11-22 20:25:20,642 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8359296376054938, 'Total loss': 0.8359296376054938} | train loss {'Reaction outcome loss': 0.8218549915722438, 'Total loss': 0.8218549915722438}
2022-11-22 20:25:20,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:20,642 INFO:     Epoch: 16
2022-11-22 20:25:21,376 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8341610397804867, 'Total loss': 0.8341610397804867} | train loss {'Reaction outcome loss': 0.8150008162673639, 'Total loss': 0.8150008162673639}
2022-11-22 20:25:21,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:21,376 INFO:     Epoch: 17
2022-11-22 20:25:22,137 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8360136293552138, 'Total loss': 0.8360136293552138} | train loss {'Reaction outcome loss': 0.8211523564494386, 'Total loss': 0.8211523564494386}
2022-11-22 20:25:22,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:22,138 INFO:     Epoch: 18
2022-11-22 20:25:22,918 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8393436528064988, 'Total loss': 0.8393436528064988} | train loss {'Reaction outcome loss': 0.8173530258694474, 'Total loss': 0.8173530258694474}
2022-11-22 20:25:22,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:22,919 INFO:     Epoch: 19
2022-11-22 20:25:23,718 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8371115963567387, 'Total loss': 0.8371115963567387} | train loss {'Reaction outcome loss': 0.8150316566837077, 'Total loss': 0.8150316566837077}
2022-11-22 20:25:23,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:23,718 INFO:     Epoch: 20
2022-11-22 20:25:24,560 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8572786043990742, 'Total loss': 0.8572786043990742} | train loss {'Reaction outcome loss': 0.8155214253737002, 'Total loss': 0.8155214253737002}
2022-11-22 20:25:24,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:24,560 INFO:     Epoch: 21
2022-11-22 20:25:25,313 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8491246497089212, 'Total loss': 0.8491246497089212} | train loss {'Reaction outcome loss': 0.8160204870360238, 'Total loss': 0.8160204870360238}
2022-11-22 20:25:25,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:25,313 INFO:     Epoch: 22
2022-11-22 20:25:26,009 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8187665065581148, 'Total loss': 0.8187665065581148} | train loss {'Reaction outcome loss': 0.8112329824846618, 'Total loss': 0.8112329824846618}
2022-11-22 20:25:26,009 INFO:     Found new best model at epoch 22
2022-11-22 20:25:26,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:26,010 INFO:     Epoch: 23
2022-11-22 20:25:26,783 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8432702855630354, 'Total loss': 0.8432702855630354} | train loss {'Reaction outcome loss': 0.8208303933240929, 'Total loss': 0.8208303933240929}
2022-11-22 20:25:26,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:26,783 INFO:     Epoch: 24
2022-11-22 20:25:27,512 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8493043028495528, 'Total loss': 0.8493043028495528} | train loss {'Reaction outcome loss': 0.8142587722564231, 'Total loss': 0.8142587722564231}
2022-11-22 20:25:27,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:27,512 INFO:     Epoch: 25
2022-11-22 20:25:28,268 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8461172573945739, 'Total loss': 0.8461172573945739} | train loss {'Reaction outcome loss': 0.8080084445525189, 'Total loss': 0.8080084445525189}
2022-11-22 20:25:28,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:28,268 INFO:     Epoch: 26
2022-11-22 20:25:29,032 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8309718424623663, 'Total loss': 0.8309718424623663} | train loss {'Reaction outcome loss': 0.8115480452167745, 'Total loss': 0.8115480452167745}
2022-11-22 20:25:29,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:29,032 INFO:     Epoch: 27
2022-11-22 20:25:29,776 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8404663327065381, 'Total loss': 0.8404663327065381} | train loss {'Reaction outcome loss': 0.812222698148416, 'Total loss': 0.812222698148416}
2022-11-22 20:25:29,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:29,776 INFO:     Epoch: 28
2022-11-22 20:25:30,539 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8140406930311159, 'Total loss': 0.8140406930311159} | train loss {'Reaction outcome loss': 0.8109311853136335, 'Total loss': 0.8109311853136335}
2022-11-22 20:25:30,540 INFO:     Found new best model at epoch 28
2022-11-22 20:25:30,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:30,541 INFO:     Epoch: 29
2022-11-22 20:25:31,267 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8402555774558674, 'Total loss': 0.8402555774558674} | train loss {'Reaction outcome loss': 0.8064870889089546, 'Total loss': 0.8064870889089546}
2022-11-22 20:25:31,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:31,268 INFO:     Epoch: 30
2022-11-22 20:25:32,004 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8299113413826986, 'Total loss': 0.8299113413826986} | train loss {'Reaction outcome loss': 0.8109727151539861, 'Total loss': 0.8109727151539861}
2022-11-22 20:25:32,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:32,004 INFO:     Epoch: 31
2022-11-22 20:25:32,764 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8128492696718737, 'Total loss': 0.8128492696718737} | train loss {'Reaction outcome loss': 0.818117280882232, 'Total loss': 0.818117280882232}
2022-11-22 20:25:32,765 INFO:     Found new best model at epoch 31
2022-11-22 20:25:32,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:32,765 INFO:     Epoch: 32
2022-11-22 20:25:33,518 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8469254090027376, 'Total loss': 0.8469254090027376} | train loss {'Reaction outcome loss': 0.8108512120587485, 'Total loss': 0.8108512120587485}
2022-11-22 20:25:33,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:33,518 INFO:     Epoch: 33
2022-11-22 20:25:34,254 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8147962059486996, 'Total loss': 0.8147962059486996} | train loss {'Reaction outcome loss': 0.8113700906841123, 'Total loss': 0.8113700906841123}
2022-11-22 20:25:34,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:34,254 INFO:     Epoch: 34
2022-11-22 20:25:35,002 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8273776403882287, 'Total loss': 0.8273776403882287} | train loss {'Reaction outcome loss': 0.8102737850072432, 'Total loss': 0.8102737850072432}
2022-11-22 20:25:35,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:35,002 INFO:     Epoch: 35
2022-11-22 20:25:35,752 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8151098950342699, 'Total loss': 0.8151098950342699} | train loss {'Reaction outcome loss': 0.8078131855750571, 'Total loss': 0.8078131855750571}
2022-11-22 20:25:35,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:35,752 INFO:     Epoch: 36
2022-11-22 20:25:36,483 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8197093971750953, 'Total loss': 0.8197093971750953} | train loss {'Reaction outcome loss': 0.8077750754599669, 'Total loss': 0.8077750754599669}
2022-11-22 20:25:36,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:36,484 INFO:     Epoch: 37
2022-11-22 20:25:37,194 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8242869011380456, 'Total loss': 0.8242869011380456} | train loss {'Reaction outcome loss': 0.8019692126585513, 'Total loss': 0.8019692126585513}
2022-11-22 20:25:37,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:37,195 INFO:     Epoch: 38
2022-11-22 20:25:37,956 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8439114053140987, 'Total loss': 0.8439114053140987} | train loss {'Reaction outcome loss': 0.805411517863371, 'Total loss': 0.805411517863371}
2022-11-22 20:25:37,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:37,956 INFO:     Epoch: 39
2022-11-22 20:25:38,678 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8353364691138268, 'Total loss': 0.8353364691138268} | train loss {'Reaction outcome loss': 0.8025811598008993, 'Total loss': 0.8025811598008993}
2022-11-22 20:25:38,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:38,678 INFO:     Epoch: 40
2022-11-22 20:25:39,395 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8372918496077711, 'Total loss': 0.8372918496077711} | train loss {'Reaction outcome loss': 0.8061094330281627, 'Total loss': 0.8061094330281627}
2022-11-22 20:25:39,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:39,395 INFO:     Epoch: 41
2022-11-22 20:25:40,115 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8448852314190431, 'Total loss': 0.8448852314190431} | train loss {'Reaction outcome loss': 0.808133649096197, 'Total loss': 0.808133649096197}
2022-11-22 20:25:40,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:40,115 INFO:     Epoch: 42
2022-11-22 20:25:40,871 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8437811095606197, 'Total loss': 0.8437811095606197} | train loss {'Reaction outcome loss': 0.8096474115945855, 'Total loss': 0.8096474115945855}
2022-11-22 20:25:40,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:40,871 INFO:     Epoch: 43
2022-11-22 20:25:41,614 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8650098727508024, 'Total loss': 0.8650098727508024} | train loss {'Reaction outcome loss': 0.8083693113862251, 'Total loss': 0.8083693113862251}
2022-11-22 20:25:41,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:41,615 INFO:     Epoch: 44
2022-11-22 20:25:42,363 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8296815461733125, 'Total loss': 0.8296815461733125} | train loss {'Reaction outcome loss': 0.8083357158972293, 'Total loss': 0.8083357158972293}
2022-11-22 20:25:42,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:42,363 INFO:     Epoch: 45
2022-11-22 20:25:43,109 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8279987980018962, 'Total loss': 0.8279987980018962} | train loss {'Reaction outcome loss': 0.8066837533396117, 'Total loss': 0.8066837533396117}
2022-11-22 20:25:43,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:43,111 INFO:     Epoch: 46
2022-11-22 20:25:43,837 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8180906772613525, 'Total loss': 0.8180906772613525} | train loss {'Reaction outcome loss': 0.8049738127358106, 'Total loss': 0.8049738127358106}
2022-11-22 20:25:43,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:43,837 INFO:     Epoch: 47
2022-11-22 20:25:44,597 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8201884491877123, 'Total loss': 0.8201884491877123} | train loss {'Reaction outcome loss': 0.8104722523567628, 'Total loss': 0.8104722523567628}
2022-11-22 20:25:44,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:44,598 INFO:     Epoch: 48
2022-11-22 20:25:45,304 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8195028792728077, 'Total loss': 0.8195028792728077} | train loss {'Reaction outcome loss': 0.803760216552384, 'Total loss': 0.803760216552384}
2022-11-22 20:25:45,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:45,305 INFO:     Epoch: 49
2022-11-22 20:25:46,005 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8170408389785073, 'Total loss': 0.8170408389785073} | train loss {'Reaction outcome loss': 0.8070669175410757, 'Total loss': 0.8070669175410757}
2022-11-22 20:25:46,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:46,005 INFO:     Epoch: 50
2022-11-22 20:25:46,753 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8203392347151582, 'Total loss': 0.8203392347151582} | train loss {'Reaction outcome loss': 0.8088985270383406, 'Total loss': 0.8088985270383406}
2022-11-22 20:25:46,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:46,753 INFO:     Epoch: 51
2022-11-22 20:25:47,510 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8578684018416838, 'Total loss': 0.8578684018416838} | train loss {'Reaction outcome loss': 0.8068298679225299, 'Total loss': 0.8068298679225299}
2022-11-22 20:25:47,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:47,510 INFO:     Epoch: 52
2022-11-22 20:25:48,223 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8187132735144008, 'Total loss': 0.8187132735144008} | train loss {'Reaction outcome loss': 0.80181250024815, 'Total loss': 0.80181250024815}
2022-11-22 20:25:48,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:48,223 INFO:     Epoch: 53
2022-11-22 20:25:48,916 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8545325168154456, 'Total loss': 0.8545325168154456} | train loss {'Reaction outcome loss': 0.805982088434453, 'Total loss': 0.805982088434453}
2022-11-22 20:25:48,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:48,917 INFO:     Epoch: 54
2022-11-22 20:25:49,628 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.807602425867861, 'Total loss': 0.807602425867861} | train loss {'Reaction outcome loss': 0.8006277431030663, 'Total loss': 0.8006277431030663}
2022-11-22 20:25:49,629 INFO:     Found new best model at epoch 54
2022-11-22 20:25:49,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:49,630 INFO:     Epoch: 55
2022-11-22 20:25:50,356 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8184722086245363, 'Total loss': 0.8184722086245363} | train loss {'Reaction outcome loss': 0.8067417581470645, 'Total loss': 0.8067417581470645}
2022-11-22 20:25:50,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:50,356 INFO:     Epoch: 56
2022-11-22 20:25:51,095 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8458135466683995, 'Total loss': 0.8458135466683995} | train loss {'Reaction outcome loss': 0.807941152368273, 'Total loss': 0.807941152368273}
2022-11-22 20:25:51,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:51,095 INFO:     Epoch: 57
2022-11-22 20:25:51,817 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8556274087591604, 'Total loss': 0.8556274087591604} | train loss {'Reaction outcome loss': 0.807748765969763, 'Total loss': 0.807748765969763}
2022-11-22 20:25:51,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:51,817 INFO:     Epoch: 58
2022-11-22 20:25:52,540 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8270254649899222, 'Total loss': 0.8270254649899222} | train loss {'Reaction outcome loss': 0.8081413613290203, 'Total loss': 0.8081413613290203}
2022-11-22 20:25:52,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:52,540 INFO:     Epoch: 59
2022-11-22 20:25:53,288 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8268201432444833, 'Total loss': 0.8268201432444833} | train loss {'Reaction outcome loss': 0.802111782346453, 'Total loss': 0.802111782346453}
2022-11-22 20:25:53,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:53,288 INFO:     Epoch: 60
2022-11-22 20:25:53,983 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8235822807658802, 'Total loss': 0.8235822807658802} | train loss {'Reaction outcome loss': 0.8064573809808614, 'Total loss': 0.8064573809808614}
2022-11-22 20:25:53,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:53,984 INFO:     Epoch: 61
2022-11-22 20:25:54,701 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8260645920580084, 'Total loss': 0.8260645920580084} | train loss {'Reaction outcome loss': 0.805154405564678, 'Total loss': 0.805154405564678}
2022-11-22 20:25:54,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:54,702 INFO:     Epoch: 62
2022-11-22 20:25:55,448 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8354102782905102, 'Total loss': 0.8354102782905102} | train loss {'Reaction outcome loss': 0.8031610216413225, 'Total loss': 0.8031610216413225}
2022-11-22 20:25:55,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:55,449 INFO:     Epoch: 63
2022-11-22 20:25:56,197 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.810771415179426, 'Total loss': 0.810771415179426} | train loss {'Reaction outcome loss': 0.8065789192306753, 'Total loss': 0.8065789192306753}
2022-11-22 20:25:56,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:56,197 INFO:     Epoch: 64
2022-11-22 20:25:56,943 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8337387063286521, 'Total loss': 0.8337387063286521} | train loss {'Reaction outcome loss': 0.8020244825859459, 'Total loss': 0.8020244825859459}
2022-11-22 20:25:56,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:56,943 INFO:     Epoch: 65
2022-11-22 20:25:57,724 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8366793326356194, 'Total loss': 0.8366793326356194} | train loss {'Reaction outcome loss': 0.8054225764104298, 'Total loss': 0.8054225764104298}
2022-11-22 20:25:57,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:57,724 INFO:     Epoch: 66
2022-11-22 20:25:58,520 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8406273688782345, 'Total loss': 0.8406273688782345} | train loss {'Reaction outcome loss': 0.8067401192017964, 'Total loss': 0.8067401192017964}
2022-11-22 20:25:58,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:58,521 INFO:     Epoch: 67
2022-11-22 20:25:59,307 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8373115116899664, 'Total loss': 0.8373115116899664} | train loss {'Reaction outcome loss': 0.8018678053301208, 'Total loss': 0.8018678053301208}
2022-11-22 20:25:59,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:25:59,307 INFO:     Epoch: 68
2022-11-22 20:26:00,094 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8190805166959763, 'Total loss': 0.8190805166959763} | train loss {'Reaction outcome loss': 0.8044575496595733, 'Total loss': 0.8044575496595733}
2022-11-22 20:26:00,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:00,094 INFO:     Epoch: 69
2022-11-22 20:26:00,847 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8364962921901182, 'Total loss': 0.8364962921901182} | train loss {'Reaction outcome loss': 0.799949026959283, 'Total loss': 0.799949026959283}
2022-11-22 20:26:00,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:00,847 INFO:     Epoch: 70
2022-11-22 20:26:01,625 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8380104018883272, 'Total loss': 0.8380104018883272} | train loss {'Reaction outcome loss': 0.8080546529317388, 'Total loss': 0.8080546529317388}
2022-11-22 20:26:01,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:01,626 INFO:     Epoch: 71
2022-11-22 20:26:02,380 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8392686769366264, 'Total loss': 0.8392686769366264} | train loss {'Reaction outcome loss': 0.8041301057046774, 'Total loss': 0.8041301057046774}
2022-11-22 20:26:02,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:02,381 INFO:     Epoch: 72
2022-11-22 20:26:03,119 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8300877247344364, 'Total loss': 0.8300877247344364} | train loss {'Reaction outcome loss': 0.8030631751430278, 'Total loss': 0.8030631751430278}
2022-11-22 20:26:03,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:03,119 INFO:     Epoch: 73
2022-11-22 20:26:03,851 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8145557879046961, 'Total loss': 0.8145557879046961} | train loss {'Reaction outcome loss': 0.8057006093920493, 'Total loss': 0.8057006093920493}
2022-11-22 20:26:03,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:03,852 INFO:     Epoch: 74
2022-11-22 20:26:04,595 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.824043751440265, 'Total loss': 0.824043751440265} | train loss {'Reaction outcome loss': 0.7987709522247315, 'Total loss': 0.7987709522247315}
2022-11-22 20:26:04,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:04,595 INFO:     Epoch: 75
2022-11-22 20:26:05,320 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8284722749482502, 'Total loss': 0.8284722749482502} | train loss {'Reaction outcome loss': 0.8041052043437957, 'Total loss': 0.8041052043437957}
2022-11-22 20:26:05,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:05,320 INFO:     Epoch: 76
2022-11-22 20:26:06,075 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8390566395087675, 'Total loss': 0.8390566395087675} | train loss {'Reaction outcome loss': 0.8041024852772148, 'Total loss': 0.8041024852772148}
2022-11-22 20:26:06,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:06,076 INFO:     Epoch: 77
2022-11-22 20:26:06,815 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8395195583050902, 'Total loss': 0.8395195583050902} | train loss {'Reaction outcome loss': 0.8003440248722933, 'Total loss': 0.8003440248722933}
2022-11-22 20:26:06,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:06,816 INFO:     Epoch: 78
2022-11-22 20:26:07,576 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8343902717937123, 'Total loss': 0.8343902717937123} | train loss {'Reaction outcome loss': 0.8009295980541074, 'Total loss': 0.8009295980541074}
2022-11-22 20:26:07,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:07,576 INFO:     Epoch: 79
2022-11-22 20:26:08,368 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8416976671327244, 'Total loss': 0.8416976671327244} | train loss {'Reaction outcome loss': 0.7978191671931014, 'Total loss': 0.7978191671931014}
2022-11-22 20:26:08,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:08,368 INFO:     Epoch: 80
2022-11-22 20:26:09,152 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8111905225298621, 'Total loss': 0.8111905225298621} | train loss {'Reaction outcome loss': 0.8015699719896122, 'Total loss': 0.8015699719896122}
2022-11-22 20:26:09,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:09,152 INFO:     Epoch: 81
2022-11-22 20:26:09,911 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8146700601686131, 'Total loss': 0.8146700601686131} | train loss {'Reaction outcome loss': 0.7986929225678346, 'Total loss': 0.7986929225678346}
2022-11-22 20:26:09,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:09,912 INFO:     Epoch: 82
2022-11-22 20:26:10,630 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.811686553738334, 'Total loss': 0.811686553738334} | train loss {'Reaction outcome loss': 0.7913684094438748, 'Total loss': 0.7913684094438748}
2022-11-22 20:26:10,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:10,630 INFO:     Epoch: 83
2022-11-22 20:26:11,389 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8005255440419371, 'Total loss': 0.8005255440419371} | train loss {'Reaction outcome loss': 0.8024167265210833, 'Total loss': 0.8024167265210833}
2022-11-22 20:26:11,389 INFO:     Found new best model at epoch 83
2022-11-22 20:26:11,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:11,390 INFO:     Epoch: 84
2022-11-22 20:26:12,164 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8207828090949492, 'Total loss': 0.8207828090949492} | train loss {'Reaction outcome loss': 0.7973057981656522, 'Total loss': 0.7973057981656522}
2022-11-22 20:26:12,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:12,164 INFO:     Epoch: 85
2022-11-22 20:26:12,986 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8275619223713875, 'Total loss': 0.8275619223713875} | train loss {'Reaction outcome loss': 0.7991229163140666, 'Total loss': 0.7991229163140666}
2022-11-22 20:26:12,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:12,986 INFO:     Epoch: 86
2022-11-22 20:26:13,777 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7924542802978646, 'Total loss': 0.7924542802978646} | train loss {'Reaction outcome loss': 0.7944932482680496, 'Total loss': 0.7944932482680496}
2022-11-22 20:26:13,777 INFO:     Found new best model at epoch 86
2022-11-22 20:26:13,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:13,778 INFO:     Epoch: 87
2022-11-22 20:26:14,551 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.842997514388778, 'Total loss': 0.842997514388778} | train loss {'Reaction outcome loss': 0.7928207576274872, 'Total loss': 0.7928207576274872}
2022-11-22 20:26:14,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:14,553 INFO:     Epoch: 88
2022-11-22 20:26:15,314 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.806538037955761, 'Total loss': 0.806538037955761} | train loss {'Reaction outcome loss': 0.7974879774512077, 'Total loss': 0.7974879774512077}
2022-11-22 20:26:15,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:15,314 INFO:     Epoch: 89
2022-11-22 20:26:16,085 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8317665539004586, 'Total loss': 0.8317665539004586} | train loss {'Reaction outcome loss': 0.7940652770655495, 'Total loss': 0.7940652770655495}
2022-11-22 20:26:16,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:16,085 INFO:     Epoch: 90
2022-11-22 20:26:16,829 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8285055610943924, 'Total loss': 0.8285055610943924} | train loss {'Reaction outcome loss': 0.7926953939759002, 'Total loss': 0.7926953939759002}
2022-11-22 20:26:16,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:16,830 INFO:     Epoch: 91
2022-11-22 20:26:17,552 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8141246004538103, 'Total loss': 0.8141246004538103} | train loss {'Reaction outcome loss': 0.7934168456768503, 'Total loss': 0.7934168456768503}
2022-11-22 20:26:17,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:17,552 INFO:     Epoch: 92
2022-11-22 20:26:18,290 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.817737412723628, 'Total loss': 0.817737412723628} | train loss {'Reaction outcome loss': 0.7888366890196897, 'Total loss': 0.7888366890196897}
2022-11-22 20:26:18,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:18,290 INFO:     Epoch: 93
2022-11-22 20:26:19,013 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8072368062355302, 'Total loss': 0.8072368062355302} | train loss {'Reaction outcome loss': 0.7868624064387107, 'Total loss': 0.7868624064387107}
2022-11-22 20:26:19,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:19,013 INFO:     Epoch: 94
2022-11-22 20:26:19,790 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8240257819945161, 'Total loss': 0.8240257819945161} | train loss {'Reaction outcome loss': 0.7886039770379358, 'Total loss': 0.7886039770379358}
2022-11-22 20:26:19,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:19,790 INFO:     Epoch: 95
2022-11-22 20:26:20,518 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7928810275413773, 'Total loss': 0.7928810275413773} | train loss {'Reaction outcome loss': 0.7820503718998968, 'Total loss': 0.7820503718998968}
2022-11-22 20:26:20,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:20,518 INFO:     Epoch: 96
2022-11-22 20:26:21,292 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8158806846900419, 'Total loss': 0.8158806846900419} | train loss {'Reaction outcome loss': 0.7812212023199822, 'Total loss': 0.7812212023199822}
2022-11-22 20:26:21,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:21,293 INFO:     Epoch: 97
2022-11-22 20:26:22,071 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8212530138817701, 'Total loss': 0.8212530138817701} | train loss {'Reaction outcome loss': 0.7765031812142352, 'Total loss': 0.7765031812142352}
2022-11-22 20:26:22,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:22,072 INFO:     Epoch: 98
2022-11-22 20:26:22,807 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7798795198852365, 'Total loss': 0.7798795198852365} | train loss {'Reaction outcome loss': 0.7805463425967158, 'Total loss': 0.7805463425967158}
2022-11-22 20:26:22,807 INFO:     Found new best model at epoch 98
2022-11-22 20:26:22,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:22,808 INFO:     Epoch: 99
2022-11-22 20:26:23,533 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8111033012921159, 'Total loss': 0.8111033012921159} | train loss {'Reaction outcome loss': 0.7796485335242992, 'Total loss': 0.7796485335242992}
2022-11-22 20:26:23,533 INFO:     Best model found after epoch 99 of 100.
2022-11-22 20:26:23,534 INFO:   Done with stage: TRAINING
2022-11-22 20:26:23,534 INFO:   Starting stage: EVALUATION
2022-11-22 20:26:23,659 INFO:   Done with stage: EVALUATION
2022-11-22 20:26:23,660 INFO:   Leaving out SEQ value Fold_3
2022-11-22 20:26:23,674 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-22 20:26:23,674 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:26:24,331 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:26:24,331 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:26:24,400 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:26:24,400 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:26:24,400 INFO:     No hyperparam tuning for this model
2022-11-22 20:26:24,400 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:26:24,400 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:26:24,401 INFO:     None feature selector for col prot
2022-11-22 20:26:24,401 INFO:     None feature selector for col prot
2022-11-22 20:26:24,401 INFO:     None feature selector for col prot
2022-11-22 20:26:24,402 INFO:     None feature selector for col chem
2022-11-22 20:26:24,402 INFO:     None feature selector for col chem
2022-11-22 20:26:24,402 INFO:     None feature selector for col chem
2022-11-22 20:26:24,402 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:26:24,402 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:26:24,403 INFO:     Number of params in model 126091
2022-11-22 20:26:24,406 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:26:24,407 INFO:   Starting stage: TRAINING
2022-11-22 20:26:24,455 INFO:     Val loss before train {'Reaction outcome loss': 1.01725093431251, 'Total loss': 1.01725093431251}
2022-11-22 20:26:24,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:24,455 INFO:     Epoch: 0
2022-11-22 20:26:25,162 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8646641782549924, 'Total loss': 0.8646641782549924} | train loss {'Reaction outcome loss': 0.8594119099319958, 'Total loss': 0.8594119099319958}
2022-11-22 20:26:25,162 INFO:     Found new best model at epoch 0
2022-11-22 20:26:25,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:25,163 INFO:     Epoch: 1
2022-11-22 20:26:25,892 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8369556353535763, 'Total loss': 0.8369556353535763} | train loss {'Reaction outcome loss': 0.8294158659753252, 'Total loss': 0.8294158659753252}
2022-11-22 20:26:25,892 INFO:     Found new best model at epoch 1
2022-11-22 20:26:25,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:25,893 INFO:     Epoch: 2
2022-11-22 20:26:26,619 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.840029870354852, 'Total loss': 0.840029870354852} | train loss {'Reaction outcome loss': 0.8175505143208582, 'Total loss': 0.8175505143208582}
2022-11-22 20:26:26,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:26,619 INFO:     Epoch: 3
2022-11-22 20:26:27,332 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8648523182369942, 'Total loss': 0.8648523182369942} | train loss {'Reaction outcome loss': 0.8047203314108927, 'Total loss': 0.8047203314108927}
2022-11-22 20:26:27,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:27,332 INFO:     Epoch: 4
2022-11-22 20:26:28,044 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8225163256013116, 'Total loss': 0.8225163256013116} | train loss {'Reaction outcome loss': 0.8003771081566811, 'Total loss': 0.8003771081566811}
2022-11-22 20:26:28,044 INFO:     Found new best model at epoch 4
2022-11-22 20:26:28,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:28,045 INFO:     Epoch: 5
2022-11-22 20:26:28,759 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8231850931810778, 'Total loss': 0.8231850931810778} | train loss {'Reaction outcome loss': 0.7976970126638647, 'Total loss': 0.7976970126638647}
2022-11-22 20:26:28,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:28,760 INFO:     Epoch: 6
2022-11-22 20:26:29,476 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8245229097299798, 'Total loss': 0.8245229097299798} | train loss {'Reaction outcome loss': 0.7899727843335418, 'Total loss': 0.7899727843335418}
2022-11-22 20:26:29,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:29,477 INFO:     Epoch: 7
2022-11-22 20:26:30,239 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8383872141671735, 'Total loss': 0.8383872141671735} | train loss {'Reaction outcome loss': 0.7908299493252254, 'Total loss': 0.7908299493252254}
2022-11-22 20:26:30,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:30,240 INFO:     Epoch: 8
2022-11-22 20:26:31,007 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8400516066440317, 'Total loss': 0.8400516066440317} | train loss {'Reaction outcome loss': 0.7954747336076908, 'Total loss': 0.7954747336076908}
2022-11-22 20:26:31,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:31,007 INFO:     Epoch: 9
2022-11-22 20:26:31,768 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8146948204484097, 'Total loss': 0.8146948204484097} | train loss {'Reaction outcome loss': 0.7919163331389427, 'Total loss': 0.7919163331389427}
2022-11-22 20:26:31,768 INFO:     Found new best model at epoch 9
2022-11-22 20:26:31,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:31,769 INFO:     Epoch: 10
2022-11-22 20:26:32,493 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8147663993890896, 'Total loss': 0.8147663993890896} | train loss {'Reaction outcome loss': 0.792958601942805, 'Total loss': 0.792958601942805}
2022-11-22 20:26:32,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:32,494 INFO:     Epoch: 11
2022-11-22 20:26:33,247 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.830565539903419, 'Total loss': 0.830565539903419} | train loss {'Reaction outcome loss': 0.7845372768943427, 'Total loss': 0.7845372768943427}
2022-11-22 20:26:33,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:33,247 INFO:     Epoch: 12
2022-11-22 20:26:34,041 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8099727360315101, 'Total loss': 0.8099727360315101} | train loss {'Reaction outcome loss': 0.7866334702636375, 'Total loss': 0.7866334702636375}
2022-11-22 20:26:34,042 INFO:     Found new best model at epoch 12
2022-11-22 20:26:34,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:34,043 INFO:     Epoch: 13
2022-11-22 20:26:34,786 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8144900064135707, 'Total loss': 0.8144900064135707} | train loss {'Reaction outcome loss': 0.7818326882895876, 'Total loss': 0.7818326882895876}
2022-11-22 20:26:34,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:34,786 INFO:     Epoch: 14
2022-11-22 20:26:35,546 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8081710040569305, 'Total loss': 0.8081710040569305} | train loss {'Reaction outcome loss': 0.7833760755716778, 'Total loss': 0.7833760755716778}
2022-11-22 20:26:35,547 INFO:     Found new best model at epoch 14
2022-11-22 20:26:35,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:35,547 INFO:     Epoch: 15
2022-11-22 20:26:36,267 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7939543876537057, 'Total loss': 0.7939543876537057} | train loss {'Reaction outcome loss': 0.7816189372392951, 'Total loss': 0.7816189372392951}
2022-11-22 20:26:36,267 INFO:     Found new best model at epoch 15
2022-11-22 20:26:36,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:36,268 INFO:     Epoch: 16
2022-11-22 20:26:36,995 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.827042467372362, 'Total loss': 0.827042467372362} | train loss {'Reaction outcome loss': 0.7792723062829893, 'Total loss': 0.7792723062829893}
2022-11-22 20:26:36,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:36,996 INFO:     Epoch: 17
2022-11-22 20:26:37,736 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8292072207428688, 'Total loss': 0.8292072207428688} | train loss {'Reaction outcome loss': 0.7795124419155668, 'Total loss': 0.7795124419155668}
2022-11-22 20:26:37,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:37,737 INFO:     Epoch: 18
2022-11-22 20:26:38,488 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8070452587549076, 'Total loss': 0.8070452587549076} | train loss {'Reaction outcome loss': 0.776552470492535, 'Total loss': 0.776552470492535}
2022-11-22 20:26:38,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:38,488 INFO:     Epoch: 19
2022-11-22 20:26:39,235 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8179569500823354, 'Total loss': 0.8179569500823354} | train loss {'Reaction outcome loss': 0.7848186224210457, 'Total loss': 0.7848186224210457}
2022-11-22 20:26:39,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:39,235 INFO:     Epoch: 20
2022-11-22 20:26:39,954 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8194123187730479, 'Total loss': 0.8194123187730479} | train loss {'Reaction outcome loss': 0.7839620990342782, 'Total loss': 0.7839620990342782}
2022-11-22 20:26:39,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:39,954 INFO:     Epoch: 21
2022-11-22 20:26:40,725 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8126913863559102, 'Total loss': 0.8126913863559102} | train loss {'Reaction outcome loss': 0.7827418413562853, 'Total loss': 0.7827418413562853}
2022-11-22 20:26:40,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:40,726 INFO:     Epoch: 22
2022-11-22 20:26:41,506 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.81374854611796, 'Total loss': 0.81374854611796} | train loss {'Reaction outcome loss': 0.7807107468242528, 'Total loss': 0.7807107468242528}
2022-11-22 20:26:41,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:41,506 INFO:     Epoch: 23
2022-11-22 20:26:42,244 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8374259596647218, 'Total loss': 0.8374259596647218} | train loss {'Reaction outcome loss': 0.773980701861323, 'Total loss': 0.773980701861323}
2022-11-22 20:26:42,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:42,244 INFO:     Epoch: 24
2022-11-22 20:26:42,990 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.821118270241937, 'Total loss': 0.821118270241937} | train loss {'Reaction outcome loss': 0.779455774143094, 'Total loss': 0.779455774143094}
2022-11-22 20:26:42,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:42,991 INFO:     Epoch: 25
2022-11-22 20:26:43,753 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8063898384571075, 'Total loss': 0.8063898384571075} | train loss {'Reaction outcome loss': 0.7799111511863646, 'Total loss': 0.7799111511863646}
2022-11-22 20:26:43,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:43,754 INFO:     Epoch: 26
2022-11-22 20:26:44,510 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8436810464359993, 'Total loss': 0.8436810464359993} | train loss {'Reaction outcome loss': 0.7723191928912382, 'Total loss': 0.7723191928912382}
2022-11-22 20:26:44,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:44,511 INFO:     Epoch: 27
2022-11-22 20:26:45,259 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.82122291381969, 'Total loss': 0.82122291381969} | train loss {'Reaction outcome loss': 0.779628439027755, 'Total loss': 0.779628439027755}
2022-11-22 20:26:45,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:45,260 INFO:     Epoch: 28
2022-11-22 20:26:46,032 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8087247104145759, 'Total loss': 0.8087247104145759} | train loss {'Reaction outcome loss': 0.7763236789185493, 'Total loss': 0.7763236789185493}
2022-11-22 20:26:46,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:46,032 INFO:     Epoch: 29
2022-11-22 20:26:46,754 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8147807717323303, 'Total loss': 0.8147807717323303} | train loss {'Reaction outcome loss': 0.7711713103974451, 'Total loss': 0.7711713103974451}
2022-11-22 20:26:46,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:46,755 INFO:     Epoch: 30
2022-11-22 20:26:47,482 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8099401593208313, 'Total loss': 0.8099401593208313} | train loss {'Reaction outcome loss': 0.7785354284722297, 'Total loss': 0.7785354284722297}
2022-11-22 20:26:47,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:47,482 INFO:     Epoch: 31
2022-11-22 20:26:48,223 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8038269988326139, 'Total loss': 0.8038269988326139} | train loss {'Reaction outcome loss': 0.7748222142213681, 'Total loss': 0.7748222142213681}
2022-11-22 20:26:48,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:48,223 INFO:     Epoch: 32
2022-11-22 20:26:48,980 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7954963147640228, 'Total loss': 0.7954963147640228} | train loss {'Reaction outcome loss': 0.7732014196817992, 'Total loss': 0.7732014196817992}
2022-11-22 20:26:48,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:48,981 INFO:     Epoch: 33
2022-11-22 20:26:49,738 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8008259236812592, 'Total loss': 0.8008259236812592} | train loss {'Reaction outcome loss': 0.7707048176986272, 'Total loss': 0.7707048176986272}
2022-11-22 20:26:49,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:49,738 INFO:     Epoch: 34
2022-11-22 20:26:50,490 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8101290644601334, 'Total loss': 0.8101290644601334} | train loss {'Reaction outcome loss': 0.7731408861572625, 'Total loss': 0.7731408861572625}
2022-11-22 20:26:50,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:50,490 INFO:     Epoch: 35
2022-11-22 20:26:51,215 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8095638703468234, 'Total loss': 0.8095638703468234} | train loss {'Reaction outcome loss': 0.7755690221903754, 'Total loss': 0.7755690221903754}
2022-11-22 20:26:51,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:51,216 INFO:     Epoch: 36
2022-11-22 20:26:51,909 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8158027411893357, 'Total loss': 0.8158027411893357} | train loss {'Reaction outcome loss': 0.7738135856438856, 'Total loss': 0.7738135856438856}
2022-11-22 20:26:51,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:51,910 INFO:     Epoch: 37
2022-11-22 20:26:52,655 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8141542666180189, 'Total loss': 0.8141542666180189} | train loss {'Reaction outcome loss': 0.7720782831311226, 'Total loss': 0.7720782831311226}
2022-11-22 20:26:52,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:52,655 INFO:     Epoch: 38
2022-11-22 20:26:53,422 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8028624723123949, 'Total loss': 0.8028624723123949} | train loss {'Reaction outcome loss': 0.7779314880732631, 'Total loss': 0.7779314880732631}
2022-11-22 20:26:53,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:53,422 INFO:     Epoch: 39
2022-11-22 20:26:54,155 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8049369703891666, 'Total loss': 0.8049369703891666} | train loss {'Reaction outcome loss': 0.7721669887665843, 'Total loss': 0.7721669887665843}
2022-11-22 20:26:54,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:54,155 INFO:     Epoch: 40
2022-11-22 20:26:54,836 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8169681589270748, 'Total loss': 0.8169681589270748} | train loss {'Reaction outcome loss': 0.772948501906434, 'Total loss': 0.772948501906434}
2022-11-22 20:26:54,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:54,837 INFO:     Epoch: 41
2022-11-22 20:26:55,591 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7960326103276985, 'Total loss': 0.7960326103276985} | train loss {'Reaction outcome loss': 0.7747269983662933, 'Total loss': 0.7747269983662933}
2022-11-22 20:26:55,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:55,592 INFO:     Epoch: 42
2022-11-22 20:26:56,362 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8071185641510542, 'Total loss': 0.8071185641510542} | train loss {'Reaction outcome loss': 0.7712892648137983, 'Total loss': 0.7712892648137983}
2022-11-22 20:26:56,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:56,363 INFO:     Epoch: 43
2022-11-22 20:26:57,071 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8320357175760491, 'Total loss': 0.8320357175760491} | train loss {'Reaction outcome loss': 0.7690729765129871, 'Total loss': 0.7690729765129871}
2022-11-22 20:26:57,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:57,071 INFO:     Epoch: 44
2022-11-22 20:26:57,773 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8331370935883633, 'Total loss': 0.8331370935883633} | train loss {'Reaction outcome loss': 0.7692183985329065, 'Total loss': 0.7692183985329065}
2022-11-22 20:26:57,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:57,774 INFO:     Epoch: 45
2022-11-22 20:26:58,494 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8042752167513204, 'Total loss': 0.8042752167513204} | train loss {'Reaction outcome loss': 0.7673836468917424, 'Total loss': 0.7673836468917424}
2022-11-22 20:26:58,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:58,495 INFO:     Epoch: 46
2022-11-22 20:26:59,190 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7826653115971144, 'Total loss': 0.7826653115971144} | train loss {'Reaction outcome loss': 0.7691267527273444, 'Total loss': 0.7691267527273444}
2022-11-22 20:26:59,191 INFO:     Found new best model at epoch 46
2022-11-22 20:26:59,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:59,191 INFO:     Epoch: 47
2022-11-22 20:26:59,944 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7865945135438165, 'Total loss': 0.7865945135438165} | train loss {'Reaction outcome loss': 0.7682838536432532, 'Total loss': 0.7682838536432532}
2022-11-22 20:26:59,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:26:59,944 INFO:     Epoch: 48
2022-11-22 20:27:00,706 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7964212333047113, 'Total loss': 0.7964212333047113} | train loss {'Reaction outcome loss': 0.7673568260230001, 'Total loss': 0.7673568260230001}
2022-11-22 20:27:00,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:00,707 INFO:     Epoch: 49
2022-11-22 20:27:01,434 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8014551227868989, 'Total loss': 0.8014551227868989} | train loss {'Reaction outcome loss': 0.7739996873453016, 'Total loss': 0.7739996873453016}
2022-11-22 20:27:01,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:01,434 INFO:     Epoch: 50
2022-11-22 20:27:02,202 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.796816592299661, 'Total loss': 0.796816592299661} | train loss {'Reaction outcome loss': 0.7671891327519886, 'Total loss': 0.7671891327519886}
2022-11-22 20:27:02,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:02,202 INFO:     Epoch: 51
2022-11-22 20:27:02,918 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7832839599875516, 'Total loss': 0.7832839599875516} | train loss {'Reaction outcome loss': 0.7669969582166828, 'Total loss': 0.7669969582166828}
2022-11-22 20:27:02,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:02,918 INFO:     Epoch: 52
2022-11-22 20:27:03,639 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8028076831684556, 'Total loss': 0.8028076831684556} | train loss {'Reaction outcome loss': 0.7599945130651115, 'Total loss': 0.7599945130651115}
2022-11-22 20:27:03,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:03,639 INFO:     Epoch: 53
2022-11-22 20:27:04,363 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.788740682047467, 'Total loss': 0.788740682047467} | train loss {'Reaction outcome loss': 0.7622621088731484, 'Total loss': 0.7622621088731484}
2022-11-22 20:27:04,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:04,364 INFO:     Epoch: 54
2022-11-22 20:27:05,093 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7931903115538663, 'Total loss': 0.7931903115538663} | train loss {'Reaction outcome loss': 0.7644301313357275, 'Total loss': 0.7644301313357275}
2022-11-22 20:27:05,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:05,093 INFO:     Epoch: 55
2022-11-22 20:27:05,872 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7799595774606217, 'Total loss': 0.7799595774606217} | train loss {'Reaction outcome loss': 0.7618803977966309, 'Total loss': 0.7618803977966309}
2022-11-22 20:27:05,873 INFO:     Found new best model at epoch 55
2022-11-22 20:27:05,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:05,873 INFO:     Epoch: 56
2022-11-22 20:27:06,638 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8150464968625889, 'Total loss': 0.8150464968625889} | train loss {'Reaction outcome loss': 0.7633229457452649, 'Total loss': 0.7633229457452649}
2022-11-22 20:27:06,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:06,639 INFO:     Epoch: 57
2022-11-22 20:27:07,359 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7844382593798083, 'Total loss': 0.7844382593798083} | train loss {'Reaction outcome loss': 0.75683900237572, 'Total loss': 0.75683900237572}
2022-11-22 20:27:07,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:07,359 INFO:     Epoch: 58
2022-11-22 20:27:08,145 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7797714984694193, 'Total loss': 0.7797714984694193} | train loss {'Reaction outcome loss': 0.7616951240867865, 'Total loss': 0.7616951240867865}
2022-11-22 20:27:08,145 INFO:     Found new best model at epoch 58
2022-11-22 20:27:08,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:08,146 INFO:     Epoch: 59
2022-11-22 20:27:08,965 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8042228512985762, 'Total loss': 0.8042228512985762} | train loss {'Reaction outcome loss': 0.7552013574320762, 'Total loss': 0.7552013574320762}
2022-11-22 20:27:08,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:08,966 INFO:     Epoch: 60
2022-11-22 20:27:09,763 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7928118026533792, 'Total loss': 0.7928118026533792} | train loss {'Reaction outcome loss': 0.7563199414337267, 'Total loss': 0.7563199414337267}
2022-11-22 20:27:09,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:09,764 INFO:     Epoch: 61
2022-11-22 20:27:10,555 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7723938739577005, 'Total loss': 0.7723938739577005} | train loss {'Reaction outcome loss': 0.7566248830713209, 'Total loss': 0.7566248830713209}
2022-11-22 20:27:10,555 INFO:     Found new best model at epoch 61
2022-11-22 20:27:10,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:10,556 INFO:     Epoch: 62
2022-11-22 20:27:11,373 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7738372212232545, 'Total loss': 0.7738372212232545} | train loss {'Reaction outcome loss': 0.7525809566017057, 'Total loss': 0.7525809566017057}
2022-11-22 20:27:11,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:11,373 INFO:     Epoch: 63
2022-11-22 20:27:12,187 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7878974301870479, 'Total loss': 0.7878974301870479} | train loss {'Reaction outcome loss': 0.7541691520419277, 'Total loss': 0.7541691520419277}
2022-11-22 20:27:12,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:12,187 INFO:     Epoch: 64
2022-11-22 20:27:13,017 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7962926820267079, 'Total loss': 0.7962926820267079} | train loss {'Reaction outcome loss': 0.7502520133237369, 'Total loss': 0.7502520133237369}
2022-11-22 20:27:13,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:13,023 INFO:     Epoch: 65
2022-11-22 20:27:13,862 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8258311457412187, 'Total loss': 0.8258311457412187} | train loss {'Reaction outcome loss': 0.7550569185223736, 'Total loss': 0.7550569185223736}
2022-11-22 20:27:13,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:13,863 INFO:     Epoch: 66
2022-11-22 20:27:14,706 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7906961039055226, 'Total loss': 0.7906961039055226} | train loss {'Reaction outcome loss': 0.7500987942101526, 'Total loss': 0.7500987942101526}
2022-11-22 20:27:14,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:14,706 INFO:     Epoch: 67
2022-11-22 20:27:15,540 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7717769943004431, 'Total loss': 0.7717769943004431} | train loss {'Reaction outcome loss': 0.7586884543788238, 'Total loss': 0.7586884543788238}
2022-11-22 20:27:15,540 INFO:     Found new best model at epoch 67
2022-11-22 20:27:15,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:15,541 INFO:     Epoch: 68
2022-11-22 20:27:16,358 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7701248644396316, 'Total loss': 0.7701248644396316} | train loss {'Reaction outcome loss': 0.749602136553311, 'Total loss': 0.749602136553311}
2022-11-22 20:27:16,359 INFO:     Found new best model at epoch 68
2022-11-22 20:27:16,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:16,360 INFO:     Epoch: 69
2022-11-22 20:27:17,161 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7695268330185913, 'Total loss': 0.7695268330185913} | train loss {'Reaction outcome loss': 0.743489504287966, 'Total loss': 0.743489504287966}
2022-11-22 20:27:17,162 INFO:     Found new best model at epoch 69
2022-11-22 20:27:17,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:17,162 INFO:     Epoch: 70
2022-11-22 20:27:17,986 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8173524612604186, 'Total loss': 0.8173524612604186} | train loss {'Reaction outcome loss': 0.7433714810453478, 'Total loss': 0.7433714810453478}
2022-11-22 20:27:17,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:17,986 INFO:     Epoch: 71
2022-11-22 20:27:18,806 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7552602554476538, 'Total loss': 0.7552602554476538} | train loss {'Reaction outcome loss': 0.7464801564079816, 'Total loss': 0.7464801564079816}
2022-11-22 20:27:18,806 INFO:     Found new best model at epoch 71
2022-11-22 20:27:18,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:18,807 INFO:     Epoch: 72
2022-11-22 20:27:19,664 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7786468142686889, 'Total loss': 0.7786468142686889} | train loss {'Reaction outcome loss': 0.7488997957256974, 'Total loss': 0.7488997957256974}
2022-11-22 20:27:19,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:19,665 INFO:     Epoch: 73
2022-11-22 20:27:20,457 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7618639122608096, 'Total loss': 0.7618639122608096} | train loss {'Reaction outcome loss': 0.7408998151783084, 'Total loss': 0.7408998151783084}
2022-11-22 20:27:20,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:20,458 INFO:     Epoch: 74
2022-11-22 20:27:21,312 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7608753678410553, 'Total loss': 0.7608753678410553} | train loss {'Reaction outcome loss': 0.737573146209365, 'Total loss': 0.737573146209365}
2022-11-22 20:27:21,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:21,312 INFO:     Epoch: 75
2022-11-22 20:27:22,133 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.762082040309906, 'Total loss': 0.762082040309906} | train loss {'Reaction outcome loss': 0.7360928287027312, 'Total loss': 0.7360928287027312}
2022-11-22 20:27:22,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:22,133 INFO:     Epoch: 76
2022-11-22 20:27:22,963 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7564749828604764, 'Total loss': 0.7564749828604764} | train loss {'Reaction outcome loss': 0.7365623550092588, 'Total loss': 0.7365623550092588}
2022-11-22 20:27:22,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:22,964 INFO:     Epoch: 77
2022-11-22 20:27:23,782 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7363892058993495, 'Total loss': 0.7363892058993495} | train loss {'Reaction outcome loss': 0.7391049490600335, 'Total loss': 0.7391049490600335}
2022-11-22 20:27:23,783 INFO:     Found new best model at epoch 77
2022-11-22 20:27:23,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:23,783 INFO:     Epoch: 78
2022-11-22 20:27:24,580 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7792658639508624, 'Total loss': 0.7792658639508624} | train loss {'Reaction outcome loss': 0.7332818806171417, 'Total loss': 0.7332818806171417}
2022-11-22 20:27:24,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:24,580 INFO:     Epoch: 79
2022-11-22 20:27:25,382 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7674904188444448, 'Total loss': 0.7674904188444448} | train loss {'Reaction outcome loss': 0.7309255210346863, 'Total loss': 0.7309255210346863}
2022-11-22 20:27:25,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:25,382 INFO:     Epoch: 80
2022-11-22 20:27:26,206 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7604237704776055, 'Total loss': 0.7604237704776055} | train loss {'Reaction outcome loss': 0.7281400528354723, 'Total loss': 0.7281400528354723}
2022-11-22 20:27:26,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:26,207 INFO:     Epoch: 81
2022-11-22 20:27:27,013 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7533052127028621, 'Total loss': 0.7533052127028621} | train loss {'Reaction outcome loss': 0.7292262645529919, 'Total loss': 0.7292262645529919}
2022-11-22 20:27:27,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:27,014 INFO:     Epoch: 82
2022-11-22 20:27:27,885 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7475556530231653, 'Total loss': 0.7475556530231653} | train loss {'Reaction outcome loss': 0.7275794784797996, 'Total loss': 0.7275794784797996}
2022-11-22 20:27:27,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:27,885 INFO:     Epoch: 83
2022-11-22 20:27:28,722 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7512892761895823, 'Total loss': 0.7512892761895823} | train loss {'Reaction outcome loss': 0.7233924997023872, 'Total loss': 0.7233924997023872}
2022-11-22 20:27:28,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:28,722 INFO:     Epoch: 84
2022-11-22 20:27:29,512 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7474539356176243, 'Total loss': 0.7474539356176243} | train loss {'Reaction outcome loss': 0.7198931179085716, 'Total loss': 0.7198931179085716}
2022-11-22 20:27:29,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:29,512 INFO:     Epoch: 85
2022-11-22 20:27:30,375 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7157560718614001, 'Total loss': 0.7157560718614001} | train loss {'Reaction outcome loss': 0.7207540905133623, 'Total loss': 0.7207540905133623}
2022-11-22 20:27:30,375 INFO:     Found new best model at epoch 85
2022-11-22 20:27:30,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:30,376 INFO:     Epoch: 86
2022-11-22 20:27:31,194 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7525006137615027, 'Total loss': 0.7525006137615027} | train loss {'Reaction outcome loss': 0.7288526090197875, 'Total loss': 0.7288526090197875}
2022-11-22 20:27:31,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:31,194 INFO:     Epoch: 87
2022-11-22 20:27:32,012 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7438646963862485, 'Total loss': 0.7438646963862485} | train loss {'Reaction outcome loss': 0.7224017292505405, 'Total loss': 0.7224017292505405}
2022-11-22 20:27:32,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:32,013 INFO:     Epoch: 88
2022-11-22 20:27:32,820 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7483885745669521, 'Total loss': 0.7483885745669521} | train loss {'Reaction outcome loss': 0.7117971643561223, 'Total loss': 0.7117971643561223}
2022-11-22 20:27:32,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:32,820 INFO:     Epoch: 89
2022-11-22 20:27:33,665 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7646228012650512, 'Total loss': 0.7646228012650512} | train loss {'Reaction outcome loss': 0.7285569451871465, 'Total loss': 0.7285569451871465}
2022-11-22 20:27:33,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:33,665 INFO:     Epoch: 90
2022-11-22 20:27:34,494 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7263547667237216, 'Total loss': 0.7263547667237216} | train loss {'Reaction outcome loss': 0.7183815019785381, 'Total loss': 0.7183815019785381}
2022-11-22 20:27:34,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:34,494 INFO:     Epoch: 91
2022-11-22 20:27:35,274 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.736652004857396, 'Total loss': 0.736652004857396} | train loss {'Reaction outcome loss': 0.7160903546409528, 'Total loss': 0.7160903546409528}
2022-11-22 20:27:35,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:35,275 INFO:     Epoch: 92
2022-11-22 20:27:36,060 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7433811606362809, 'Total loss': 0.7433811606362809} | train loss {'Reaction outcome loss': 0.7181799681704553, 'Total loss': 0.7181799681704553}
2022-11-22 20:27:36,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:36,061 INFO:     Epoch: 93
2022-11-22 20:27:36,873 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7668483770170877, 'Total loss': 0.7668483770170877} | train loss {'Reaction outcome loss': 0.7115046988989486, 'Total loss': 0.7115046988989486}
2022-11-22 20:27:36,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:36,873 INFO:     Epoch: 94
2022-11-22 20:27:37,695 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.717910076989684, 'Total loss': 0.717910076989684} | train loss {'Reaction outcome loss': 0.7189102271785501, 'Total loss': 0.7189102271785501}
2022-11-22 20:27:37,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:37,695 INFO:     Epoch: 95
2022-11-22 20:27:38,529 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7409656283467315, 'Total loss': 0.7409656283467315} | train loss {'Reaction outcome loss': 0.7236086746952572, 'Total loss': 0.7236086746952572}
2022-11-22 20:27:38,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:38,529 INFO:     Epoch: 96
2022-11-22 20:27:39,314 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7547527045704597, 'Total loss': 0.7547527045704597} | train loss {'Reaction outcome loss': 0.7107634540708339, 'Total loss': 0.7107634540708339}
2022-11-22 20:27:39,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:39,314 INFO:     Epoch: 97
2022-11-22 20:27:40,098 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.725074534499368, 'Total loss': 0.725074534499368} | train loss {'Reaction outcome loss': 0.7140494563051911, 'Total loss': 0.7140494563051911}
2022-11-22 20:27:40,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:40,099 INFO:     Epoch: 98
2022-11-22 20:27:40,900 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7657012634499129, 'Total loss': 0.7657012634499129} | train loss {'Reaction outcome loss': 0.7256852057380755, 'Total loss': 0.7256852057380755}
2022-11-22 20:27:40,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:40,900 INFO:     Epoch: 99
2022-11-22 20:27:41,714 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.74334086096564, 'Total loss': 0.74334086096564} | train loss {'Reaction outcome loss': 0.7157321927733109, 'Total loss': 0.7157321927733109}
2022-11-22 20:27:41,714 INFO:     Best model found after epoch 86 of 100.
2022-11-22 20:27:41,715 INFO:   Done with stage: TRAINING
2022-11-22 20:27:41,715 INFO:   Starting stage: EVALUATION
2022-11-22 20:27:41,845 INFO:   Done with stage: EVALUATION
2022-11-22 20:27:41,845 INFO:   Leaving out SEQ value Fold_4
2022-11-22 20:27:41,859 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:27:41,859 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:27:42,544 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:27:42,544 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:27:42,617 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:27:42,617 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:27:42,617 INFO:     No hyperparam tuning for this model
2022-11-22 20:27:42,617 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:27:42,617 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:27:42,618 INFO:     None feature selector for col prot
2022-11-22 20:27:42,618 INFO:     None feature selector for col prot
2022-11-22 20:27:42,618 INFO:     None feature selector for col prot
2022-11-22 20:27:42,619 INFO:     None feature selector for col chem
2022-11-22 20:27:42,619 INFO:     None feature selector for col chem
2022-11-22 20:27:42,619 INFO:     None feature selector for col chem
2022-11-22 20:27:42,619 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:27:42,619 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:27:42,621 INFO:     Number of params in model 126091
2022-11-22 20:27:42,624 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:27:42,624 INFO:   Starting stage: TRAINING
2022-11-22 20:27:42,675 INFO:     Val loss before train {'Reaction outcome loss': 0.9913549853319471, 'Total loss': 0.9913549853319471}
2022-11-22 20:27:42,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:42,675 INFO:     Epoch: 0
2022-11-22 20:27:43,471 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8566442077810114, 'Total loss': 0.8566442077810114} | train loss {'Reaction outcome loss': 0.8781401702335903, 'Total loss': 0.8781401702335903}
2022-11-22 20:27:43,471 INFO:     Found new best model at epoch 0
2022-11-22 20:27:43,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:43,472 INFO:     Epoch: 1
2022-11-22 20:27:44,267 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8505161411382935, 'Total loss': 0.8505161411382935} | train loss {'Reaction outcome loss': 0.8447905801996893, 'Total loss': 0.8447905801996893}
2022-11-22 20:27:44,267 INFO:     Found new best model at epoch 1
2022-11-22 20:27:44,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:44,268 INFO:     Epoch: 2
2022-11-22 20:27:45,058 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8105193532326005, 'Total loss': 0.8105193532326005} | train loss {'Reaction outcome loss': 0.8322233325364639, 'Total loss': 0.8322233325364639}
2022-11-22 20:27:45,058 INFO:     Found new best model at epoch 2
2022-11-22 20:27:45,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:45,059 INFO:     Epoch: 3
2022-11-22 20:27:45,822 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.839326261119409, 'Total loss': 0.839326261119409} | train loss {'Reaction outcome loss': 0.8285362592765263, 'Total loss': 0.8285362592765263}
2022-11-22 20:27:45,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:45,822 INFO:     Epoch: 4
2022-11-22 20:27:46,633 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8086775724183429, 'Total loss': 0.8086775724183429} | train loss {'Reaction outcome loss': 0.8220874113695962, 'Total loss': 0.8220874113695962}
2022-11-22 20:27:46,633 INFO:     Found new best model at epoch 4
2022-11-22 20:27:46,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:46,635 INFO:     Epoch: 5
2022-11-22 20:27:47,461 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8139167306098071, 'Total loss': 0.8139167306098071} | train loss {'Reaction outcome loss': 0.8102513683085539, 'Total loss': 0.8102513683085539}
2022-11-22 20:27:47,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:47,463 INFO:     Epoch: 6
2022-11-22 20:27:48,309 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8425692590800199, 'Total loss': 0.8425692590800199} | train loss {'Reaction outcome loss': 0.81714514250658, 'Total loss': 0.81714514250658}
2022-11-22 20:27:48,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:48,309 INFO:     Epoch: 7
2022-11-22 20:27:49,139 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8224887624382973, 'Total loss': 0.8224887624382973} | train loss {'Reaction outcome loss': 0.8135300105931808, 'Total loss': 0.8135300105931808}
2022-11-22 20:27:49,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:49,139 INFO:     Epoch: 8
2022-11-22 20:27:49,908 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8217860514467413, 'Total loss': 0.8217860514467413} | train loss {'Reaction outcome loss': 0.8023687253192979, 'Total loss': 0.8023687253192979}
2022-11-22 20:27:49,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:49,909 INFO:     Epoch: 9
2022-11-22 20:27:50,707 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8170342790809545, 'Total loss': 0.8170342790809545} | train loss {'Reaction outcome loss': 0.8113372229799932, 'Total loss': 0.8113372229799932}
2022-11-22 20:27:50,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:50,707 INFO:     Epoch: 10
2022-11-22 20:27:51,499 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8066184778105129, 'Total loss': 0.8066184778105129} | train loss {'Reaction outcome loss': 0.8126236303728454, 'Total loss': 0.8126236303728454}
2022-11-22 20:27:51,499 INFO:     Found new best model at epoch 10
2022-11-22 20:27:51,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:51,500 INFO:     Epoch: 11
2022-11-22 20:27:52,262 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.796231553635814, 'Total loss': 0.796231553635814} | train loss {'Reaction outcome loss': 0.810634090097583, 'Total loss': 0.810634090097583}
2022-11-22 20:27:52,262 INFO:     Found new best model at epoch 11
2022-11-22 20:27:52,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:52,263 INFO:     Epoch: 12
2022-11-22 20:27:53,017 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8417679288170554, 'Total loss': 0.8417679288170554} | train loss {'Reaction outcome loss': 0.7981478975743663, 'Total loss': 0.7981478975743663}
2022-11-22 20:27:53,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:53,017 INFO:     Epoch: 13
2022-11-22 20:27:53,846 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8133890479803085, 'Total loss': 0.8133890479803085} | train loss {'Reaction outcome loss': 0.805930366443128, 'Total loss': 0.805930366443128}
2022-11-22 20:27:53,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:53,847 INFO:     Epoch: 14
2022-11-22 20:27:54,666 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8344809981909665, 'Total loss': 0.8344809981909665} | train loss {'Reaction outcome loss': 0.7999958403256475, 'Total loss': 0.7999958403256475}
2022-11-22 20:27:54,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:54,666 INFO:     Epoch: 15
2022-11-22 20:27:55,498 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8443838425657966, 'Total loss': 0.8443838425657966} | train loss {'Reaction outcome loss': 0.80402133622948, 'Total loss': 0.80402133622948}
2022-11-22 20:27:55,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:55,498 INFO:     Epoch: 16
2022-11-22 20:27:56,299 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.819960471581329, 'Total loss': 0.819960471581329} | train loss {'Reaction outcome loss': 0.8020957438313231, 'Total loss': 0.8020957438313231}
2022-11-22 20:27:56,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:56,300 INFO:     Epoch: 17
2022-11-22 20:27:57,097 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.83329976959662, 'Total loss': 0.83329976959662} | train loss {'Reaction outcome loss': 0.7977441949503762, 'Total loss': 0.7977441949503762}
2022-11-22 20:27:57,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:57,097 INFO:     Epoch: 18
2022-11-22 20:27:57,925 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8188993470235304, 'Total loss': 0.8188993470235304} | train loss {'Reaction outcome loss': 0.7989380465478313, 'Total loss': 0.7989380465478313}
2022-11-22 20:27:57,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:57,926 INFO:     Epoch: 19
2022-11-22 20:27:58,771 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8412373661994934, 'Total loss': 0.8412373661994934} | train loss {'Reaction outcome loss': 0.7949528009307628, 'Total loss': 0.7949528009307628}
2022-11-22 20:27:58,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:58,771 INFO:     Epoch: 20
2022-11-22 20:27:59,581 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8083156015385281, 'Total loss': 0.8083156015385281} | train loss {'Reaction outcome loss': 0.7971629771042843, 'Total loss': 0.7971629771042843}
2022-11-22 20:27:59,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:27:59,581 INFO:     Epoch: 21
2022-11-22 20:28:00,421 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.805982232093811, 'Total loss': 0.805982232093811} | train loss {'Reaction outcome loss': 0.7990360457070019, 'Total loss': 0.7990360457070019}
2022-11-22 20:28:00,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:00,422 INFO:     Epoch: 22
2022-11-22 20:28:01,211 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8141311095519499, 'Total loss': 0.8141311095519499} | train loss {'Reaction outcome loss': 0.8058624193376425, 'Total loss': 0.8058624193376425}
2022-11-22 20:28:01,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:01,211 INFO:     Epoch: 23
2022-11-22 20:28:02,090 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8179306360808286, 'Total loss': 0.8179306360808286} | train loss {'Reaction outcome loss': 0.7970829280055299, 'Total loss': 0.7970829280055299}
2022-11-22 20:28:02,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:02,090 INFO:     Epoch: 24
2022-11-22 20:28:02,875 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8002061102200638, 'Total loss': 0.8002061102200638} | train loss {'Reaction outcome loss': 0.7947442036502216, 'Total loss': 0.7947442036502216}
2022-11-22 20:28:02,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:02,876 INFO:     Epoch: 25
2022-11-22 20:28:03,681 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8122224814512513, 'Total loss': 0.8122224814512513} | train loss {'Reaction outcome loss': 0.8002520755845673, 'Total loss': 0.8002520755845673}
2022-11-22 20:28:03,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:03,681 INFO:     Epoch: 26
2022-11-22 20:28:04,434 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.805693195624785, 'Total loss': 0.805693195624785} | train loss {'Reaction outcome loss': 0.7974534340050756, 'Total loss': 0.7974534340050756}
2022-11-22 20:28:04,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:04,435 INFO:     Epoch: 27
2022-11-22 20:28:05,217 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7920643243600022, 'Total loss': 0.7920643243600022} | train loss {'Reaction outcome loss': 0.797393098656012, 'Total loss': 0.797393098656012}
2022-11-22 20:28:05,217 INFO:     Found new best model at epoch 27
2022-11-22 20:28:05,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:05,218 INFO:     Epoch: 28
2022-11-22 20:28:06,038 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8037044114687226, 'Total loss': 0.8037044114687226} | train loss {'Reaction outcome loss': 0.7920361490882173, 'Total loss': 0.7920361490882173}
2022-11-22 20:28:06,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:06,039 INFO:     Epoch: 29
2022-11-22 20:28:06,827 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8127858753908764, 'Total loss': 0.8127858753908764} | train loss {'Reaction outcome loss': 0.7970700782172534, 'Total loss': 0.7970700782172534}
2022-11-22 20:28:06,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:06,828 INFO:     Epoch: 30
2022-11-22 20:28:07,605 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.792862865735184, 'Total loss': 0.792862865735184} | train loss {'Reaction outcome loss': 0.7957952184336526, 'Total loss': 0.7957952184336526}
2022-11-22 20:28:07,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:07,606 INFO:     Epoch: 31
2022-11-22 20:28:08,444 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8061652373183857, 'Total loss': 0.8061652373183857} | train loss {'Reaction outcome loss': 0.7929832824638912, 'Total loss': 0.7929832824638912}
2022-11-22 20:28:08,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:08,444 INFO:     Epoch: 32
2022-11-22 20:28:09,213 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8291536227545955, 'Total loss': 0.8291536227545955} | train loss {'Reaction outcome loss': 0.7978539211409432, 'Total loss': 0.7978539211409432}
2022-11-22 20:28:09,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:09,213 INFO:     Epoch: 33
2022-11-22 20:28:10,102 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8185049783099781, 'Total loss': 0.8185049783099781} | train loss {'Reaction outcome loss': 0.7944034449908198, 'Total loss': 0.7944034449908198}
2022-11-22 20:28:10,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:10,102 INFO:     Epoch: 34
2022-11-22 20:28:10,906 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8374643149701032, 'Total loss': 0.8374643149701032} | train loss {'Reaction outcome loss': 0.7978683755105855, 'Total loss': 0.7978683755105855}
2022-11-22 20:28:10,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:10,906 INFO:     Epoch: 35
2022-11-22 20:28:11,700 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8350490020080046, 'Total loss': 0.8350490020080046} | train loss {'Reaction outcome loss': 0.7914742854176735, 'Total loss': 0.7914742854176735}
2022-11-22 20:28:11,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:11,701 INFO:     Epoch: 36
2022-11-22 20:28:12,463 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8060027591206811, 'Total loss': 0.8060027591206811} | train loss {'Reaction outcome loss': 0.7925503168787275, 'Total loss': 0.7925503168787275}
2022-11-22 20:28:12,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:12,463 INFO:     Epoch: 37
2022-11-22 20:28:13,258 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7906817550008948, 'Total loss': 0.7906817550008948} | train loss {'Reaction outcome loss': 0.7925517250080498, 'Total loss': 0.7925517250080498}
2022-11-22 20:28:13,258 INFO:     Found new best model at epoch 37
2022-11-22 20:28:13,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:13,259 INFO:     Epoch: 38
2022-11-22 20:28:13,999 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8230782340873372, 'Total loss': 0.8230782340873372} | train loss {'Reaction outcome loss': 0.7932484153582126, 'Total loss': 0.7932484153582126}
2022-11-22 20:28:13,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:13,999 INFO:     Epoch: 39
2022-11-22 20:28:14,801 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8442359424450181, 'Total loss': 0.8442359424450181} | train loss {'Reaction outcome loss': 0.7893079232196418, 'Total loss': 0.7893079232196418}
2022-11-22 20:28:14,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:14,801 INFO:     Epoch: 40
2022-11-22 20:28:15,569 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7989459322257475, 'Total loss': 0.7989459322257475} | train loss {'Reaction outcome loss': 0.7797595086146374, 'Total loss': 0.7797595086146374}
2022-11-22 20:28:15,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:15,570 INFO:     Epoch: 41
2022-11-22 20:28:16,404 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7882614203474738, 'Total loss': 0.7882614203474738} | train loss {'Reaction outcome loss': 0.7889027627755184, 'Total loss': 0.7889027627755184}
2022-11-22 20:28:16,404 INFO:     Found new best model at epoch 41
2022-11-22 20:28:16,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:16,405 INFO:     Epoch: 42
2022-11-22 20:28:17,198 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8237737258049574, 'Total loss': 0.8237737258049574} | train loss {'Reaction outcome loss': 0.7868881026092841, 'Total loss': 0.7868881026092841}
2022-11-22 20:28:17,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:17,198 INFO:     Epoch: 43
2022-11-22 20:28:17,926 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.81727495924993, 'Total loss': 0.81727495924993} | train loss {'Reaction outcome loss': 0.7863725799687055, 'Total loss': 0.7863725799687055}
2022-11-22 20:28:17,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:17,926 INFO:     Epoch: 44
2022-11-22 20:28:18,666 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8323016539216042, 'Total loss': 0.8323016539216042} | train loss {'Reaction outcome loss': 0.7849002845433294, 'Total loss': 0.7849002845433294}
2022-11-22 20:28:18,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:18,667 INFO:     Epoch: 45
2022-11-22 20:28:19,471 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8002811981873079, 'Total loss': 0.8002811981873079} | train loss {'Reaction outcome loss': 0.7851035139998611, 'Total loss': 0.7851035139998611}
2022-11-22 20:28:19,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:19,471 INFO:     Epoch: 46
2022-11-22 20:28:20,232 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7902447865767912, 'Total loss': 0.7902447865767912} | train loss {'Reaction outcome loss': 0.7819236960946297, 'Total loss': 0.7819236960946297}
2022-11-22 20:28:20,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:20,232 INFO:     Epoch: 47
2022-11-22 20:28:21,017 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7813557220453565, 'Total loss': 0.7813557220453565} | train loss {'Reaction outcome loss': 0.7843881156979775, 'Total loss': 0.7843881156979775}
2022-11-22 20:28:21,017 INFO:     Found new best model at epoch 47
2022-11-22 20:28:21,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:21,018 INFO:     Epoch: 48
2022-11-22 20:28:21,774 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.776090797375549, 'Total loss': 0.776090797375549} | train loss {'Reaction outcome loss': 0.7764372205247685, 'Total loss': 0.7764372205247685}
2022-11-22 20:28:21,774 INFO:     Found new best model at epoch 48
2022-11-22 20:28:21,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:21,775 INFO:     Epoch: 49
2022-11-22 20:28:22,503 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.794362024827437, 'Total loss': 0.794362024827437} | train loss {'Reaction outcome loss': 0.7770526769209881, 'Total loss': 0.7770526769209881}
2022-11-22 20:28:22,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:22,503 INFO:     Epoch: 50
2022-11-22 20:28:23,223 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7730173275552013, 'Total loss': 0.7730173275552013} | train loss {'Reaction outcome loss': 0.7803440430942847, 'Total loss': 0.7803440430942847}
2022-11-22 20:28:23,224 INFO:     Found new best model at epoch 50
2022-11-22 20:28:23,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:23,225 INFO:     Epoch: 51
2022-11-22 20:28:23,998 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7851276551796631, 'Total loss': 0.7851276551796631} | train loss {'Reaction outcome loss': 0.7781221616024874, 'Total loss': 0.7781221616024874}
2022-11-22 20:28:23,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:23,999 INFO:     Epoch: 52
2022-11-22 20:28:24,720 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8512804873965003, 'Total loss': 0.8512804873965003} | train loss {'Reaction outcome loss': 0.7738782948377181, 'Total loss': 0.7738782948377181}
2022-11-22 20:28:24,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:24,721 INFO:     Epoch: 53
2022-11-22 20:28:25,517 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.769196655601263, 'Total loss': 0.769196655601263} | train loss {'Reaction outcome loss': 0.780184264329015, 'Total loss': 0.780184264329015}
2022-11-22 20:28:25,517 INFO:     Found new best model at epoch 53
2022-11-22 20:28:25,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:25,518 INFO:     Epoch: 54
2022-11-22 20:28:26,240 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7860300500284542, 'Total loss': 0.7860300500284542} | train loss {'Reaction outcome loss': 0.7736719167962366, 'Total loss': 0.7736719167962366}
2022-11-22 20:28:26,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:26,240 INFO:     Epoch: 55
2022-11-22 20:28:26,973 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7743789714507081, 'Total loss': 0.7743789714507081} | train loss {'Reaction outcome loss': 0.7711226168943911, 'Total loss': 0.7711226168943911}
2022-11-22 20:28:26,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:26,973 INFO:     Epoch: 56
2022-11-22 20:28:27,731 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8231134062463586, 'Total loss': 0.8231134062463586} | train loss {'Reaction outcome loss': 0.7646878354403437, 'Total loss': 0.7646878354403437}
2022-11-22 20:28:27,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:27,731 INFO:     Epoch: 57
2022-11-22 20:28:28,477 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7764578400687738, 'Total loss': 0.7764578400687738} | train loss {'Reaction outcome loss': 0.768633876771343, 'Total loss': 0.768633876771343}
2022-11-22 20:28:28,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:28,478 INFO:     Epoch: 58
2022-11-22 20:28:29,310 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7927479723637755, 'Total loss': 0.7927479723637755} | train loss {'Reaction outcome loss': 0.7630136712473266, 'Total loss': 0.7630136712473266}
2022-11-22 20:28:29,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:29,311 INFO:     Epoch: 59
2022-11-22 20:28:30,042 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7798762565309351, 'Total loss': 0.7798762565309351} | train loss {'Reaction outcome loss': 0.7575285578260617, 'Total loss': 0.7575285578260617}
2022-11-22 20:28:30,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:30,043 INFO:     Epoch: 60
2022-11-22 20:28:30,780 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7932399436831474, 'Total loss': 0.7932399436831474} | train loss {'Reaction outcome loss': 0.7631905597691633, 'Total loss': 0.7631905597691633}
2022-11-22 20:28:30,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:30,780 INFO:     Epoch: 61
2022-11-22 20:28:31,487 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7551686296408827, 'Total loss': 0.7551686296408827} | train loss {'Reaction outcome loss': 0.7619140601887995, 'Total loss': 0.7619140601887995}
2022-11-22 20:28:31,487 INFO:     Found new best model at epoch 61
2022-11-22 20:28:31,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:31,488 INFO:     Epoch: 62
2022-11-22 20:28:32,209 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7497400888665156, 'Total loss': 0.7497400888665156} | train loss {'Reaction outcome loss': 0.7565577480257774, 'Total loss': 0.7565577480257774}
2022-11-22 20:28:32,209 INFO:     Found new best model at epoch 62
2022-11-22 20:28:32,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:32,210 INFO:     Epoch: 63
2022-11-22 20:28:32,919 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7711575044827028, 'Total loss': 0.7711575044827028} | train loss {'Reaction outcome loss': 0.7513073243656937, 'Total loss': 0.7513073243656937}
2022-11-22 20:28:32,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:32,919 INFO:     Epoch: 64
2022-11-22 20:28:33,712 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7765650708567012, 'Total loss': 0.7765650708567012} | train loss {'Reaction outcome loss': 0.7483443054617668, 'Total loss': 0.7483443054617668}
2022-11-22 20:28:33,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:33,712 INFO:     Epoch: 65
2022-11-22 20:28:34,439 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7532581714066592, 'Total loss': 0.7532581714066592} | train loss {'Reaction outcome loss': 0.7495819698791115, 'Total loss': 0.7495819698791115}
2022-11-22 20:28:34,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:34,440 INFO:     Epoch: 66
2022-11-22 20:28:35,148 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7861464592543516, 'Total loss': 0.7861464592543516} | train loss {'Reaction outcome loss': 0.7461309704245354, 'Total loss': 0.7461309704245354}
2022-11-22 20:28:35,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:35,149 INFO:     Epoch: 67
2022-11-22 20:28:35,868 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7741030675613068, 'Total loss': 0.7741030675613068} | train loss {'Reaction outcome loss': 0.7478873504667866, 'Total loss': 0.7478873504667866}
2022-11-22 20:28:35,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:35,868 INFO:     Epoch: 68
2022-11-22 20:28:36,639 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7486611682582985, 'Total loss': 0.7486611682582985} | train loss {'Reaction outcome loss': 0.7413499411271542, 'Total loss': 0.7413499411271542}
2022-11-22 20:28:36,639 INFO:     Found new best model at epoch 68
2022-11-22 20:28:36,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:36,640 INFO:     Epoch: 69
2022-11-22 20:28:37,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7751672606576573, 'Total loss': 0.7751672606576573} | train loss {'Reaction outcome loss': 0.7366126784864737, 'Total loss': 0.7366126784864737}
2022-11-22 20:28:37,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:37,383 INFO:     Epoch: 70
2022-11-22 20:28:38,117 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7615445032715797, 'Total loss': 0.7615445032715797} | train loss {'Reaction outcome loss': 0.7328238707415912, 'Total loss': 0.7328238707415912}
2022-11-22 20:28:38,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:38,118 INFO:     Epoch: 71
2022-11-22 20:28:38,877 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7669426053762436, 'Total loss': 0.7669426053762436} | train loss {'Reaction outcome loss': 0.7398906565442377, 'Total loss': 0.7398906565442377}
2022-11-22 20:28:38,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:38,878 INFO:     Epoch: 72
2022-11-22 20:28:39,656 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7511817040768537, 'Total loss': 0.7511817040768537} | train loss {'Reaction outcome loss': 0.7464426123366064, 'Total loss': 0.7464426123366064}
2022-11-22 20:28:39,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:39,657 INFO:     Epoch: 73
2022-11-22 20:28:40,441 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7425848696042191, 'Total loss': 0.7425848696042191} | train loss {'Reaction outcome loss': 0.7400999878134046, 'Total loss': 0.7400999878134046}
2022-11-22 20:28:40,441 INFO:     Found new best model at epoch 73
2022-11-22 20:28:40,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:40,442 INFO:     Epoch: 74
2022-11-22 20:28:41,203 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7946375994519754, 'Total loss': 0.7946375994519754} | train loss {'Reaction outcome loss': 0.7321789461739209, 'Total loss': 0.7321789461739209}
2022-11-22 20:28:41,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:41,203 INFO:     Epoch: 75
2022-11-22 20:28:41,938 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7478704269636761, 'Total loss': 0.7478704269636761} | train loss {'Reaction outcome loss': 0.7345004172957673, 'Total loss': 0.7345004172957673}
2022-11-22 20:28:41,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:41,938 INFO:     Epoch: 76
2022-11-22 20:28:42,703 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7557740360498428, 'Total loss': 0.7557740360498428} | train loss {'Reaction outcome loss': 0.7414680045478198, 'Total loss': 0.7414680045478198}
2022-11-22 20:28:42,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:42,703 INFO:     Epoch: 77
2022-11-22 20:28:43,470 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7751009173013947, 'Total loss': 0.7751009173013947} | train loss {'Reaction outcome loss': 0.730040466907073, 'Total loss': 0.730040466907073}
2022-11-22 20:28:43,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:43,470 INFO:     Epoch: 78
2022-11-22 20:28:44,277 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7523296685381369, 'Total loss': 0.7523296685381369} | train loss {'Reaction outcome loss': 0.7247335505728819, 'Total loss': 0.7247335505728819}
2022-11-22 20:28:44,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:44,277 INFO:     Epoch: 79
2022-11-22 20:28:45,000 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7395009940320795, 'Total loss': 0.7395009940320795} | train loss {'Reaction outcome loss': 0.7257341602627112, 'Total loss': 0.7257341602627112}
2022-11-22 20:28:45,001 INFO:     Found new best model at epoch 79
2022-11-22 20:28:45,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:45,001 INFO:     Epoch: 80
2022-11-22 20:28:45,756 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7722879174080762, 'Total loss': 0.7722879174080762} | train loss {'Reaction outcome loss': 0.7282105876474965, 'Total loss': 0.7282105876474965}
2022-11-22 20:28:45,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:45,757 INFO:     Epoch: 81
2022-11-22 20:28:46,520 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7662971256808802, 'Total loss': 0.7662971256808802} | train loss {'Reaction outcome loss': 0.7286548219165023, 'Total loss': 0.7286548219165023}
2022-11-22 20:28:46,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:46,520 INFO:     Epoch: 82
2022-11-22 20:28:47,268 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7373257291249253, 'Total loss': 0.7373257291249253} | train loss {'Reaction outcome loss': 0.7338628343173436, 'Total loss': 0.7338628343173436}
2022-11-22 20:28:47,268 INFO:     Found new best model at epoch 82
2022-11-22 20:28:47,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:47,269 INFO:     Epoch: 83
2022-11-22 20:28:48,028 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7586756958202883, 'Total loss': 0.7586756958202883} | train loss {'Reaction outcome loss': 0.7328927947550404, 'Total loss': 0.7328927947550404}
2022-11-22 20:28:48,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:48,029 INFO:     Epoch: 84
2022-11-22 20:28:48,808 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7785873568870805, 'Total loss': 0.7785873568870805} | train loss {'Reaction outcome loss': 0.7258745478124035, 'Total loss': 0.7258745478124035}
2022-11-22 20:28:48,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:48,809 INFO:     Epoch: 85
2022-11-22 20:28:49,598 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7601466910405592, 'Total loss': 0.7601466910405592} | train loss {'Reaction outcome loss': 0.7249648675626638, 'Total loss': 0.7249648675626638}
2022-11-22 20:28:49,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:49,599 INFO:     Epoch: 86
2022-11-22 20:28:50,302 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7389989833940159, 'Total loss': 0.7389989833940159} | train loss {'Reaction outcome loss': 0.7220233287130083, 'Total loss': 0.7220233287130083}
2022-11-22 20:28:50,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:50,303 INFO:     Epoch: 87
2022-11-22 20:28:51,053 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8469692956317555, 'Total loss': 0.8469692956317555} | train loss {'Reaction outcome loss': 0.7238545608155581, 'Total loss': 0.7238545608155581}
2022-11-22 20:28:51,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:51,054 INFO:     Epoch: 88
2022-11-22 20:28:51,853 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7684852643446489, 'Total loss': 0.7684852643446489} | train loss {'Reaction outcome loss': 0.727848367058501, 'Total loss': 0.727848367058501}
2022-11-22 20:28:51,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:51,853 INFO:     Epoch: 89
2022-11-22 20:28:52,619 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7260181809013541, 'Total loss': 0.7260181809013541} | train loss {'Reaction outcome loss': 0.7298459357144881, 'Total loss': 0.7298459357144881}
2022-11-22 20:28:52,619 INFO:     Found new best model at epoch 89
2022-11-22 20:28:52,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:52,620 INFO:     Epoch: 90
2022-11-22 20:28:53,373 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7266982624476607, 'Total loss': 0.7266982624476607} | train loss {'Reaction outcome loss': 0.7208009305048962, 'Total loss': 0.7208009305048962}
2022-11-22 20:28:53,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:53,373 INFO:     Epoch: 91
2022-11-22 20:28:54,113 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7243804112076759, 'Total loss': 0.7243804112076759} | train loss {'Reaction outcome loss': 0.7271229408225235, 'Total loss': 0.7271229408225235}
2022-11-22 20:28:54,113 INFO:     Found new best model at epoch 91
2022-11-22 20:28:54,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:54,114 INFO:     Epoch: 92
2022-11-22 20:28:54,908 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7430251477794214, 'Total loss': 0.7430251477794214} | train loss {'Reaction outcome loss': 0.718400034795002, 'Total loss': 0.718400034795002}
2022-11-22 20:28:54,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:54,909 INFO:     Epoch: 93
2022-11-22 20:28:55,637 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.733937207609415, 'Total loss': 0.733937207609415} | train loss {'Reaction outcome loss': 0.7201011079914715, 'Total loss': 0.7201011079914715}
2022-11-22 20:28:55,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:55,638 INFO:     Epoch: 94
2022-11-22 20:28:56,376 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7371415448459712, 'Total loss': 0.7371415448459712} | train loss {'Reaction outcome loss': 0.7102577108509687, 'Total loss': 0.7102577108509687}
2022-11-22 20:28:56,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:56,376 INFO:     Epoch: 95
2022-11-22 20:28:57,125 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7584334401921793, 'Total loss': 0.7584334401921793} | train loss {'Reaction outcome loss': 0.7188827643589097, 'Total loss': 0.7188827643589097}
2022-11-22 20:28:57,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:57,126 INFO:     Epoch: 96
2022-11-22 20:28:57,885 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7706130421297117, 'Total loss': 0.7706130421297117} | train loss {'Reaction outcome loss': 0.717048070564562, 'Total loss': 0.717048070564562}
2022-11-22 20:28:57,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:57,885 INFO:     Epoch: 97
2022-11-22 20:28:58,663 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8030343956568025, 'Total loss': 0.8030343956568025} | train loss {'Reaction outcome loss': 0.7100398398175531, 'Total loss': 0.7100398398175531}
2022-11-22 20:28:58,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:58,664 INFO:     Epoch: 98
2022-11-22 20:28:59,404 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7209281840107657, 'Total loss': 0.7209281840107657} | train loss {'Reaction outcome loss': 0.72154910187332, 'Total loss': 0.72154910187332}
2022-11-22 20:28:59,404 INFO:     Found new best model at epoch 98
2022-11-22 20:28:59,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:28:59,405 INFO:     Epoch: 99
2022-11-22 20:29:00,185 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.74383525618098, 'Total loss': 0.74383525618098} | train loss {'Reaction outcome loss': 0.711892754934272, 'Total loss': 0.711892754934272}
2022-11-22 20:29:00,186 INFO:     Best model found after epoch 99 of 100.
2022-11-22 20:29:00,186 INFO:   Done with stage: TRAINING
2022-11-22 20:29:00,186 INFO:   Starting stage: EVALUATION
2022-11-22 20:29:00,311 INFO:   Done with stage: EVALUATION
2022-11-22 20:29:00,311 INFO:   Leaving out SEQ value Fold_5
2022-11-22 20:29:00,324 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:29:00,324 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:29:00,996 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:29:00,996 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:29:01,065 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:29:01,066 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:29:01,066 INFO:     No hyperparam tuning for this model
2022-11-22 20:29:01,066 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:29:01,066 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:29:01,067 INFO:     None feature selector for col prot
2022-11-22 20:29:01,067 INFO:     None feature selector for col prot
2022-11-22 20:29:01,067 INFO:     None feature selector for col prot
2022-11-22 20:29:01,068 INFO:     None feature selector for col chem
2022-11-22 20:29:01,068 INFO:     None feature selector for col chem
2022-11-22 20:29:01,068 INFO:     None feature selector for col chem
2022-11-22 20:29:01,068 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:29:01,068 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:29:01,069 INFO:     Number of params in model 126091
2022-11-22 20:29:01,072 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:29:01,073 INFO:   Starting stage: TRAINING
2022-11-22 20:29:01,121 INFO:     Val loss before train {'Reaction outcome loss': 1.07692759280855, 'Total loss': 1.07692759280855}
2022-11-22 20:29:01,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:01,122 INFO:     Epoch: 0
2022-11-22 20:29:01,849 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9009552557360042, 'Total loss': 0.9009552557360042} | train loss {'Reaction outcome loss': 0.8673969561513136, 'Total loss': 0.8673969561513136}
2022-11-22 20:29:01,849 INFO:     Found new best model at epoch 0
2022-11-22 20:29:01,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:01,850 INFO:     Epoch: 1
2022-11-22 20:29:02,574 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9250548630952835, 'Total loss': 0.9250548630952835} | train loss {'Reaction outcome loss': 0.8378943698367609, 'Total loss': 0.8378943698367609}
2022-11-22 20:29:02,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:02,574 INFO:     Epoch: 2
2022-11-22 20:29:03,307 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8787778412753885, 'Total loss': 0.8787778412753885} | train loss {'Reaction outcome loss': 0.8354091667513616, 'Total loss': 0.8354091667513616}
2022-11-22 20:29:03,307 INFO:     Found new best model at epoch 2
2022-11-22 20:29:03,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:03,308 INFO:     Epoch: 3
2022-11-22 20:29:04,049 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8677682666616007, 'Total loss': 0.8677682666616007} | train loss {'Reaction outcome loss': 0.8214477765174047, 'Total loss': 0.8214477765174047}
2022-11-22 20:29:04,049 INFO:     Found new best model at epoch 3
2022-11-22 20:29:04,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:04,050 INFO:     Epoch: 4
2022-11-22 20:29:04,791 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.882698926736008, 'Total loss': 0.882698926736008} | train loss {'Reaction outcome loss': 0.8143385660793134, 'Total loss': 0.8143385660793134}
2022-11-22 20:29:04,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:04,792 INFO:     Epoch: 5
2022-11-22 20:29:05,544 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8629789271137931, 'Total loss': 0.8629789271137931} | train loss {'Reaction outcome loss': 0.8138155821363936, 'Total loss': 0.8138155821363936}
2022-11-22 20:29:05,544 INFO:     Found new best model at epoch 5
2022-11-22 20:29:05,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:05,545 INFO:     Epoch: 6
2022-11-22 20:29:06,269 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8536530198021368, 'Total loss': 0.8536530198021368} | train loss {'Reaction outcome loss': 0.8099643723202138, 'Total loss': 0.8099643723202138}
2022-11-22 20:29:06,269 INFO:     Found new best model at epoch 6
2022-11-22 20:29:06,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:06,270 INFO:     Epoch: 7
2022-11-22 20:29:07,029 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8535286845131353, 'Total loss': 0.8535286845131353} | train loss {'Reaction outcome loss': 0.81455719247762, 'Total loss': 0.81455719247762}
2022-11-22 20:29:07,029 INFO:     Found new best model at epoch 7
2022-11-22 20:29:07,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:07,030 INFO:     Epoch: 8
2022-11-22 20:29:07,757 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8649162257259543, 'Total loss': 0.8649162257259543} | train loss {'Reaction outcome loss': 0.799851913563153, 'Total loss': 0.799851913563153}
2022-11-22 20:29:07,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:07,758 INFO:     Epoch: 9
2022-11-22 20:29:08,477 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8685100058262999, 'Total loss': 0.8685100058262999} | train loss {'Reaction outcome loss': 0.7982936252798387, 'Total loss': 0.7982936252798387}
2022-11-22 20:29:08,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:08,477 INFO:     Epoch: 10
2022-11-22 20:29:09,235 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8640156103806063, 'Total loss': 0.8640156103806063} | train loss {'Reaction outcome loss': 0.7970817897483887, 'Total loss': 0.7970817897483887}
2022-11-22 20:29:09,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:09,235 INFO:     Epoch: 11
2022-11-22 20:29:10,024 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8615413565527309, 'Total loss': 0.8615413565527309} | train loss {'Reaction outcome loss': 0.7982670125449717, 'Total loss': 0.7982670125449717}
2022-11-22 20:29:10,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:10,024 INFO:     Epoch: 12
2022-11-22 20:29:10,731 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8486386943947185, 'Total loss': 0.8486386943947185} | train loss {'Reaction outcome loss': 0.7971289779251887, 'Total loss': 0.7971289779251887}
2022-11-22 20:29:10,731 INFO:     Found new best model at epoch 12
2022-11-22 20:29:10,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:10,732 INFO:     Epoch: 13
2022-11-22 20:29:11,481 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8940996121276509, 'Total loss': 0.8940996121276509} | train loss {'Reaction outcome loss': 0.8041579223837447, 'Total loss': 0.8041579223837447}
2022-11-22 20:29:11,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:11,481 INFO:     Epoch: 14
2022-11-22 20:29:12,253 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8553438559174538, 'Total loss': 0.8553438559174538} | train loss {'Reaction outcome loss': 0.7930331588515386, 'Total loss': 0.7930331588515386}
2022-11-22 20:29:12,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:12,253 INFO:     Epoch: 15
2022-11-22 20:29:13,032 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8493393009359186, 'Total loss': 0.8493393009359186} | train loss {'Reaction outcome loss': 0.8037349143129612, 'Total loss': 0.8037349143129612}
2022-11-22 20:29:13,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:13,032 INFO:     Epoch: 16
2022-11-22 20:29:13,811 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8845272863453085, 'Total loss': 0.8845272863453085} | train loss {'Reaction outcome loss': 0.7880580798093124, 'Total loss': 0.7880580798093124}
2022-11-22 20:29:13,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:13,812 INFO:     Epoch: 17
2022-11-22 20:29:14,582 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8340707136826082, 'Total loss': 0.8340707136826082} | train loss {'Reaction outcome loss': 0.7898672919886315, 'Total loss': 0.7898672919886315}
2022-11-22 20:29:14,582 INFO:     Found new best model at epoch 17
2022-11-22 20:29:14,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:14,583 INFO:     Epoch: 18
2022-11-22 20:29:15,322 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8427027890628035, 'Total loss': 0.8427027890628035} | train loss {'Reaction outcome loss': 0.7924220923952728, 'Total loss': 0.7924220923952728}
2022-11-22 20:29:15,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:15,322 INFO:     Epoch: 19
2022-11-22 20:29:16,082 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8197430656714872, 'Total loss': 0.8197430656714872} | train loss {'Reaction outcome loss': 0.789601384748814, 'Total loss': 0.789601384748814}
2022-11-22 20:29:16,083 INFO:     Found new best model at epoch 19
2022-11-22 20:29:16,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:16,084 INFO:     Epoch: 20
2022-11-22 20:29:16,805 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8357388417829167, 'Total loss': 0.8357388417829167} | train loss {'Reaction outcome loss': 0.7816831195266986, 'Total loss': 0.7816831195266986}
2022-11-22 20:29:16,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:16,805 INFO:     Epoch: 21
2022-11-22 20:29:17,554 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8344214694066481, 'Total loss': 0.8344214694066481} | train loss {'Reaction outcome loss': 0.7824509386048626, 'Total loss': 0.7824509386048626}
2022-11-22 20:29:17,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:17,554 INFO:     Epoch: 22
2022-11-22 20:29:18,356 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8343188369816, 'Total loss': 0.8343188369816} | train loss {'Reaction outcome loss': 0.7906951012640346, 'Total loss': 0.7906951012640346}
2022-11-22 20:29:18,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:18,356 INFO:     Epoch: 23
2022-11-22 20:29:19,125 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.842375323176384, 'Total loss': 0.842375323176384} | train loss {'Reaction outcome loss': 0.7867342552192781, 'Total loss': 0.7867342552192781}
2022-11-22 20:29:19,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:19,126 INFO:     Epoch: 24
2022-11-22 20:29:19,887 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8463649275628004, 'Total loss': 0.8463649275628004} | train loss {'Reaction outcome loss': 0.7865440115513589, 'Total loss': 0.7865440115513589}
2022-11-22 20:29:19,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:19,888 INFO:     Epoch: 25
2022-11-22 20:29:20,658 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8324689052321694, 'Total loss': 0.8324689052321694} | train loss {'Reaction outcome loss': 0.7876670952991918, 'Total loss': 0.7876670952991918}
2022-11-22 20:29:20,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:20,659 INFO:     Epoch: 26
2022-11-22 20:29:21,456 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8457848849621686, 'Total loss': 0.8457848849621686} | train loss {'Reaction outcome loss': 0.7862222405821688, 'Total loss': 0.7862222405821688}
2022-11-22 20:29:21,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:21,456 INFO:     Epoch: 27
2022-11-22 20:29:22,210 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8215022161602974, 'Total loss': 0.8215022161602974} | train loss {'Reaction outcome loss': 0.7878563758815348, 'Total loss': 0.7878563758815348}
2022-11-22 20:29:22,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:22,210 INFO:     Epoch: 28
2022-11-22 20:29:22,979 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8722368383949454, 'Total loss': 0.8722368383949454} | train loss {'Reaction outcome loss': 0.7807930006913328, 'Total loss': 0.7807930006913328}
2022-11-22 20:29:22,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:22,979 INFO:     Epoch: 29
2022-11-22 20:29:23,731 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.851773398166353, 'Total loss': 0.851773398166353} | train loss {'Reaction outcome loss': 0.7870588526280544, 'Total loss': 0.7870588526280544}
2022-11-22 20:29:23,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:23,731 INFO:     Epoch: 30
2022-11-22 20:29:24,461 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8420354507186196, 'Total loss': 0.8420354507186196} | train loss {'Reaction outcome loss': 0.7844930461905746, 'Total loss': 0.7844930461905746}
2022-11-22 20:29:24,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:24,461 INFO:     Epoch: 31
2022-11-22 20:29:25,196 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8355385904962366, 'Total loss': 0.8355385904962366} | train loss {'Reaction outcome loss': 0.7892732012127093, 'Total loss': 0.7892732012127093}
2022-11-22 20:29:25,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:25,197 INFO:     Epoch: 32
2022-11-22 20:29:25,967 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8472711714831266, 'Total loss': 0.8472711714831266} | train loss {'Reaction outcome loss': 0.7818813774629161, 'Total loss': 0.7818813774629161}
2022-11-22 20:29:25,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:25,968 INFO:     Epoch: 33
2022-11-22 20:29:26,732 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8278201574629004, 'Total loss': 0.8278201574629004} | train loss {'Reaction outcome loss': 0.784936198459463, 'Total loss': 0.784936198459463}
2022-11-22 20:29:26,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:26,733 INFO:     Epoch: 34
2022-11-22 20:29:27,483 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8517165644602342, 'Total loss': 0.8517165644602342} | train loss {'Reaction outcome loss': 0.7795812999188658, 'Total loss': 0.7795812999188658}
2022-11-22 20:29:27,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:27,483 INFO:     Epoch: 35
2022-11-22 20:29:28,208 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8402051627635956, 'Total loss': 0.8402051627635956} | train loss {'Reaction outcome loss': 0.7872072651318693, 'Total loss': 0.7872072651318693}
2022-11-22 20:29:28,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:28,208 INFO:     Epoch: 36
2022-11-22 20:29:28,928 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8568210554393855, 'Total loss': 0.8568210554393855} | train loss {'Reaction outcome loss': 0.7766615829245764, 'Total loss': 0.7766615829245764}
2022-11-22 20:29:28,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:28,928 INFO:     Epoch: 37
2022-11-22 20:29:29,676 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8439850021492351, 'Total loss': 0.8439850021492351} | train loss {'Reaction outcome loss': 0.7800851676552764, 'Total loss': 0.7800851676552764}
2022-11-22 20:29:29,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:29,676 INFO:     Epoch: 38
2022-11-22 20:29:30,373 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8413233601234176, 'Total loss': 0.8413233601234176} | train loss {'Reaction outcome loss': 0.7803747336632809, 'Total loss': 0.7803747336632809}
2022-11-22 20:29:30,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:30,373 INFO:     Epoch: 39
2022-11-22 20:29:31,111 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.83003030852838, 'Total loss': 0.83003030852838} | train loss {'Reaction outcome loss': 0.7838152788187328, 'Total loss': 0.7838152788187328}
2022-11-22 20:29:31,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:31,111 INFO:     Epoch: 40
2022-11-22 20:29:31,871 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8295346037908033, 'Total loss': 0.8295346037908033} | train loss {'Reaction outcome loss': 0.7804236149015696, 'Total loss': 0.7804236149015696}
2022-11-22 20:29:31,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:31,871 INFO:     Epoch: 41
2022-11-22 20:29:32,577 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.877171361988241, 'Total loss': 0.877171361988241} | train loss {'Reaction outcome loss': 0.780134002086122, 'Total loss': 0.780134002086122}
2022-11-22 20:29:32,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:32,577 INFO:     Epoch: 42
2022-11-22 20:29:33,330 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8641876524144952, 'Total loss': 0.8641876524144952} | train loss {'Reaction outcome loss': 0.7790202454396105, 'Total loss': 0.7790202454396105}
2022-11-22 20:29:33,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:33,330 INFO:     Epoch: 43
2022-11-22 20:29:34,093 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8312621821056713, 'Total loss': 0.8312621821056713} | train loss {'Reaction outcome loss': 0.7727033580287628, 'Total loss': 0.7727033580287628}
2022-11-22 20:29:34,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:34,094 INFO:     Epoch: 44
2022-11-22 20:29:34,805 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8409108546647158, 'Total loss': 0.8409108546647158} | train loss {'Reaction outcome loss': 0.7852488629489776, 'Total loss': 0.7852488629489776}
2022-11-22 20:29:34,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:34,805 INFO:     Epoch: 45
2022-11-22 20:29:35,520 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.854721880771897, 'Total loss': 0.854721880771897} | train loss {'Reaction outcome loss': 0.782891651155495, 'Total loss': 0.782891651155495}
2022-11-22 20:29:35,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:35,520 INFO:     Epoch: 46
2022-11-22 20:29:36,290 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8431775651194833, 'Total loss': 0.8431775651194833} | train loss {'Reaction outcome loss': 0.7890683121768086, 'Total loss': 0.7890683121768086}
2022-11-22 20:29:36,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:36,290 INFO:     Epoch: 47
2022-11-22 20:29:37,031 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8394077643752098, 'Total loss': 0.8394077643752098} | train loss {'Reaction outcome loss': 0.7836026408170399, 'Total loss': 0.7836026408170399}
2022-11-22 20:29:37,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:37,032 INFO:     Epoch: 48
2022-11-22 20:29:37,751 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8398737826130607, 'Total loss': 0.8398737826130607} | train loss {'Reaction outcome loss': 0.783234335331299, 'Total loss': 0.783234335331299}
2022-11-22 20:29:37,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:37,751 INFO:     Epoch: 49
2022-11-22 20:29:38,509 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8554940833286806, 'Total loss': 0.8554940833286806} | train loss {'Reaction outcome loss': 0.7821725961650431, 'Total loss': 0.7821725961650431}
2022-11-22 20:29:38,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:38,510 INFO:     Epoch: 50
2022-11-22 20:29:39,291 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8659629706632007, 'Total loss': 0.8659629706632007} | train loss {'Reaction outcome loss': 0.7834563640206449, 'Total loss': 0.7834563640206449}
2022-11-22 20:29:39,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:39,292 INFO:     Epoch: 51
2022-11-22 20:29:40,011 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8459284698421304, 'Total loss': 0.8459284698421304} | train loss {'Reaction outcome loss': 0.7950277190942031, 'Total loss': 0.7950277190942031}
2022-11-22 20:29:40,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:40,011 INFO:     Epoch: 52
2022-11-22 20:29:40,748 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8561648631637747, 'Total loss': 0.8561648631637747} | train loss {'Reaction outcome loss': 0.7837974208327922, 'Total loss': 0.7837974208327922}
2022-11-22 20:29:40,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:40,748 INFO:     Epoch: 53
2022-11-22 20:29:41,537 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8623848808082667, 'Total loss': 0.8623848808082667} | train loss {'Reaction outcome loss': 0.7818553397047375, 'Total loss': 0.7818553397047375}
2022-11-22 20:29:41,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:41,537 INFO:     Epoch: 54
2022-11-22 20:29:42,323 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8391375230117277, 'Total loss': 0.8391375230117277} | train loss {'Reaction outcome loss': 0.7834486312832427, 'Total loss': 0.7834486312832427}
2022-11-22 20:29:42,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:42,324 INFO:     Epoch: 55
2022-11-22 20:29:43,071 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8552771637385542, 'Total loss': 0.8552771637385542} | train loss {'Reaction outcome loss': 0.7758383454098875, 'Total loss': 0.7758383454098875}
2022-11-22 20:29:43,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:43,071 INFO:     Epoch: 56
2022-11-22 20:29:43,794 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8354022773829374, 'Total loss': 0.8354022773829374} | train loss {'Reaction outcome loss': 0.7817629251161567, 'Total loss': 0.7817629251161567}
2022-11-22 20:29:43,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:43,795 INFO:     Epoch: 57
2022-11-22 20:29:44,539 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8442333272912286, 'Total loss': 0.8442333272912286} | train loss {'Reaction outcome loss': 0.7769745915283558, 'Total loss': 0.7769745915283558}
2022-11-22 20:29:44,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:44,540 INFO:     Epoch: 58
2022-11-22 20:29:45,292 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.827167119492184, 'Total loss': 0.827167119492184} | train loss {'Reaction outcome loss': 0.7801476350197425, 'Total loss': 0.7801476350197425}
2022-11-22 20:29:45,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:45,292 INFO:     Epoch: 59
2022-11-22 20:29:46,079 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.850237017328089, 'Total loss': 0.850237017328089} | train loss {'Reaction outcome loss': 0.7835624074405022, 'Total loss': 0.7835624074405022}
2022-11-22 20:29:46,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:46,079 INFO:     Epoch: 60
2022-11-22 20:29:46,844 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8530943840742111, 'Total loss': 0.8530943840742111} | train loss {'Reaction outcome loss': 0.7897412366712624, 'Total loss': 0.7897412366712624}
2022-11-22 20:29:46,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:46,845 INFO:     Epoch: 61
2022-11-22 20:29:47,565 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8570488081736998, 'Total loss': 0.8570488081736998} | train loss {'Reaction outcome loss': 0.7935511123554909, 'Total loss': 0.7935511123554909}
2022-11-22 20:29:47,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:47,565 INFO:     Epoch: 62
2022-11-22 20:29:48,332 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.849987654523416, 'Total loss': 0.849987654523416} | train loss {'Reaction outcome loss': 0.7740985990204068, 'Total loss': 0.7740985990204068}
2022-11-22 20:29:48,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:48,332 INFO:     Epoch: 63
2022-11-22 20:29:49,089 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8542795533483679, 'Total loss': 0.8542795533483679} | train loss {'Reaction outcome loss': 0.7669585085877402, 'Total loss': 0.7669585085877402}
2022-11-22 20:29:49,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:49,089 INFO:     Epoch: 64
2022-11-22 20:29:49,815 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8560033914717761, 'Total loss': 0.8560033914717761} | train loss {'Reaction outcome loss': 0.7742590668954348, 'Total loss': 0.7742590668954348}
2022-11-22 20:29:49,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:49,815 INFO:     Epoch: 65
2022-11-22 20:29:50,527 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8377821181308139, 'Total loss': 0.8377821181308139} | train loss {'Reaction outcome loss': 0.7812726230997789, 'Total loss': 0.7812726230997789}
2022-11-22 20:29:50,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:50,527 INFO:     Epoch: 66
2022-11-22 20:29:51,276 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8044388389045541, 'Total loss': 0.8044388389045541} | train loss {'Reaction outcome loss': 0.7783909156496226, 'Total loss': 0.7783909156496226}
2022-11-22 20:29:51,276 INFO:     Found new best model at epoch 66
2022-11-22 20:29:51,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:51,277 INFO:     Epoch: 67
2022-11-22 20:29:52,072 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8311386853456497, 'Total loss': 0.8311386853456497} | train loss {'Reaction outcome loss': 0.7693594811175034, 'Total loss': 0.7693594811175034}
2022-11-22 20:29:52,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:52,073 INFO:     Epoch: 68
2022-11-22 20:29:52,858 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.829445402730595, 'Total loss': 0.829445402730595} | train loss {'Reaction outcome loss': 0.7717361080984355, 'Total loss': 0.7717361080984355}
2022-11-22 20:29:52,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:52,858 INFO:     Epoch: 69
2022-11-22 20:29:53,656 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.825818500735543, 'Total loss': 0.825818500735543} | train loss {'Reaction outcome loss': 0.7883326055308585, 'Total loss': 0.7883326055308585}
2022-11-22 20:29:53,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:53,656 INFO:     Epoch: 70
2022-11-22 20:29:54,363 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8525243767283179, 'Total loss': 0.8525243767283179} | train loss {'Reaction outcome loss': 0.7748667999559086, 'Total loss': 0.7748667999559086}
2022-11-22 20:29:54,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:54,364 INFO:     Epoch: 71
2022-11-22 20:29:55,109 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8637282604520972, 'Total loss': 0.8637282604520972} | train loss {'Reaction outcome loss': 0.7715079954519928, 'Total loss': 0.7715079954519928}
2022-11-22 20:29:55,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:55,110 INFO:     Epoch: 72
2022-11-22 20:29:55,839 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8527437489141118, 'Total loss': 0.8527437489141118} | train loss {'Reaction outcome loss': 0.7768037561100987, 'Total loss': 0.7768037561100987}
2022-11-22 20:29:55,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:55,839 INFO:     Epoch: 73
2022-11-22 20:29:56,566 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8756877170367674, 'Total loss': 0.8756877170367674} | train loss {'Reaction outcome loss': 0.7699212401140074, 'Total loss': 0.7699212401140074}
2022-11-22 20:29:56,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:56,567 INFO:     Epoch: 74
2022-11-22 20:29:57,322 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8408806269819086, 'Total loss': 0.8408806269819086} | train loss {'Reaction outcome loss': 0.7698374204186775, 'Total loss': 0.7698374204186775}
2022-11-22 20:29:57,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:57,323 INFO:     Epoch: 75
2022-11-22 20:29:58,088 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8243882574818351, 'Total loss': 0.8243882574818351} | train loss {'Reaction outcome loss': 0.7686672735552074, 'Total loss': 0.7686672735552074}
2022-11-22 20:29:58,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:58,089 INFO:     Epoch: 76
2022-11-22 20:29:58,844 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8352298574014143, 'Total loss': 0.8352298574014143} | train loss {'Reaction outcome loss': 0.7766507018191612, 'Total loss': 0.7766507018191612}
2022-11-22 20:29:58,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:58,844 INFO:     Epoch: 77
2022-11-22 20:29:59,633 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8080456324599006, 'Total loss': 0.8080456324599006} | train loss {'Reaction outcome loss': 0.7766184450885062, 'Total loss': 0.7766184450885062}
2022-11-22 20:29:59,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:29:59,633 INFO:     Epoch: 78
2022-11-22 20:30:00,361 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8268051648681815, 'Total loss': 0.8268051648681815} | train loss {'Reaction outcome loss': 0.7677148491264838, 'Total loss': 0.7677148491264838}
2022-11-22 20:30:00,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:00,361 INFO:     Epoch: 79
2022-11-22 20:30:01,130 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8360694226893511, 'Total loss': 0.8360694226893511} | train loss {'Reaction outcome loss': 0.7674946133424396, 'Total loss': 0.7674946133424396}
2022-11-22 20:30:01,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:01,130 INFO:     Epoch: 80
2022-11-22 20:30:01,871 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8249612443826415, 'Total loss': 0.8249612443826415} | train loss {'Reaction outcome loss': 0.7713433606663214, 'Total loss': 0.7713433606663214}
2022-11-22 20:30:01,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:01,871 INFO:     Epoch: 81
2022-11-22 20:30:02,655 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8275148678909648, 'Total loss': 0.8275148678909648} | train loss {'Reaction outcome loss': 0.7691588389728716, 'Total loss': 0.7691588389728716}
2022-11-22 20:30:02,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:02,655 INFO:     Epoch: 82
2022-11-22 20:30:03,410 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.804828056557612, 'Total loss': 0.804828056557612} | train loss {'Reaction outcome loss': 0.7748098649718018, 'Total loss': 0.7748098649718018}
2022-11-22 20:30:03,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:03,410 INFO:     Epoch: 83
2022-11-22 20:30:04,225 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8056478635831312, 'Total loss': 0.8056478635831312} | train loss {'Reaction outcome loss': 0.7673190771055366, 'Total loss': 0.7673190771055366}
2022-11-22 20:30:04,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:04,225 INFO:     Epoch: 84
2022-11-22 20:30:04,978 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8124246976592324, 'Total loss': 0.8124246976592324} | train loss {'Reaction outcome loss': 0.7618475512937013, 'Total loss': 0.7618475512937013}
2022-11-22 20:30:04,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:04,978 INFO:     Epoch: 85
2022-11-22 20:30:05,721 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8188986764712767, 'Total loss': 0.8188986764712767} | train loss {'Reaction outcome loss': 0.7665611401743252, 'Total loss': 0.7665611401743252}
2022-11-22 20:30:05,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:05,721 INFO:     Epoch: 86
2022-11-22 20:30:06,451 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8409562971104275, 'Total loss': 0.8409562971104275} | train loss {'Reaction outcome loss': 0.7617199484273972, 'Total loss': 0.7617199484273972}
2022-11-22 20:30:06,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:06,451 INFO:     Epoch: 87
2022-11-22 20:30:07,193 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8053641705350443, 'Total loss': 0.8053641705350443} | train loss {'Reaction outcome loss': 0.760036161915976, 'Total loss': 0.760036161915976}
2022-11-22 20:30:07,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:07,194 INFO:     Epoch: 88
2022-11-22 20:30:07,915 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8735040642998435, 'Total loss': 0.8735040642998435} | train loss {'Reaction outcome loss': 0.7660095340568527, 'Total loss': 0.7660095340568527}
2022-11-22 20:30:07,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:07,915 INFO:     Epoch: 89
2022-11-22 20:30:08,667 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7986809441989119, 'Total loss': 0.7986809441989119} | train loss {'Reaction outcome loss': 0.7652072490226884, 'Total loss': 0.7652072490226884}
2022-11-22 20:30:08,667 INFO:     Found new best model at epoch 89
2022-11-22 20:30:08,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:08,668 INFO:     Epoch: 90
2022-11-22 20:30:09,408 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8092437555844133, 'Total loss': 0.8092437555844133} | train loss {'Reaction outcome loss': 0.7570257562133464, 'Total loss': 0.7570257562133464}
2022-11-22 20:30:09,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:09,408 INFO:     Epoch: 91
2022-11-22 20:30:10,144 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8510502509095452, 'Total loss': 0.8510502509095452} | train loss {'Reaction outcome loss': 0.7476066072218814, 'Total loss': 0.7476066072218814}
2022-11-22 20:30:10,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:10,145 INFO:     Epoch: 92
2022-11-22 20:30:10,887 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8040662705898285, 'Total loss': 0.8040662705898285} | train loss {'Reaction outcome loss': 0.7610168508913836, 'Total loss': 0.7610168508913836}
2022-11-22 20:30:10,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:10,888 INFO:     Epoch: 93
2022-11-22 20:30:11,634 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8215679837898775, 'Total loss': 0.8215679837898775} | train loss {'Reaction outcome loss': 0.7543899014531842, 'Total loss': 0.7543899014531842}
2022-11-22 20:30:11,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:11,635 INFO:     Epoch: 94
2022-11-22 20:30:12,361 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8237997239286249, 'Total loss': 0.8237997239286249} | train loss {'Reaction outcome loss': 0.7592224224134978, 'Total loss': 0.7592224224134978}
2022-11-22 20:30:12,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:12,361 INFO:     Epoch: 95
2022-11-22 20:30:13,136 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8124753521247343, 'Total loss': 0.8124753521247343} | train loss {'Reaction outcome loss': 0.754805948087561, 'Total loss': 0.754805948087561}
2022-11-22 20:30:13,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:13,136 INFO:     Epoch: 96
2022-11-22 20:30:13,843 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8000749349594116, 'Total loss': 0.8000749349594116} | train loss {'Reaction outcome loss': 0.7555594684835146, 'Total loss': 0.7555594684835146}
2022-11-22 20:30:13,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:13,843 INFO:     Epoch: 97
2022-11-22 20:30:14,587 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.790107021277601, 'Total loss': 0.790107021277601} | train loss {'Reaction outcome loss': 0.7521593970386123, 'Total loss': 0.7521593970386123}
2022-11-22 20:30:14,587 INFO:     Found new best model at epoch 97
2022-11-22 20:30:14,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:14,588 INFO:     Epoch: 98
2022-11-22 20:30:15,362 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8038174686106768, 'Total loss': 0.8038174686106768} | train loss {'Reaction outcome loss': 0.7477168241131161, 'Total loss': 0.7477168241131161}
2022-11-22 20:30:15,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:15,363 INFO:     Epoch: 99
2022-11-22 20:30:16,114 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8304250944744457, 'Total loss': 0.8304250944744457} | train loss {'Reaction outcome loss': 0.752746795292808, 'Total loss': 0.752746795292808}
2022-11-22 20:30:16,115 INFO:     Best model found after epoch 98 of 100.
2022-11-22 20:30:16,115 INFO:   Done with stage: TRAINING
2022-11-22 20:30:16,115 INFO:   Starting stage: EVALUATION
2022-11-22 20:30:16,232 INFO:   Done with stage: EVALUATION
2022-11-22 20:30:16,232 INFO:   Leaving out SEQ value Fold_6
2022-11-22 20:30:16,245 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 20:30:16,246 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:30:16,920 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:30:16,920 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:30:16,988 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:30:16,989 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:30:16,989 INFO:     No hyperparam tuning for this model
2022-11-22 20:30:16,989 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:30:16,989 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:30:16,990 INFO:     None feature selector for col prot
2022-11-22 20:30:16,990 INFO:     None feature selector for col prot
2022-11-22 20:30:16,990 INFO:     None feature selector for col prot
2022-11-22 20:30:16,991 INFO:     None feature selector for col chem
2022-11-22 20:30:16,991 INFO:     None feature selector for col chem
2022-11-22 20:30:16,991 INFO:     None feature selector for col chem
2022-11-22 20:30:16,991 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:30:16,991 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:30:16,992 INFO:     Number of params in model 126091
2022-11-22 20:30:16,995 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:30:16,996 INFO:   Starting stage: TRAINING
2022-11-22 20:30:17,045 INFO:     Val loss before train {'Reaction outcome loss': 0.9804869768294421, 'Total loss': 0.9804869768294421}
2022-11-22 20:30:17,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:17,045 INFO:     Epoch: 0
2022-11-22 20:30:17,744 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8215856999158859, 'Total loss': 0.8215856999158859} | train loss {'Reaction outcome loss': 0.8821122416805837, 'Total loss': 0.8821122416805837}
2022-11-22 20:30:17,744 INFO:     Found new best model at epoch 0
2022-11-22 20:30:17,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:17,745 INFO:     Epoch: 1
2022-11-22 20:30:18,487 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7911862365224145, 'Total loss': 0.7911862365224145} | train loss {'Reaction outcome loss': 0.8412334854083676, 'Total loss': 0.8412334854083676}
2022-11-22 20:30:18,487 INFO:     Found new best model at epoch 1
2022-11-22 20:30:18,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:18,488 INFO:     Epoch: 2
2022-11-22 20:30:19,201 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.787115985696966, 'Total loss': 0.787115985696966} | train loss {'Reaction outcome loss': 0.8392108543024909, 'Total loss': 0.8392108543024909}
2022-11-22 20:30:19,201 INFO:     Found new best model at epoch 2
2022-11-22 20:30:19,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:19,202 INFO:     Epoch: 3
2022-11-22 20:30:19,934 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7836594866080717, 'Total loss': 0.7836594866080717} | train loss {'Reaction outcome loss': 0.8310285937641898, 'Total loss': 0.8310285937641898}
2022-11-22 20:30:19,934 INFO:     Found new best model at epoch 3
2022-11-22 20:30:19,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:19,935 INFO:     Epoch: 4
2022-11-22 20:30:20,657 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7701842513951388, 'Total loss': 0.7701842513951388} | train loss {'Reaction outcome loss': 0.8264555122342802, 'Total loss': 0.8264555122342802}
2022-11-22 20:30:20,658 INFO:     Found new best model at epoch 4
2022-11-22 20:30:20,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:20,658 INFO:     Epoch: 5
2022-11-22 20:30:21,389 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8004095147956501, 'Total loss': 0.8004095147956501} | train loss {'Reaction outcome loss': 0.8189851705345416, 'Total loss': 0.8189851705345416}
2022-11-22 20:30:21,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:21,389 INFO:     Epoch: 6
2022-11-22 20:30:22,107 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7915746468034658, 'Total loss': 0.7915746468034658} | train loss {'Reaction outcome loss': 0.8194959019460986, 'Total loss': 0.8194959019460986}
2022-11-22 20:30:22,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:22,107 INFO:     Epoch: 7
2022-11-22 20:30:22,830 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7657731575044718, 'Total loss': 0.7657731575044718} | train loss {'Reaction outcome loss': 0.8126131763621685, 'Total loss': 0.8126131763621685}
2022-11-22 20:30:22,830 INFO:     Found new best model at epoch 7
2022-11-22 20:30:22,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:22,831 INFO:     Epoch: 8
2022-11-22 20:30:23,545 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7678739706223662, 'Total loss': 0.7678739706223662} | train loss {'Reaction outcome loss': 0.8112065800495686, 'Total loss': 0.8112065800495686}
2022-11-22 20:30:23,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:23,546 INFO:     Epoch: 9
2022-11-22 20:30:24,284 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7883458855477247, 'Total loss': 0.7883458855477247} | train loss {'Reaction outcome loss': 0.8053256566486051, 'Total loss': 0.8053256566486051}
2022-11-22 20:30:24,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:24,284 INFO:     Epoch: 10
2022-11-22 20:30:25,042 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7729326953942125, 'Total loss': 0.7729326953942125} | train loss {'Reaction outcome loss': 0.8031920455396175, 'Total loss': 0.8031920455396175}
2022-11-22 20:30:25,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:25,042 INFO:     Epoch: 11
2022-11-22 20:30:25,760 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7737160243771293, 'Total loss': 0.7737160243771293} | train loss {'Reaction outcome loss': 0.8058439067775204, 'Total loss': 0.8058439067775204}
2022-11-22 20:30:25,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:25,760 INFO:     Epoch: 12
2022-11-22 20:30:26,542 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7640801295638084, 'Total loss': 0.7640801295638084} | train loss {'Reaction outcome loss': 0.8016736918399411, 'Total loss': 0.8016736918399411}
2022-11-22 20:30:26,542 INFO:     Found new best model at epoch 12
2022-11-22 20:30:26,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:26,543 INFO:     Epoch: 13
2022-11-22 20:30:27,288 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7754088003527034, 'Total loss': 0.7754088003527034} | train loss {'Reaction outcome loss': 0.8049772679805756, 'Total loss': 0.8049772679805756}
2022-11-22 20:30:27,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:27,288 INFO:     Epoch: 14
2022-11-22 20:30:28,047 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.760873404416171, 'Total loss': 0.760873404416171} | train loss {'Reaction outcome loss': 0.8024935549305331, 'Total loss': 0.8024935549305331}
2022-11-22 20:30:28,047 INFO:     Found new best model at epoch 14
2022-11-22 20:30:28,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:28,048 INFO:     Epoch: 15
2022-11-22 20:30:28,789 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.772518630054864, 'Total loss': 0.772518630054864} | train loss {'Reaction outcome loss': 0.8003794939046905, 'Total loss': 0.8003794939046905}
2022-11-22 20:30:28,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:28,789 INFO:     Epoch: 16
2022-11-22 20:30:29,507 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.756423949517987, 'Total loss': 0.756423949517987} | train loss {'Reaction outcome loss': 0.7977640682891491, 'Total loss': 0.7977640682891491}
2022-11-22 20:30:29,508 INFO:     Found new best model at epoch 16
2022-11-22 20:30:29,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:29,508 INFO:     Epoch: 17
2022-11-22 20:30:30,249 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7833514010364359, 'Total loss': 0.7833514010364359} | train loss {'Reaction outcome loss': 0.8004903726039394, 'Total loss': 0.8004903726039394}
2022-11-22 20:30:30,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:30,250 INFO:     Epoch: 18
2022-11-22 20:30:31,037 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7633023580366914, 'Total loss': 0.7633023580366914} | train loss {'Reaction outcome loss': 0.8019736925921133, 'Total loss': 0.8019736925921133}
2022-11-22 20:30:31,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:31,037 INFO:     Epoch: 19
2022-11-22 20:30:31,788 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7657552083784883, 'Total loss': 0.7657552083784883} | train loss {'Reaction outcome loss': 0.8037550963701741, 'Total loss': 0.8037550963701741}
2022-11-22 20:30:31,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:31,788 INFO:     Epoch: 20
2022-11-22 20:30:32,536 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7753860449249094, 'Total loss': 0.7753860449249094} | train loss {'Reaction outcome loss': 0.7992536333059111, 'Total loss': 0.7992536333059111}
2022-11-22 20:30:32,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:32,537 INFO:     Epoch: 21
2022-11-22 20:30:33,296 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7668640498410572, 'Total loss': 0.7668640498410572} | train loss {'Reaction outcome loss': 0.7990942593784102, 'Total loss': 0.7990942593784102}
2022-11-22 20:30:33,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:33,296 INFO:     Epoch: 22
2022-11-22 20:30:34,055 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7939472090114247, 'Total loss': 0.7939472090114247} | train loss {'Reaction outcome loss': 0.7968675227415177, 'Total loss': 0.7968675227415177}
2022-11-22 20:30:34,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:34,055 INFO:     Epoch: 23
2022-11-22 20:30:34,821 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7715676616538655, 'Total loss': 0.7715676616538655} | train loss {'Reaction outcome loss': 0.7981494429611391, 'Total loss': 0.7981494429611391}
2022-11-22 20:30:34,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:34,821 INFO:     Epoch: 24
2022-11-22 20:30:35,568 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7559265413067557, 'Total loss': 0.7559265413067557} | train loss {'Reaction outcome loss': 0.7964423766299602, 'Total loss': 0.7964423766299602}
2022-11-22 20:30:35,568 INFO:     Found new best model at epoch 24
2022-11-22 20:30:35,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:35,570 INFO:     Epoch: 25
2022-11-22 20:30:36,329 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7700598416003314, 'Total loss': 0.7700598416003314} | train loss {'Reaction outcome loss': 0.7962936828694036, 'Total loss': 0.7962936828694036}
2022-11-22 20:30:36,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:36,329 INFO:     Epoch: 26
2022-11-22 20:30:37,088 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7671068073673681, 'Total loss': 0.7671068073673681} | train loss {'Reaction outcome loss': 0.7978352174883888, 'Total loss': 0.7978352174883888}
2022-11-22 20:30:37,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:37,088 INFO:     Epoch: 27
2022-11-22 20:30:37,883 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7602839869531718, 'Total loss': 0.7602839869531718} | train loss {'Reaction outcome loss': 0.7989110870346907, 'Total loss': 0.7989110870346907}
2022-11-22 20:30:37,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:37,884 INFO:     Epoch: 28
2022-11-22 20:30:38,644 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7914933304895054, 'Total loss': 0.7914933304895054} | train loss {'Reaction outcome loss': 0.7976550344497927, 'Total loss': 0.7976550344497927}
2022-11-22 20:30:38,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:38,644 INFO:     Epoch: 29
2022-11-22 20:30:39,393 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7603987834670327, 'Total loss': 0.7603987834670327} | train loss {'Reaction outcome loss': 0.7969172253243385, 'Total loss': 0.7969172253243385}
2022-11-22 20:30:39,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:39,393 INFO:     Epoch: 30
2022-11-22 20:30:40,111 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7668916400183331, 'Total loss': 0.7668916400183331} | train loss {'Reaction outcome loss': 0.7974625091639257, 'Total loss': 0.7974625091639257}
2022-11-22 20:30:40,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:40,112 INFO:     Epoch: 31
2022-11-22 20:30:40,873 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7732242311943661, 'Total loss': 0.7732242311943661} | train loss {'Reaction outcome loss': 0.7983577788597153, 'Total loss': 0.7983577788597153}
2022-11-22 20:30:40,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:40,873 INFO:     Epoch: 32
2022-11-22 20:30:41,624 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7655901319601319, 'Total loss': 0.7655901319601319} | train loss {'Reaction outcome loss': 0.7956483406164954, 'Total loss': 0.7956483406164954}
2022-11-22 20:30:41,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:41,624 INFO:     Epoch: 33
2022-11-22 20:30:42,393 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7665347064083273, 'Total loss': 0.7665347064083273} | train loss {'Reaction outcome loss': 0.7945391563398223, 'Total loss': 0.7945391563398223}
2022-11-22 20:30:42,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:42,394 INFO:     Epoch: 34
2022-11-22 20:30:43,143 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7644469507715919, 'Total loss': 0.7644469507715919} | train loss {'Reaction outcome loss': 0.7960373891457435, 'Total loss': 0.7960373891457435}
2022-11-22 20:30:43,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:43,143 INFO:     Epoch: 35
2022-11-22 20:30:43,925 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7755408442833207, 'Total loss': 0.7755408442833207} | train loss {'Reaction outcome loss': 0.7966491729021072, 'Total loss': 0.7966491729021072}
2022-11-22 20:30:43,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:43,925 INFO:     Epoch: 36
2022-11-22 20:30:44,683 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7579887400973927, 'Total loss': 0.7579887400973927} | train loss {'Reaction outcome loss': 0.7915497630113556, 'Total loss': 0.7915497630113556}
2022-11-22 20:30:44,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:44,683 INFO:     Epoch: 37
2022-11-22 20:30:45,431 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7748690789396112, 'Total loss': 0.7748690789396112} | train loss {'Reaction outcome loss': 0.7910852042898056, 'Total loss': 0.7910852042898056}
2022-11-22 20:30:45,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:45,431 INFO:     Epoch: 38
2022-11-22 20:30:46,162 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7696854973381216, 'Total loss': 0.7696854973381216} | train loss {'Reaction outcome loss': 0.7915640208990343, 'Total loss': 0.7915640208990343}
2022-11-22 20:30:46,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:46,162 INFO:     Epoch: 39
2022-11-22 20:30:46,914 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7644265808842399, 'Total loss': 0.7644265808842399} | train loss {'Reaction outcome loss': 0.7950374172820199, 'Total loss': 0.7950374172820199}
2022-11-22 20:30:46,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:46,914 INFO:     Epoch: 40
2022-11-22 20:30:47,676 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7624510804360564, 'Total loss': 0.7624510804360564} | train loss {'Reaction outcome loss': 0.7941229764011598, 'Total loss': 0.7941229764011598}
2022-11-22 20:30:47,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:47,676 INFO:     Epoch: 41
2022-11-22 20:30:48,461 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7574349404735998, 'Total loss': 0.7574349404735998} | train loss {'Reaction outcome loss': 0.7955132838218443, 'Total loss': 0.7955132838218443}
2022-11-22 20:30:48,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:48,462 INFO:     Epoch: 42
2022-11-22 20:30:49,206 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7624636102806438, 'Total loss': 0.7624636102806438} | train loss {'Reaction outcome loss': 0.7920104370963189, 'Total loss': 0.7920104370963189}
2022-11-22 20:30:49,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:49,206 INFO:     Epoch: 43
2022-11-22 20:30:49,975 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7762272412126715, 'Total loss': 0.7762272412126715} | train loss {'Reaction outcome loss': 0.7834430499182593, 'Total loss': 0.7834430499182593}
2022-11-22 20:30:49,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:49,976 INFO:     Epoch: 44
2022-11-22 20:30:50,731 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7984208959070119, 'Total loss': 0.7984208959070119} | train loss {'Reaction outcome loss': 0.7958823401601084, 'Total loss': 0.7958823401601084}
2022-11-22 20:30:50,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:50,731 INFO:     Epoch: 45
2022-11-22 20:30:51,448 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7798419086770578, 'Total loss': 0.7798419086770578} | train loss {'Reaction outcome loss': 0.7911137681935103, 'Total loss': 0.7911137681935103}
2022-11-22 20:30:51,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:51,448 INFO:     Epoch: 46
2022-11-22 20:30:52,172 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7588733001188799, 'Total loss': 0.7588733001188799} | train loss {'Reaction outcome loss': 0.7886369765525864, 'Total loss': 0.7886369765525864}
2022-11-22 20:30:52,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:52,172 INFO:     Epoch: 47
2022-11-22 20:30:52,917 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7585966167124835, 'Total loss': 0.7585966167124835} | train loss {'Reaction outcome loss': 0.7924237169565693, 'Total loss': 0.7924237169565693}
2022-11-22 20:30:52,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:52,917 INFO:     Epoch: 48
2022-11-22 20:30:53,644 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7484932447021658, 'Total loss': 0.7484932447021658} | train loss {'Reaction outcome loss': 0.7963286302983761, 'Total loss': 0.7963286302983761}
2022-11-22 20:30:53,646 INFO:     Found new best model at epoch 48
2022-11-22 20:30:53,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:53,647 INFO:     Epoch: 49
2022-11-22 20:30:54,374 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7571766437454657, 'Total loss': 0.7571766437454657} | train loss {'Reaction outcome loss': 0.7942559841659761, 'Total loss': 0.7942559841659761}
2022-11-22 20:30:54,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:54,375 INFO:     Epoch: 50
2022-11-22 20:30:55,135 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7684597792950544, 'Total loss': 0.7684597792950544} | train loss {'Reaction outcome loss': 0.7888312256864963, 'Total loss': 0.7888312256864963}
2022-11-22 20:30:55,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:55,135 INFO:     Epoch: 51
2022-11-22 20:30:55,865 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7663409127430483, 'Total loss': 0.7663409127430483} | train loss {'Reaction outcome loss': 0.7908811137801216, 'Total loss': 0.7908811137801216}
2022-11-22 20:30:55,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:55,865 INFO:     Epoch: 52
2022-11-22 20:30:56,641 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.758348292925141, 'Total loss': 0.758348292925141} | train loss {'Reaction outcome loss': 0.7910078052551516, 'Total loss': 0.7910078052551516}
2022-11-22 20:30:56,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:56,641 INFO:     Epoch: 53
2022-11-22 20:30:57,393 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7566132606430487, 'Total loss': 0.7566132606430487} | train loss {'Reaction outcome loss': 0.7908723700431085, 'Total loss': 0.7908723700431085}
2022-11-22 20:30:57,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:57,393 INFO:     Epoch: 54
2022-11-22 20:30:58,188 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7471328662200407, 'Total loss': 0.7471328662200407} | train loss {'Reaction outcome loss': 0.790819198133484, 'Total loss': 0.790819198133484}
2022-11-22 20:30:58,189 INFO:     Found new best model at epoch 54
2022-11-22 20:30:58,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:58,189 INFO:     Epoch: 55
2022-11-22 20:30:58,964 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7712604091926054, 'Total loss': 0.7712604091926054} | train loss {'Reaction outcome loss': 0.7914257772987888, 'Total loss': 0.7914257772987888}
2022-11-22 20:30:58,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:58,964 INFO:     Epoch: 56
2022-11-22 20:30:59,786 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7572434077208693, 'Total loss': 0.7572434077208693} | train loss {'Reaction outcome loss': 0.7865333557128906, 'Total loss': 0.7865333557128906}
2022-11-22 20:30:59,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:30:59,787 INFO:     Epoch: 57
2022-11-22 20:31:00,663 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.761909038505771, 'Total loss': 0.761909038505771} | train loss {'Reaction outcome loss': 0.7909742579344781, 'Total loss': 0.7909742579344781}
2022-11-22 20:31:00,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:00,663 INFO:     Epoch: 58
2022-11-22 20:31:01,495 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7606646445664492, 'Total loss': 0.7606646445664492} | train loss {'Reaction outcome loss': 0.7891496751577624, 'Total loss': 0.7891496751577624}
2022-11-22 20:31:01,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:01,495 INFO:     Epoch: 59
2022-11-22 20:31:02,362 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7634786800904707, 'Total loss': 0.7634786800904707} | train loss {'Reaction outcome loss': 0.791111571534026, 'Total loss': 0.791111571534026}
2022-11-22 20:31:02,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:02,362 INFO:     Epoch: 60
2022-11-22 20:31:03,213 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7618694894693114, 'Total loss': 0.7618694894693114} | train loss {'Reaction outcome loss': 0.7919337709824885, 'Total loss': 0.7919337709824885}
2022-11-22 20:31:03,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:03,214 INFO:     Epoch: 61
2022-11-22 20:31:04,012 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7872356887568127, 'Total loss': 0.7872356887568127} | train loss {'Reaction outcome loss': 0.7898624985208434, 'Total loss': 0.7898624985208434}
2022-11-22 20:31:04,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:04,013 INFO:     Epoch: 62
2022-11-22 20:31:04,778 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7944467121904547, 'Total loss': 0.7944467121904547} | train loss {'Reaction outcome loss': 0.7939767300361588, 'Total loss': 0.7939767300361588}
2022-11-22 20:31:04,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:04,778 INFO:     Epoch: 63
2022-11-22 20:31:05,529 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7684258276765997, 'Total loss': 0.7684258276765997} | train loss {'Reaction outcome loss': 0.7908799663907097, 'Total loss': 0.7908799663907097}
2022-11-22 20:31:05,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:05,529 INFO:     Epoch: 64
2022-11-22 20:31:06,278 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7512356259606101, 'Total loss': 0.7512356259606101} | train loss {'Reaction outcome loss': 0.7907485714362513, 'Total loss': 0.7907485714362513}
2022-11-22 20:31:06,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:06,278 INFO:     Epoch: 65
2022-11-22 20:31:07,014 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7749229805036024, 'Total loss': 0.7749229805036024} | train loss {'Reaction outcome loss': 0.787828817002235, 'Total loss': 0.787828817002235}
2022-11-22 20:31:07,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:07,014 INFO:     Epoch: 66
2022-11-22 20:31:07,776 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.76713469827717, 'Total loss': 0.76713469827717} | train loss {'Reaction outcome loss': 0.7893897481863538, 'Total loss': 0.7893897481863538}
2022-11-22 20:31:07,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:07,776 INFO:     Epoch: 67
2022-11-22 20:31:08,562 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.756126044826074, 'Total loss': 0.756126044826074} | train loss {'Reaction outcome loss': 0.790238298956425, 'Total loss': 0.790238298956425}
2022-11-22 20:31:08,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:08,562 INFO:     Epoch: 68
2022-11-22 20:31:09,290 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7779564491727136, 'Total loss': 0.7779564491727136} | train loss {'Reaction outcome loss': 0.7892439673624693, 'Total loss': 0.7892439673624693}
2022-11-22 20:31:09,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:09,290 INFO:     Epoch: 69
2022-11-22 20:31:10,038 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7657442912459373, 'Total loss': 0.7657442912459373} | train loss {'Reaction outcome loss': 0.790906741734474, 'Total loss': 0.790906741734474}
2022-11-22 20:31:10,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:10,038 INFO:     Epoch: 70
2022-11-22 20:31:10,770 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7507450343532995, 'Total loss': 0.7507450343532995} | train loss {'Reaction outcome loss': 0.7915814902272916, 'Total loss': 0.7915814902272916}
2022-11-22 20:31:10,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:10,770 INFO:     Epoch: 71
2022-11-22 20:31:11,521 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7776889990676533, 'Total loss': 0.7776889990676533} | train loss {'Reaction outcome loss': 0.7907482619968152, 'Total loss': 0.7907482619968152}
2022-11-22 20:31:11,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:11,521 INFO:     Epoch: 72
2022-11-22 20:31:12,254 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7522836889732968, 'Total loss': 0.7522836889732968} | train loss {'Reaction outcome loss': 0.7923038374752768, 'Total loss': 0.7923038374752768}
2022-11-22 20:31:12,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:12,255 INFO:     Epoch: 73
2022-11-22 20:31:13,015 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7613226839087226, 'Total loss': 0.7613226839087226} | train loss {'Reaction outcome loss': 0.7894682356667134, 'Total loss': 0.7894682356667134}
2022-11-22 20:31:13,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:13,016 INFO:     Epoch: 74
2022-11-22 20:31:13,772 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7607657665556128, 'Total loss': 0.7607657665556128} | train loss {'Reaction outcome loss': 0.7898456615305716, 'Total loss': 0.7898456615305716}
2022-11-22 20:31:13,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:13,772 INFO:     Epoch: 75
2022-11-22 20:31:14,527 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7504471662369642, 'Total loss': 0.7504471662369642} | train loss {'Reaction outcome loss': 0.7897965640069977, 'Total loss': 0.7897965640069977}
2022-11-22 20:31:14,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:14,528 INFO:     Epoch: 76
2022-11-22 20:31:15,284 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7405276217243888, 'Total loss': 0.7405276217243888} | train loss {'Reaction outcome loss': 0.7829589174399453, 'Total loss': 0.7829589174399453}
2022-11-22 20:31:15,284 INFO:     Found new best model at epoch 76
2022-11-22 20:31:15,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:15,285 INFO:     Epoch: 77
2022-11-22 20:31:16,025 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7640245611017401, 'Total loss': 0.7640245611017401} | train loss {'Reaction outcome loss': 0.7849397363681947, 'Total loss': 0.7849397363681947}
2022-11-22 20:31:16,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:16,025 INFO:     Epoch: 78
2022-11-22 20:31:16,802 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7621818868951364, 'Total loss': 0.7621818868951364} | train loss {'Reaction outcome loss': 0.7889337281305944, 'Total loss': 0.7889337281305944}
2022-11-22 20:31:16,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:16,802 INFO:     Epoch: 79
2022-11-22 20:31:17,531 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7629366550933231, 'Total loss': 0.7629366550933231} | train loss {'Reaction outcome loss': 0.7853709480935528, 'Total loss': 0.7853709480935528}
2022-11-22 20:31:17,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:17,532 INFO:     Epoch: 80
2022-11-22 20:31:18,263 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7479702857407656, 'Total loss': 0.7479702857407656} | train loss {'Reaction outcome loss': 0.7849798844225945, 'Total loss': 0.7849798844225945}
2022-11-22 20:31:18,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:18,264 INFO:     Epoch: 81
2022-11-22 20:31:18,979 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7618644041093913, 'Total loss': 0.7618644041093913} | train loss {'Reaction outcome loss': 0.790200482933752, 'Total loss': 0.790200482933752}
2022-11-22 20:31:18,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:18,979 INFO:     Epoch: 82
2022-11-22 20:31:19,735 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7598872618241743, 'Total loss': 0.7598872618241743} | train loss {'Reaction outcome loss': 0.7842252237662193, 'Total loss': 0.7842252237662193}
2022-11-22 20:31:19,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:19,735 INFO:     Epoch: 83
2022-11-22 20:31:20,516 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7433207096023993, 'Total loss': 0.7433207096023993} | train loss {'Reaction outcome loss': 0.7926006070788829, 'Total loss': 0.7926006070788829}
2022-11-22 20:31:20,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:20,517 INFO:     Epoch: 84
2022-11-22 20:31:21,279 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7441852688789368, 'Total loss': 0.7441852688789368} | train loss {'Reaction outcome loss': 0.7889992950424072, 'Total loss': 0.7889992950424072}
2022-11-22 20:31:21,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:21,279 INFO:     Epoch: 85
2022-11-22 20:31:22,010 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7468345612287521, 'Total loss': 0.7468345612287521} | train loss {'Reaction outcome loss': 0.78865948115145, 'Total loss': 0.78865948115145}
2022-11-22 20:31:22,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:22,010 INFO:     Epoch: 86
2022-11-22 20:31:22,751 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7630704993551428, 'Total loss': 0.7630704993551428} | train loss {'Reaction outcome loss': 0.7856779017996404, 'Total loss': 0.7856779017996404}
2022-11-22 20:31:22,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:22,751 INFO:     Epoch: 87
2022-11-22 20:31:23,498 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7497081817551092, 'Total loss': 0.7497081817551092} | train loss {'Reaction outcome loss': 0.7875890273961329, 'Total loss': 0.7875890273961329}
2022-11-22 20:31:23,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:23,499 INFO:     Epoch: 88
2022-11-22 20:31:24,220 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7489206479354338, 'Total loss': 0.7489206479354338} | train loss {'Reaction outcome loss': 0.7852679756620238, 'Total loss': 0.7852679756620238}
2022-11-22 20:31:24,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:24,220 INFO:     Epoch: 89
2022-11-22 20:31:24,969 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7674716365608302, 'Total loss': 0.7674716365608302} | train loss {'Reaction outcome loss': 0.7856815378031423, 'Total loss': 0.7856815378031423}
2022-11-22 20:31:24,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:24,970 INFO:     Epoch: 90
2022-11-22 20:31:25,711 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7425787083127282, 'Total loss': 0.7425787083127282} | train loss {'Reaction outcome loss': 0.788220432136328, 'Total loss': 0.788220432136328}
2022-11-22 20:31:25,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:25,711 INFO:     Epoch: 91
2022-11-22 20:31:26,421 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7528767070987008, 'Total loss': 0.7528767070987008} | train loss {'Reaction outcome loss': 0.7833345630957235, 'Total loss': 0.7833345630957235}
2022-11-22 20:31:26,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:26,421 INFO:     Epoch: 92
2022-11-22 20:31:27,153 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7619924545288086, 'Total loss': 0.7619924545288086} | train loss {'Reaction outcome loss': 0.7919755049290196, 'Total loss': 0.7919755049290196}
2022-11-22 20:31:27,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:27,154 INFO:     Epoch: 93
2022-11-22 20:31:27,903 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7498666169968519, 'Total loss': 0.7498666169968519} | train loss {'Reaction outcome loss': 0.7846573522134174, 'Total loss': 0.7846573522134174}
2022-11-22 20:31:27,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:27,904 INFO:     Epoch: 94
2022-11-22 20:31:28,586 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7388009124181487, 'Total loss': 0.7388009124181487} | train loss {'Reaction outcome loss': 0.7814932348987749, 'Total loss': 0.7814932348987749}
2022-11-22 20:31:28,587 INFO:     Found new best model at epoch 94
2022-11-22 20:31:28,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:28,587 INFO:     Epoch: 95
2022-11-22 20:31:29,346 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7859261279756372, 'Total loss': 0.7859261279756372} | train loss {'Reaction outcome loss': 0.7775335483733685, 'Total loss': 0.7775335483733685}
2022-11-22 20:31:29,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:29,346 INFO:     Epoch: 96
2022-11-22 20:31:30,084 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7451217817989263, 'Total loss': 0.7451217817989263} | train loss {'Reaction outcome loss': 0.7849089094708043, 'Total loss': 0.7849089094708043}
2022-11-22 20:31:30,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:30,084 INFO:     Epoch: 97
2022-11-22 20:31:30,842 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7469105764546178, 'Total loss': 0.7469105764546178} | train loss {'Reaction outcome loss': 0.7827078816631148, 'Total loss': 0.7827078816631148}
2022-11-22 20:31:30,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:30,842 INFO:     Epoch: 98
2022-11-22 20:31:31,613 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7882644256407564, 'Total loss': 0.7882644256407564} | train loss {'Reaction outcome loss': 0.7804648967519883, 'Total loss': 0.7804648967519883}
2022-11-22 20:31:31,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:31,614 INFO:     Epoch: 99
2022-11-22 20:31:32,336 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7407256371595643, 'Total loss': 0.7407256371595643} | train loss {'Reaction outcome loss': 0.7886086874190839, 'Total loss': 0.7886086874190839}
2022-11-22 20:31:32,336 INFO:     Best model found after epoch 95 of 100.
2022-11-22 20:31:32,336 INFO:   Done with stage: TRAINING
2022-11-22 20:31:32,336 INFO:   Starting stage: EVALUATION
2022-11-22 20:31:32,449 INFO:   Done with stage: EVALUATION
2022-11-22 20:31:32,450 INFO:   Leaving out SEQ value Fold_7
2022-11-22 20:31:32,463 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 20:31:32,463 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:31:33,135 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:31:33,135 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:31:33,206 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:31:33,206 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:31:33,206 INFO:     No hyperparam tuning for this model
2022-11-22 20:31:33,206 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:31:33,206 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:31:33,207 INFO:     None feature selector for col prot
2022-11-22 20:31:33,207 INFO:     None feature selector for col prot
2022-11-22 20:31:33,207 INFO:     None feature selector for col prot
2022-11-22 20:31:33,208 INFO:     None feature selector for col chem
2022-11-22 20:31:33,208 INFO:     None feature selector for col chem
2022-11-22 20:31:33,208 INFO:     None feature selector for col chem
2022-11-22 20:31:33,208 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:31:33,208 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:31:33,210 INFO:     Number of params in model 126091
2022-11-22 20:31:33,213 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:31:33,213 INFO:   Starting stage: TRAINING
2022-11-22 20:31:33,262 INFO:     Val loss before train {'Reaction outcome loss': 0.9844681173563004, 'Total loss': 0.9844681173563004}
2022-11-22 20:31:33,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:33,263 INFO:     Epoch: 0
2022-11-22 20:31:34,036 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8470878953283484, 'Total loss': 0.8470878953283484} | train loss {'Reaction outcome loss': 0.8696916700611191, 'Total loss': 0.8696916700611191}
2022-11-22 20:31:34,036 INFO:     Found new best model at epoch 0
2022-11-22 20:31:34,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:34,037 INFO:     Epoch: 1
2022-11-22 20:31:34,799 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8431609943509102, 'Total loss': 0.8431609943509102} | train loss {'Reaction outcome loss': 0.8391291483515694, 'Total loss': 0.8391291483515694}
2022-11-22 20:31:34,799 INFO:     Found new best model at epoch 1
2022-11-22 20:31:34,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:34,800 INFO:     Epoch: 2
2022-11-22 20:31:35,548 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.818565768274394, 'Total loss': 0.818565768274394} | train loss {'Reaction outcome loss': 0.8281754922241934, 'Total loss': 0.8281754922241934}
2022-11-22 20:31:35,548 INFO:     Found new best model at epoch 2
2022-11-22 20:31:35,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:35,549 INFO:     Epoch: 3
2022-11-22 20:31:36,282 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8227637599815022, 'Total loss': 0.8227637599815022} | train loss {'Reaction outcome loss': 0.8239427399971793, 'Total loss': 0.8239427399971793}
2022-11-22 20:31:36,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:36,282 INFO:     Epoch: 4
2022-11-22 20:31:37,054 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8022036362778057, 'Total loss': 0.8022036362778057} | train loss {'Reaction outcome loss': 0.8175664577753313, 'Total loss': 0.8175664577753313}
2022-11-22 20:31:37,054 INFO:     Found new best model at epoch 4
2022-11-22 20:31:37,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:37,055 INFO:     Epoch: 5
2022-11-22 20:31:37,837 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.79646185785532, 'Total loss': 0.79646185785532} | train loss {'Reaction outcome loss': 0.8084802364389743, 'Total loss': 0.8084802364389743}
2022-11-22 20:31:37,837 INFO:     Found new best model at epoch 5
2022-11-22 20:31:37,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:37,838 INFO:     Epoch: 6
2022-11-22 20:31:38,608 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8037201139059934, 'Total loss': 0.8037201139059934} | train loss {'Reaction outcome loss': 0.8072430367671675, 'Total loss': 0.8072430367671675}
2022-11-22 20:31:38,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:38,608 INFO:     Epoch: 7
2022-11-22 20:31:39,337 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8223660378293558, 'Total loss': 0.8223660378293558} | train loss {'Reaction outcome loss': 0.8046894247733778, 'Total loss': 0.8046894247733778}
2022-11-22 20:31:39,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:39,338 INFO:     Epoch: 8
2022-11-22 20:31:40,052 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.799943280490962, 'Total loss': 0.799943280490962} | train loss {'Reaction outcome loss': 0.800147172784613, 'Total loss': 0.800147172784613}
2022-11-22 20:31:40,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:40,053 INFO:     Epoch: 9
2022-11-22 20:31:40,760 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7867420986294746, 'Total loss': 0.7867420986294746} | train loss {'Reaction outcome loss': 0.8050106324015125, 'Total loss': 0.8050106324015125}
2022-11-22 20:31:40,760 INFO:     Found new best model at epoch 9
2022-11-22 20:31:40,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:40,761 INFO:     Epoch: 10
2022-11-22 20:31:41,503 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7857530977238308, 'Total loss': 0.7857530977238308} | train loss {'Reaction outcome loss': 0.7959027760211499, 'Total loss': 0.7959027760211499}
2022-11-22 20:31:41,503 INFO:     Found new best model at epoch 10
2022-11-22 20:31:41,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:41,504 INFO:     Epoch: 11
2022-11-22 20:31:42,214 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7900905060497198, 'Total loss': 0.7900905060497198} | train loss {'Reaction outcome loss': 0.7881451422168363, 'Total loss': 0.7881451422168363}
2022-11-22 20:31:42,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:42,214 INFO:     Epoch: 12
2022-11-22 20:31:42,979 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7884132252498106, 'Total loss': 0.7884132252498106} | train loss {'Reaction outcome loss': 0.7929559863142429, 'Total loss': 0.7929559863142429}
2022-11-22 20:31:42,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:42,979 INFO:     Epoch: 13
2022-11-22 20:31:43,693 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7911612052809108, 'Total loss': 0.7911612052809108} | train loss {'Reaction outcome loss': 0.789438267869334, 'Total loss': 0.789438267869334}
2022-11-22 20:31:43,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:43,694 INFO:     Epoch: 14
2022-11-22 20:31:44,440 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7768057469617237, 'Total loss': 0.7768057469617237} | train loss {'Reaction outcome loss': 0.7877287939190865, 'Total loss': 0.7877287939190865}
2022-11-22 20:31:44,440 INFO:     Found new best model at epoch 14
2022-11-22 20:31:44,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:44,441 INFO:     Epoch: 15
2022-11-22 20:31:45,188 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7756015468727459, 'Total loss': 0.7756015468727459} | train loss {'Reaction outcome loss': 0.783872376766897, 'Total loss': 0.783872376766897}
2022-11-22 20:31:45,188 INFO:     Found new best model at epoch 15
2022-11-22 20:31:45,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:45,189 INFO:     Epoch: 16
2022-11-22 20:31:45,978 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7692876464941285, 'Total loss': 0.7692876464941285} | train loss {'Reaction outcome loss': 0.7888840963282893, 'Total loss': 0.7888840963282893}
2022-11-22 20:31:45,978 INFO:     Found new best model at epoch 16
2022-11-22 20:31:45,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:45,979 INFO:     Epoch: 17
2022-11-22 20:31:46,763 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7795530889521946, 'Total loss': 0.7795530889521946} | train loss {'Reaction outcome loss': 0.7857098120354837, 'Total loss': 0.7857098120354837}
2022-11-22 20:31:46,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:46,763 INFO:     Epoch: 18
2022-11-22 20:31:47,490 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7881524915044958, 'Total loss': 0.7881524915044958} | train loss {'Reaction outcome loss': 0.7859479682820458, 'Total loss': 0.7859479682820458}
2022-11-22 20:31:47,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:47,491 INFO:     Epoch: 19
2022-11-22 20:31:48,256 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7783089950680733, 'Total loss': 0.7783089950680733} | train loss {'Reaction outcome loss': 0.7813416189484058, 'Total loss': 0.7813416189484058}
2022-11-22 20:31:48,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:48,256 INFO:     Epoch: 20
2022-11-22 20:31:49,016 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7794244716113264, 'Total loss': 0.7794244716113264} | train loss {'Reaction outcome loss': 0.7849976187271457, 'Total loss': 0.7849976187271457}
2022-11-22 20:31:49,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:49,017 INFO:     Epoch: 21
2022-11-22 20:31:49,776 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7899844070727174, 'Total loss': 0.7899844070727174} | train loss {'Reaction outcome loss': 0.7852823536001867, 'Total loss': 0.7852823536001867}
2022-11-22 20:31:49,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:49,776 INFO:     Epoch: 22
2022-11-22 20:31:50,570 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7707354656674645, 'Total loss': 0.7707354656674645} | train loss {'Reaction outcome loss': 0.7844589761187953, 'Total loss': 0.7844589761187953}
2022-11-22 20:31:50,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:50,570 INFO:     Epoch: 23
2022-11-22 20:31:51,366 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.773136399009011, 'Total loss': 0.773136399009011} | train loss {'Reaction outcome loss': 0.7804165138832985, 'Total loss': 0.7804165138832985}
2022-11-22 20:31:51,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:51,366 INFO:     Epoch: 24
2022-11-22 20:31:52,124 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7887904833663594, 'Total loss': 0.7887904833663594} | train loss {'Reaction outcome loss': 0.7785921083582986, 'Total loss': 0.7785921083582986}
2022-11-22 20:31:52,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:52,124 INFO:     Epoch: 25
2022-11-22 20:31:52,870 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7640816833485257, 'Total loss': 0.7640816833485257} | train loss {'Reaction outcome loss': 0.7867208173077914, 'Total loss': 0.7867208173077914}
2022-11-22 20:31:52,870 INFO:     Found new best model at epoch 25
2022-11-22 20:31:52,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:52,871 INFO:     Epoch: 26
2022-11-22 20:31:53,623 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7988815334710208, 'Total loss': 0.7988815334710208} | train loss {'Reaction outcome loss': 0.7795947919930181, 'Total loss': 0.7795947919930181}
2022-11-22 20:31:53,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:53,623 INFO:     Epoch: 27
2022-11-22 20:31:54,354 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8228561383756724, 'Total loss': 0.8228561383756724} | train loss {'Reaction outcome loss': 0.7824119008596866, 'Total loss': 0.7824119008596866}
2022-11-22 20:31:54,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:54,354 INFO:     Epoch: 28
2022-11-22 20:31:55,088 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7664206515658986, 'Total loss': 0.7664206515658986} | train loss {'Reaction outcome loss': 0.7855760607748262, 'Total loss': 0.7855760607748262}
2022-11-22 20:31:55,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:55,088 INFO:     Epoch: 29
2022-11-22 20:31:55,831 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7876714379950003, 'Total loss': 0.7876714379950003} | train loss {'Reaction outcome loss': 0.7822302501768835, 'Total loss': 0.7822302501768835}
2022-11-22 20:31:55,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:55,832 INFO:     Epoch: 30
2022-11-22 20:31:56,598 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7732429497621276, 'Total loss': 0.7732429497621276} | train loss {'Reaction outcome loss': 0.791008397576309, 'Total loss': 0.791008397576309}
2022-11-22 20:31:56,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:56,598 INFO:     Epoch: 31
2022-11-22 20:31:57,360 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.762778175148097, 'Total loss': 0.762778175148097} | train loss {'Reaction outcome loss': 0.7790558886143469, 'Total loss': 0.7790558886143469}
2022-11-22 20:31:57,360 INFO:     Found new best model at epoch 31
2022-11-22 20:31:57,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:57,361 INFO:     Epoch: 32
2022-11-22 20:31:58,143 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7938972041010857, 'Total loss': 0.7938972041010857} | train loss {'Reaction outcome loss': 0.7796380853941364, 'Total loss': 0.7796380853941364}
2022-11-22 20:31:58,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:58,143 INFO:     Epoch: 33
2022-11-22 20:31:58,973 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7630704431371256, 'Total loss': 0.7630704431371256} | train loss {'Reaction outcome loss': 0.7805648601103213, 'Total loss': 0.7805648601103213}
2022-11-22 20:31:58,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:58,975 INFO:     Epoch: 34
2022-11-22 20:31:59,778 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.779477712105621, 'Total loss': 0.779477712105621} | train loss {'Reaction outcome loss': 0.7768633291125298, 'Total loss': 0.7768633291125298}
2022-11-22 20:31:59,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:31:59,779 INFO:     Epoch: 35
2022-11-22 20:32:00,578 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7626943479884755, 'Total loss': 0.7626943479884755} | train loss {'Reaction outcome loss': 0.7832673379490452, 'Total loss': 0.7832673379490452}
2022-11-22 20:32:00,578 INFO:     Found new best model at epoch 35
2022-11-22 20:32:00,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:00,579 INFO:     Epoch: 36
2022-11-22 20:32:01,393 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7609422965483232, 'Total loss': 0.7609422965483232} | train loss {'Reaction outcome loss': 0.7726334563546604, 'Total loss': 0.7726334563546604}
2022-11-22 20:32:01,393 INFO:     Found new best model at epoch 36
2022-11-22 20:32:01,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:01,394 INFO:     Epoch: 37
2022-11-22 20:32:02,199 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7777870134873823, 'Total loss': 0.7777870134873823} | train loss {'Reaction outcome loss': 0.7725018268871692, 'Total loss': 0.7725018268871692}
2022-11-22 20:32:02,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:02,199 INFO:     Epoch: 38
2022-11-22 20:32:03,011 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7890478169376199, 'Total loss': 0.7890478169376199} | train loss {'Reaction outcome loss': 0.7777480267949642, 'Total loss': 0.7777480267949642}
2022-11-22 20:32:03,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:03,011 INFO:     Epoch: 39
2022-11-22 20:32:03,859 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7711365080692552, 'Total loss': 0.7711365080692552} | train loss {'Reaction outcome loss': 0.7765166163444519, 'Total loss': 0.7765166163444519}
2022-11-22 20:32:03,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:03,859 INFO:     Epoch: 40
2022-11-22 20:32:04,673 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.762521472166885, 'Total loss': 0.762521472166885} | train loss {'Reaction outcome loss': 0.779240091962199, 'Total loss': 0.779240091962199}
2022-11-22 20:32:04,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:04,673 INFO:     Epoch: 41
2022-11-22 20:32:05,535 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7622148536823012, 'Total loss': 0.7622148536823012} | train loss {'Reaction outcome loss': 0.7728959573132377, 'Total loss': 0.7728959573132377}
2022-11-22 20:32:05,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:05,536 INFO:     Epoch: 42
2022-11-22 20:32:06,359 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7772762782194398, 'Total loss': 0.7772762782194398} | train loss {'Reaction outcome loss': 0.7760257647643166, 'Total loss': 0.7760257647643166}
2022-11-22 20:32:06,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:06,359 INFO:     Epoch: 43
2022-11-22 20:32:07,170 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7909417274323377, 'Total loss': 0.7909417274323377} | train loss {'Reaction outcome loss': 0.7782716316080862, 'Total loss': 0.7782716316080862}
2022-11-22 20:32:07,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:07,171 INFO:     Epoch: 44
2022-11-22 20:32:08,063 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7977307073094628, 'Total loss': 0.7977307073094628} | train loss {'Reaction outcome loss': 0.7689339959573361, 'Total loss': 0.7689339959573361}
2022-11-22 20:32:08,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:08,064 INFO:     Epoch: 45
2022-11-22 20:32:08,912 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7690936848521233, 'Total loss': 0.7690936848521233} | train loss {'Reaction outcome loss': 0.7747096350837138, 'Total loss': 0.7747096350837138}
2022-11-22 20:32:08,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:08,912 INFO:     Epoch: 46
2022-11-22 20:32:09,743 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7534379843961109, 'Total loss': 0.7534379843961109} | train loss {'Reaction outcome loss': 0.770933005117601, 'Total loss': 0.770933005117601}
2022-11-22 20:32:09,743 INFO:     Found new best model at epoch 46
2022-11-22 20:32:09,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:09,744 INFO:     Epoch: 47
2022-11-22 20:32:10,572 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7532848302613605, 'Total loss': 0.7532848302613605} | train loss {'Reaction outcome loss': 0.7677488027801437, 'Total loss': 0.7677488027801437}
2022-11-22 20:32:10,572 INFO:     Found new best model at epoch 47
2022-11-22 20:32:10,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:10,573 INFO:     Epoch: 48
2022-11-22 20:32:11,426 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7862742082639174, 'Total loss': 0.7862742082639174} | train loss {'Reaction outcome loss': 0.7708648933518317, 'Total loss': 0.7708648933518317}
2022-11-22 20:32:11,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:11,427 INFO:     Epoch: 49
2022-11-22 20:32:12,307 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7903069670904767, 'Total loss': 0.7903069670904767} | train loss {'Reaction outcome loss': 0.7793085832268961, 'Total loss': 0.7793085832268961}
2022-11-22 20:32:12,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:12,307 INFO:     Epoch: 50
2022-11-22 20:32:13,183 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7919692451303656, 'Total loss': 0.7919692451303656} | train loss {'Reaction outcome loss': 0.774304315207466, 'Total loss': 0.774304315207466}
2022-11-22 20:32:13,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:13,183 INFO:     Epoch: 51
2022-11-22 20:32:14,000 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.781129043887962, 'Total loss': 0.781129043887962} | train loss {'Reaction outcome loss': 0.7724050202917668, 'Total loss': 0.7724050202917668}
2022-11-22 20:32:14,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:14,000 INFO:     Epoch: 52
2022-11-22 20:32:14,855 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7557429420677099, 'Total loss': 0.7557429420677099} | train loss {'Reaction outcome loss': 0.7666780159117714, 'Total loss': 0.7666780159117714}
2022-11-22 20:32:14,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:14,855 INFO:     Epoch: 53
2022-11-22 20:32:15,718 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7853682298551906, 'Total loss': 0.7853682298551906} | train loss {'Reaction outcome loss': 0.767785532580268, 'Total loss': 0.767785532580268}
2022-11-22 20:32:15,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:15,718 INFO:     Epoch: 54
2022-11-22 20:32:16,545 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7670637328516353, 'Total loss': 0.7670637328516353} | train loss {'Reaction outcome loss': 0.7655530907213688, 'Total loss': 0.7655530907213688}
2022-11-22 20:32:16,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:16,545 INFO:     Epoch: 55
2022-11-22 20:32:17,378 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7613671123981476, 'Total loss': 0.7613671123981476} | train loss {'Reaction outcome loss': 0.7613278862930113, 'Total loss': 0.7613278862930113}
2022-11-22 20:32:17,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:17,378 INFO:     Epoch: 56
2022-11-22 20:32:18,178 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7642439590259031, 'Total loss': 0.7642439590259031} | train loss {'Reaction outcome loss': 0.7644255176907585, 'Total loss': 0.7644255176907585}
2022-11-22 20:32:18,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:18,179 INFO:     Epoch: 57
2022-11-22 20:32:19,041 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7858177396384153, 'Total loss': 0.7858177396384153} | train loss {'Reaction outcome loss': 0.7612483209720061, 'Total loss': 0.7612483209720061}
2022-11-22 20:32:19,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:19,041 INFO:     Epoch: 58
2022-11-22 20:32:19,914 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7713997452096506, 'Total loss': 0.7713997452096506} | train loss {'Reaction outcome loss': 0.765197804738437, 'Total loss': 0.765197804738437}
2022-11-22 20:32:19,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:19,915 INFO:     Epoch: 59
2022-11-22 20:32:20,724 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7733958275480703, 'Total loss': 0.7733958275480703} | train loss {'Reaction outcome loss': 0.7641547870251441, 'Total loss': 0.7641547870251441}
2022-11-22 20:32:20,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:20,725 INFO:     Epoch: 60
2022-11-22 20:32:21,533 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7610549500042741, 'Total loss': 0.7610549500042741} | train loss {'Reaction outcome loss': 0.7643813763054148, 'Total loss': 0.7643813763054148}
2022-11-22 20:32:21,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:21,533 INFO:     Epoch: 61
2022-11-22 20:32:22,368 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7920102449980649, 'Total loss': 0.7920102449980649} | train loss {'Reaction outcome loss': 0.762254431363075, 'Total loss': 0.762254431363075}
2022-11-22 20:32:22,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:22,369 INFO:     Epoch: 62
2022-11-22 20:32:23,185 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7537693367762999, 'Total loss': 0.7537693367762999} | train loss {'Reaction outcome loss': 0.7533087151786012, 'Total loss': 0.7533087151786012}
2022-11-22 20:32:23,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:23,185 INFO:     Epoch: 63
2022-11-22 20:32:24,073 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7575396739623763, 'Total loss': 0.7575396739623763} | train loss {'Reaction outcome loss': 0.7624958197195684, 'Total loss': 0.7624958197195684}
2022-11-22 20:32:24,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:24,073 INFO:     Epoch: 64
2022-11-22 20:32:24,907 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7687093960967931, 'Total loss': 0.7687093960967931} | train loss {'Reaction outcome loss': 0.7644802114415553, 'Total loss': 0.7644802114415553}
2022-11-22 20:32:24,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:24,908 INFO:     Epoch: 65
2022-11-22 20:32:25,776 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7703140581196005, 'Total loss': 0.7703140581196005} | train loss {'Reaction outcome loss': 0.7566067179845225, 'Total loss': 0.7566067179845225}
2022-11-22 20:32:25,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:25,776 INFO:     Epoch: 66
2022-11-22 20:32:26,600 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7495236159725622, 'Total loss': 0.7495236159725622} | train loss {'Reaction outcome loss': 0.7491352322601503, 'Total loss': 0.7491352322601503}
2022-11-22 20:32:26,602 INFO:     Found new best model at epoch 66
2022-11-22 20:32:26,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:26,602 INFO:     Epoch: 67
2022-11-22 20:32:27,415 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7536879696629264, 'Total loss': 0.7536879696629264} | train loss {'Reaction outcome loss': 0.762043024383245, 'Total loss': 0.762043024383245}
2022-11-22 20:32:27,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:27,416 INFO:     Epoch: 68
2022-11-22 20:32:28,210 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7689923752437938, 'Total loss': 0.7689923752437938} | train loss {'Reaction outcome loss': 0.7513457120906922, 'Total loss': 0.7513457120906922}
2022-11-22 20:32:28,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:28,210 INFO:     Epoch: 69
2022-11-22 20:32:29,008 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8295538554137404, 'Total loss': 0.8295538554137404} | train loss {'Reaction outcome loss': 0.7469791690668752, 'Total loss': 0.7469791690668752}
2022-11-22 20:32:29,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:29,009 INFO:     Epoch: 70
2022-11-22 20:32:29,817 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.753231748261235, 'Total loss': 0.753231748261235} | train loss {'Reaction outcome loss': 0.7510371198577266, 'Total loss': 0.7510371198577266}
2022-11-22 20:32:29,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:29,817 INFO:     Epoch: 71
2022-11-22 20:32:30,616 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7881126038052819, 'Total loss': 0.7881126038052819} | train loss {'Reaction outcome loss': 0.750324898189114, 'Total loss': 0.750324898189114}
2022-11-22 20:32:30,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:30,616 INFO:     Epoch: 72
2022-11-22 20:32:31,414 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7494671978056431, 'Total loss': 0.7494671978056431} | train loss {'Reaction outcome loss': 0.7474911337898623, 'Total loss': 0.7474911337898623}
2022-11-22 20:32:31,415 INFO:     Found new best model at epoch 72
2022-11-22 20:32:31,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:31,416 INFO:     Epoch: 73
2022-11-22 20:32:32,233 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7669363949786533, 'Total loss': 0.7669363949786533} | train loss {'Reaction outcome loss': 0.748339282168496, 'Total loss': 0.748339282168496}
2022-11-22 20:32:32,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:32,234 INFO:     Epoch: 74
2022-11-22 20:32:33,083 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.74186126481403, 'Total loss': 0.74186126481403} | train loss {'Reaction outcome loss': 0.7470639753005197, 'Total loss': 0.7470639753005197}
2022-11-22 20:32:33,083 INFO:     Found new best model at epoch 74
2022-11-22 20:32:33,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:33,084 INFO:     Epoch: 75
2022-11-22 20:32:33,888 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7740027870644223, 'Total loss': 0.7740027870644223} | train loss {'Reaction outcome loss': 0.7435791454007549, 'Total loss': 0.7435791454007549}
2022-11-22 20:32:33,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:33,888 INFO:     Epoch: 76
2022-11-22 20:32:34,713 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7533805309371515, 'Total loss': 0.7533805309371515} | train loss {'Reaction outcome loss': 0.7406705851636587, 'Total loss': 0.7406705851636587}
2022-11-22 20:32:34,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:34,713 INFO:     Epoch: 77
2022-11-22 20:32:35,553 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7380551932887598, 'Total loss': 0.7380551932887598} | train loss {'Reaction outcome loss': 0.7504394078446973, 'Total loss': 0.7504394078446973}
2022-11-22 20:32:35,553 INFO:     Found new best model at epoch 77
2022-11-22 20:32:35,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:35,554 INFO:     Epoch: 78
2022-11-22 20:32:36,330 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7828883759000085, 'Total loss': 0.7828883759000085} | train loss {'Reaction outcome loss': 0.7396451368206932, 'Total loss': 0.7396451368206932}
2022-11-22 20:32:36,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:36,330 INFO:     Epoch: 79
2022-11-22 20:32:37,088 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.758074326948686, 'Total loss': 0.758074326948686} | train loss {'Reaction outcome loss': 0.7425108951246066, 'Total loss': 0.7425108951246066}
2022-11-22 20:32:37,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:37,088 INFO:     Epoch: 80
2022-11-22 20:32:37,908 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7459787577390671, 'Total loss': 0.7459787577390671} | train loss {'Reaction outcome loss': 0.7370479151366218, 'Total loss': 0.7370479151366218}
2022-11-22 20:32:37,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:37,908 INFO:     Epoch: 81
2022-11-22 20:32:38,679 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7562856538729235, 'Total loss': 0.7562856538729235} | train loss {'Reaction outcome loss': 0.7417935753661778, 'Total loss': 0.7417935753661778}
2022-11-22 20:32:38,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:38,679 INFO:     Epoch: 82
2022-11-22 20:32:39,504 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7573725310238925, 'Total loss': 0.7573725310238925} | train loss {'Reaction outcome loss': 0.7336926755885924, 'Total loss': 0.7336926755885924}
2022-11-22 20:32:39,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:39,505 INFO:     Epoch: 83
2022-11-22 20:32:40,295 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7355739379470999, 'Total loss': 0.7355739379470999} | train loss {'Reaction outcome loss': 0.7322655061800634, 'Total loss': 0.7322655061800634}
2022-11-22 20:32:40,295 INFO:     Found new best model at epoch 83
2022-11-22 20:32:40,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:40,296 INFO:     Epoch: 84
2022-11-22 20:32:41,106 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7277205498381094, 'Total loss': 0.7277205498381094} | train loss {'Reaction outcome loss': 0.7257682152332798, 'Total loss': 0.7257682152332798}
2022-11-22 20:32:41,107 INFO:     Found new best model at epoch 84
2022-11-22 20:32:41,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:41,107 INFO:     Epoch: 85
2022-11-22 20:32:41,923 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7233092398806051, 'Total loss': 0.7233092398806051} | train loss {'Reaction outcome loss': 0.728674829366707, 'Total loss': 0.728674829366707}
2022-11-22 20:32:41,923 INFO:     Found new best model at epoch 85
2022-11-22 20:32:41,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:41,924 INFO:     Epoch: 86
2022-11-22 20:32:42,718 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7349210246042772, 'Total loss': 0.7349210246042772} | train loss {'Reaction outcome loss': 0.7269058052089906, 'Total loss': 0.7269058052089906}
2022-11-22 20:32:42,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:42,719 INFO:     Epoch: 87
2022-11-22 20:32:43,508 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7238367247310552, 'Total loss': 0.7238367247310552} | train loss {'Reaction outcome loss': 0.71881895428223, 'Total loss': 0.71881895428223}
2022-11-22 20:32:43,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:43,508 INFO:     Epoch: 88
2022-11-22 20:32:44,325 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7265746105800975, 'Total loss': 0.7265746105800975} | train loss {'Reaction outcome loss': 0.7151620984077454, 'Total loss': 0.7151620984077454}
2022-11-22 20:32:44,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:44,326 INFO:     Epoch: 89
2022-11-22 20:32:45,118 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.763504566794092, 'Total loss': 0.763504566794092} | train loss {'Reaction outcome loss': 0.7179903837461625, 'Total loss': 0.7179903837461625}
2022-11-22 20:32:45,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:45,119 INFO:     Epoch: 90
2022-11-22 20:32:45,938 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7536252940242941, 'Total loss': 0.7536252940242941} | train loss {'Reaction outcome loss': 0.7166667555368715, 'Total loss': 0.7166667555368715}
2022-11-22 20:32:45,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:45,938 INFO:     Epoch: 91
2022-11-22 20:32:46,728 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7305093041875146, 'Total loss': 0.7305093041875146} | train loss {'Reaction outcome loss': 0.708605874810488, 'Total loss': 0.708605874810488}
2022-11-22 20:32:46,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:46,728 INFO:     Epoch: 92
2022-11-22 20:32:47,585 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.731645639647137, 'Total loss': 0.731645639647137} | train loss {'Reaction outcome loss': 0.7125068640997333, 'Total loss': 0.7125068640997333}
2022-11-22 20:32:47,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:47,585 INFO:     Epoch: 93
2022-11-22 20:32:48,402 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7461264993656765, 'Total loss': 0.7461264993656765} | train loss {'Reaction outcome loss': 0.7144278889341701, 'Total loss': 0.7144278889341701}
2022-11-22 20:32:48,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:48,402 INFO:     Epoch: 94
2022-11-22 20:32:49,204 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.767259799621322, 'Total loss': 0.767259799621322} | train loss {'Reaction outcome loss': 0.7123893418860051, 'Total loss': 0.7123893418860051}
2022-11-22 20:32:49,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:49,205 INFO:     Epoch: 95
2022-11-22 20:32:50,004 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7738701369274746, 'Total loss': 0.7738701369274746} | train loss {'Reaction outcome loss': 0.7149547862429773, 'Total loss': 0.7149547862429773}
2022-11-22 20:32:50,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:50,004 INFO:     Epoch: 96
2022-11-22 20:32:50,811 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7036907462911173, 'Total loss': 0.7036907462911173} | train loss {'Reaction outcome loss': 0.7102511560003604, 'Total loss': 0.7102511560003604}
2022-11-22 20:32:50,811 INFO:     Found new best model at epoch 96
2022-11-22 20:32:50,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:50,812 INFO:     Epoch: 97
2022-11-22 20:32:51,614 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7127810249274428, 'Total loss': 0.7127810249274428} | train loss {'Reaction outcome loss': 0.7115436776150619, 'Total loss': 0.7115436776150619}
2022-11-22 20:32:51,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:51,614 INFO:     Epoch: 98
2022-11-22 20:32:52,387 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7162104025483131, 'Total loss': 0.7162104025483131} | train loss {'Reaction outcome loss': 0.7141675023782638, 'Total loss': 0.7141675023782638}
2022-11-22 20:32:52,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:52,387 INFO:     Epoch: 99
2022-11-22 20:32:53,173 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7201178155162118, 'Total loss': 0.7201178155162118} | train loss {'Reaction outcome loss': 0.7084610043994842, 'Total loss': 0.7084610043994842}
2022-11-22 20:32:53,173 INFO:     Best model found after epoch 97 of 100.
2022-11-22 20:32:53,173 INFO:   Done with stage: TRAINING
2022-11-22 20:32:53,173 INFO:   Starting stage: EVALUATION
2022-11-22 20:32:53,287 INFO:   Done with stage: EVALUATION
2022-11-22 20:32:53,287 INFO:   Leaving out SEQ value Fold_8
2022-11-22 20:32:53,301 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:32:53,301 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:32:53,982 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:32:53,983 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:32:54,059 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:32:54,059 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:32:54,059 INFO:     No hyperparam tuning for this model
2022-11-22 20:32:54,059 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:32:54,060 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:32:54,060 INFO:     None feature selector for col prot
2022-11-22 20:32:54,061 INFO:     None feature selector for col prot
2022-11-22 20:32:54,061 INFO:     None feature selector for col prot
2022-11-22 20:32:54,061 INFO:     None feature selector for col chem
2022-11-22 20:32:54,062 INFO:     None feature selector for col chem
2022-11-22 20:32:54,062 INFO:     None feature selector for col chem
2022-11-22 20:32:54,062 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:32:54,062 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:32:54,063 INFO:     Number of params in model 126091
2022-11-22 20:32:54,067 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:32:54,067 INFO:   Starting stage: TRAINING
2022-11-22 20:32:54,118 INFO:     Val loss before train {'Reaction outcome loss': 1.0217146263881163, 'Total loss': 1.0217146263881163}
2022-11-22 20:32:54,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:54,118 INFO:     Epoch: 0
2022-11-22 20:32:54,931 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.847357764840126, 'Total loss': 0.847357764840126} | train loss {'Reaction outcome loss': 0.8746469653087107, 'Total loss': 0.8746469653087107}
2022-11-22 20:32:54,932 INFO:     Found new best model at epoch 0
2022-11-22 20:32:54,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:54,932 INFO:     Epoch: 1
2022-11-22 20:32:55,740 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8247041424567049, 'Total loss': 0.8247041424567049} | train loss {'Reaction outcome loss': 0.8380773710878754, 'Total loss': 0.8380773710878754}
2022-11-22 20:32:55,740 INFO:     Found new best model at epoch 1
2022-11-22 20:32:55,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:55,741 INFO:     Epoch: 2
2022-11-22 20:32:56,527 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8178216523744843, 'Total loss': 0.8178216523744843} | train loss {'Reaction outcome loss': 0.8305577779347114, 'Total loss': 0.8305577779347114}
2022-11-22 20:32:56,527 INFO:     Found new best model at epoch 2
2022-11-22 20:32:56,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:56,528 INFO:     Epoch: 3
2022-11-22 20:32:57,341 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8361746208234266, 'Total loss': 0.8361746208234266} | train loss {'Reaction outcome loss': 0.8300817828429373, 'Total loss': 0.8300817828429373}
2022-11-22 20:32:57,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:57,341 INFO:     Epoch: 4
2022-11-22 20:32:58,154 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7881626215848055, 'Total loss': 0.7881626215848055} | train loss {'Reaction outcome loss': 0.8216637975049887, 'Total loss': 0.8216637975049887}
2022-11-22 20:32:58,155 INFO:     Found new best model at epoch 4
2022-11-22 20:32:58,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:58,156 INFO:     Epoch: 5
2022-11-22 20:32:58,978 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7862579869953069, 'Total loss': 0.7862579869953069} | train loss {'Reaction outcome loss': 0.8143102795730236, 'Total loss': 0.8143102795730236}
2022-11-22 20:32:58,978 INFO:     Found new best model at epoch 5
2022-11-22 20:32:58,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:58,979 INFO:     Epoch: 6
2022-11-22 20:32:59,742 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8152379637414758, 'Total loss': 0.8152379637414758} | train loss {'Reaction outcome loss': 0.8102842588053059, 'Total loss': 0.8102842588053059}
2022-11-22 20:32:59,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:32:59,742 INFO:     Epoch: 7
2022-11-22 20:33:00,520 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8104666566306894, 'Total loss': 0.8104666566306894} | train loss {'Reaction outcome loss': 0.8088971374005924, 'Total loss': 0.8088971374005924}
2022-11-22 20:33:00,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:00,520 INFO:     Epoch: 8
2022-11-22 20:33:01,304 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8245172669941728, 'Total loss': 0.8245172669941728} | train loss {'Reaction outcome loss': 0.8098909309820125, 'Total loss': 0.8098909309820125}
2022-11-22 20:33:01,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:01,305 INFO:     Epoch: 9
2022-11-22 20:33:02,099 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8109943758357655, 'Total loss': 0.8109943758357655} | train loss {'Reaction outcome loss': 0.8080396410907328, 'Total loss': 0.8080396410907328}
2022-11-22 20:33:02,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:02,099 INFO:     Epoch: 10
2022-11-22 20:33:02,900 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7959691292860291, 'Total loss': 0.7959691292860291} | train loss {'Reaction outcome loss': 0.8058709311581816, 'Total loss': 0.8058709311581816}
2022-11-22 20:33:02,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:02,900 INFO:     Epoch: 11
2022-11-22 20:33:03,675 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7931785996664654, 'Total loss': 0.7931785996664654} | train loss {'Reaction outcome loss': 0.8049651209400733, 'Total loss': 0.8049651209400733}
2022-11-22 20:33:03,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:03,675 INFO:     Epoch: 12
2022-11-22 20:33:04,478 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.801015074618838, 'Total loss': 0.801015074618838} | train loss {'Reaction outcome loss': 0.798971674310775, 'Total loss': 0.798971674310775}
2022-11-22 20:33:04,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:04,479 INFO:     Epoch: 13
2022-11-22 20:33:05,278 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7956788607619025, 'Total loss': 0.7956788607619025} | train loss {'Reaction outcome loss': 0.7985449124444352, 'Total loss': 0.7985449124444352}
2022-11-22 20:33:05,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:05,278 INFO:     Epoch: 14
2022-11-22 20:33:06,018 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7795563333413817, 'Total loss': 0.7795563333413817} | train loss {'Reaction outcome loss': 0.7996799093991639, 'Total loss': 0.7996799093991639}
2022-11-22 20:33:06,019 INFO:     Found new best model at epoch 14
2022-11-22 20:33:06,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:06,019 INFO:     Epoch: 15
2022-11-22 20:33:06,798 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8084401962431994, 'Total loss': 0.8084401962431994} | train loss {'Reaction outcome loss': 0.7998808692341391, 'Total loss': 0.7998808692341391}
2022-11-22 20:33:06,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:06,798 INFO:     Epoch: 16
2022-11-22 20:33:07,516 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7720194824717261, 'Total loss': 0.7720194824717261} | train loss {'Reaction outcome loss': 0.800779089029984, 'Total loss': 0.800779089029984}
2022-11-22 20:33:07,516 INFO:     Found new best model at epoch 16
2022-11-22 20:33:07,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:07,517 INFO:     Epoch: 17
2022-11-22 20:33:08,235 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8425050960345701, 'Total loss': 0.8425050960345701} | train loss {'Reaction outcome loss': 0.802460793179539, 'Total loss': 0.802460793179539}
2022-11-22 20:33:08,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:08,235 INFO:     Epoch: 18
2022-11-22 20:33:08,981 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8264422138983553, 'Total loss': 0.8264422138983553} | train loss {'Reaction outcome loss': 0.7963888365850758, 'Total loss': 0.7963888365850758}
2022-11-22 20:33:08,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:08,981 INFO:     Epoch: 19
2022-11-22 20:33:09,730 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8355088938366283, 'Total loss': 0.8355088938366283} | train loss {'Reaction outcome loss': 0.7974169887451508, 'Total loss': 0.7974169887451508}
2022-11-22 20:33:09,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:09,730 INFO:     Epoch: 20
2022-11-22 20:33:10,451 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8080325749787417, 'Total loss': 0.8080325749787417} | train loss {'Reaction outcome loss': 0.7907440431325542, 'Total loss': 0.7907440431325542}
2022-11-22 20:33:10,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:10,451 INFO:     Epoch: 21
2022-11-22 20:33:11,226 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7885657040910288, 'Total loss': 0.7885657040910288} | train loss {'Reaction outcome loss': 0.7969282531303915, 'Total loss': 0.7969282531303915}
2022-11-22 20:33:11,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:11,227 INFO:     Epoch: 22
2022-11-22 20:33:11,993 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7609947499903765, 'Total loss': 0.7609947499903765} | train loss {'Reaction outcome loss': 0.793112667646968, 'Total loss': 0.793112667646968}
2022-11-22 20:33:11,993 INFO:     Found new best model at epoch 22
2022-11-22 20:33:11,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:11,994 INFO:     Epoch: 23
2022-11-22 20:33:12,739 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7671660896052014, 'Total loss': 0.7671660896052014} | train loss {'Reaction outcome loss': 0.801647652739938, 'Total loss': 0.801647652739938}
2022-11-22 20:33:12,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:12,739 INFO:     Epoch: 24
2022-11-22 20:33:13,472 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7743489146232605, 'Total loss': 0.7743489146232605} | train loss {'Reaction outcome loss': 0.7948739804960938, 'Total loss': 0.7948739804960938}
2022-11-22 20:33:13,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:13,473 INFO:     Epoch: 25
2022-11-22 20:33:14,202 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7811215594410896, 'Total loss': 0.7811215594410896} | train loss {'Reaction outcome loss': 0.7948874746739623, 'Total loss': 0.7948874746739623}
2022-11-22 20:33:14,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:14,202 INFO:     Epoch: 26
2022-11-22 20:33:14,946 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8034241287545725, 'Total loss': 0.8034241287545725} | train loss {'Reaction outcome loss': 0.7947918847806541, 'Total loss': 0.7947918847806541}
2022-11-22 20:33:14,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:14,947 INFO:     Epoch: 27
2022-11-22 20:33:15,691 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8101590688933026, 'Total loss': 0.8101590688933026} | train loss {'Reaction outcome loss': 0.7918112863171921, 'Total loss': 0.7918112863171921}
2022-11-22 20:33:15,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:15,691 INFO:     Epoch: 28
2022-11-22 20:33:16,412 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7957084808837284, 'Total loss': 0.7957084808837284} | train loss {'Reaction outcome loss': 0.7939208352614028, 'Total loss': 0.7939208352614028}
2022-11-22 20:33:16,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:16,413 INFO:     Epoch: 29
2022-11-22 20:33:17,147 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7975009076974608, 'Total loss': 0.7975009076974608} | train loss {'Reaction outcome loss': 0.7893078471967566, 'Total loss': 0.7893078471967566}
2022-11-22 20:33:17,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:17,148 INFO:     Epoch: 30
2022-11-22 20:33:17,854 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7833360403098844, 'Total loss': 0.7833360403098844} | train loss {'Reaction outcome loss': 0.7956638862246926, 'Total loss': 0.7956638862246926}
2022-11-22 20:33:17,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:17,854 INFO:     Epoch: 31
2022-11-22 20:33:18,574 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7970902973955328, 'Total loss': 0.7970902973955328} | train loss {'Reaction outcome loss': 0.7899521606171179, 'Total loss': 0.7899521606171179}
2022-11-22 20:33:18,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:18,574 INFO:     Epoch: 32
2022-11-22 20:33:19,298 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7794662686911497, 'Total loss': 0.7794662686911497} | train loss {'Reaction outcome loss': 0.7901096901430292, 'Total loss': 0.7901096901430292}
2022-11-22 20:33:19,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:19,298 INFO:     Epoch: 33
2022-11-22 20:33:20,043 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7674322710795836, 'Total loss': 0.7674322710795836} | train loss {'Reaction outcome loss': 0.791366270241829, 'Total loss': 0.791366270241829}
2022-11-22 20:33:20,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:20,044 INFO:     Epoch: 34
2022-11-22 20:33:20,783 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7807306328957732, 'Total loss': 0.7807306328957732} | train loss {'Reaction outcome loss': 0.7846543549405418, 'Total loss': 0.7846543549405418}
2022-11-22 20:33:20,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:20,783 INFO:     Epoch: 35
2022-11-22 20:33:21,525 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7689608592878688, 'Total loss': 0.7689608592878688} | train loss {'Reaction outcome loss': 0.7872602476282158, 'Total loss': 0.7872602476282158}
2022-11-22 20:33:21,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:21,526 INFO:     Epoch: 36
2022-11-22 20:33:22,233 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7848143232139674, 'Total loss': 0.7848143232139674} | train loss {'Reaction outcome loss': 0.7918190785989105, 'Total loss': 0.7918190785989105}
2022-11-22 20:33:22,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:22,233 INFO:     Epoch: 37
2022-11-22 20:33:22,964 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7815474000844088, 'Total loss': 0.7815474000844088} | train loss {'Reaction outcome loss': 0.7912012931065038, 'Total loss': 0.7912012931065038}
2022-11-22 20:33:22,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:22,965 INFO:     Epoch: 38
2022-11-22 20:33:23,758 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.792257703163407, 'Total loss': 0.792257703163407} | train loss {'Reaction outcome loss': 0.7868306201237899, 'Total loss': 0.7868306201237899}
2022-11-22 20:33:23,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:23,759 INFO:     Epoch: 39
2022-11-22 20:33:24,476 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7980832410129634, 'Total loss': 0.7980832410129634} | train loss {'Reaction outcome loss': 0.7884895432333232, 'Total loss': 0.7884895432333232}
2022-11-22 20:33:24,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:24,477 INFO:     Epoch: 40
2022-11-22 20:33:25,206 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7721635706045411, 'Total loss': 0.7721635706045411} | train loss {'Reaction outcome loss': 0.7975674787996269, 'Total loss': 0.7975674787996269}
2022-11-22 20:33:25,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:25,206 INFO:     Epoch: 41
2022-11-22 20:33:25,937 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.781657612459226, 'Total loss': 0.781657612459226} | train loss {'Reaction outcome loss': 0.7844377196872765, 'Total loss': 0.7844377196872765}
2022-11-22 20:33:25,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:25,937 INFO:     Epoch: 42
2022-11-22 20:33:26,689 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7659825540401719, 'Total loss': 0.7659825540401719} | train loss {'Reaction outcome loss': 0.7847009757873018, 'Total loss': 0.7847009757873018}
2022-11-22 20:33:26,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:26,689 INFO:     Epoch: 43
2022-11-22 20:33:27,425 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7792699174447493, 'Total loss': 0.7792699174447493} | train loss {'Reaction outcome loss': 0.7793369335744545, 'Total loss': 0.7793369335744545}
2022-11-22 20:33:27,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:27,425 INFO:     Epoch: 44
2022-11-22 20:33:28,130 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7789514525370165, 'Total loss': 0.7789514525370165} | train loss {'Reaction outcome loss': 0.7917648758965465, 'Total loss': 0.7917648758965465}
2022-11-22 20:33:28,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:28,130 INFO:     Epoch: 45
2022-11-22 20:33:28,876 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7896096753803167, 'Total loss': 0.7896096753803167} | train loss {'Reaction outcome loss': 0.7866556705974856, 'Total loss': 0.7866556705974856}
2022-11-22 20:33:28,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:28,877 INFO:     Epoch: 46
2022-11-22 20:33:29,623 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7772797088731419, 'Total loss': 0.7772797088731419} | train loss {'Reaction outcome loss': 0.7927582704345224, 'Total loss': 0.7927582704345224}
2022-11-22 20:33:29,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:29,623 INFO:     Epoch: 47
2022-11-22 20:33:30,374 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7721404785459692, 'Total loss': 0.7721404785459692} | train loss {'Reaction outcome loss': 0.785299319728666, 'Total loss': 0.785299319728666}
2022-11-22 20:33:30,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:30,374 INFO:     Epoch: 48
2022-11-22 20:33:31,158 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.772406896406954, 'Total loss': 0.772406896406954} | train loss {'Reaction outcome loss': 0.7831376262521936, 'Total loss': 0.7831376262521936}
2022-11-22 20:33:31,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:31,158 INFO:     Epoch: 49
2022-11-22 20:33:31,910 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7534608021378517, 'Total loss': 0.7534608021378517} | train loss {'Reaction outcome loss': 0.7830478943552566, 'Total loss': 0.7830478943552566}
2022-11-22 20:33:31,910 INFO:     Found new best model at epoch 49
2022-11-22 20:33:31,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:31,911 INFO:     Epoch: 50
2022-11-22 20:33:32,686 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7709384296428073, 'Total loss': 0.7709384296428073} | train loss {'Reaction outcome loss': 0.780434439056798, 'Total loss': 0.780434439056798}
2022-11-22 20:33:32,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:32,686 INFO:     Epoch: 51
2022-11-22 20:33:33,446 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7639357190240513, 'Total loss': 0.7639357190240513} | train loss {'Reaction outcome loss': 0.7854326617138588, 'Total loss': 0.7854326617138588}
2022-11-22 20:33:33,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:33,447 INFO:     Epoch: 52
2022-11-22 20:33:34,249 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8024710003625263, 'Total loss': 0.8024710003625263} | train loss {'Reaction outcome loss': 0.7808649375853751, 'Total loss': 0.7808649375853751}
2022-11-22 20:33:34,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:34,249 INFO:     Epoch: 53
2022-11-22 20:33:34,980 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.775715057822791, 'Total loss': 0.775715057822791} | train loss {'Reaction outcome loss': 0.787715623856556, 'Total loss': 0.787715623856556}
2022-11-22 20:33:34,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:34,981 INFO:     Epoch: 54
2022-11-22 20:33:35,742 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7688296362757683, 'Total loss': 0.7688296362757683} | train loss {'Reaction outcome loss': 0.7819588560807077, 'Total loss': 0.7819588560807077}
2022-11-22 20:33:35,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:35,742 INFO:     Epoch: 55
2022-11-22 20:33:36,491 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7790123772892085, 'Total loss': 0.7790123772892085} | train loss {'Reaction outcome loss': 0.7814949838980007, 'Total loss': 0.7814949838980007}
2022-11-22 20:33:36,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:36,491 INFO:     Epoch: 56
2022-11-22 20:33:37,255 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7612653415311467, 'Total loss': 0.7612653415311467} | train loss {'Reaction outcome loss': 0.7867047978557555, 'Total loss': 0.7867047978557555}
2022-11-22 20:33:37,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:37,255 INFO:     Epoch: 57
2022-11-22 20:33:37,997 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7649379379369996, 'Total loss': 0.7649379379369996} | train loss {'Reaction outcome loss': 0.7768491171752876, 'Total loss': 0.7768491171752876}
2022-11-22 20:33:37,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:37,998 INFO:     Epoch: 58
2022-11-22 20:33:38,721 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7805533436211672, 'Total loss': 0.7805533436211672} | train loss {'Reaction outcome loss': 0.7730854255890074, 'Total loss': 0.7730854255890074}
2022-11-22 20:33:38,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:38,721 INFO:     Epoch: 59
2022-11-22 20:33:39,466 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7688563344153491, 'Total loss': 0.7688563344153491} | train loss {'Reaction outcome loss': 0.7744476282403536, 'Total loss': 0.7744476282403536}
2022-11-22 20:33:39,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:39,466 INFO:     Epoch: 60
2022-11-22 20:33:40,203 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7496017834002321, 'Total loss': 0.7496017834002321} | train loss {'Reaction outcome loss': 0.7781549450839579, 'Total loss': 0.7781549450839579}
2022-11-22 20:33:40,203 INFO:     Found new best model at epoch 60
2022-11-22 20:33:40,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:40,204 INFO:     Epoch: 61
2022-11-22 20:33:40,950 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8027706769379702, 'Total loss': 0.8027706769379702} | train loss {'Reaction outcome loss': 0.770850228394574, 'Total loss': 0.770850228394574}
2022-11-22 20:33:40,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:40,950 INFO:     Epoch: 62
2022-11-22 20:33:41,714 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7746333852410316, 'Total loss': 0.7746333852410316} | train loss {'Reaction outcome loss': 0.7724781449024494, 'Total loss': 0.7724781449024494}
2022-11-22 20:33:41,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:41,715 INFO:     Epoch: 63
2022-11-22 20:33:42,479 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7830729254267432, 'Total loss': 0.7830729254267432} | train loss {'Reaction outcome loss': 0.7747630743754779, 'Total loss': 0.7747630743754779}
2022-11-22 20:33:42,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:42,479 INFO:     Epoch: 64
2022-11-22 20:33:43,238 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7768658264116808, 'Total loss': 0.7768658264116808} | train loss {'Reaction outcome loss': 0.7681316683890849, 'Total loss': 0.7681316683890849}
2022-11-22 20:33:43,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:43,238 INFO:     Epoch: 65
2022-11-22 20:33:43,994 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7634933218359947, 'Total loss': 0.7634933218359947} | train loss {'Reaction outcome loss': 0.7760935215814876, 'Total loss': 0.7760935215814876}
2022-11-22 20:33:43,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:43,994 INFO:     Epoch: 66
2022-11-22 20:33:44,697 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7634685994549231, 'Total loss': 0.7634685994549231} | train loss {'Reaction outcome loss': 0.7711107590903155, 'Total loss': 0.7711107590903155}
2022-11-22 20:33:44,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:44,697 INFO:     Epoch: 67
2022-11-22 20:33:45,439 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7443144490773027, 'Total loss': 0.7443144490773027} | train loss {'Reaction outcome loss': 0.7648049159812541, 'Total loss': 0.7648049159812541}
2022-11-22 20:33:45,440 INFO:     Found new best model at epoch 67
2022-11-22 20:33:45,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:45,440 INFO:     Epoch: 68
2022-11-22 20:33:46,198 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7757287905974821, 'Total loss': 0.7757287905974821} | train loss {'Reaction outcome loss': 0.7591972907303799, 'Total loss': 0.7591972907303799}
2022-11-22 20:33:46,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:46,198 INFO:     Epoch: 69
2022-11-22 20:33:46,944 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7477867413650859, 'Total loss': 0.7477867413650859} | train loss {'Reaction outcome loss': 0.7720562324289851, 'Total loss': 0.7720562324289851}
2022-11-22 20:33:46,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:46,944 INFO:     Epoch: 70
2022-11-22 20:33:47,706 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7904269194061105, 'Total loss': 0.7904269194061105} | train loss {'Reaction outcome loss': 0.7541451059613633, 'Total loss': 0.7541451059613633}
2022-11-22 20:33:47,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:47,707 INFO:     Epoch: 71
2022-11-22 20:33:48,460 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7712377702647989, 'Total loss': 0.7712377702647989} | train loss {'Reaction outcome loss': 0.7573254095156666, 'Total loss': 0.7573254095156666}
2022-11-22 20:33:48,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:48,460 INFO:     Epoch: 72
2022-11-22 20:33:49,236 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7353904132138599, 'Total loss': 0.7353904132138599} | train loss {'Reaction outcome loss': 0.7552006587325802, 'Total loss': 0.7552006587325802}
2022-11-22 20:33:49,236 INFO:     Found new best model at epoch 72
2022-11-22 20:33:49,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:49,237 INFO:     Epoch: 73
2022-11-22 20:33:50,002 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8063098354773088, 'Total loss': 0.8063098354773088} | train loss {'Reaction outcome loss': 0.759036419845303, 'Total loss': 0.759036419845303}
2022-11-22 20:33:50,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:50,002 INFO:     Epoch: 74
2022-11-22 20:33:50,756 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7282358055764978, 'Total loss': 0.7282358055764978} | train loss {'Reaction outcome loss': 0.7469030523348433, 'Total loss': 0.7469030523348433}
2022-11-22 20:33:50,756 INFO:     Found new best model at epoch 74
2022-11-22 20:33:50,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:50,757 INFO:     Epoch: 75
2022-11-22 20:33:51,473 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7368704642761837, 'Total loss': 0.7368704642761837} | train loss {'Reaction outcome loss': 0.7349407627032354, 'Total loss': 0.7349407627032354}
2022-11-22 20:33:51,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:51,473 INFO:     Epoch: 76
2022-11-22 20:33:52,242 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7516084286299619, 'Total loss': 0.7516084286299619} | train loss {'Reaction outcome loss': 0.743938999740701, 'Total loss': 0.743938999740701}
2022-11-22 20:33:52,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:52,242 INFO:     Epoch: 77
2022-11-22 20:33:52,950 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7381163754246451, 'Total loss': 0.7381163754246451} | train loss {'Reaction outcome loss': 0.7527154653902478, 'Total loss': 0.7527154653902478}
2022-11-22 20:33:52,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:52,951 INFO:     Epoch: 78
2022-11-22 20:33:53,691 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7502671100876548, 'Total loss': 0.7502671100876548} | train loss {'Reaction outcome loss': 0.7438410782681303, 'Total loss': 0.7438410782681303}
2022-11-22 20:33:53,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:53,691 INFO:     Epoch: 79
2022-11-22 20:33:54,450 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7485134425488386, 'Total loss': 0.7485134425488386} | train loss {'Reaction outcome loss': 0.7320842913046539, 'Total loss': 0.7320842913046539}
2022-11-22 20:33:54,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:54,450 INFO:     Epoch: 80
2022-11-22 20:33:55,224 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7240741909904913, 'Total loss': 0.7240741909904913} | train loss {'Reaction outcome loss': 0.7331016801961279, 'Total loss': 0.7331016801961279}
2022-11-22 20:33:55,224 INFO:     Found new best model at epoch 80
2022-11-22 20:33:55,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:55,225 INFO:     Epoch: 81
2022-11-22 20:33:55,974 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7452625049786135, 'Total loss': 0.7452625049786135} | train loss {'Reaction outcome loss': 0.7306148012881337, 'Total loss': 0.7306148012881337}
2022-11-22 20:33:55,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:55,975 INFO:     Epoch: 82
2022-11-22 20:33:56,697 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7081941576166586, 'Total loss': 0.7081941576166586} | train loss {'Reaction outcome loss': 0.7239752516059982, 'Total loss': 0.7239752516059982}
2022-11-22 20:33:56,697 INFO:     Found new best model at epoch 82
2022-11-22 20:33:56,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:56,698 INFO:     Epoch: 83
2022-11-22 20:33:57,446 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7132031267339533, 'Total loss': 0.7132031267339533} | train loss {'Reaction outcome loss': 0.7255309084166399, 'Total loss': 0.7255309084166399}
2022-11-22 20:33:57,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:57,446 INFO:     Epoch: 84
2022-11-22 20:33:58,199 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7339519411325455, 'Total loss': 0.7339519411325455} | train loss {'Reaction outcome loss': 0.7256075365144593, 'Total loss': 0.7256075365144593}
2022-11-22 20:33:58,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:58,199 INFO:     Epoch: 85
2022-11-22 20:33:58,944 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7146424231204119, 'Total loss': 0.7146424231204119} | train loss {'Reaction outcome loss': 0.7167888761531969, 'Total loss': 0.7167888761531969}
2022-11-22 20:33:58,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:58,945 INFO:     Epoch: 86
2022-11-22 20:33:59,723 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.733178698881106, 'Total loss': 0.733178698881106} | train loss {'Reaction outcome loss': 0.7295323822662415, 'Total loss': 0.7295323822662415}
2022-11-22 20:33:59,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:33:59,724 INFO:     Epoch: 87
2022-11-22 20:34:00,477 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7126870663328604, 'Total loss': 0.7126870663328604} | train loss {'Reaction outcome loss': 0.7334322504669066, 'Total loss': 0.7334322504669066}
2022-11-22 20:34:00,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:00,477 INFO:     Epoch: 88
2022-11-22 20:34:01,255 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7197983278469606, 'Total loss': 0.7197983278469606} | train loss {'Reaction outcome loss': 0.7249315372604107, 'Total loss': 0.7249315372604107}
2022-11-22 20:34:01,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:01,256 INFO:     Epoch: 89
2022-11-22 20:34:02,010 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7646717266602949, 'Total loss': 0.7646717266602949} | train loss {'Reaction outcome loss': 0.717499976879672, 'Total loss': 0.717499976879672}
2022-11-22 20:34:02,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:02,010 INFO:     Epoch: 90
2022-11-22 20:34:02,760 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7428350882096724, 'Total loss': 0.7428350882096724} | train loss {'Reaction outcome loss': 0.7215058560434141, 'Total loss': 0.7215058560434141}
2022-11-22 20:34:02,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:02,761 INFO:     Epoch: 91
2022-11-22 20:34:03,558 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7189631421457637, 'Total loss': 0.7189631421457637} | train loss {'Reaction outcome loss': 0.7204197044616286, 'Total loss': 0.7204197044616286}
2022-11-22 20:34:03,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:03,558 INFO:     Epoch: 92
2022-11-22 20:34:04,335 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7081862776116892, 'Total loss': 0.7081862776116892} | train loss {'Reaction outcome loss': 0.7202856849109837, 'Total loss': 0.7202856849109837}
2022-11-22 20:34:04,335 INFO:     Found new best model at epoch 92
2022-11-22 20:34:04,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:04,336 INFO:     Epoch: 93
2022-11-22 20:34:05,089 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7143920720978216, 'Total loss': 0.7143920720978216} | train loss {'Reaction outcome loss': 0.7197115116032512, 'Total loss': 0.7197115116032512}
2022-11-22 20:34:05,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:05,089 INFO:     Epoch: 94
2022-11-22 20:34:05,843 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7509785728021101, 'Total loss': 0.7509785728021101} | train loss {'Reaction outcome loss': 0.7115936841559314, 'Total loss': 0.7115936841559314}
2022-11-22 20:34:05,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:05,844 INFO:     Epoch: 95
2022-11-22 20:34:06,608 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7083000174977563, 'Total loss': 0.7083000174977563} | train loss {'Reaction outcome loss': 0.7194929168774531, 'Total loss': 0.7194929168774531}
2022-11-22 20:34:06,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:06,608 INFO:     Epoch: 96
2022-11-22 20:34:07,378 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7274251187389548, 'Total loss': 0.7274251187389548} | train loss {'Reaction outcome loss': 0.7186209911457923, 'Total loss': 0.7186209911457923}
2022-11-22 20:34:07,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:07,378 INFO:     Epoch: 97
2022-11-22 20:34:08,139 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7486594292250547, 'Total loss': 0.7486594292250547} | train loss {'Reaction outcome loss': 0.7099792081334813, 'Total loss': 0.7099792081334813}
2022-11-22 20:34:08,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:08,140 INFO:     Epoch: 98
2022-11-22 20:34:08,861 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.753283714028922, 'Total loss': 0.753283714028922} | train loss {'Reaction outcome loss': 0.7233993205946949, 'Total loss': 0.7233993205946949}
2022-11-22 20:34:08,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:08,862 INFO:     Epoch: 99
2022-11-22 20:34:09,581 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6870399781248786, 'Total loss': 0.6870399781248786} | train loss {'Reaction outcome loss': 0.7196092323253029, 'Total loss': 0.7196092323253029}
2022-11-22 20:34:09,581 INFO:     Found new best model at epoch 99
2022-11-22 20:34:09,582 INFO:     Best model found after epoch 100 of 100.
2022-11-22 20:34:09,582 INFO:   Done with stage: TRAINING
2022-11-22 20:34:09,583 INFO:   Starting stage: EVALUATION
2022-11-22 20:34:09,701 INFO:   Done with stage: EVALUATION
2022-11-22 20:34:09,702 INFO:   Leaving out SEQ value Fold_9
2022-11-22 20:34:09,715 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 20:34:09,715 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:34:10,386 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:34:10,386 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:34:10,456 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:34:10,456 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:34:10,457 INFO:     No hyperparam tuning for this model
2022-11-22 20:34:10,457 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:34:10,457 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:34:10,458 INFO:     None feature selector for col prot
2022-11-22 20:34:10,458 INFO:     None feature selector for col prot
2022-11-22 20:34:10,458 INFO:     None feature selector for col prot
2022-11-22 20:34:10,458 INFO:     None feature selector for col chem
2022-11-22 20:34:10,459 INFO:     None feature selector for col chem
2022-11-22 20:34:10,459 INFO:     None feature selector for col chem
2022-11-22 20:34:10,459 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:34:10,459 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:34:10,460 INFO:     Number of params in model 126091
2022-11-22 20:34:10,464 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:34:10,464 INFO:   Starting stage: TRAINING
2022-11-22 20:34:10,513 INFO:     Val loss before train {'Reaction outcome loss': 1.0388828292489052, 'Total loss': 1.0388828292489052}
2022-11-22 20:34:10,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:10,513 INFO:     Epoch: 0
2022-11-22 20:34:11,277 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8336765657771718, 'Total loss': 0.8336765657771718} | train loss {'Reaction outcome loss': 0.8943420894924672, 'Total loss': 0.8943420894924672}
2022-11-22 20:34:11,277 INFO:     Found new best model at epoch 0
2022-11-22 20:34:11,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:11,278 INFO:     Epoch: 1
2022-11-22 20:34:12,048 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.839108104055578, 'Total loss': 0.839108104055578} | train loss {'Reaction outcome loss': 0.8520083684594401, 'Total loss': 0.8520083684594401}
2022-11-22 20:34:12,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:12,049 INFO:     Epoch: 2
2022-11-22 20:34:12,842 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8158149881796404, 'Total loss': 0.8158149881796404} | train loss {'Reaction outcome loss': 0.8443923002529529, 'Total loss': 0.8443923002529529}
2022-11-22 20:34:12,842 INFO:     Found new best model at epoch 2
2022-11-22 20:34:12,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:12,843 INFO:     Epoch: 3
2022-11-22 20:34:13,614 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8196644749153744, 'Total loss': 0.8196644749153744} | train loss {'Reaction outcome loss': 0.8297407567020385, 'Total loss': 0.8297407567020385}
2022-11-22 20:34:13,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:13,614 INFO:     Epoch: 4
2022-11-22 20:34:14,382 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8418645235625181, 'Total loss': 0.8418645235625181} | train loss {'Reaction outcome loss': 0.8268004645022654, 'Total loss': 0.8268004645022654}
2022-11-22 20:34:14,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:14,382 INFO:     Epoch: 5
2022-11-22 20:34:15,119 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7928722290830179, 'Total loss': 0.7928722290830179} | train loss {'Reaction outcome loss': 0.8265696024942782, 'Total loss': 0.8265696024942782}
2022-11-22 20:34:15,119 INFO:     Found new best model at epoch 5
2022-11-22 20:34:15,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:15,120 INFO:     Epoch: 6
2022-11-22 20:34:15,864 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.804225505752997, 'Total loss': 0.804225505752997} | train loss {'Reaction outcome loss': 0.8207396641373634, 'Total loss': 0.8207396641373634}
2022-11-22 20:34:15,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:15,865 INFO:     Epoch: 7
2022-11-22 20:34:16,608 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8026228560642763, 'Total loss': 0.8026228560642763} | train loss {'Reaction outcome loss': 0.8143825449289814, 'Total loss': 0.8143825449289814}
2022-11-22 20:34:16,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:16,608 INFO:     Epoch: 8
2022-11-22 20:34:17,333 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7913837480274114, 'Total loss': 0.7913837480274114} | train loss {'Reaction outcome loss': 0.8217443496349358, 'Total loss': 0.8217443496349358}
2022-11-22 20:34:17,333 INFO:     Found new best model at epoch 8
2022-11-22 20:34:17,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:17,334 INFO:     Epoch: 9
2022-11-22 20:34:18,111 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7998479117046703, 'Total loss': 0.7998479117046703} | train loss {'Reaction outcome loss': 0.8137208968400955, 'Total loss': 0.8137208968400955}
2022-11-22 20:34:18,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:18,111 INFO:     Epoch: 10
2022-11-22 20:34:18,867 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7978778711774133, 'Total loss': 0.7978778711774133} | train loss {'Reaction outcome loss': 0.8108203794446683, 'Total loss': 0.8108203794446683}
2022-11-22 20:34:18,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:18,867 INFO:     Epoch: 11
2022-11-22 20:34:19,586 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8162242458625273, 'Total loss': 0.8162242458625273} | train loss {'Reaction outcome loss': 0.8097275993035685, 'Total loss': 0.8097275993035685}
2022-11-22 20:34:19,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:19,586 INFO:     Epoch: 12
2022-11-22 20:34:20,318 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.800213335589929, 'Total loss': 0.800213335589929} | train loss {'Reaction outcome loss': 0.806985386557156, 'Total loss': 0.806985386557156}
2022-11-22 20:34:20,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:20,319 INFO:     Epoch: 13
2022-11-22 20:34:21,075 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7950201413848184, 'Total loss': 0.7950201413848184} | train loss {'Reaction outcome loss': 0.8071035370230675, 'Total loss': 0.8071035370230675}
2022-11-22 20:34:21,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:21,076 INFO:     Epoch: 14
2022-11-22 20:34:21,833 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7892333418130875, 'Total loss': 0.7892333418130875} | train loss {'Reaction outcome loss': 0.8045781700601501, 'Total loss': 0.8045781700601501}
2022-11-22 20:34:21,833 INFO:     Found new best model at epoch 14
2022-11-22 20:34:21,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:21,834 INFO:     Epoch: 15
2022-11-22 20:34:22,566 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7897478457201611, 'Total loss': 0.7897478457201611} | train loss {'Reaction outcome loss': 0.8081758441703935, 'Total loss': 0.8081758441703935}
2022-11-22 20:34:22,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:22,566 INFO:     Epoch: 16
2022-11-22 20:34:23,326 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7680622393434698, 'Total loss': 0.7680622393434698} | train loss {'Reaction outcome loss': 0.8036223850663631, 'Total loss': 0.8036223850663631}
2022-11-22 20:34:23,326 INFO:     Found new best model at epoch 16
2022-11-22 20:34:23,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:23,327 INFO:     Epoch: 17
2022-11-22 20:34:24,049 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8210530836473812, 'Total loss': 0.8210530836473812} | train loss {'Reaction outcome loss': 0.7983966863924458, 'Total loss': 0.7983966863924458}
2022-11-22 20:34:24,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:24,049 INFO:     Epoch: 18
2022-11-22 20:34:24,792 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8015457825227217, 'Total loss': 0.8015457825227217} | train loss {'Reaction outcome loss': 0.8003862751347404, 'Total loss': 0.8003862751347404}
2022-11-22 20:34:24,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:24,792 INFO:     Epoch: 19
2022-11-22 20:34:25,539 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7780145447362553, 'Total loss': 0.7780145447362553} | train loss {'Reaction outcome loss': 0.8028186260452194, 'Total loss': 0.8028186260452194}
2022-11-22 20:34:25,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:25,539 INFO:     Epoch: 20
2022-11-22 20:34:26,286 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7887180952185934, 'Total loss': 0.7887180952185934} | train loss {'Reaction outcome loss': 0.8014056050489026, 'Total loss': 0.8014056050489026}
2022-11-22 20:34:26,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:26,287 INFO:     Epoch: 21
2022-11-22 20:34:27,003 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7848704321817919, 'Total loss': 0.7848704321817919} | train loss {'Reaction outcome loss': 0.7964637569121776, 'Total loss': 0.7964637569121776}
2022-11-22 20:34:27,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:27,003 INFO:     Epoch: 22
2022-11-22 20:34:27,752 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7789175043051894, 'Total loss': 0.7789175043051894} | train loss {'Reaction outcome loss': 0.7958597175536617, 'Total loss': 0.7958597175536617}
2022-11-22 20:34:27,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:27,752 INFO:     Epoch: 23
2022-11-22 20:34:28,476 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7855210080742836, 'Total loss': 0.7855210080742836} | train loss {'Reaction outcome loss': 0.7895920363164717, 'Total loss': 0.7895920363164717}
2022-11-22 20:34:28,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:28,476 INFO:     Epoch: 24
2022-11-22 20:34:29,202 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8067804270169951, 'Total loss': 0.8067804270169951} | train loss {'Reaction outcome loss': 0.7953469122369443, 'Total loss': 0.7953469122369443}
2022-11-22 20:34:29,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:29,203 INFO:     Epoch: 25
2022-11-22 20:34:29,951 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7929649048230865, 'Total loss': 0.7929649048230865} | train loss {'Reaction outcome loss': 0.7919990268926467, 'Total loss': 0.7919990268926467}
2022-11-22 20:34:29,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:29,951 INFO:     Epoch: 26
2022-11-22 20:34:30,716 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.790256917476654, 'Total loss': 0.790256917476654} | train loss {'Reaction outcome loss': 0.7901467354667764, 'Total loss': 0.7901467354667764}
2022-11-22 20:34:30,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:30,716 INFO:     Epoch: 27
2022-11-22 20:34:31,429 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7808256941762838, 'Total loss': 0.7808256941762838} | train loss {'Reaction outcome loss': 0.7961114849294385, 'Total loss': 0.7961114849294385}
2022-11-22 20:34:31,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:31,431 INFO:     Epoch: 28
2022-11-22 20:34:32,149 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7712550813501532, 'Total loss': 0.7712550813501532} | train loss {'Reaction outcome loss': 0.7971259314687021, 'Total loss': 0.7971259314687021}
2022-11-22 20:34:32,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:32,149 INFO:     Epoch: 29
2022-11-22 20:34:32,907 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7697601318359375, 'Total loss': 0.7697601318359375} | train loss {'Reaction outcome loss': 0.7998202788012643, 'Total loss': 0.7998202788012643}
2022-11-22 20:34:32,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:32,907 INFO:     Epoch: 30
2022-11-22 20:34:33,639 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7751063176176765, 'Total loss': 0.7751063176176765} | train loss {'Reaction outcome loss': 0.7870320383339159, 'Total loss': 0.7870320383339159}
2022-11-22 20:34:33,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:33,639 INFO:     Epoch: 31
2022-11-22 20:34:34,362 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.9177904650568962, 'Total loss': 0.9177904650568962} | train loss {'Reaction outcome loss': 0.7888856519374156, 'Total loss': 0.7888856519374156}
2022-11-22 20:34:34,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:34,362 INFO:     Epoch: 32
2022-11-22 20:34:35,084 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7810077701102603, 'Total loss': 0.7810077701102603} | train loss {'Reaction outcome loss': 0.7897980606123325, 'Total loss': 0.7897980606123325}
2022-11-22 20:34:35,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:35,084 INFO:     Epoch: 33
2022-11-22 20:34:35,825 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7617938403378833, 'Total loss': 0.7617938403378833} | train loss {'Reaction outcome loss': 0.7838471653240342, 'Total loss': 0.7838471653240342}
2022-11-22 20:34:35,825 INFO:     Found new best model at epoch 33
2022-11-22 20:34:35,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:35,826 INFO:     Epoch: 34
2022-11-22 20:34:36,570 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7828254625201225, 'Total loss': 0.7828254625201225} | train loss {'Reaction outcome loss': 0.7886731497222378, 'Total loss': 0.7886731497222378}
2022-11-22 20:34:36,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:36,570 INFO:     Epoch: 35
2022-11-22 20:34:37,334 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7550319135189056, 'Total loss': 0.7550319135189056} | train loss {'Reaction outcome loss': 0.7855212817028645, 'Total loss': 0.7855212817028645}
2022-11-22 20:34:37,335 INFO:     Found new best model at epoch 35
2022-11-22 20:34:37,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:37,335 INFO:     Epoch: 36
2022-11-22 20:34:38,079 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7614354152571071, 'Total loss': 0.7614354152571071} | train loss {'Reaction outcome loss': 0.7852798327803612, 'Total loss': 0.7852798327803612}
2022-11-22 20:34:38,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:38,080 INFO:     Epoch: 37
2022-11-22 20:34:38,804 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7668685750527815, 'Total loss': 0.7668685750527815} | train loss {'Reaction outcome loss': 0.7852556886932542, 'Total loss': 0.7852556886932542}
2022-11-22 20:34:38,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:38,805 INFO:     Epoch: 38
2022-11-22 20:34:39,536 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7711702483621511, 'Total loss': 0.7711702483621511} | train loss {'Reaction outcome loss': 0.7819749752600347, 'Total loss': 0.7819749752600347}
2022-11-22 20:34:39,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:39,537 INFO:     Epoch: 39
2022-11-22 20:34:40,308 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7841695973818953, 'Total loss': 0.7841695973818953} | train loss {'Reaction outcome loss': 0.7813069092169884, 'Total loss': 0.7813069092169884}
2022-11-22 20:34:40,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:40,308 INFO:     Epoch: 40
2022-11-22 20:34:41,017 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7911505529826338, 'Total loss': 0.7911505529826338} | train loss {'Reaction outcome loss': 0.780772075297371, 'Total loss': 0.780772075297371}
2022-11-22 20:34:41,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:41,018 INFO:     Epoch: 41
2022-11-22 20:34:41,768 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8143463581800461, 'Total loss': 0.8143463581800461} | train loss {'Reaction outcome loss': 0.7798823443872314, 'Total loss': 0.7798823443872314}
2022-11-22 20:34:41,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:41,768 INFO:     Epoch: 42
2022-11-22 20:34:42,536 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7797241292216561, 'Total loss': 0.7797241292216561} | train loss {'Reaction outcome loss': 0.7716694719368412, 'Total loss': 0.7716694719368412}
2022-11-22 20:34:42,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:42,537 INFO:     Epoch: 43
2022-11-22 20:34:43,321 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7632618858055635, 'Total loss': 0.7632618858055635} | train loss {'Reaction outcome loss': 0.7730485254958752, 'Total loss': 0.7730485254958752}
2022-11-22 20:34:43,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:43,321 INFO:     Epoch: 44
2022-11-22 20:34:44,118 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8114043501290408, 'Total loss': 0.8114043501290408} | train loss {'Reaction outcome loss': 0.7680005875806655, 'Total loss': 0.7680005875806655}
2022-11-22 20:34:44,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:44,118 INFO:     Epoch: 45
2022-11-22 20:34:44,865 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7920114486054941, 'Total loss': 0.7920114486054941} | train loss {'Reaction outcome loss': 0.7684786894148395, 'Total loss': 0.7684786894148395}
2022-11-22 20:34:44,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:44,865 INFO:     Epoch: 46
2022-11-22 20:34:45,632 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.760872399265116, 'Total loss': 0.760872399265116} | train loss {'Reaction outcome loss': 0.7718515119725659, 'Total loss': 0.7718515119725659}
2022-11-22 20:34:45,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:45,633 INFO:     Epoch: 47
2022-11-22 20:34:46,401 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7456238527189601, 'Total loss': 0.7456238527189601} | train loss {'Reaction outcome loss': 0.7699539711879145, 'Total loss': 0.7699539711879145}
2022-11-22 20:34:46,401 INFO:     Found new best model at epoch 47
2022-11-22 20:34:46,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:46,402 INFO:     Epoch: 48
2022-11-22 20:34:47,167 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7665618522600695, 'Total loss': 0.7665618522600695} | train loss {'Reaction outcome loss': 0.7649884869254404, 'Total loss': 0.7649884869254404}
2022-11-22 20:34:47,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:47,167 INFO:     Epoch: 49
2022-11-22 20:34:47,946 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7500613433393565, 'Total loss': 0.7500613433393565} | train loss {'Reaction outcome loss': 0.7665400489443733, 'Total loss': 0.7665400489443733}
2022-11-22 20:34:47,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:47,947 INFO:     Epoch: 50
2022-11-22 20:34:48,735 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7533100227063353, 'Total loss': 0.7533100227063353} | train loss {'Reaction outcome loss': 0.7630677070588835, 'Total loss': 0.7630677070588835}
2022-11-22 20:34:48,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:48,735 INFO:     Epoch: 51
2022-11-22 20:34:49,539 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7398013032295487, 'Total loss': 0.7398013032295487} | train loss {'Reaction outcome loss': 0.758516131269355, 'Total loss': 0.758516131269355}
2022-11-22 20:34:49,539 INFO:     Found new best model at epoch 51
2022-11-22 20:34:49,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:49,540 INFO:     Epoch: 52
2022-11-22 20:34:50,367 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7574121538888324, 'Total loss': 0.7574121538888324} | train loss {'Reaction outcome loss': 0.7565528252913106, 'Total loss': 0.7565528252913106}
2022-11-22 20:34:50,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:50,368 INFO:     Epoch: 53
2022-11-22 20:34:51,157 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7404478361660783, 'Total loss': 0.7404478361660783} | train loss {'Reaction outcome loss': 0.7518329817441202, 'Total loss': 0.7518329817441202}
2022-11-22 20:34:51,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:51,158 INFO:     Epoch: 54
2022-11-22 20:34:51,914 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.749592050909996, 'Total loss': 0.749592050909996} | train loss {'Reaction outcome loss': 0.7494228404135473, 'Total loss': 0.7494228404135473}
2022-11-22 20:34:51,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:51,914 INFO:     Epoch: 55
2022-11-22 20:34:52,677 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7790911041877486, 'Total loss': 0.7790911041877486} | train loss {'Reaction outcome loss': 0.7530456569886976, 'Total loss': 0.7530456569886976}
2022-11-22 20:34:52,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:52,677 INFO:     Epoch: 56
2022-11-22 20:34:53,417 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.743371990593997, 'Total loss': 0.743371990593997} | train loss {'Reaction outcome loss': 0.7501812263602211, 'Total loss': 0.7501812263602211}
2022-11-22 20:34:53,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:53,417 INFO:     Epoch: 57
2022-11-22 20:34:54,135 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7341699376702309, 'Total loss': 0.7341699376702309} | train loss {'Reaction outcome loss': 0.745553785334191, 'Total loss': 0.745553785334191}
2022-11-22 20:34:54,135 INFO:     Found new best model at epoch 57
2022-11-22 20:34:54,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:54,136 INFO:     Epoch: 58
2022-11-22 20:34:54,873 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7483171644535932, 'Total loss': 0.7483171644535932} | train loss {'Reaction outcome loss': 0.7436141624085365, 'Total loss': 0.7436141624085365}
2022-11-22 20:34:54,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:54,873 INFO:     Epoch: 59
2022-11-22 20:34:55,673 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7228037457574498, 'Total loss': 0.7228037457574498} | train loss {'Reaction outcome loss': 0.7455662292458357, 'Total loss': 0.7455662292458357}
2022-11-22 20:34:55,673 INFO:     Found new best model at epoch 59
2022-11-22 20:34:55,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:55,674 INFO:     Epoch: 60
2022-11-22 20:34:56,454 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7721408659761603, 'Total loss': 0.7721408659761603} | train loss {'Reaction outcome loss': 0.7427503247895548, 'Total loss': 0.7427503247895548}
2022-11-22 20:34:56,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:56,455 INFO:     Epoch: 61
2022-11-22 20:34:57,203 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7197185727682981, 'Total loss': 0.7197185727682981} | train loss {'Reaction outcome loss': 0.7449327811839119, 'Total loss': 0.7449327811839119}
2022-11-22 20:34:57,203 INFO:     Found new best model at epoch 61
2022-11-22 20:34:57,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:57,204 INFO:     Epoch: 62
2022-11-22 20:34:57,981 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7369638579812917, 'Total loss': 0.7369638579812917} | train loss {'Reaction outcome loss': 0.7438303255025418, 'Total loss': 0.7438303255025418}
2022-11-22 20:34:57,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:57,982 INFO:     Epoch: 63
2022-11-22 20:34:58,718 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7105278745293617, 'Total loss': 0.7105278745293617} | train loss {'Reaction outcome loss': 0.7492787324853482, 'Total loss': 0.7492787324853482}
2022-11-22 20:34:58,718 INFO:     Found new best model at epoch 63
2022-11-22 20:34:58,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:58,719 INFO:     Epoch: 64
2022-11-22 20:34:59,511 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7899215512654998, 'Total loss': 0.7899215512654998} | train loss {'Reaction outcome loss': 0.7354613012604175, 'Total loss': 0.7354613012604175}
2022-11-22 20:34:59,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:34:59,511 INFO:     Epoch: 65
2022-11-22 20:35:00,282 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7222864891995083, 'Total loss': 0.7222864891995083} | train loss {'Reaction outcome loss': 0.7396157595419115, 'Total loss': 0.7396157595419115}
2022-11-22 20:35:00,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:00,282 INFO:     Epoch: 66
2022-11-22 20:35:01,026 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7489506297490813, 'Total loss': 0.7489506297490813} | train loss {'Reaction outcome loss': 0.7366692611286717, 'Total loss': 0.7366692611286717}
2022-11-22 20:35:01,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:01,026 INFO:     Epoch: 67
2022-11-22 20:35:01,820 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7238157825036482, 'Total loss': 0.7238157825036482} | train loss {'Reaction outcome loss': 0.7430939262192096, 'Total loss': 0.7430939262192096}
2022-11-22 20:35:01,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:01,821 INFO:     Epoch: 68
2022-11-22 20:35:02,583 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7103639156980948, 'Total loss': 0.7103639156980948} | train loss {'Reaction outcome loss': 0.7304822422804371, 'Total loss': 0.7304822422804371}
2022-11-22 20:35:02,584 INFO:     Found new best model at epoch 68
2022-11-22 20:35:02,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:02,585 INFO:     Epoch: 69
2022-11-22 20:35:03,355 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7427527484568682, 'Total loss': 0.7427527484568682} | train loss {'Reaction outcome loss': 0.7365969236819975, 'Total loss': 0.7365969236819975}
2022-11-22 20:35:03,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:03,355 INFO:     Epoch: 70
2022-11-22 20:35:04,121 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7091880914839831, 'Total loss': 0.7091880914839831} | train loss {'Reaction outcome loss': 0.7338249825782353, 'Total loss': 0.7338249825782353}
2022-11-22 20:35:04,121 INFO:     Found new best model at epoch 70
2022-11-22 20:35:04,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:04,122 INFO:     Epoch: 71
2022-11-22 20:35:04,862 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.6893444975668733, 'Total loss': 0.6893444975668733} | train loss {'Reaction outcome loss': 0.7269296475475834, 'Total loss': 0.7269296475475834}
2022-11-22 20:35:04,862 INFO:     Found new best model at epoch 71
2022-11-22 20:35:04,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:04,863 INFO:     Epoch: 72
2022-11-22 20:35:05,648 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7126613509925929, 'Total loss': 0.7126613509925929} | train loss {'Reaction outcome loss': 0.7292314218657632, 'Total loss': 0.7292314218657632}
2022-11-22 20:35:05,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:05,649 INFO:     Epoch: 73
2022-11-22 20:35:06,399 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7152340208942239, 'Total loss': 0.7152340208942239} | train loss {'Reaction outcome loss': 0.7318601224931979, 'Total loss': 0.7318601224931979}
2022-11-22 20:35:06,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:06,399 INFO:     Epoch: 74
2022-11-22 20:35:07,146 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.75223662907427, 'Total loss': 0.75223662907427} | train loss {'Reaction outcome loss': 0.730345006491388, 'Total loss': 0.730345006491388}
2022-11-22 20:35:07,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:07,147 INFO:     Epoch: 75
2022-11-22 20:35:07,896 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.6894732354716822, 'Total loss': 0.6894732354716822} | train loss {'Reaction outcome loss': 0.7275173974133307, 'Total loss': 0.7275173974133307}
2022-11-22 20:35:07,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:07,896 INFO:     Epoch: 76
2022-11-22 20:35:08,693 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7206876589493318, 'Total loss': 0.7206876589493318} | train loss {'Reaction outcome loss': 0.7279523381542775, 'Total loss': 0.7279523381542775}
2022-11-22 20:35:08,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:08,694 INFO:     Epoch: 77
2022-11-22 20:35:09,431 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7249300100586631, 'Total loss': 0.7249300100586631} | train loss {'Reaction outcome loss': 0.7248585094367305, 'Total loss': 0.7248585094367305}
2022-11-22 20:35:09,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:09,431 INFO:     Epoch: 78
2022-11-22 20:35:10,207 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7173538397658955, 'Total loss': 0.7173538397658955} | train loss {'Reaction outcome loss': 0.723658044732386, 'Total loss': 0.723658044732386}
2022-11-22 20:35:10,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:10,208 INFO:     Epoch: 79
2022-11-22 20:35:10,975 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7556400881572203, 'Total loss': 0.7556400881572203} | train loss {'Reaction outcome loss': 0.724465248205008, 'Total loss': 0.724465248205008}
2022-11-22 20:35:10,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:10,976 INFO:     Epoch: 80
2022-11-22 20:35:11,762 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7126995237036184, 'Total loss': 0.7126995237036184} | train loss {'Reaction outcome loss': 0.728658102452755, 'Total loss': 0.728658102452755}
2022-11-22 20:35:11,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:11,762 INFO:     Epoch: 81
2022-11-22 20:35:12,503 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.719714225015857, 'Total loss': 0.719714225015857} | train loss {'Reaction outcome loss': 0.7263176823335309, 'Total loss': 0.7263176823335309}
2022-11-22 20:35:12,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:12,503 INFO:     Epoch: 82
2022-11-22 20:35:13,320 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7004662650552663, 'Total loss': 0.7004662650552663} | train loss {'Reaction outcome loss': 0.7235144410402544, 'Total loss': 0.7235144410402544}
2022-11-22 20:35:13,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:13,320 INFO:     Epoch: 83
2022-11-22 20:35:14,062 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7287793206897649, 'Total loss': 0.7287793206897649} | train loss {'Reaction outcome loss': 0.7275870436381909, 'Total loss': 0.7275870436381909}
2022-11-22 20:35:14,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:14,062 INFO:     Epoch: 84
2022-11-22 20:35:14,822 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6893191154707562, 'Total loss': 0.6893191154707562} | train loss {'Reaction outcome loss': 0.7171817381055124, 'Total loss': 0.7171817381055124}
2022-11-22 20:35:14,822 INFO:     Found new best model at epoch 84
2022-11-22 20:35:14,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:14,823 INFO:     Epoch: 85
2022-11-22 20:35:15,539 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6975455724380233, 'Total loss': 0.6975455724380233} | train loss {'Reaction outcome loss': 0.7244778833081645, 'Total loss': 0.7244778833081645}
2022-11-22 20:35:15,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:15,539 INFO:     Epoch: 86
2022-11-22 20:35:16,298 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6926093927838586, 'Total loss': 0.6926093927838586} | train loss {'Reaction outcome loss': 0.718210739714484, 'Total loss': 0.718210739714484}
2022-11-22 20:35:16,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:16,299 INFO:     Epoch: 87
2022-11-22 20:35:17,007 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7036055489019915, 'Total loss': 0.7036055489019915} | train loss {'Reaction outcome loss': 0.7167899392905736, 'Total loss': 0.7167899392905736}
2022-11-22 20:35:17,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:17,007 INFO:     Epoch: 88
2022-11-22 20:35:17,764 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.705729594284838, 'Total loss': 0.705729594284838} | train loss {'Reaction outcome loss': 0.7272186251657624, 'Total loss': 0.7272186251657624}
2022-11-22 20:35:17,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:17,764 INFO:     Epoch: 89
2022-11-22 20:35:18,502 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6961878538131714, 'Total loss': 0.6961878538131714} | train loss {'Reaction outcome loss': 0.7117935563287427, 'Total loss': 0.7117935563287427}
2022-11-22 20:35:18,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:18,503 INFO:     Epoch: 90
2022-11-22 20:35:19,259 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6944679103114388, 'Total loss': 0.6944679103114388} | train loss {'Reaction outcome loss': 0.7205525023802635, 'Total loss': 0.7205525023802635}
2022-11-22 20:35:19,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:19,259 INFO:     Epoch: 91
2022-11-22 20:35:20,064 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7399385449561205, 'Total loss': 0.7399385449561205} | train loss {'Reaction outcome loss': 0.7195879861472114, 'Total loss': 0.7195879861472114}
2022-11-22 20:35:20,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:20,064 INFO:     Epoch: 92
2022-11-22 20:35:20,806 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.673379547894001, 'Total loss': 0.673379547894001} | train loss {'Reaction outcome loss': 0.7207937924371611, 'Total loss': 0.7207937924371611}
2022-11-22 20:35:20,806 INFO:     Found new best model at epoch 92
2022-11-22 20:35:20,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:20,807 INFO:     Epoch: 93
2022-11-22 20:35:21,543 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6965682702985677, 'Total loss': 0.6965682702985677} | train loss {'Reaction outcome loss': 0.7107814814775221, 'Total loss': 0.7107814814775221}
2022-11-22 20:35:21,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:21,543 INFO:     Epoch: 94
2022-11-22 20:35:22,296 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7381076406348835, 'Total loss': 0.7381076406348835} | train loss {'Reaction outcome loss': 0.7135669918911111, 'Total loss': 0.7135669918911111}
2022-11-22 20:35:22,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:22,296 INFO:     Epoch: 95
2022-11-22 20:35:23,032 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7059741914272308, 'Total loss': 0.7059741914272308} | train loss {'Reaction outcome loss': 0.7165791572582337, 'Total loss': 0.7165791572582337}
2022-11-22 20:35:23,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:23,032 INFO:     Epoch: 96
2022-11-22 20:35:23,773 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7240892919627103, 'Total loss': 0.7240892919627103} | train loss {'Reaction outcome loss': 0.719146803111559, 'Total loss': 0.719146803111559}
2022-11-22 20:35:23,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:23,773 INFO:     Epoch: 97
2022-11-22 20:35:24,531 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7236615202643655, 'Total loss': 0.7236615202643655} | train loss {'Reaction outcome loss': 0.7163810269726861, 'Total loss': 0.7163810269726861}
2022-11-22 20:35:24,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:24,531 INFO:     Epoch: 98
2022-11-22 20:35:25,246 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7059824832461097, 'Total loss': 0.7059824832461097} | train loss {'Reaction outcome loss': 0.7139759995043278, 'Total loss': 0.7139759995043278}
2022-11-22 20:35:25,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:25,246 INFO:     Epoch: 99
2022-11-22 20:35:25,974 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6937645497647199, 'Total loss': 0.6937645497647199} | train loss {'Reaction outcome loss': 0.7126973523728309, 'Total loss': 0.7126973523728309}
2022-11-22 20:35:25,974 INFO:     Best model found after epoch 93 of 100.
2022-11-22 20:35:25,974 INFO:   Done with stage: TRAINING
2022-11-22 20:35:25,974 INFO:   Starting stage: EVALUATION
2022-11-22 20:35:26,088 INFO:   Done with stage: EVALUATION
2022-11-22 20:35:26,096 INFO:   Leaving out SEQ value Fold_0
2022-11-22 20:35:26,109 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:35:26,110 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:35:26,776 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:35:26,776 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:35:26,844 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:35:26,845 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:35:26,845 INFO:     No hyperparam tuning for this model
2022-11-22 20:35:26,845 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:35:26,845 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:35:26,846 INFO:     None feature selector for col prot
2022-11-22 20:35:26,846 INFO:     None feature selector for col prot
2022-11-22 20:35:26,846 INFO:     None feature selector for col prot
2022-11-22 20:35:26,846 INFO:     None feature selector for col chem
2022-11-22 20:35:26,847 INFO:     None feature selector for col chem
2022-11-22 20:35:26,847 INFO:     None feature selector for col chem
2022-11-22 20:35:26,847 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:35:26,847 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:35:26,848 INFO:     Number of params in model 126091
2022-11-22 20:35:26,851 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:35:26,852 INFO:   Starting stage: TRAINING
2022-11-22 20:35:26,901 INFO:     Val loss before train {'Reaction outcome loss': 0.9860628504644741, 'Total loss': 0.9860628504644741}
2022-11-22 20:35:26,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:26,901 INFO:     Epoch: 0
2022-11-22 20:35:27,652 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8417362123727798, 'Total loss': 0.8417362123727798} | train loss {'Reaction outcome loss': 0.8667866677654033, 'Total loss': 0.8667866677654033}
2022-11-22 20:35:27,652 INFO:     Found new best model at epoch 0
2022-11-22 20:35:27,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:27,653 INFO:     Epoch: 1
2022-11-22 20:35:28,379 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8493332686749372, 'Total loss': 0.8493332686749372} | train loss {'Reaction outcome loss': 0.8287017735899711, 'Total loss': 0.8287017735899711}
2022-11-22 20:35:28,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:28,379 INFO:     Epoch: 2
2022-11-22 20:35:29,114 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8314252976666797, 'Total loss': 0.8314252976666797} | train loss {'Reaction outcome loss': 0.8281494501902132, 'Total loss': 0.8281494501902132}
2022-11-22 20:35:29,114 INFO:     Found new best model at epoch 2
2022-11-22 20:35:29,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:29,115 INFO:     Epoch: 3
2022-11-22 20:35:29,831 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8442747321995822, 'Total loss': 0.8442747321995822} | train loss {'Reaction outcome loss': 0.8153405156670784, 'Total loss': 0.8153405156670784}
2022-11-22 20:35:29,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:29,831 INFO:     Epoch: 4
2022-11-22 20:35:30,565 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8079703443429687, 'Total loss': 0.8079703443429687} | train loss {'Reaction outcome loss': 0.8105144163783715, 'Total loss': 0.8105144163783715}
2022-11-22 20:35:30,565 INFO:     Found new best model at epoch 4
2022-11-22 20:35:30,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:30,566 INFO:     Epoch: 5
2022-11-22 20:35:31,335 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8189805895090103, 'Total loss': 0.8189805895090103} | train loss {'Reaction outcome loss': 0.8057337601574099, 'Total loss': 0.8057337601574099}
2022-11-22 20:35:31,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:31,335 INFO:     Epoch: 6
2022-11-22 20:35:32,121 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8392623012716119, 'Total loss': 0.8392623012716119} | train loss {'Reaction outcome loss': 0.7997116916033686, 'Total loss': 0.7997116916033686}
2022-11-22 20:35:32,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:32,121 INFO:     Epoch: 7
2022-11-22 20:35:32,903 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7819474976171147, 'Total loss': 0.7819474976171147} | train loss {'Reaction outcome loss': 0.7993954276552006, 'Total loss': 0.7993954276552006}
2022-11-22 20:35:32,904 INFO:     Found new best model at epoch 7
2022-11-22 20:35:32,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:32,904 INFO:     Epoch: 8
2022-11-22 20:35:33,682 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8117777888070453, 'Total loss': 0.8117777888070453} | train loss {'Reaction outcome loss': 0.7935473125808093, 'Total loss': 0.7935473125808093}
2022-11-22 20:35:33,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:33,683 INFO:     Epoch: 9
2022-11-22 20:35:34,441 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8151658184149049, 'Total loss': 0.8151658184149049} | train loss {'Reaction outcome loss': 0.7984145845685686, 'Total loss': 0.7984145845685686}
2022-11-22 20:35:34,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:34,442 INFO:     Epoch: 10
2022-11-22 20:35:35,156 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7909452827139334, 'Total loss': 0.7909452827139334} | train loss {'Reaction outcome loss': 0.7935901329225423, 'Total loss': 0.7935901329225423}
2022-11-22 20:35:35,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:35,156 INFO:     Epoch: 11
2022-11-22 20:35:35,900 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7969713075594469, 'Total loss': 0.7969713075594469} | train loss {'Reaction outcome loss': 0.7919076904958608, 'Total loss': 0.7919076904958608}
2022-11-22 20:35:35,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:35,901 INFO:     Epoch: 12
2022-11-22 20:35:36,702 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8241717050021345, 'Total loss': 0.8241717050021345} | train loss {'Reaction outcome loss': 0.7926503006292849, 'Total loss': 0.7926503006292849}
2022-11-22 20:35:36,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:36,702 INFO:     Epoch: 13
2022-11-22 20:35:37,457 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8159496933221817, 'Total loss': 0.8159496933221817} | train loss {'Reaction outcome loss': 0.7864068723454767, 'Total loss': 0.7864068723454767}
2022-11-22 20:35:37,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:37,458 INFO:     Epoch: 14
2022-11-22 20:35:38,200 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8272285800088536, 'Total loss': 0.8272285800088536} | train loss {'Reaction outcome loss': 0.7848687726624158, 'Total loss': 0.7848687726624158}
2022-11-22 20:35:38,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:38,200 INFO:     Epoch: 15
2022-11-22 20:35:38,921 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8001188737424937, 'Total loss': 0.8001188737424937} | train loss {'Reaction outcome loss': 0.7866193676481441, 'Total loss': 0.7866193676481441}
2022-11-22 20:35:38,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:38,921 INFO:     Epoch: 16
2022-11-22 20:35:39,664 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8094735457138582, 'Total loss': 0.8094735457138582} | train loss {'Reaction outcome loss': 0.7892954536846706, 'Total loss': 0.7892954536846706}
2022-11-22 20:35:39,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:39,664 INFO:     Epoch: 17
2022-11-22 20:35:40,399 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7837264442985709, 'Total loss': 0.7837264442985709} | train loss {'Reaction outcome loss': 0.7885349768765119, 'Total loss': 0.7885349768765119}
2022-11-22 20:35:40,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:40,400 INFO:     Epoch: 18
2022-11-22 20:35:41,153 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7912542298436165, 'Total loss': 0.7912542298436165} | train loss {'Reaction outcome loss': 0.7873820795088399, 'Total loss': 0.7873820795088399}
2022-11-22 20:35:41,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:41,153 INFO:     Epoch: 19
2022-11-22 20:35:41,935 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8213579363443635, 'Total loss': 0.8213579363443635} | train loss {'Reaction outcome loss': 0.7811768816441905, 'Total loss': 0.7811768816441905}
2022-11-22 20:35:41,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:41,935 INFO:     Epoch: 20
2022-11-22 20:35:42,684 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7979474358937957, 'Total loss': 0.7979474358937957} | train loss {'Reaction outcome loss': 0.7855947695216354, 'Total loss': 0.7855947695216354}
2022-11-22 20:35:42,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:42,684 INFO:     Epoch: 21
2022-11-22 20:35:43,424 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8010135238820856, 'Total loss': 0.8010135238820856} | train loss {'Reaction outcome loss': 0.7874295527837715, 'Total loss': 0.7874295527837715}
2022-11-22 20:35:43,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:43,425 INFO:     Epoch: 22
2022-11-22 20:35:44,178 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7915530773726377, 'Total loss': 0.7915530773726377} | train loss {'Reaction outcome loss': 0.7802842742326308, 'Total loss': 0.7802842742326308}
2022-11-22 20:35:44,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:44,178 INFO:     Epoch: 23
2022-11-22 20:35:44,895 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7940854260867293, 'Total loss': 0.7940854260867293} | train loss {'Reaction outcome loss': 0.7854894035932969, 'Total loss': 0.7854894035932969}
2022-11-22 20:35:44,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:44,895 INFO:     Epoch: 24
2022-11-22 20:35:45,616 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7968017926270311, 'Total loss': 0.7968017926270311} | train loss {'Reaction outcome loss': 0.7810062505760972, 'Total loss': 0.7810062505760972}
2022-11-22 20:35:45,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:45,616 INFO:     Epoch: 25
2022-11-22 20:35:46,393 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.789417453110218, 'Total loss': 0.789417453110218} | train loss {'Reaction outcome loss': 0.7822033297042458, 'Total loss': 0.7822033297042458}
2022-11-22 20:35:46,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:46,393 INFO:     Epoch: 26
2022-11-22 20:35:47,165 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8235863027247515, 'Total loss': 0.8235863027247515} | train loss {'Reaction outcome loss': 0.7781951358123701, 'Total loss': 0.7781951358123701}
2022-11-22 20:35:47,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:47,166 INFO:     Epoch: 27
2022-11-22 20:35:47,919 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7754229618744417, 'Total loss': 0.7754229618744417} | train loss {'Reaction outcome loss': 0.7832477218034316, 'Total loss': 0.7832477218034316}
2022-11-22 20:35:47,919 INFO:     Found new best model at epoch 27
2022-11-22 20:35:47,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:47,920 INFO:     Epoch: 28
2022-11-22 20:35:48,684 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8042584230953996, 'Total loss': 0.8042584230953996} | train loss {'Reaction outcome loss': 0.779911818188064, 'Total loss': 0.779911818188064}
2022-11-22 20:35:48,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:48,685 INFO:     Epoch: 29
2022-11-22 20:35:49,427 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7740438025106083, 'Total loss': 0.7740438025106083} | train loss {'Reaction outcome loss': 0.7796462880105388, 'Total loss': 0.7796462880105388}
2022-11-22 20:35:49,427 INFO:     Found new best model at epoch 29
2022-11-22 20:35:49,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:49,428 INFO:     Epoch: 30
2022-11-22 20:35:50,155 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7824042669751428, 'Total loss': 0.7824042669751428} | train loss {'Reaction outcome loss': 0.785491408742204, 'Total loss': 0.785491408742204}
2022-11-22 20:35:50,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:50,156 INFO:     Epoch: 31
2022-11-22 20:35:50,925 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8029947545040738, 'Total loss': 0.8029947545040738} | train loss {'Reaction outcome loss': 0.7829337208854908, 'Total loss': 0.7829337208854908}
2022-11-22 20:35:50,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:50,926 INFO:     Epoch: 32
2022-11-22 20:35:51,701 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7677257372574373, 'Total loss': 0.7677257372574373} | train loss {'Reaction outcome loss': 0.7803110310009548, 'Total loss': 0.7803110310009548}
2022-11-22 20:35:51,701 INFO:     Found new best model at epoch 32
2022-11-22 20:35:51,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:51,702 INFO:     Epoch: 33
2022-11-22 20:35:52,438 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7849932102994486, 'Total loss': 0.7849932102994486} | train loss {'Reaction outcome loss': 0.7800910185794441, 'Total loss': 0.7800910185794441}
2022-11-22 20:35:52,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:52,439 INFO:     Epoch: 34
2022-11-22 20:35:53,205 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7885300049727614, 'Total loss': 0.7885300049727614} | train loss {'Reaction outcome loss': 0.7815840797764915, 'Total loss': 0.7815840797764915}
2022-11-22 20:35:53,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:53,205 INFO:     Epoch: 35
2022-11-22 20:35:54,002 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7719861384142529, 'Total loss': 0.7719861384142529} | train loss {'Reaction outcome loss': 0.7771441417081015, 'Total loss': 0.7771441417081015}
2022-11-22 20:35:54,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:54,002 INFO:     Epoch: 36
2022-11-22 20:35:54,764 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7896783182566817, 'Total loss': 0.7896783182566817} | train loss {'Reaction outcome loss': 0.7785720535687037, 'Total loss': 0.7785720535687037}
2022-11-22 20:35:54,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:54,764 INFO:     Epoch: 37
2022-11-22 20:35:55,483 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8081531429832632, 'Total loss': 0.8081531429832632} | train loss {'Reaction outcome loss': 0.7758136898887401, 'Total loss': 0.7758136898887401}
2022-11-22 20:35:55,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:55,483 INFO:     Epoch: 38
2022-11-22 20:35:56,229 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7926435240290381, 'Total loss': 0.7926435240290381} | train loss {'Reaction outcome loss': 0.7792187414607223, 'Total loss': 0.7792187414607223}
2022-11-22 20:35:56,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:56,230 INFO:     Epoch: 39
2022-11-22 20:35:56,963 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7990088225765661, 'Total loss': 0.7990088225765661} | train loss {'Reaction outcome loss': 0.7788360542180587, 'Total loss': 0.7788360542180587}
2022-11-22 20:35:56,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:56,963 INFO:     Epoch: 40
2022-11-22 20:35:57,713 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.787255428054116, 'Total loss': 0.787255428054116} | train loss {'Reaction outcome loss': 0.7795872583681224, 'Total loss': 0.7795872583681224}
2022-11-22 20:35:57,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:57,713 INFO:     Epoch: 41
2022-11-22 20:35:58,452 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7758425697684288, 'Total loss': 0.7758425697684288} | train loss {'Reaction outcome loss': 0.7848776531462767, 'Total loss': 0.7848776531462767}
2022-11-22 20:35:58,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:58,452 INFO:     Epoch: 42
2022-11-22 20:35:59,182 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7862992279908874, 'Total loss': 0.7862992279908874} | train loss {'Reaction outcome loss': 0.7716561198234558, 'Total loss': 0.7716561198234558}
2022-11-22 20:35:59,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:59,182 INFO:     Epoch: 43
2022-11-22 20:35:59,974 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8018265149810098, 'Total loss': 0.8018265149810098} | train loss {'Reaction outcome loss': 0.7741196853773934, 'Total loss': 0.7741196853773934}
2022-11-22 20:35:59,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:35:59,974 INFO:     Epoch: 44
2022-11-22 20:36:00,811 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7944240075620738, 'Total loss': 0.7944240075620738} | train loss {'Reaction outcome loss': 0.7719713226873047, 'Total loss': 0.7719713226873047}
2022-11-22 20:36:00,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:00,811 INFO:     Epoch: 45
2022-11-22 20:36:01,598 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7721352069215341, 'Total loss': 0.7721352069215341} | train loss {'Reaction outcome loss': 0.7777391827836329, 'Total loss': 0.7777391827836329}
2022-11-22 20:36:01,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:01,599 INFO:     Epoch: 46
2022-11-22 20:36:02,357 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7729991803115065, 'Total loss': 0.7729991803115065} | train loss {'Reaction outcome loss': 0.770594558180595, 'Total loss': 0.770594558180595}
2022-11-22 20:36:02,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:02,358 INFO:     Epoch: 47
2022-11-22 20:36:03,155 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7964346334338188, 'Total loss': 0.7964346334338188} | train loss {'Reaction outcome loss': 0.7660977355071477, 'Total loss': 0.7660977355071477}
2022-11-22 20:36:03,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:03,156 INFO:     Epoch: 48
2022-11-22 20:36:03,965 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7683793902397156, 'Total loss': 0.7683793902397156} | train loss {'Reaction outcome loss': 0.7736938783100673, 'Total loss': 0.7736938783100673}
2022-11-22 20:36:03,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:03,965 INFO:     Epoch: 49
2022-11-22 20:36:04,718 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7950793017040599, 'Total loss': 0.7950793017040599} | train loss {'Reaction outcome loss': 0.7738531354738741, 'Total loss': 0.7738531354738741}
2022-11-22 20:36:04,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:04,719 INFO:     Epoch: 50
2022-11-22 20:36:05,458 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8077850233424794, 'Total loss': 0.8077850233424794} | train loss {'Reaction outcome loss': 0.771347262543075, 'Total loss': 0.771347262543075}
2022-11-22 20:36:05,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:05,458 INFO:     Epoch: 51
2022-11-22 20:36:06,212 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7819818922064521, 'Total loss': 0.7819818922064521} | train loss {'Reaction outcome loss': 0.7744059479966455, 'Total loss': 0.7744059479966455}
2022-11-22 20:36:06,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:06,212 INFO:     Epoch: 52
2022-11-22 20:36:06,947 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7728272920305078, 'Total loss': 0.7728272920305078} | train loss {'Reaction outcome loss': 0.7695193480472176, 'Total loss': 0.7695193480472176}
2022-11-22 20:36:06,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:06,947 INFO:     Epoch: 53
2022-11-22 20:36:07,722 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.792488931254907, 'Total loss': 0.792488931254907} | train loss {'Reaction outcome loss': 0.7664684472643599, 'Total loss': 0.7664684472643599}
2022-11-22 20:36:07,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:07,722 INFO:     Epoch: 54
2022-11-22 20:36:08,431 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7607941627502441, 'Total loss': 0.7607941627502441} | train loss {'Reaction outcome loss': 0.7759491846269491, 'Total loss': 0.7759491846269491}
2022-11-22 20:36:08,431 INFO:     Found new best model at epoch 54
2022-11-22 20:36:08,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:08,432 INFO:     Epoch: 55
2022-11-22 20:36:09,180 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7866451096805659, 'Total loss': 0.7866451096805659} | train loss {'Reaction outcome loss': 0.7641049201391181, 'Total loss': 0.7641049201391181}
2022-11-22 20:36:09,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:09,180 INFO:     Epoch: 56
2022-11-22 20:36:09,950 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7751473513516512, 'Total loss': 0.7751473513516512} | train loss {'Reaction outcome loss': 0.7648455415453229, 'Total loss': 0.7648455415453229}
2022-11-22 20:36:09,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:09,950 INFO:     Epoch: 57
2022-11-22 20:36:10,718 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7766591950573705, 'Total loss': 0.7766591950573705} | train loss {'Reaction outcome loss': 0.7660198534021572, 'Total loss': 0.7660198534021572}
2022-11-22 20:36:10,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:10,719 INFO:     Epoch: 58
2022-11-22 20:36:11,498 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7797515175559304, 'Total loss': 0.7797515175559304} | train loss {'Reaction outcome loss': 0.7656727056114041, 'Total loss': 0.7656727056114041}
2022-11-22 20:36:11,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:11,499 INFO:     Epoch: 59
2022-11-22 20:36:12,253 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7877440357750113, 'Total loss': 0.7877440357750113} | train loss {'Reaction outcome loss': 0.7698322114895801, 'Total loss': 0.7698322114895801}
2022-11-22 20:36:12,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:12,254 INFO:     Epoch: 60
2022-11-22 20:36:12,975 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7736284211277962, 'Total loss': 0.7736284211277962} | train loss {'Reaction outcome loss': 0.7658785675253187, 'Total loss': 0.7658785675253187}
2022-11-22 20:36:12,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:12,975 INFO:     Epoch: 61
2022-11-22 20:36:13,678 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7596044039184396, 'Total loss': 0.7596044039184396} | train loss {'Reaction outcome loss': 0.7593762624020479, 'Total loss': 0.7593762624020479}
2022-11-22 20:36:13,678 INFO:     Found new best model at epoch 61
2022-11-22 20:36:13,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:13,679 INFO:     Epoch: 62
2022-11-22 20:36:14,477 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7658316445621577, 'Total loss': 0.7658316445621577} | train loss {'Reaction outcome loss': 0.7685132496210993, 'Total loss': 0.7685132496210993}
2022-11-22 20:36:14,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:14,477 INFO:     Epoch: 63
2022-11-22 20:36:15,218 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7843182682991028, 'Total loss': 0.7843182682991028} | train loss {'Reaction outcome loss': 0.7575604936298059, 'Total loss': 0.7575604936298059}
2022-11-22 20:36:15,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:15,219 INFO:     Epoch: 64
2022-11-22 20:36:15,941 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7638831775296818, 'Total loss': 0.7638831775296818} | train loss {'Reaction outcome loss': 0.763094591729495, 'Total loss': 0.763094591729495}
2022-11-22 20:36:15,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:15,941 INFO:     Epoch: 65
2022-11-22 20:36:16,683 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7741999443281781, 'Total loss': 0.7741999443281781} | train loss {'Reaction outcome loss': 0.7549274909253023, 'Total loss': 0.7549274909253023}
2022-11-22 20:36:16,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:16,683 INFO:     Epoch: 66
2022-11-22 20:36:17,478 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7611092423850839, 'Total loss': 0.7611092423850839} | train loss {'Reaction outcome loss': 0.756951539978689, 'Total loss': 0.756951539978689}
2022-11-22 20:36:17,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:17,478 INFO:     Epoch: 67
2022-11-22 20:36:18,228 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7871573242274198, 'Total loss': 0.7871573242274198} | train loss {'Reaction outcome loss': 0.752162496897639, 'Total loss': 0.752162496897639}
2022-11-22 20:36:18,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:18,229 INFO:     Epoch: 68
2022-11-22 20:36:18,941 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7464873225174167, 'Total loss': 0.7464873225174167} | train loss {'Reaction outcome loss': 0.7524675584569269, 'Total loss': 0.7524675584569269}
2022-11-22 20:36:18,942 INFO:     Found new best model at epoch 68
2022-11-22 20:36:18,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:18,942 INFO:     Epoch: 69
2022-11-22 20:36:19,699 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7525320425629616, 'Total loss': 0.7525320425629616} | train loss {'Reaction outcome loss': 0.7532211325606522, 'Total loss': 0.7532211325606522}
2022-11-22 20:36:19,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:19,700 INFO:     Epoch: 70
2022-11-22 20:36:20,409 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.779421172358773, 'Total loss': 0.779421172358773} | train loss {'Reaction outcome loss': 0.7550214591074963, 'Total loss': 0.7550214591074963}
2022-11-22 20:36:20,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:20,409 INFO:     Epoch: 71
2022-11-22 20:36:21,175 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.745312637226148, 'Total loss': 0.745312637226148} | train loss {'Reaction outcome loss': 0.7444515572518718, 'Total loss': 0.7444515572518718}
2022-11-22 20:36:21,176 INFO:     Found new best model at epoch 71
2022-11-22 20:36:21,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:21,176 INFO:     Epoch: 72
2022-11-22 20:36:21,972 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7468514327298511, 'Total loss': 0.7468514327298511} | train loss {'Reaction outcome loss': 0.7453923024693314, 'Total loss': 0.7453923024693314}
2022-11-22 20:36:21,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:21,972 INFO:     Epoch: 73
2022-11-22 20:36:22,720 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7838052368976853, 'Total loss': 0.7838052368976853} | train loss {'Reaction outcome loss': 0.7425217874804322, 'Total loss': 0.7425217874804322}
2022-11-22 20:36:22,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:22,721 INFO:     Epoch: 74
2022-11-22 20:36:23,464 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7489270642399788, 'Total loss': 0.7489270642399788} | train loss {'Reaction outcome loss': 0.7470602425993705, 'Total loss': 0.7470602425993705}
2022-11-22 20:36:23,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:23,464 INFO:     Epoch: 75
2022-11-22 20:36:24,242 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7679813531312075, 'Total loss': 0.7679813531312075} | train loss {'Reaction outcome loss': 0.7408026798647277, 'Total loss': 0.7408026798647277}
2022-11-22 20:36:24,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:24,243 INFO:     Epoch: 76
2022-11-22 20:36:25,021 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7455016272989187, 'Total loss': 0.7455016272989187} | train loss {'Reaction outcome loss': 0.7350538814554409, 'Total loss': 0.7350538814554409}
2022-11-22 20:36:25,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:25,022 INFO:     Epoch: 77
2022-11-22 20:36:25,759 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7433040446855805, 'Total loss': 0.7433040446855805} | train loss {'Reaction outcome loss': 0.7327972532535086, 'Total loss': 0.7327972532535086}
2022-11-22 20:36:25,759 INFO:     Found new best model at epoch 77
2022-11-22 20:36:25,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:25,760 INFO:     Epoch: 78
2022-11-22 20:36:26,526 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7486325238238681, 'Total loss': 0.7486325238238681} | train loss {'Reaction outcome loss': 0.7318430726017271, 'Total loss': 0.7318430726017271}
2022-11-22 20:36:26,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:26,527 INFO:     Epoch: 79
2022-11-22 20:36:27,272 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.772422478618947, 'Total loss': 0.772422478618947} | train loss {'Reaction outcome loss': 0.7293298852686979, 'Total loss': 0.7293298852686979}
2022-11-22 20:36:27,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:27,272 INFO:     Epoch: 80
2022-11-22 20:36:28,015 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.724211377853697, 'Total loss': 0.724211377853697} | train loss {'Reaction outcome loss': 0.729871912026892, 'Total loss': 0.729871912026892}
2022-11-22 20:36:28,015 INFO:     Found new best model at epoch 80
2022-11-22 20:36:28,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:28,016 INFO:     Epoch: 81
2022-11-22 20:36:28,732 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7413501387292688, 'Total loss': 0.7413501387292688} | train loss {'Reaction outcome loss': 0.72848989878382, 'Total loss': 0.72848989878382}
2022-11-22 20:36:28,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:28,732 INFO:     Epoch: 82
2022-11-22 20:36:29,491 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7569122233174064, 'Total loss': 0.7569122233174064} | train loss {'Reaction outcome loss': 0.7287690729511027, 'Total loss': 0.7287690729511027}
2022-11-22 20:36:29,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:29,491 INFO:     Epoch: 83
2022-11-22 20:36:30,271 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7350872118364681, 'Total loss': 0.7350872118364681} | train loss {'Reaction outcome loss': 0.7299156039345022, 'Total loss': 0.7299156039345022}
2022-11-22 20:36:30,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:30,271 INFO:     Epoch: 84
2022-11-22 20:36:31,020 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7471507062966173, 'Total loss': 0.7471507062966173} | train loss {'Reaction outcome loss': 0.7217515171182399, 'Total loss': 0.7217515171182399}
2022-11-22 20:36:31,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:31,021 INFO:     Epoch: 85
2022-11-22 20:36:31,760 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7649971395730972, 'Total loss': 0.7649971395730972} | train loss {'Reaction outcome loss': 0.7264786356565903, 'Total loss': 0.7264786356565903}
2022-11-22 20:36:31,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:31,760 INFO:     Epoch: 86
2022-11-22 20:36:32,559 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7140660739757798, 'Total loss': 0.7140660739757798} | train loss {'Reaction outcome loss': 0.721170242221988, 'Total loss': 0.721170242221988}
2022-11-22 20:36:32,559 INFO:     Found new best model at epoch 86
2022-11-22 20:36:32,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:32,560 INFO:     Epoch: 87
2022-11-22 20:36:33,304 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7383135977116498, 'Total loss': 0.7383135977116498} | train loss {'Reaction outcome loss': 0.7255558661052159, 'Total loss': 0.7255558661052159}
2022-11-22 20:36:33,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:33,304 INFO:     Epoch: 88
2022-11-22 20:36:34,004 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7464233399792151, 'Total loss': 0.7464233399792151} | train loss {'Reaction outcome loss': 0.7332871798349887, 'Total loss': 0.7332871798349887}
2022-11-22 20:36:34,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:34,005 INFO:     Epoch: 89
2022-11-22 20:36:34,775 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7347299084067345, 'Total loss': 0.7347299084067345} | train loss {'Reaction outcome loss': 0.726762505331818, 'Total loss': 0.726762505331818}
2022-11-22 20:36:34,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:34,775 INFO:     Epoch: 90
2022-11-22 20:36:35,566 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7440819652243094, 'Total loss': 0.7440819652243094} | train loss {'Reaction outcome loss': 0.7310765052328304, 'Total loss': 0.7310765052328304}
2022-11-22 20:36:35,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:35,567 INFO:     Epoch: 91
2022-11-22 20:36:36,320 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7323600649833679, 'Total loss': 0.7323600649833679} | train loss {'Reaction outcome loss': 0.7227022886276245, 'Total loss': 0.7227022886276245}
2022-11-22 20:36:36,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:36,321 INFO:     Epoch: 92
2022-11-22 20:36:37,073 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7397825535048138, 'Total loss': 0.7397825535048138} | train loss {'Reaction outcome loss': 0.7205287421236233, 'Total loss': 0.7205287421236233}
2022-11-22 20:36:37,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:37,074 INFO:     Epoch: 93
2022-11-22 20:36:37,868 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7780555601824414, 'Total loss': 0.7780555601824414} | train loss {'Reaction outcome loss': 0.7133138696149904, 'Total loss': 0.7133138696149904}
2022-11-22 20:36:37,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:37,868 INFO:     Epoch: 94
2022-11-22 20:36:38,627 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.781834137710658, 'Total loss': 0.781834137710658} | train loss {'Reaction outcome loss': 0.7178615084716252, 'Total loss': 0.7178615084716252}
2022-11-22 20:36:38,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:38,627 INFO:     Epoch: 95
2022-11-22 20:36:39,405 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7720070535486395, 'Total loss': 0.7720070535486395} | train loss {'Reaction outcome loss': 0.721119776185678, 'Total loss': 0.721119776185678}
2022-11-22 20:36:39,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:39,406 INFO:     Epoch: 96
2022-11-22 20:36:40,124 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7312144284898584, 'Total loss': 0.7312144284898584} | train loss {'Reaction outcome loss': 0.7206303507697825, 'Total loss': 0.7206303507697825}
2022-11-22 20:36:40,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:40,124 INFO:     Epoch: 97
2022-11-22 20:36:40,871 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7550537518479608, 'Total loss': 0.7550537518479608} | train loss {'Reaction outcome loss': 0.7133137729703164, 'Total loss': 0.7133137729703164}
2022-11-22 20:36:40,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:40,872 INFO:     Epoch: 98
2022-11-22 20:36:41,638 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7583018900318579, 'Total loss': 0.7583018900318579} | train loss {'Reaction outcome loss': 0.723234492053791, 'Total loss': 0.723234492053791}
2022-11-22 20:36:41,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:41,639 INFO:     Epoch: 99
2022-11-22 20:36:42,401 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7203103737397627, 'Total loss': 0.7203103737397627} | train loss {'Reaction outcome loss': 0.7158166329471433, 'Total loss': 0.7158166329471433}
2022-11-22 20:36:42,401 INFO:     Best model found after epoch 87 of 100.
2022-11-22 20:36:42,401 INFO:   Done with stage: TRAINING
2022-11-22 20:36:42,402 INFO:   Starting stage: EVALUATION
2022-11-22 20:36:42,529 INFO:   Done with stage: EVALUATION
2022-11-22 20:36:42,529 INFO:   Leaving out SEQ value Fold_1
2022-11-22 20:36:42,542 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-22 20:36:42,543 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:36:43,203 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:36:43,203 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:36:43,272 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:36:43,272 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:36:43,272 INFO:     No hyperparam tuning for this model
2022-11-22 20:36:43,272 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:36:43,272 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:36:43,273 INFO:     None feature selector for col prot
2022-11-22 20:36:43,273 INFO:     None feature selector for col prot
2022-11-22 20:36:43,273 INFO:     None feature selector for col prot
2022-11-22 20:36:43,274 INFO:     None feature selector for col chem
2022-11-22 20:36:43,274 INFO:     None feature selector for col chem
2022-11-22 20:36:43,274 INFO:     None feature selector for col chem
2022-11-22 20:36:43,274 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:36:43,274 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:36:43,275 INFO:     Number of params in model 126091
2022-11-22 20:36:43,278 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:36:43,278 INFO:   Starting stage: TRAINING
2022-11-22 20:36:43,327 INFO:     Val loss before train {'Reaction outcome loss': 1.0142253484836845, 'Total loss': 1.0142253484836845}
2022-11-22 20:36:43,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:43,327 INFO:     Epoch: 0
2022-11-22 20:36:44,060 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8316400605578755, 'Total loss': 0.8316400605578755} | train loss {'Reaction outcome loss': 0.8796962973021676, 'Total loss': 0.8796962973021676}
2022-11-22 20:36:44,061 INFO:     Found new best model at epoch 0
2022-11-22 20:36:44,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:44,062 INFO:     Epoch: 1
2022-11-22 20:36:44,786 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8336088740548422, 'Total loss': 0.8336088740548422} | train loss {'Reaction outcome loss': 0.8379687868028021, 'Total loss': 0.8379687868028021}
2022-11-22 20:36:44,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:44,786 INFO:     Epoch: 2
2022-11-22 20:36:45,530 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8254756206689879, 'Total loss': 0.8254756206689879} | train loss {'Reaction outcome loss': 0.8317902643739441, 'Total loss': 0.8317902643739441}
2022-11-22 20:36:45,530 INFO:     Found new best model at epoch 2
2022-11-22 20:36:45,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:45,531 INFO:     Epoch: 3
2022-11-22 20:36:46,264 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8366977641748827, 'Total loss': 0.8366977641748827} | train loss {'Reaction outcome loss': 0.8221526879342005, 'Total loss': 0.8221526879342005}
2022-11-22 20:36:46,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:46,265 INFO:     Epoch: 4
2022-11-22 20:36:47,008 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.831916622644247, 'Total loss': 0.831916622644247} | train loss {'Reaction outcome loss': 0.8149888383017646, 'Total loss': 0.8149888383017646}
2022-11-22 20:36:47,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:47,008 INFO:     Epoch: 5
2022-11-22 20:36:47,762 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.819882943186649, 'Total loss': 0.819882943186649} | train loss {'Reaction outcome loss': 0.8152056987638827, 'Total loss': 0.8152056987638827}
2022-11-22 20:36:47,762 INFO:     Found new best model at epoch 5
2022-11-22 20:36:47,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:47,763 INFO:     Epoch: 6
2022-11-22 20:36:48,475 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8036980920059736, 'Total loss': 0.8036980920059736} | train loss {'Reaction outcome loss': 0.8069401515854729, 'Total loss': 0.8069401515854729}
2022-11-22 20:36:48,475 INFO:     Found new best model at epoch 6
2022-11-22 20:36:48,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:48,476 INFO:     Epoch: 7
2022-11-22 20:36:49,184 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.835955445156541, 'Total loss': 0.835955445156541} | train loss {'Reaction outcome loss': 0.8074047018471078, 'Total loss': 0.8074047018471078}
2022-11-22 20:36:49,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:49,184 INFO:     Epoch: 8
2022-11-22 20:36:49,925 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8119181817354157, 'Total loss': 0.8119181817354157} | train loss {'Reaction outcome loss': 0.8035243129043422, 'Total loss': 0.8035243129043422}
2022-11-22 20:36:49,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:49,925 INFO:     Epoch: 9
2022-11-22 20:36:50,687 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8134673653646957, 'Total loss': 0.8134673653646957} | train loss {'Reaction outcome loss': 0.7985749577053289, 'Total loss': 0.7985749577053289}
2022-11-22 20:36:50,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:50,688 INFO:     Epoch: 10
2022-11-22 20:36:51,436 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8050750542518704, 'Total loss': 0.8050750542518704} | train loss {'Reaction outcome loss': 0.8009609762778498, 'Total loss': 0.8009609762778498}
2022-11-22 20:36:51,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:51,436 INFO:     Epoch: 11
2022-11-22 20:36:52,125 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8030607159747634, 'Total loss': 0.8030607159747634} | train loss {'Reaction outcome loss': 0.7946973739828102, 'Total loss': 0.7946973739828102}
2022-11-22 20:36:52,125 INFO:     Found new best model at epoch 11
2022-11-22 20:36:52,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:52,126 INFO:     Epoch: 12
2022-11-22 20:36:52,841 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8549451737902886, 'Total loss': 0.8549451737902886} | train loss {'Reaction outcome loss': 0.7969896526616297, 'Total loss': 0.7969896526616297}
2022-11-22 20:36:52,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:52,841 INFO:     Epoch: 13
2022-11-22 20:36:53,570 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8142404708751413, 'Total loss': 0.8142404708751413} | train loss {'Reaction outcome loss': 0.7970136045612426, 'Total loss': 0.7970136045612426}
2022-11-22 20:36:53,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:53,570 INFO:     Epoch: 14
2022-11-22 20:36:54,300 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8043825487757839, 'Total loss': 0.8043825487757839} | train loss {'Reaction outcome loss': 0.7987293940758018, 'Total loss': 0.7987293940758018}
2022-11-22 20:36:54,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:54,301 INFO:     Epoch: 15
2022-11-22 20:36:54,997 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8176640549371409, 'Total loss': 0.8176640549371409} | train loss {'Reaction outcome loss': 0.7913544918774578, 'Total loss': 0.7913544918774578}
2022-11-22 20:36:54,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:54,997 INFO:     Epoch: 16
2022-11-22 20:36:55,701 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8147318564182104, 'Total loss': 0.8147318564182104} | train loss {'Reaction outcome loss': 0.7873086462050308, 'Total loss': 0.7873086462050308}
2022-11-22 20:36:55,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:55,701 INFO:     Epoch: 17
2022-11-22 20:36:56,436 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8056414231311443, 'Total loss': 0.8056414231311443} | train loss {'Reaction outcome loss': 0.7939098183019662, 'Total loss': 0.7939098183019662}
2022-11-22 20:36:56,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:56,437 INFO:     Epoch: 18
2022-11-22 20:36:57,137 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8230547738629718, 'Total loss': 0.8230547738629718} | train loss {'Reaction outcome loss': 0.793778410173738, 'Total loss': 0.793778410173738}
2022-11-22 20:36:57,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:57,137 INFO:     Epoch: 19
2022-11-22 20:36:57,922 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.811407127352648, 'Total loss': 0.811407127352648} | train loss {'Reaction outcome loss': 0.7958788126093861, 'Total loss': 0.7958788126093861}
2022-11-22 20:36:57,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:57,922 INFO:     Epoch: 20
2022-11-22 20:36:58,756 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8171313314936882, 'Total loss': 0.8171313314936882} | train loss {'Reaction outcome loss': 0.7872173975034015, 'Total loss': 0.7872173975034015}
2022-11-22 20:36:58,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:58,756 INFO:     Epoch: 21
2022-11-22 20:36:59,476 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.797451178001803, 'Total loss': 0.797451178001803} | train loss {'Reaction outcome loss': 0.7858831112276871, 'Total loss': 0.7858831112276871}
2022-11-22 20:36:59,476 INFO:     Found new best model at epoch 21
2022-11-22 20:36:59,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:36:59,477 INFO:     Epoch: 22
2022-11-22 20:37:00,250 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7993116441161133, 'Total loss': 0.7993116441161133} | train loss {'Reaction outcome loss': 0.7859600950415733, 'Total loss': 0.7859600950415733}
2022-11-22 20:37:00,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:00,251 INFO:     Epoch: 23
2022-11-22 20:37:01,000 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8522331090860589, 'Total loss': 0.8522331090860589} | train loss {'Reaction outcome loss': 0.7875100537337394, 'Total loss': 0.7875100537337394}
2022-11-22 20:37:01,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:01,000 INFO:     Epoch: 24
2022-11-22 20:37:01,766 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.80022044722424, 'Total loss': 0.80022044722424} | train loss {'Reaction outcome loss': 0.7837794718673691, 'Total loss': 0.7837794718673691}
2022-11-22 20:37:01,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:01,766 INFO:     Epoch: 25
2022-11-22 20:37:02,522 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8627829302188962, 'Total loss': 0.8627829302188962} | train loss {'Reaction outcome loss': 0.7840797888889234, 'Total loss': 0.7840797888889234}
2022-11-22 20:37:02,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:02,522 INFO:     Epoch: 26
2022-11-22 20:37:03,339 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8092023688693379, 'Total loss': 0.8092023688693379} | train loss {'Reaction outcome loss': 0.7896982882739094, 'Total loss': 0.7896982882739094}
2022-11-22 20:37:03,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:03,340 INFO:     Epoch: 27
2022-11-22 20:37:04,139 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7840729002342668, 'Total loss': 0.7840729002342668} | train loss {'Reaction outcome loss': 0.7860866158342166, 'Total loss': 0.7860866158342166}
2022-11-22 20:37:04,139 INFO:     Found new best model at epoch 27
2022-11-22 20:37:04,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:04,140 INFO:     Epoch: 28
2022-11-22 20:37:04,945 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7968434781529182, 'Total loss': 0.7968434781529182} | train loss {'Reaction outcome loss': 0.7795138480486693, 'Total loss': 0.7795138480486693}
2022-11-22 20:37:04,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:04,945 INFO:     Epoch: 29
2022-11-22 20:37:05,752 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7853053579496783, 'Total loss': 0.7853053579496783} | train loss {'Reaction outcome loss': 0.78206465028441, 'Total loss': 0.78206465028441}
2022-11-22 20:37:05,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:05,752 INFO:     Epoch: 30
2022-11-22 20:37:06,598 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.781384119460749, 'Total loss': 0.781384119460749} | train loss {'Reaction outcome loss': 0.7782669871922874, 'Total loss': 0.7782669871922874}
2022-11-22 20:37:06,599 INFO:     Found new best model at epoch 30
2022-11-22 20:37:06,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:06,600 INFO:     Epoch: 31
2022-11-22 20:37:07,423 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8024421209512755, 'Total loss': 0.8024421209512755} | train loss {'Reaction outcome loss': 0.7792829530229294, 'Total loss': 0.7792829530229294}
2022-11-22 20:37:07,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:07,424 INFO:     Epoch: 32
2022-11-22 20:37:08,300 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7973490800968436, 'Total loss': 0.7973490800968436} | train loss {'Reaction outcome loss': 0.7839638585906951, 'Total loss': 0.7839638585906951}
2022-11-22 20:37:08,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:08,300 INFO:     Epoch: 33
2022-11-22 20:37:09,123 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8210264000781747, 'Total loss': 0.8210264000781747} | train loss {'Reaction outcome loss': 0.7785124136096656, 'Total loss': 0.7785124136096656}
2022-11-22 20:37:09,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:09,124 INFO:     Epoch: 34
2022-11-22 20:37:09,931 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8109857814256535, 'Total loss': 0.8109857814256535} | train loss {'Reaction outcome loss': 0.7773121954727565, 'Total loss': 0.7773121954727565}
2022-11-22 20:37:09,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:09,931 INFO:     Epoch: 35
2022-11-22 20:37:10,712 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7857015389342641, 'Total loss': 0.7857015389342641} | train loss {'Reaction outcome loss': 0.7812181728366961, 'Total loss': 0.7812181728366961}
2022-11-22 20:37:10,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:10,713 INFO:     Epoch: 36
2022-11-22 20:37:11,544 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7756464003130447, 'Total loss': 0.7756464003130447} | train loss {'Reaction outcome loss': 0.7784141587867658, 'Total loss': 0.7784141587867658}
2022-11-22 20:37:11,544 INFO:     Found new best model at epoch 36
2022-11-22 20:37:11,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:11,545 INFO:     Epoch: 37
2022-11-22 20:37:12,364 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8010813593864441, 'Total loss': 0.8010813593864441} | train loss {'Reaction outcome loss': 0.7745760768774606, 'Total loss': 0.7745760768774606}
2022-11-22 20:37:12,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:12,365 INFO:     Epoch: 38
2022-11-22 20:37:13,146 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7908472391062005, 'Total loss': 0.7908472391062005} | train loss {'Reaction outcome loss': 0.7784726006503949, 'Total loss': 0.7784726006503949}
2022-11-22 20:37:13,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:13,147 INFO:     Epoch: 39
2022-11-22 20:37:13,954 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7974339335463768, 'Total loss': 0.7974339335463768} | train loss {'Reaction outcome loss': 0.7816003854137389, 'Total loss': 0.7816003854137389}
2022-11-22 20:37:13,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:13,954 INFO:     Epoch: 40
2022-11-22 20:37:14,739 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8083191805107649, 'Total loss': 0.8083191805107649} | train loss {'Reaction outcome loss': 0.7795007204322658, 'Total loss': 0.7795007204322658}
2022-11-22 20:37:14,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:14,740 INFO:     Epoch: 41
2022-11-22 20:37:15,523 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7950536137403443, 'Total loss': 0.7950536137403443} | train loss {'Reaction outcome loss': 0.779363911828877, 'Total loss': 0.779363911828877}
2022-11-22 20:37:15,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:15,523 INFO:     Epoch: 42
2022-11-22 20:37:16,321 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.810564388369405, 'Total loss': 0.810564388369405} | train loss {'Reaction outcome loss': 0.7729774550400643, 'Total loss': 0.7729774550400643}
2022-11-22 20:37:16,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:16,321 INFO:     Epoch: 43
2022-11-22 20:37:17,106 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7997072685596555, 'Total loss': 0.7997072685596555} | train loss {'Reaction outcome loss': 0.7757511338824598, 'Total loss': 0.7757511338824598}
2022-11-22 20:37:17,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:17,106 INFO:     Epoch: 44
2022-11-22 20:37:17,898 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.807840239863063, 'Total loss': 0.807840239863063} | train loss {'Reaction outcome loss': 0.7771045100787048, 'Total loss': 0.7771045100787048}
2022-11-22 20:37:17,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:17,898 INFO:     Epoch: 45
2022-11-22 20:37:18,687 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.809661346812581, 'Total loss': 0.809661346812581} | train loss {'Reaction outcome loss': 0.7744799306608522, 'Total loss': 0.7744799306608522}
2022-11-22 20:37:18,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:18,687 INFO:     Epoch: 46
2022-11-22 20:37:19,483 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.795224454513816, 'Total loss': 0.795224454513816} | train loss {'Reaction outcome loss': 0.769666684507833, 'Total loss': 0.769666684507833}
2022-11-22 20:37:19,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:19,483 INFO:     Epoch: 47
2022-11-22 20:37:20,267 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7833894006041593, 'Total loss': 0.7833894006041593} | train loss {'Reaction outcome loss': 0.7699755067197384, 'Total loss': 0.7699755067197384}
2022-11-22 20:37:20,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:20,268 INFO:     Epoch: 48
2022-11-22 20:37:21,056 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7873603611491448, 'Total loss': 0.7873603611491448} | train loss {'Reaction outcome loss': 0.7712472044391396, 'Total loss': 0.7712472044391396}
2022-11-22 20:37:21,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:21,057 INFO:     Epoch: 49
2022-11-22 20:37:21,842 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7996726548948954, 'Total loss': 0.7996726548948954} | train loss {'Reaction outcome loss': 0.772720097514337, 'Total loss': 0.772720097514337}
2022-11-22 20:37:21,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:21,842 INFO:     Epoch: 50
2022-11-22 20:37:22,614 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8003701193388119, 'Total loss': 0.8003701193388119} | train loss {'Reaction outcome loss': 0.7746567252732108, 'Total loss': 0.7746567252732108}
2022-11-22 20:37:22,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:22,615 INFO:     Epoch: 51
2022-11-22 20:37:23,371 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.795727752668913, 'Total loss': 0.795727752668913} | train loss {'Reaction outcome loss': 0.7664925076466038, 'Total loss': 0.7664925076466038}
2022-11-22 20:37:23,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:23,372 INFO:     Epoch: 52
2022-11-22 20:37:24,194 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7632002872090007, 'Total loss': 0.7632002872090007} | train loss {'Reaction outcome loss': 0.7639033850818995, 'Total loss': 0.7639033850818995}
2022-11-22 20:37:24,194 INFO:     Found new best model at epoch 52
2022-11-22 20:37:24,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:24,195 INFO:     Epoch: 53
2022-11-22 20:37:25,016 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.781246940756953, 'Total loss': 0.781246940756953} | train loss {'Reaction outcome loss': 0.7664104696409202, 'Total loss': 0.7664104696409202}
2022-11-22 20:37:25,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:25,016 INFO:     Epoch: 54
2022-11-22 20:37:25,771 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7956517796183742, 'Total loss': 0.7956517796183742} | train loss {'Reaction outcome loss': 0.7679474305959395, 'Total loss': 0.7679474305959395}
2022-11-22 20:37:25,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:25,772 INFO:     Epoch: 55
2022-11-22 20:37:26,597 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7767679400222246, 'Total loss': 0.7767679400222246} | train loss {'Reaction outcome loss': 0.7687594781441943, 'Total loss': 0.7687594781441943}
2022-11-22 20:37:26,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:26,598 INFO:     Epoch: 56
2022-11-22 20:37:27,402 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7843741795351339, 'Total loss': 0.7843741795351339} | train loss {'Reaction outcome loss': 0.7637103872044096, 'Total loss': 0.7637103872044096}
2022-11-22 20:37:27,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:27,403 INFO:     Epoch: 57
2022-11-22 20:37:28,182 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7835895779520966, 'Total loss': 0.7835895779520966} | train loss {'Reaction outcome loss': 0.7693259838677238, 'Total loss': 0.7693259838677238}
2022-11-22 20:37:28,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:28,182 INFO:     Epoch: 58
2022-11-22 20:37:28,963 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7700802254122358, 'Total loss': 0.7700802254122358} | train loss {'Reaction outcome loss': 0.7652383045649823, 'Total loss': 0.7652383045649823}
2022-11-22 20:37:28,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:28,963 INFO:     Epoch: 59
2022-11-22 20:37:29,732 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7945186218550039, 'Total loss': 0.7945186218550039} | train loss {'Reaction outcome loss': 0.7611071597401498, 'Total loss': 0.7611071597401498}
2022-11-22 20:37:29,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:29,733 INFO:     Epoch: 60
2022-11-22 20:37:30,551 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7920689056085986, 'Total loss': 0.7920689056085986} | train loss {'Reaction outcome loss': 0.7638829853922251, 'Total loss': 0.7638829853922251}
2022-11-22 20:37:30,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:30,551 INFO:     Epoch: 61
2022-11-22 20:37:31,343 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7935812459435574, 'Total loss': 0.7935812459435574} | train loss {'Reaction outcome loss': 0.7594056659274631, 'Total loss': 0.7594056659274631}
2022-11-22 20:37:31,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:31,343 INFO:     Epoch: 62
2022-11-22 20:37:32,137 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8081941542237304, 'Total loss': 0.8081941542237304} | train loss {'Reaction outcome loss': 0.7564571742658261, 'Total loss': 0.7564571742658261}
2022-11-22 20:37:32,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:32,137 INFO:     Epoch: 63
2022-11-22 20:37:32,930 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7760366991508839, 'Total loss': 0.7760366991508839} | train loss {'Reaction outcome loss': 0.7627049195177761, 'Total loss': 0.7627049195177761}
2022-11-22 20:37:32,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:32,930 INFO:     Epoch: 64
2022-11-22 20:37:33,733 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7805669432462647, 'Total loss': 0.7805669432462647} | train loss {'Reaction outcome loss': 0.7559094593358138, 'Total loss': 0.7559094593358138}
2022-11-22 20:37:33,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:33,734 INFO:     Epoch: 65
2022-11-22 20:37:34,526 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8234637442023255, 'Total loss': 0.8234637442023255} | train loss {'Reaction outcome loss': 0.7563951531800713, 'Total loss': 0.7563951531800713}
2022-11-22 20:37:34,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:34,526 INFO:     Epoch: 66
2022-11-22 20:37:35,308 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7710590972456821, 'Total loss': 0.7710590972456821} | train loss {'Reaction outcome loss': 0.7555719067039803, 'Total loss': 0.7555719067039803}
2022-11-22 20:37:35,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:35,309 INFO:     Epoch: 67
2022-11-22 20:37:36,133 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8036182779212331, 'Total loss': 0.8036182779212331} | train loss {'Reaction outcome loss': 0.7556434366928697, 'Total loss': 0.7556434366928697}
2022-11-22 20:37:36,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:36,133 INFO:     Epoch: 68
2022-11-22 20:37:36,911 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7559898731320404, 'Total loss': 0.7559898731320404} | train loss {'Reaction outcome loss': 0.7592069135035997, 'Total loss': 0.7592069135035997}
2022-11-22 20:37:36,911 INFO:     Found new best model at epoch 68
2022-11-22 20:37:36,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:36,912 INFO:     Epoch: 69
2022-11-22 20:37:37,667 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7693183532980985, 'Total loss': 0.7693183532980985} | train loss {'Reaction outcome loss': 0.7532033390469022, 'Total loss': 0.7532033390469022}
2022-11-22 20:37:37,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:37,668 INFO:     Epoch: 70
2022-11-22 20:37:38,449 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7753649714381196, 'Total loss': 0.7753649714381196} | train loss {'Reaction outcome loss': 0.7534474808983351, 'Total loss': 0.7534474808983351}
2022-11-22 20:37:38,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:38,450 INFO:     Epoch: 71
2022-11-22 20:37:39,273 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.76621206208717, 'Total loss': 0.76621206208717} | train loss {'Reaction outcome loss': 0.7539628122323825, 'Total loss': 0.7539628122323825}
2022-11-22 20:37:39,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:39,274 INFO:     Epoch: 72
2022-11-22 20:37:40,088 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7611872179563656, 'Total loss': 0.7611872179563656} | train loss {'Reaction outcome loss': 0.7570625538688628, 'Total loss': 0.7570625538688628}
2022-11-22 20:37:40,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:40,088 INFO:     Epoch: 73
2022-11-22 20:37:40,843 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7716955161371897, 'Total loss': 0.7716955161371897} | train loss {'Reaction outcome loss': 0.7452143797413312, 'Total loss': 0.7452143797413312}
2022-11-22 20:37:40,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:40,843 INFO:     Epoch: 74
2022-11-22 20:37:41,650 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7581138777178388, 'Total loss': 0.7581138777178388} | train loss {'Reaction outcome loss': 0.7415433608823352, 'Total loss': 0.7415433608823352}
2022-11-22 20:37:41,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:41,650 INFO:     Epoch: 75
2022-11-22 20:37:42,385 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7620770134205042, 'Total loss': 0.7620770134205042} | train loss {'Reaction outcome loss': 0.7518805077782383, 'Total loss': 0.7518805077782383}
2022-11-22 20:37:42,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:42,385 INFO:     Epoch: 76
2022-11-22 20:37:43,139 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7705610138039256, 'Total loss': 0.7705610138039256} | train loss {'Reaction outcome loss': 0.7427573494705153, 'Total loss': 0.7427573494705153}
2022-11-22 20:37:43,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:43,139 INFO:     Epoch: 77
2022-11-22 20:37:43,913 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7541321114052174, 'Total loss': 0.7541321114052174} | train loss {'Reaction outcome loss': 0.7412795413730076, 'Total loss': 0.7412795413730076}
2022-11-22 20:37:43,913 INFO:     Found new best model at epoch 77
2022-11-22 20:37:43,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:43,914 INFO:     Epoch: 78
2022-11-22 20:37:44,669 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.750043532183004, 'Total loss': 0.750043532183004} | train loss {'Reaction outcome loss': 0.738087558084064, 'Total loss': 0.738087558084064}
2022-11-22 20:37:44,670 INFO:     Found new best model at epoch 78
2022-11-22 20:37:44,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:44,670 INFO:     Epoch: 79
2022-11-22 20:37:45,456 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7690834527791932, 'Total loss': 0.7690834527791932} | train loss {'Reaction outcome loss': 0.7373521535239592, 'Total loss': 0.7373521535239592}
2022-11-22 20:37:45,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:45,456 INFO:     Epoch: 80
2022-11-22 20:37:46,236 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7588477093119954, 'Total loss': 0.7588477093119954} | train loss {'Reaction outcome loss': 0.7517057113931993, 'Total loss': 0.7517057113931993}
2022-11-22 20:37:46,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:46,236 INFO:     Epoch: 81
2022-11-22 20:37:47,027 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7531500666640526, 'Total loss': 0.7531500666640526} | train loss {'Reaction outcome loss': 0.7396405593112663, 'Total loss': 0.7396405593112663}
2022-11-22 20:37:47,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:47,027 INFO:     Epoch: 82
2022-11-22 20:37:47,797 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7866832121860149, 'Total loss': 0.7866832121860149} | train loss {'Reaction outcome loss': 0.7436343054957841, 'Total loss': 0.7436343054957841}
2022-11-22 20:37:47,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:47,798 INFO:     Epoch: 83
2022-11-22 20:37:48,606 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7435393375019694, 'Total loss': 0.7435393375019694} | train loss {'Reaction outcome loss': 0.7421637914553592, 'Total loss': 0.7421637914553592}
2022-11-22 20:37:48,606 INFO:     Found new best model at epoch 83
2022-11-22 20:37:48,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:48,607 INFO:     Epoch: 84
2022-11-22 20:37:49,398 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7623358348081278, 'Total loss': 0.7623358348081278} | train loss {'Reaction outcome loss': 0.7405243688895379, 'Total loss': 0.7405243688895379}
2022-11-22 20:37:49,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:49,398 INFO:     Epoch: 85
2022-11-22 20:37:50,212 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7450328496999519, 'Total loss': 0.7450328496999519} | train loss {'Reaction outcome loss': 0.7404397152088307, 'Total loss': 0.7404397152088307}
2022-11-22 20:37:50,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:50,212 INFO:     Epoch: 86
2022-11-22 20:37:51,022 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7306137743384339, 'Total loss': 0.7306137743384339} | train loss {'Reaction outcome loss': 0.7263754723984518, 'Total loss': 0.7263754723984518}
2022-11-22 20:37:51,022 INFO:     Found new best model at epoch 86
2022-11-22 20:37:51,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:51,023 INFO:     Epoch: 87
2022-11-22 20:37:51,797 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7939450609129529, 'Total loss': 0.7939450609129529} | train loss {'Reaction outcome loss': 0.7318849415200237, 'Total loss': 0.7318849415200237}
2022-11-22 20:37:51,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:51,797 INFO:     Epoch: 88
2022-11-22 20:37:52,593 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7838421893674273, 'Total loss': 0.7838421893674273} | train loss {'Reaction outcome loss': 0.7365952786594752, 'Total loss': 0.7365952786594752}
2022-11-22 20:37:52,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:52,593 INFO:     Epoch: 89
2022-11-22 20:37:53,418 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7529220844424048, 'Total loss': 0.7529220844424048} | train loss {'Reaction outcome loss': 0.7270370498606207, 'Total loss': 0.7270370498606207}
2022-11-22 20:37:53,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:53,419 INFO:     Epoch: 90
2022-11-22 20:37:54,221 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7540266042531922, 'Total loss': 0.7540266042531922} | train loss {'Reaction outcome loss': 0.7267631135359713, 'Total loss': 0.7267631135359713}
2022-11-22 20:37:54,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:54,221 INFO:     Epoch: 91
2022-11-22 20:37:55,010 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7461033255554909, 'Total loss': 0.7461033255554909} | train loss {'Reaction outcome loss': 0.7281723920209908, 'Total loss': 0.7281723920209908}
2022-11-22 20:37:55,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:55,010 INFO:     Epoch: 92
2022-11-22 20:37:55,786 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.781939250785251, 'Total loss': 0.781939250785251} | train loss {'Reaction outcome loss': 0.7307567241996404, 'Total loss': 0.7307567241996404}
2022-11-22 20:37:55,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:55,787 INFO:     Epoch: 93
2022-11-22 20:37:56,538 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7296564682971599, 'Total loss': 0.7296564682971599} | train loss {'Reaction outcome loss': 0.7322583204679528, 'Total loss': 0.7322583204679528}
2022-11-22 20:37:56,538 INFO:     Found new best model at epoch 93
2022-11-22 20:37:56,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:56,539 INFO:     Epoch: 94
2022-11-22 20:37:57,298 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7568616700726886, 'Total loss': 0.7568616700726886} | train loss {'Reaction outcome loss': 0.7322351999979451, 'Total loss': 0.7322351999979451}
2022-11-22 20:37:57,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:57,299 INFO:     Epoch: 95
2022-11-22 20:37:58,053 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7342046887375587, 'Total loss': 0.7342046887375587} | train loss {'Reaction outcome loss': 0.7284638300354098, 'Total loss': 0.7284638300354098}
2022-11-22 20:37:58,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:58,053 INFO:     Epoch: 96
2022-11-22 20:37:58,809 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8017620776974878, 'Total loss': 0.8017620776974878} | train loss {'Reaction outcome loss': 0.7173094706525528, 'Total loss': 0.7173094706525528}
2022-11-22 20:37:58,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:58,809 INFO:     Epoch: 97
2022-11-22 20:37:59,576 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7733200053836025, 'Total loss': 0.7733200053836025} | train loss {'Reaction outcome loss': 0.7328246276319763, 'Total loss': 0.7328246276319763}
2022-11-22 20:37:59,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:37:59,577 INFO:     Epoch: 98
2022-11-22 20:38:00,316 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7372114575186441, 'Total loss': 0.7372114575186441} | train loss {'Reaction outcome loss': 0.7187776589467202, 'Total loss': 0.7187776589467202}
2022-11-22 20:38:00,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:00,317 INFO:     Epoch: 99
2022-11-22 20:38:01,127 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8076843660931254, 'Total loss': 0.8076843660931254} | train loss {'Reaction outcome loss': 0.7187475292893594, 'Total loss': 0.7187475292893594}
2022-11-22 20:38:01,127 INFO:     Best model found after epoch 94 of 100.
2022-11-22 20:38:01,127 INFO:   Done with stage: TRAINING
2022-11-22 20:38:01,128 INFO:   Starting stage: EVALUATION
2022-11-22 20:38:01,264 INFO:   Done with stage: EVALUATION
2022-11-22 20:38:01,264 INFO:   Leaving out SEQ value Fold_2
2022-11-22 20:38:01,278 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:38:01,278 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:38:01,959 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:38:01,959 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:38:02,033 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:38:02,033 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:38:02,033 INFO:     No hyperparam tuning for this model
2022-11-22 20:38:02,033 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:38:02,033 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:38:02,034 INFO:     None feature selector for col prot
2022-11-22 20:38:02,034 INFO:     None feature selector for col prot
2022-11-22 20:38:02,034 INFO:     None feature selector for col prot
2022-11-22 20:38:02,035 INFO:     None feature selector for col chem
2022-11-22 20:38:02,035 INFO:     None feature selector for col chem
2022-11-22 20:38:02,035 INFO:     None feature selector for col chem
2022-11-22 20:38:02,035 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:38:02,035 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:38:02,036 INFO:     Number of params in model 126091
2022-11-22 20:38:02,040 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:38:02,040 INFO:   Starting stage: TRAINING
2022-11-22 20:38:02,092 INFO:     Val loss before train {'Reaction outcome loss': 0.9450522451238199, 'Total loss': 0.9450522451238199}
2022-11-22 20:38:02,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:02,092 INFO:     Epoch: 0
2022-11-22 20:38:02,858 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8147332641211423, 'Total loss': 0.8147332641211423} | train loss {'Reaction outcome loss': 0.8815938301897241, 'Total loss': 0.8815938301897241}
2022-11-22 20:38:02,858 INFO:     Found new best model at epoch 0
2022-11-22 20:38:02,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:02,859 INFO:     Epoch: 1
2022-11-22 20:38:03,626 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7976291782476685, 'Total loss': 0.7976291782476685} | train loss {'Reaction outcome loss': 0.8512052152803552, 'Total loss': 0.8512052152803552}
2022-11-22 20:38:03,626 INFO:     Found new best model at epoch 1
2022-11-22 20:38:03,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:03,627 INFO:     Epoch: 2
2022-11-22 20:38:04,373 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.817917061122981, 'Total loss': 0.817917061122981} | train loss {'Reaction outcome loss': 0.8360726350714803, 'Total loss': 0.8360726350714803}
2022-11-22 20:38:04,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:04,373 INFO:     Epoch: 3
2022-11-22 20:38:05,137 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8150282041593031, 'Total loss': 0.8150282041593031} | train loss {'Reaction outcome loss': 0.8353283618867156, 'Total loss': 0.8353283618867156}
2022-11-22 20:38:05,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:05,137 INFO:     Epoch: 4
2022-11-22 20:38:05,875 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7850729260932315, 'Total loss': 0.7850729260932315} | train loss {'Reaction outcome loss': 0.8315895027235934, 'Total loss': 0.8315895027235934}
2022-11-22 20:38:05,876 INFO:     Found new best model at epoch 4
2022-11-22 20:38:05,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:05,877 INFO:     Epoch: 5
2022-11-22 20:38:06,621 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8127462281422182, 'Total loss': 0.8127462281422182} | train loss {'Reaction outcome loss': 0.8222268520277521, 'Total loss': 0.8222268520277521}
2022-11-22 20:38:06,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:06,621 INFO:     Epoch: 6
2022-11-22 20:38:07,375 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7893901311538436, 'Total loss': 0.7893901311538436} | train loss {'Reaction outcome loss': 0.8222357003312362, 'Total loss': 0.8222357003312362}
2022-11-22 20:38:07,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:07,375 INFO:     Epoch: 7
2022-11-22 20:38:08,118 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7773965827443383, 'Total loss': 0.7773965827443383} | train loss {'Reaction outcome loss': 0.8278853691254671, 'Total loss': 0.8278853691254671}
2022-11-22 20:38:08,118 INFO:     Found new best model at epoch 7
2022-11-22 20:38:08,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:08,119 INFO:     Epoch: 8
2022-11-22 20:38:08,882 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7789433110844005, 'Total loss': 0.7789433110844005} | train loss {'Reaction outcome loss': 0.8192203269313704, 'Total loss': 0.8192203269313704}
2022-11-22 20:38:08,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:08,882 INFO:     Epoch: 9
2022-11-22 20:38:09,655 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7993472841652957, 'Total loss': 0.7993472841652957} | train loss {'Reaction outcome loss': 0.8188375180308153, 'Total loss': 0.8188375180308153}
2022-11-22 20:38:09,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:09,656 INFO:     Epoch: 10
2022-11-22 20:38:10,399 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7963907285170122, 'Total loss': 0.7963907285170122} | train loss {'Reaction outcome loss': 0.8175511325177877, 'Total loss': 0.8175511325177877}
2022-11-22 20:38:10,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:10,399 INFO:     Epoch: 11
2022-11-22 20:38:11,120 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8315696635029532, 'Total loss': 0.8315696635029532} | train loss {'Reaction outcome loss': 0.8202718434787473, 'Total loss': 0.8202718434787473}
2022-11-22 20:38:11,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:11,120 INFO:     Epoch: 12
2022-11-22 20:38:11,862 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7891698005524549, 'Total loss': 0.7891698005524549} | train loss {'Reaction outcome loss': 0.8054374921539051, 'Total loss': 0.8054374921539051}
2022-11-22 20:38:11,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:11,863 INFO:     Epoch: 13
2022-11-22 20:38:12,586 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.803712326017293, 'Total loss': 0.803712326017293} | train loss {'Reaction outcome loss': 0.8058672915948065, 'Total loss': 0.8058672915948065}
2022-11-22 20:38:12,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:12,587 INFO:     Epoch: 14
2022-11-22 20:38:13,345 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7779750620776956, 'Total loss': 0.7779750620776956} | train loss {'Reaction outcome loss': 0.8139194591566619, 'Total loss': 0.8139194591566619}
2022-11-22 20:38:13,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:13,346 INFO:     Epoch: 15
2022-11-22 20:38:14,061 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7753693149848417, 'Total loss': 0.7753693149848417} | train loss {'Reaction outcome loss': 0.8140392677504041, 'Total loss': 0.8140392677504041}
2022-11-22 20:38:14,061 INFO:     Found new best model at epoch 15
2022-11-22 20:38:14,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:14,062 INFO:     Epoch: 16
2022-11-22 20:38:14,812 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7786759598688646, 'Total loss': 0.7786759598688646} | train loss {'Reaction outcome loss': 0.8102284283773137, 'Total loss': 0.8102284283773137}
2022-11-22 20:38:14,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:14,812 INFO:     Epoch: 17
2022-11-22 20:38:15,528 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7624104625799439, 'Total loss': 0.7624104625799439} | train loss {'Reaction outcome loss': 0.8059998768785221, 'Total loss': 0.8059998768785221}
2022-11-22 20:38:15,529 INFO:     Found new best model at epoch 17
2022-11-22 20:38:15,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:15,529 INFO:     Epoch: 18
2022-11-22 20:38:16,262 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7622853781689297, 'Total loss': 0.7622853781689297} | train loss {'Reaction outcome loss': 0.8051940654875779, 'Total loss': 0.8051940654875779}
2022-11-22 20:38:16,263 INFO:     Found new best model at epoch 18
2022-11-22 20:38:16,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:16,264 INFO:     Epoch: 19
2022-11-22 20:38:17,004 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7853310744870793, 'Total loss': 0.7853310744870793} | train loss {'Reaction outcome loss': 0.7986986783600831, 'Total loss': 0.7986986783600831}
2022-11-22 20:38:17,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:17,004 INFO:     Epoch: 20
2022-11-22 20:38:17,738 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7789835374463688, 'Total loss': 0.7789835374463688} | train loss {'Reaction outcome loss': 0.801262466651708, 'Total loss': 0.801262466651708}
2022-11-22 20:38:17,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:17,738 INFO:     Epoch: 21
2022-11-22 20:38:18,467 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7940171868963675, 'Total loss': 0.7940171868963675} | train loss {'Reaction outcome loss': 0.8044486282325467, 'Total loss': 0.8044486282325467}
2022-11-22 20:38:18,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:18,467 INFO:     Epoch: 22
2022-11-22 20:38:19,162 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7812542258338495, 'Total loss': 0.7812542258338495} | train loss {'Reaction outcome loss': 0.8059512024466325, 'Total loss': 0.8059512024466325}
2022-11-22 20:38:19,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:19,162 INFO:     Epoch: 23
2022-11-22 20:38:19,891 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7863704704425551, 'Total loss': 0.7863704704425551} | train loss {'Reaction outcome loss': 0.8030221731315258, 'Total loss': 0.8030221731315258}
2022-11-22 20:38:19,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:19,891 INFO:     Epoch: 24
2022-11-22 20:38:20,606 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.797954417087815, 'Total loss': 0.797954417087815} | train loss {'Reaction outcome loss': 0.8056401467998984, 'Total loss': 0.8056401467998984}
2022-11-22 20:38:20,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:20,607 INFO:     Epoch: 25
2022-11-22 20:38:21,358 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.771126963198185, 'Total loss': 0.771126963198185} | train loss {'Reaction outcome loss': 0.8117623297791732, 'Total loss': 0.8117623297791732}
2022-11-22 20:38:21,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:21,358 INFO:     Epoch: 26
2022-11-22 20:38:22,122 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8535221828655764, 'Total loss': 0.8535221828655764} | train loss {'Reaction outcome loss': 0.8053128625217237, 'Total loss': 0.8053128625217237}
2022-11-22 20:38:22,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:22,122 INFO:     Epoch: 27
2022-11-22 20:38:22,895 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7854146401990544, 'Total loss': 0.7854146401990544} | train loss {'Reaction outcome loss': 0.811135543020148, 'Total loss': 0.811135543020148}
2022-11-22 20:38:22,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:22,896 INFO:     Epoch: 28
2022-11-22 20:38:23,648 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7697410475124012, 'Total loss': 0.7697410475124012} | train loss {'Reaction outcome loss': 0.7998942460125757, 'Total loss': 0.7998942460125757}
2022-11-22 20:38:23,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:23,648 INFO:     Epoch: 29
2022-11-22 20:38:24,417 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7727814160964706, 'Total loss': 0.7727814160964706} | train loss {'Reaction outcome loss': 0.7948018465688836, 'Total loss': 0.7948018465688836}
2022-11-22 20:38:24,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:24,417 INFO:     Epoch: 30
2022-11-22 20:38:25,171 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8163092603737657, 'Total loss': 0.8163092603737657} | train loss {'Reaction outcome loss': 0.7982635292477211, 'Total loss': 0.7982635292477211}
2022-11-22 20:38:25,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:25,172 INFO:     Epoch: 31
2022-11-22 20:38:25,867 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7808854505419731, 'Total loss': 0.7808854505419731} | train loss {'Reaction outcome loss': 0.796615977398297, 'Total loss': 0.796615977398297}
2022-11-22 20:38:25,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:25,867 INFO:     Epoch: 32
2022-11-22 20:38:26,620 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7757521027868445, 'Total loss': 0.7757521027868445} | train loss {'Reaction outcome loss': 0.803432693727586, 'Total loss': 0.803432693727586}
2022-11-22 20:38:26,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:26,620 INFO:     Epoch: 33
2022-11-22 20:38:27,393 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7896675616502762, 'Total loss': 0.7896675616502762} | train loss {'Reaction outcome loss': 0.795677001478701, 'Total loss': 0.795677001478701}
2022-11-22 20:38:27,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:27,393 INFO:     Epoch: 34
2022-11-22 20:38:28,196 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7593254697593775, 'Total loss': 0.7593254697593775} | train loss {'Reaction outcome loss': 0.80285448016908, 'Total loss': 0.80285448016908}
2022-11-22 20:38:28,197 INFO:     Found new best model at epoch 34
2022-11-22 20:38:28,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:28,197 INFO:     Epoch: 35
2022-11-22 20:38:28,979 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.758271455087445, 'Total loss': 0.758271455087445} | train loss {'Reaction outcome loss': 0.8057136615278268, 'Total loss': 0.8057136615278268}
2022-11-22 20:38:28,980 INFO:     Found new best model at epoch 35
2022-11-22 20:38:28,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:28,981 INFO:     Epoch: 36
2022-11-22 20:38:29,747 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7675418725067918, 'Total loss': 0.7675418725067918} | train loss {'Reaction outcome loss': 0.7948457601099361, 'Total loss': 0.7948457601099361}
2022-11-22 20:38:29,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:29,747 INFO:     Epoch: 37
2022-11-22 20:38:30,507 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.769003452225165, 'Total loss': 0.769003452225165} | train loss {'Reaction outcome loss': 0.8025010746982899, 'Total loss': 0.8025010746982899}
2022-11-22 20:38:30,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:30,507 INFO:     Epoch: 38
2022-11-22 20:38:31,226 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7903362620960582, 'Total loss': 0.7903362620960582} | train loss {'Reaction outcome loss': 0.8005734370787617, 'Total loss': 0.8005734370787617}
2022-11-22 20:38:31,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:31,227 INFO:     Epoch: 39
2022-11-22 20:38:32,024 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7756469561295076, 'Total loss': 0.7756469561295076} | train loss {'Reaction outcome loss': 0.7987141752773933, 'Total loss': 0.7987141752773933}
2022-11-22 20:38:32,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:32,024 INFO:     Epoch: 40
2022-11-22 20:38:32,784 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7712904892184518, 'Total loss': 0.7712904892184518} | train loss {'Reaction outcome loss': 0.7960203645924325, 'Total loss': 0.7960203645924325}
2022-11-22 20:38:32,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:32,784 INFO:     Epoch: 41
2022-11-22 20:38:33,515 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7629084925759922, 'Total loss': 0.7629084925759922} | train loss {'Reaction outcome loss': 0.7918251028910339, 'Total loss': 0.7918251028910339}
2022-11-22 20:38:33,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:33,515 INFO:     Epoch: 42
2022-11-22 20:38:34,265 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7884310003031384, 'Total loss': 0.7884310003031384} | train loss {'Reaction outcome loss': 0.7971222538214463, 'Total loss': 0.7971222538214463}
2022-11-22 20:38:34,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:34,265 INFO:     Epoch: 43
2022-11-22 20:38:35,001 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7635650418021462, 'Total loss': 0.7635650418021462} | train loss {'Reaction outcome loss': 0.7950832158749402, 'Total loss': 0.7950832158749402}
2022-11-22 20:38:35,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:35,001 INFO:     Epoch: 44
2022-11-22 20:38:35,717 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7718264772133394, 'Total loss': 0.7718264772133394} | train loss {'Reaction outcome loss': 0.7977227114955423, 'Total loss': 0.7977227114955423}
2022-11-22 20:38:35,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:35,717 INFO:     Epoch: 45
2022-11-22 20:38:36,455 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7686496559869159, 'Total loss': 0.7686496559869159} | train loss {'Reaction outcome loss': 0.8005553117165198, 'Total loss': 0.8005553117165198}
2022-11-22 20:38:36,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:36,455 INFO:     Epoch: 46
2022-11-22 20:38:37,219 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.76985560154373, 'Total loss': 0.76985560154373} | train loss {'Reaction outcome loss': 0.7969188491101207, 'Total loss': 0.7969188491101207}
2022-11-22 20:38:37,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:37,219 INFO:     Epoch: 47
2022-11-22 20:38:38,006 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7607463130896742, 'Total loss': 0.7607463130896742} | train loss {'Reaction outcome loss': 0.7993638263298914, 'Total loss': 0.7993638263298914}
2022-11-22 20:38:38,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:38,006 INFO:     Epoch: 48
2022-11-22 20:38:38,769 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7691671272570436, 'Total loss': 0.7691671272570436} | train loss {'Reaction outcome loss': 0.7958253194928652, 'Total loss': 0.7958253194928652}
2022-11-22 20:38:38,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:38,769 INFO:     Epoch: 49
2022-11-22 20:38:39,501 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7888786183162169, 'Total loss': 0.7888786183162169} | train loss {'Reaction outcome loss': 0.7901692048378801, 'Total loss': 0.7901692048378801}
2022-11-22 20:38:39,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:39,501 INFO:     Epoch: 50
2022-11-22 20:38:40,234 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7599058909849687, 'Total loss': 0.7599058909849687} | train loss {'Reaction outcome loss': 0.7868375684085646, 'Total loss': 0.7868375684085646}
2022-11-22 20:38:40,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:40,234 INFO:     Epoch: 51
2022-11-22 20:38:40,963 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7610724707218733, 'Total loss': 0.7610724707218733} | train loss {'Reaction outcome loss': 0.7914821445217982, 'Total loss': 0.7914821445217982}
2022-11-22 20:38:40,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:40,965 INFO:     Epoch: 52
2022-11-22 20:38:41,659 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.788406943733042, 'Total loss': 0.788406943733042} | train loss {'Reaction outcome loss': 0.7931243523593373, 'Total loss': 0.7931243523593373}
2022-11-22 20:38:41,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:41,659 INFO:     Epoch: 53
2022-11-22 20:38:42,379 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7779096859422597, 'Total loss': 0.7779096859422597} | train loss {'Reaction outcome loss': 0.7900395149342444, 'Total loss': 0.7900395149342444}
2022-11-22 20:38:42,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:42,380 INFO:     Epoch: 54
2022-11-22 20:38:43,104 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7656947144053199, 'Total loss': 0.7656947144053199} | train loss {'Reaction outcome loss': 0.7898219088431795, 'Total loss': 0.7898219088431795}
2022-11-22 20:38:43,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:43,104 INFO:     Epoch: 55
2022-11-22 20:38:43,864 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7526908469471064, 'Total loss': 0.7526908469471064} | train loss {'Reaction outcome loss': 0.7973539377996314, 'Total loss': 0.7973539377996314}
2022-11-22 20:38:43,865 INFO:     Found new best model at epoch 55
2022-11-22 20:38:43,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:43,866 INFO:     Epoch: 56
2022-11-22 20:38:44,581 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7621410069140521, 'Total loss': 0.7621410069140521} | train loss {'Reaction outcome loss': 0.790279483837396, 'Total loss': 0.790279483837396}
2022-11-22 20:38:44,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:44,581 INFO:     Epoch: 57
2022-11-22 20:38:45,311 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.783214500004595, 'Total loss': 0.783214500004595} | train loss {'Reaction outcome loss': 0.7932195864949632, 'Total loss': 0.7932195864949632}
2022-11-22 20:38:45,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:45,312 INFO:     Epoch: 58
2022-11-22 20:38:46,081 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7507135217840021, 'Total loss': 0.7507135217840021} | train loss {'Reaction outcome loss': 0.789005025678318, 'Total loss': 0.789005025678318}
2022-11-22 20:38:46,081 INFO:     Found new best model at epoch 58
2022-11-22 20:38:46,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:46,082 INFO:     Epoch: 59
2022-11-22 20:38:46,796 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7521017146381465, 'Total loss': 0.7521017146381465} | train loss {'Reaction outcome loss': 0.7887151530879711, 'Total loss': 0.7887151530879711}
2022-11-22 20:38:46,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:46,797 INFO:     Epoch: 60
2022-11-22 20:38:47,536 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7478973337195136, 'Total loss': 0.7478973337195136} | train loss {'Reaction outcome loss': 0.7886234409654671, 'Total loss': 0.7886234409654671}
2022-11-22 20:38:47,537 INFO:     Found new best model at epoch 60
2022-11-22 20:38:47,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:47,537 INFO:     Epoch: 61
2022-11-22 20:38:48,281 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7543693354183977, 'Total loss': 0.7543693354183977} | train loss {'Reaction outcome loss': 0.782256101608759, 'Total loss': 0.782256101608759}
2022-11-22 20:38:48,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:48,282 INFO:     Epoch: 62
2022-11-22 20:38:49,037 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7561827051368627, 'Total loss': 0.7561827051368627} | train loss {'Reaction outcome loss': 0.7779977695662, 'Total loss': 0.7779977695662}
2022-11-22 20:38:49,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:49,037 INFO:     Epoch: 63
2022-11-22 20:38:49,791 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.804689572616057, 'Total loss': 0.804689572616057} | train loss {'Reaction outcome loss': 0.7802200526119727, 'Total loss': 0.7802200526119727}
2022-11-22 20:38:49,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:49,792 INFO:     Epoch: 64
2022-11-22 20:38:50,514 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7790320576591925, 'Total loss': 0.7790320576591925} | train loss {'Reaction outcome loss': 0.7966378783648796, 'Total loss': 0.7966378783648796}
2022-11-22 20:38:50,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:50,515 INFO:     Epoch: 65
2022-11-22 20:38:51,306 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7544594996354796, 'Total loss': 0.7544594996354796} | train loss {'Reaction outcome loss': 0.7945239174703838, 'Total loss': 0.7945239174703838}
2022-11-22 20:38:51,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:51,306 INFO:     Epoch: 66
2022-11-22 20:38:52,114 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.744712616909634, 'Total loss': 0.744712616909634} | train loss {'Reaction outcome loss': 0.7918658944276663, 'Total loss': 0.7918658944276663}
2022-11-22 20:38:52,114 INFO:     Found new best model at epoch 66
2022-11-22 20:38:52,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:52,115 INFO:     Epoch: 67
2022-11-22 20:38:52,842 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7684277465397661, 'Total loss': 0.7684277465397661} | train loss {'Reaction outcome loss': 0.7753140697715736, 'Total loss': 0.7753140697715736}
2022-11-22 20:38:52,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:52,842 INFO:     Epoch: 68
2022-11-22 20:38:53,608 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7462022345174443, 'Total loss': 0.7462022345174443} | train loss {'Reaction outcome loss': 0.7809834138825837, 'Total loss': 0.7809834138825837}
2022-11-22 20:38:53,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:53,608 INFO:     Epoch: 69
2022-11-22 20:38:54,357 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7789665657010946, 'Total loss': 0.7789665657010946} | train loss {'Reaction outcome loss': 0.7823954789262069, 'Total loss': 0.7823954789262069}
2022-11-22 20:38:54,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:54,357 INFO:     Epoch: 70
2022-11-22 20:38:55,112 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7305046130310405, 'Total loss': 0.7305046130310405} | train loss {'Reaction outcome loss': 0.7736326034976403, 'Total loss': 0.7736326034976403}
2022-11-22 20:38:55,112 INFO:     Found new best model at epoch 70
2022-11-22 20:38:55,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:55,113 INFO:     Epoch: 71
2022-11-22 20:38:55,833 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7254537418484688, 'Total loss': 0.7254537418484688} | train loss {'Reaction outcome loss': 0.7818217477817767, 'Total loss': 0.7818217477817767}
2022-11-22 20:38:55,833 INFO:     Found new best model at epoch 71
2022-11-22 20:38:55,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:55,834 INFO:     Epoch: 72
2022-11-22 20:38:56,600 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7310719307173382, 'Total loss': 0.7310719307173382} | train loss {'Reaction outcome loss': 0.7657291650892752, 'Total loss': 0.7657291650892752}
2022-11-22 20:38:56,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:56,600 INFO:     Epoch: 73
2022-11-22 20:38:57,360 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7360586713660847, 'Total loss': 0.7360586713660847} | train loss {'Reaction outcome loss': 0.7691243128918925, 'Total loss': 0.7691243128918925}
2022-11-22 20:38:57,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:57,360 INFO:     Epoch: 74
2022-11-22 20:38:58,108 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7237460471012376, 'Total loss': 0.7237460471012376} | train loss {'Reaction outcome loss': 0.7684230374903814, 'Total loss': 0.7684230374903814}
2022-11-22 20:38:58,108 INFO:     Found new best model at epoch 74
2022-11-22 20:38:58,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:58,109 INFO:     Epoch: 75
2022-11-22 20:38:58,803 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7780452600934289, 'Total loss': 0.7780452600934289} | train loss {'Reaction outcome loss': 0.7628950534561868, 'Total loss': 0.7628950534561868}
2022-11-22 20:38:58,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:58,803 INFO:     Epoch: 76
2022-11-22 20:38:59,540 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7940685058181937, 'Total loss': 0.7940685058181937} | train loss {'Reaction outcome loss': 0.7606300679054337, 'Total loss': 0.7606300679054337}
2022-11-22 20:38:59,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:38:59,540 INFO:     Epoch: 77
2022-11-22 20:39:00,278 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7381720299070532, 'Total loss': 0.7381720299070532} | train loss {'Reaction outcome loss': 0.7716581808169362, 'Total loss': 0.7716581808169362}
2022-11-22 20:39:00,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:00,278 INFO:     Epoch: 78
2022-11-22 20:39:01,058 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7289614609696649, 'Total loss': 0.7289614609696649} | train loss {'Reaction outcome loss': 0.7609180027415395, 'Total loss': 0.7609180027415395}
2022-11-22 20:39:01,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:01,058 INFO:     Epoch: 79
2022-11-22 20:39:01,810 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7275165299122984, 'Total loss': 0.7275165299122984} | train loss {'Reaction outcome loss': 0.7659931295072502, 'Total loss': 0.7659931295072502}
2022-11-22 20:39:01,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:01,810 INFO:     Epoch: 80
2022-11-22 20:39:02,579 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7394169758666645, 'Total loss': 0.7394169758666645} | train loss {'Reaction outcome loss': 0.7560420649857656, 'Total loss': 0.7560420649857656}
2022-11-22 20:39:02,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:02,579 INFO:     Epoch: 81
2022-11-22 20:39:03,320 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7242476791143417, 'Total loss': 0.7242476791143417} | train loss {'Reaction outcome loss': 0.7523349246032808, 'Total loss': 0.7523349246032808}
2022-11-22 20:39:03,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:03,320 INFO:     Epoch: 82
2022-11-22 20:39:04,119 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7004044963554903, 'Total loss': 0.7004044963554903} | train loss {'Reaction outcome loss': 0.7512104455758686, 'Total loss': 0.7512104455758686}
2022-11-22 20:39:04,119 INFO:     Found new best model at epoch 82
2022-11-22 20:39:04,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:04,120 INFO:     Epoch: 83
2022-11-22 20:39:04,863 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7127414284781977, 'Total loss': 0.7127414284781977} | train loss {'Reaction outcome loss': 0.7491385518509125, 'Total loss': 0.7491385518509125}
2022-11-22 20:39:04,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:04,864 INFO:     Epoch: 84
2022-11-22 20:39:05,608 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7285295609723438, 'Total loss': 0.7285295609723438} | train loss {'Reaction outcome loss': 0.7495576882893257, 'Total loss': 0.7495576882893257}
2022-11-22 20:39:05,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:05,608 INFO:     Epoch: 85
2022-11-22 20:39:06,328 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7141288254748691, 'Total loss': 0.7141288254748691} | train loss {'Reaction outcome loss': 0.7480624379658023, 'Total loss': 0.7480624379658023}
2022-11-22 20:39:06,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:06,329 INFO:     Epoch: 86
2022-11-22 20:39:07,026 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7102530266750943, 'Total loss': 0.7102530266750943} | train loss {'Reaction outcome loss': 0.7415261840530736, 'Total loss': 0.7415261840530736}
2022-11-22 20:39:07,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:07,026 INFO:     Epoch: 87
2022-11-22 20:39:07,779 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7291334217244928, 'Total loss': 0.7291334217244928} | train loss {'Reaction outcome loss': 0.7538478544607818, 'Total loss': 0.7538478544607818}
2022-11-22 20:39:07,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:07,780 INFO:     Epoch: 88
2022-11-22 20:39:08,570 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.695249390873042, 'Total loss': 0.695249390873042} | train loss {'Reaction outcome loss': 0.7483774985861682, 'Total loss': 0.7483774985861682}
2022-11-22 20:39:08,570 INFO:     Found new best model at epoch 88
2022-11-22 20:39:08,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:08,571 INFO:     Epoch: 89
2022-11-22 20:39:09,348 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7007164108482274, 'Total loss': 0.7007164108482274} | train loss {'Reaction outcome loss': 0.7487732853725372, 'Total loss': 0.7487732853725372}
2022-11-22 20:39:09,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:09,349 INFO:     Epoch: 90
2022-11-22 20:39:10,066 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7100372835993767, 'Total loss': 0.7100372835993767} | train loss {'Reaction outcome loss': 0.747248166003208, 'Total loss': 0.747248166003208}
2022-11-22 20:39:10,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:10,066 INFO:     Epoch: 91
2022-11-22 20:39:10,807 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8126257068731568, 'Total loss': 0.8126257068731568} | train loss {'Reaction outcome loss': 0.7381142096722174, 'Total loss': 0.7381142096722174}
2022-11-22 20:39:10,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:10,807 INFO:     Epoch: 92
2022-11-22 20:39:11,549 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.738230667331002, 'Total loss': 0.738230667331002} | train loss {'Reaction outcome loss': 0.7389945560380032, 'Total loss': 0.7389945560380032}
2022-11-22 20:39:11,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:11,549 INFO:     Epoch: 93
2022-11-22 20:39:12,268 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6809233115477995, 'Total loss': 0.6809233115477995} | train loss {'Reaction outcome loss': 0.7330621567814939, 'Total loss': 0.7330621567814939}
2022-11-22 20:39:12,270 INFO:     Found new best model at epoch 93
2022-11-22 20:39:12,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:12,271 INFO:     Epoch: 94
2022-11-22 20:39:12,981 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6912247403101488, 'Total loss': 0.6912247403101488} | train loss {'Reaction outcome loss': 0.7360374735675843, 'Total loss': 0.7360374735675843}
2022-11-22 20:39:12,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:12,981 INFO:     Epoch: 95
2022-11-22 20:39:13,725 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7156018533489921, 'Total loss': 0.7156018533489921} | train loss {'Reaction outcome loss': 0.7364662594278815, 'Total loss': 0.7364662594278815}
2022-11-22 20:39:13,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:13,725 INFO:     Epoch: 96
2022-11-22 20:39:14,471 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6949578151106834, 'Total loss': 0.6949578151106834} | train loss {'Reaction outcome loss': 0.7233303264085098, 'Total loss': 0.7233303264085098}
2022-11-22 20:39:14,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:14,471 INFO:     Epoch: 97
2022-11-22 20:39:15,259 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6752908697182481, 'Total loss': 0.6752908697182481} | train loss {'Reaction outcome loss': 0.7283642673902666, 'Total loss': 0.7283642673902666}
2022-11-22 20:39:15,260 INFO:     Found new best model at epoch 97
2022-11-22 20:39:15,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:15,261 INFO:     Epoch: 98
2022-11-22 20:39:15,996 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.675620824098587, 'Total loss': 0.675620824098587} | train loss {'Reaction outcome loss': 0.7284454605297038, 'Total loss': 0.7284454605297038}
2022-11-22 20:39:15,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:15,996 INFO:     Epoch: 99
2022-11-22 20:39:16,754 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6600062345916574, 'Total loss': 0.6600062345916574} | train loss {'Reaction outcome loss': 0.7295942716752952, 'Total loss': 0.7295942716752952}
2022-11-22 20:39:16,754 INFO:     Found new best model at epoch 99
2022-11-22 20:39:16,755 INFO:     Best model found after epoch 100 of 100.
2022-11-22 20:39:16,755 INFO:   Done with stage: TRAINING
2022-11-22 20:39:16,755 INFO:   Starting stage: EVALUATION
2022-11-22 20:39:16,873 INFO:   Done with stage: EVALUATION
2022-11-22 20:39:16,874 INFO:   Leaving out SEQ value Fold_3
2022-11-22 20:39:16,887 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-22 20:39:16,887 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:39:17,546 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:39:17,546 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:39:17,614 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:39:17,614 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:39:17,614 INFO:     No hyperparam tuning for this model
2022-11-22 20:39:17,614 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:39:17,614 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:39:17,615 INFO:     None feature selector for col prot
2022-11-22 20:39:17,615 INFO:     None feature selector for col prot
2022-11-22 20:39:17,615 INFO:     None feature selector for col prot
2022-11-22 20:39:17,616 INFO:     None feature selector for col chem
2022-11-22 20:39:17,616 INFO:     None feature selector for col chem
2022-11-22 20:39:17,616 INFO:     None feature selector for col chem
2022-11-22 20:39:17,616 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:39:17,616 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:39:17,618 INFO:     Number of params in model 126091
2022-11-22 20:39:17,621 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:39:17,621 INFO:   Starting stage: TRAINING
2022-11-22 20:39:17,669 INFO:     Val loss before train {'Reaction outcome loss': 1.0517845833024313, 'Total loss': 1.0517845833024313}
2022-11-22 20:39:17,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:17,669 INFO:     Epoch: 0
2022-11-22 20:39:18,406 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8254141863002333, 'Total loss': 0.8254141863002333} | train loss {'Reaction outcome loss': 0.8700903444016566, 'Total loss': 0.8700903444016566}
2022-11-22 20:39:18,407 INFO:     Found new best model at epoch 0
2022-11-22 20:39:18,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:18,407 INFO:     Epoch: 1
2022-11-22 20:39:19,187 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8131014489850332, 'Total loss': 0.8131014489850332} | train loss {'Reaction outcome loss': 0.8309378383345292, 'Total loss': 0.8309378383345292}
2022-11-22 20:39:19,187 INFO:     Found new best model at epoch 1
2022-11-22 20:39:19,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:19,188 INFO:     Epoch: 2
2022-11-22 20:39:19,898 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.829928976158763, 'Total loss': 0.829928976158763} | train loss {'Reaction outcome loss': 0.8250138078068123, 'Total loss': 0.8250138078068123}
2022-11-22 20:39:19,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:19,899 INFO:     Epoch: 3
2022-11-22 20:39:20,600 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8210150356902632, 'Total loss': 0.8210150356902632} | train loss {'Reaction outcome loss': 0.8163359469321908, 'Total loss': 0.8163359469321908}
2022-11-22 20:39:20,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:20,600 INFO:     Epoch: 4
2022-11-22 20:39:21,321 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7985024937363558, 'Total loss': 0.7985024937363558} | train loss {'Reaction outcome loss': 0.8098243197701016, 'Total loss': 0.8098243197701016}
2022-11-22 20:39:21,322 INFO:     Found new best model at epoch 4
2022-11-22 20:39:21,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:21,322 INFO:     Epoch: 5
2022-11-22 20:39:22,061 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8251444156779799, 'Total loss': 0.8251444156779799} | train loss {'Reaction outcome loss': 0.8059512340143079, 'Total loss': 0.8059512340143079}
2022-11-22 20:39:22,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:22,061 INFO:     Epoch: 6
2022-11-22 20:39:22,832 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7939250891984895, 'Total loss': 0.7939250891984895} | train loss {'Reaction outcome loss': 0.8014101721957082, 'Total loss': 0.8014101721957082}
2022-11-22 20:39:22,832 INFO:     Found new best model at epoch 6
2022-11-22 20:39:22,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:22,833 INFO:     Epoch: 7
2022-11-22 20:39:23,600 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7939614584279615, 'Total loss': 0.7939614584279615} | train loss {'Reaction outcome loss': 0.8004532085090387, 'Total loss': 0.8004532085090387}
2022-11-22 20:39:23,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:23,600 INFO:     Epoch: 8
2022-11-22 20:39:24,297 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7894313948792081, 'Total loss': 0.7894313948792081} | train loss {'Reaction outcome loss': 0.7956098076261457, 'Total loss': 0.7956098076261457}
2022-11-22 20:39:24,298 INFO:     Found new best model at epoch 8
2022-11-22 20:39:24,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:24,299 INFO:     Epoch: 9
2022-11-22 20:39:25,037 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8303275946960893, 'Total loss': 0.8303275946960893} | train loss {'Reaction outcome loss': 0.793364902622387, 'Total loss': 0.793364902622387}
2022-11-22 20:39:25,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:25,037 INFO:     Epoch: 10
2022-11-22 20:39:25,726 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7960945631182471, 'Total loss': 0.7960945631182471} | train loss {'Reaction outcome loss': 0.7987512822766774, 'Total loss': 0.7987512822766774}
2022-11-22 20:39:25,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:25,727 INFO:     Epoch: 11
2022-11-22 20:39:26,432 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7957287520863289, 'Total loss': 0.7957287520863289} | train loss {'Reaction outcome loss': 0.788345566416373, 'Total loss': 0.788345566416373}
2022-11-22 20:39:26,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:26,432 INFO:     Epoch: 12
2022-11-22 20:39:27,162 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7999287774396497, 'Total loss': 0.7999287774396497} | train loss {'Reaction outcome loss': 0.7950707135386155, 'Total loss': 0.7950707135386155}
2022-11-22 20:39:27,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:27,162 INFO:     Epoch: 13
2022-11-22 20:39:27,900 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8112695466640384, 'Total loss': 0.8112695466640384} | train loss {'Reaction outcome loss': 0.7944226253960953, 'Total loss': 0.7944226253960953}
2022-11-22 20:39:27,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:27,900 INFO:     Epoch: 14
2022-11-22 20:39:28,674 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7940982192061669, 'Total loss': 0.7940982192061669} | train loss {'Reaction outcome loss': 0.7873537141035815, 'Total loss': 0.7873537141035815}
2022-11-22 20:39:28,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:28,675 INFO:     Epoch: 15
2022-11-22 20:39:29,426 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7871654068314752, 'Total loss': 0.7871654068314752} | train loss {'Reaction outcome loss': 0.7894444214027436, 'Total loss': 0.7894444214027436}
2022-11-22 20:39:29,426 INFO:     Found new best model at epoch 15
2022-11-22 20:39:29,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:29,427 INFO:     Epoch: 16
2022-11-22 20:39:30,175 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8218812817750976, 'Total loss': 0.8218812817750976} | train loss {'Reaction outcome loss': 0.7871710478526647, 'Total loss': 0.7871710478526647}
2022-11-22 20:39:30,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:30,175 INFO:     Epoch: 17
2022-11-22 20:39:30,933 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7776644576427548, 'Total loss': 0.7776644576427548} | train loss {'Reaction outcome loss': 0.7853264323756343, 'Total loss': 0.7853264323756343}
2022-11-22 20:39:30,934 INFO:     Found new best model at epoch 17
2022-11-22 20:39:30,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:30,935 INFO:     Epoch: 18
2022-11-22 20:39:31,697 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7895858856134637, 'Total loss': 0.7895858856134637} | train loss {'Reaction outcome loss': 0.7906701537917872, 'Total loss': 0.7906701537917872}
2022-11-22 20:39:31,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:31,697 INFO:     Epoch: 19
2022-11-22 20:39:32,420 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7800760546395945, 'Total loss': 0.7800760546395945} | train loss {'Reaction outcome loss': 0.7871426059330096, 'Total loss': 0.7871426059330096}
2022-11-22 20:39:32,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:32,420 INFO:     Epoch: 20
2022-11-22 20:39:33,106 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8548619144184645, 'Total loss': 0.8548619144184645} | train loss {'Reaction outcome loss': 0.7881647218934825, 'Total loss': 0.7881647218934825}
2022-11-22 20:39:33,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:33,106 INFO:     Epoch: 21
2022-11-22 20:39:33,861 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8299647098363832, 'Total loss': 0.8299647098363832} | train loss {'Reaction outcome loss': 0.7891229634157947, 'Total loss': 0.7891229634157947}
2022-11-22 20:39:33,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:33,862 INFO:     Epoch: 22
2022-11-22 20:39:34,599 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7839819885963617, 'Total loss': 0.7839819885963617} | train loss {'Reaction outcome loss': 0.7850245771105172, 'Total loss': 0.7850245771105172}
2022-11-22 20:39:34,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:34,600 INFO:     Epoch: 23
2022-11-22 20:39:35,335 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7917886362519375, 'Total loss': 0.7917886362519375} | train loss {'Reaction outcome loss': 0.7890012307000942, 'Total loss': 0.7890012307000942}
2022-11-22 20:39:35,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:35,335 INFO:     Epoch: 24
2022-11-22 20:39:36,084 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7774262864922368, 'Total loss': 0.7774262864922368} | train loss {'Reaction outcome loss': 0.7856391284798012, 'Total loss': 0.7856391284798012}
2022-11-22 20:39:36,084 INFO:     Found new best model at epoch 24
2022-11-22 20:39:36,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:36,085 INFO:     Epoch: 25
2022-11-22 20:39:36,793 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7740458471830501, 'Total loss': 0.7740458471830501} | train loss {'Reaction outcome loss': 0.7834039343917956, 'Total loss': 0.7834039343917956}
2022-11-22 20:39:36,793 INFO:     Found new best model at epoch 25
2022-11-22 20:39:36,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:36,794 INFO:     Epoch: 26
2022-11-22 20:39:37,524 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7887682734533797, 'Total loss': 0.7887682734533797} | train loss {'Reaction outcome loss': 0.7841780527693326, 'Total loss': 0.7841780527693326}
2022-11-22 20:39:37,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:37,525 INFO:     Epoch: 27
2022-11-22 20:39:38,257 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.781499502963798, 'Total loss': 0.781499502963798} | train loss {'Reaction outcome loss': 0.7851509782867353, 'Total loss': 0.7851509782867353}
2022-11-22 20:39:38,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:38,257 INFO:     Epoch: 28
2022-11-22 20:39:39,047 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7638383417628533, 'Total loss': 0.7638383417628533} | train loss {'Reaction outcome loss': 0.7780328446724376, 'Total loss': 0.7780328446724376}
2022-11-22 20:39:39,047 INFO:     Found new best model at epoch 28
2022-11-22 20:39:39,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:39,048 INFO:     Epoch: 29
2022-11-22 20:39:39,776 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8501964724341105, 'Total loss': 0.8501964724341105} | train loss {'Reaction outcome loss': 0.7770679858131487, 'Total loss': 0.7770679858131487}
2022-11-22 20:39:39,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:39,776 INFO:     Epoch: 30
2022-11-22 20:39:40,529 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7895108918811, 'Total loss': 0.7895108918811} | train loss {'Reaction outcome loss': 0.781168677523488, 'Total loss': 0.781168677523488}
2022-11-22 20:39:40,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:40,530 INFO:     Epoch: 31
2022-11-22 20:39:41,246 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7721720296283101, 'Total loss': 0.7721720296283101} | train loss {'Reaction outcome loss': 0.7831332897309398, 'Total loss': 0.7831332897309398}
2022-11-22 20:39:41,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:41,247 INFO:     Epoch: 32
2022-11-22 20:39:41,965 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7704668349997942, 'Total loss': 0.7704668349997942} | train loss {'Reaction outcome loss': 0.7865904118926799, 'Total loss': 0.7865904118926799}
2022-11-22 20:39:41,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:41,966 INFO:     Epoch: 33
2022-11-22 20:39:42,691 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7651901272840278, 'Total loss': 0.7651901272840278} | train loss {'Reaction outcome loss': 0.7762541069847638, 'Total loss': 0.7762541069847638}
2022-11-22 20:39:42,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:42,692 INFO:     Epoch: 34
2022-11-22 20:39:43,425 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7670965284802193, 'Total loss': 0.7670965284802193} | train loss {'Reaction outcome loss': 0.7799962975206922, 'Total loss': 0.7799962975206922}
2022-11-22 20:39:43,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:43,426 INFO:     Epoch: 35
2022-11-22 20:39:44,190 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.775192110344421, 'Total loss': 0.775192110344421} | train loss {'Reaction outcome loss': 0.7785337700462732, 'Total loss': 0.7785337700462732}
2022-11-22 20:39:44,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:44,191 INFO:     Epoch: 36
2022-11-22 20:39:44,928 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7813518581002258, 'Total loss': 0.7813518581002258} | train loss {'Reaction outcome loss': 0.775504286538382, 'Total loss': 0.775504286538382}
2022-11-22 20:39:44,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:44,928 INFO:     Epoch: 37
2022-11-22 20:39:45,677 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7675259806389032, 'Total loss': 0.7675259806389032} | train loss {'Reaction outcome loss': 0.7731264725816055, 'Total loss': 0.7731264725816055}
2022-11-22 20:39:45,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:45,678 INFO:     Epoch: 38
2022-11-22 20:39:46,425 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7694538873295451, 'Total loss': 0.7694538873295451} | train loss {'Reaction outcome loss': 0.7724950700754025, 'Total loss': 0.7724950700754025}
2022-11-22 20:39:46,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:46,426 INFO:     Epoch: 39
2022-11-22 20:39:47,178 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7869480813658515, 'Total loss': 0.7869480813658515} | train loss {'Reaction outcome loss': 0.765055488611831, 'Total loss': 0.765055488611831}
2022-11-22 20:39:47,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:47,178 INFO:     Epoch: 40
2022-11-22 20:39:47,885 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7604230891826541, 'Total loss': 0.7604230891826541} | train loss {'Reaction outcome loss': 0.7697705429841261, 'Total loss': 0.7697705429841261}
2022-11-22 20:39:47,885 INFO:     Found new best model at epoch 40
2022-11-22 20:39:47,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:47,886 INFO:     Epoch: 41
2022-11-22 20:39:48,647 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7874771536782731, 'Total loss': 0.7874771536782731} | train loss {'Reaction outcome loss': 0.7689153010972211, 'Total loss': 0.7689153010972211}
2022-11-22 20:39:48,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:48,648 INFO:     Epoch: 42
2022-11-22 20:39:49,390 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.767666830572971, 'Total loss': 0.767666830572971} | train loss {'Reaction outcome loss': 0.7676772073399826, 'Total loss': 0.7676772073399826}
2022-11-22 20:39:49,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:49,390 INFO:     Epoch: 43
2022-11-22 20:39:50,143 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7499107794706211, 'Total loss': 0.7499107794706211} | train loss {'Reaction outcome loss': 0.7668858219365604, 'Total loss': 0.7668858219365604}
2022-11-22 20:39:50,144 INFO:     Found new best model at epoch 43
2022-11-22 20:39:50,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:50,145 INFO:     Epoch: 44
2022-11-22 20:39:50,869 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.779031112443569, 'Total loss': 0.779031112443569} | train loss {'Reaction outcome loss': 0.7625926350716685, 'Total loss': 0.7625926350716685}
2022-11-22 20:39:50,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:50,870 INFO:     Epoch: 45
2022-11-22 20:39:51,629 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7513994740885358, 'Total loss': 0.7513994740885358} | train loss {'Reaction outcome loss': 0.7632858716562146, 'Total loss': 0.7632858716562146}
2022-11-22 20:39:51,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:51,630 INFO:     Epoch: 46
2022-11-22 20:39:52,386 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7652732314065446, 'Total loss': 0.7652732314065446} | train loss {'Reaction outcome loss': 0.7635938310232319, 'Total loss': 0.7635938310232319}
2022-11-22 20:39:52,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:52,387 INFO:     Epoch: 47
2022-11-22 20:39:53,132 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7505306650039761, 'Total loss': 0.7505306650039761} | train loss {'Reaction outcome loss': 0.7650769076874999, 'Total loss': 0.7650769076874999}
2022-11-22 20:39:53,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:53,133 INFO:     Epoch: 48
2022-11-22 20:39:53,852 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7518792284089465, 'Total loss': 0.7518792284089465} | train loss {'Reaction outcome loss': 0.7600730969036211, 'Total loss': 0.7600730969036211}
2022-11-22 20:39:53,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:53,853 INFO:     Epoch: 49
2022-11-22 20:39:54,569 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.731762997632803, 'Total loss': 0.731762997632803} | train loss {'Reaction outcome loss': 0.7554418587538062, 'Total loss': 0.7554418587538062}
2022-11-22 20:39:54,569 INFO:     Found new best model at epoch 49
2022-11-22 20:39:54,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:54,570 INFO:     Epoch: 50
2022-11-22 20:39:55,350 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7552900050961694, 'Total loss': 0.7552900050961694} | train loss {'Reaction outcome loss': 0.7540354304870621, 'Total loss': 0.7540354304870621}
2022-11-22 20:39:55,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:55,350 INFO:     Epoch: 51
2022-11-22 20:39:56,063 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7409792182057403, 'Total loss': 0.7409792182057403} | train loss {'Reaction outcome loss': 0.7564533264910589, 'Total loss': 0.7564533264910589}
2022-11-22 20:39:56,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:56,064 INFO:     Epoch: 52
2022-11-22 20:39:56,787 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7658755876297174, 'Total loss': 0.7658755876297174} | train loss {'Reaction outcome loss': 0.7607489324739722, 'Total loss': 0.7607489324739722}
2022-11-22 20:39:56,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:56,788 INFO:     Epoch: 53
2022-11-22 20:39:57,485 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7594969307267389, 'Total loss': 0.7594969307267389} | train loss {'Reaction outcome loss': 0.746375458895183, 'Total loss': 0.746375458895183}
2022-11-22 20:39:57,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:57,485 INFO:     Epoch: 54
2022-11-22 20:39:58,225 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7304873625899471, 'Total loss': 0.7304873625899471} | train loss {'Reaction outcome loss': 0.7514981667770714, 'Total loss': 0.7514981667770714}
2022-11-22 20:39:58,226 INFO:     Found new best model at epoch 54
2022-11-22 20:39:58,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:58,226 INFO:     Epoch: 55
2022-11-22 20:39:58,959 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7812795029130093, 'Total loss': 0.7812795029130093} | train loss {'Reaction outcome loss': 0.7453235164284706, 'Total loss': 0.7453235164284706}
2022-11-22 20:39:58,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:58,959 INFO:     Epoch: 56
2022-11-22 20:39:59,736 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7510398369888927, 'Total loss': 0.7510398369888927} | train loss {'Reaction outcome loss': 0.7533808245522077, 'Total loss': 0.7533808245522077}
2022-11-22 20:39:59,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:39:59,737 INFO:     Epoch: 57
2022-11-22 20:40:00,482 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7543502145035322, 'Total loss': 0.7543502145035322} | train loss {'Reaction outcome loss': 0.74672212561623, 'Total loss': 0.74672212561623}
2022-11-22 20:40:00,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:00,482 INFO:     Epoch: 58
2022-11-22 20:40:01,215 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7512159292087999, 'Total loss': 0.7512159292087999} | train loss {'Reaction outcome loss': 0.7460893046904783, 'Total loss': 0.7460893046904783}
2022-11-22 20:40:01,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:01,215 INFO:     Epoch: 59
2022-11-22 20:40:01,952 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7461256766042044, 'Total loss': 0.7461256766042044} | train loss {'Reaction outcome loss': 0.740722467420531, 'Total loss': 0.740722467420531}
2022-11-22 20:40:01,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:01,952 INFO:     Epoch: 60
2022-11-22 20:40:02,706 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7307888276355211, 'Total loss': 0.7307888276355211} | train loss {'Reaction outcome loss': 0.7441054026855797, 'Total loss': 0.7441054026855797}
2022-11-22 20:40:02,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:02,707 INFO:     Epoch: 61
2022-11-22 20:40:03,413 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7299674867197524, 'Total loss': 0.7299674867197524} | train loss {'Reaction outcome loss': 0.7419170974219431, 'Total loss': 0.7419170974219431}
2022-11-22 20:40:03,414 INFO:     Found new best model at epoch 61
2022-11-22 20:40:03,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:03,414 INFO:     Epoch: 62
2022-11-22 20:40:04,171 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7487630352031353, 'Total loss': 0.7487630352031353} | train loss {'Reaction outcome loss': 0.7374338540630262, 'Total loss': 0.7374338540630262}
2022-11-22 20:40:04,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:04,171 INFO:     Epoch: 63
2022-11-22 20:40:04,911 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.745965474566748, 'Total loss': 0.745965474566748} | train loss {'Reaction outcome loss': 0.7361269385599699, 'Total loss': 0.7361269385599699}
2022-11-22 20:40:04,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:04,912 INFO:     Epoch: 64
2022-11-22 20:40:05,649 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7449514741121337, 'Total loss': 0.7449514741121337} | train loss {'Reaction outcome loss': 0.7371556766209055, 'Total loss': 0.7371556766209055}
2022-11-22 20:40:05,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:05,649 INFO:     Epoch: 65
2022-11-22 20:40:06,397 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7422320662542831, 'Total loss': 0.7422320662542831} | train loss {'Reaction outcome loss': 0.7363171942654203, 'Total loss': 0.7363171942654203}
2022-11-22 20:40:06,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:06,397 INFO:     Epoch: 66
2022-11-22 20:40:07,164 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7391085153402284, 'Total loss': 0.7391085153402284} | train loss {'Reaction outcome loss': 0.7397789988727843, 'Total loss': 0.7397789988727843}
2022-11-22 20:40:07,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:07,165 INFO:     Epoch: 67
2022-11-22 20:40:07,897 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7334233910538429, 'Total loss': 0.7334233910538429} | train loss {'Reaction outcome loss': 0.7315885839892216, 'Total loss': 0.7315885839892216}
2022-11-22 20:40:07,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:07,897 INFO:     Epoch: 68
2022-11-22 20:40:08,644 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7238521527412326, 'Total loss': 0.7238521527412326} | train loss {'Reaction outcome loss': 0.728567865417629, 'Total loss': 0.728567865417629}
2022-11-22 20:40:08,644 INFO:     Found new best model at epoch 68
2022-11-22 20:40:08,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:08,645 INFO:     Epoch: 69
2022-11-22 20:40:09,370 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7255971161432044, 'Total loss': 0.7255971161432044} | train loss {'Reaction outcome loss': 0.7300395944812259, 'Total loss': 0.7300395944812259}
2022-11-22 20:40:09,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:09,370 INFO:     Epoch: 70
2022-11-22 20:40:10,073 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7206265780814859, 'Total loss': 0.7206265780814859} | train loss {'Reaction outcome loss': 0.7318411107923164, 'Total loss': 0.7318411107923164}
2022-11-22 20:40:10,073 INFO:     Found new best model at epoch 70
2022-11-22 20:40:10,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:10,074 INFO:     Epoch: 71
2022-11-22 20:40:10,826 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7210972198220187, 'Total loss': 0.7210972198220187} | train loss {'Reaction outcome loss': 0.7233859161373044, 'Total loss': 0.7233859161373044}
2022-11-22 20:40:10,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:10,826 INFO:     Epoch: 72
2022-11-22 20:40:11,563 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7391946558342424, 'Total loss': 0.7391946558342424} | train loss {'Reaction outcome loss': 0.7205674375911229, 'Total loss': 0.7205674375911229}
2022-11-22 20:40:11,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:11,563 INFO:     Epoch: 73
2022-11-22 20:40:12,306 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7345010915467906, 'Total loss': 0.7345010915467906} | train loss {'Reaction outcome loss': 0.7261973804504168, 'Total loss': 0.7261973804504168}
2022-11-22 20:40:12,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:12,306 INFO:     Epoch: 74
2022-11-22 20:40:13,045 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7212853459424751, 'Total loss': 0.7212853459424751} | train loss {'Reaction outcome loss': 0.7288576136114168, 'Total loss': 0.7288576136114168}
2022-11-22 20:40:13,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:13,045 INFO:     Epoch: 75
2022-11-22 20:40:13,752 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7659455821957699, 'Total loss': 0.7659455821957699} | train loss {'Reaction outcome loss': 0.7249129364480738, 'Total loss': 0.7249129364480738}
2022-11-22 20:40:13,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:13,752 INFO:     Epoch: 76
2022-11-22 20:40:14,473 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7246241465557454, 'Total loss': 0.7246241465557454} | train loss {'Reaction outcome loss': 0.714743693221788, 'Total loss': 0.714743693221788}
2022-11-22 20:40:14,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:14,474 INFO:     Epoch: 77
2022-11-22 20:40:15,187 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7192023451938185, 'Total loss': 0.7192023451938185} | train loss {'Reaction outcome loss': 0.7288559104819767, 'Total loss': 0.7288559104819767}
2022-11-22 20:40:15,187 INFO:     Found new best model at epoch 77
2022-11-22 20:40:15,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:15,188 INFO:     Epoch: 78
2022-11-22 20:40:15,905 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7139703776947287, 'Total loss': 0.7139703776947287} | train loss {'Reaction outcome loss': 0.7193032489692579, 'Total loss': 0.7193032489692579}
2022-11-22 20:40:15,905 INFO:     Found new best model at epoch 78
2022-11-22 20:40:15,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:15,906 INFO:     Epoch: 79
2022-11-22 20:40:16,638 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7128518071285513, 'Total loss': 0.7128518071285513} | train loss {'Reaction outcome loss': 0.7299929460907568, 'Total loss': 0.7299929460907568}
2022-11-22 20:40:16,638 INFO:     Found new best model at epoch 79
2022-11-22 20:40:16,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:16,639 INFO:     Epoch: 80
2022-11-22 20:40:17,402 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7360861010329668, 'Total loss': 0.7360861010329668} | train loss {'Reaction outcome loss': 0.7170029260584565, 'Total loss': 0.7170029260584565}
2022-11-22 20:40:17,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:17,402 INFO:     Epoch: 81
2022-11-22 20:40:18,137 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.763030314861342, 'Total loss': 0.763030314861342} | train loss {'Reaction outcome loss': 0.7205439581245673, 'Total loss': 0.7205439581245673}
2022-11-22 20:40:18,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:18,137 INFO:     Epoch: 82
2022-11-22 20:40:18,922 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7155131565970044, 'Total loss': 0.7155131565970044} | train loss {'Reaction outcome loss': 0.7269194828437977, 'Total loss': 0.7269194828437977}
2022-11-22 20:40:18,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:18,923 INFO:     Epoch: 83
2022-11-22 20:40:19,655 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7199309669261755, 'Total loss': 0.7199309669261755} | train loss {'Reaction outcome loss': 0.7170007630694107, 'Total loss': 0.7170007630694107}
2022-11-22 20:40:19,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:19,656 INFO:     Epoch: 84
2022-11-22 20:40:20,367 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7244447234065033, 'Total loss': 0.7244447234065033} | train loss {'Reaction outcome loss': 0.7153952301281398, 'Total loss': 0.7153952301281398}
2022-11-22 20:40:20,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:20,367 INFO:     Epoch: 85
2022-11-22 20:40:21,111 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7194444807462914, 'Total loss': 0.7194444807462914} | train loss {'Reaction outcome loss': 0.7206658653792788, 'Total loss': 0.7206658653792788}
2022-11-22 20:40:21,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:21,113 INFO:     Epoch: 86
2022-11-22 20:40:21,846 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7001920397891555, 'Total loss': 0.7001920397891555} | train loss {'Reaction outcome loss': 0.7220961301297438, 'Total loss': 0.7220961301297438}
2022-11-22 20:40:21,846 INFO:     Found new best model at epoch 86
2022-11-22 20:40:21,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:21,847 INFO:     Epoch: 87
2022-11-22 20:40:22,538 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7069063041099283, 'Total loss': 0.7069063041099283} | train loss {'Reaction outcome loss': 0.7231988668686054, 'Total loss': 0.7231988668686054}
2022-11-22 20:40:22,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:22,538 INFO:     Epoch: 88
2022-11-22 20:40:23,280 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.710925888183505, 'Total loss': 0.710925888183505} | train loss {'Reaction outcome loss': 0.7274806074431686, 'Total loss': 0.7274806074431686}
2022-11-22 20:40:23,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:23,281 INFO:     Epoch: 89
2022-11-22 20:40:24,024 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.739318800526996, 'Total loss': 0.739318800526996} | train loss {'Reaction outcome loss': 0.7215147100877567, 'Total loss': 0.7215147100877567}
2022-11-22 20:40:24,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:24,025 INFO:     Epoch: 90
2022-11-22 20:40:24,739 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7124775065932163, 'Total loss': 0.7124775065932163} | train loss {'Reaction outcome loss': 0.7163841409883538, 'Total loss': 0.7163841409883538}
2022-11-22 20:40:24,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:24,740 INFO:     Epoch: 91
2022-11-22 20:40:25,456 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7009601620740669, 'Total loss': 0.7009601620740669} | train loss {'Reaction outcome loss': 0.7219412313377271, 'Total loss': 0.7219412313377271}
2022-11-22 20:40:25,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:25,456 INFO:     Epoch: 92
2022-11-22 20:40:26,194 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7731952958328779, 'Total loss': 0.7731952958328779} | train loss {'Reaction outcome loss': 0.7207464316829306, 'Total loss': 0.7207464316829306}
2022-11-22 20:40:26,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:26,194 INFO:     Epoch: 93
2022-11-22 20:40:26,944 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7202301857083343, 'Total loss': 0.7202301857083343} | train loss {'Reaction outcome loss': 0.721163098318655, 'Total loss': 0.721163098318655}
2022-11-22 20:40:26,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:26,945 INFO:     Epoch: 94
2022-11-22 20:40:27,704 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6988744250563688, 'Total loss': 0.6988744250563688} | train loss {'Reaction outcome loss': 0.7127111317192922, 'Total loss': 0.7127111317192922}
2022-11-22 20:40:27,704 INFO:     Found new best model at epoch 94
2022-11-22 20:40:27,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:27,705 INFO:     Epoch: 95
2022-11-22 20:40:28,458 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7025636295939601, 'Total loss': 0.7025636295939601} | train loss {'Reaction outcome loss': 0.7170526458591712, 'Total loss': 0.7170526458591712}
2022-11-22 20:40:28,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:28,458 INFO:     Epoch: 96
2022-11-22 20:40:29,195 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7254932065342747, 'Total loss': 0.7254932065342747} | train loss {'Reaction outcome loss': 0.720710843923639, 'Total loss': 0.720710843923639}
2022-11-22 20:40:29,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:29,196 INFO:     Epoch: 97
2022-11-22 20:40:29,946 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7079504506532536, 'Total loss': 0.7079504506532536} | train loss {'Reaction outcome loss': 0.7170622196109568, 'Total loss': 0.7170622196109568}
2022-11-22 20:40:29,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:29,946 INFO:     Epoch: 98
2022-11-22 20:40:30,685 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7252896393454352, 'Total loss': 0.7252896393454352} | train loss {'Reaction outcome loss': 0.7149942160019132, 'Total loss': 0.7149942160019132}
2022-11-22 20:40:30,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:30,686 INFO:     Epoch: 99
2022-11-22 20:40:31,430 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7352523367072261, 'Total loss': 0.7352523367072261} | train loss {'Reaction outcome loss': 0.7268852452274228, 'Total loss': 0.7268852452274228}
2022-11-22 20:40:31,430 INFO:     Best model found after epoch 95 of 100.
2022-11-22 20:40:31,430 INFO:   Done with stage: TRAINING
2022-11-22 20:40:31,430 INFO:   Starting stage: EVALUATION
2022-11-22 20:40:31,559 INFO:   Done with stage: EVALUATION
2022-11-22 20:40:31,559 INFO:   Leaving out SEQ value Fold_4
2022-11-22 20:40:31,572 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 20:40:31,572 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:40:32,242 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:40:32,242 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:40:32,311 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:40:32,311 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:40:32,311 INFO:     No hyperparam tuning for this model
2022-11-22 20:40:32,311 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:40:32,311 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:40:32,312 INFO:     None feature selector for col prot
2022-11-22 20:40:32,312 INFO:     None feature selector for col prot
2022-11-22 20:40:32,312 INFO:     None feature selector for col prot
2022-11-22 20:40:32,313 INFO:     None feature selector for col chem
2022-11-22 20:40:32,313 INFO:     None feature selector for col chem
2022-11-22 20:40:32,313 INFO:     None feature selector for col chem
2022-11-22 20:40:32,313 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:40:32,313 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:40:32,315 INFO:     Number of params in model 126091
2022-11-22 20:40:32,318 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:40:32,318 INFO:   Starting stage: TRAINING
2022-11-22 20:40:32,367 INFO:     Val loss before train {'Reaction outcome loss': 1.0007290149276906, 'Total loss': 1.0007290149276906}
2022-11-22 20:40:32,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:32,367 INFO:     Epoch: 0
2022-11-22 20:40:33,092 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8355344892902807, 'Total loss': 0.8355344892902807} | train loss {'Reaction outcome loss': 0.8900238783849824, 'Total loss': 0.8900238783849824}
2022-11-22 20:40:33,092 INFO:     Found new best model at epoch 0
2022-11-22 20:40:33,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:33,093 INFO:     Epoch: 1
2022-11-22 20:40:33,858 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.821134549650279, 'Total loss': 0.821134549650279} | train loss {'Reaction outcome loss': 0.861188524673062, 'Total loss': 0.861188524673062}
2022-11-22 20:40:33,859 INFO:     Found new best model at epoch 1
2022-11-22 20:40:33,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:33,860 INFO:     Epoch: 2
2022-11-22 20:40:34,624 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8302497511560266, 'Total loss': 0.8302497511560266} | train loss {'Reaction outcome loss': 0.853169376330991, 'Total loss': 0.853169376330991}
2022-11-22 20:40:34,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:34,625 INFO:     Epoch: 3
2022-11-22 20:40:35,332 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8138277998024767, 'Total loss': 0.8138277998024767} | train loss {'Reaction outcome loss': 0.8464379750432507, 'Total loss': 0.8464379750432507}
2022-11-22 20:40:35,332 INFO:     Found new best model at epoch 3
2022-11-22 20:40:35,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:35,333 INFO:     Epoch: 4
2022-11-22 20:40:36,049 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7926927141167901, 'Total loss': 0.7926927141167901} | train loss {'Reaction outcome loss': 0.839188524191418, 'Total loss': 0.839188524191418}
2022-11-22 20:40:36,049 INFO:     Found new best model at epoch 4
2022-11-22 20:40:36,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:36,050 INFO:     Epoch: 5
2022-11-22 20:40:36,835 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.791088876399127, 'Total loss': 0.791088876399127} | train loss {'Reaction outcome loss': 0.834360652873593, 'Total loss': 0.834360652873593}
2022-11-22 20:40:36,835 INFO:     Found new best model at epoch 5
2022-11-22 20:40:36,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:36,836 INFO:     Epoch: 6
2022-11-22 20:40:37,600 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8217918181961233, 'Total loss': 0.8217918181961233} | train loss {'Reaction outcome loss': 0.8307455230143762, 'Total loss': 0.8307455230143762}
2022-11-22 20:40:37,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:37,601 INFO:     Epoch: 7
2022-11-22 20:40:38,342 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8277666060761972, 'Total loss': 0.8277666060761972} | train loss {'Reaction outcome loss': 0.8311332232288776, 'Total loss': 0.8311332232288776}
2022-11-22 20:40:38,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:38,343 INFO:     Epoch: 8
2022-11-22 20:40:39,124 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7929286313327876, 'Total loss': 0.7929286313327876} | train loss {'Reaction outcome loss': 0.8277422726875351, 'Total loss': 0.8277422726875351}
2022-11-22 20:40:39,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:39,125 INFO:     Epoch: 9
2022-11-22 20:40:39,873 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.782337674363093, 'Total loss': 0.782337674363093} | train loss {'Reaction outcome loss': 0.8231711035534259, 'Total loss': 0.8231711035534259}
2022-11-22 20:40:39,873 INFO:     Found new best model at epoch 9
2022-11-22 20:40:39,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:39,874 INFO:     Epoch: 10
2022-11-22 20:40:40,651 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.765283430841836, 'Total loss': 0.765283430841836} | train loss {'Reaction outcome loss': 0.820245162013077, 'Total loss': 0.820245162013077}
2022-11-22 20:40:40,651 INFO:     Found new best model at epoch 10
2022-11-22 20:40:40,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:40,652 INFO:     Epoch: 11
2022-11-22 20:40:41,358 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7858109867030924, 'Total loss': 0.7858109867030924} | train loss {'Reaction outcome loss': 0.8129774544748568, 'Total loss': 0.8129774544748568}
2022-11-22 20:40:41,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:41,358 INFO:     Epoch: 12
2022-11-22 20:40:42,159 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7797598032788797, 'Total loss': 0.7797598032788797} | train loss {'Reaction outcome loss': 0.8200438189650735, 'Total loss': 0.8200438189650735}
2022-11-22 20:40:42,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:42,159 INFO:     Epoch: 13
2022-11-22 20:40:42,903 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7785295830531553, 'Total loss': 0.7785295830531553} | train loss {'Reaction outcome loss': 0.8172458776783559, 'Total loss': 0.8172458776783559}
2022-11-22 20:40:42,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:42,904 INFO:     Epoch: 14
2022-11-22 20:40:43,674 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7826004231517966, 'Total loss': 0.7826004231517966} | train loss {'Reaction outcome loss': 0.8134036509981079, 'Total loss': 0.8134036509981079}
2022-11-22 20:40:43,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:43,674 INFO:     Epoch: 15
2022-11-22 20:40:44,412 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7846082211895422, 'Total loss': 0.7846082211895422} | train loss {'Reaction outcome loss': 0.8172314285991653, 'Total loss': 0.8172314285991653}
2022-11-22 20:40:44,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:44,412 INFO:     Epoch: 16
2022-11-22 20:40:45,215 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.780319253152067, 'Total loss': 0.780319253152067} | train loss {'Reaction outcome loss': 0.8143790665893785, 'Total loss': 0.8143790665893785}
2022-11-22 20:40:45,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:45,215 INFO:     Epoch: 17
2022-11-22 20:40:45,990 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7929397916251962, 'Total loss': 0.7929397916251962} | train loss {'Reaction outcome loss': 0.8042893736593185, 'Total loss': 0.8042893736593185}
2022-11-22 20:40:45,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:45,992 INFO:     Epoch: 18
2022-11-22 20:40:46,730 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7842021665789864, 'Total loss': 0.7842021665789864} | train loss {'Reaction outcome loss': 0.8127802856747182, 'Total loss': 0.8127802856747182}
2022-11-22 20:40:46,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:46,730 INFO:     Epoch: 19
2022-11-22 20:40:47,463 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7724575854160569, 'Total loss': 0.7724575854160569} | train loss {'Reaction outcome loss': 0.8157492934936478, 'Total loss': 0.8157492934936478}
2022-11-22 20:40:47,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:47,463 INFO:     Epoch: 20
2022-11-22 20:40:48,229 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7762937491590326, 'Total loss': 0.7762937491590326} | train loss {'Reaction outcome loss': 0.8092135319546345, 'Total loss': 0.8092135319546345}
2022-11-22 20:40:48,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:48,229 INFO:     Epoch: 21
2022-11-22 20:40:48,946 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7782376659187403, 'Total loss': 0.7782376659187403} | train loss {'Reaction outcome loss': 0.8115004686818968, 'Total loss': 0.8115004686818968}
2022-11-22 20:40:48,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:48,946 INFO:     Epoch: 22
2022-11-22 20:40:49,711 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7645307054573839, 'Total loss': 0.7645307054573839} | train loss {'Reaction outcome loss': 0.811228257633986, 'Total loss': 0.811228257633986}
2022-11-22 20:40:49,711 INFO:     Found new best model at epoch 22
2022-11-22 20:40:49,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:49,712 INFO:     Epoch: 23
2022-11-22 20:40:50,488 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.789921949532899, 'Total loss': 0.789921949532899} | train loss {'Reaction outcome loss': 0.8133904686377894, 'Total loss': 0.8133904686377894}
2022-11-22 20:40:50,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:50,488 INFO:     Epoch: 24
2022-11-22 20:40:51,270 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8145177493041212, 'Total loss': 0.8145177493041212} | train loss {'Reaction outcome loss': 0.8073401812824511, 'Total loss': 0.8073401812824511}
2022-11-22 20:40:51,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:51,270 INFO:     Epoch: 25
2022-11-22 20:40:52,057 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7707446827129885, 'Total loss': 0.7707446827129885} | train loss {'Reaction outcome loss': 0.8123906621288869, 'Total loss': 0.8123906621288869}
2022-11-22 20:40:52,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:52,058 INFO:     Epoch: 26
2022-11-22 20:40:52,831 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7877416393973611, 'Total loss': 0.7877416393973611} | train loss {'Reaction outcome loss': 0.8119207576157585, 'Total loss': 0.8119207576157585}
2022-11-22 20:40:52,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:52,831 INFO:     Epoch: 27
2022-11-22 20:40:53,643 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7804040604016997, 'Total loss': 0.7804040604016997} | train loss {'Reaction outcome loss': 0.8096240466881183, 'Total loss': 0.8096240466881183}
2022-11-22 20:40:53,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:53,643 INFO:     Epoch: 28
2022-11-22 20:40:54,427 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7805474813688885, 'Total loss': 0.7805474813688885} | train loss {'Reaction outcome loss': 0.8029108043880232, 'Total loss': 0.8029108043880232}
2022-11-22 20:40:54,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:54,427 INFO:     Epoch: 29
2022-11-22 20:40:55,167 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7879132770679214, 'Total loss': 0.7879132770679214} | train loss {'Reaction outcome loss': 0.8087205193456142, 'Total loss': 0.8087205193456142}
2022-11-22 20:40:55,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:55,167 INFO:     Epoch: 30
2022-11-22 20:40:55,958 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7733634066852656, 'Total loss': 0.7733634066852656} | train loss {'Reaction outcome loss': 0.8034409302617272, 'Total loss': 0.8034409302617272}
2022-11-22 20:40:55,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:55,958 INFO:     Epoch: 31
2022-11-22 20:40:56,713 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7804871140555902, 'Total loss': 0.7804871140555902} | train loss {'Reaction outcome loss': 0.804175662657907, 'Total loss': 0.804175662657907}
2022-11-22 20:40:56,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:56,713 INFO:     Epoch: 32
2022-11-22 20:40:57,453 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7863539193164218, 'Total loss': 0.7863539193164218} | train loss {'Reaction outcome loss': 0.8093723279814566, 'Total loss': 0.8093723279814566}
2022-11-22 20:40:57,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:57,454 INFO:     Epoch: 33
2022-11-22 20:40:58,238 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7932095337997783, 'Total loss': 0.7932095337997783} | train loss {'Reaction outcome loss': 0.8035201098649732, 'Total loss': 0.8035201098649732}
2022-11-22 20:40:58,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:58,238 INFO:     Epoch: 34
2022-11-22 20:40:58,979 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7933759499679912, 'Total loss': 0.7933759499679912} | train loss {'Reaction outcome loss': 0.8077540016703068, 'Total loss': 0.8077540016703068}
2022-11-22 20:40:58,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:58,980 INFO:     Epoch: 35
2022-11-22 20:40:59,726 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7781987495043061, 'Total loss': 0.7781987495043061} | train loss {'Reaction outcome loss': 0.8098419865052546, 'Total loss': 0.8098419865052546}
2022-11-22 20:40:59,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:40:59,727 INFO:     Epoch: 36
2022-11-22 20:41:00,476 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7957616719332609, 'Total loss': 0.7957616719332609} | train loss {'Reaction outcome loss': 0.8035064325217278, 'Total loss': 0.8035064325217278}
2022-11-22 20:41:00,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:00,477 INFO:     Epoch: 37
2022-11-22 20:41:01,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7771868712522767, 'Total loss': 0.7771868712522767} | train loss {'Reaction outcome loss': 0.8083134960503348, 'Total loss': 0.8083134960503348}
2022-11-22 20:41:01,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:01,255 INFO:     Epoch: 38
2022-11-22 20:41:02,036 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7634406218474562, 'Total loss': 0.7634406218474562} | train loss {'Reaction outcome loss': 0.8041403478672428, 'Total loss': 0.8041403478672428}
2022-11-22 20:41:02,036 INFO:     Found new best model at epoch 38
2022-11-22 20:41:02,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:02,037 INFO:     Epoch: 39
2022-11-22 20:41:02,809 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7810147154060277, 'Total loss': 0.7810147154060277} | train loss {'Reaction outcome loss': 0.8085274428369538, 'Total loss': 0.8085274428369538}
2022-11-22 20:41:02,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:02,809 INFO:     Epoch: 40
2022-11-22 20:41:03,597 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7684962844306772, 'Total loss': 0.7684962844306772} | train loss {'Reaction outcome loss': 0.8032109074054226, 'Total loss': 0.8032109074054226}
2022-11-22 20:41:03,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:03,597 INFO:     Epoch: 41
2022-11-22 20:41:04,393 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7645588876171545, 'Total loss': 0.7645588876171545} | train loss {'Reaction outcome loss': 0.8040807280809649, 'Total loss': 0.8040807280809649}
2022-11-22 20:41:04,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:04,394 INFO:     Epoch: 42
2022-11-22 20:41:05,241 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7778965485366908, 'Total loss': 0.7778965485366908} | train loss {'Reaction outcome loss': 0.8066968893812548, 'Total loss': 0.8066968893812548}
2022-11-22 20:41:05,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:05,241 INFO:     Epoch: 43
2022-11-22 20:41:06,001 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7981612560423937, 'Total loss': 0.7981612560423937} | train loss {'Reaction outcome loss': 0.8053201444206699, 'Total loss': 0.8053201444206699}
2022-11-22 20:41:06,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:06,002 INFO:     Epoch: 44
2022-11-22 20:41:06,815 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7699124650521711, 'Total loss': 0.7699124650521711} | train loss {'Reaction outcome loss': 0.8064116203496533, 'Total loss': 0.8064116203496533}
2022-11-22 20:41:06,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:06,816 INFO:     Epoch: 45
2022-11-22 20:41:07,565 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7860732125965032, 'Total loss': 0.7860732125965032} | train loss {'Reaction outcome loss': 0.8072987120718725, 'Total loss': 0.8072987120718725}
2022-11-22 20:41:07,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:07,566 INFO:     Epoch: 46
2022-11-22 20:41:08,306 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7979418256066062, 'Total loss': 0.7979418256066062} | train loss {'Reaction outcome loss': 0.8103518461988818, 'Total loss': 0.8103518461988818}
2022-11-22 20:41:08,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:08,306 INFO:     Epoch: 47
2022-11-22 20:41:09,048 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7683006748557091, 'Total loss': 0.7683006748557091} | train loss {'Reaction outcome loss': 0.8106870373650905, 'Total loss': 0.8106870373650905}
2022-11-22 20:41:09,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:09,048 INFO:     Epoch: 48
2022-11-22 20:41:09,807 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7807326872240413, 'Total loss': 0.7807326872240413} | train loss {'Reaction outcome loss': 0.8095564921536753, 'Total loss': 0.8095564921536753}
2022-11-22 20:41:09,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:09,807 INFO:     Epoch: 49
2022-11-22 20:41:10,581 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.790007814087651, 'Total loss': 0.790007814087651} | train loss {'Reaction outcome loss': 0.8061910135851752, 'Total loss': 0.8061910135851752}
2022-11-22 20:41:10,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:10,581 INFO:     Epoch: 50
2022-11-22 20:41:11,362 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7801105447790839, 'Total loss': 0.7801105447790839} | train loss {'Reaction outcome loss': 0.8033330424899056, 'Total loss': 0.8033330424899056}
2022-11-22 20:41:11,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:11,362 INFO:     Epoch: 51
2022-11-22 20:41:12,112 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7752727615562353, 'Total loss': 0.7752727615562353} | train loss {'Reaction outcome loss': 0.8100286068454865, 'Total loss': 0.8100286068454865}
2022-11-22 20:41:12,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:12,112 INFO:     Epoch: 52
2022-11-22 20:41:12,888 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7763780511238358, 'Total loss': 0.7763780511238358} | train loss {'Reaction outcome loss': 0.8110995463305904, 'Total loss': 0.8110995463305904}
2022-11-22 20:41:12,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:12,888 INFO:     Epoch: 53
2022-11-22 20:41:13,606 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8098848712715235, 'Total loss': 0.8098848712715235} | train loss {'Reaction outcome loss': 0.803826124677735, 'Total loss': 0.803826124677735}
2022-11-22 20:41:13,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:13,606 INFO:     Epoch: 54
2022-11-22 20:41:14,349 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7821816033260389, 'Total loss': 0.7821816033260389} | train loss {'Reaction outcome loss': 0.807515726214455, 'Total loss': 0.807515726214455}
2022-11-22 20:41:14,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:14,349 INFO:     Epoch: 55
2022-11-22 20:41:15,089 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8734073740514842, 'Total loss': 0.8734073740514842} | train loss {'Reaction outcome loss': 0.8055836302378485, 'Total loss': 0.8055836302378485}
2022-11-22 20:41:15,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:15,090 INFO:     Epoch: 56
2022-11-22 20:41:15,835 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7743093290112235, 'Total loss': 0.7743093290112235} | train loss {'Reaction outcome loss': 0.8101916751794277, 'Total loss': 0.8101916751794277}
2022-11-22 20:41:15,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:15,836 INFO:     Epoch: 57
2022-11-22 20:41:16,590 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7880981639027596, 'Total loss': 0.7880981639027596} | train loss {'Reaction outcome loss': 0.8033630880376985, 'Total loss': 0.8033630880376985}
2022-11-22 20:41:16,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:16,590 INFO:     Epoch: 58
2022-11-22 20:41:17,351 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7881116365844553, 'Total loss': 0.7881116365844553} | train loss {'Reaction outcome loss': 0.8045785373016712, 'Total loss': 0.8045785373016712}
2022-11-22 20:41:17,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:17,353 INFO:     Epoch: 59
2022-11-22 20:41:18,115 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7777017808773301, 'Total loss': 0.7777017808773301} | train loss {'Reaction outcome loss': 0.8065361610103038, 'Total loss': 0.8065361610103038}
2022-11-22 20:41:18,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:18,116 INFO:     Epoch: 60
2022-11-22 20:41:18,888 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7866514745083723, 'Total loss': 0.7866514745083723} | train loss {'Reaction outcome loss': 0.8101616876740609, 'Total loss': 0.8101616876740609}
2022-11-22 20:41:18,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:18,888 INFO:     Epoch: 61
2022-11-22 20:41:19,693 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7713938572190024, 'Total loss': 0.7713938572190024} | train loss {'Reaction outcome loss': 0.8062522798295944, 'Total loss': 0.8062522798295944}
2022-11-22 20:41:19,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:19,693 INFO:     Epoch: 62
2022-11-22 20:41:20,407 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7707333388653669, 'Total loss': 0.7707333388653669} | train loss {'Reaction outcome loss': 0.8061537428969338, 'Total loss': 0.8061537428969338}
2022-11-22 20:41:20,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:20,407 INFO:     Epoch: 63
2022-11-22 20:41:21,173 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7650890472260389, 'Total loss': 0.7650890472260389} | train loss {'Reaction outcome loss': 0.806094947361177, 'Total loss': 0.806094947361177}
2022-11-22 20:41:21,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:21,174 INFO:     Epoch: 64
2022-11-22 20:41:21,928 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7712707065723159, 'Total loss': 0.7712707065723159} | train loss {'Reaction outcome loss': 0.8066595852855714, 'Total loss': 0.8066595852855714}
2022-11-22 20:41:21,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:21,928 INFO:     Epoch: 65
2022-11-22 20:41:22,674 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7757226011969827, 'Total loss': 0.7757226011969827} | train loss {'Reaction outcome loss': 0.8064366794161258, 'Total loss': 0.8064366794161258}
2022-11-22 20:41:22,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:22,674 INFO:     Epoch: 66
2022-11-22 20:41:23,412 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7815555496649309, 'Total loss': 0.7815555496649309} | train loss {'Reaction outcome loss': 0.8114049104192564, 'Total loss': 0.8114049104192564}
2022-11-22 20:41:23,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:23,413 INFO:     Epoch: 67
2022-11-22 20:41:24,177 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8084840354594317, 'Total loss': 0.8084840354594317} | train loss {'Reaction outcome loss': 0.8040573008118137, 'Total loss': 0.8040573008118137}
2022-11-22 20:41:24,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:24,177 INFO:     Epoch: 68
2022-11-22 20:41:24,933 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7724864360961047, 'Total loss': 0.7724864360961047} | train loss {'Reaction outcome loss': 0.8068752781518044, 'Total loss': 0.8068752781518044}
2022-11-22 20:41:24,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:24,933 INFO:     Epoch: 69
2022-11-22 20:41:25,749 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7765275483781641, 'Total loss': 0.7765275483781641} | train loss {'Reaction outcome loss': 0.8063308306999745, 'Total loss': 0.8063308306999745}
2022-11-22 20:41:25,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:25,749 INFO:     Epoch: 70
2022-11-22 20:41:26,488 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7564588697119192, 'Total loss': 0.7564588697119192} | train loss {'Reaction outcome loss': 0.8042815229104411, 'Total loss': 0.8042815229104411}
2022-11-22 20:41:26,488 INFO:     Found new best model at epoch 70
2022-11-22 20:41:26,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:26,489 INFO:     Epoch: 71
2022-11-22 20:41:27,233 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7681619342077862, 'Total loss': 0.7681619342077862} | train loss {'Reaction outcome loss': 0.8089834760513998, 'Total loss': 0.8089834760513998}
2022-11-22 20:41:27,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:27,234 INFO:     Epoch: 72
2022-11-22 20:41:27,998 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7780018828131936, 'Total loss': 0.7780018828131936} | train loss {'Reaction outcome loss': 0.8064428127460903, 'Total loss': 0.8064428127460903}
2022-11-22 20:41:27,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:27,998 INFO:     Epoch: 73
2022-11-22 20:41:28,784 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7799601527777585, 'Total loss': 0.7799601527777585} | train loss {'Reaction outcome loss': 0.803865751191493, 'Total loss': 0.803865751191493}
2022-11-22 20:41:28,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:28,784 INFO:     Epoch: 74
2022-11-22 20:41:29,566 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7912717901847579, 'Total loss': 0.7912717901847579} | train loss {'Reaction outcome loss': 0.8025410588710539, 'Total loss': 0.8025410588710539}
2022-11-22 20:41:29,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:29,566 INFO:     Epoch: 75
2022-11-22 20:41:30,282 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7729373553937132, 'Total loss': 0.7729373553937132} | train loss {'Reaction outcome loss': 0.8081806378979837, 'Total loss': 0.8081806378979837}
2022-11-22 20:41:30,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:30,283 INFO:     Epoch: 76
2022-11-22 20:41:31,055 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8109362653710626, 'Total loss': 0.8109362653710626} | train loss {'Reaction outcome loss': 0.802896175894045, 'Total loss': 0.802896175894045}
2022-11-22 20:41:31,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:31,055 INFO:     Epoch: 77
2022-11-22 20:41:31,831 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8006268319758502, 'Total loss': 0.8006268319758502} | train loss {'Reaction outcome loss': 0.8061471213736842, 'Total loss': 0.8061471213736842}
2022-11-22 20:41:31,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:31,831 INFO:     Epoch: 78
2022-11-22 20:41:32,602 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7962775122035634, 'Total loss': 0.7962775122035634} | train loss {'Reaction outcome loss': 0.8040039267751479, 'Total loss': 0.8040039267751479}
2022-11-22 20:41:32,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:32,602 INFO:     Epoch: 79
2022-11-22 20:41:33,400 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7671116387302225, 'Total loss': 0.7671116387302225} | train loss {'Reaction outcome loss': 0.8069349176460697, 'Total loss': 0.8069349176460697}
2022-11-22 20:41:33,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:33,400 INFO:     Epoch: 80
2022-11-22 20:41:34,153 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7807195572690531, 'Total loss': 0.7807195572690531} | train loss {'Reaction outcome loss': 0.8061488590413525, 'Total loss': 0.8061488590413525}
2022-11-22 20:41:34,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:34,153 INFO:     Epoch: 81
2022-11-22 20:41:34,916 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7779229771007191, 'Total loss': 0.7779229771007191} | train loss {'Reaction outcome loss': 0.7977763836181933, 'Total loss': 0.7977763836181933}
2022-11-22 20:41:34,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:34,917 INFO:     Epoch: 82
2022-11-22 20:41:35,672 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7793223756280813, 'Total loss': 0.7793223756280813} | train loss {'Reaction outcome loss': 0.7971030449074122, 'Total loss': 0.7971030449074122}
2022-11-22 20:41:35,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:35,673 INFO:     Epoch: 83
2022-11-22 20:41:36,396 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7814072695645419, 'Total loss': 0.7814072695645419} | train loss {'Reaction outcome loss': 0.8030901774764061, 'Total loss': 0.8030901774764061}
2022-11-22 20:41:36,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:36,396 INFO:     Epoch: 84
2022-11-22 20:41:37,189 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7699334912679412, 'Total loss': 0.7699334912679412} | train loss {'Reaction outcome loss': 0.8033534127377695, 'Total loss': 0.8033534127377695}
2022-11-22 20:41:37,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:37,189 INFO:     Epoch: 85
2022-11-22 20:41:37,986 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7723046168684959, 'Total loss': 0.7723046168684959} | train loss {'Reaction outcome loss': 0.8083879664059608, 'Total loss': 0.8083879664059608}
2022-11-22 20:41:37,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:37,986 INFO:     Epoch: 86
2022-11-22 20:41:38,742 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.759971484541893, 'Total loss': 0.759971484541893} | train loss {'Reaction outcome loss': 0.8048769127457372, 'Total loss': 0.8048769127457372}
2022-11-22 20:41:38,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:38,742 INFO:     Epoch: 87
2022-11-22 20:41:39,507 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7672237191687931, 'Total loss': 0.7672237191687931} | train loss {'Reaction outcome loss': 0.8066406093177295, 'Total loss': 0.8066406093177295}
2022-11-22 20:41:39,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:39,508 INFO:     Epoch: 88
2022-11-22 20:41:40,225 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7806204692883925, 'Total loss': 0.7806204692883925} | train loss {'Reaction outcome loss': 0.8022756691901914, 'Total loss': 0.8022756691901914}
2022-11-22 20:41:40,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:40,225 INFO:     Epoch: 89
2022-11-22 20:41:41,002 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7850016043944792, 'Total loss': 0.7850016043944792} | train loss {'Reaction outcome loss': 0.8077418646745144, 'Total loss': 0.8077418646745144}
2022-11-22 20:41:41,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:41,003 INFO:     Epoch: 90
2022-11-22 20:41:41,765 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7922832383350893, 'Total loss': 0.7922832383350893} | train loss {'Reaction outcome loss': 0.8052372549089694, 'Total loss': 0.8052372549089694}
2022-11-22 20:41:41,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:41,765 INFO:     Epoch: 91
2022-11-22 20:41:42,494 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.760714169930328, 'Total loss': 0.760714169930328} | train loss {'Reaction outcome loss': 0.810672405866846, 'Total loss': 0.810672405866846}
2022-11-22 20:41:42,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:42,495 INFO:     Epoch: 92
2022-11-22 20:41:43,233 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7831938104196028, 'Total loss': 0.7831938104196028} | train loss {'Reaction outcome loss': 0.8051321519118163, 'Total loss': 0.8051321519118163}
2022-11-22 20:41:43,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:43,233 INFO:     Epoch: 93
2022-11-22 20:41:43,977 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7630830996415832, 'Total loss': 0.7630830996415832} | train loss {'Reaction outcome loss': 0.8015696675546707, 'Total loss': 0.8015696675546707}
2022-11-22 20:41:43,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:43,977 INFO:     Epoch: 94
2022-11-22 20:41:44,710 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7997786070812832, 'Total loss': 0.7997786070812832} | train loss {'Reaction outcome loss': 0.8040154714497828, 'Total loss': 0.8040154714497828}
2022-11-22 20:41:44,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:44,710 INFO:     Epoch: 95
2022-11-22 20:41:45,460 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7719737298109315, 'Total loss': 0.7719737298109315} | train loss {'Reaction outcome loss': 0.8046882751608088, 'Total loss': 0.8046882751608088}
2022-11-22 20:41:45,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:45,460 INFO:     Epoch: 96
2022-11-22 20:41:46,231 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7587372078136965, 'Total loss': 0.7587372078136965} | train loss {'Reaction outcome loss': 0.8075227690560203, 'Total loss': 0.8075227690560203}
2022-11-22 20:41:46,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:46,232 INFO:     Epoch: 97
2022-11-22 20:41:47,003 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7825735035267744, 'Total loss': 0.7825735035267744} | train loss {'Reaction outcome loss': 0.8003209818515086, 'Total loss': 0.8003209818515086}
2022-11-22 20:41:47,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:47,003 INFO:     Epoch: 98
2022-11-22 20:41:47,788 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7767509953542189, 'Total loss': 0.7767509953542189} | train loss {'Reaction outcome loss': 0.8054340570684402, 'Total loss': 0.8054340570684402}
2022-11-22 20:41:47,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:47,788 INFO:     Epoch: 99
2022-11-22 20:41:48,537 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.769206468354572, 'Total loss': 0.769206468354572} | train loss {'Reaction outcome loss': 0.8067963031991836, 'Total loss': 0.8067963031991836}
2022-11-22 20:41:48,538 INFO:     Best model found after epoch 71 of 100.
2022-11-22 20:41:48,539 INFO:   Done with stage: TRAINING
2022-11-22 20:41:48,539 INFO:   Starting stage: EVALUATION
2022-11-22 20:41:48,652 INFO:   Done with stage: EVALUATION
2022-11-22 20:41:48,653 INFO:   Leaving out SEQ value Fold_5
2022-11-22 20:41:48,666 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:41:48,666 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:41:49,341 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:41:49,341 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:41:49,412 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:41:49,412 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:41:49,412 INFO:     No hyperparam tuning for this model
2022-11-22 20:41:49,412 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:41:49,412 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:41:49,413 INFO:     None feature selector for col prot
2022-11-22 20:41:49,413 INFO:     None feature selector for col prot
2022-11-22 20:41:49,413 INFO:     None feature selector for col prot
2022-11-22 20:41:49,413 INFO:     None feature selector for col chem
2022-11-22 20:41:49,414 INFO:     None feature selector for col chem
2022-11-22 20:41:49,414 INFO:     None feature selector for col chem
2022-11-22 20:41:49,414 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:41:49,414 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:41:49,415 INFO:     Number of params in model 126091
2022-11-22 20:41:49,418 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:41:49,418 INFO:   Starting stage: TRAINING
2022-11-22 20:41:49,467 INFO:     Val loss before train {'Reaction outcome loss': 1.0535327250307256, 'Total loss': 1.0535327250307256}
2022-11-22 20:41:49,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:49,468 INFO:     Epoch: 0
2022-11-22 20:41:50,256 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8581716905940663, 'Total loss': 0.8581716905940663} | train loss {'Reaction outcome loss': 0.8685198443138648, 'Total loss': 0.8685198443138648}
2022-11-22 20:41:50,256 INFO:     Found new best model at epoch 0
2022-11-22 20:41:50,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:50,257 INFO:     Epoch: 1
2022-11-22 20:41:51,031 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8589388132095337, 'Total loss': 0.8589388132095337} | train loss {'Reaction outcome loss': 0.8454312321386839, 'Total loss': 0.8454312321386839}
2022-11-22 20:41:51,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:51,031 INFO:     Epoch: 2
2022-11-22 20:41:51,764 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8580308482050896, 'Total loss': 0.8580308482050896} | train loss {'Reaction outcome loss': 0.8393717513151979, 'Total loss': 0.8393717513151979}
2022-11-22 20:41:51,764 INFO:     Found new best model at epoch 2
2022-11-22 20:41:51,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:51,765 INFO:     Epoch: 3
2022-11-22 20:41:52,494 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8340478742664511, 'Total loss': 0.8340478742664511} | train loss {'Reaction outcome loss': 0.8219310944138268, 'Total loss': 0.8219310944138268}
2022-11-22 20:41:52,494 INFO:     Found new best model at epoch 3
2022-11-22 20:41:52,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:52,495 INFO:     Epoch: 4
2022-11-22 20:41:53,269 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8463267900727012, 'Total loss': 0.8463267900727012} | train loss {'Reaction outcome loss': 0.8198341901003108, 'Total loss': 0.8198341901003108}
2022-11-22 20:41:53,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:53,270 INFO:     Epoch: 5
2022-11-22 20:41:54,031 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8441136885773052, 'Total loss': 0.8441136885773052} | train loss {'Reaction outcome loss': 0.8180629497899218, 'Total loss': 0.8180629497899218}
2022-11-22 20:41:54,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:54,031 INFO:     Epoch: 6
2022-11-22 20:41:54,809 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8295375697992065, 'Total loss': 0.8295375697992065} | train loss {'Reaction outcome loss': 0.8077716386993887, 'Total loss': 0.8077716386993887}
2022-11-22 20:41:54,810 INFO:     Found new best model at epoch 6
2022-11-22 20:41:54,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:54,811 INFO:     Epoch: 7
2022-11-22 20:41:55,541 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8409489054571498, 'Total loss': 0.8409489054571498} | train loss {'Reaction outcome loss': 0.7986402902525929, 'Total loss': 0.7986402902525929}
2022-11-22 20:41:55,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:55,542 INFO:     Epoch: 8
2022-11-22 20:41:56,270 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8321166444908489, 'Total loss': 0.8321166444908489} | train loss {'Reaction outcome loss': 0.7998305152543643, 'Total loss': 0.7998305152543643}
2022-11-22 20:41:56,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:56,271 INFO:     Epoch: 9
2022-11-22 20:41:57,003 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8462040268562057, 'Total loss': 0.8462040268562057} | train loss {'Reaction outcome loss': 0.8039131832991534, 'Total loss': 0.8039131832991534}
2022-11-22 20:41:57,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:57,003 INFO:     Epoch: 10
2022-11-22 20:41:57,725 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.81475960531018, 'Total loss': 0.81475960531018} | train loss {'Reaction outcome loss': 0.8011101522909002, 'Total loss': 0.8011101522909002}
2022-11-22 20:41:57,725 INFO:     Found new best model at epoch 10
2022-11-22 20:41:57,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:57,726 INFO:     Epoch: 11
2022-11-22 20:41:58,443 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8506543385711584, 'Total loss': 0.8506543385711584} | train loss {'Reaction outcome loss': 0.7955204388390669, 'Total loss': 0.7955204388390669}
2022-11-22 20:41:58,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:58,443 INFO:     Epoch: 12
2022-11-22 20:41:59,164 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8276264017278497, 'Total loss': 0.8276264017278497} | train loss {'Reaction outcome loss': 0.7938354253044978, 'Total loss': 0.7938354253044978}
2022-11-22 20:41:59,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:59,164 INFO:     Epoch: 13
2022-11-22 20:41:59,914 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8637428432703018, 'Total loss': 0.8637428432703018} | train loss {'Reaction outcome loss': 0.7910678203289325, 'Total loss': 0.7910678203289325}
2022-11-22 20:41:59,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:41:59,914 INFO:     Epoch: 14
2022-11-22 20:42:00,707 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8241086500612173, 'Total loss': 0.8241086500612173} | train loss {'Reaction outcome loss': 0.8025590568660241, 'Total loss': 0.8025590568660241}
2022-11-22 20:42:00,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:00,707 INFO:     Epoch: 15
2022-11-22 20:42:01,478 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8548947132446549, 'Total loss': 0.8548947132446549} | train loss {'Reaction outcome loss': 0.8023067121563653, 'Total loss': 0.8023067121563653}
2022-11-22 20:42:01,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:01,478 INFO:     Epoch: 16
2022-11-22 20:42:02,279 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8337600366635756, 'Total loss': 0.8337600366635756} | train loss {'Reaction outcome loss': 0.7937903362005828, 'Total loss': 0.7937903362005828}
2022-11-22 20:42:02,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:02,279 INFO:     Epoch: 17
2022-11-22 20:42:03,068 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8271442726254463, 'Total loss': 0.8271442726254463} | train loss {'Reaction outcome loss': 0.797968802664444, 'Total loss': 0.797968802664444}
2022-11-22 20:42:03,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:03,068 INFO:     Epoch: 18
2022-11-22 20:42:03,879 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.839609603990208, 'Total loss': 0.839609603990208} | train loss {'Reaction outcome loss': 0.8009637080223454, 'Total loss': 0.8009637080223454}
2022-11-22 20:42:03,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:03,879 INFO:     Epoch: 19
2022-11-22 20:42:04,669 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8233964741230011, 'Total loss': 0.8233964741230011} | train loss {'Reaction outcome loss': 0.7886642244934794, 'Total loss': 0.7886642244934794}
2022-11-22 20:42:04,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:04,670 INFO:     Epoch: 20
2022-11-22 20:42:05,443 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8348898819901727, 'Total loss': 0.8348898819901727} | train loss {'Reaction outcome loss': 0.7914437829000265, 'Total loss': 0.7914437829000265}
2022-11-22 20:42:05,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:05,443 INFO:     Epoch: 21
2022-11-22 20:42:06,259 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8456651209430261, 'Total loss': 0.8456651209430261} | train loss {'Reaction outcome loss': 0.7889643434570869, 'Total loss': 0.7889643434570869}
2022-11-22 20:42:06,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:06,259 INFO:     Epoch: 22
2022-11-22 20:42:07,109 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8300051851706072, 'Total loss': 0.8300051851706072} | train loss {'Reaction outcome loss': 0.7888163503425324, 'Total loss': 0.7888163503425324}
2022-11-22 20:42:07,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:07,110 INFO:     Epoch: 23
2022-11-22 20:42:07,933 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8078326921571385, 'Total loss': 0.8078326921571385} | train loss {'Reaction outcome loss': 0.781541679914181, 'Total loss': 0.781541679914181}
2022-11-22 20:42:07,933 INFO:     Found new best model at epoch 23
2022-11-22 20:42:07,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:07,934 INFO:     Epoch: 24
2022-11-22 20:42:08,764 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.856702595949173, 'Total loss': 0.856702595949173} | train loss {'Reaction outcome loss': 0.7905983043465055, 'Total loss': 0.7905983043465055}
2022-11-22 20:42:08,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:08,764 INFO:     Epoch: 25
2022-11-22 20:42:09,582 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8309344974431124, 'Total loss': 0.8309344974431124} | train loss {'Reaction outcome loss': 0.7979151064809035, 'Total loss': 0.7979151064809035}
2022-11-22 20:42:09,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:09,582 INFO:     Epoch: 26
2022-11-22 20:42:10,402 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8532561754638498, 'Total loss': 0.8532561754638498} | train loss {'Reaction outcome loss': 0.7849487473486889, 'Total loss': 0.7849487473486889}
2022-11-22 20:42:10,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:10,402 INFO:     Epoch: 27
2022-11-22 20:42:11,240 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8176856332204558, 'Total loss': 0.8176856332204558} | train loss {'Reaction outcome loss': 0.7933883568053304, 'Total loss': 0.7933883568053304}
2022-11-22 20:42:11,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:11,240 INFO:     Epoch: 28
2022-11-22 20:42:12,015 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8354929902336814, 'Total loss': 0.8354929902336814} | train loss {'Reaction outcome loss': 0.7850209531875757, 'Total loss': 0.7850209531875757}
2022-11-22 20:42:12,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:12,015 INFO:     Epoch: 29
2022-11-22 20:42:12,784 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8493976383046671, 'Total loss': 0.8493976383046671} | train loss {'Reaction outcome loss': 0.7899662256240845, 'Total loss': 0.7899662256240845}
2022-11-22 20:42:12,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:12,784 INFO:     Epoch: 30
2022-11-22 20:42:13,627 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8613560430028222, 'Total loss': 0.8613560430028222} | train loss {'Reaction outcome loss': 0.7951084559986948, 'Total loss': 0.7951084559986948}
2022-11-22 20:42:13,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:13,627 INFO:     Epoch: 31
2022-11-22 20:42:14,458 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8118003708395091, 'Total loss': 0.8118003708395091} | train loss {'Reaction outcome loss': 0.7873105190784825, 'Total loss': 0.7873105190784825}
2022-11-22 20:42:14,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:14,458 INFO:     Epoch: 32
2022-11-22 20:42:15,286 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8154788118871775, 'Total loss': 0.8154788118871775} | train loss {'Reaction outcome loss': 0.7854829188662502, 'Total loss': 0.7854829188662502}
2022-11-22 20:42:15,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:15,287 INFO:     Epoch: 33
2022-11-22 20:42:16,138 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8363160504536196, 'Total loss': 0.8363160504536196} | train loss {'Reaction outcome loss': 0.7835057733753915, 'Total loss': 0.7835057733753915}
2022-11-22 20:42:16,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:16,138 INFO:     Epoch: 34
2022-11-22 20:42:16,952 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.821563759310679, 'Total loss': 0.821563759310679} | train loss {'Reaction outcome loss': 0.7928907182293865, 'Total loss': 0.7928907182293865}
2022-11-22 20:42:16,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:16,953 INFO:     Epoch: 35
2022-11-22 20:42:17,780 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8620375489646738, 'Total loss': 0.8620375489646738} | train loss {'Reaction outcome loss': 0.7982838678697826, 'Total loss': 0.7982838678697826}
2022-11-22 20:42:17,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:17,780 INFO:     Epoch: 36
2022-11-22 20:42:18,602 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8280574543909593, 'Total loss': 0.8280574543909593} | train loss {'Reaction outcome loss': 0.7851352254871414, 'Total loss': 0.7851352254871414}
2022-11-22 20:42:18,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:18,602 INFO:     Epoch: 37
2022-11-22 20:42:19,444 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8301607350056822, 'Total loss': 0.8301607350056822} | train loss {'Reaction outcome loss': 0.7880069267773918, 'Total loss': 0.7880069267773918}
2022-11-22 20:42:19,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:19,446 INFO:     Epoch: 38
2022-11-22 20:42:20,253 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.813060691410845, 'Total loss': 0.813060691410845} | train loss {'Reaction outcome loss': 0.7869415520897761, 'Total loss': 0.7869415520897761}
2022-11-22 20:42:20,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:20,253 INFO:     Epoch: 39
2022-11-22 20:42:21,064 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8353956680406224, 'Total loss': 0.8353956680406224} | train loss {'Reaction outcome loss': 0.7949981966964629, 'Total loss': 0.7949981966964629}
2022-11-22 20:42:21,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:21,065 INFO:     Epoch: 40
2022-11-22 20:42:21,887 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8677945678884332, 'Total loss': 0.8677945678884332} | train loss {'Reaction outcome loss': 0.7850252814621095, 'Total loss': 0.7850252814621095}
2022-11-22 20:42:21,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:21,888 INFO:     Epoch: 41
2022-11-22 20:42:22,714 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.811669678173282, 'Total loss': 0.811669678173282} | train loss {'Reaction outcome loss': 0.7893313480774883, 'Total loss': 0.7893313480774883}
2022-11-22 20:42:22,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:22,714 INFO:     Epoch: 42
2022-11-22 20:42:23,527 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8095819828185168, 'Total loss': 0.8095819828185168} | train loss {'Reaction outcome loss': 0.7810206547801793, 'Total loss': 0.7810206547801793}
2022-11-22 20:42:23,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:23,528 INFO:     Epoch: 43
2022-11-22 20:42:24,343 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8079718188806013, 'Total loss': 0.8079718188806013} | train loss {'Reaction outcome loss': 0.7769758830427641, 'Total loss': 0.7769758830427641}
2022-11-22 20:42:24,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:24,344 INFO:     Epoch: 44
2022-11-22 20:42:25,142 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8083683800968257, 'Total loss': 0.8083683800968257} | train loss {'Reaction outcome loss': 0.7828235185218726, 'Total loss': 0.7828235185218726}
2022-11-22 20:42:25,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:25,143 INFO:     Epoch: 45
2022-11-22 20:42:25,962 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8195540214126761, 'Total loss': 0.8195540214126761} | train loss {'Reaction outcome loss': 0.7770458376600675, 'Total loss': 0.7770458376600675}
2022-11-22 20:42:25,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:25,963 INFO:     Epoch: 46
2022-11-22 20:42:26,710 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8173199512741782, 'Total loss': 0.8173199512741782} | train loss {'Reaction outcome loss': 0.7790656722026316, 'Total loss': 0.7790656722026316}
2022-11-22 20:42:26,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:26,710 INFO:     Epoch: 47
2022-11-22 20:42:27,506 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.839831991629167, 'Total loss': 0.839831991629167} | train loss {'Reaction outcome loss': 0.7752683522247592, 'Total loss': 0.7752683522247592}
2022-11-22 20:42:27,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:27,507 INFO:     Epoch: 48
2022-11-22 20:42:28,307 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8150697147304361, 'Total loss': 0.8150697147304361} | train loss {'Reaction outcome loss': 0.7783189923898411, 'Total loss': 0.7783189923898411}
2022-11-22 20:42:28,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:28,307 INFO:     Epoch: 49
2022-11-22 20:42:29,113 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8214206065643918, 'Total loss': 0.8214206065643918} | train loss {'Reaction outcome loss': 0.7767426028304737, 'Total loss': 0.7767426028304737}
2022-11-22 20:42:29,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:29,113 INFO:     Epoch: 50
2022-11-22 20:42:29,886 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8188387189399112, 'Total loss': 0.8188387189399112} | train loss {'Reaction outcome loss': 0.7669196345274024, 'Total loss': 0.7669196345274024}
2022-11-22 20:42:29,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:29,886 INFO:     Epoch: 51
2022-11-22 20:42:30,726 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7953844273632223, 'Total loss': 0.7953844273632223} | train loss {'Reaction outcome loss': 0.7696907434627595, 'Total loss': 0.7696907434627595}
2022-11-22 20:42:30,726 INFO:     Found new best model at epoch 51
2022-11-22 20:42:30,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:30,727 INFO:     Epoch: 52
2022-11-22 20:42:31,501 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8163647624579343, 'Total loss': 0.8163647624579343} | train loss {'Reaction outcome loss': 0.7713641758389801, 'Total loss': 0.7713641758389801}
2022-11-22 20:42:31,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:31,501 INFO:     Epoch: 53
2022-11-22 20:42:32,290 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8292820263992656, 'Total loss': 0.8292820263992656} | train loss {'Reaction outcome loss': 0.7701609390467284, 'Total loss': 0.7701609390467284}
2022-11-22 20:42:32,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:32,291 INFO:     Epoch: 54
2022-11-22 20:42:33,092 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7933058122342284, 'Total loss': 0.7933058122342284} | train loss {'Reaction outcome loss': 0.768401896603677, 'Total loss': 0.768401896603677}
2022-11-22 20:42:33,093 INFO:     Found new best model at epoch 54
2022-11-22 20:42:33,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:33,094 INFO:     Epoch: 55
2022-11-22 20:42:33,879 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8069747496734966, 'Total loss': 0.8069747496734966} | train loss {'Reaction outcome loss': 0.7655389089936669, 'Total loss': 0.7655389089936669}
2022-11-22 20:42:33,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:33,880 INFO:     Epoch: 56
2022-11-22 20:42:34,721 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.810095107013529, 'Total loss': 0.810095107013529} | train loss {'Reaction outcome loss': 0.764405191487629, 'Total loss': 0.764405191487629}
2022-11-22 20:42:34,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:34,722 INFO:     Epoch: 57
2022-11-22 20:42:35,509 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.79379041492939, 'Total loss': 0.79379041492939} | train loss {'Reaction outcome loss': 0.7618149448985513, 'Total loss': 0.7618149448985513}
2022-11-22 20:42:35,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:35,510 INFO:     Epoch: 58
2022-11-22 20:42:36,313 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8262056952173059, 'Total loss': 0.8262056952173059} | train loss {'Reaction outcome loss': 0.7731472164513129, 'Total loss': 0.7731472164513129}
2022-11-22 20:42:36,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:36,314 INFO:     Epoch: 59
2022-11-22 20:42:37,129 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8058290793137117, 'Total loss': 0.8058290793137117} | train loss {'Reaction outcome loss': 0.7781392230919981, 'Total loss': 0.7781392230919981}
2022-11-22 20:42:37,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:37,130 INFO:     Epoch: 60
2022-11-22 20:42:37,967 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8096214072270826, 'Total loss': 0.8096214072270826} | train loss {'Reaction outcome loss': 0.7636207083941471, 'Total loss': 0.7636207083941471}
2022-11-22 20:42:37,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:37,968 INFO:     Epoch: 61
2022-11-22 20:42:38,731 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8060491599819877, 'Total loss': 0.8060491599819877} | train loss {'Reaction outcome loss': 0.7677359045275792, 'Total loss': 0.7677359045275792}
2022-11-22 20:42:38,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:38,731 INFO:     Epoch: 62
2022-11-22 20:42:39,495 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7959294718774882, 'Total loss': 0.7959294718774882} | train loss {'Reaction outcome loss': 0.7694774262818248, 'Total loss': 0.7694774262818248}
2022-11-22 20:42:39,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:39,495 INFO:     Epoch: 63
2022-11-22 20:42:40,290 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7933203842152249, 'Total loss': 0.7933203842152249} | train loss {'Reaction outcome loss': 0.7666688192831842, 'Total loss': 0.7666688192831842}
2022-11-22 20:42:40,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:40,290 INFO:     Epoch: 64
2022-11-22 20:42:41,112 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7945782406763597, 'Total loss': 0.7945782406763597} | train loss {'Reaction outcome loss': 0.7586444109557611, 'Total loss': 0.7586444109557611}
2022-11-22 20:42:41,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:41,113 INFO:     Epoch: 65
2022-11-22 20:42:41,908 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8026576990431006, 'Total loss': 0.8026576990431006} | train loss {'Reaction outcome loss': 0.7554591095399278, 'Total loss': 0.7554591095399278}
2022-11-22 20:42:41,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:41,909 INFO:     Epoch: 66
2022-11-22 20:42:42,691 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7817961444908922, 'Total loss': 0.7817961444908922} | train loss {'Reaction outcome loss': 0.7520991604518794, 'Total loss': 0.7520991604518794}
2022-11-22 20:42:42,692 INFO:     Found new best model at epoch 66
2022-11-22 20:42:42,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:42,693 INFO:     Epoch: 67
2022-11-22 20:42:43,449 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.823987524617802, 'Total loss': 0.823987524617802} | train loss {'Reaction outcome loss': 0.752852382915102, 'Total loss': 0.752852382915102}
2022-11-22 20:42:43,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:43,449 INFO:     Epoch: 68
2022-11-22 20:42:44,241 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7744467346505686, 'Total loss': 0.7744467346505686} | train loss {'Reaction outcome loss': 0.7528721904947691, 'Total loss': 0.7528721904947691}
2022-11-22 20:42:44,241 INFO:     Found new best model at epoch 68
2022-11-22 20:42:44,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:44,242 INFO:     Epoch: 69
2022-11-22 20:42:45,053 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8135013702240858, 'Total loss': 0.8135013702240858} | train loss {'Reaction outcome loss': 0.7628726819266192, 'Total loss': 0.7628726819266192}
2022-11-22 20:42:45,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:45,053 INFO:     Epoch: 70
2022-11-22 20:42:45,852 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8039181185039607, 'Total loss': 0.8039181185039607} | train loss {'Reaction outcome loss': 0.7471244586141486, 'Total loss': 0.7471244586141486}
2022-11-22 20:42:45,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:45,852 INFO:     Epoch: 71
2022-11-22 20:42:46,630 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8017747524109754, 'Total loss': 0.8017747524109754} | train loss {'Reaction outcome loss': 0.7432911876242171, 'Total loss': 0.7432911876242171}
2022-11-22 20:42:46,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:46,631 INFO:     Epoch: 72
2022-11-22 20:42:47,406 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7855112870985811, 'Total loss': 0.7855112870985811} | train loss {'Reaction outcome loss': 0.7597069952048754, 'Total loss': 0.7597069952048754}
2022-11-22 20:42:47,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:47,407 INFO:     Epoch: 73
2022-11-22 20:42:48,243 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8044352253729646, 'Total loss': 0.8044352253729646} | train loss {'Reaction outcome loss': 0.7599253150132986, 'Total loss': 0.7599253150132986}
2022-11-22 20:42:48,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:48,244 INFO:     Epoch: 74
2022-11-22 20:42:49,008 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8333516561172225, 'Total loss': 0.8333516561172225} | train loss {'Reaction outcome loss': 0.7333339450933672, 'Total loss': 0.7333339450933672}
2022-11-22 20:42:49,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:49,008 INFO:     Epoch: 75
2022-11-22 20:42:49,832 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7818861725655469, 'Total loss': 0.7818861725655469} | train loss {'Reaction outcome loss': 0.7361235265065784, 'Total loss': 0.7361235265065784}
2022-11-22 20:42:49,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:49,832 INFO:     Epoch: 76
2022-11-22 20:42:50,599 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8242187811569734, 'Total loss': 0.8242187811569734} | train loss {'Reaction outcome loss': 0.7431369507119723, 'Total loss': 0.7431369507119723}
2022-11-22 20:42:50,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:50,600 INFO:     Epoch: 77
2022-11-22 20:42:51,376 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7768339731476523, 'Total loss': 0.7768339731476523} | train loss {'Reaction outcome loss': 0.7344002958673698, 'Total loss': 0.7344002958673698}
2022-11-22 20:42:51,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:51,377 INFO:     Epoch: 78
2022-11-22 20:42:52,201 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7779030061580918, 'Total loss': 0.7779030061580918} | train loss {'Reaction outcome loss': 0.7233671841479326, 'Total loss': 0.7233671841479326}
2022-11-22 20:42:52,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:52,202 INFO:     Epoch: 79
2022-11-22 20:42:53,020 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8245247846299951, 'Total loss': 0.8245247846299951} | train loss {'Reaction outcome loss': 0.7369193328536956, 'Total loss': 0.7369193328536956}
2022-11-22 20:42:53,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:53,020 INFO:     Epoch: 80
2022-11-22 20:42:53,859 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7634603997523134, 'Total loss': 0.7634603997523134} | train loss {'Reaction outcome loss': 0.7237755313575992, 'Total loss': 0.7237755313575992}
2022-11-22 20:42:53,859 INFO:     Found new best model at epoch 80
2022-11-22 20:42:53,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:53,860 INFO:     Epoch: 81
2022-11-22 20:42:54,690 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7658880833875049, 'Total loss': 0.7658880833875049} | train loss {'Reaction outcome loss': 0.7252064071263862, 'Total loss': 0.7252064071263862}
2022-11-22 20:42:54,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:54,690 INFO:     Epoch: 82
2022-11-22 20:42:55,449 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8039845289154486, 'Total loss': 0.8039845289154486} | train loss {'Reaction outcome loss': 0.7206346596542158, 'Total loss': 0.7206346596542158}
2022-11-22 20:42:55,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:55,449 INFO:     Epoch: 83
2022-11-22 20:42:56,218 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7611765732819383, 'Total loss': 0.7611765732819383} | train loss {'Reaction outcome loss': 0.72419792992866, 'Total loss': 0.72419792992866}
2022-11-22 20:42:56,218 INFO:     Found new best model at epoch 83
2022-11-22 20:42:56,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:56,219 INFO:     Epoch: 84
2022-11-22 20:42:56,976 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.752700378948992, 'Total loss': 0.752700378948992} | train loss {'Reaction outcome loss': 0.7191119428407325, 'Total loss': 0.7191119428407325}
2022-11-22 20:42:56,977 INFO:     Found new best model at epoch 84
2022-11-22 20:42:56,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:56,977 INFO:     Epoch: 85
2022-11-22 20:42:57,753 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7940937382253733, 'Total loss': 0.7940937382253733} | train loss {'Reaction outcome loss': 0.7145660588374505, 'Total loss': 0.7145660588374505}
2022-11-22 20:42:57,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:57,754 INFO:     Epoch: 86
2022-11-22 20:42:58,574 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7617428478869525, 'Total loss': 0.7617428478869525} | train loss {'Reaction outcome loss': 0.7263534989072243, 'Total loss': 0.7263534989072243}
2022-11-22 20:42:58,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:58,574 INFO:     Epoch: 87
2022-11-22 20:42:59,340 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7671038156205957, 'Total loss': 0.7671038156205957} | train loss {'Reaction outcome loss': 0.7210010422265482, 'Total loss': 0.7210010422265482}
2022-11-22 20:42:59,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:42:59,340 INFO:     Epoch: 88
2022-11-22 20:43:00,175 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7370880977673964, 'Total loss': 0.7370880977673964} | train loss {'Reaction outcome loss': 0.7346826168568993, 'Total loss': 0.7346826168568993}
2022-11-22 20:43:00,175 INFO:     Found new best model at epoch 88
2022-11-22 20:43:00,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:00,176 INFO:     Epoch: 89
2022-11-22 20:43:00,924 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7762905596332117, 'Total loss': 0.7762905596332117} | train loss {'Reaction outcome loss': 0.7174478431462277, 'Total loss': 0.7174478431462277}
2022-11-22 20:43:00,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:00,925 INFO:     Epoch: 90
2022-11-22 20:43:01,759 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7610134773633697, 'Total loss': 0.7610134773633697} | train loss {'Reaction outcome loss': 0.718524254164715, 'Total loss': 0.718524254164715}
2022-11-22 20:43:01,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:01,759 INFO:     Epoch: 91
2022-11-22 20:43:02,527 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.808480674570257, 'Total loss': 0.808480674570257} | train loss {'Reaction outcome loss': 0.7130966938519285, 'Total loss': 0.7130966938519285}
2022-11-22 20:43:02,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:02,527 INFO:     Epoch: 92
2022-11-22 20:43:03,348 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.798469749363986, 'Total loss': 0.798469749363986} | train loss {'Reaction outcome loss': 0.7132282119530898, 'Total loss': 0.7132282119530898}
2022-11-22 20:43:03,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:03,348 INFO:     Epoch: 93
2022-11-22 20:43:04,146 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7629809450696815, 'Total loss': 0.7629809450696815} | train loss {'Reaction outcome loss': 0.7147943665865462, 'Total loss': 0.7147943665865462}
2022-11-22 20:43:04,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:04,147 INFO:     Epoch: 94
2022-11-22 20:43:04,950 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7571146562695503, 'Total loss': 0.7571146562695503} | train loss {'Reaction outcome loss': 0.7139311200573377, 'Total loss': 0.7139311200573377}
2022-11-22 20:43:04,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:04,950 INFO:     Epoch: 95
2022-11-22 20:43:05,760 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7376738075505603, 'Total loss': 0.7376738075505603} | train loss {'Reaction outcome loss': 0.7118810397772654, 'Total loss': 0.7118810397772654}
2022-11-22 20:43:05,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:05,761 INFO:     Epoch: 96
2022-11-22 20:43:06,539 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7574824474074624, 'Total loss': 0.7574824474074624} | train loss {'Reaction outcome loss': 0.7083685388449232, 'Total loss': 0.7083685388449232}
2022-11-22 20:43:06,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:06,539 INFO:     Epoch: 97
2022-11-22 20:43:07,321 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7659298364411701, 'Total loss': 0.7659298364411701} | train loss {'Reaction outcome loss': 0.7119187324153267, 'Total loss': 0.7119187324153267}
2022-11-22 20:43:07,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:07,321 INFO:     Epoch: 98
2022-11-22 20:43:08,131 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7609462385827844, 'Total loss': 0.7609462385827844} | train loss {'Reaction outcome loss': 0.7121301197450653, 'Total loss': 0.7121301197450653}
2022-11-22 20:43:08,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:08,132 INFO:     Epoch: 99
2022-11-22 20:43:08,906 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8306601867079735, 'Total loss': 0.8306601867079735} | train loss {'Reaction outcome loss': 0.7122169870596665, 'Total loss': 0.7122169870596665}
2022-11-22 20:43:08,906 INFO:     Best model found after epoch 89 of 100.
2022-11-22 20:43:08,906 INFO:   Done with stage: TRAINING
2022-11-22 20:43:08,906 INFO:   Starting stage: EVALUATION
2022-11-22 20:43:09,025 INFO:   Done with stage: EVALUATION
2022-11-22 20:43:09,025 INFO:   Leaving out SEQ value Fold_6
2022-11-22 20:43:09,040 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 20:43:09,040 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:43:09,713 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:43:09,713 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:43:09,785 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:43:09,786 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:43:09,786 INFO:     No hyperparam tuning for this model
2022-11-22 20:43:09,786 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:43:09,786 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:43:09,787 INFO:     None feature selector for col prot
2022-11-22 20:43:09,787 INFO:     None feature selector for col prot
2022-11-22 20:43:09,787 INFO:     None feature selector for col prot
2022-11-22 20:43:09,788 INFO:     None feature selector for col chem
2022-11-22 20:43:09,788 INFO:     None feature selector for col chem
2022-11-22 20:43:09,788 INFO:     None feature selector for col chem
2022-11-22 20:43:09,788 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:43:09,788 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:43:09,790 INFO:     Number of params in model 126091
2022-11-22 20:43:09,793 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:43:09,793 INFO:   Starting stage: TRAINING
2022-11-22 20:43:09,846 INFO:     Val loss before train {'Reaction outcome loss': 0.9639703807505694, 'Total loss': 0.9639703807505694}
2022-11-22 20:43:09,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:09,846 INFO:     Epoch: 0
2022-11-22 20:43:10,624 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8010588457638567, 'Total loss': 0.8010588457638567} | train loss {'Reaction outcome loss': 0.8835897754517293, 'Total loss': 0.8835897754517293}
2022-11-22 20:43:10,624 INFO:     Found new best model at epoch 0
2022-11-22 20:43:10,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:10,625 INFO:     Epoch: 1
2022-11-22 20:43:11,396 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7871330414306034, 'Total loss': 0.7871330414306034} | train loss {'Reaction outcome loss': 0.8327344267839386, 'Total loss': 0.8327344267839386}
2022-11-22 20:43:11,396 INFO:     Found new best model at epoch 1
2022-11-22 20:43:11,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:11,397 INFO:     Epoch: 2
2022-11-22 20:43:12,176 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8129896853457798, 'Total loss': 0.8129896853457798} | train loss {'Reaction outcome loss': 0.8269191136763941, 'Total loss': 0.8269191136763941}
2022-11-22 20:43:12,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:12,177 INFO:     Epoch: 3
2022-11-22 20:43:12,949 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7717150327834216, 'Total loss': 0.7717150327834216} | train loss {'Reaction outcome loss': 0.8289873527903711, 'Total loss': 0.8289873527903711}
2022-11-22 20:43:12,949 INFO:     Found new best model at epoch 3
2022-11-22 20:43:12,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:12,950 INFO:     Epoch: 4
2022-11-22 20:43:13,694 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7841937365857038, 'Total loss': 0.7841937365857038} | train loss {'Reaction outcome loss': 0.824057656430429, 'Total loss': 0.824057656430429}
2022-11-22 20:43:13,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:13,694 INFO:     Epoch: 5
2022-11-22 20:43:14,489 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8087978105653416, 'Total loss': 0.8087978105653416} | train loss {'Reaction outcome loss': 0.8216643124338119, 'Total loss': 0.8216643124338119}
2022-11-22 20:43:14,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:14,489 INFO:     Epoch: 6
2022-11-22 20:43:15,259 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7628742388703607, 'Total loss': 0.7628742388703607} | train loss {'Reaction outcome loss': 0.8184621030044171, 'Total loss': 0.8184621030044171}
2022-11-22 20:43:15,259 INFO:     Found new best model at epoch 6
2022-11-22 20:43:15,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:15,260 INFO:     Epoch: 7
2022-11-22 20:43:16,009 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8135651641271331, 'Total loss': 0.8135651641271331} | train loss {'Reaction outcome loss': 0.8132390661105033, 'Total loss': 0.8132390661105033}
2022-11-22 20:43:16,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:16,009 INFO:     Epoch: 8
2022-11-22 20:43:16,766 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7801602584394541, 'Total loss': 0.7801602584394541} | train loss {'Reaction outcome loss': 0.822604120979386, 'Total loss': 0.822604120979386}
2022-11-22 20:43:16,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:16,766 INFO:     Epoch: 9
2022-11-22 20:43:17,539 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7635253410447728, 'Total loss': 0.7635253410447728} | train loss {'Reaction outcome loss': 0.816190290475084, 'Total loss': 0.816190290475084}
2022-11-22 20:43:17,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:17,539 INFO:     Epoch: 10
2022-11-22 20:43:18,295 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7791482453996484, 'Total loss': 0.7791482453996484} | train loss {'Reaction outcome loss': 0.8091187219946615, 'Total loss': 0.8091187219946615}
2022-11-22 20:43:18,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:18,295 INFO:     Epoch: 11
2022-11-22 20:43:19,040 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.787877504798499, 'Total loss': 0.787877504798499} | train loss {'Reaction outcome loss': 0.8121816345280216, 'Total loss': 0.8121816345280216}
2022-11-22 20:43:19,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:19,040 INFO:     Epoch: 12
2022-11-22 20:43:19,825 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7707377855073322, 'Total loss': 0.7707377855073322} | train loss {'Reaction outcome loss': 0.8041494440647864, 'Total loss': 0.8041494440647864}
2022-11-22 20:43:19,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:19,826 INFO:     Epoch: 13
2022-11-22 20:43:20,581 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7640657675537196, 'Total loss': 0.7640657675537196} | train loss {'Reaction outcome loss': 0.7992076111897346, 'Total loss': 0.7992076111897346}
2022-11-22 20:43:20,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:20,582 INFO:     Epoch: 14
2022-11-22 20:43:21,315 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7712452242320235, 'Total loss': 0.7712452242320235} | train loss {'Reaction outcome loss': 0.8005668905473524, 'Total loss': 0.8005668905473524}
2022-11-22 20:43:21,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:21,315 INFO:     Epoch: 15
2022-11-22 20:43:22,086 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8119267821311951, 'Total loss': 0.8119267821311951} | train loss {'Reaction outcome loss': 0.7982343230997363, 'Total loss': 0.7982343230997363}
2022-11-22 20:43:22,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:22,087 INFO:     Epoch: 16
2022-11-22 20:43:22,882 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7555236260999333, 'Total loss': 0.7555236260999333} | train loss {'Reaction outcome loss': 0.8031328582475262, 'Total loss': 0.8031328582475262}
2022-11-22 20:43:22,883 INFO:     Found new best model at epoch 16
2022-11-22 20:43:22,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:22,883 INFO:     Epoch: 17
2022-11-22 20:43:23,607 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7541811032728716, 'Total loss': 0.7541811032728716} | train loss {'Reaction outcome loss': 0.7950610084639441, 'Total loss': 0.7950610084639441}
2022-11-22 20:43:23,607 INFO:     Found new best model at epoch 17
2022-11-22 20:43:23,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:23,608 INFO:     Epoch: 18
2022-11-22 20:43:24,330 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7617220126769759, 'Total loss': 0.7617220126769759} | train loss {'Reaction outcome loss': 0.7998658150674836, 'Total loss': 0.7998658150674836}
2022-11-22 20:43:24,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:24,330 INFO:     Epoch: 19
2022-11-22 20:43:25,043 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7791476764462211, 'Total loss': 0.7791476764462211} | train loss {'Reaction outcome loss': 0.7957205111461301, 'Total loss': 0.7957205111461301}
2022-11-22 20:43:25,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:25,043 INFO:     Epoch: 20
2022-11-22 20:43:25,801 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7702614685351198, 'Total loss': 0.7702614685351198} | train loss {'Reaction outcome loss': 0.798929170975762, 'Total loss': 0.798929170975762}
2022-11-22 20:43:25,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:25,801 INFO:     Epoch: 21
2022-11-22 20:43:26,587 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7784356718713586, 'Total loss': 0.7784356718713586} | train loss {'Reaction outcome loss': 0.7949642762541771, 'Total loss': 0.7949642762541771}
2022-11-22 20:43:26,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:26,587 INFO:     Epoch: 22
2022-11-22 20:43:27,368 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7725712887265466, 'Total loss': 0.7725712887265466} | train loss {'Reaction outcome loss': 0.7927034121126898, 'Total loss': 0.7927034121126898}
2022-11-22 20:43:27,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:27,368 INFO:     Epoch: 23
2022-11-22 20:43:28,117 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7502759031274102, 'Total loss': 0.7502759031274102} | train loss {'Reaction outcome loss': 0.7949084858259847, 'Total loss': 0.7949084858259847}
2022-11-22 20:43:28,118 INFO:     Found new best model at epoch 23
2022-11-22 20:43:28,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:28,118 INFO:     Epoch: 24
2022-11-22 20:43:28,912 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7715717222202908, 'Total loss': 0.7715717222202908} | train loss {'Reaction outcome loss': 0.7923678037139678, 'Total loss': 0.7923678037139678}
2022-11-22 20:43:28,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:28,912 INFO:     Epoch: 25
2022-11-22 20:43:29,656 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7610879188234155, 'Total loss': 0.7610879188234155} | train loss {'Reaction outcome loss': 0.7914038992697193, 'Total loss': 0.7914038992697193}
2022-11-22 20:43:29,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:29,656 INFO:     Epoch: 26
2022-11-22 20:43:30,399 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7795164876363494, 'Total loss': 0.7795164876363494} | train loss {'Reaction outcome loss': 0.7952119920162424, 'Total loss': 0.7952119920162424}
2022-11-22 20:43:30,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:30,400 INFO:     Epoch: 27
2022-11-22 20:43:31,143 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7568495266816833, 'Total loss': 0.7568495266816833} | train loss {'Reaction outcome loss': 0.7938363052183582, 'Total loss': 0.7938363052183582}
2022-11-22 20:43:31,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:31,143 INFO:     Epoch: 28
2022-11-22 20:43:31,902 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7585902491753752, 'Total loss': 0.7585902491753752} | train loss {'Reaction outcome loss': 0.7903033796577684, 'Total loss': 0.7903033796577684}
2022-11-22 20:43:31,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:31,902 INFO:     Epoch: 29
2022-11-22 20:43:32,674 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7651644091714512, 'Total loss': 0.7651644091714512} | train loss {'Reaction outcome loss': 0.7908722878463806, 'Total loss': 0.7908722878463806}
2022-11-22 20:43:32,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:32,675 INFO:     Epoch: 30
2022-11-22 20:43:33,392 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.773005604066632, 'Total loss': 0.773005604066632} | train loss {'Reaction outcome loss': 0.7902359139294394, 'Total loss': 0.7902359139294394}
2022-11-22 20:43:33,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:33,392 INFO:     Epoch: 31
2022-11-22 20:43:34,146 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7462950917807493, 'Total loss': 0.7462950917807493} | train loss {'Reaction outcome loss': 0.7936742806867245, 'Total loss': 0.7936742806867245}
2022-11-22 20:43:34,146 INFO:     Found new best model at epoch 31
2022-11-22 20:43:34,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:34,146 INFO:     Epoch: 32
2022-11-22 20:43:34,854 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7753486403010108, 'Total loss': 0.7753486403010108} | train loss {'Reaction outcome loss': 0.7900094919868054, 'Total loss': 0.7900094919868054}
2022-11-22 20:43:34,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:34,854 INFO:     Epoch: 33
2022-11-22 20:43:35,615 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7600198652256619, 'Total loss': 0.7600198652256619} | train loss {'Reaction outcome loss': 0.7942594929087546, 'Total loss': 0.7942594929087546}
2022-11-22 20:43:35,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:35,615 INFO:     Epoch: 34
2022-11-22 20:43:36,323 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7685717344284058, 'Total loss': 0.7685717344284058} | train loss {'Reaction outcome loss': 0.7906716093420982, 'Total loss': 0.7906716093420982}
2022-11-22 20:43:36,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:36,323 INFO:     Epoch: 35
2022-11-22 20:43:37,082 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7609118318015878, 'Total loss': 0.7609118318015878} | train loss {'Reaction outcome loss': 0.7882381016688962, 'Total loss': 0.7882381016688962}
2022-11-22 20:43:37,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:37,082 INFO:     Epoch: 36
2022-11-22 20:43:37,785 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7635727111588825, 'Total loss': 0.7635727111588825} | train loss {'Reaction outcome loss': 0.794314153732792, 'Total loss': 0.794314153732792}
2022-11-22 20:43:37,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:37,786 INFO:     Epoch: 37
2022-11-22 20:43:38,522 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7651065378026529, 'Total loss': 0.7651065378026529} | train loss {'Reaction outcome loss': 0.7913330696042506, 'Total loss': 0.7913330696042506}
2022-11-22 20:43:38,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:38,522 INFO:     Epoch: 38
2022-11-22 20:43:39,306 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7673481933095239, 'Total loss': 0.7673481933095239} | train loss {'Reaction outcome loss': 0.7891000374670951, 'Total loss': 0.7891000374670951}
2022-11-22 20:43:39,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:39,307 INFO:     Epoch: 39
2022-11-22 20:43:40,055 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7618562484329398, 'Total loss': 0.7618562484329398} | train loss {'Reaction outcome loss': 0.7864155573469978, 'Total loss': 0.7864155573469978}
2022-11-22 20:43:40,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:40,055 INFO:     Epoch: 40
2022-11-22 20:43:40,838 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7602403942834247, 'Total loss': 0.7602403942834247} | train loss {'Reaction outcome loss': 0.7944379041512166, 'Total loss': 0.7944379041512166}
2022-11-22 20:43:40,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:40,839 INFO:     Epoch: 41
2022-11-22 20:43:41,585 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7757988023487005, 'Total loss': 0.7757988023487005} | train loss {'Reaction outcome loss': 0.7870714295535318, 'Total loss': 0.7870714295535318}
2022-11-22 20:43:41,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:41,585 INFO:     Epoch: 42
2022-11-22 20:43:42,318 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7593799423087727, 'Total loss': 0.7593799423087727} | train loss {'Reaction outcome loss': 0.7864150847158125, 'Total loss': 0.7864150847158125}
2022-11-22 20:43:42,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:42,319 INFO:     Epoch: 43
2022-11-22 20:43:43,034 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7497185441580686, 'Total loss': 0.7497185441580686} | train loss {'Reaction outcome loss': 0.7898528288689352, 'Total loss': 0.7898528288689352}
2022-11-22 20:43:43,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:43,034 INFO:     Epoch: 44
2022-11-22 20:43:43,780 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7572444365783171, 'Total loss': 0.7572444365783171} | train loss {'Reaction outcome loss': 0.7862148871344905, 'Total loss': 0.7862148871344905}
2022-11-22 20:43:43,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:43,781 INFO:     Epoch: 45
2022-11-22 20:43:44,559 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7536172419786453, 'Total loss': 0.7536172419786453} | train loss {'Reaction outcome loss': 0.7895160223687848, 'Total loss': 0.7895160223687848}
2022-11-22 20:43:44,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:44,559 INFO:     Epoch: 46
2022-11-22 20:43:45,312 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7660753266377882, 'Total loss': 0.7660753266377882} | train loss {'Reaction outcome loss': 0.7859920880967571, 'Total loss': 0.7859920880967571}
2022-11-22 20:43:45,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:45,312 INFO:     Epoch: 47
2022-11-22 20:43:46,054 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7654506699605421, 'Total loss': 0.7654506699605421} | train loss {'Reaction outcome loss': 0.7886129974597885, 'Total loss': 0.7886129974597885}
2022-11-22 20:43:46,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:46,055 INFO:     Epoch: 48
2022-11-22 20:43:46,811 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7580688487399708, 'Total loss': 0.7580688487399708} | train loss {'Reaction outcome loss': 0.7860368376056994, 'Total loss': 0.7860368376056994}
2022-11-22 20:43:46,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:46,811 INFO:     Epoch: 49
2022-11-22 20:43:47,552 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7578813210129738, 'Total loss': 0.7578813210129738} | train loss {'Reaction outcome loss': 0.7915679390632337, 'Total loss': 0.7915679390632337}
2022-11-22 20:43:47,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:47,553 INFO:     Epoch: 50
2022-11-22 20:43:48,280 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.76050173423507, 'Total loss': 0.76050173423507} | train loss {'Reaction outcome loss': 0.7898617522610772, 'Total loss': 0.7898617522610772}
2022-11-22 20:43:48,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:48,281 INFO:     Epoch: 51
2022-11-22 20:43:49,046 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7639971063895659, 'Total loss': 0.7639971063895659} | train loss {'Reaction outcome loss': 0.7827011266302678, 'Total loss': 0.7827011266302678}
2022-11-22 20:43:49,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:49,047 INFO:     Epoch: 52
2022-11-22 20:43:49,791 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7508559714664113, 'Total loss': 0.7508559714664113} | train loss {'Reaction outcome loss': 0.7846486575661167, 'Total loss': 0.7846486575661167}
2022-11-22 20:43:49,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:49,792 INFO:     Epoch: 53
2022-11-22 20:43:50,555 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7431355917995627, 'Total loss': 0.7431355917995627} | train loss {'Reaction outcome loss': 0.7820623621584908, 'Total loss': 0.7820623621584908}
2022-11-22 20:43:50,555 INFO:     Found new best model at epoch 53
2022-11-22 20:43:50,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:50,556 INFO:     Epoch: 54
2022-11-22 20:43:51,332 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7496116892857985, 'Total loss': 0.7496116892857985} | train loss {'Reaction outcome loss': 0.7825027150552599, 'Total loss': 0.7825027150552599}
2022-11-22 20:43:51,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:51,332 INFO:     Epoch: 55
2022-11-22 20:43:52,091 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7488927272233096, 'Total loss': 0.7488927272233096} | train loss {'Reaction outcome loss': 0.7829651247349477, 'Total loss': 0.7829651247349477}
2022-11-22 20:43:52,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:52,091 INFO:     Epoch: 56
2022-11-22 20:43:52,839 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.75472557883371, 'Total loss': 0.75472557883371} | train loss {'Reaction outcome loss': 0.7786270386028674, 'Total loss': 0.7786270386028674}
2022-11-22 20:43:52,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:52,839 INFO:     Epoch: 57
2022-11-22 20:43:53,607 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7431136830286547, 'Total loss': 0.7431136830286547} | train loss {'Reaction outcome loss': 0.7814263225563111, 'Total loss': 0.7814263225563111}
2022-11-22 20:43:53,608 INFO:     Found new best model at epoch 57
2022-11-22 20:43:53,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:53,609 INFO:     Epoch: 58
2022-11-22 20:43:54,354 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7504607411948118, 'Total loss': 0.7504607411948118} | train loss {'Reaction outcome loss': 0.7847885494270632, 'Total loss': 0.7847885494270632}
2022-11-22 20:43:54,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:54,354 INFO:     Epoch: 59
2022-11-22 20:43:55,091 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7512915310534564, 'Total loss': 0.7512915310534564} | train loss {'Reaction outcome loss': 0.7798361144959927, 'Total loss': 0.7798361144959927}
2022-11-22 20:43:55,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:55,092 INFO:     Epoch: 60
2022-11-22 20:43:55,837 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7548397447575222, 'Total loss': 0.7548397447575222} | train loss {'Reaction outcome loss': 0.7784734943941716, 'Total loss': 0.7784734943941716}
2022-11-22 20:43:55,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:55,837 INFO:     Epoch: 61
2022-11-22 20:43:56,589 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7440175600349903, 'Total loss': 0.7440175600349903} | train loss {'Reaction outcome loss': 0.7795066889976302, 'Total loss': 0.7795066889976302}
2022-11-22 20:43:56,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:56,589 INFO:     Epoch: 62
2022-11-22 20:43:57,341 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.746258991008455, 'Total loss': 0.746258991008455} | train loss {'Reaction outcome loss': 0.7728582468003996, 'Total loss': 0.7728582468003996}
2022-11-22 20:43:57,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:57,341 INFO:     Epoch: 63
2022-11-22 20:43:58,075 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7730640572580424, 'Total loss': 0.7730640572580424} | train loss {'Reaction outcome loss': 0.7698208464970512, 'Total loss': 0.7698208464970512}
2022-11-22 20:43:58,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:58,075 INFO:     Epoch: 64
2022-11-22 20:43:58,830 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7441172667525031, 'Total loss': 0.7441172667525031} | train loss {'Reaction outcome loss': 0.7704661442868171, 'Total loss': 0.7704661442868171}
2022-11-22 20:43:58,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:58,830 INFO:     Epoch: 65
2022-11-22 20:43:59,627 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7553076141259887, 'Total loss': 0.7553076141259887} | train loss {'Reaction outcome loss': 0.766302282291074, 'Total loss': 0.766302282291074}
2022-11-22 20:43:59,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:43:59,628 INFO:     Epoch: 66
2022-11-22 20:44:00,428 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7372679046609185, 'Total loss': 0.7372679046609185} | train loss {'Reaction outcome loss': 0.7652915841148745, 'Total loss': 0.7652915841148745}
2022-11-22 20:44:00,428 INFO:     Found new best model at epoch 66
2022-11-22 20:44:00,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:00,429 INFO:     Epoch: 67
2022-11-22 20:44:01,205 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7358199886300347, 'Total loss': 0.7358199886300347} | train loss {'Reaction outcome loss': 0.7585998459929421, 'Total loss': 0.7585998459929421}
2022-11-22 20:44:01,205 INFO:     Found new best model at epoch 67
2022-11-22 20:44:01,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:01,206 INFO:     Epoch: 68
2022-11-22 20:44:01,978 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7658280127427795, 'Total loss': 0.7658280127427795} | train loss {'Reaction outcome loss': 0.7688260175768407, 'Total loss': 0.7688260175768407}
2022-11-22 20:44:01,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:01,979 INFO:     Epoch: 69
2022-11-22 20:44:02,711 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7335104854269461, 'Total loss': 0.7335104854269461} | train loss {'Reaction outcome loss': 0.775282604679946, 'Total loss': 0.775282604679946}
2022-11-22 20:44:02,711 INFO:     Found new best model at epoch 69
2022-11-22 20:44:02,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:02,712 INFO:     Epoch: 70
2022-11-22 20:44:03,476 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7312024581161413, 'Total loss': 0.7312024581161413} | train loss {'Reaction outcome loss': 0.7605852918519128, 'Total loss': 0.7605852918519128}
2022-11-22 20:44:03,476 INFO:     Found new best model at epoch 70
2022-11-22 20:44:03,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:03,477 INFO:     Epoch: 71
2022-11-22 20:44:04,210 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7694371403618292, 'Total loss': 0.7694371403618292} | train loss {'Reaction outcome loss': 0.7658926291210998, 'Total loss': 0.7658926291210998}
2022-11-22 20:44:04,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:04,210 INFO:     Epoch: 72
2022-11-22 20:44:04,932 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.732244876975363, 'Total loss': 0.732244876975363} | train loss {'Reaction outcome loss': 0.7579897509947899, 'Total loss': 0.7579897509947899}
2022-11-22 20:44:04,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:04,932 INFO:     Epoch: 73
2022-11-22 20:44:05,725 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7369890463623133, 'Total loss': 0.7369890463623133} | train loss {'Reaction outcome loss': 0.7541049205728115, 'Total loss': 0.7541049205728115}
2022-11-22 20:44:05,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:05,725 INFO:     Epoch: 74
2022-11-22 20:44:06,459 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7187168842012231, 'Total loss': 0.7187168842012231} | train loss {'Reaction outcome loss': 0.7529859238814923, 'Total loss': 0.7529859238814923}
2022-11-22 20:44:06,459 INFO:     Found new best model at epoch 74
2022-11-22 20:44:06,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:06,460 INFO:     Epoch: 75
2022-11-22 20:44:07,212 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7408739165826277, 'Total loss': 0.7408739165826277} | train loss {'Reaction outcome loss': 0.7425256939905305, 'Total loss': 0.7425256939905305}
2022-11-22 20:44:07,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:07,212 INFO:     Epoch: 76
2022-11-22 20:44:07,908 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.764512225985527, 'Total loss': 0.764512225985527} | train loss {'Reaction outcome loss': 0.7484888148403936, 'Total loss': 0.7484888148403936}
2022-11-22 20:44:07,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:07,908 INFO:     Epoch: 77
2022-11-22 20:44:08,676 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7315881841562011, 'Total loss': 0.7315881841562011} | train loss {'Reaction outcome loss': 0.7370118569702871, 'Total loss': 0.7370118569702871}
2022-11-22 20:44:08,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:08,676 INFO:     Epoch: 78
2022-11-22 20:44:09,423 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7244768589735031, 'Total loss': 0.7244768589735031} | train loss {'Reaction outcome loss': 0.7308766217001023, 'Total loss': 0.7308766217001023}
2022-11-22 20:44:09,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:09,423 INFO:     Epoch: 79
2022-11-22 20:44:10,194 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6991422318599441, 'Total loss': 0.6991422318599441} | train loss {'Reaction outcome loss': 0.7477974020425351, 'Total loss': 0.7477974020425351}
2022-11-22 20:44:10,194 INFO:     Found new best model at epoch 79
2022-11-22 20:44:10,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:10,195 INFO:     Epoch: 80
2022-11-22 20:44:10,895 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.6893700327385556, 'Total loss': 0.6893700327385556} | train loss {'Reaction outcome loss': 0.7325949159360701, 'Total loss': 0.7325949159360701}
2022-11-22 20:44:10,895 INFO:     Found new best model at epoch 80
2022-11-22 20:44:10,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:10,896 INFO:     Epoch: 81
2022-11-22 20:44:11,648 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7084743211215193, 'Total loss': 0.7084743211215193} | train loss {'Reaction outcome loss': 0.7443358203576457, 'Total loss': 0.7443358203576457}
2022-11-22 20:44:11,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:11,649 INFO:     Epoch: 82
2022-11-22 20:44:12,385 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7068297944285653, 'Total loss': 0.7068297944285653} | train loss {'Reaction outcome loss': 0.7341085516156689, 'Total loss': 0.7341085516156689}
2022-11-22 20:44:12,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:12,385 INFO:     Epoch: 83
2022-11-22 20:44:13,084 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7057889388366179, 'Total loss': 0.7057889388366179} | train loss {'Reaction outcome loss': 0.7264759325452389, 'Total loss': 0.7264759325452389}
2022-11-22 20:44:13,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:13,084 INFO:     Epoch: 84
2022-11-22 20:44:13,831 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7304885387420654, 'Total loss': 0.7304885387420654} | train loss {'Reaction outcome loss': 0.7291761391585873, 'Total loss': 0.7291761391585873}
2022-11-22 20:44:13,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:13,831 INFO:     Epoch: 85
2022-11-22 20:44:14,575 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6990564065900716, 'Total loss': 0.6990564065900716} | train loss {'Reaction outcome loss': 0.7378607071455447, 'Total loss': 0.7378607071455447}
2022-11-22 20:44:14,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:14,576 INFO:     Epoch: 86
2022-11-22 20:44:15,300 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7119559733705088, 'Total loss': 0.7119559733705088} | train loss {'Reaction outcome loss': 0.7296050640363847, 'Total loss': 0.7296050640363847}
2022-11-22 20:44:15,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:15,301 INFO:     Epoch: 87
2022-11-22 20:44:16,034 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6870435997843742, 'Total loss': 0.6870435997843742} | train loss {'Reaction outcome loss': 0.7368217914575531, 'Total loss': 0.7368217914575531}
2022-11-22 20:44:16,034 INFO:     Found new best model at epoch 87
2022-11-22 20:44:16,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:16,035 INFO:     Epoch: 88
2022-11-22 20:44:16,796 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6909856240857731, 'Total loss': 0.6909856240857731} | train loss {'Reaction outcome loss': 0.7221905370393107, 'Total loss': 0.7221905370393107}
2022-11-22 20:44:16,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:16,796 INFO:     Epoch: 89
2022-11-22 20:44:17,540 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6877281388098543, 'Total loss': 0.6877281388098543} | train loss {'Reaction outcome loss': 0.7232664702159743, 'Total loss': 0.7232664702159743}
2022-11-22 20:44:17,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:17,540 INFO:     Epoch: 90
2022-11-22 20:44:18,289 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7022290893576362, 'Total loss': 0.7022290893576362} | train loss {'Reaction outcome loss': 0.7296670875962703, 'Total loss': 0.7296670875962703}
2022-11-22 20:44:18,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:18,289 INFO:     Epoch: 91
2022-11-22 20:44:19,051 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.700463901866566, 'Total loss': 0.700463901866566} | train loss {'Reaction outcome loss': 0.7241328973923961, 'Total loss': 0.7241328973923961}
2022-11-22 20:44:19,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:19,051 INFO:     Epoch: 92
2022-11-22 20:44:19,794 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6959974095225334, 'Total loss': 0.6959974095225334} | train loss {'Reaction outcome loss': 0.7239424053940081, 'Total loss': 0.7239424053940081}
2022-11-22 20:44:19,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:19,794 INFO:     Epoch: 93
2022-11-22 20:44:20,508 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7040119022130966, 'Total loss': 0.7040119022130966} | train loss {'Reaction outcome loss': 0.7234023594327511, 'Total loss': 0.7234023594327511}
2022-11-22 20:44:20,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:20,508 INFO:     Epoch: 94
2022-11-22 20:44:21,267 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7342251315712929, 'Total loss': 0.7342251315712929} | train loss {'Reaction outcome loss': 0.7274689366740565, 'Total loss': 0.7274689366740565}
2022-11-22 20:44:21,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:21,267 INFO:     Epoch: 95
2022-11-22 20:44:22,045 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6992036788301035, 'Total loss': 0.6992036788301035} | train loss {'Reaction outcome loss': 0.7273221464166718, 'Total loss': 0.7273221464166718}
2022-11-22 20:44:22,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:22,046 INFO:     Epoch: 96
2022-11-22 20:44:22,843 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6807513995604082, 'Total loss': 0.6807513995604082} | train loss {'Reaction outcome loss': 0.7145586225294298, 'Total loss': 0.7145586225294298}
2022-11-22 20:44:22,843 INFO:     Found new best model at epoch 96
2022-11-22 20:44:22,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:22,844 INFO:     Epoch: 97
2022-11-22 20:44:23,645 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7159510126168077, 'Total loss': 0.7159510126168077} | train loss {'Reaction outcome loss': 0.7121066744289091, 'Total loss': 0.7121066744289091}
2022-11-22 20:44:23,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:23,645 INFO:     Epoch: 98
2022-11-22 20:44:24,408 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7687176777557894, 'Total loss': 0.7687176777557894} | train loss {'Reaction outcome loss': 0.7181759315032151, 'Total loss': 0.7181759315032151}
2022-11-22 20:44:24,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:24,409 INFO:     Epoch: 99
2022-11-22 20:44:25,160 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6881449005820535, 'Total loss': 0.6881449005820535} | train loss {'Reaction outcome loss': 0.7223694131018654, 'Total loss': 0.7223694131018654}
2022-11-22 20:44:25,161 INFO:     Best model found after epoch 97 of 100.
2022-11-22 20:44:25,161 INFO:   Done with stage: TRAINING
2022-11-22 20:44:25,161 INFO:   Starting stage: EVALUATION
2022-11-22 20:44:25,274 INFO:   Done with stage: EVALUATION
2022-11-22 20:44:25,274 INFO:   Leaving out SEQ value Fold_7
2022-11-22 20:44:25,287 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:44:25,287 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:44:25,949 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:44:25,949 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:44:26,018 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:44:26,018 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:44:26,018 INFO:     No hyperparam tuning for this model
2022-11-22 20:44:26,018 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:44:26,018 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:44:26,019 INFO:     None feature selector for col prot
2022-11-22 20:44:26,019 INFO:     None feature selector for col prot
2022-11-22 20:44:26,019 INFO:     None feature selector for col prot
2022-11-22 20:44:26,020 INFO:     None feature selector for col chem
2022-11-22 20:44:26,020 INFO:     None feature selector for col chem
2022-11-22 20:44:26,020 INFO:     None feature selector for col chem
2022-11-22 20:44:26,020 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:44:26,020 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:44:26,021 INFO:     Number of params in model 126091
2022-11-22 20:44:26,025 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:44:26,025 INFO:   Starting stage: TRAINING
2022-11-22 20:44:26,074 INFO:     Val loss before train {'Reaction outcome loss': 1.0480286844752051, 'Total loss': 1.0480286844752051}
2022-11-22 20:44:26,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:26,074 INFO:     Epoch: 0
2022-11-22 20:44:26,783 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8517543185840953, 'Total loss': 0.8517543185840953} | train loss {'Reaction outcome loss': 0.868747904714273, 'Total loss': 0.868747904714273}
2022-11-22 20:44:26,783 INFO:     Found new best model at epoch 0
2022-11-22 20:44:26,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:26,784 INFO:     Epoch: 1
2022-11-22 20:44:27,528 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8678523430770094, 'Total loss': 0.8678523430770094} | train loss {'Reaction outcome loss': 0.833037245151948, 'Total loss': 0.833037245151948}
2022-11-22 20:44:27,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:27,528 INFO:     Epoch: 2
2022-11-22 20:44:28,294 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8338645920157433, 'Total loss': 0.8338645920157433} | train loss {'Reaction outcome loss': 0.8286245015202737, 'Total loss': 0.8286245015202737}
2022-11-22 20:44:28,294 INFO:     Found new best model at epoch 2
2022-11-22 20:44:28,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:28,295 INFO:     Epoch: 3
2022-11-22 20:44:29,030 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.816445576196367, 'Total loss': 0.816445576196367} | train loss {'Reaction outcome loss': 0.8189675888236688, 'Total loss': 0.8189675888236688}
2022-11-22 20:44:29,030 INFO:     Found new best model at epoch 3
2022-11-22 20:44:29,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:29,031 INFO:     Epoch: 4
2022-11-22 20:44:29,773 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8279018388553099, 'Total loss': 0.8279018388553099} | train loss {'Reaction outcome loss': 0.812574192699121, 'Total loss': 0.812574192699121}
2022-11-22 20:44:29,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:29,773 INFO:     Epoch: 5
2022-11-22 20:44:30,523 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8278831480578943, 'Total loss': 0.8278831480578943} | train loss {'Reaction outcome loss': 0.8061771975488079, 'Total loss': 0.8061771975488079}
2022-11-22 20:44:30,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:30,524 INFO:     Epoch: 6
2022-11-22 20:44:31,267 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7940722758119757, 'Total loss': 0.7940722758119757} | train loss {'Reaction outcome loss': 0.7995573675145908, 'Total loss': 0.7995573675145908}
2022-11-22 20:44:31,267 INFO:     Found new best model at epoch 6
2022-11-22 20:44:31,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:31,268 INFO:     Epoch: 7
2022-11-22 20:44:32,022 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8138576840812509, 'Total loss': 0.8138576840812509} | train loss {'Reaction outcome loss': 0.8002461199857751, 'Total loss': 0.8002461199857751}
2022-11-22 20:44:32,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:32,022 INFO:     Epoch: 8
2022-11-22 20:44:32,749 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8068825202909383, 'Total loss': 0.8068825202909383} | train loss {'Reaction outcome loss': 0.7939718129683514, 'Total loss': 0.7939718129683514}
2022-11-22 20:44:32,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:32,749 INFO:     Epoch: 9
2022-11-22 20:44:33,514 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8048735653812235, 'Total loss': 0.8048735653812235} | train loss {'Reaction outcome loss': 0.7964496432518472, 'Total loss': 0.7964496432518472}
2022-11-22 20:44:33,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:33,514 INFO:     Epoch: 10
2022-11-22 20:44:34,255 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8027040599422022, 'Total loss': 0.8027040599422022} | train loss {'Reaction outcome loss': 0.7981288682441322, 'Total loss': 0.7981288682441322}
2022-11-22 20:44:34,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:34,255 INFO:     Epoch: 11
2022-11-22 20:44:35,003 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8297951546582308, 'Total loss': 0.8297951546582308} | train loss {'Reaction outcome loss': 0.7917171367577144, 'Total loss': 0.7917171367577144}
2022-11-22 20:44:35,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:35,003 INFO:     Epoch: 12
2022-11-22 20:44:35,720 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7981825579296459, 'Total loss': 0.7981825579296459} | train loss {'Reaction outcome loss': 0.791505995088694, 'Total loss': 0.791505995088694}
2022-11-22 20:44:35,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:35,720 INFO:     Epoch: 13
2022-11-22 20:44:36,451 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8199456875974481, 'Total loss': 0.8199456875974481} | train loss {'Reaction outcome loss': 0.7913947511692436, 'Total loss': 0.7913947511692436}
2022-11-22 20:44:36,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:36,452 INFO:     Epoch: 14
2022-11-22 20:44:37,213 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8099148212508722, 'Total loss': 0.8099148212508722} | train loss {'Reaction outcome loss': 0.7943261007873379, 'Total loss': 0.7943261007873379}
2022-11-22 20:44:37,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:37,213 INFO:     Epoch: 15
2022-11-22 20:44:37,941 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.77699920094826, 'Total loss': 0.77699920094826} | train loss {'Reaction outcome loss': 0.7865305518617436, 'Total loss': 0.7865305518617436}
2022-11-22 20:44:37,941 INFO:     Found new best model at epoch 15
2022-11-22 20:44:37,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:37,942 INFO:     Epoch: 16
2022-11-22 20:44:38,650 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8123584328727289, 'Total loss': 0.8123584328727289} | train loss {'Reaction outcome loss': 0.790547701655602, 'Total loss': 0.790547701655602}
2022-11-22 20:44:38,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:38,650 INFO:     Epoch: 17
2022-11-22 20:44:39,390 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8448895202441649, 'Total loss': 0.8448895202441649} | train loss {'Reaction outcome loss': 0.7844638464402179, 'Total loss': 0.7844638464402179}
2022-11-22 20:44:39,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:39,390 INFO:     Epoch: 18
2022-11-22 20:44:40,158 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8088428859006275, 'Total loss': 0.8088428859006275} | train loss {'Reaction outcome loss': 0.7863523070909539, 'Total loss': 0.7863523070909539}
2022-11-22 20:44:40,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:40,159 INFO:     Epoch: 19
2022-11-22 20:44:40,905 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.803198981014165, 'Total loss': 0.803198981014165} | train loss {'Reaction outcome loss': 0.7859628018067808, 'Total loss': 0.7859628018067808}
2022-11-22 20:44:40,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:40,905 INFO:     Epoch: 20
2022-11-22 20:44:41,649 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8343226022341035, 'Total loss': 0.8343226022341035} | train loss {'Reaction outcome loss': 0.7865483082070642, 'Total loss': 0.7865483082070642}
2022-11-22 20:44:41,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:41,649 INFO:     Epoch: 21
2022-11-22 20:44:42,389 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8600865494121205, 'Total loss': 0.8600865494121205} | train loss {'Reaction outcome loss': 0.791727181964991, 'Total loss': 0.791727181964991}
2022-11-22 20:44:42,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:42,390 INFO:     Epoch: 22
2022-11-22 20:44:43,165 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8219437233426354, 'Total loss': 0.8219437233426354} | train loss {'Reaction outcome loss': 0.7904141732624599, 'Total loss': 0.7904141732624599}
2022-11-22 20:44:43,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:43,166 INFO:     Epoch: 23
2022-11-22 20:44:43,871 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.808197861368006, 'Total loss': 0.808197861368006} | train loss {'Reaction outcome loss': 0.7813581516548079, 'Total loss': 0.7813581516548079}
2022-11-22 20:44:43,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:43,871 INFO:     Epoch: 24
2022-11-22 20:44:44,587 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7905960469083353, 'Total loss': 0.7905960469083353} | train loss {'Reaction outcome loss': 0.7852300315487142, 'Total loss': 0.7852300315487142}
2022-11-22 20:44:44,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:44,587 INFO:     Epoch: 25
2022-11-22 20:44:45,321 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8083819523453712, 'Total loss': 0.8083819523453712} | train loss {'Reaction outcome loss': 0.786643079470615, 'Total loss': 0.786643079470615}
2022-11-22 20:44:45,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:45,321 INFO:     Epoch: 26
2022-11-22 20:44:46,038 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.792100574482571, 'Total loss': 0.792100574482571} | train loss {'Reaction outcome loss': 0.781355619430542, 'Total loss': 0.781355619430542}
2022-11-22 20:44:46,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:46,039 INFO:     Epoch: 27
2022-11-22 20:44:46,815 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7959989275444638, 'Total loss': 0.7959989275444638} | train loss {'Reaction outcome loss': 0.7857719889708927, 'Total loss': 0.7857719889708927}
2022-11-22 20:44:46,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:46,815 INFO:     Epoch: 28
2022-11-22 20:44:47,583 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.80239633877169, 'Total loss': 0.80239633877169} | train loss {'Reaction outcome loss': 0.7801628354860812, 'Total loss': 0.7801628354860812}
2022-11-22 20:44:47,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:47,583 INFO:     Epoch: 29
2022-11-22 20:44:48,316 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8015691048719666, 'Total loss': 0.8015691048719666} | train loss {'Reaction outcome loss': 0.7855511245678882, 'Total loss': 0.7855511245678882}
2022-11-22 20:44:48,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:48,317 INFO:     Epoch: 30
2022-11-22 20:44:49,042 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8122225390239195, 'Total loss': 0.8122225390239195} | train loss {'Reaction outcome loss': 0.7803512788548761, 'Total loss': 0.7803512788548761}
2022-11-22 20:44:49,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:49,042 INFO:     Epoch: 31
2022-11-22 20:44:49,813 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.819993218915029, 'Total loss': 0.819993218915029} | train loss {'Reaction outcome loss': 0.7808425343766504, 'Total loss': 0.7808425343766504}
2022-11-22 20:44:49,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:49,813 INFO:     Epoch: 32
2022-11-22 20:44:50,543 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8013051768595522, 'Total loss': 0.8013051768595522} | train loss {'Reaction outcome loss': 0.787980850861997, 'Total loss': 0.787980850861997}
2022-11-22 20:44:50,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:50,543 INFO:     Epoch: 33
2022-11-22 20:44:51,324 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8032453656196594, 'Total loss': 0.8032453656196594} | train loss {'Reaction outcome loss': 0.7776079445469136, 'Total loss': 0.7776079445469136}
2022-11-22 20:44:51,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:51,324 INFO:     Epoch: 34
2022-11-22 20:44:52,119 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8392724896019156, 'Total loss': 0.8392724896019156} | train loss {'Reaction outcome loss': 0.7818426617554256, 'Total loss': 0.7818426617554256}
2022-11-22 20:44:52,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:52,119 INFO:     Epoch: 35
2022-11-22 20:44:52,877 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8223939592188055, 'Total loss': 0.8223939592188055} | train loss {'Reaction outcome loss': 0.7838208934482263, 'Total loss': 0.7838208934482263}
2022-11-22 20:44:52,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:52,877 INFO:     Epoch: 36
2022-11-22 20:44:53,609 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7987838937816295, 'Total loss': 0.7987838937816295} | train loss {'Reaction outcome loss': 0.781034232888903, 'Total loss': 0.781034232888903}
2022-11-22 20:44:53,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:53,609 INFO:     Epoch: 37
2022-11-22 20:44:54,370 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7952412536198442, 'Total loss': 0.7952412536198442} | train loss {'Reaction outcome loss': 0.7822488478251866, 'Total loss': 0.7822488478251866}
2022-11-22 20:44:54,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:54,371 INFO:     Epoch: 38
2022-11-22 20:44:55,071 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8274722546339035, 'Total loss': 0.8274722546339035} | train loss {'Reaction outcome loss': 0.7757720094554278, 'Total loss': 0.7757720094554278}
2022-11-22 20:44:55,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:55,071 INFO:     Epoch: 39
2022-11-22 20:44:55,843 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7994566932320595, 'Total loss': 0.7994566932320595} | train loss {'Reaction outcome loss': 0.7807246383355588, 'Total loss': 0.7807246383355588}
2022-11-22 20:44:55,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:55,844 INFO:     Epoch: 40
2022-11-22 20:44:56,629 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8133968277411028, 'Total loss': 0.8133968277411028} | train loss {'Reaction outcome loss': 0.7802192597973103, 'Total loss': 0.7802192597973103}
2022-11-22 20:44:56,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:56,630 INFO:     Epoch: 41
2022-11-22 20:44:57,354 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8227225440469655, 'Total loss': 0.8227225440469655} | train loss {'Reaction outcome loss': 0.7772784317026333, 'Total loss': 0.7772784317026333}
2022-11-22 20:44:57,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:57,354 INFO:     Epoch: 42
2022-11-22 20:44:58,078 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8071194264021787, 'Total loss': 0.8071194264021787} | train loss {'Reaction outcome loss': 0.788873603027694, 'Total loss': 0.788873603027694}
2022-11-22 20:44:58,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:58,078 INFO:     Epoch: 43
2022-11-22 20:44:58,833 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.812291338362477, 'Total loss': 0.812291338362477} | train loss {'Reaction outcome loss': 0.7696899562465901, 'Total loss': 0.7696899562465901}
2022-11-22 20:44:58,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:58,833 INFO:     Epoch: 44
2022-11-22 20:44:59,550 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8252780166539279, 'Total loss': 0.8252780166539279} | train loss {'Reaction outcome loss': 0.780534861768995, 'Total loss': 0.780534861768995}
2022-11-22 20:44:59,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:44:59,550 INFO:     Epoch: 45
2022-11-22 20:45:00,312 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.779021408747543, 'Total loss': 0.779021408747543} | train loss {'Reaction outcome loss': 0.7775024025415888, 'Total loss': 0.7775024025415888}
2022-11-22 20:45:00,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:00,312 INFO:     Epoch: 46
2022-11-22 20:45:01,060 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7932352911342274, 'Total loss': 0.7932352911342274} | train loss {'Reaction outcome loss': 0.7756823702734343, 'Total loss': 0.7756823702734343}
2022-11-22 20:45:01,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:01,061 INFO:     Epoch: 47
2022-11-22 20:45:01,856 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8085629791021347, 'Total loss': 0.8085629791021347} | train loss {'Reaction outcome loss': 0.7711626617275938, 'Total loss': 0.7711626617275938}
2022-11-22 20:45:01,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:01,856 INFO:     Epoch: 48
2022-11-22 20:45:02,641 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8182397179982879, 'Total loss': 0.8182397179982879} | train loss {'Reaction outcome loss': 0.7759620173853271, 'Total loss': 0.7759620173853271}
2022-11-22 20:45:02,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:02,642 INFO:     Epoch: 49
2022-11-22 20:45:03,410 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7931116914207285, 'Total loss': 0.7931116914207285} | train loss {'Reaction outcome loss': 0.7764592468738556, 'Total loss': 0.7764592468738556}
2022-11-22 20:45:03,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:03,410 INFO:     Epoch: 50
2022-11-22 20:45:04,146 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7944094626740976, 'Total loss': 0.7944094626740976} | train loss {'Reaction outcome loss': 0.7736550489250494, 'Total loss': 0.7736550489250494}
2022-11-22 20:45:04,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:04,147 INFO:     Epoch: 51
2022-11-22 20:45:04,911 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7985952631993727, 'Total loss': 0.7985952631993727} | train loss {'Reaction outcome loss': 0.7788610728419557, 'Total loss': 0.7788610728419557}
2022-11-22 20:45:04,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:04,911 INFO:     Epoch: 52
2022-11-22 20:45:05,654 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7836302105676044, 'Total loss': 0.7836302105676044} | train loss {'Reaction outcome loss': 0.776685411346202, 'Total loss': 0.776685411346202}
2022-11-22 20:45:05,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:05,654 INFO:     Epoch: 53
2022-11-22 20:45:06,364 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7976068949157541, 'Total loss': 0.7976068949157541} | train loss {'Reaction outcome loss': 0.7756677175054745, 'Total loss': 0.7756677175054745}
2022-11-22 20:45:06,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:06,364 INFO:     Epoch: 54
2022-11-22 20:45:07,133 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7944774018092589, 'Total loss': 0.7944774018092589} | train loss {'Reaction outcome loss': 0.7773012410621254, 'Total loss': 0.7773012410621254}
2022-11-22 20:45:07,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:07,133 INFO:     Epoch: 55
2022-11-22 20:45:07,919 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7779468765312975, 'Total loss': 0.7779468765312975} | train loss {'Reaction outcome loss': 0.7669770965770799, 'Total loss': 0.7669770965770799}
2022-11-22 20:45:07,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:07,919 INFO:     Epoch: 56
2022-11-22 20:45:08,658 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8274613314054229, 'Total loss': 0.8274613314054229} | train loss {'Reaction outcome loss': 0.7701179191774251, 'Total loss': 0.7701179191774251}
2022-11-22 20:45:08,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:08,658 INFO:     Epoch: 57
2022-11-22 20:45:09,368 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7968083206902851, 'Total loss': 0.7968083206902851} | train loss {'Reaction outcome loss': 0.7720889329910279, 'Total loss': 0.7720889329910279}
2022-11-22 20:45:09,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:09,368 INFO:     Epoch: 58
2022-11-22 20:45:10,094 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8345321057872339, 'Total loss': 0.8345321057872339} | train loss {'Reaction outcome loss': 0.7732432324059155, 'Total loss': 0.7732432324059155}
2022-11-22 20:45:10,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:10,094 INFO:     Epoch: 59
2022-11-22 20:45:10,826 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8043975640426982, 'Total loss': 0.8043975640426982} | train loss {'Reaction outcome loss': 0.7723378788451759, 'Total loss': 0.7723378788451759}
2022-11-22 20:45:10,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:10,826 INFO:     Epoch: 60
2022-11-22 20:45:11,609 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8029379390857436, 'Total loss': 0.8029379390857436} | train loss {'Reaction outcome loss': 0.7685815862246922, 'Total loss': 0.7685815862246922}
2022-11-22 20:45:11,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:11,609 INFO:     Epoch: 61
2022-11-22 20:45:12,342 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8950390300967477, 'Total loss': 0.8950390300967477} | train loss {'Reaction outcome loss': 0.7696492755899624, 'Total loss': 0.7696492755899624}
2022-11-22 20:45:12,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:12,342 INFO:     Epoch: 62
2022-11-22 20:45:13,043 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8005089150233702, 'Total loss': 0.8005089150233702} | train loss {'Reaction outcome loss': 0.7666714958998622, 'Total loss': 0.7666714958998622}
2022-11-22 20:45:13,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:13,043 INFO:     Epoch: 63
2022-11-22 20:45:13,822 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7913831465623595, 'Total loss': 0.7913831465623595} | train loss {'Reaction outcome loss': 0.7663141114371164, 'Total loss': 0.7663141114371164}
2022-11-22 20:45:13,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:13,822 INFO:     Epoch: 64
2022-11-22 20:45:14,584 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.810144844380292, 'Total loss': 0.810144844380292} | train loss {'Reaction outcome loss': 0.7690370843118551, 'Total loss': 0.7690370843118551}
2022-11-22 20:45:14,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:14,584 INFO:     Epoch: 65
2022-11-22 20:45:15,333 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7992370467294346, 'Total loss': 0.7992370467294346} | train loss {'Reaction outcome loss': 0.7565349311244731, 'Total loss': 0.7565349311244731}
2022-11-22 20:45:15,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:15,334 INFO:     Epoch: 66
2022-11-22 20:45:16,091 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7869268560951407, 'Total loss': 0.7869268560951407} | train loss {'Reaction outcome loss': 0.7591680198299642, 'Total loss': 0.7591680198299642}
2022-11-22 20:45:16,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:16,092 INFO:     Epoch: 67
2022-11-22 20:45:16,817 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.809705565598878, 'Total loss': 0.809705565598878} | train loss {'Reaction outcome loss': 0.7544513057689277, 'Total loss': 0.7544513057689277}
2022-11-22 20:45:16,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:16,817 INFO:     Epoch: 68
2022-11-22 20:45:17,553 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7711179026148536, 'Total loss': 0.7711179026148536} | train loss {'Reaction outcome loss': 0.7490053805769706, 'Total loss': 0.7490053805769706}
2022-11-22 20:45:17,553 INFO:     Found new best model at epoch 68
2022-11-22 20:45:17,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:17,554 INFO:     Epoch: 69
2022-11-22 20:45:18,276 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7842714325948195, 'Total loss': 0.7842714325948195} | train loss {'Reaction outcome loss': 0.75317419438946, 'Total loss': 0.75317419438946}
2022-11-22 20:45:18,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:18,276 INFO:     Epoch: 70
2022-11-22 20:45:19,006 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8070470501076091, 'Total loss': 0.8070470501076091} | train loss {'Reaction outcome loss': 0.755055088413005, 'Total loss': 0.755055088413005}
2022-11-22 20:45:19,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:19,006 INFO:     Epoch: 71
2022-11-22 20:45:19,737 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7983344353058122, 'Total loss': 0.7983344353058122} | train loss {'Reaction outcome loss': 0.7551359097568356, 'Total loss': 0.7551359097568356}
2022-11-22 20:45:19,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:19,737 INFO:     Epoch: 72
2022-11-22 20:45:20,471 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7710289823060686, 'Total loss': 0.7710289823060686} | train loss {'Reaction outcome loss': 0.7437494618552072, 'Total loss': 0.7437494618552072}
2022-11-22 20:45:20,471 INFO:     Found new best model at epoch 72
2022-11-22 20:45:20,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:20,472 INFO:     Epoch: 73
2022-11-22 20:45:21,202 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7990729849446904, 'Total loss': 0.7990729849446904} | train loss {'Reaction outcome loss': 0.7478980799110568, 'Total loss': 0.7478980799110568}
2022-11-22 20:45:21,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:21,202 INFO:     Epoch: 74
2022-11-22 20:45:22,006 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7920531955632296, 'Total loss': 0.7920531955632296} | train loss {'Reaction outcome loss': 0.7486885357876213, 'Total loss': 0.7486885357876213}
2022-11-22 20:45:22,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:22,006 INFO:     Epoch: 75
2022-11-22 20:45:22,768 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7850270921533758, 'Total loss': 0.7850270921533758} | train loss {'Reaction outcome loss': 0.742278583439029, 'Total loss': 0.742278583439029}
2022-11-22 20:45:22,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:22,768 INFO:     Epoch: 76
2022-11-22 20:45:23,512 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7727789933031256, 'Total loss': 0.7727789933031256} | train loss {'Reaction outcome loss': 0.736557895188429, 'Total loss': 0.736557895188429}
2022-11-22 20:45:23,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:23,512 INFO:     Epoch: 77
2022-11-22 20:45:24,243 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7623152082616632, 'Total loss': 0.7623152082616632} | train loss {'Reaction outcome loss': 0.739249070809812, 'Total loss': 0.739249070809812}
2022-11-22 20:45:24,243 INFO:     Found new best model at epoch 77
2022-11-22 20:45:24,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:24,244 INFO:     Epoch: 78
2022-11-22 20:45:25,013 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7549663470550017, 'Total loss': 0.7549663470550017} | train loss {'Reaction outcome loss': 0.7406328326585342, 'Total loss': 0.7406328326585342}
2022-11-22 20:45:25,013 INFO:     Found new best model at epoch 78
2022-11-22 20:45:25,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:25,014 INFO:     Epoch: 79
2022-11-22 20:45:25,729 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7827899591489271, 'Total loss': 0.7827899591489271} | train loss {'Reaction outcome loss': 0.7305198904202909, 'Total loss': 0.7305198904202909}
2022-11-22 20:45:25,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:25,729 INFO:     Epoch: 80
2022-11-22 20:45:26,452 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.745778041807088, 'Total loss': 0.745778041807088} | train loss {'Reaction outcome loss': 0.7329941281858756, 'Total loss': 0.7329941281858756}
2022-11-22 20:45:26,453 INFO:     Found new best model at epoch 80
2022-11-22 20:45:26,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:26,454 INFO:     Epoch: 81
2022-11-22 20:45:27,235 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8012982600114562, 'Total loss': 0.8012982600114562} | train loss {'Reaction outcome loss': 0.732321099359162, 'Total loss': 0.732321099359162}
2022-11-22 20:45:27,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:27,237 INFO:     Epoch: 82
2022-11-22 20:45:27,938 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7892207306894389, 'Total loss': 0.7892207306894389} | train loss {'Reaction outcome loss': 0.7326732366668934, 'Total loss': 0.7326732366668934}
2022-11-22 20:45:27,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:27,938 INFO:     Epoch: 83
2022-11-22 20:45:28,672 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7615886147726666, 'Total loss': 0.7615886147726666} | train loss {'Reaction outcome loss': 0.7284265974346472, 'Total loss': 0.7284265974346472}
2022-11-22 20:45:28,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:28,672 INFO:     Epoch: 84
2022-11-22 20:45:29,427 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7529932985251601, 'Total loss': 0.7529932985251601} | train loss {'Reaction outcome loss': 0.7186454713344574, 'Total loss': 0.7186454713344574}
2022-11-22 20:45:29,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:29,427 INFO:     Epoch: 85
2022-11-22 20:45:30,210 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7676834152503447, 'Total loss': 0.7676834152503447} | train loss {'Reaction outcome loss': 0.7227979523794992, 'Total loss': 0.7227979523794992}
2022-11-22 20:45:30,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:30,210 INFO:     Epoch: 86
2022-11-22 20:45:30,929 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7391025556082075, 'Total loss': 0.7391025556082075} | train loss {'Reaction outcome loss': 0.7177092054668738, 'Total loss': 0.7177092054668738}
2022-11-22 20:45:30,930 INFO:     Found new best model at epoch 86
2022-11-22 20:45:30,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:30,930 INFO:     Epoch: 87
2022-11-22 20:45:31,684 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7415569167245518, 'Total loss': 0.7415569167245518} | train loss {'Reaction outcome loss': 0.7267665411744799, 'Total loss': 0.7267665411744799}
2022-11-22 20:45:31,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:31,684 INFO:     Epoch: 88
2022-11-22 20:45:32,435 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7898518178950656, 'Total loss': 0.7898518178950656} | train loss {'Reaction outcome loss': 0.7142303491125301, 'Total loss': 0.7142303491125301}
2022-11-22 20:45:32,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:32,435 INFO:     Epoch: 89
2022-11-22 20:45:33,159 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7474479207938368, 'Total loss': 0.7474479207938368} | train loss {'Reaction outcome loss': 0.7128499802278012, 'Total loss': 0.7128499802278012}
2022-11-22 20:45:33,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:33,159 INFO:     Epoch: 90
2022-11-22 20:45:33,868 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7598262530836192, 'Total loss': 0.7598262530836192} | train loss {'Reaction outcome loss': 0.7254772691094146, 'Total loss': 0.7254772691094146}
2022-11-22 20:45:33,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:33,869 INFO:     Epoch: 91
2022-11-22 20:45:34,599 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7494077709588137, 'Total loss': 0.7494077709588137} | train loss {'Reaction outcome loss': 0.7166012436759716, 'Total loss': 0.7166012436759716}
2022-11-22 20:45:34,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:34,599 INFO:     Epoch: 92
2022-11-22 20:45:35,389 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7593988281759348, 'Total loss': 0.7593988281759348} | train loss {'Reaction outcome loss': 0.7220068487585808, 'Total loss': 0.7220068487585808}
2022-11-22 20:45:35,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:35,390 INFO:     Epoch: 93
2022-11-22 20:45:36,124 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7488518418236212, 'Total loss': 0.7488518418236212} | train loss {'Reaction outcome loss': 0.7116694336034813, 'Total loss': 0.7116694336034813}
2022-11-22 20:45:36,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:36,124 INFO:     Epoch: 94
2022-11-22 20:45:36,893 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7534014934843237, 'Total loss': 0.7534014934843237} | train loss {'Reaction outcome loss': 0.7142655471149756, 'Total loss': 0.7142655471149756}
2022-11-22 20:45:36,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:36,893 INFO:     Epoch: 95
2022-11-22 20:45:37,674 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7867164117368785, 'Total loss': 0.7867164117368785} | train loss {'Reaction outcome loss': 0.7011095224594583, 'Total loss': 0.7011095224594583}
2022-11-22 20:45:37,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:37,674 INFO:     Epoch: 96
2022-11-22 20:45:38,434 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7155615626411005, 'Total loss': 0.7155615626411005} | train loss {'Reaction outcome loss': 0.7141796732435421, 'Total loss': 0.7141796732435421}
2022-11-22 20:45:38,434 INFO:     Found new best model at epoch 96
2022-11-22 20:45:38,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:38,435 INFO:     Epoch: 97
2022-11-22 20:45:39,204 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7432015531442382, 'Total loss': 0.7432015531442382} | train loss {'Reaction outcome loss': 0.7032527731389415, 'Total loss': 0.7032527731389415}
2022-11-22 20:45:39,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:39,205 INFO:     Epoch: 98
2022-11-22 20:45:39,970 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8276113542643461, 'Total loss': 0.8276113542643461} | train loss {'Reaction outcome loss': 0.708454333458628, 'Total loss': 0.708454333458628}
2022-11-22 20:45:39,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:39,970 INFO:     Epoch: 99
2022-11-22 20:45:40,748 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7369715916839513, 'Total loss': 0.7369715916839513} | train loss {'Reaction outcome loss': 0.7083251192861674, 'Total loss': 0.7083251192861674}
2022-11-22 20:45:40,748 INFO:     Best model found after epoch 97 of 100.
2022-11-22 20:45:40,748 INFO:   Done with stage: TRAINING
2022-11-22 20:45:40,748 INFO:   Starting stage: EVALUATION
2022-11-22 20:45:40,872 INFO:   Done with stage: EVALUATION
2022-11-22 20:45:40,872 INFO:   Leaving out SEQ value Fold_8
2022-11-22 20:45:40,885 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 20:45:40,885 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:45:41,556 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:45:41,556 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:45:41,625 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:45:41,625 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:45:41,625 INFO:     No hyperparam tuning for this model
2022-11-22 20:45:41,625 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:45:41,625 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:45:41,626 INFO:     None feature selector for col prot
2022-11-22 20:45:41,626 INFO:     None feature selector for col prot
2022-11-22 20:45:41,626 INFO:     None feature selector for col prot
2022-11-22 20:45:41,627 INFO:     None feature selector for col chem
2022-11-22 20:45:41,627 INFO:     None feature selector for col chem
2022-11-22 20:45:41,627 INFO:     None feature selector for col chem
2022-11-22 20:45:41,627 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:45:41,627 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:45:41,628 INFO:     Number of params in model 126091
2022-11-22 20:45:41,632 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:45:41,632 INFO:   Starting stage: TRAINING
2022-11-22 20:45:41,681 INFO:     Val loss before train {'Reaction outcome loss': 0.9768893840638074, 'Total loss': 0.9768893840638074}
2022-11-22 20:45:41,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:41,681 INFO:     Epoch: 0
2022-11-22 20:45:42,422 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.844641154462641, 'Total loss': 0.844641154462641} | train loss {'Reaction outcome loss': 0.8826536311497611, 'Total loss': 0.8826536311497611}
2022-11-22 20:45:42,422 INFO:     Found new best model at epoch 0
2022-11-22 20:45:42,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:42,423 INFO:     Epoch: 1
2022-11-22 20:45:43,150 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7967153371057727, 'Total loss': 0.7967153371057727} | train loss {'Reaction outcome loss': 0.8507547972183074, 'Total loss': 0.8507547972183074}
2022-11-22 20:45:43,150 INFO:     Found new best model at epoch 1
2022-11-22 20:45:43,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:43,151 INFO:     Epoch: 2
2022-11-22 20:45:43,903 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7907492145895958, 'Total loss': 0.7907492145895958} | train loss {'Reaction outcome loss': 0.8379931255213676, 'Total loss': 0.8379931255213676}
2022-11-22 20:45:43,903 INFO:     Found new best model at epoch 2
2022-11-22 20:45:43,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:43,904 INFO:     Epoch: 3
2022-11-22 20:45:44,682 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8064628168940544, 'Total loss': 0.8064628168940544} | train loss {'Reaction outcome loss': 0.828329551003633, 'Total loss': 0.828329551003633}
2022-11-22 20:45:44,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:44,682 INFO:     Epoch: 4
2022-11-22 20:45:45,445 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7966579280116342, 'Total loss': 0.7966579280116342} | train loss {'Reaction outcome loss': 0.8292900055887238, 'Total loss': 0.8292900055887238}
2022-11-22 20:45:45,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:45,445 INFO:     Epoch: 5
2022-11-22 20:45:46,224 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7723976922306147, 'Total loss': 0.7723976922306147} | train loss {'Reaction outcome loss': 0.816544886438116, 'Total loss': 0.816544886438116}
2022-11-22 20:45:46,225 INFO:     Found new best model at epoch 5
2022-11-22 20:45:46,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:46,226 INFO:     Epoch: 6
2022-11-22 20:45:46,934 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7995886254039678, 'Total loss': 0.7995886254039678} | train loss {'Reaction outcome loss': 0.8167985907245067, 'Total loss': 0.8167985907245067}
2022-11-22 20:45:46,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:46,935 INFO:     Epoch: 7
2022-11-22 20:45:47,658 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7738854918967594, 'Total loss': 0.7738854918967594} | train loss {'Reaction outcome loss': 0.8131695454639774, 'Total loss': 0.8131695454639774}
2022-11-22 20:45:47,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:47,658 INFO:     Epoch: 8
2022-11-22 20:45:48,492 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7814607308669523, 'Total loss': 0.7814607308669523} | train loss {'Reaction outcome loss': 0.8095546255428945, 'Total loss': 0.8095546255428945}
2022-11-22 20:45:48,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:48,492 INFO:     Epoch: 9
2022-11-22 20:45:49,226 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7961522720076821, 'Total loss': 0.7961522720076821} | train loss {'Reaction outcome loss': 0.8029971436387108, 'Total loss': 0.8029971436387108}
2022-11-22 20:45:49,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:49,227 INFO:     Epoch: 10
2022-11-22 20:45:50,019 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7660812810063362, 'Total loss': 0.7660812810063362} | train loss {'Reaction outcome loss': 0.8071620502779561, 'Total loss': 0.8071620502779561}
2022-11-22 20:45:50,019 INFO:     Found new best model at epoch 10
2022-11-22 20:45:50,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:50,020 INFO:     Epoch: 11
2022-11-22 20:45:50,765 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7919334809888493, 'Total loss': 0.7919334809888493} | train loss {'Reaction outcome loss': 0.801969455675252, 'Total loss': 0.801969455675252}
2022-11-22 20:45:50,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:50,765 INFO:     Epoch: 12
2022-11-22 20:45:51,521 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.761754879897291, 'Total loss': 0.761754879897291} | train loss {'Reaction outcome loss': 0.8042659117810188, 'Total loss': 0.8042659117810188}
2022-11-22 20:45:51,521 INFO:     Found new best model at epoch 12
2022-11-22 20:45:51,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:51,522 INFO:     Epoch: 13
2022-11-22 20:45:52,258 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7514237490567294, 'Total loss': 0.7514237490567294} | train loss {'Reaction outcome loss': 0.8007131441225929, 'Total loss': 0.8007131441225929}
2022-11-22 20:45:52,258 INFO:     Found new best model at epoch 13
2022-11-22 20:45:52,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:52,259 INFO:     Epoch: 14
2022-11-22 20:45:52,993 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7716288512403314, 'Total loss': 0.7716288512403314} | train loss {'Reaction outcome loss': 0.7998867366583117, 'Total loss': 0.7998867366583117}
2022-11-22 20:45:52,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:52,993 INFO:     Epoch: 15
2022-11-22 20:45:53,742 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.815284630114382, 'Total loss': 0.815284630114382} | train loss {'Reaction outcome loss': 0.803492487918946, 'Total loss': 0.803492487918946}
2022-11-22 20:45:53,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:53,743 INFO:     Epoch: 16
2022-11-22 20:45:54,522 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.764899882403287, 'Total loss': 0.764899882403287} | train loss {'Reaction outcome loss': 0.8039850659908787, 'Total loss': 0.8039850659908787}
2022-11-22 20:45:54,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:54,522 INFO:     Epoch: 17
2022-11-22 20:45:55,263 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7657190642573617, 'Total loss': 0.7657190642573617} | train loss {'Reaction outcome loss': 0.8040438541962255, 'Total loss': 0.8040438541962255}
2022-11-22 20:45:55,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:55,263 INFO:     Epoch: 18
2022-11-22 20:45:55,994 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.760676200416955, 'Total loss': 0.760676200416955} | train loss {'Reaction outcome loss': 0.7970978347284179, 'Total loss': 0.7970978347284179}
2022-11-22 20:45:55,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:55,994 INFO:     Epoch: 19
2022-11-22 20:45:56,723 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7740617394447327, 'Total loss': 0.7740617394447327} | train loss {'Reaction outcome loss': 0.7944954953366711, 'Total loss': 0.7944954953366711}
2022-11-22 20:45:56,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:56,723 INFO:     Epoch: 20
2022-11-22 20:45:57,443 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7808955277908932, 'Total loss': 0.7808955277908932} | train loss {'Reaction outcome loss': 0.7967672557119401, 'Total loss': 0.7967672557119401}
2022-11-22 20:45:57,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:57,443 INFO:     Epoch: 21
2022-11-22 20:45:58,175 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7798874865878712, 'Total loss': 0.7798874865878712} | train loss {'Reaction outcome loss': 0.7941989883059456, 'Total loss': 0.7941989883059456}
2022-11-22 20:45:58,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:58,176 INFO:     Epoch: 22
2022-11-22 20:45:58,975 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7491470351815224, 'Total loss': 0.7491470351815224} | train loss {'Reaction outcome loss': 0.7912650716400915, 'Total loss': 0.7912650716400915}
2022-11-22 20:45:58,976 INFO:     Found new best model at epoch 22
2022-11-22 20:45:58,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:58,977 INFO:     Epoch: 23
2022-11-22 20:45:59,774 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.764940197494897, 'Total loss': 0.764940197494897} | train loss {'Reaction outcome loss': 0.7930244651412771, 'Total loss': 0.7930244651412771}
2022-11-22 20:45:59,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:45:59,774 INFO:     Epoch: 24
2022-11-22 20:46:00,601 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7465834807265889, 'Total loss': 0.7465834807265889} | train loss {'Reaction outcome loss': 0.7939432304232351, 'Total loss': 0.7939432304232351}
2022-11-22 20:46:00,601 INFO:     Found new best model at epoch 24
2022-11-22 20:46:00,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:00,602 INFO:     Epoch: 25
2022-11-22 20:46:01,429 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7498616210438989, 'Total loss': 0.7498616210438989} | train loss {'Reaction outcome loss': 0.7918929172860038, 'Total loss': 0.7918929172860038}
2022-11-22 20:46:01,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:01,429 INFO:     Epoch: 26
2022-11-22 20:46:02,234 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7564207328991457, 'Total loss': 0.7564207328991457} | train loss {'Reaction outcome loss': 0.7916455664221318, 'Total loss': 0.7916455664221318}
2022-11-22 20:46:02,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:02,235 INFO:     Epoch: 27
2022-11-22 20:46:03,006 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7649858919056979, 'Total loss': 0.7649858919056979} | train loss {'Reaction outcome loss': 0.795319676399231, 'Total loss': 0.795319676399231}
2022-11-22 20:46:03,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:03,006 INFO:     Epoch: 28
2022-11-22 20:46:03,803 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7739060202782805, 'Total loss': 0.7739060202782805} | train loss {'Reaction outcome loss': 0.7937188224206048, 'Total loss': 0.7937188224206048}
2022-11-22 20:46:03,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:03,803 INFO:     Epoch: 29
2022-11-22 20:46:04,578 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7628500095822595, 'Total loss': 0.7628500095822595} | train loss {'Reaction outcome loss': 0.7944841001543307, 'Total loss': 0.7944841001543307}
2022-11-22 20:46:04,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:04,579 INFO:     Epoch: 30
2022-11-22 20:46:05,390 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7638103528456255, 'Total loss': 0.7638103528456255} | train loss {'Reaction outcome loss': 0.7904359760784334, 'Total loss': 0.7904359760784334}
2022-11-22 20:46:05,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:05,390 INFO:     Epoch: 31
2022-11-22 20:46:06,108 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7619618800553408, 'Total loss': 0.7619618800553408} | train loss {'Reaction outcome loss': 0.7907321472321788, 'Total loss': 0.7907321472321788}
2022-11-22 20:46:06,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:06,108 INFO:     Epoch: 32
2022-11-22 20:46:06,843 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7643495615233075, 'Total loss': 0.7643495615233075} | train loss {'Reaction outcome loss': 0.7871661505872204, 'Total loss': 0.7871661505872204}
2022-11-22 20:46:06,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:06,844 INFO:     Epoch: 33
2022-11-22 20:46:07,613 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7528285885399039, 'Total loss': 0.7528285885399039} | train loss {'Reaction outcome loss': 0.7895747765658363, 'Total loss': 0.7895747765658363}
2022-11-22 20:46:07,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:07,614 INFO:     Epoch: 34
2022-11-22 20:46:08,372 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7536614449186758, 'Total loss': 0.7536614449186758} | train loss {'Reaction outcome loss': 0.7928401433652447, 'Total loss': 0.7928401433652447}
2022-11-22 20:46:08,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:08,372 INFO:     Epoch: 35
2022-11-22 20:46:09,182 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7477481697093357, 'Total loss': 0.7477481697093357} | train loss {'Reaction outcome loss': 0.7877049467736675, 'Total loss': 0.7877049467736675}
2022-11-22 20:46:09,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:09,182 INFO:     Epoch: 36
2022-11-22 20:46:09,919 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.769281996244734, 'Total loss': 0.769281996244734} | train loss {'Reaction outcome loss': 0.7851425001938497, 'Total loss': 0.7851425001938497}
2022-11-22 20:46:09,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:09,919 INFO:     Epoch: 37
2022-11-22 20:46:10,696 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7425019226290963, 'Total loss': 0.7425019226290963} | train loss {'Reaction outcome loss': 0.7947631510755708, 'Total loss': 0.7947631510755708}
2022-11-22 20:46:10,696 INFO:     Found new best model at epoch 37
2022-11-22 20:46:10,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:10,697 INFO:     Epoch: 38
2022-11-22 20:46:11,476 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7558452426032587, 'Total loss': 0.7558452426032587} | train loss {'Reaction outcome loss': 0.7933922872668312, 'Total loss': 0.7933922872668312}
2022-11-22 20:46:11,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:11,476 INFO:     Epoch: 39
2022-11-22 20:46:12,192 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7560765587470748, 'Total loss': 0.7560765587470748} | train loss {'Reaction outcome loss': 0.7932617451635099, 'Total loss': 0.7932617451635099}
2022-11-22 20:46:12,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:12,192 INFO:     Epoch: 40
2022-11-22 20:46:12,917 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7550133114511316, 'Total loss': 0.7550133114511316} | train loss {'Reaction outcome loss': 0.7856314118591047, 'Total loss': 0.7856314118591047}
2022-11-22 20:46:12,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:12,917 INFO:     Epoch: 41
2022-11-22 20:46:13,666 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7358755367723379, 'Total loss': 0.7358755367723379} | train loss {'Reaction outcome loss': 0.7859056694132667, 'Total loss': 0.7859056694132667}
2022-11-22 20:46:13,666 INFO:     Found new best model at epoch 41
2022-11-22 20:46:13,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:13,667 INFO:     Epoch: 42
2022-11-22 20:46:14,449 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7495774904435332, 'Total loss': 0.7495774904435332} | train loss {'Reaction outcome loss': 0.7884569374784347, 'Total loss': 0.7884569374784347}
2022-11-22 20:46:14,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:14,450 INFO:     Epoch: 43
2022-11-22 20:46:15,176 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7865420573137023, 'Total loss': 0.7865420573137023} | train loss {'Reaction outcome loss': 0.7878061837006, 'Total loss': 0.7878061837006}
2022-11-22 20:46:15,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:15,176 INFO:     Epoch: 44
2022-11-22 20:46:15,958 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7515636337074366, 'Total loss': 0.7515636337074366} | train loss {'Reaction outcome loss': 0.7849930927397744, 'Total loss': 0.7849930927397744}
2022-11-22 20:46:15,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:15,958 INFO:     Epoch: 45
2022-11-22 20:46:16,719 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7812871858477592, 'Total loss': 0.7812871858477592} | train loss {'Reaction outcome loss': 0.7821781110138663, 'Total loss': 0.7821781110138663}
2022-11-22 20:46:16,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:16,720 INFO:     Epoch: 46
2022-11-22 20:46:17,476 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7671413055875085, 'Total loss': 0.7671413055875085} | train loss {'Reaction outcome loss': 0.7837734320952047, 'Total loss': 0.7837734320952047}
2022-11-22 20:46:17,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:17,476 INFO:     Epoch: 47
2022-11-22 20:46:18,225 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7882553488016129, 'Total loss': 0.7882553488016129} | train loss {'Reaction outcome loss': 0.7781267555490616, 'Total loss': 0.7781267555490616}
2022-11-22 20:46:18,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:18,226 INFO:     Epoch: 48
2022-11-22 20:46:18,997 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7578821405768394, 'Total loss': 0.7578821405768394} | train loss {'Reaction outcome loss': 0.7785916912459558, 'Total loss': 0.7785916912459558}
2022-11-22 20:46:18,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:18,997 INFO:     Epoch: 49
2022-11-22 20:46:19,769 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7303245074369691, 'Total loss': 0.7303245074369691} | train loss {'Reaction outcome loss': 0.7872796959934696, 'Total loss': 0.7872796959934696}
2022-11-22 20:46:19,769 INFO:     Found new best model at epoch 49
2022-11-22 20:46:19,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:19,770 INFO:     Epoch: 50
2022-11-22 20:46:20,507 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7462339638309046, 'Total loss': 0.7462339638309046} | train loss {'Reaction outcome loss': 0.7762606864975344, 'Total loss': 0.7762606864975344}
2022-11-22 20:46:20,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:20,508 INFO:     Epoch: 51
2022-11-22 20:46:21,268 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7344741265882145, 'Total loss': 0.7344741265882145} | train loss {'Reaction outcome loss': 0.7772112875696151, 'Total loss': 0.7772112875696151}
2022-11-22 20:46:21,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:21,268 INFO:     Epoch: 52
2022-11-22 20:46:22,010 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7286975857886401, 'Total loss': 0.7286975857886401} | train loss {'Reaction outcome loss': 0.7835364405426287, 'Total loss': 0.7835364405426287}
2022-11-22 20:46:22,010 INFO:     Found new best model at epoch 52
2022-11-22 20:46:22,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:22,011 INFO:     Epoch: 53
2022-11-22 20:46:22,737 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7400036894462325, 'Total loss': 0.7400036894462325} | train loss {'Reaction outcome loss': 0.7761920424959352, 'Total loss': 0.7761920424959352}
2022-11-22 20:46:22,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:22,738 INFO:     Epoch: 54
2022-11-22 20:46:23,478 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7249164466153492, 'Total loss': 0.7249164466153492} | train loss {'Reaction outcome loss': 0.7788314786889861, 'Total loss': 0.7788314786889861}
2022-11-22 20:46:23,478 INFO:     Found new best model at epoch 54
2022-11-22 20:46:23,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:23,479 INFO:     Epoch: 55
2022-11-22 20:46:24,207 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.743147306821563, 'Total loss': 0.743147306821563} | train loss {'Reaction outcome loss': 0.7756568918064717, 'Total loss': 0.7756568918064717}
2022-11-22 20:46:24,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:24,208 INFO:     Epoch: 56
2022-11-22 20:46:24,983 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7416615221988071, 'Total loss': 0.7416615221988071} | train loss {'Reaction outcome loss': 0.7799189774499785, 'Total loss': 0.7799189774499785}
2022-11-22 20:46:24,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:24,983 INFO:     Epoch: 57
2022-11-22 20:46:25,731 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7398874989964745, 'Total loss': 0.7398874989964745} | train loss {'Reaction outcome loss': 0.7721966077243129, 'Total loss': 0.7721966077243129}
2022-11-22 20:46:25,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:25,731 INFO:     Epoch: 58
2022-11-22 20:46:26,479 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.734493147243153, 'Total loss': 0.734493147243153} | train loss {'Reaction outcome loss': 0.7731521877069627, 'Total loss': 0.7731521877069627}
2022-11-22 20:46:26,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:26,479 INFO:     Epoch: 59
2022-11-22 20:46:27,254 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7500256753780625, 'Total loss': 0.7500256753780625} | train loss {'Reaction outcome loss': 0.766389770853904, 'Total loss': 0.766389770853904}
2022-11-22 20:46:27,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:27,254 INFO:     Epoch: 60
2022-11-22 20:46:27,993 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7409823604605414, 'Total loss': 0.7409823604605414} | train loss {'Reaction outcome loss': 0.7698924461559903, 'Total loss': 0.7698924461559903}
2022-11-22 20:46:27,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:27,993 INFO:     Epoch: 61
2022-11-22 20:46:28,725 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.731778658926487, 'Total loss': 0.731778658926487} | train loss {'Reaction outcome loss': 0.7691073563070067, 'Total loss': 0.7691073563070067}
2022-11-22 20:46:28,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:28,725 INFO:     Epoch: 62
2022-11-22 20:46:29,501 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.744734874503179, 'Total loss': 0.744734874503179} | train loss {'Reaction outcome loss': 0.7636853338729951, 'Total loss': 0.7636853338729951}
2022-11-22 20:46:29,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:29,502 INFO:     Epoch: 63
2022-11-22 20:46:30,262 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7189097086136992, 'Total loss': 0.7189097086136992} | train loss {'Reaction outcome loss': 0.7624793151213277, 'Total loss': 0.7624793151213277}
2022-11-22 20:46:30,263 INFO:     Found new best model at epoch 63
2022-11-22 20:46:30,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:30,263 INFO:     Epoch: 64
2022-11-22 20:46:31,006 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7230948453599756, 'Total loss': 0.7230948453599756} | train loss {'Reaction outcome loss': 0.7708397735991785, 'Total loss': 0.7708397735991785}
2022-11-22 20:46:31,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:31,006 INFO:     Epoch: 65
2022-11-22 20:46:31,756 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7187681462277066, 'Total loss': 0.7187681462277066} | train loss {'Reaction outcome loss': 0.7583104511422496, 'Total loss': 0.7583104511422496}
2022-11-22 20:46:31,756 INFO:     Found new best model at epoch 65
2022-11-22 20:46:31,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:31,757 INFO:     Epoch: 66
2022-11-22 20:46:32,509 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7331053330139681, 'Total loss': 0.7331053330139681} | train loss {'Reaction outcome loss': 0.7628830908046614, 'Total loss': 0.7628830908046614}
2022-11-22 20:46:32,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:32,510 INFO:     Epoch: 67
2022-11-22 20:46:33,249 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7346418195150115, 'Total loss': 0.7346418195150115} | train loss {'Reaction outcome loss': 0.7618940605992272, 'Total loss': 0.7618940605992272}
2022-11-22 20:46:33,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:33,249 INFO:     Epoch: 68
2022-11-22 20:46:33,981 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7243172465400263, 'Total loss': 0.7243172465400263} | train loss {'Reaction outcome loss': 0.7574618792822284, 'Total loss': 0.7574618792822284}
2022-11-22 20:46:33,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:33,981 INFO:     Epoch: 69
2022-11-22 20:46:34,708 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7193167886950753, 'Total loss': 0.7193167886950753} | train loss {'Reaction outcome loss': 0.7587334486024995, 'Total loss': 0.7587334486024995}
2022-11-22 20:46:34,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:34,708 INFO:     Epoch: 70
2022-11-22 20:46:35,476 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7206021682782606, 'Total loss': 0.7206021682782606} | train loss {'Reaction outcome loss': 0.7519988387582763, 'Total loss': 0.7519988387582763}
2022-11-22 20:46:35,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:35,476 INFO:     Epoch: 71
2022-11-22 20:46:36,210 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7172324196858839, 'Total loss': 0.7172324196858839} | train loss {'Reaction outcome loss': 0.7485917037533175, 'Total loss': 0.7485917037533175}
2022-11-22 20:46:36,211 INFO:     Found new best model at epoch 71
2022-11-22 20:46:36,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:36,212 INFO:     Epoch: 72
2022-11-22 20:46:36,953 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7138089537620544, 'Total loss': 0.7138089537620544} | train loss {'Reaction outcome loss': 0.7592356683265779, 'Total loss': 0.7592356683265779}
2022-11-22 20:46:36,953 INFO:     Found new best model at epoch 72
2022-11-22 20:46:36,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:36,954 INFO:     Epoch: 73
2022-11-22 20:46:37,730 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7095470800995827, 'Total loss': 0.7095470800995827} | train loss {'Reaction outcome loss': 0.7386538165230905, 'Total loss': 0.7386538165230905}
2022-11-22 20:46:37,730 INFO:     Found new best model at epoch 73
2022-11-22 20:46:37,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:37,731 INFO:     Epoch: 74
2022-11-22 20:46:38,484 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.725001762536439, 'Total loss': 0.725001762536439} | train loss {'Reaction outcome loss': 0.7431477788955935, 'Total loss': 0.7431477788955935}
2022-11-22 20:46:38,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:38,485 INFO:     Epoch: 75
2022-11-22 20:46:39,221 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.709702542559667, 'Total loss': 0.709702542559667} | train loss {'Reaction outcome loss': 0.7417611381219279, 'Total loss': 0.7417611381219279}
2022-11-22 20:46:39,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:39,222 INFO:     Epoch: 76
2022-11-22 20:46:40,005 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.714628894220699, 'Total loss': 0.714628894220699} | train loss {'Reaction outcome loss': 0.7345372985808118, 'Total loss': 0.7345372985808118}
2022-11-22 20:46:40,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:40,005 INFO:     Epoch: 77
2022-11-22 20:46:40,792 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.680446011776274, 'Total loss': 0.680446011776274} | train loss {'Reaction outcome loss': 0.7429274232877839, 'Total loss': 0.7429274232877839}
2022-11-22 20:46:40,792 INFO:     Found new best model at epoch 77
2022-11-22 20:46:40,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:40,793 INFO:     Epoch: 78
2022-11-22 20:46:41,622 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.694914622740312, 'Total loss': 0.694914622740312} | train loss {'Reaction outcome loss': 0.7342766478898064, 'Total loss': 0.7342766478898064}
2022-11-22 20:46:41,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:41,623 INFO:     Epoch: 79
2022-11-22 20:46:42,339 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.73725756325505, 'Total loss': 0.73725756325505} | train loss {'Reaction outcome loss': 0.7371873389328679, 'Total loss': 0.7371873389328679}
2022-11-22 20:46:42,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:42,339 INFO:     Epoch: 80
2022-11-22 20:46:43,137 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7037744677879594, 'Total loss': 0.7037744677879594} | train loss {'Reaction outcome loss': 0.7335100824073437, 'Total loss': 0.7335100824073437}
2022-11-22 20:46:43,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:43,137 INFO:     Epoch: 81
2022-11-22 20:46:43,920 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.744271535765041, 'Total loss': 0.744271535765041} | train loss {'Reaction outcome loss': 0.7319188077122935, 'Total loss': 0.7319188077122935}
2022-11-22 20:46:43,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:43,920 INFO:     Epoch: 82
2022-11-22 20:46:44,710 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7364992031996901, 'Total loss': 0.7364992031996901} | train loss {'Reaction outcome loss': 0.7287664471134063, 'Total loss': 0.7287664471134063}
2022-11-22 20:46:44,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:44,711 INFO:     Epoch: 83
2022-11-22 20:46:45,452 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6779426600445401, 'Total loss': 0.6779426600445401} | train loss {'Reaction outcome loss': 0.7250373286585654, 'Total loss': 0.7250373286585654}
2022-11-22 20:46:45,452 INFO:     Found new best model at epoch 83
2022-11-22 20:46:45,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:45,453 INFO:     Epoch: 84
2022-11-22 20:46:46,182 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6967456577853723, 'Total loss': 0.6967456577853723} | train loss {'Reaction outcome loss': 0.7281458673457946, 'Total loss': 0.7281458673457946}
2022-11-22 20:46:46,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:46,182 INFO:     Epoch: 85
2022-11-22 20:46:46,961 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7125675962729887, 'Total loss': 0.7125675962729887} | train loss {'Reaction outcome loss': 0.7214618477850191, 'Total loss': 0.7214618477850191}
2022-11-22 20:46:46,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:46,961 INFO:     Epoch: 86
2022-11-22 20:46:47,734 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6842636235735633, 'Total loss': 0.6842636235735633} | train loss {'Reaction outcome loss': 0.7261754825951592, 'Total loss': 0.7261754825951592}
2022-11-22 20:46:47,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:47,734 INFO:     Epoch: 87
2022-11-22 20:46:48,513 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.694186424667185, 'Total loss': 0.694186424667185} | train loss {'Reaction outcome loss': 0.72181834394653, 'Total loss': 0.72181834394653}
2022-11-22 20:46:48,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:48,515 INFO:     Epoch: 88
2022-11-22 20:46:49,330 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7030144320292906, 'Total loss': 0.7030144320292906} | train loss {'Reaction outcome loss': 0.7212249342231981, 'Total loss': 0.7212249342231981}
2022-11-22 20:46:49,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:49,330 INFO:     Epoch: 89
2022-11-22 20:46:50,073 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6705401837825775, 'Total loss': 0.6705401837825775} | train loss {'Reaction outcome loss': 0.7227982263411245, 'Total loss': 0.7227982263411245}
2022-11-22 20:46:50,073 INFO:     Found new best model at epoch 89
2022-11-22 20:46:50,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:50,074 INFO:     Epoch: 90
2022-11-22 20:46:50,804 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6834960877895355, 'Total loss': 0.6834960877895355} | train loss {'Reaction outcome loss': 0.7307455527686304, 'Total loss': 0.7307455527686304}
2022-11-22 20:46:50,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:50,804 INFO:     Epoch: 91
2022-11-22 20:46:51,582 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7300081754272635, 'Total loss': 0.7300081754272635} | train loss {'Reaction outcome loss': 0.714383872646478, 'Total loss': 0.714383872646478}
2022-11-22 20:46:51,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:51,582 INFO:     Epoch: 92
2022-11-22 20:46:52,364 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6846699023788626, 'Total loss': 0.6846699023788626} | train loss {'Reaction outcome loss': 0.7211404799093162, 'Total loss': 0.7211404799093162}
2022-11-22 20:46:52,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:52,364 INFO:     Epoch: 93
2022-11-22 20:46:53,193 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6841700835661455, 'Total loss': 0.6841700835661455} | train loss {'Reaction outcome loss': 0.7241670515748763, 'Total loss': 0.7241670515748763}
2022-11-22 20:46:53,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:53,193 INFO:     Epoch: 94
2022-11-22 20:46:53,993 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6814625601876866, 'Total loss': 0.6814625601876866} | train loss {'Reaction outcome loss': 0.7181884186162103, 'Total loss': 0.7181884186162103}
2022-11-22 20:46:53,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:53,994 INFO:     Epoch: 95
2022-11-22 20:46:54,767 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6866344999183308, 'Total loss': 0.6866344999183308} | train loss {'Reaction outcome loss': 0.7168018990947355, 'Total loss': 0.7168018990947355}
2022-11-22 20:46:54,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:54,767 INFO:     Epoch: 96
2022-11-22 20:46:55,496 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6883500286123969, 'Total loss': 0.6883500286123969} | train loss {'Reaction outcome loss': 0.725319947206205, 'Total loss': 0.725319947206205}
2022-11-22 20:46:55,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:55,496 INFO:     Epoch: 97
2022-11-22 20:46:56,286 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6785515221682462, 'Total loss': 0.6785515221682462} | train loss {'Reaction outcome loss': 0.7189553514603646, 'Total loss': 0.7189553514603646}
2022-11-22 20:46:56,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:56,286 INFO:     Epoch: 98
2022-11-22 20:46:57,047 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6754202029921792, 'Total loss': 0.6754202029921792} | train loss {'Reaction outcome loss': 0.7244812162412751, 'Total loss': 0.7244812162412751}
2022-11-22 20:46:57,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:57,048 INFO:     Epoch: 99
2022-11-22 20:46:57,894 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6688425093889236, 'Total loss': 0.6688425093889236} | train loss {'Reaction outcome loss': 0.7135303816007029, 'Total loss': 0.7135303816007029}
2022-11-22 20:46:57,894 INFO:     Found new best model at epoch 99
2022-11-22 20:46:57,895 INFO:     Best model found after epoch 100 of 100.
2022-11-22 20:46:57,895 INFO:   Done with stage: TRAINING
2022-11-22 20:46:57,895 INFO:   Starting stage: EVALUATION
2022-11-22 20:46:58,009 INFO:   Done with stage: EVALUATION
2022-11-22 20:46:58,009 INFO:   Leaving out SEQ value Fold_9
2022-11-22 20:46:58,023 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:46:58,023 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:46:58,715 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:46:58,715 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:46:58,786 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:46:58,786 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:46:58,786 INFO:     No hyperparam tuning for this model
2022-11-22 20:46:58,786 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:46:58,786 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:46:58,787 INFO:     None feature selector for col prot
2022-11-22 20:46:58,787 INFO:     None feature selector for col prot
2022-11-22 20:46:58,787 INFO:     None feature selector for col prot
2022-11-22 20:46:58,788 INFO:     None feature selector for col chem
2022-11-22 20:46:58,788 INFO:     None feature selector for col chem
2022-11-22 20:46:58,788 INFO:     None feature selector for col chem
2022-11-22 20:46:58,788 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:46:58,788 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:46:58,790 INFO:     Number of params in model 126091
2022-11-22 20:46:58,793 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:46:58,793 INFO:   Starting stage: TRAINING
2022-11-22 20:46:58,843 INFO:     Val loss before train {'Reaction outcome loss': 1.0529894828796387, 'Total loss': 1.0529894828796387}
2022-11-22 20:46:58,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:58,843 INFO:     Epoch: 0
2022-11-22 20:46:59,629 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8718796758489176, 'Total loss': 0.8718796758489176} | train loss {'Reaction outcome loss': 0.8741294216168555, 'Total loss': 0.8741294216168555}
2022-11-22 20:46:59,629 INFO:     Found new best model at epoch 0
2022-11-22 20:46:59,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:46:59,630 INFO:     Epoch: 1
2022-11-22 20:47:00,461 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8312586627223275, 'Total loss': 0.8312586627223275} | train loss {'Reaction outcome loss': 0.8489502341399792, 'Total loss': 0.8489502341399792}
2022-11-22 20:47:00,462 INFO:     Found new best model at epoch 1
2022-11-22 20:47:00,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:00,463 INFO:     Epoch: 2
2022-11-22 20:47:01,266 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8515167331153696, 'Total loss': 0.8515167331153696} | train loss {'Reaction outcome loss': 0.8320164152002527, 'Total loss': 0.8320164152002527}
2022-11-22 20:47:01,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:01,266 INFO:     Epoch: 3
2022-11-22 20:47:02,100 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8541373786601153, 'Total loss': 0.8541373786601153} | train loss {'Reaction outcome loss': 0.8357915361883187, 'Total loss': 0.8357915361883187}
2022-11-22 20:47:02,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:02,100 INFO:     Epoch: 4
2022-11-22 20:47:02,938 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8112507076425985, 'Total loss': 0.8112507076425985} | train loss {'Reaction outcome loss': 0.8306098156853726, 'Total loss': 0.8306098156853726}
2022-11-22 20:47:02,938 INFO:     Found new best model at epoch 4
2022-11-22 20:47:02,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:02,939 INFO:     Epoch: 5
2022-11-22 20:47:03,803 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8239373585039919, 'Total loss': 0.8239373585039919} | train loss {'Reaction outcome loss': 0.8178611260194045, 'Total loss': 0.8178611260194045}
2022-11-22 20:47:03,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:03,804 INFO:     Epoch: 6
2022-11-22 20:47:04,619 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8266492127017542, 'Total loss': 0.8266492127017542} | train loss {'Reaction outcome loss': 0.8156931891373778, 'Total loss': 0.8156931891373778}
2022-11-22 20:47:04,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:04,619 INFO:     Epoch: 7
2022-11-22 20:47:05,417 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8501772291281007, 'Total loss': 0.8501772291281007} | train loss {'Reaction outcome loss': 0.8182171011260646, 'Total loss': 0.8182171011260646}
2022-11-22 20:47:05,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:05,417 INFO:     Epoch: 8
2022-11-22 20:47:06,208 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8101764741269025, 'Total loss': 0.8101764741269025} | train loss {'Reaction outcome loss': 0.8160030411081276, 'Total loss': 0.8160030411081276}
2022-11-22 20:47:06,208 INFO:     Found new best model at epoch 8
2022-11-22 20:47:06,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:06,209 INFO:     Epoch: 9
2022-11-22 20:47:07,080 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8145939802581613, 'Total loss': 0.8145939802581613} | train loss {'Reaction outcome loss': 0.8153965867724013, 'Total loss': 0.8153965867724013}
2022-11-22 20:47:07,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:07,081 INFO:     Epoch: 10
2022-11-22 20:47:07,887 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7985486015677452, 'Total loss': 0.7985486015677452} | train loss {'Reaction outcome loss': 0.8101959162154179, 'Total loss': 0.8101959162154179}
2022-11-22 20:47:07,887 INFO:     Found new best model at epoch 10
2022-11-22 20:47:07,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:07,888 INFO:     Epoch: 11
2022-11-22 20:47:08,750 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8270511044697328, 'Total loss': 0.8270511044697328} | train loss {'Reaction outcome loss': 0.8063369399381553, 'Total loss': 0.8063369399381553}
2022-11-22 20:47:08,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:08,751 INFO:     Epoch: 12
2022-11-22 20:47:09,573 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8381140652027997, 'Total loss': 0.8381140652027997} | train loss {'Reaction outcome loss': 0.803524025508508, 'Total loss': 0.803524025508508}
2022-11-22 20:47:09,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:09,573 INFO:     Epoch: 13
2022-11-22 20:47:10,418 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8199327276511625, 'Total loss': 0.8199327276511625} | train loss {'Reaction outcome loss': 0.8045134938921523, 'Total loss': 0.8045134938921523}
2022-11-22 20:47:10,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:10,418 INFO:     Epoch: 14
2022-11-22 20:47:11,230 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8537290116602724, 'Total loss': 0.8537290116602724} | train loss {'Reaction outcome loss': 0.8127000925511967, 'Total loss': 0.8127000925511967}
2022-11-22 20:47:11,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:11,230 INFO:     Epoch: 15
2022-11-22 20:47:12,046 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7953440099954605, 'Total loss': 0.7953440099954605} | train loss {'Reaction outcome loss': 0.8199039071436353, 'Total loss': 0.8199039071436353}
2022-11-22 20:47:12,046 INFO:     Found new best model at epoch 15
2022-11-22 20:47:12,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:12,047 INFO:     Epoch: 16
2022-11-22 20:47:12,872 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8151124180717901, 'Total loss': 0.8151124180717901} | train loss {'Reaction outcome loss': 0.8046538496789662, 'Total loss': 0.8046538496789662}
2022-11-22 20:47:12,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:12,873 INFO:     Epoch: 17
2022-11-22 20:47:13,730 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8283025927164338, 'Total loss': 0.8283025927164338} | train loss {'Reaction outcome loss': 0.8043439967278768, 'Total loss': 0.8043439967278768}
2022-11-22 20:47:13,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:13,730 INFO:     Epoch: 18
2022-11-22 20:47:14,590 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8257381225174124, 'Total loss': 0.8257381225174124} | train loss {'Reaction outcome loss': 0.8030103402823089, 'Total loss': 0.8030103402823089}
2022-11-22 20:47:14,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:14,590 INFO:     Epoch: 19
2022-11-22 20:47:15,443 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.832330197095871, 'Total loss': 0.832330197095871} | train loss {'Reaction outcome loss': 0.802205920581393, 'Total loss': 0.802205920581393}
2022-11-22 20:47:15,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:15,443 INFO:     Epoch: 20
2022-11-22 20:47:16,230 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8125295015898618, 'Total loss': 0.8125295015898618} | train loss {'Reaction outcome loss': 0.8003667969452707, 'Total loss': 0.8003667969452707}
2022-11-22 20:47:16,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:16,230 INFO:     Epoch: 21
2022-11-22 20:47:17,062 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8067695213989778, 'Total loss': 0.8067695213989778} | train loss {'Reaction outcome loss': 0.7984119253119959, 'Total loss': 0.7984119253119959}
2022-11-22 20:47:17,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:17,063 INFO:     Epoch: 22
2022-11-22 20:47:17,881 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7867031253196977, 'Total loss': 0.7867031253196977} | train loss {'Reaction outcome loss': 0.7971641614369536, 'Total loss': 0.7971641614369536}
2022-11-22 20:47:17,881 INFO:     Found new best model at epoch 22
2022-11-22 20:47:17,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:17,882 INFO:     Epoch: 23
2022-11-22 20:47:18,730 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7915755063295364, 'Total loss': 0.7915755063295364} | train loss {'Reaction outcome loss': 0.8008154318762212, 'Total loss': 0.8008154318762212}
2022-11-22 20:47:18,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:18,730 INFO:     Epoch: 24
2022-11-22 20:47:19,603 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7948711514472961, 'Total loss': 0.7948711514472961} | train loss {'Reaction outcome loss': 0.8066857373907499, 'Total loss': 0.8066857373907499}
2022-11-22 20:47:19,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:19,604 INFO:     Epoch: 25
2022-11-22 20:47:20,431 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8043769415129315, 'Total loss': 0.8043769415129315} | train loss {'Reaction outcome loss': 0.7970861628470634, 'Total loss': 0.7970861628470634}
2022-11-22 20:47:20,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:20,431 INFO:     Epoch: 26
2022-11-22 20:47:21,266 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.79941802946004, 'Total loss': 0.79941802946004} | train loss {'Reaction outcome loss': 0.802199216627399, 'Total loss': 0.802199216627399}
2022-11-22 20:47:21,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:21,266 INFO:     Epoch: 27
2022-11-22 20:47:22,062 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7800946452400901, 'Total loss': 0.7800946452400901} | train loss {'Reaction outcome loss': 0.7999030280828114, 'Total loss': 0.7999030280828114}
2022-11-22 20:47:22,062 INFO:     Found new best model at epoch 27
2022-11-22 20:47:22,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:22,063 INFO:     Epoch: 28
2022-11-22 20:47:22,853 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8198815773833882, 'Total loss': 0.8198815773833882} | train loss {'Reaction outcome loss': 0.7963095964931766, 'Total loss': 0.7963095964931766}
2022-11-22 20:47:22,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:22,853 INFO:     Epoch: 29
2022-11-22 20:47:23,655 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.797179941426624, 'Total loss': 0.797179941426624} | train loss {'Reaction outcome loss': 0.8103248463709828, 'Total loss': 0.8103248463709828}
2022-11-22 20:47:23,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:23,655 INFO:     Epoch: 30
2022-11-22 20:47:24,435 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8080255179242655, 'Total loss': 0.8080255179242655} | train loss {'Reaction outcome loss': 0.8017434153238289, 'Total loss': 0.8017434153238289}
2022-11-22 20:47:24,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:24,435 INFO:     Epoch: 31
2022-11-22 20:47:25,219 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8020296449011023, 'Total loss': 0.8020296449011023} | train loss {'Reaction outcome loss': 0.802188383784854, 'Total loss': 0.802188383784854}
2022-11-22 20:47:25,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:25,220 INFO:     Epoch: 32
2022-11-22 20:47:26,039 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8200333159078251, 'Total loss': 0.8200333159078251} | train loss {'Reaction outcome loss': 0.8005285159296353, 'Total loss': 0.8005285159296353}
2022-11-22 20:47:26,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:26,039 INFO:     Epoch: 33
2022-11-22 20:47:26,871 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7913859981027517, 'Total loss': 0.7913859981027517} | train loss {'Reaction outcome loss': 0.7956094444099708, 'Total loss': 0.7956094444099708}
2022-11-22 20:47:26,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:26,871 INFO:     Epoch: 34
2022-11-22 20:47:27,676 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8084165406498042, 'Total loss': 0.8084165406498042} | train loss {'Reaction outcome loss': 0.7970251370719087, 'Total loss': 0.7970251370719087}
2022-11-22 20:47:27,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:27,676 INFO:     Epoch: 35
2022-11-22 20:47:28,482 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8103038580580191, 'Total loss': 0.8103038580580191} | train loss {'Reaction outcome loss': 0.8034967946620123, 'Total loss': 0.8034967946620123}
2022-11-22 20:47:28,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:28,483 INFO:     Epoch: 36
2022-11-22 20:47:29,269 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8360079100186174, 'Total loss': 0.8360079100186174} | train loss {'Reaction outcome loss': 0.7967334873220215, 'Total loss': 0.7967334873220215}
2022-11-22 20:47:29,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:29,269 INFO:     Epoch: 37
2022-11-22 20:47:30,093 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7797019752589139, 'Total loss': 0.7797019752589139} | train loss {'Reaction outcome loss': 0.8045944262612686, 'Total loss': 0.8045944262612686}
2022-11-22 20:47:30,093 INFO:     Found new best model at epoch 37
2022-11-22 20:47:30,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:30,094 INFO:     Epoch: 38
2022-11-22 20:47:30,903 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7848861678080126, 'Total loss': 0.7848861678080126} | train loss {'Reaction outcome loss': 0.7938043812991153, 'Total loss': 0.7938043812991153}
2022-11-22 20:47:30,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:30,903 INFO:     Epoch: 39
2022-11-22 20:47:31,721 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8102920854633505, 'Total loss': 0.8102920854633505} | train loss {'Reaction outcome loss': 0.7922166037987842, 'Total loss': 0.7922166037987842}
2022-11-22 20:47:31,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:31,722 INFO:     Epoch: 40
2022-11-22 20:47:32,562 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8083316649902951, 'Total loss': 0.8083316649902951} | train loss {'Reaction outcome loss': 0.7911941042313209, 'Total loss': 0.7911941042313209}
2022-11-22 20:47:32,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:32,564 INFO:     Epoch: 41
2022-11-22 20:47:33,367 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8028443733399565, 'Total loss': 0.8028443733399565} | train loss {'Reaction outcome loss': 0.7931860041039193, 'Total loss': 0.7931860041039193}
2022-11-22 20:47:33,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:33,368 INFO:     Epoch: 42
2022-11-22 20:47:34,169 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7925579900091345, 'Total loss': 0.7925579900091345} | train loss {'Reaction outcome loss': 0.8007098869514852, 'Total loss': 0.8007098869514852}
2022-11-22 20:47:34,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:34,169 INFO:     Epoch: 43
2022-11-22 20:47:34,955 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7974577850916169, 'Total loss': 0.7974577850916169} | train loss {'Reaction outcome loss': 0.7982470794969242, 'Total loss': 0.7982470794969242}
2022-11-22 20:47:34,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:34,956 INFO:     Epoch: 44
2022-11-22 20:47:35,798 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8075999983332374, 'Total loss': 0.8075999983332374} | train loss {'Reaction outcome loss': 0.7951171743242365, 'Total loss': 0.7951171743242365}
2022-11-22 20:47:35,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:35,798 INFO:     Epoch: 45
2022-11-22 20:47:36,613 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.796015164391561, 'Total loss': 0.796015164391561} | train loss {'Reaction outcome loss': 0.8005031687528016, 'Total loss': 0.8005031687528016}
2022-11-22 20:47:36,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:36,614 INFO:     Epoch: 46
2022-11-22 20:47:37,377 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7908074239438231, 'Total loss': 0.7908074239438231} | train loss {'Reaction outcome loss': 0.7951362207833572, 'Total loss': 0.7951362207833572}
2022-11-22 20:47:37,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:37,378 INFO:     Epoch: 47
2022-11-22 20:47:38,130 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7870351848277178, 'Total loss': 0.7870351848277178} | train loss {'Reaction outcome loss': 0.8010711105246293, 'Total loss': 0.8010711105246293}
2022-11-22 20:47:38,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:38,130 INFO:     Epoch: 48
2022-11-22 20:47:38,937 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7938366600058295, 'Total loss': 0.7938366600058295} | train loss {'Reaction outcome loss': 0.7969641971443346, 'Total loss': 0.7969641971443346}
2022-11-22 20:47:38,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:38,938 INFO:     Epoch: 49
2022-11-22 20:47:39,712 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7727371288294141, 'Total loss': 0.7727371288294141} | train loss {'Reaction outcome loss': 0.7941806537178364, 'Total loss': 0.7941806537178364}
2022-11-22 20:47:39,712 INFO:     Found new best model at epoch 49
2022-11-22 20:47:39,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:39,713 INFO:     Epoch: 50
2022-11-22 20:47:40,482 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8103318932381544, 'Total loss': 0.8103318932381544} | train loss {'Reaction outcome loss': 0.7892350503790234, 'Total loss': 0.7892350503790234}
2022-11-22 20:47:40,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:40,482 INFO:     Epoch: 51
2022-11-22 20:47:41,261 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8109268634156748, 'Total loss': 0.8109268634156748} | train loss {'Reaction outcome loss': 0.7914688959416107, 'Total loss': 0.7914688959416107}
2022-11-22 20:47:41,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:41,261 INFO:     Epoch: 52
2022-11-22 20:47:42,062 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7858383134007454, 'Total loss': 0.7858383134007454} | train loss {'Reaction outcome loss': 0.7971760870112099, 'Total loss': 0.7971760870112099}
2022-11-22 20:47:42,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:42,063 INFO:     Epoch: 53
2022-11-22 20:47:42,896 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7949567010456865, 'Total loss': 0.7949567010456865} | train loss {'Reaction outcome loss': 0.7997186950102508, 'Total loss': 0.7997186950102508}
2022-11-22 20:47:42,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:42,896 INFO:     Epoch: 54
2022-11-22 20:47:43,678 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.800634770908139, 'Total loss': 0.800634770908139} | train loss {'Reaction outcome loss': 0.7868161808382644, 'Total loss': 0.7868161808382644}
2022-11-22 20:47:43,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:43,678 INFO:     Epoch: 55
2022-11-22 20:47:44,501 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7893658686767925, 'Total loss': 0.7893658686767925} | train loss {'Reaction outcome loss': 0.7933398570850311, 'Total loss': 0.7933398570850311}
2022-11-22 20:47:44,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:44,501 INFO:     Epoch: 56
2022-11-22 20:47:45,256 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.799999938769774, 'Total loss': 0.799999938769774} | train loss {'Reaction outcome loss': 0.7976458704905954, 'Total loss': 0.7976458704905954}
2022-11-22 20:47:45,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:45,256 INFO:     Epoch: 57
2022-11-22 20:47:45,996 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.869726720858704, 'Total loss': 0.869726720858704} | train loss {'Reaction outcome loss': 0.796644141573293, 'Total loss': 0.796644141573293}
2022-11-22 20:47:45,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:45,996 INFO:     Epoch: 58
2022-11-22 20:47:46,791 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8073916143991731, 'Total loss': 0.8073916143991731} | train loss {'Reaction outcome loss': 0.7878975360258388, 'Total loss': 0.7878975360258388}
2022-11-22 20:47:46,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:46,791 INFO:     Epoch: 59
2022-11-22 20:47:47,618 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8079963394186713, 'Total loss': 0.8079963394186713} | train loss {'Reaction outcome loss': 0.7997577922788226, 'Total loss': 0.7997577922788226}
2022-11-22 20:47:47,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:47,618 INFO:     Epoch: 60
2022-11-22 20:47:48,435 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8212229948152195, 'Total loss': 0.8212229948152195} | train loss {'Reaction outcome loss': 0.8003732571717699, 'Total loss': 0.8003732571717699}
2022-11-22 20:47:48,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:48,435 INFO:     Epoch: 61
2022-11-22 20:47:49,188 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8146215941418301, 'Total loss': 0.8146215941418301} | train loss {'Reaction outcome loss': 0.7942164815389193, 'Total loss': 0.7942164815389193}
2022-11-22 20:47:49,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:49,188 INFO:     Epoch: 62
2022-11-22 20:47:49,952 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7936443537473679, 'Total loss': 0.7936443537473679} | train loss {'Reaction outcome loss': 0.7941208975276484, 'Total loss': 0.7941208975276484}
2022-11-22 20:47:49,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:49,952 INFO:     Epoch: 63
2022-11-22 20:47:50,723 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.796685978770256, 'Total loss': 0.796685978770256} | train loss {'Reaction outcome loss': 0.7945379146680176, 'Total loss': 0.7945379146680176}
2022-11-22 20:47:50,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:50,723 INFO:     Epoch: 64
2022-11-22 20:47:51,526 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.78950454226949, 'Total loss': 0.78950454226949} | train loss {'Reaction outcome loss': 0.7938970380466477, 'Total loss': 0.7938970380466477}
2022-11-22 20:47:51,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:51,527 INFO:     Epoch: 65
2022-11-22 20:47:52,355 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8080670522017912, 'Total loss': 0.8080670522017912} | train loss {'Reaction outcome loss': 0.7877200056425473, 'Total loss': 0.7877200056425473}
2022-11-22 20:47:52,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:52,355 INFO:     Epoch: 66
2022-11-22 20:47:53,142 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7814708968455141, 'Total loss': 0.7814708968455141} | train loss {'Reaction outcome loss': 0.7891145207379994, 'Total loss': 0.7891145207379994}
2022-11-22 20:47:53,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:53,142 INFO:     Epoch: 67
2022-11-22 20:47:53,969 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7899830273606561, 'Total loss': 0.7899830273606561} | train loss {'Reaction outcome loss': 0.7859502699271388, 'Total loss': 0.7859502699271388}
2022-11-22 20:47:53,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:53,969 INFO:     Epoch: 68
2022-11-22 20:47:54,752 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8073138418522748, 'Total loss': 0.8073138418522748} | train loss {'Reaction outcome loss': 0.797022779702175, 'Total loss': 0.797022779702175}
2022-11-22 20:47:54,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:54,753 INFO:     Epoch: 69
2022-11-22 20:47:55,534 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7967093078927561, 'Total loss': 0.7967093078927561} | train loss {'Reaction outcome loss': 0.7921484682543075, 'Total loss': 0.7921484682543075}
2022-11-22 20:47:55,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:55,534 INFO:     Epoch: 70
2022-11-22 20:47:56,311 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8033995154229078, 'Total loss': 0.8033995154229078} | train loss {'Reaction outcome loss': 0.7867719601643713, 'Total loss': 0.7867719601643713}
2022-11-22 20:47:56,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:56,311 INFO:     Epoch: 71
2022-11-22 20:47:57,100 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7858670855110342, 'Total loss': 0.7858670855110342} | train loss {'Reaction outcome loss': 0.7860165657664118, 'Total loss': 0.7860165657664118}
2022-11-22 20:47:57,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:57,101 INFO:     Epoch: 72
2022-11-22 20:47:57,863 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8248866708441214, 'Total loss': 0.8248866708441214} | train loss {'Reaction outcome loss': 0.7971597850805352, 'Total loss': 0.7971597850805352}
2022-11-22 20:47:57,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:57,863 INFO:     Epoch: 73
2022-11-22 20:47:58,698 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7796549620953473, 'Total loss': 0.7796549620953473} | train loss {'Reaction outcome loss': 0.7980030686990452, 'Total loss': 0.7980030686990452}
2022-11-22 20:47:58,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:58,699 INFO:     Epoch: 74
2022-11-22 20:47:59,481 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8538549041206186, 'Total loss': 0.8538549041206186} | train loss {'Reaction outcome loss': 0.7915044806988133, 'Total loss': 0.7915044806988133}
2022-11-22 20:47:59,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:47:59,481 INFO:     Epoch: 75
2022-11-22 20:48:00,279 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7806768139654939, 'Total loss': 0.7806768139654939} | train loss {'Reaction outcome loss': 0.7996359302206077, 'Total loss': 0.7996359302206077}
2022-11-22 20:48:00,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:00,279 INFO:     Epoch: 76
2022-11-22 20:48:01,053 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7859424115581946, 'Total loss': 0.7859424115581946} | train loss {'Reaction outcome loss': 0.793886470529232, 'Total loss': 0.793886470529232}
2022-11-22 20:48:01,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:01,053 INFO:     Epoch: 77
2022-11-22 20:48:01,812 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7907618169080127, 'Total loss': 0.7907618169080127} | train loss {'Reaction outcome loss': 0.8008228846889759, 'Total loss': 0.8008228846889759}
2022-11-22 20:48:01,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:01,812 INFO:     Epoch: 78
2022-11-22 20:48:02,580 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7984975291924044, 'Total loss': 0.7984975291924044} | train loss {'Reaction outcome loss': 0.7917650286485309, 'Total loss': 0.7917650286485309}
2022-11-22 20:48:02,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:02,580 INFO:     Epoch: 79
2022-11-22 20:48:03,403 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8000627593560652, 'Total loss': 0.8000627593560652} | train loss {'Reaction outcome loss': 0.7891603920020556, 'Total loss': 0.7891603920020556}
2022-11-22 20:48:03,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:03,404 INFO:     Epoch: 80
2022-11-22 20:48:04,175 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8003983287648722, 'Total loss': 0.8003983287648722} | train loss {'Reaction outcome loss': 0.7891146421191181, 'Total loss': 0.7891146421191181}
2022-11-22 20:48:04,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:04,176 INFO:     Epoch: 81
2022-11-22 20:48:04,978 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7906978936357931, 'Total loss': 0.7906978936357931} | train loss {'Reaction outcome loss': 0.7958068479651864, 'Total loss': 0.7958068479651864}
2022-11-22 20:48:04,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:04,978 INFO:     Epoch: 82
2022-11-22 20:48:05,743 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8008601414886388, 'Total loss': 0.8008601414886388} | train loss {'Reaction outcome loss': 0.788156796442835, 'Total loss': 0.788156796442835}
2022-11-22 20:48:05,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:05,743 INFO:     Epoch: 83
2022-11-22 20:48:06,541 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8042258979244665, 'Total loss': 0.8042258979244665} | train loss {'Reaction outcome loss': 0.7962206651566, 'Total loss': 0.7962206651566}
2022-11-22 20:48:06,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:06,541 INFO:     Epoch: 84
2022-11-22 20:48:07,302 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7942130951718851, 'Total loss': 0.7942130951718851} | train loss {'Reaction outcome loss': 0.8010484100836008, 'Total loss': 0.8010484100836008}
2022-11-22 20:48:07,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:07,302 INFO:     Epoch: 85
2022-11-22 20:48:08,018 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7873706079342149, 'Total loss': 0.7873706079342149} | train loss {'Reaction outcome loss': 0.7988974543718191, 'Total loss': 0.7988974543718191}
2022-11-22 20:48:08,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:08,018 INFO:     Epoch: 86
2022-11-22 20:48:08,800 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8377993743528019, 'Total loss': 0.8377993743528019} | train loss {'Reaction outcome loss': 0.7911561717871229, 'Total loss': 0.7911561717871229}
2022-11-22 20:48:08,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:08,801 INFO:     Epoch: 87
2022-11-22 20:48:09,603 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8079508583654057, 'Total loss': 0.8079508583654057} | train loss {'Reaction outcome loss': 0.7882324228523231, 'Total loss': 0.7882324228523231}
2022-11-22 20:48:09,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:09,604 INFO:     Epoch: 88
2022-11-22 20:48:10,374 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8004154210740869, 'Total loss': 0.8004154210740869} | train loss {'Reaction outcome loss': 0.7934393645056829, 'Total loss': 0.7934393645056829}
2022-11-22 20:48:10,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:10,374 INFO:     Epoch: 89
2022-11-22 20:48:11,129 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8135727454315532, 'Total loss': 0.8135727454315532} | train loss {'Reaction outcome loss': 0.8067313430280338, 'Total loss': 0.8067313430280338}
2022-11-22 20:48:11,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:11,129 INFO:     Epoch: 90
2022-11-22 20:48:11,932 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8175108622420918, 'Total loss': 0.8175108622420918} | train loss {'Reaction outcome loss': 0.7955389099142812, 'Total loss': 0.7955389099142812}
2022-11-22 20:48:11,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:11,932 INFO:     Epoch: 91
2022-11-22 20:48:12,722 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8142217749899084, 'Total loss': 0.8142217749899084} | train loss {'Reaction outcome loss': 0.7864679131008353, 'Total loss': 0.7864679131008353}
2022-11-22 20:48:12,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:12,722 INFO:     Epoch: 92
2022-11-22 20:48:13,466 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7979612032120879, 'Total loss': 0.7979612032120879} | train loss {'Reaction outcome loss': 0.7891856626822398, 'Total loss': 0.7891856626822398}
2022-11-22 20:48:13,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:13,466 INFO:     Epoch: 93
2022-11-22 20:48:14,256 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8227260085669431, 'Total loss': 0.8227260085669431} | train loss {'Reaction outcome loss': 0.791988360857674, 'Total loss': 0.791988360857674}
2022-11-22 20:48:14,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:14,257 INFO:     Epoch: 94
2022-11-22 20:48:15,073 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.787332876839421, 'Total loss': 0.787332876839421} | train loss {'Reaction outcome loss': 0.7975062203069447, 'Total loss': 0.7975062203069447}
2022-11-22 20:48:15,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:15,073 INFO:     Epoch: 95
2022-11-22 20:48:15,808 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7760326557538726, 'Total loss': 0.7760326557538726} | train loss {'Reaction outcome loss': 0.7874580146330088, 'Total loss': 0.7874580146330088}
2022-11-22 20:48:15,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:15,808 INFO:     Epoch: 96
2022-11-22 20:48:16,570 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7815878970379179, 'Total loss': 0.7815878970379179} | train loss {'Reaction outcome loss': 0.7925699157753454, 'Total loss': 0.7925699157753454}
2022-11-22 20:48:16,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:16,570 INFO:     Epoch: 97
2022-11-22 20:48:17,305 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7937100712548603, 'Total loss': 0.7937100712548603} | train loss {'Reaction outcome loss': 0.7924813408600656, 'Total loss': 0.7924813408600656}
2022-11-22 20:48:17,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:17,305 INFO:     Epoch: 98
2022-11-22 20:48:18,062 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7943117225711996, 'Total loss': 0.7943117225711996} | train loss {'Reaction outcome loss': 0.7973994418435734, 'Total loss': 0.7973994418435734}
2022-11-22 20:48:18,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:18,062 INFO:     Epoch: 99
2022-11-22 20:48:18,829 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8149812993678179, 'Total loss': 0.8149812993678179} | train loss {'Reaction outcome loss': 0.7941920477369053, 'Total loss': 0.7941920477369053}
2022-11-22 20:48:18,829 INFO:     Best model found after epoch 50 of 100.
2022-11-22 20:48:18,830 INFO:   Done with stage: TRAINING
2022-11-22 20:48:18,830 INFO:   Starting stage: EVALUATION
2022-11-22 20:48:18,948 INFO:   Done with stage: EVALUATION
2022-11-22 20:48:18,957 INFO:   Leaving out SEQ value Fold_0
2022-11-22 20:48:18,971 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:48:18,971 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:48:19,637 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:48:19,638 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:48:19,706 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:48:19,706 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:48:19,706 INFO:     No hyperparam tuning for this model
2022-11-22 20:48:19,706 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:48:19,706 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:48:19,707 INFO:     None feature selector for col prot
2022-11-22 20:48:19,707 INFO:     None feature selector for col prot
2022-11-22 20:48:19,707 INFO:     None feature selector for col prot
2022-11-22 20:48:19,708 INFO:     None feature selector for col chem
2022-11-22 20:48:19,708 INFO:     None feature selector for col chem
2022-11-22 20:48:19,708 INFO:     None feature selector for col chem
2022-11-22 20:48:19,708 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:48:19,708 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:48:19,710 INFO:     Number of params in model 126091
2022-11-22 20:48:19,713 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:48:19,713 INFO:   Starting stage: TRAINING
2022-11-22 20:48:19,762 INFO:     Val loss before train {'Reaction outcome loss': 1.073325980793346, 'Total loss': 1.073325980793346}
2022-11-22 20:48:19,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:19,763 INFO:     Epoch: 0
2022-11-22 20:48:20,495 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9079832258549604, 'Total loss': 0.9079832258549604} | train loss {'Reaction outcome loss': 0.8567713618278503, 'Total loss': 0.8567713618278503}
2022-11-22 20:48:20,495 INFO:     Found new best model at epoch 0
2022-11-22 20:48:20,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:20,496 INFO:     Epoch: 1
2022-11-22 20:48:21,227 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8908551301468502, 'Total loss': 0.8908551301468502} | train loss {'Reaction outcome loss': 0.8231283963943015, 'Total loss': 0.8231283963943015}
2022-11-22 20:48:21,227 INFO:     Found new best model at epoch 1
2022-11-22 20:48:21,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:21,228 INFO:     Epoch: 2
2022-11-22 20:48:22,005 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8652112565257333, 'Total loss': 0.8652112565257333} | train loss {'Reaction outcome loss': 0.8152546312127794, 'Total loss': 0.8152546312127794}
2022-11-22 20:48:22,006 INFO:     Found new best model at epoch 2
2022-11-22 20:48:22,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:22,007 INFO:     Epoch: 3
2022-11-22 20:48:22,755 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8843447105451063, 'Total loss': 0.8843447105451063} | train loss {'Reaction outcome loss': 0.8112130463123322, 'Total loss': 0.8112130463123322}
2022-11-22 20:48:22,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:22,755 INFO:     Epoch: 4
2022-11-22 20:48:23,501 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.896220322359692, 'Total loss': 0.896220322359692} | train loss {'Reaction outcome loss': 0.8031777552195958, 'Total loss': 0.8031777552195958}
2022-11-22 20:48:23,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:23,502 INFO:     Epoch: 5
2022-11-22 20:48:24,235 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8542346168648113, 'Total loss': 0.8542346168648113} | train loss {'Reaction outcome loss': 0.8003240685073697, 'Total loss': 0.8003240685073697}
2022-11-22 20:48:24,236 INFO:     Found new best model at epoch 5
2022-11-22 20:48:24,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:24,236 INFO:     Epoch: 6
2022-11-22 20:48:24,962 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8536980721083555, 'Total loss': 0.8536980721083555} | train loss {'Reaction outcome loss': 0.7997550260047523, 'Total loss': 0.7997550260047523}
2022-11-22 20:48:24,962 INFO:     Found new best model at epoch 6
2022-11-22 20:48:24,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:24,963 INFO:     Epoch: 7
2022-11-22 20:48:25,716 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8643140088428151, 'Total loss': 0.8643140088428151} | train loss {'Reaction outcome loss': 0.7948262984655341, 'Total loss': 0.7948262984655341}
2022-11-22 20:48:25,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:25,716 INFO:     Epoch: 8
2022-11-22 20:48:26,456 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8746738040989096, 'Total loss': 0.8746738040989096} | train loss {'Reaction outcome loss': 0.7894177710523411, 'Total loss': 0.7894177710523411}
2022-11-22 20:48:26,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:26,457 INFO:     Epoch: 9
2022-11-22 20:48:27,218 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8655664988539435, 'Total loss': 0.8655664988539435} | train loss {'Reaction outcome loss': 0.7962169855224843, 'Total loss': 0.7962169855224843}
2022-11-22 20:48:27,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:27,218 INFO:     Epoch: 10
2022-11-22 20:48:27,947 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8603043989701704, 'Total loss': 0.8603043989701704} | train loss {'Reaction outcome loss': 0.7896761309127418, 'Total loss': 0.7896761309127418}
2022-11-22 20:48:27,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:27,947 INFO:     Epoch: 11
2022-11-22 20:48:28,677 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8640928322618658, 'Total loss': 0.8640928322618658} | train loss {'Reaction outcome loss': 0.7909856342539495, 'Total loss': 0.7909856342539495}
2022-11-22 20:48:28,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:28,677 INFO:     Epoch: 12
2022-11-22 20:48:29,398 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8582257770679214, 'Total loss': 0.8582257770679214} | train loss {'Reaction outcome loss': 0.7900553978219325, 'Total loss': 0.7900553978219325}
2022-11-22 20:48:29,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:29,398 INFO:     Epoch: 13
2022-11-22 20:48:30,124 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8657653128558939, 'Total loss': 0.8657653128558939} | train loss {'Reaction outcome loss': 0.7895222832961958, 'Total loss': 0.7895222832961958}
2022-11-22 20:48:30,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:30,124 INFO:     Epoch: 14
2022-11-22 20:48:30,863 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8323561853983186, 'Total loss': 0.8323561853983186} | train loss {'Reaction outcome loss': 0.7879884280720536, 'Total loss': 0.7879884280720536}
2022-11-22 20:48:30,863 INFO:     Found new best model at epoch 14
2022-11-22 20:48:30,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:30,864 INFO:     Epoch: 15
2022-11-22 20:48:31,649 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8489517522129145, 'Total loss': 0.8489517522129145} | train loss {'Reaction outcome loss': 0.7836374825360823, 'Total loss': 0.7836374825360823}
2022-11-22 20:48:31,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:31,649 INFO:     Epoch: 16
2022-11-22 20:48:32,351 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8215917545286092, 'Total loss': 0.8215917545286092} | train loss {'Reaction outcome loss': 0.7864756962474512, 'Total loss': 0.7864756962474512}
2022-11-22 20:48:32,351 INFO:     Found new best model at epoch 16
2022-11-22 20:48:32,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:32,352 INFO:     Epoch: 17
2022-11-22 20:48:33,109 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8696762424978343, 'Total loss': 0.8696762424978343} | train loss {'Reaction outcome loss': 0.7864034071260569, 'Total loss': 0.7864034071260569}
2022-11-22 20:48:33,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:33,109 INFO:     Epoch: 18
2022-11-22 20:48:33,821 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8433220498263836, 'Total loss': 0.8433220498263836} | train loss {'Reaction outcome loss': 0.7850660396473749, 'Total loss': 0.7850660396473749}
2022-11-22 20:48:33,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:33,822 INFO:     Epoch: 19
2022-11-22 20:48:34,536 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.869159646332264, 'Total loss': 0.869159646332264} | train loss {'Reaction outcome loss': 0.7870958078880699, 'Total loss': 0.7870958078880699}
2022-11-22 20:48:34,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:34,538 INFO:     Epoch: 20
2022-11-22 20:48:35,260 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8984436934644525, 'Total loss': 0.8984436934644525} | train loss {'Reaction outcome loss': 0.7830820711291566, 'Total loss': 0.7830820711291566}
2022-11-22 20:48:35,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:35,260 INFO:     Epoch: 21
2022-11-22 20:48:36,039 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8416705815629526, 'Total loss': 0.8416705815629526} | train loss {'Reaction outcome loss': 0.7828128348807899, 'Total loss': 0.7828128348807899}
2022-11-22 20:48:36,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:36,040 INFO:     Epoch: 22
2022-11-22 20:48:36,778 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8491739888082851, 'Total loss': 0.8491739888082851} | train loss {'Reaction outcome loss': 0.7861590148234854, 'Total loss': 0.7861590148234854}
2022-11-22 20:48:36,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:36,778 INFO:     Epoch: 23
2022-11-22 20:48:37,533 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8483055687763474, 'Total loss': 0.8483055687763474} | train loss {'Reaction outcome loss': 0.7809270149591018, 'Total loss': 0.7809270149591018}
2022-11-22 20:48:37,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:37,533 INFO:     Epoch: 24
2022-11-22 20:48:38,299 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8756811374967749, 'Total loss': 0.8756811374967749} | train loss {'Reaction outcome loss': 0.7751239609961607, 'Total loss': 0.7751239609961607}
2022-11-22 20:48:38,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:38,299 INFO:     Epoch: 25
2022-11-22 20:48:39,043 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8591057116335089, 'Total loss': 0.8591057116335089} | train loss {'Reaction outcome loss': 0.7859216356764034, 'Total loss': 0.7859216356764034}
2022-11-22 20:48:39,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:39,044 INFO:     Epoch: 26
2022-11-22 20:48:39,783 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8788511455059052, 'Total loss': 0.8788511455059052} | train loss {'Reaction outcome loss': 0.7868987392406075, 'Total loss': 0.7868987392406075}
2022-11-22 20:48:39,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:39,783 INFO:     Epoch: 27
2022-11-22 20:48:40,548 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8417251448739659, 'Total loss': 0.8417251448739659} | train loss {'Reaction outcome loss': 0.7836177356389105, 'Total loss': 0.7836177356389105}
2022-11-22 20:48:40,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:40,549 INFO:     Epoch: 28
2022-11-22 20:48:41,308 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8592814403501424, 'Total loss': 0.8592814403501424} | train loss {'Reaction outcome loss': 0.7778337292525233, 'Total loss': 0.7778337292525233}
2022-11-22 20:48:41,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:41,308 INFO:     Epoch: 29
2022-11-22 20:48:42,095 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8815758309581063, 'Total loss': 0.8815758309581063} | train loss {'Reaction outcome loss': 0.7797243961266109, 'Total loss': 0.7797243961266109}
2022-11-22 20:48:42,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:42,095 INFO:     Epoch: 30
2022-11-22 20:48:42,819 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8896734633228995, 'Total loss': 0.8896734633228995} | train loss {'Reaction outcome loss': 0.7800977407669535, 'Total loss': 0.7800977407669535}
2022-11-22 20:48:42,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:42,820 INFO:     Epoch: 31
2022-11-22 20:48:43,570 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8553645211187276, 'Total loss': 0.8553645211187276} | train loss {'Reaction outcome loss': 0.7835451463047339, 'Total loss': 0.7835451463047339}
2022-11-22 20:48:43,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:43,570 INFO:     Epoch: 32
2022-11-22 20:48:44,299 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8593172905119982, 'Total loss': 0.8593172905119982} | train loss {'Reaction outcome loss': 0.7821581794291127, 'Total loss': 0.7821581794291127}
2022-11-22 20:48:44,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:44,299 INFO:     Epoch: 33
2022-11-22 20:48:45,072 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8418128869750283, 'Total loss': 0.8418128869750283} | train loss {'Reaction outcome loss': 0.7802979358604976, 'Total loss': 0.7802979358604976}
2022-11-22 20:48:45,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:45,073 INFO:     Epoch: 34
2022-11-22 20:48:45,836 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8295930800112811, 'Total loss': 0.8295930800112811} | train loss {'Reaction outcome loss': 0.7745451850550515, 'Total loss': 0.7745451850550515}
2022-11-22 20:48:45,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:45,836 INFO:     Epoch: 35
2022-11-22 20:48:46,635 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8617461560802027, 'Total loss': 0.8617461560802027} | train loss {'Reaction outcome loss': 0.7806899276314949, 'Total loss': 0.7806899276314949}
2022-11-22 20:48:46,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:46,635 INFO:     Epoch: 36
2022-11-22 20:48:47,403 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8592574501579459, 'Total loss': 0.8592574501579459} | train loss {'Reaction outcome loss': 0.7782857715475316, 'Total loss': 0.7782857715475316}
2022-11-22 20:48:47,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:47,403 INFO:     Epoch: 37
2022-11-22 20:48:48,215 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8662715960632671, 'Total loss': 0.8662715960632671} | train loss {'Reaction outcome loss': 0.7758484393966442, 'Total loss': 0.7758484393966442}
2022-11-22 20:48:48,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:48,215 INFO:     Epoch: 38
2022-11-22 20:48:48,940 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8878020305525173, 'Total loss': 0.8878020305525173} | train loss {'Reaction outcome loss': 0.7736249163442729, 'Total loss': 0.7736249163442729}
2022-11-22 20:48:48,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:48,940 INFO:     Epoch: 39
2022-11-22 20:48:49,710 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8637735024094582, 'Total loss': 0.8637735024094582} | train loss {'Reaction outcome loss': 0.7789067919156989, 'Total loss': 0.7789067919156989}
2022-11-22 20:48:49,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:49,710 INFO:     Epoch: 40
2022-11-22 20:48:50,399 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8523249036886476, 'Total loss': 0.8523249036886476} | train loss {'Reaction outcome loss': 0.7781050879128125, 'Total loss': 0.7781050879128125}
2022-11-22 20:48:50,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:50,399 INFO:     Epoch: 41
2022-11-22 20:48:51,168 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8338571610775861, 'Total loss': 0.8338571610775861} | train loss {'Reaction outcome loss': 0.7738511192555331, 'Total loss': 0.7738511192555331}
2022-11-22 20:48:51,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:51,168 INFO:     Epoch: 42
2022-11-22 20:48:51,926 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8574800863862038, 'Total loss': 0.8574800863862038} | train loss {'Reaction outcome loss': 0.7789672896570089, 'Total loss': 0.7789672896570089}
2022-11-22 20:48:51,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:51,926 INFO:     Epoch: 43
2022-11-22 20:48:52,668 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8809708153659647, 'Total loss': 0.8809708153659647} | train loss {'Reaction outcome loss': 0.771800144716185, 'Total loss': 0.771800144716185}
2022-11-22 20:48:52,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:52,669 INFO:     Epoch: 44
2022-11-22 20:48:53,443 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8610643595457077, 'Total loss': 0.8610643595457077} | train loss {'Reaction outcome loss': 0.7781480964349241, 'Total loss': 0.7781480964349241}
2022-11-22 20:48:53,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:53,443 INFO:     Epoch: 45
2022-11-22 20:48:54,201 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8363760757175359, 'Total loss': 0.8363760757175359} | train loss {'Reaction outcome loss': 0.7760851529179787, 'Total loss': 0.7760851529179787}
2022-11-22 20:48:54,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:54,201 INFO:     Epoch: 46
2022-11-22 20:48:54,958 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8189099201593887, 'Total loss': 0.8189099201593887} | train loss {'Reaction outcome loss': 0.7730842462607792, 'Total loss': 0.7730842462607792}
2022-11-22 20:48:54,958 INFO:     Found new best model at epoch 46
2022-11-22 20:48:54,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:54,959 INFO:     Epoch: 47
2022-11-22 20:48:55,726 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8459653434428301, 'Total loss': 0.8459653434428301} | train loss {'Reaction outcome loss': 0.7802249684625743, 'Total loss': 0.7802249684625743}
2022-11-22 20:48:55,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:55,726 INFO:     Epoch: 48
2022-11-22 20:48:56,485 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8330768245187673, 'Total loss': 0.8330768245187673} | train loss {'Reaction outcome loss': 0.7741771559326016, 'Total loss': 0.7741771559326016}
2022-11-22 20:48:56,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:56,485 INFO:     Epoch: 49
2022-11-22 20:48:57,255 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8667388030073859, 'Total loss': 0.8667388030073859} | train loss {'Reaction outcome loss': 0.7747594744575267, 'Total loss': 0.7747594744575267}
2022-11-22 20:48:57,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:57,256 INFO:     Epoch: 50
2022-11-22 20:48:57,990 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8328793658451601, 'Total loss': 0.8328793658451601} | train loss {'Reaction outcome loss': 0.7779202876042347, 'Total loss': 0.7779202876042347}
2022-11-22 20:48:57,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:57,990 INFO:     Epoch: 51
2022-11-22 20:48:58,732 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8548545850948854, 'Total loss': 0.8548545850948854} | train loss {'Reaction outcome loss': 0.7711905249527522, 'Total loss': 0.7711905249527522}
2022-11-22 20:48:58,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:58,733 INFO:     Epoch: 52
2022-11-22 20:48:59,533 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8303679207509215, 'Total loss': 0.8303679207509215} | train loss {'Reaction outcome loss': 0.7757988636590997, 'Total loss': 0.7757988636590997}
2022-11-22 20:48:59,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:48:59,534 INFO:     Epoch: 53
2022-11-22 20:49:00,328 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8562397137284279, 'Total loss': 0.8562397137284279} | train loss {'Reaction outcome loss': 0.7683001203196389, 'Total loss': 0.7683001203196389}
2022-11-22 20:49:00,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:00,328 INFO:     Epoch: 54
2022-11-22 20:49:01,062 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8478243025866422, 'Total loss': 0.8478243025866422} | train loss {'Reaction outcome loss': 0.7699566468900564, 'Total loss': 0.7699566468900564}
2022-11-22 20:49:01,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:01,062 INFO:     Epoch: 55
2022-11-22 20:49:01,822 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8422799977389249, 'Total loss': 0.8422799977389249} | train loss {'Reaction outcome loss': 0.7724380809433606, 'Total loss': 0.7724380809433606}
2022-11-22 20:49:01,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:01,822 INFO:     Epoch: 56
2022-11-22 20:49:02,533 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8275517306544564, 'Total loss': 0.8275517306544564} | train loss {'Reaction outcome loss': 0.7747802438784619, 'Total loss': 0.7747802438784619}
2022-11-22 20:49:02,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:02,533 INFO:     Epoch: 57
2022-11-22 20:49:03,292 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8351518335667524, 'Total loss': 0.8351518335667524} | train loss {'Reaction outcome loss': 0.7726042219570705, 'Total loss': 0.7726042219570705}
2022-11-22 20:49:03,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:03,292 INFO:     Epoch: 58
2022-11-22 20:49:04,025 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8539408553730358, 'Total loss': 0.8539408553730358} | train loss {'Reaction outcome loss': 0.7675079821323861, 'Total loss': 0.7675079821323861}
2022-11-22 20:49:04,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:04,025 INFO:     Epoch: 59
2022-11-22 20:49:04,763 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8227016085928137, 'Total loss': 0.8227016085928137} | train loss {'Reaction outcome loss': 0.7735190148256263, 'Total loss': 0.7735190148256263}
2022-11-22 20:49:04,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:04,764 INFO:     Epoch: 60
2022-11-22 20:49:05,478 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8226209885694764, 'Total loss': 0.8226209885694764} | train loss {'Reaction outcome loss': 0.7730339485771802, 'Total loss': 0.7730339485771802}
2022-11-22 20:49:05,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:05,479 INFO:     Epoch: 61
2022-11-22 20:49:06,192 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8354801786216822, 'Total loss': 0.8354801786216822} | train loss {'Reaction outcome loss': 0.7699931430573366, 'Total loss': 0.7699931430573366}
2022-11-22 20:49:06,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:06,192 INFO:     Epoch: 62
2022-11-22 20:49:06,918 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8467982695861296, 'Total loss': 0.8467982695861296} | train loss {'Reaction outcome loss': 0.768892218507066, 'Total loss': 0.768892218507066}
2022-11-22 20:49:06,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:06,918 INFO:     Epoch: 63
2022-11-22 20:49:07,671 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.837998470122164, 'Total loss': 0.837998470122164} | train loss {'Reaction outcome loss': 0.7687412025977154, 'Total loss': 0.7687412025977154}
2022-11-22 20:49:07,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:07,671 INFO:     Epoch: 64
2022-11-22 20:49:08,421 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8292115418748423, 'Total loss': 0.8292115418748423} | train loss {'Reaction outcome loss': 0.7728661385117744, 'Total loss': 0.7728661385117744}
2022-11-22 20:49:08,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:08,422 INFO:     Epoch: 65
2022-11-22 20:49:09,141 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8621482009237463, 'Total loss': 0.8621482009237463} | train loss {'Reaction outcome loss': 0.770911646619135, 'Total loss': 0.770911646619135}
2022-11-22 20:49:09,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:09,141 INFO:     Epoch: 66
2022-11-22 20:49:09,887 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8708401762626388, 'Total loss': 0.8708401762626388} | train loss {'Reaction outcome loss': 0.7677318555359938, 'Total loss': 0.7677318555359938}
2022-11-22 20:49:09,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:09,887 INFO:     Epoch: 67
2022-11-22 20:49:10,598 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8288126770745624, 'Total loss': 0.8288126770745624} | train loss {'Reaction outcome loss': 0.7668042545415917, 'Total loss': 0.7668042545415917}
2022-11-22 20:49:10,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:10,598 INFO:     Epoch: 68
2022-11-22 20:49:11,285 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.816333757205443, 'Total loss': 0.816333757205443} | train loss {'Reaction outcome loss': 0.7689645287941913, 'Total loss': 0.7689645287941913}
2022-11-22 20:49:11,285 INFO:     Found new best model at epoch 68
2022-11-22 20:49:11,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:11,286 INFO:     Epoch: 69
2022-11-22 20:49:12,002 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8402996574613181, 'Total loss': 0.8402996574613181} | train loss {'Reaction outcome loss': 0.7680936736719949, 'Total loss': 0.7680936736719949}
2022-11-22 20:49:12,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:12,003 INFO:     Epoch: 70
2022-11-22 20:49:12,783 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8490275219082832, 'Total loss': 0.8490275219082832} | train loss {'Reaction outcome loss': 0.7656188406506363, 'Total loss': 0.7656188406506363}
2022-11-22 20:49:12,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:12,783 INFO:     Epoch: 71
2022-11-22 20:49:13,520 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8251408982005987, 'Total loss': 0.8251408982005987} | train loss {'Reaction outcome loss': 0.7660338535600779, 'Total loss': 0.7660338535600779}
2022-11-22 20:49:13,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:13,520 INFO:     Epoch: 72
2022-11-22 20:49:14,265 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8317657444964756, 'Total loss': 0.8317657444964756} | train loss {'Reaction outcome loss': 0.7703648518542854, 'Total loss': 0.7703648518542854}
2022-11-22 20:49:14,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:14,265 INFO:     Epoch: 73
2022-11-22 20:49:15,021 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.835901222445748, 'Total loss': 0.835901222445748} | train loss {'Reaction outcome loss': 0.7681208100854134, 'Total loss': 0.7681208100854134}
2022-11-22 20:49:15,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:15,021 INFO:     Epoch: 74
2022-11-22 20:49:15,748 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8121068917892196, 'Total loss': 0.8121068917892196} | train loss {'Reaction outcome loss': 0.7672707534566218, 'Total loss': 0.7672707534566218}
2022-11-22 20:49:15,748 INFO:     Found new best model at epoch 74
2022-11-22 20:49:15,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:15,749 INFO:     Epoch: 75
2022-11-22 20:49:16,487 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8345304578542709, 'Total loss': 0.8345304578542709} | train loss {'Reaction outcome loss': 0.7673599064350128, 'Total loss': 0.7673599064350128}
2022-11-22 20:49:16,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:16,487 INFO:     Epoch: 76
2022-11-22 20:49:17,220 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8685172301801768, 'Total loss': 0.8685172301801768} | train loss {'Reaction outcome loss': 0.7648261140803901, 'Total loss': 0.7648261140803901}
2022-11-22 20:49:17,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:17,221 INFO:     Epoch: 77
2022-11-22 20:49:17,972 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8148372024297714, 'Total loss': 0.8148372024297714} | train loss {'Reaction outcome loss': 0.7643963801617525, 'Total loss': 0.7643963801617525}
2022-11-22 20:49:17,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:17,972 INFO:     Epoch: 78
2022-11-22 20:49:18,700 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8354753276163881, 'Total loss': 0.8354753276163881} | train loss {'Reaction outcome loss': 0.7656081331019499, 'Total loss': 0.7656081331019499}
2022-11-22 20:49:18,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:18,700 INFO:     Epoch: 79
2022-11-22 20:49:19,487 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8225654329765927, 'Total loss': 0.8225654329765927} | train loss {'Reaction outcome loss': 0.766722665635907, 'Total loss': 0.766722665635907}
2022-11-22 20:49:19,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:19,487 INFO:     Epoch: 80
2022-11-22 20:49:20,200 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8017264563928951, 'Total loss': 0.8017264563928951} | train loss {'Reaction outcome loss': 0.7553569721324104, 'Total loss': 0.7553569721324104}
2022-11-22 20:49:20,201 INFO:     Found new best model at epoch 80
2022-11-22 20:49:20,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:20,202 INFO:     Epoch: 81
2022-11-22 20:49:20,908 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.815725098956715, 'Total loss': 0.815725098956715} | train loss {'Reaction outcome loss': 0.7634426811519934, 'Total loss': 0.7634426811519934}
2022-11-22 20:49:20,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:20,908 INFO:     Epoch: 82
2022-11-22 20:49:21,624 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8057086532088843, 'Total loss': 0.8057086532088843} | train loss {'Reaction outcome loss': 0.756199551480157, 'Total loss': 0.756199551480157}
2022-11-22 20:49:21,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:21,624 INFO:     Epoch: 83
2022-11-22 20:49:22,312 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8198534839532592, 'Total loss': 0.8198534839532592} | train loss {'Reaction outcome loss': 0.758545202503399, 'Total loss': 0.758545202503399}
2022-11-22 20:49:22,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:22,312 INFO:     Epoch: 84
2022-11-22 20:49:23,032 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8583891818469221, 'Total loss': 0.8583891818469221} | train loss {'Reaction outcome loss': 0.7587257405933069, 'Total loss': 0.7587257405933069}
2022-11-22 20:49:23,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:23,032 INFO:     Epoch: 85
2022-11-22 20:49:23,738 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8143577169288289, 'Total loss': 0.8143577169288289} | train loss {'Reaction outcome loss': 0.7595455785186923, 'Total loss': 0.7595455785186923}
2022-11-22 20:49:23,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:23,738 INFO:     Epoch: 86
2022-11-22 20:49:24,423 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8103422156789086, 'Total loss': 0.8103422156789086} | train loss {'Reaction outcome loss': 0.7550150906553074, 'Total loss': 0.7550150906553074}
2022-11-22 20:49:24,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:24,424 INFO:     Epoch: 87
2022-11-22 20:49:25,144 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8246067620136521, 'Total loss': 0.8246067620136521} | train loss {'Reaction outcome loss': 0.7563304730824062, 'Total loss': 0.7563304730824062}
2022-11-22 20:49:25,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:25,144 INFO:     Epoch: 88
2022-11-22 20:49:25,874 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8260679983279922, 'Total loss': 0.8260679983279922} | train loss {'Reaction outcome loss': 0.7571868282191607, 'Total loss': 0.7571868282191607}
2022-11-22 20:49:25,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:25,874 INFO:     Epoch: 89
2022-11-22 20:49:26,587 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8161613588983362, 'Total loss': 0.8161613588983362} | train loss {'Reaction outcome loss': 0.7587012814015758, 'Total loss': 0.7587012814015758}
2022-11-22 20:49:26,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:26,587 INFO:     Epoch: 90
2022-11-22 20:49:27,343 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8435280092737891, 'Total loss': 0.8435280092737891} | train loss {'Reaction outcome loss': 0.7442427933216095, 'Total loss': 0.7442427933216095}
2022-11-22 20:49:27,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:27,344 INFO:     Epoch: 91
2022-11-22 20:49:28,071 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8019105582074686, 'Total loss': 0.8019105582074686} | train loss {'Reaction outcome loss': 0.747219305257408, 'Total loss': 0.747219305257408}
2022-11-22 20:49:28,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:28,071 INFO:     Epoch: 92
2022-11-22 20:49:28,841 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7823254676027731, 'Total loss': 0.7823254676027731} | train loss {'Reaction outcome loss': 0.745923904253512, 'Total loss': 0.745923904253512}
2022-11-22 20:49:28,841 INFO:     Found new best model at epoch 92
2022-11-22 20:49:28,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:28,842 INFO:     Epoch: 93
2022-11-22 20:49:29,589 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7994499795816161, 'Total loss': 0.7994499795816161} | train loss {'Reaction outcome loss': 0.7397322652291278, 'Total loss': 0.7397322652291278}
2022-11-22 20:49:29,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:29,590 INFO:     Epoch: 94
2022-11-22 20:49:30,302 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8006750873544, 'Total loss': 0.8006750873544} | train loss {'Reaction outcome loss': 0.7368817783131891, 'Total loss': 0.7368817783131891}
2022-11-22 20:49:30,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:30,303 INFO:     Epoch: 95
2022-11-22 20:49:31,040 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7998439459638162, 'Total loss': 0.7998439459638162} | train loss {'Reaction outcome loss': 0.733685992810191, 'Total loss': 0.733685992810191}
2022-11-22 20:49:31,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:31,040 INFO:     Epoch: 96
2022-11-22 20:49:31,796 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8065116066824306, 'Total loss': 0.8065116066824306} | train loss {'Reaction outcome loss': 0.7352492080659282, 'Total loss': 0.7352492080659282}
2022-11-22 20:49:31,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:31,796 INFO:     Epoch: 97
2022-11-22 20:49:32,552 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8316785638982599, 'Total loss': 0.8316785638982599} | train loss {'Reaction outcome loss': 0.7260915893681196, 'Total loss': 0.7260915893681196}
2022-11-22 20:49:32,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:32,552 INFO:     Epoch: 98
2022-11-22 20:49:33,271 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.793682798743248, 'Total loss': 0.793682798743248} | train loss {'Reaction outcome loss': 0.7311102710208114, 'Total loss': 0.7311102710208114}
2022-11-22 20:49:33,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:33,271 INFO:     Epoch: 99
2022-11-22 20:49:33,993 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7916832498528741, 'Total loss': 0.7916832498528741} | train loss {'Reaction outcome loss': 0.7278250988040652, 'Total loss': 0.7278250988040652}
2022-11-22 20:49:33,993 INFO:     Best model found after epoch 93 of 100.
2022-11-22 20:49:33,994 INFO:   Done with stage: TRAINING
2022-11-22 20:49:33,994 INFO:   Starting stage: EVALUATION
2022-11-22 20:49:34,119 INFO:   Done with stage: EVALUATION
2022-11-22 20:49:34,119 INFO:   Leaving out SEQ value Fold_1
2022-11-22 20:49:34,133 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:49:34,133 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:49:34,808 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:49:34,808 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:49:34,876 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:49:34,876 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:49:34,876 INFO:     No hyperparam tuning for this model
2022-11-22 20:49:34,876 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:49:34,876 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:49:34,877 INFO:     None feature selector for col prot
2022-11-22 20:49:34,877 INFO:     None feature selector for col prot
2022-11-22 20:49:34,878 INFO:     None feature selector for col prot
2022-11-22 20:49:34,878 INFO:     None feature selector for col chem
2022-11-22 20:49:34,878 INFO:     None feature selector for col chem
2022-11-22 20:49:34,878 INFO:     None feature selector for col chem
2022-11-22 20:49:34,878 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:49:34,878 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:49:34,880 INFO:     Number of params in model 126091
2022-11-22 20:49:34,883 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:49:34,883 INFO:   Starting stage: TRAINING
2022-11-22 20:49:34,932 INFO:     Val loss before train {'Reaction outcome loss': 0.9705459150401029, 'Total loss': 0.9705459150401029}
2022-11-22 20:49:34,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:34,932 INFO:     Epoch: 0
2022-11-22 20:49:35,683 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8386956368657675, 'Total loss': 0.8386956368657675} | train loss {'Reaction outcome loss': 0.881289430418793, 'Total loss': 0.881289430418793}
2022-11-22 20:49:35,683 INFO:     Found new best model at epoch 0
2022-11-22 20:49:35,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:35,684 INFO:     Epoch: 1
2022-11-22 20:49:36,442 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8144832835956053, 'Total loss': 0.8144832835956053} | train loss {'Reaction outcome loss': 0.8518885515174087, 'Total loss': 0.8518885515174087}
2022-11-22 20:49:36,443 INFO:     Found new best model at epoch 1
2022-11-22 20:49:36,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:36,444 INFO:     Epoch: 2
2022-11-22 20:49:37,184 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8100189390507612, 'Total loss': 0.8100189390507612} | train loss {'Reaction outcome loss': 0.8396059537420467, 'Total loss': 0.8396059537420467}
2022-11-22 20:49:37,184 INFO:     Found new best model at epoch 2
2022-11-22 20:49:37,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:37,185 INFO:     Epoch: 3
2022-11-22 20:49:37,888 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8560101328925653, 'Total loss': 0.8560101328925653} | train loss {'Reaction outcome loss': 0.8309152657888373, 'Total loss': 0.8309152657888373}
2022-11-22 20:49:37,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:37,888 INFO:     Epoch: 4
2022-11-22 20:49:38,662 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8158819350329313, 'Total loss': 0.8158819350329313} | train loss {'Reaction outcome loss': 0.8270194181374141, 'Total loss': 0.8270194181374141}
2022-11-22 20:49:38,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:38,662 INFO:     Epoch: 5
2022-11-22 20:49:39,400 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7941256253556772, 'Total loss': 0.7941256253556772} | train loss {'Reaction outcome loss': 0.8242391485340741, 'Total loss': 0.8242391485340741}
2022-11-22 20:49:39,401 INFO:     Found new best model at epoch 5
2022-11-22 20:49:39,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:39,401 INFO:     Epoch: 6
2022-11-22 20:49:40,151 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8226669911633838, 'Total loss': 0.8226669911633838} | train loss {'Reaction outcome loss': 0.8196954150589145, 'Total loss': 0.8196954150589145}
2022-11-22 20:49:40,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:40,151 INFO:     Epoch: 7
2022-11-22 20:49:40,901 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7857890515164896, 'Total loss': 0.7857890515164896} | train loss {'Reaction outcome loss': 0.8142285873695295, 'Total loss': 0.8142285873695295}
2022-11-22 20:49:40,901 INFO:     Found new best model at epoch 7
2022-11-22 20:49:40,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:40,902 INFO:     Epoch: 8
2022-11-22 20:49:41,663 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8074804781512781, 'Total loss': 0.8074804781512781} | train loss {'Reaction outcome loss': 0.8096738145059469, 'Total loss': 0.8096738145059469}
2022-11-22 20:49:41,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:41,663 INFO:     Epoch: 9
2022-11-22 20:49:42,394 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8014420081268657, 'Total loss': 0.8014420081268657} | train loss {'Reaction outcome loss': 0.8119684983272941, 'Total loss': 0.8119684983272941}
2022-11-22 20:49:42,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:42,394 INFO:     Epoch: 10
2022-11-22 20:49:43,113 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8296241800893437, 'Total loss': 0.8296241800893437} | train loss {'Reaction outcome loss': 0.8066942904676709, 'Total loss': 0.8066942904676709}
2022-11-22 20:49:43,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:43,114 INFO:     Epoch: 11
2022-11-22 20:49:43,870 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7823791688477452, 'Total loss': 0.7823791688477452} | train loss {'Reaction outcome loss': 0.8074838392588557, 'Total loss': 0.8074838392588557}
2022-11-22 20:49:43,871 INFO:     Found new best model at epoch 11
2022-11-22 20:49:43,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:43,871 INFO:     Epoch: 12
2022-11-22 20:49:44,597 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7933219542557542, 'Total loss': 0.7933219542557542} | train loss {'Reaction outcome loss': 0.8068633951702896, 'Total loss': 0.8068633951702896}
2022-11-22 20:49:44,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:44,598 INFO:     Epoch: 13
2022-11-22 20:49:45,306 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8228057297793302, 'Total loss': 0.8228057297793302} | train loss {'Reaction outcome loss': 0.8105457663536072, 'Total loss': 0.8105457663536072}
2022-11-22 20:49:45,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:45,306 INFO:     Epoch: 14
2022-11-22 20:49:46,074 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7929656681689349, 'Total loss': 0.7929656681689349} | train loss {'Reaction outcome loss': 0.8061236396127818, 'Total loss': 0.8061236396127818}
2022-11-22 20:49:46,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:46,075 INFO:     Epoch: 15
2022-11-22 20:49:46,827 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.787738863717426, 'Total loss': 0.787738863717426} | train loss {'Reaction outcome loss': 0.8116302298039806, 'Total loss': 0.8116302298039806}
2022-11-22 20:49:46,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:46,827 INFO:     Epoch: 16
2022-11-22 20:49:47,529 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.798079835420305, 'Total loss': 0.798079835420305} | train loss {'Reaction outcome loss': 0.8019377060082494, 'Total loss': 0.8019377060082494}
2022-11-22 20:49:47,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:47,529 INFO:     Epoch: 17
2022-11-22 20:49:48,282 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8097728578881784, 'Total loss': 0.8097728578881784} | train loss {'Reaction outcome loss': 0.8068754246040266, 'Total loss': 0.8068754246040266}
2022-11-22 20:49:48,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:48,283 INFO:     Epoch: 18
2022-11-22 20:49:48,978 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7940534563227133, 'Total loss': 0.7940534563227133} | train loss {'Reaction outcome loss': 0.8084632723915334, 'Total loss': 0.8084632723915334}
2022-11-22 20:49:48,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:48,978 INFO:     Epoch: 19
2022-11-22 20:49:49,786 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.814979302612218, 'Total loss': 0.814979302612218} | train loss {'Reaction outcome loss': 0.8033038507918923, 'Total loss': 0.8033038507918923}
2022-11-22 20:49:49,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:49,786 INFO:     Epoch: 20
2022-11-22 20:49:50,532 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7865780632604252, 'Total loss': 0.7865780632604252} | train loss {'Reaction outcome loss': 0.8052519747189113, 'Total loss': 0.8052519747189113}
2022-11-22 20:49:50,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:50,532 INFO:     Epoch: 21
2022-11-22 20:49:51,300 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7844581035050479, 'Total loss': 0.7844581035050479} | train loss {'Reaction outcome loss': 0.8023088728894993, 'Total loss': 0.8023088728894993}
2022-11-22 20:49:51,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:51,300 INFO:     Epoch: 22
2022-11-22 20:49:52,043 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8263040733608332, 'Total loss': 0.8263040733608332} | train loss {'Reaction outcome loss': 0.8019183896025833, 'Total loss': 0.8019183896025833}
2022-11-22 20:49:52,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:52,044 INFO:     Epoch: 23
2022-11-22 20:49:52,819 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8331650197505951, 'Total loss': 0.8331650197505951} | train loss {'Reaction outcome loss': 0.7972235072632226, 'Total loss': 0.7972235072632226}
2022-11-22 20:49:52,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:52,819 INFO:     Epoch: 24
2022-11-22 20:49:53,546 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7921412573619322, 'Total loss': 0.7921412573619322} | train loss {'Reaction outcome loss': 0.7997494914093796, 'Total loss': 0.7997494914093796}
2022-11-22 20:49:53,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:53,546 INFO:     Epoch: 25
2022-11-22 20:49:54,302 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7925530191172253, 'Total loss': 0.7925530191172253} | train loss {'Reaction outcome loss': 0.7980900089351498, 'Total loss': 0.7980900089351498}
2022-11-22 20:49:54,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:54,303 INFO:     Epoch: 26
2022-11-22 20:49:55,048 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7857115349986337, 'Total loss': 0.7857115349986337} | train loss {'Reaction outcome loss': 0.7973969105555087, 'Total loss': 0.7973969105555087}
2022-11-22 20:49:55,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:55,048 INFO:     Epoch: 27
2022-11-22 20:49:55,760 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8122824105349454, 'Total loss': 0.8122824105349454} | train loss {'Reaction outcome loss': 0.8007850546009686, 'Total loss': 0.8007850546009686}
2022-11-22 20:49:55,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:55,761 INFO:     Epoch: 28
2022-11-22 20:49:56,518 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8179525021802295, 'Total loss': 0.8179525021802295} | train loss {'Reaction outcome loss': 0.7951495103690089, 'Total loss': 0.7951495103690089}
2022-11-22 20:49:56,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:56,518 INFO:     Epoch: 29
2022-11-22 20:49:57,243 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7951303022828969, 'Total loss': 0.7951303022828969} | train loss {'Reaction outcome loss': 0.8002634278365544, 'Total loss': 0.8002634278365544}
2022-11-22 20:49:57,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:57,244 INFO:     Epoch: 30
2022-11-22 20:49:57,983 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.795345001430674, 'Total loss': 0.795345001430674} | train loss {'Reaction outcome loss': 0.7943212740275325, 'Total loss': 0.7943212740275325}
2022-11-22 20:49:57,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:57,983 INFO:     Epoch: 31
2022-11-22 20:49:58,713 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7727196863429113, 'Total loss': 0.7727196863429113} | train loss {'Reaction outcome loss': 0.8016397470114183, 'Total loss': 0.8016397470114183}
2022-11-22 20:49:58,713 INFO:     Found new best model at epoch 31
2022-11-22 20:49:58,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:58,714 INFO:     Epoch: 32
2022-11-22 20:49:59,446 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8091131828048013, 'Total loss': 0.8091131828048013} | train loss {'Reaction outcome loss': 0.800629565667133, 'Total loss': 0.800629565667133}
2022-11-22 20:49:59,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:49:59,447 INFO:     Epoch: 33
2022-11-22 20:50:00,204 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7856367738409475, 'Total loss': 0.7856367738409475} | train loss {'Reaction outcome loss': 0.8009963260621441, 'Total loss': 0.8009963260621441}
2022-11-22 20:50:00,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:00,205 INFO:     Epoch: 34
2022-11-22 20:50:00,942 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7961811450394717, 'Total loss': 0.7961811450394717} | train loss {'Reaction outcome loss': 0.7986897146215244, 'Total loss': 0.7986897146215244}
2022-11-22 20:50:00,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:00,942 INFO:     Epoch: 35
2022-11-22 20:50:01,658 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8199899250810797, 'Total loss': 0.8199899250810797} | train loss {'Reaction outcome loss': 0.7972443343425284, 'Total loss': 0.7972443343425284}
2022-11-22 20:50:01,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:01,658 INFO:     Epoch: 36
2022-11-22 20:50:02,424 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7608780766075308, 'Total loss': 0.7608780766075308} | train loss {'Reaction outcome loss': 0.8001810268479951, 'Total loss': 0.8001810268479951}
2022-11-22 20:50:02,424 INFO:     Found new best model at epoch 36
2022-11-22 20:50:02,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:02,425 INFO:     Epoch: 37
2022-11-22 20:50:03,164 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7979819862680002, 'Total loss': 0.7979819862680002} | train loss {'Reaction outcome loss': 0.7942026326850969, 'Total loss': 0.7942026326850969}
2022-11-22 20:50:03,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:03,164 INFO:     Epoch: 38
2022-11-22 20:50:03,869 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7772814909165556, 'Total loss': 0.7772814909165556} | train loss {'Reaction outcome loss': 0.7930516651698521, 'Total loss': 0.7930516651698521}
2022-11-22 20:50:03,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:03,869 INFO:     Epoch: 39
2022-11-22 20:50:04,614 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7811264653097499, 'Total loss': 0.7811264653097499} | train loss {'Reaction outcome loss': 0.7933079589386376, 'Total loss': 0.7933079589386376}
2022-11-22 20:50:04,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:04,614 INFO:     Epoch: 40
2022-11-22 20:50:05,393 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8168243129145015, 'Total loss': 0.8168243129145015} | train loss {'Reaction outcome loss': 0.7945525958829996, 'Total loss': 0.7945525958829996}
2022-11-22 20:50:05,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:05,393 INFO:     Epoch: 41
2022-11-22 20:50:06,178 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8003691028464924, 'Total loss': 0.8003691028464924} | train loss {'Reaction outcome loss': 0.8000185782812079, 'Total loss': 0.8000185782812079}
2022-11-22 20:50:06,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:06,179 INFO:     Epoch: 42
2022-11-22 20:50:06,900 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.79696678573435, 'Total loss': 0.79696678573435} | train loss {'Reaction outcome loss': 0.7938822535835967, 'Total loss': 0.7938822535835967}
2022-11-22 20:50:06,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:06,901 INFO:     Epoch: 43
2022-11-22 20:50:07,591 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8024517311291262, 'Total loss': 0.8024517311291262} | train loss {'Reaction outcome loss': 0.7960045055467255, 'Total loss': 0.7960045055467255}
2022-11-22 20:50:07,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:07,591 INFO:     Epoch: 44
2022-11-22 20:50:08,356 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7780176313085989, 'Total loss': 0.7780176313085989} | train loss {'Reaction outcome loss': 0.7944510377183253, 'Total loss': 0.7944510377183253}
2022-11-22 20:50:08,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:08,356 INFO:     Epoch: 45
2022-11-22 20:50:09,082 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7835087329149246, 'Total loss': 0.7835087329149246} | train loss {'Reaction outcome loss': 0.7906883601023227, 'Total loss': 0.7906883601023227}
2022-11-22 20:50:09,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:09,083 INFO:     Epoch: 46
2022-11-22 20:50:09,821 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7985537350177765, 'Total loss': 0.7985537350177765} | train loss {'Reaction outcome loss': 0.7899204033978131, 'Total loss': 0.7899204033978131}
2022-11-22 20:50:09,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:09,821 INFO:     Epoch: 47
2022-11-22 20:50:10,534 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.784697562456131, 'Total loss': 0.784697562456131} | train loss {'Reaction outcome loss': 0.7986958358969007, 'Total loss': 0.7986958358969007}
2022-11-22 20:50:10,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:10,534 INFO:     Epoch: 48
2022-11-22 20:50:11,278 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7586872777478262, 'Total loss': 0.7586872777478262} | train loss {'Reaction outcome loss': 0.7920674038176634, 'Total loss': 0.7920674038176634}
2022-11-22 20:50:11,278 INFO:     Found new best model at epoch 48
2022-11-22 20:50:11,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:11,279 INFO:     Epoch: 49
2022-11-22 20:50:12,018 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7971212349154733, 'Total loss': 0.7971212349154733} | train loss {'Reaction outcome loss': 0.7893891863676966, 'Total loss': 0.7893891863676966}
2022-11-22 20:50:12,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:12,019 INFO:     Epoch: 50
2022-11-22 20:50:12,735 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8089082539081573, 'Total loss': 0.8089082539081573} | train loss {'Reaction outcome loss': 0.7936897192682538, 'Total loss': 0.7936897192682538}
2022-11-22 20:50:12,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:12,735 INFO:     Epoch: 51
2022-11-22 20:50:13,454 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7843125747008757, 'Total loss': 0.7843125747008757} | train loss {'Reaction outcome loss': 0.7875790842941829, 'Total loss': 0.7875790842941829}
2022-11-22 20:50:13,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:13,455 INFO:     Epoch: 52
2022-11-22 20:50:14,186 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7836269892074845, 'Total loss': 0.7836269892074845} | train loss {'Reaction outcome loss': 0.7924936040323608, 'Total loss': 0.7924936040323608}
2022-11-22 20:50:14,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:14,187 INFO:     Epoch: 53
2022-11-22 20:50:14,944 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7804942645809867, 'Total loss': 0.7804942645809867} | train loss {'Reaction outcome loss': 0.7891119769641332, 'Total loss': 0.7891119769641332}
2022-11-22 20:50:14,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:14,945 INFO:     Epoch: 54
2022-11-22 20:50:15,734 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.784199446439743, 'Total loss': 0.784199446439743} | train loss {'Reaction outcome loss': 0.7871227834905897, 'Total loss': 0.7871227834905897}
2022-11-22 20:50:15,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:15,735 INFO:     Epoch: 55
2022-11-22 20:50:16,468 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7758187631314452, 'Total loss': 0.7758187631314452} | train loss {'Reaction outcome loss': 0.7899088482467496, 'Total loss': 0.7899088482467496}
2022-11-22 20:50:16,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:16,469 INFO:     Epoch: 56
2022-11-22 20:50:17,185 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7770296680656347, 'Total loss': 0.7770296680656347} | train loss {'Reaction outcome loss': 0.7909146919542429, 'Total loss': 0.7909146919542429}
2022-11-22 20:50:17,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:17,185 INFO:     Epoch: 57
2022-11-22 20:50:17,892 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7833799286322161, 'Total loss': 0.7833799286322161} | train loss {'Reaction outcome loss': 0.7887119298078575, 'Total loss': 0.7887119298078575}
2022-11-22 20:50:17,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:17,892 INFO:     Epoch: 58
2022-11-22 20:50:18,590 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7994938282804056, 'Total loss': 0.7994938282804056} | train loss {'Reaction outcome loss': 0.7887370608290848, 'Total loss': 0.7887370608290848}
2022-11-22 20:50:18,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:18,591 INFO:     Epoch: 59
2022-11-22 20:50:19,354 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7940877188335765, 'Total loss': 0.7940877188335765} | train loss {'Reaction outcome loss': 0.7924405517626781, 'Total loss': 0.7924405517626781}
2022-11-22 20:50:19,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:19,354 INFO:     Epoch: 60
2022-11-22 20:50:20,069 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7852325635877523, 'Total loss': 0.7852325635877523} | train loss {'Reaction outcome loss': 0.7886868659330875, 'Total loss': 0.7886868659330875}
2022-11-22 20:50:20,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:20,069 INFO:     Epoch: 61
2022-11-22 20:50:20,780 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7911545207554643, 'Total loss': 0.7911545207554643} | train loss {'Reaction outcome loss': 0.7831456489708959, 'Total loss': 0.7831456489708959}
2022-11-22 20:50:20,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:20,780 INFO:     Epoch: 62
2022-11-22 20:50:21,502 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7830100872299888, 'Total loss': 0.7830100872299888} | train loss {'Reaction outcome loss': 0.7904877922972854, 'Total loss': 0.7904877922972854}
2022-11-22 20:50:21,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:21,502 INFO:     Epoch: 63
2022-11-22 20:50:22,259 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7783653858033094, 'Total loss': 0.7783653858033094} | train loss {'Reaction outcome loss': 0.7786510124498484, 'Total loss': 0.7786510124498484}
2022-11-22 20:50:22,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:22,260 INFO:     Epoch: 64
2022-11-22 20:50:23,055 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7848857129839334, 'Total loss': 0.7848857129839334} | train loss {'Reaction outcome loss': 0.7886495621836915, 'Total loss': 0.7886495621836915}
2022-11-22 20:50:23,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:23,055 INFO:     Epoch: 65
2022-11-22 20:50:23,840 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8004884950139306, 'Total loss': 0.8004884950139306} | train loss {'Reaction outcome loss': 0.7841359817251867, 'Total loss': 0.7841359817251867}
2022-11-22 20:50:23,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:23,840 INFO:     Epoch: 66
2022-11-22 20:50:24,611 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7651392065665938, 'Total loss': 0.7651392065665938} | train loss {'Reaction outcome loss': 0.7838933196603035, 'Total loss': 0.7838933196603035}
2022-11-22 20:50:24,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:24,611 INFO:     Epoch: 67
2022-11-22 20:50:25,332 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7574535682797432, 'Total loss': 0.7574535682797432} | train loss {'Reaction outcome loss': 0.7844802027454182, 'Total loss': 0.7844802027454182}
2022-11-22 20:50:25,333 INFO:     Found new best model at epoch 67
2022-11-22 20:50:25,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:25,334 INFO:     Epoch: 68
2022-11-22 20:50:26,067 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.780183762989261, 'Total loss': 0.780183762989261} | train loss {'Reaction outcome loss': 0.7856902801260657, 'Total loss': 0.7856902801260657}
2022-11-22 20:50:26,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:26,068 INFO:     Epoch: 69
2022-11-22 20:50:26,805 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7588554925539277, 'Total loss': 0.7588554925539277} | train loss {'Reaction outcome loss': 0.7730251472823474, 'Total loss': 0.7730251472823474}
2022-11-22 20:50:26,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:26,806 INFO:     Epoch: 70
2022-11-22 20:50:27,562 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7670435072346167, 'Total loss': 0.7670435072346167} | train loss {'Reaction outcome loss': 0.7835227546643238, 'Total loss': 0.7835227546643238}
2022-11-22 20:50:27,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:27,562 INFO:     Epoch: 71
2022-11-22 20:50:28,326 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7644758515737273, 'Total loss': 0.7644758515737273} | train loss {'Reaction outcome loss': 0.7806460876854099, 'Total loss': 0.7806460876854099}
2022-11-22 20:50:28,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:28,326 INFO:     Epoch: 72
2022-11-22 20:50:29,111 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7544640973210335, 'Total loss': 0.7544640973210335} | train loss {'Reaction outcome loss': 0.7809659539436807, 'Total loss': 0.7809659539436807}
2022-11-22 20:50:29,111 INFO:     Found new best model at epoch 72
2022-11-22 20:50:29,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:29,112 INFO:     Epoch: 73
2022-11-22 20:50:29,792 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7701087248596278, 'Total loss': 0.7701087248596278} | train loss {'Reaction outcome loss': 0.7754285536250289, 'Total loss': 0.7754285536250289}
2022-11-22 20:50:29,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:29,793 INFO:     Epoch: 74
2022-11-22 20:50:30,513 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7777367403561418, 'Total loss': 0.7777367403561418} | train loss {'Reaction outcome loss': 0.7758013020972816, 'Total loss': 0.7758013020972816}
2022-11-22 20:50:30,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:30,513 INFO:     Epoch: 75
2022-11-22 20:50:31,213 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7901168221777136, 'Total loss': 0.7901168221777136} | train loss {'Reaction outcome loss': 0.7767197207528718, 'Total loss': 0.7767197207528718}
2022-11-22 20:50:31,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:31,214 INFO:     Epoch: 76
2022-11-22 20:50:31,958 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7938536236231978, 'Total loss': 0.7938536236231978} | train loss {'Reaction outcome loss': 0.7744684516167154, 'Total loss': 0.7744684516167154}
2022-11-22 20:50:31,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:31,958 INFO:     Epoch: 77
2022-11-22 20:50:32,702 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7738664455034516, 'Total loss': 0.7738664455034516} | train loss {'Reaction outcome loss': 0.774279388602899, 'Total loss': 0.774279388602899}
2022-11-22 20:50:32,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:32,702 INFO:     Epoch: 78
2022-11-22 20:50:33,432 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7961417436599731, 'Total loss': 0.7961417436599731} | train loss {'Reaction outcome loss': 0.7781938866693147, 'Total loss': 0.7781938866693147}
2022-11-22 20:50:33,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:33,432 INFO:     Epoch: 79
2022-11-22 20:50:34,165 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.767096764662049, 'Total loss': 0.767096764662049} | train loss {'Reaction outcome loss': 0.7687825224837478, 'Total loss': 0.7687825224837478}
2022-11-22 20:50:34,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:34,165 INFO:     Epoch: 80
2022-11-22 20:50:34,903 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.745333276011727, 'Total loss': 0.745333276011727} | train loss {'Reaction outcome loss': 0.767713423772734, 'Total loss': 0.767713423772734}
2022-11-22 20:50:34,903 INFO:     Found new best model at epoch 80
2022-11-22 20:50:34,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:34,904 INFO:     Epoch: 81
2022-11-22 20:50:35,655 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.776949333873662, 'Total loss': 0.776949333873662} | train loss {'Reaction outcome loss': 0.7777788647583552, 'Total loss': 0.7777788647583552}
2022-11-22 20:50:35,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:35,656 INFO:     Epoch: 82
2022-11-22 20:50:36,368 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.774977600032633, 'Total loss': 0.774977600032633} | train loss {'Reaction outcome loss': 0.7773986882093001, 'Total loss': 0.7773986882093001}
2022-11-22 20:50:36,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:36,369 INFO:     Epoch: 83
2022-11-22 20:50:37,125 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7618828307498585, 'Total loss': 0.7618828307498585} | train loss {'Reaction outcome loss': 0.7716592631777939, 'Total loss': 0.7716592631777939}
2022-11-22 20:50:37,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:37,126 INFO:     Epoch: 84
2022-11-22 20:50:37,867 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7761034095151857, 'Total loss': 0.7761034095151857} | train loss {'Reaction outcome loss': 0.7724685679893104, 'Total loss': 0.7724685679893104}
2022-11-22 20:50:37,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:37,867 INFO:     Epoch: 85
2022-11-22 20:50:38,639 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7972543713721362, 'Total loss': 0.7972543713721362} | train loss {'Reaction outcome loss': 0.7716062555507738, 'Total loss': 0.7716062555507738}
2022-11-22 20:50:38,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:38,640 INFO:     Epoch: 86
2022-11-22 20:50:39,401 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7719257734715939, 'Total loss': 0.7719257734715939} | train loss {'Reaction outcome loss': 0.7597031921756511, 'Total loss': 0.7597031921756511}
2022-11-22 20:50:39,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:39,402 INFO:     Epoch: 87
2022-11-22 20:50:40,161 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7775550281459634, 'Total loss': 0.7775550281459634} | train loss {'Reaction outcome loss': 0.7646562654144909, 'Total loss': 0.7646562654144909}
2022-11-22 20:50:40,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:40,161 INFO:     Epoch: 88
2022-11-22 20:50:40,897 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7485752126032655, 'Total loss': 0.7485752126032655} | train loss {'Reaction outcome loss': 0.7653995107631294, 'Total loss': 0.7653995107631294}
2022-11-22 20:50:40,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:40,897 INFO:     Epoch: 89
2022-11-22 20:50:41,649 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7866245650432326, 'Total loss': 0.7866245650432326} | train loss {'Reaction outcome loss': 0.7607259129991337, 'Total loss': 0.7607259129991337}
2022-11-22 20:50:41,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:41,649 INFO:     Epoch: 90
2022-11-22 20:50:42,432 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.76039511913603, 'Total loss': 0.76039511913603} | train loss {'Reaction outcome loss': 0.758402212055362, 'Total loss': 0.758402212055362}
2022-11-22 20:50:42,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:42,432 INFO:     Epoch: 91
2022-11-22 20:50:43,198 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7864850535988808, 'Total loss': 0.7864850535988808} | train loss {'Reaction outcome loss': 0.7555495499348154, 'Total loss': 0.7555495499348154}
2022-11-22 20:50:43,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:43,198 INFO:     Epoch: 92
2022-11-22 20:50:43,952 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7582115554674105, 'Total loss': 0.7582115554674105} | train loss {'Reaction outcome loss': 0.7594869790028552, 'Total loss': 0.7594869790028552}
2022-11-22 20:50:43,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:43,952 INFO:     Epoch: 93
2022-11-22 20:50:44,707 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7435116557912393, 'Total loss': 0.7435116557912393} | train loss {'Reaction outcome loss': 0.7595606931618282, 'Total loss': 0.7595606931618282}
2022-11-22 20:50:44,708 INFO:     Found new best model at epoch 93
2022-11-22 20:50:44,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:44,709 INFO:     Epoch: 94
2022-11-22 20:50:45,455 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7574503150853243, 'Total loss': 0.7574503150853243} | train loss {'Reaction outcome loss': 0.7514176937998558, 'Total loss': 0.7514176937998558}
2022-11-22 20:50:45,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:45,455 INFO:     Epoch: 95
2022-11-22 20:50:46,206 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7583363889293238, 'Total loss': 0.7583363889293238} | train loss {'Reaction outcome loss': 0.7512539318629674, 'Total loss': 0.7512539318629674}
2022-11-22 20:50:46,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:46,207 INFO:     Epoch: 96
2022-11-22 20:50:46,933 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7567198513583704, 'Total loss': 0.7567198513583704} | train loss {'Reaction outcome loss': 0.7502267590590885, 'Total loss': 0.7502267590590885}
2022-11-22 20:50:46,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:46,934 INFO:     Epoch: 97
2022-11-22 20:50:47,694 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7630589225075461, 'Total loss': 0.7630589225075461} | train loss {'Reaction outcome loss': 0.750413326584563, 'Total loss': 0.750413326584563}
2022-11-22 20:50:47,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:47,694 INFO:     Epoch: 98
2022-11-22 20:50:48,431 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7706842266700484, 'Total loss': 0.7706842266700484} | train loss {'Reaction outcome loss': 0.7506861146007265, 'Total loss': 0.7506861146007265}
2022-11-22 20:50:48,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:48,432 INFO:     Epoch: 99
2022-11-22 20:50:49,223 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7355130924419924, 'Total loss': 0.7355130924419924} | train loss {'Reaction outcome loss': 0.7519163839671077, 'Total loss': 0.7519163839671077}
2022-11-22 20:50:49,223 INFO:     Found new best model at epoch 99
2022-11-22 20:50:49,224 INFO:     Best model found after epoch 100 of 100.
2022-11-22 20:50:49,224 INFO:   Done with stage: TRAINING
2022-11-22 20:50:49,224 INFO:   Starting stage: EVALUATION
2022-11-22 20:50:49,348 INFO:   Done with stage: EVALUATION
2022-11-22 20:50:49,348 INFO:   Leaving out SEQ value Fold_2
2022-11-22 20:50:49,361 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:50:49,361 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:50:50,028 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:50:50,028 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:50:50,097 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:50:50,098 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:50:50,098 INFO:     No hyperparam tuning for this model
2022-11-22 20:50:50,098 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:50:50,098 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:50:50,099 INFO:     None feature selector for col prot
2022-11-22 20:50:50,099 INFO:     None feature selector for col prot
2022-11-22 20:50:50,099 INFO:     None feature selector for col prot
2022-11-22 20:50:50,099 INFO:     None feature selector for col chem
2022-11-22 20:50:50,100 INFO:     None feature selector for col chem
2022-11-22 20:50:50,100 INFO:     None feature selector for col chem
2022-11-22 20:50:50,100 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:50:50,100 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:50:50,101 INFO:     Number of params in model 126091
2022-11-22 20:50:50,104 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:50:50,104 INFO:   Starting stage: TRAINING
2022-11-22 20:50:50,153 INFO:     Val loss before train {'Reaction outcome loss': 1.036874837496064, 'Total loss': 1.036874837496064}
2022-11-22 20:50:50,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:50,154 INFO:     Epoch: 0
2022-11-22 20:50:50,889 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.846730384637009, 'Total loss': 0.846730384637009} | train loss {'Reaction outcome loss': 0.8826257845892115, 'Total loss': 0.8826257845892115}
2022-11-22 20:50:50,890 INFO:     Found new best model at epoch 0
2022-11-22 20:50:50,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:50,890 INFO:     Epoch: 1
2022-11-22 20:50:51,579 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8493301983584057, 'Total loss': 0.8493301983584057} | train loss {'Reaction outcome loss': 0.8483261428622582, 'Total loss': 0.8483261428622582}
2022-11-22 20:50:51,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:51,579 INFO:     Epoch: 2
2022-11-22 20:50:52,321 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8277130045674064, 'Total loss': 0.8277130045674064} | train loss {'Reaction outcome loss': 0.8473272609565905, 'Total loss': 0.8473272609565905}
2022-11-22 20:50:52,321 INFO:     Found new best model at epoch 2
2022-11-22 20:50:52,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:52,322 INFO:     Epoch: 3
2022-11-22 20:50:53,058 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.841751481321725, 'Total loss': 0.841751481321725} | train loss {'Reaction outcome loss': 0.8315891923933376, 'Total loss': 0.8315891923933376}
2022-11-22 20:50:53,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:53,058 INFO:     Epoch: 4
2022-11-22 20:50:53,791 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8170738091522997, 'Total loss': 0.8170738091522997} | train loss {'Reaction outcome loss': 0.8362484061524935, 'Total loss': 0.8362484061524935}
2022-11-22 20:50:53,791 INFO:     Found new best model at epoch 4
2022-11-22 20:50:53,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:53,792 INFO:     Epoch: 5
2022-11-22 20:50:54,548 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8128952275622975, 'Total loss': 0.8128952275622975} | train loss {'Reaction outcome loss': 0.8210396742531163, 'Total loss': 0.8210396742531163}
2022-11-22 20:50:54,548 INFO:     Found new best model at epoch 5
2022-11-22 20:50:54,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:54,549 INFO:     Epoch: 6
2022-11-22 20:50:55,284 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8120744208043272, 'Total loss': 0.8120744208043272} | train loss {'Reaction outcome loss': 0.8208913413377908, 'Total loss': 0.8208913413377908}
2022-11-22 20:50:55,284 INFO:     Found new best model at epoch 6
2022-11-22 20:50:55,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:55,285 INFO:     Epoch: 7
2022-11-22 20:50:56,004 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.803708903491497, 'Total loss': 0.803708903491497} | train loss {'Reaction outcome loss': 0.8165766258954037, 'Total loss': 0.8165766258954037}
2022-11-22 20:50:56,004 INFO:     Found new best model at epoch 7
2022-11-22 20:50:56,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:56,005 INFO:     Epoch: 8
2022-11-22 20:50:56,759 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8107700049877167, 'Total loss': 0.8107700049877167} | train loss {'Reaction outcome loss': 0.821362214291144, 'Total loss': 0.821362214291144}
2022-11-22 20:50:56,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:56,760 INFO:     Epoch: 9
2022-11-22 20:50:57,519 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8141847367991101, 'Total loss': 0.8141847367991101} | train loss {'Reaction outcome loss': 0.822031260863972, 'Total loss': 0.822031260863972}
2022-11-22 20:50:57,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:57,520 INFO:     Epoch: 10
2022-11-22 20:50:58,255 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8144382624463602, 'Total loss': 0.8144382624463602} | train loss {'Reaction outcome loss': 0.8156875943847997, 'Total loss': 0.8156875943847997}
2022-11-22 20:50:58,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:58,255 INFO:     Epoch: 11
2022-11-22 20:50:59,050 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7921781316399574, 'Total loss': 0.7921781316399574} | train loss {'Reaction outcome loss': 0.8139052082169876, 'Total loss': 0.8139052082169876}
2022-11-22 20:50:59,050 INFO:     Found new best model at epoch 11
2022-11-22 20:50:59,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:59,051 INFO:     Epoch: 12
2022-11-22 20:50:59,848 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8049816468899901, 'Total loss': 0.8049816468899901} | train loss {'Reaction outcome loss': 0.8074522291117834, 'Total loss': 0.8074522291117834}
2022-11-22 20:50:59,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:50:59,848 INFO:     Epoch: 13
2022-11-22 20:51:00,603 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8063985285433856, 'Total loss': 0.8063985285433856} | train loss {'Reaction outcome loss': 0.8106876632221315, 'Total loss': 0.8106876632221315}
2022-11-22 20:51:00,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:00,604 INFO:     Epoch: 14
2022-11-22 20:51:01,384 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7993257702751593, 'Total loss': 0.7993257702751593} | train loss {'Reaction outcome loss': 0.8065290577136554, 'Total loss': 0.8065290577136554}
2022-11-22 20:51:01,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:01,384 INFO:     Epoch: 15
2022-11-22 20:51:02,217 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8090633871880445, 'Total loss': 0.8090633871880445} | train loss {'Reaction outcome loss': 0.8110073482700688, 'Total loss': 0.8110073482700688}
2022-11-22 20:51:02,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:02,217 INFO:     Epoch: 16
2022-11-22 20:51:03,042 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.803123800591989, 'Total loss': 0.803123800591989} | train loss {'Reaction outcome loss': 0.8103404495156246, 'Total loss': 0.8103404495156246}
2022-11-22 20:51:03,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:03,043 INFO:     Epoch: 17
2022-11-22 20:51:03,844 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8055204559456218, 'Total loss': 0.8055204559456218} | train loss {'Reaction outcome loss': 0.8095792728940002, 'Total loss': 0.8095792728940002}
2022-11-22 20:51:03,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:03,844 INFO:     Epoch: 18
2022-11-22 20:51:04,624 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7974095866084099, 'Total loss': 0.7974095866084099} | train loss {'Reaction outcome loss': 0.8091917789054786, 'Total loss': 0.8091917789054786}
2022-11-22 20:51:04,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:04,624 INFO:     Epoch: 19
2022-11-22 20:51:05,404 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.785098673267798, 'Total loss': 0.785098673267798} | train loss {'Reaction outcome loss': 0.8087331494580396, 'Total loss': 0.8087331494580396}
2022-11-22 20:51:05,404 INFO:     Found new best model at epoch 19
2022-11-22 20:51:05,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:05,405 INFO:     Epoch: 20
2022-11-22 20:51:06,131 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8006016822023825, 'Total loss': 0.8006016822023825} | train loss {'Reaction outcome loss': 0.806762357351751, 'Total loss': 0.806762357351751}
2022-11-22 20:51:06,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:06,131 INFO:     Epoch: 21
2022-11-22 20:51:06,865 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7838926003737883, 'Total loss': 0.7838926003737883} | train loss {'Reaction outcome loss': 0.802491402095146, 'Total loss': 0.802491402095146}
2022-11-22 20:51:06,866 INFO:     Found new best model at epoch 21
2022-11-22 20:51:06,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:06,866 INFO:     Epoch: 22
2022-11-22 20:51:07,655 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8156793598424305, 'Total loss': 0.8156793598424305} | train loss {'Reaction outcome loss': 0.8018870853219437, 'Total loss': 0.8018870853219437}
2022-11-22 20:51:07,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:07,656 INFO:     Epoch: 23
2022-11-22 20:51:08,378 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8046103451739658, 'Total loss': 0.8046103451739658} | train loss {'Reaction outcome loss': 0.8040553985337014, 'Total loss': 0.8040553985337014}
2022-11-22 20:51:08,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:08,379 INFO:     Epoch: 24
2022-11-22 20:51:09,126 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8215615126219663, 'Total loss': 0.8215615126219663} | train loss {'Reaction outcome loss': 0.800308606402594, 'Total loss': 0.800308606402594}
2022-11-22 20:51:09,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:09,127 INFO:     Epoch: 25
2022-11-22 20:51:09,869 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7950242392041467, 'Total loss': 0.7950242392041467} | train loss {'Reaction outcome loss': 0.809848249501545, 'Total loss': 0.809848249501545}
2022-11-22 20:51:09,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:09,870 INFO:     Epoch: 26
2022-11-22 20:51:10,644 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7928167066790841, 'Total loss': 0.7928167066790841} | train loss {'Reaction outcome loss': 0.8008796244497723, 'Total loss': 0.8008796244497723}
2022-11-22 20:51:10,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:10,644 INFO:     Epoch: 27
2022-11-22 20:51:11,360 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7880481772802093, 'Total loss': 0.7880481772802093} | train loss {'Reaction outcome loss': 0.8062189221382141, 'Total loss': 0.8062189221382141}
2022-11-22 20:51:11,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:11,361 INFO:     Epoch: 28
2022-11-22 20:51:12,106 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8065513568845663, 'Total loss': 0.8065513568845663} | train loss {'Reaction outcome loss': 0.799524065815968, 'Total loss': 0.799524065815968}
2022-11-22 20:51:12,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:12,107 INFO:     Epoch: 29
2022-11-22 20:51:12,872 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8129142793742093, 'Total loss': 0.8129142793742093} | train loss {'Reaction outcome loss': 0.7996489476819753, 'Total loss': 0.7996489476819753}
2022-11-22 20:51:12,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:12,873 INFO:     Epoch: 30
2022-11-22 20:51:13,621 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8025116954337467, 'Total loss': 0.8025116954337467} | train loss {'Reaction outcome loss': 0.8013820709728519, 'Total loss': 0.8013820709728519}
2022-11-22 20:51:13,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:13,621 INFO:     Epoch: 31
2022-11-22 20:51:14,359 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8055188310417262, 'Total loss': 0.8055188310417262} | train loss {'Reaction outcome loss': 0.7995279491671666, 'Total loss': 0.7995279491671666}
2022-11-22 20:51:14,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:14,360 INFO:     Epoch: 32
2022-11-22 20:51:15,112 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8127413459799506, 'Total loss': 0.8127413459799506} | train loss {'Reaction outcome loss': 0.803914838353632, 'Total loss': 0.803914838353632}
2022-11-22 20:51:15,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:15,112 INFO:     Epoch: 33
2022-11-22 20:51:15,896 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7958734089677985, 'Total loss': 0.7958734089677985} | train loss {'Reaction outcome loss': 0.7962707094094048, 'Total loss': 0.7962707094094048}
2022-11-22 20:51:15,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:15,898 INFO:     Epoch: 34
2022-11-22 20:51:16,650 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7953100814060732, 'Total loss': 0.7953100814060732} | train loss {'Reaction outcome loss': 0.8024381479994971, 'Total loss': 0.8024381479994971}
2022-11-22 20:51:16,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:16,650 INFO:     Epoch: 35
2022-11-22 20:51:17,431 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.790008317340504, 'Total loss': 0.790008317340504} | train loss {'Reaction outcome loss': 0.8053423265213908, 'Total loss': 0.8053423265213908}
2022-11-22 20:51:17,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:17,432 INFO:     Epoch: 36
2022-11-22 20:51:18,252 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8071292184970595, 'Total loss': 0.8071292184970595} | train loss {'Reaction outcome loss': 0.7971014268243843, 'Total loss': 0.7971014268243843}
2022-11-22 20:51:18,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:18,253 INFO:     Epoch: 37
2022-11-22 20:51:18,993 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7887805720621889, 'Total loss': 0.7887805720621889} | train loss {'Reaction outcome loss': 0.8000432795841201, 'Total loss': 0.8000432795841201}
2022-11-22 20:51:18,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:18,994 INFO:     Epoch: 38
2022-11-22 20:51:19,753 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7864545963027261, 'Total loss': 0.7864545963027261} | train loss {'Reaction outcome loss': 0.8068102608446167, 'Total loss': 0.8068102608446167}
2022-11-22 20:51:19,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:19,754 INFO:     Epoch: 39
2022-11-22 20:51:20,501 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7980332313613459, 'Total loss': 0.7980332313613459} | train loss {'Reaction outcome loss': 0.7939358687835184, 'Total loss': 0.7939358687835184}
2022-11-22 20:51:20,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:20,502 INFO:     Epoch: 40
2022-11-22 20:51:21,265 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8095805909145962, 'Total loss': 0.8095805909145962} | train loss {'Reaction outcome loss': 0.7965282796606844, 'Total loss': 0.7965282796606844}
2022-11-22 20:51:21,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:21,266 INFO:     Epoch: 41
2022-11-22 20:51:22,051 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.80601113086397, 'Total loss': 0.80601113086397} | train loss {'Reaction outcome loss': 0.7956488726713397, 'Total loss': 0.7956488726713397}
2022-11-22 20:51:22,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:22,051 INFO:     Epoch: 42
2022-11-22 20:51:22,790 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8024914434010332, 'Total loss': 0.8024914434010332} | train loss {'Reaction outcome loss': 0.795716064902935, 'Total loss': 0.795716064902935}
2022-11-22 20:51:22,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:22,791 INFO:     Epoch: 43
2022-11-22 20:51:23,522 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8045667972077023, 'Total loss': 0.8045667972077023} | train loss {'Reaction outcome loss': 0.7953834866705211, 'Total loss': 0.7953834866705211}
2022-11-22 20:51:23,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:23,522 INFO:     Epoch: 44
2022-11-22 20:51:24,224 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7893169183622707, 'Total loss': 0.7893169183622707} | train loss {'Reaction outcome loss': 0.7983950999101647, 'Total loss': 0.7983950999101647}
2022-11-22 20:51:24,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:24,225 INFO:     Epoch: 45
2022-11-22 20:51:24,978 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7860657931728796, 'Total loss': 0.7860657931728796} | train loss {'Reaction outcome loss': 0.7944476363147318, 'Total loss': 0.7944476363147318}
2022-11-22 20:51:24,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:24,979 INFO:     Epoch: 46
2022-11-22 20:51:25,742 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7979154207489707, 'Total loss': 0.7979154207489707} | train loss {'Reaction outcome loss': 0.7970983653898663, 'Total loss': 0.7970983653898663}
2022-11-22 20:51:25,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:25,742 INFO:     Epoch: 47
2022-11-22 20:51:26,480 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7921846495433287, 'Total loss': 0.7921846495433287} | train loss {'Reaction outcome loss': 0.801051621675974, 'Total loss': 0.801051621675974}
2022-11-22 20:51:26,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:26,480 INFO:     Epoch: 48
2022-11-22 20:51:27,316 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7826500501145016, 'Total loss': 0.7826500501145016} | train loss {'Reaction outcome loss': 0.8019437981761901, 'Total loss': 0.8019437981761901}
2022-11-22 20:51:27,317 INFO:     Found new best model at epoch 48
2022-11-22 20:51:27,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:27,318 INFO:     Epoch: 49
2022-11-22 20:51:28,098 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8237075101245533, 'Total loss': 0.8237075101245533} | train loss {'Reaction outcome loss': 0.8017929558329254, 'Total loss': 0.8017929558329254}
2022-11-22 20:51:28,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:28,099 INFO:     Epoch: 50
2022-11-22 20:51:28,853 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7893428816036745, 'Total loss': 0.7893428816036745} | train loss {'Reaction outcome loss': 0.7988812736412774, 'Total loss': 0.7988812736412774}
2022-11-22 20:51:28,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:28,853 INFO:     Epoch: 51
2022-11-22 20:51:29,608 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7872355377132242, 'Total loss': 0.7872355377132242} | train loss {'Reaction outcome loss': 0.7922342529422358, 'Total loss': 0.7922342529422358}
2022-11-22 20:51:29,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:29,608 INFO:     Epoch: 52
2022-11-22 20:51:30,346 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8102218996394764, 'Total loss': 0.8102218996394764} | train loss {'Reaction outcome loss': 0.7983722076242269, 'Total loss': 0.7983722076242269}
2022-11-22 20:51:30,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:30,346 INFO:     Epoch: 53
2022-11-22 20:51:31,068 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7963097115809267, 'Total loss': 0.7963097115809267} | train loss {'Reaction outcome loss': 0.8038776942834198, 'Total loss': 0.8038776942834198}
2022-11-22 20:51:31,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:31,069 INFO:     Epoch: 54
2022-11-22 20:51:31,799 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7982660220427946, 'Total loss': 0.7982660220427946} | train loss {'Reaction outcome loss': 0.7962626278521079, 'Total loss': 0.7962626278521079}
2022-11-22 20:51:31,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:31,799 INFO:     Epoch: 55
2022-11-22 20:51:32,501 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7985801209102977, 'Total loss': 0.7985801209102977} | train loss {'Reaction outcome loss': 0.7896058866490236, 'Total loss': 0.7896058866490236}
2022-11-22 20:51:32,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:32,501 INFO:     Epoch: 56
2022-11-22 20:51:33,205 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7832692841237242, 'Total loss': 0.7832692841237242} | train loss {'Reaction outcome loss': 0.8001841280141823, 'Total loss': 0.8001841280141823}
2022-11-22 20:51:33,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:33,205 INFO:     Epoch: 57
2022-11-22 20:51:33,935 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7873008732091297, 'Total loss': 0.7873008732091297} | train loss {'Reaction outcome loss': 0.8167468814956031, 'Total loss': 0.8167468814956031}
2022-11-22 20:51:33,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:33,935 INFO:     Epoch: 58
2022-11-22 20:51:34,695 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8448069827123121, 'Total loss': 0.8448069827123121} | train loss {'Reaction outcome loss': 0.8036288831398072, 'Total loss': 0.8036288831398072}
2022-11-22 20:51:34,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:34,695 INFO:     Epoch: 59
2022-11-22 20:51:35,451 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7940719256346876, 'Total loss': 0.7940719256346876} | train loss {'Reaction outcome loss': 0.799462988263803, 'Total loss': 0.799462988263803}
2022-11-22 20:51:35,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:35,451 INFO:     Epoch: 60
2022-11-22 20:51:36,191 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7776394940235398, 'Total loss': 0.7776394940235398} | train loss {'Reaction outcome loss': 0.7926445611213383, 'Total loss': 0.7926445611213383}
2022-11-22 20:51:36,191 INFO:     Found new best model at epoch 60
2022-11-22 20:51:36,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:36,192 INFO:     Epoch: 61
2022-11-22 20:51:36,982 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7836814705621112, 'Total loss': 0.7836814705621112} | train loss {'Reaction outcome loss': 0.7993546970460096, 'Total loss': 0.7993546970460096}
2022-11-22 20:51:36,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:36,982 INFO:     Epoch: 62
2022-11-22 20:51:37,726 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7918147614056413, 'Total loss': 0.7918147614056413} | train loss {'Reaction outcome loss': 0.7943722139968563, 'Total loss': 0.7943722139968563}
2022-11-22 20:51:37,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:37,727 INFO:     Epoch: 63
2022-11-22 20:51:38,464 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8096050748770888, 'Total loss': 0.8096050748770888} | train loss {'Reaction outcome loss': 0.8013763069382563, 'Total loss': 0.8013763069382563}
2022-11-22 20:51:38,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:38,464 INFO:     Epoch: 64
2022-11-22 20:51:39,233 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8034750385717913, 'Total loss': 0.8034750385717913} | train loss {'Reaction outcome loss': 0.7842903000864423, 'Total loss': 0.7842903000864423}
2022-11-22 20:51:39,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:39,233 INFO:     Epoch: 65
2022-11-22 20:51:39,998 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7984891357746992, 'Total loss': 0.7984891357746992} | train loss {'Reaction outcome loss': 0.7953547661603704, 'Total loss': 0.7953547661603704}
2022-11-22 20:51:39,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:39,998 INFO:     Epoch: 66
2022-11-22 20:51:40,719 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7981389530680396, 'Total loss': 0.7981389530680396} | train loss {'Reaction outcome loss': 0.7898565359443788, 'Total loss': 0.7898565359443788}
2022-11-22 20:51:40,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:40,720 INFO:     Epoch: 67
2022-11-22 20:51:41,466 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7876344059001316, 'Total loss': 0.7876344059001316} | train loss {'Reaction outcome loss': 0.7867723667187246, 'Total loss': 0.7867723667187246}
2022-11-22 20:51:41,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:41,466 INFO:     Epoch: 68
2022-11-22 20:51:42,262 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7950113828886639, 'Total loss': 0.7950113828886639} | train loss {'Reaction outcome loss': 0.7876647598588997, 'Total loss': 0.7876647598588997}
2022-11-22 20:51:42,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:42,262 INFO:     Epoch: 69
2022-11-22 20:51:43,035 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7945891043001955, 'Total loss': 0.7945891043001955} | train loss {'Reaction outcome loss': 0.791006167287286, 'Total loss': 0.791006167287286}
2022-11-22 20:51:43,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:43,036 INFO:     Epoch: 70
2022-11-22 20:51:43,764 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8146710030057214, 'Total loss': 0.8146710030057214} | train loss {'Reaction outcome loss': 0.7932663877242008, 'Total loss': 0.7932663877242008}
2022-11-22 20:51:43,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:43,764 INFO:     Epoch: 71
2022-11-22 20:51:44,527 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.767203418368643, 'Total loss': 0.767203418368643} | train loss {'Reaction outcome loss': 0.789729155494496, 'Total loss': 0.789729155494496}
2022-11-22 20:51:44,528 INFO:     Found new best model at epoch 71
2022-11-22 20:51:44,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:44,528 INFO:     Epoch: 72
2022-11-22 20:51:45,263 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7861747213385322, 'Total loss': 0.7861747213385322} | train loss {'Reaction outcome loss': 0.7812020842604309, 'Total loss': 0.7812020842604309}
2022-11-22 20:51:45,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:45,264 INFO:     Epoch: 73
2022-11-22 20:51:46,042 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7816242643377997, 'Total loss': 0.7816242643377997} | train loss {'Reaction outcome loss': 0.792822795358264, 'Total loss': 0.792822795358264}
2022-11-22 20:51:46,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:46,042 INFO:     Epoch: 74
2022-11-22 20:51:46,859 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7805021770975806, 'Total loss': 0.7805021770975806} | train loss {'Reaction outcome loss': 0.7765212206826037, 'Total loss': 0.7765212206826037}
2022-11-22 20:51:46,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:46,860 INFO:     Epoch: 75
2022-11-22 20:51:47,607 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7886758988553827, 'Total loss': 0.7886758988553827} | train loss {'Reaction outcome loss': 0.7865266225598602, 'Total loss': 0.7865266225598602}
2022-11-22 20:51:47,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:47,607 INFO:     Epoch: 76
2022-11-22 20:51:48,408 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7790743952447717, 'Total loss': 0.7790743952447717} | train loss {'Reaction outcome loss': 0.779677375125499, 'Total loss': 0.779677375125499}
2022-11-22 20:51:48,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:48,408 INFO:     Epoch: 77
2022-11-22 20:51:49,173 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7738759029995311, 'Total loss': 0.7738759029995311} | train loss {'Reaction outcome loss': 0.781666071188112, 'Total loss': 0.781666071188112}
2022-11-22 20:51:49,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:49,173 INFO:     Epoch: 78
2022-11-22 20:51:49,913 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7778153046965599, 'Total loss': 0.7778153046965599} | train loss {'Reaction outcome loss': 0.7753135707938237, 'Total loss': 0.7753135707938237}
2022-11-22 20:51:49,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:49,913 INFO:     Epoch: 79
2022-11-22 20:51:50,680 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7946475703607906, 'Total loss': 0.7946475703607906} | train loss {'Reaction outcome loss': 0.777531132132177, 'Total loss': 0.777531132132177}
2022-11-22 20:51:50,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:50,680 INFO:     Epoch: 80
2022-11-22 20:51:51,424 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7800888737494295, 'Total loss': 0.7800888737494295} | train loss {'Reaction outcome loss': 0.7731852368847562, 'Total loss': 0.7731852368847562}
2022-11-22 20:51:51,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:51,424 INFO:     Epoch: 81
2022-11-22 20:51:52,202 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7839624461802569, 'Total loss': 0.7839624461802569} | train loss {'Reaction outcome loss': 0.7681137615973167, 'Total loss': 0.7681137615973167}
2022-11-22 20:51:52,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:52,203 INFO:     Epoch: 82
2022-11-22 20:51:52,934 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.799947393888777, 'Total loss': 0.799947393888777} | train loss {'Reaction outcome loss': 0.77873753252541, 'Total loss': 0.77873753252541}
2022-11-22 20:51:52,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:52,935 INFO:     Epoch: 83
2022-11-22 20:51:53,737 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7931653762405569, 'Total loss': 0.7931653762405569} | train loss {'Reaction outcome loss': 0.775411323105034, 'Total loss': 0.775411323105034}
2022-11-22 20:51:53,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:53,737 INFO:     Epoch: 84
2022-11-22 20:51:54,537 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7702270482074131, 'Total loss': 0.7702270482074131} | train loss {'Reaction outcome loss': 0.7749538255123957, 'Total loss': 0.7749538255123957}
2022-11-22 20:51:54,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:54,538 INFO:     Epoch: 85
2022-11-22 20:51:55,363 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7592341059988196, 'Total loss': 0.7592341059988196} | train loss {'Reaction outcome loss': 0.7636710013741785, 'Total loss': 0.7636710013741785}
2022-11-22 20:51:55,363 INFO:     Found new best model at epoch 85
2022-11-22 20:51:55,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:55,364 INFO:     Epoch: 86
2022-11-22 20:51:56,107 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7517583004452966, 'Total loss': 0.7517583004452966} | train loss {'Reaction outcome loss': 0.7609282853873635, 'Total loss': 0.7609282853873635}
2022-11-22 20:51:56,107 INFO:     Found new best model at epoch 86
2022-11-22 20:51:56,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:56,108 INFO:     Epoch: 87
2022-11-22 20:51:56,940 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7566404613581571, 'Total loss': 0.7566404613581571} | train loss {'Reaction outcome loss': 0.7652749279250017, 'Total loss': 0.7652749279250017}
2022-11-22 20:51:56,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:56,940 INFO:     Epoch: 88
2022-11-22 20:51:57,721 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.748718030073426, 'Total loss': 0.748718030073426} | train loss {'Reaction outcome loss': 0.7641442498938757, 'Total loss': 0.7641442498938757}
2022-11-22 20:51:57,721 INFO:     Found new best model at epoch 88
2022-11-22 20:51:57,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:57,722 INFO:     Epoch: 89
2022-11-22 20:51:58,523 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7898476056077264, 'Total loss': 0.7898476056077264} | train loss {'Reaction outcome loss': 0.7640384745214753, 'Total loss': 0.7640384745214753}
2022-11-22 20:51:58,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:58,523 INFO:     Epoch: 90
2022-11-22 20:51:59,389 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7598872455683622, 'Total loss': 0.7598872455683622} | train loss {'Reaction outcome loss': 0.7550062292560875, 'Total loss': 0.7550062292560875}
2022-11-22 20:51:59,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:51:59,390 INFO:     Epoch: 91
2022-11-22 20:52:00,258 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7579394362189553, 'Total loss': 0.7579394362189553} | train loss {'Reaction outcome loss': 0.7592894780008417, 'Total loss': 0.7592894780008417}
2022-11-22 20:52:00,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:00,258 INFO:     Epoch: 92
2022-11-22 20:52:01,110 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7346577773039992, 'Total loss': 0.7346577773039992} | train loss {'Reaction outcome loss': 0.7555325573031236, 'Total loss': 0.7555325573031236}
2022-11-22 20:52:01,110 INFO:     Found new best model at epoch 92
2022-11-22 20:52:01,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:01,111 INFO:     Epoch: 93
2022-11-22 20:52:01,945 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7722983190959151, 'Total loss': 0.7722983190959151} | train loss {'Reaction outcome loss': 0.752669350820997, 'Total loss': 0.752669350820997}
2022-11-22 20:52:01,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:01,946 INFO:     Epoch: 94
2022-11-22 20:52:02,750 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.750042933632027, 'Total loss': 0.750042933632027} | train loss {'Reaction outcome loss': 0.7446580647456984, 'Total loss': 0.7446580647456984}
2022-11-22 20:52:02,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:02,750 INFO:     Epoch: 95
2022-11-22 20:52:03,570 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7384962378577753, 'Total loss': 0.7384962378577753} | train loss {'Reaction outcome loss': 0.7559820671795834, 'Total loss': 0.7559820671795834}
2022-11-22 20:52:03,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:03,571 INFO:     Epoch: 96
2022-11-22 20:52:04,367 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8017064576799219, 'Total loss': 0.8017064576799219} | train loss {'Reaction outcome loss': 0.7616673352023368, 'Total loss': 0.7616673352023368}
2022-11-22 20:52:04,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:04,367 INFO:     Epoch: 97
2022-11-22 20:52:05,154 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7495661709796299, 'Total loss': 0.7495661709796299} | train loss {'Reaction outcome loss': 0.7546028389259871, 'Total loss': 0.7546028389259871}
2022-11-22 20:52:05,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:05,155 INFO:     Epoch: 98
2022-11-22 20:52:05,960 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7637290433049202, 'Total loss': 0.7637290433049202} | train loss {'Reaction outcome loss': 0.745128181057903, 'Total loss': 0.745128181057903}
2022-11-22 20:52:05,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:05,960 INFO:     Epoch: 99
2022-11-22 20:52:06,779 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7793115411292423, 'Total loss': 0.7793115411292423} | train loss {'Reaction outcome loss': 0.7448647159796494, 'Total loss': 0.7448647159796494}
2022-11-22 20:52:06,779 INFO:     Best model found after epoch 93 of 100.
2022-11-22 20:52:06,780 INFO:   Done with stage: TRAINING
2022-11-22 20:52:06,780 INFO:   Starting stage: EVALUATION
2022-11-22 20:52:06,899 INFO:   Done with stage: EVALUATION
2022-11-22 20:52:06,899 INFO:   Leaving out SEQ value Fold_3
2022-11-22 20:52:06,913 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 20:52:06,913 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:52:07,587 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:52:07,587 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:52:07,660 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:52:07,660 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:52:07,660 INFO:     No hyperparam tuning for this model
2022-11-22 20:52:07,660 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:52:07,660 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:52:07,661 INFO:     None feature selector for col prot
2022-11-22 20:52:07,661 INFO:     None feature selector for col prot
2022-11-22 20:52:07,661 INFO:     None feature selector for col prot
2022-11-22 20:52:07,662 INFO:     None feature selector for col chem
2022-11-22 20:52:07,662 INFO:     None feature selector for col chem
2022-11-22 20:52:07,662 INFO:     None feature selector for col chem
2022-11-22 20:52:07,662 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:52:07,662 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:52:07,664 INFO:     Number of params in model 126091
2022-11-22 20:52:07,667 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:52:07,667 INFO:   Starting stage: TRAINING
2022-11-22 20:52:07,721 INFO:     Val loss before train {'Reaction outcome loss': 1.0252107896588065, 'Total loss': 1.0252107896588065}
2022-11-22 20:52:07,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:07,721 INFO:     Epoch: 0
2022-11-22 20:52:08,531 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8202783770181916, 'Total loss': 0.8202783770181916} | train loss {'Reaction outcome loss': 0.8740744532371054, 'Total loss': 0.8740744532371054}
2022-11-22 20:52:08,531 INFO:     Found new best model at epoch 0
2022-11-22 20:52:08,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:08,532 INFO:     Epoch: 1
2022-11-22 20:52:09,374 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8002780296585776, 'Total loss': 0.8002780296585776} | train loss {'Reaction outcome loss': 0.83322928365396, 'Total loss': 0.83322928365396}
2022-11-22 20:52:09,374 INFO:     Found new best model at epoch 1
2022-11-22 20:52:09,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:09,375 INFO:     Epoch: 2
2022-11-22 20:52:10,221 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8156073046001521, 'Total loss': 0.8156073046001521} | train loss {'Reaction outcome loss': 0.8210553194187126, 'Total loss': 0.8210553194187126}
2022-11-22 20:52:10,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:10,222 INFO:     Epoch: 3
2022-11-22 20:52:11,061 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7992105687206442, 'Total loss': 0.7992105687206442} | train loss {'Reaction outcome loss': 0.8121668344857741, 'Total loss': 0.8121668344857741}
2022-11-22 20:52:11,061 INFO:     Found new best model at epoch 3
2022-11-22 20:52:11,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:11,062 INFO:     Epoch: 4
2022-11-22 20:52:11,845 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8132134479555216, 'Total loss': 0.8132134479555216} | train loss {'Reaction outcome loss': 0.8063246197846471, 'Total loss': 0.8063246197846471}
2022-11-22 20:52:11,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:11,846 INFO:     Epoch: 5
2022-11-22 20:52:12,667 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7986459224061533, 'Total loss': 0.7986459224061533} | train loss {'Reaction outcome loss': 0.7990128681367757, 'Total loss': 0.7990128681367757}
2022-11-22 20:52:12,668 INFO:     Found new best model at epoch 5
2022-11-22 20:52:12,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:12,668 INFO:     Epoch: 6
2022-11-22 20:52:13,467 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7847545126622374, 'Total loss': 0.7847545126622374} | train loss {'Reaction outcome loss': 0.7978917941755178, 'Total loss': 0.7978917941755178}
2022-11-22 20:52:13,467 INFO:     Found new best model at epoch 6
2022-11-22 20:52:13,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:13,468 INFO:     Epoch: 7
2022-11-22 20:52:14,249 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7904644662683661, 'Total loss': 0.7904644662683661} | train loss {'Reaction outcome loss': 0.799632986710996, 'Total loss': 0.799632986710996}
2022-11-22 20:52:14,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:14,249 INFO:     Epoch: 8
2022-11-22 20:52:15,085 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7956256859681823, 'Total loss': 0.7956256859681823} | train loss {'Reaction outcome loss': 0.7982627660644298, 'Total loss': 0.7982627660644298}
2022-11-22 20:52:15,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:15,086 INFO:     Epoch: 9
2022-11-22 20:52:15,887 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8265535872090947, 'Total loss': 0.8265535872090947} | train loss {'Reaction outcome loss': 0.7923916097806425, 'Total loss': 0.7923916097806425}
2022-11-22 20:52:15,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:15,887 INFO:     Epoch: 10
2022-11-22 20:52:16,662 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7767826223915274, 'Total loss': 0.7767826223915274} | train loss {'Reaction outcome loss': 0.7936623493019416, 'Total loss': 0.7936623493019416}
2022-11-22 20:52:16,662 INFO:     Found new best model at epoch 10
2022-11-22 20:52:16,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:16,663 INFO:     Epoch: 11
2022-11-22 20:52:17,470 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7940486371517181, 'Total loss': 0.7940486371517181} | train loss {'Reaction outcome loss': 0.7922200639637149, 'Total loss': 0.7922200639637149}
2022-11-22 20:52:17,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:17,470 INFO:     Epoch: 12
2022-11-22 20:52:18,283 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7805525281212546, 'Total loss': 0.7805525281212546} | train loss {'Reaction outcome loss': 0.7918925903281387, 'Total loss': 0.7918925903281387}
2022-11-22 20:52:18,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:18,285 INFO:     Epoch: 13
2022-11-22 20:52:19,060 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8322230712933973, 'Total loss': 0.8322230712933973} | train loss {'Reaction outcome loss': 0.7873299174162807, 'Total loss': 0.7873299174162807}
2022-11-22 20:52:19,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:19,060 INFO:     Epoch: 14
2022-11-22 20:52:19,875 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7951650721105662, 'Total loss': 0.7951650721105662} | train loss {'Reaction outcome loss': 0.7877280437216467, 'Total loss': 0.7877280437216467}
2022-11-22 20:52:19,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:19,875 INFO:     Epoch: 15
2022-11-22 20:52:20,711 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8005254146727648, 'Total loss': 0.8005254146727648} | train loss {'Reaction outcome loss': 0.7891515788983325, 'Total loss': 0.7891515788983325}
2022-11-22 20:52:20,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:20,711 INFO:     Epoch: 16
2022-11-22 20:52:21,507 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8145902441306547, 'Total loss': 0.8145902441306547} | train loss {'Reaction outcome loss': 0.7918488159471628, 'Total loss': 0.7918488159471628}
2022-11-22 20:52:21,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:21,508 INFO:     Epoch: 17
2022-11-22 20:52:22,286 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7818376997655089, 'Total loss': 0.7818376997655089} | train loss {'Reaction outcome loss': 0.7861208539836261, 'Total loss': 0.7861208539836261}
2022-11-22 20:52:22,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:22,286 INFO:     Epoch: 18
2022-11-22 20:52:23,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7971199838952585, 'Total loss': 0.7971199838952585} | train loss {'Reaction outcome loss': 0.7909699566510259, 'Total loss': 0.7909699566510259}
2022-11-22 20:52:23,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:23,066 INFO:     Epoch: 19
2022-11-22 20:52:23,825 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7963959479873831, 'Total loss': 0.7963959479873831} | train loss {'Reaction outcome loss': 0.7855323295812218, 'Total loss': 0.7855323295812218}
2022-11-22 20:52:23,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:23,826 INFO:     Epoch: 20
2022-11-22 20:52:24,642 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7936428406021812, 'Total loss': 0.7936428406021812} | train loss {'Reaction outcome loss': 0.7901699281468684, 'Total loss': 0.7901699281468684}
2022-11-22 20:52:24,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:24,643 INFO:     Epoch: 21
2022-11-22 20:52:25,471 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7804436805573377, 'Total loss': 0.7804436805573377} | train loss {'Reaction outcome loss': 0.7835645082045575, 'Total loss': 0.7835645082045575}
2022-11-22 20:52:25,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:25,471 INFO:     Epoch: 22
2022-11-22 20:52:26,273 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8104731034148823, 'Total loss': 0.8104731034148823} | train loss {'Reaction outcome loss': 0.7856081536837987, 'Total loss': 0.7856081536837987}
2022-11-22 20:52:26,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:26,273 INFO:     Epoch: 23
2022-11-22 20:52:27,071 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7734293416142464, 'Total loss': 0.7734293416142464} | train loss {'Reaction outcome loss': 0.7861942820403041, 'Total loss': 0.7861942820403041}
2022-11-22 20:52:27,071 INFO:     Found new best model at epoch 23
2022-11-22 20:52:27,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:27,072 INFO:     Epoch: 24
2022-11-22 20:52:27,834 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.801747583530166, 'Total loss': 0.801747583530166} | train loss {'Reaction outcome loss': 0.7903041308023492, 'Total loss': 0.7903041308023492}
2022-11-22 20:52:27,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:27,835 INFO:     Epoch: 25
2022-11-22 20:52:28,656 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8184411383487962, 'Total loss': 0.8184411383487962} | train loss {'Reaction outcome loss': 0.7848081670245346, 'Total loss': 0.7848081670245346}
2022-11-22 20:52:28,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:28,656 INFO:     Epoch: 26
2022-11-22 20:52:29,459 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7892019098455255, 'Total loss': 0.7892019098455255} | train loss {'Reaction outcome loss': 0.7848907391027529, 'Total loss': 0.7848907391027529}
2022-11-22 20:52:29,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:29,459 INFO:     Epoch: 27
2022-11-22 20:52:30,272 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7869767594066533, 'Total loss': 0.7869767594066533} | train loss {'Reaction outcome loss': 0.7872706157820565, 'Total loss': 0.7872706157820565}
2022-11-22 20:52:30,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:30,273 INFO:     Epoch: 28
2022-11-22 20:52:31,085 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7745998298579996, 'Total loss': 0.7745998298579996} | train loss {'Reaction outcome loss': 0.7849790539060321, 'Total loss': 0.7849790539060321}
2022-11-22 20:52:31,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:31,086 INFO:     Epoch: 29
2022-11-22 20:52:31,876 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7715979787436399, 'Total loss': 0.7715979787436399} | train loss {'Reaction outcome loss': 0.7821366838046483, 'Total loss': 0.7821366838046483}
2022-11-22 20:52:31,876 INFO:     Found new best model at epoch 29
2022-11-22 20:52:31,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:31,877 INFO:     Epoch: 30
2022-11-22 20:52:32,647 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7910154150290922, 'Total loss': 0.7910154150290922} | train loss {'Reaction outcome loss': 0.7848131733281272, 'Total loss': 0.7848131733281272}
2022-11-22 20:52:32,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:32,647 INFO:     Epoch: 31
2022-11-22 20:52:33,481 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7911593839526176, 'Total loss': 0.7911593839526176} | train loss {'Reaction outcome loss': 0.7853817229368248, 'Total loss': 0.7853817229368248}
2022-11-22 20:52:33,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:33,482 INFO:     Epoch: 32
2022-11-22 20:52:34,267 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8431656773794781, 'Total loss': 0.8431656773794781} | train loss {'Reaction outcome loss': 0.786331025435, 'Total loss': 0.786331025435}
2022-11-22 20:52:34,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:34,267 INFO:     Epoch: 33
2022-11-22 20:52:35,051 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7768946005539461, 'Total loss': 0.7768946005539461} | train loss {'Reaction outcome loss': 0.7836401186427292, 'Total loss': 0.7836401186427292}
2022-11-22 20:52:35,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:35,051 INFO:     Epoch: 34
2022-11-22 20:52:35,840 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7796868390657685, 'Total loss': 0.7796868390657685} | train loss {'Reaction outcome loss': 0.7865321503610027, 'Total loss': 0.7865321503610027}
2022-11-22 20:52:35,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:35,841 INFO:     Epoch: 35
2022-11-22 20:52:36,649 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7809871184554967, 'Total loss': 0.7809871184554967} | train loss {'Reaction outcome loss': 0.7838054523176077, 'Total loss': 0.7838054523176077}
2022-11-22 20:52:36,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:36,649 INFO:     Epoch: 36
2022-11-22 20:52:37,435 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.768741751936349, 'Total loss': 0.768741751936349} | train loss {'Reaction outcome loss': 0.7861913160401948, 'Total loss': 0.7861913160401948}
2022-11-22 20:52:37,435 INFO:     Found new best model at epoch 36
2022-11-22 20:52:37,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:37,436 INFO:     Epoch: 37
2022-11-22 20:52:38,217 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7555106830867854, 'Total loss': 0.7555106830867854} | train loss {'Reaction outcome loss': 0.7833761091134986, 'Total loss': 0.7833761091134986}
2022-11-22 20:52:38,217 INFO:     Found new best model at epoch 37
2022-11-22 20:52:38,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:38,218 INFO:     Epoch: 38
2022-11-22 20:52:39,032 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7878803939304568, 'Total loss': 0.7878803939304568} | train loss {'Reaction outcome loss': 0.7822189979407252, 'Total loss': 0.7822189979407252}
2022-11-22 20:52:39,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:39,033 INFO:     Epoch: 39
2022-11-22 20:52:39,790 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8082503093914553, 'Total loss': 0.8082503093914553} | train loss {'Reaction outcome loss': 0.7839143560857189, 'Total loss': 0.7839143560857189}
2022-11-22 20:52:39,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:39,790 INFO:     Epoch: 40
2022-11-22 20:52:40,609 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7832958434115757, 'Total loss': 0.7832958434115757} | train loss {'Reaction outcome loss': 0.7859041417131618, 'Total loss': 0.7859041417131618}
2022-11-22 20:52:40,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:40,609 INFO:     Epoch: 41
2022-11-22 20:52:41,390 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.772020548582077, 'Total loss': 0.772020548582077} | train loss {'Reaction outcome loss': 0.7852613254469268, 'Total loss': 0.7852613254469268}
2022-11-22 20:52:41,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:41,390 INFO:     Epoch: 42
2022-11-22 20:52:42,171 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.784511608156291, 'Total loss': 0.784511608156291} | train loss {'Reaction outcome loss': 0.780572336790513, 'Total loss': 0.780572336790513}
2022-11-22 20:52:42,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:42,171 INFO:     Epoch: 43
2022-11-22 20:52:42,934 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7895049574700269, 'Total loss': 0.7895049574700269} | train loss {'Reaction outcome loss': 0.782683590966828, 'Total loss': 0.782683590966828}
2022-11-22 20:52:42,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:42,934 INFO:     Epoch: 44
2022-11-22 20:52:43,717 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7833985923366114, 'Total loss': 0.7833985923366114} | train loss {'Reaction outcome loss': 0.7885960370302201, 'Total loss': 0.7885960370302201}
2022-11-22 20:52:43,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:43,718 INFO:     Epoch: 45
2022-11-22 20:52:44,474 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7898600142110478, 'Total loss': 0.7898600142110478} | train loss {'Reaction outcome loss': 0.7773287681900725, 'Total loss': 0.7773287681900725}
2022-11-22 20:52:44,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:44,475 INFO:     Epoch: 46
2022-11-22 20:52:45,263 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8032382320274006, 'Total loss': 0.8032382320274006} | train loss {'Reaction outcome loss': 0.7789415678807667, 'Total loss': 0.7789415678807667}
2022-11-22 20:52:45,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:45,263 INFO:     Epoch: 47
2022-11-22 20:52:46,049 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7987613833763383, 'Total loss': 0.7987613833763383} | train loss {'Reaction outcome loss': 0.7821972357983492, 'Total loss': 0.7821972357983492}
2022-11-22 20:52:46,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:46,049 INFO:     Epoch: 48
2022-11-22 20:52:46,865 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7732127627188509, 'Total loss': 0.7732127627188509} | train loss {'Reaction outcome loss': 0.7803315719779657, 'Total loss': 0.7803315719779657}
2022-11-22 20:52:46,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:46,866 INFO:     Epoch: 49
2022-11-22 20:52:47,639 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7671540650454435, 'Total loss': 0.7671540650454435} | train loss {'Reaction outcome loss': 0.7857154293936126, 'Total loss': 0.7857154293936126}
2022-11-22 20:52:47,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:47,639 INFO:     Epoch: 50
2022-11-22 20:52:48,462 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7799059254201975, 'Total loss': 0.7799059254201975} | train loss {'Reaction outcome loss': 0.7797344595802074, 'Total loss': 0.7797344595802074}
2022-11-22 20:52:48,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:48,462 INFO:     Epoch: 51
2022-11-22 20:52:49,250 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8049437640742823, 'Total loss': 0.8049437640742823} | train loss {'Reaction outcome loss': 0.7790014569856683, 'Total loss': 0.7790014569856683}
2022-11-22 20:52:49,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:49,250 INFO:     Epoch: 52
2022-11-22 20:52:50,066 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7784746634689245, 'Total loss': 0.7784746634689245} | train loss {'Reaction outcome loss': 0.7820934541371404, 'Total loss': 0.7820934541371404}
2022-11-22 20:52:50,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:50,067 INFO:     Epoch: 53
2022-11-22 20:52:50,849 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7851267260583964, 'Total loss': 0.7851267260583964} | train loss {'Reaction outcome loss': 0.7801981085417222, 'Total loss': 0.7801981085417222}
2022-11-22 20:52:50,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:50,850 INFO:     Epoch: 54
2022-11-22 20:52:51,628 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7840120060877367, 'Total loss': 0.7840120060877367} | train loss {'Reaction outcome loss': 0.7786191100976905, 'Total loss': 0.7786191100976905}
2022-11-22 20:52:51,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:51,629 INFO:     Epoch: 55
2022-11-22 20:52:52,421 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7648525434461507, 'Total loss': 0.7648525434461507} | train loss {'Reaction outcome loss': 0.7840612524626206, 'Total loss': 0.7840612524626206}
2022-11-22 20:52:52,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:52,422 INFO:     Epoch: 56
2022-11-22 20:52:53,213 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7923228761011903, 'Total loss': 0.7923228761011903} | train loss {'Reaction outcome loss': 0.781173842658802, 'Total loss': 0.781173842658802}
2022-11-22 20:52:53,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:53,213 INFO:     Epoch: 57
2022-11-22 20:52:53,965 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7774002592672001, 'Total loss': 0.7774002592672001} | train loss {'Reaction outcome loss': 0.7807448726527545, 'Total loss': 0.7807448726527545}
2022-11-22 20:52:53,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:53,965 INFO:     Epoch: 58
2022-11-22 20:52:54,722 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7689266529950228, 'Total loss': 0.7689266529950228} | train loss {'Reaction outcome loss': 0.7793580428678162, 'Total loss': 0.7793580428678162}
2022-11-22 20:52:54,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:54,722 INFO:     Epoch: 59
2022-11-22 20:52:55,513 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7774712070822716, 'Total loss': 0.7774712070822716} | train loss {'Reaction outcome loss': 0.7811221420764923, 'Total loss': 0.7811221420764923}
2022-11-22 20:52:55,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:55,514 INFO:     Epoch: 60
2022-11-22 20:52:56,282 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8010614934292707, 'Total loss': 0.8010614934292707} | train loss {'Reaction outcome loss': 0.7794590788228172, 'Total loss': 0.7794590788228172}
2022-11-22 20:52:56,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:56,283 INFO:     Epoch: 61
2022-11-22 20:52:57,049 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7685080428015102, 'Total loss': 0.7685080428015102} | train loss {'Reaction outcome loss': 0.7817502991885555, 'Total loss': 0.7817502991885555}
2022-11-22 20:52:57,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:57,050 INFO:     Epoch: 62
2022-11-22 20:52:57,816 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7682197601957754, 'Total loss': 0.7682197601957754} | train loss {'Reaction outcome loss': 0.7854230919662787, 'Total loss': 0.7854230919662787}
2022-11-22 20:52:57,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:57,816 INFO:     Epoch: 63
2022-11-22 20:52:58,614 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7757431824098934, 'Total loss': 0.7757431824098934} | train loss {'Reaction outcome loss': 0.7787424346622156, 'Total loss': 0.7787424346622156}
2022-11-22 20:52:58,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:58,615 INFO:     Epoch: 64
2022-11-22 20:52:59,374 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7767059511759065, 'Total loss': 0.7767059511759065} | train loss {'Reaction outcome loss': 0.7769563415829016, 'Total loss': 0.7769563415829016}
2022-11-22 20:52:59,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:52:59,374 INFO:     Epoch: 65
2022-11-22 20:53:00,183 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8183726817369461, 'Total loss': 0.8183726817369461} | train loss {'Reaction outcome loss': 0.7784761042011027, 'Total loss': 0.7784761042011027}
2022-11-22 20:53:00,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:00,183 INFO:     Epoch: 66
2022-11-22 20:53:00,940 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7965627272020687, 'Total loss': 0.7965627272020687} | train loss {'Reaction outcome loss': 0.7803693925847812, 'Total loss': 0.7803693925847812}
2022-11-22 20:53:00,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:00,940 INFO:     Epoch: 67
2022-11-22 20:53:01,752 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7681187133897435, 'Total loss': 0.7681187133897435} | train loss {'Reaction outcome loss': 0.7830743703306938, 'Total loss': 0.7830743703306938}
2022-11-22 20:53:01,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:01,753 INFO:     Epoch: 68
2022-11-22 20:53:02,533 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8396383821964264, 'Total loss': 0.8396383821964264} | train loss {'Reaction outcome loss': 0.7780795282247115, 'Total loss': 0.7780795282247115}
2022-11-22 20:53:02,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:02,535 INFO:     Epoch: 69
2022-11-22 20:53:03,341 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7836866656487639, 'Total loss': 0.7836866656487639} | train loss {'Reaction outcome loss': 0.7796977161144724, 'Total loss': 0.7796977161144724}
2022-11-22 20:53:03,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:03,342 INFO:     Epoch: 70
2022-11-22 20:53:04,120 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7868297858671709, 'Total loss': 0.7868297858671709} | train loss {'Reaction outcome loss': 0.7787900588950333, 'Total loss': 0.7787900588950333}
2022-11-22 20:53:04,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:04,120 INFO:     Epoch: 71
2022-11-22 20:53:04,886 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7975368120453574, 'Total loss': 0.7975368120453574} | train loss {'Reaction outcome loss': 0.7831211933067866, 'Total loss': 0.7831211933067866}
2022-11-22 20:53:04,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:04,886 INFO:     Epoch: 72
2022-11-22 20:53:05,613 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7779202488335696, 'Total loss': 0.7779202488335696} | train loss {'Reaction outcome loss': 0.7719539281665062, 'Total loss': 0.7719539281665062}
2022-11-22 20:53:05,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:05,614 INFO:     Epoch: 73
2022-11-22 20:53:06,417 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7592103047804399, 'Total loss': 0.7592103047804399} | train loss {'Reaction outcome loss': 0.7782400965690612, 'Total loss': 0.7782400965690612}
2022-11-22 20:53:06,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:06,417 INFO:     Epoch: 74
2022-11-22 20:53:07,145 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7908734394745394, 'Total loss': 0.7908734394745394} | train loss {'Reaction outcome loss': 0.7810020576934426, 'Total loss': 0.7810020576934426}
2022-11-22 20:53:07,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:07,145 INFO:     Epoch: 75
2022-11-22 20:53:07,903 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7831165472214873, 'Total loss': 0.7831165472214873} | train loss {'Reaction outcome loss': 0.7814527824216959, 'Total loss': 0.7814527824216959}
2022-11-22 20:53:07,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:07,904 INFO:     Epoch: 76
2022-11-22 20:53:08,646 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8147752691398967, 'Total loss': 0.8147752691398967} | train loss {'Reaction outcome loss': 0.7734807341682668, 'Total loss': 0.7734807341682668}
2022-11-22 20:53:08,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:08,647 INFO:     Epoch: 77
2022-11-22 20:53:09,356 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7557984218001366, 'Total loss': 0.7557984218001366} | train loss {'Reaction outcome loss': 0.7761527124716311, 'Total loss': 0.7761527124716311}
2022-11-22 20:53:09,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:09,357 INFO:     Epoch: 78
2022-11-22 20:53:10,085 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7742864469235594, 'Total loss': 0.7742864469235594} | train loss {'Reaction outcome loss': 0.7761683224415292, 'Total loss': 0.7761683224415292}
2022-11-22 20:53:10,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:10,085 INFO:     Epoch: 79
2022-11-22 20:53:10,795 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7890634875405919, 'Total loss': 0.7890634875405919} | train loss {'Reaction outcome loss': 0.7782770043733168, 'Total loss': 0.7782770043733168}
2022-11-22 20:53:10,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:10,795 INFO:     Epoch: 80
2022-11-22 20:53:11,564 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.78879475729032, 'Total loss': 0.78879475729032} | train loss {'Reaction outcome loss': 0.7755537117014126, 'Total loss': 0.7755537117014126}
2022-11-22 20:53:11,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:11,564 INFO:     Epoch: 81
2022-11-22 20:53:12,307 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.779582220045003, 'Total loss': 0.779582220045003} | train loss {'Reaction outcome loss': 0.7741894006729126, 'Total loss': 0.7741894006729126}
2022-11-22 20:53:12,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:12,307 INFO:     Epoch: 82
2022-11-22 20:53:13,045 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7824054299430414, 'Total loss': 0.7824054299430414} | train loss {'Reaction outcome loss': 0.7745253581173566, 'Total loss': 0.7745253581173566}
2022-11-22 20:53:13,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:13,046 INFO:     Epoch: 83
2022-11-22 20:53:13,767 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7779980789531361, 'Total loss': 0.7779980789531361} | train loss {'Reaction outcome loss': 0.7715825431200922, 'Total loss': 0.7715825431200922}
2022-11-22 20:53:13,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:13,768 INFO:     Epoch: 84
2022-11-22 20:53:14,490 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7916539988734506, 'Total loss': 0.7916539988734506} | train loss {'Reaction outcome loss': 0.7809429438746706, 'Total loss': 0.7809429438746706}
2022-11-22 20:53:14,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:14,491 INFO:     Epoch: 85
2022-11-22 20:53:15,237 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7657613435929472, 'Total loss': 0.7657613435929472} | train loss {'Reaction outcome loss': 0.7786737997921146, 'Total loss': 0.7786737997921146}
2022-11-22 20:53:15,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:15,237 INFO:     Epoch: 86
2022-11-22 20:53:15,996 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7826826762069355, 'Total loss': 0.7826826762069355} | train loss {'Reaction outcome loss': 0.7763409280047124, 'Total loss': 0.7763409280047124}
2022-11-22 20:53:15,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:15,996 INFO:     Epoch: 87
2022-11-22 20:53:16,785 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7869561626152559, 'Total loss': 0.7869561626152559} | train loss {'Reaction outcome loss': 0.7748175784033172, 'Total loss': 0.7748175784033172}
2022-11-22 20:53:16,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:16,785 INFO:     Epoch: 88
2022-11-22 20:53:17,534 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7735223282467235, 'Total loss': 0.7735223282467235} | train loss {'Reaction outcome loss': 0.7728680120438945, 'Total loss': 0.7728680120438945}
2022-11-22 20:53:17,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:17,534 INFO:     Epoch: 89
2022-11-22 20:53:18,278 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7736988690766421, 'Total loss': 0.7736988690766421} | train loss {'Reaction outcome loss': 0.7753271821810275, 'Total loss': 0.7753271821810275}
2022-11-22 20:53:18,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:18,278 INFO:     Epoch: 90
2022-11-22 20:53:19,030 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7694075364958156, 'Total loss': 0.7694075364958156} | train loss {'Reaction outcome loss': 0.7698652600755497, 'Total loss': 0.7698652600755497}
2022-11-22 20:53:19,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:19,031 INFO:     Epoch: 91
2022-11-22 20:53:19,809 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8240497003902089, 'Total loss': 0.8240497003902089} | train loss {'Reaction outcome loss': 0.7743928038344091, 'Total loss': 0.7743928038344091}
2022-11-22 20:53:19,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:19,810 INFO:     Epoch: 92
2022-11-22 20:53:20,533 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7938584278930317, 'Total loss': 0.7938584278930317} | train loss {'Reaction outcome loss': 0.7722568935277511, 'Total loss': 0.7722568935277511}
2022-11-22 20:53:20,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:20,534 INFO:     Epoch: 93
2022-11-22 20:53:21,244 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7786461304534565, 'Total loss': 0.7786461304534565} | train loss {'Reaction outcome loss': 0.7712192526885442, 'Total loss': 0.7712192526885442}
2022-11-22 20:53:21,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:21,244 INFO:     Epoch: 94
2022-11-22 20:53:22,016 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7720540145581419, 'Total loss': 0.7720540145581419} | train loss {'Reaction outcome loss': 0.7728293915184177, 'Total loss': 0.7728293915184177}
2022-11-22 20:53:22,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:22,017 INFO:     Epoch: 95
2022-11-22 20:53:22,775 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7802101990038698, 'Total loss': 0.7802101990038698} | train loss {'Reaction outcome loss': 0.7691050674234118, 'Total loss': 0.7691050674234118}
2022-11-22 20:53:22,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:22,775 INFO:     Epoch: 96
2022-11-22 20:53:23,544 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7985550165176392, 'Total loss': 0.7985550165176392} | train loss {'Reaction outcome loss': 0.7732896664921118, 'Total loss': 0.7732896664921118}
2022-11-22 20:53:23,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:23,544 INFO:     Epoch: 97
2022-11-22 20:53:24,322 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7780297114090486, 'Total loss': 0.7780297114090486} | train loss {'Reaction outcome loss': 0.7688130232752586, 'Total loss': 0.7688130232752586}
2022-11-22 20:53:24,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:24,322 INFO:     Epoch: 98
2022-11-22 20:53:25,102 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7831497436219995, 'Total loss': 0.7831497436219995} | train loss {'Reaction outcome loss': 0.7728681924391766, 'Total loss': 0.7728681924391766}
2022-11-22 20:53:25,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:25,102 INFO:     Epoch: 99
2022-11-22 20:53:25,842 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7891906567595222, 'Total loss': 0.7891906567595222} | train loss {'Reaction outcome loss': 0.7604640701595617, 'Total loss': 0.7604640701595617}
2022-11-22 20:53:25,842 INFO:     Best model found after epoch 38 of 100.
2022-11-22 20:53:25,842 INFO:   Done with stage: TRAINING
2022-11-22 20:53:25,842 INFO:   Starting stage: EVALUATION
2022-11-22 20:53:25,968 INFO:   Done with stage: EVALUATION
2022-11-22 20:53:25,969 INFO:   Leaving out SEQ value Fold_4
2022-11-22 20:53:25,982 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:53:25,982 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:53:26,652 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:53:26,652 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:53:26,721 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:53:26,722 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:53:26,722 INFO:     No hyperparam tuning for this model
2022-11-22 20:53:26,722 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:53:26,722 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:53:26,722 INFO:     None feature selector for col prot
2022-11-22 20:53:26,723 INFO:     None feature selector for col prot
2022-11-22 20:53:26,723 INFO:     None feature selector for col prot
2022-11-22 20:53:26,723 INFO:     None feature selector for col chem
2022-11-22 20:53:26,723 INFO:     None feature selector for col chem
2022-11-22 20:53:26,724 INFO:     None feature selector for col chem
2022-11-22 20:53:26,724 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:53:26,724 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:53:26,725 INFO:     Number of params in model 126091
2022-11-22 20:53:26,728 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:53:26,728 INFO:   Starting stage: TRAINING
2022-11-22 20:53:26,777 INFO:     Val loss before train {'Reaction outcome loss': 1.0030389861627058, 'Total loss': 1.0030389861627058}
2022-11-22 20:53:26,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:26,778 INFO:     Epoch: 0
2022-11-22 20:53:27,524 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8417526009407911, 'Total loss': 0.8417526009407911} | train loss {'Reaction outcome loss': 0.8874205537894477, 'Total loss': 0.8874205537894477}
2022-11-22 20:53:27,524 INFO:     Found new best model at epoch 0
2022-11-22 20:53:27,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:27,525 INFO:     Epoch: 1
2022-11-22 20:53:28,339 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8287524194879965, 'Total loss': 0.8287524194879965} | train loss {'Reaction outcome loss': 0.8605013739483559, 'Total loss': 0.8605013739483559}
2022-11-22 20:53:28,339 INFO:     Found new best model at epoch 1
2022-11-22 20:53:28,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:28,340 INFO:     Epoch: 2
2022-11-22 20:53:29,088 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8072074015032161, 'Total loss': 0.8072074015032161} | train loss {'Reaction outcome loss': 0.8435813067895681, 'Total loss': 0.8435813067895681}
2022-11-22 20:53:29,088 INFO:     Found new best model at epoch 2
2022-11-22 20:53:29,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:29,089 INFO:     Epoch: 3
2022-11-22 20:53:29,822 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8052353980866346, 'Total loss': 0.8052353980866346} | train loss {'Reaction outcome loss': 0.839566243322272, 'Total loss': 0.839566243322272}
2022-11-22 20:53:29,822 INFO:     Found new best model at epoch 3
2022-11-22 20:53:29,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:29,823 INFO:     Epoch: 4
2022-11-22 20:53:30,580 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7818258892406117, 'Total loss': 0.7818258892406117} | train loss {'Reaction outcome loss': 0.8329963071143579, 'Total loss': 0.8329963071143579}
2022-11-22 20:53:30,581 INFO:     Found new best model at epoch 4
2022-11-22 20:53:30,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:30,581 INFO:     Epoch: 5
2022-11-22 20:53:31,307 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7929064868526026, 'Total loss': 0.7929064868526026} | train loss {'Reaction outcome loss': 0.8200314501941446, 'Total loss': 0.8200314501941446}
2022-11-22 20:53:31,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:31,307 INFO:     Epoch: 6
2022-11-22 20:53:32,068 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7966396300630136, 'Total loss': 0.7966396300630136} | train loss {'Reaction outcome loss': 0.8246262898359463, 'Total loss': 0.8246262898359463}
2022-11-22 20:53:32,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:32,068 INFO:     Epoch: 7
2022-11-22 20:53:32,795 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7784965702078559, 'Total loss': 0.7784965702078559} | train loss {'Reaction outcome loss': 0.8246099761864434, 'Total loss': 0.8246099761864434}
2022-11-22 20:53:32,796 INFO:     Found new best model at epoch 7
2022-11-22 20:53:32,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:32,797 INFO:     Epoch: 8
2022-11-22 20:53:33,559 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8009037253531542, 'Total loss': 0.8009037253531542} | train loss {'Reaction outcome loss': 0.8213693039861285, 'Total loss': 0.8213693039861285}
2022-11-22 20:53:33,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:33,560 INFO:     Epoch: 9
2022-11-22 20:53:34,292 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7904995625669305, 'Total loss': 0.7904995625669305} | train loss {'Reaction outcome loss': 0.815216443557971, 'Total loss': 0.815216443557971}
2022-11-22 20:53:34,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:34,292 INFO:     Epoch: 10
2022-11-22 20:53:35,041 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7803958159956065, 'Total loss': 0.7803958159956065} | train loss {'Reaction outcome loss': 0.8243290977439417, 'Total loss': 0.8243290977439417}
2022-11-22 20:53:35,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:35,041 INFO:     Epoch: 11
2022-11-22 20:53:35,819 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8129105764356527, 'Total loss': 0.8129105764356527} | train loss {'Reaction outcome loss': 0.8213608100829337, 'Total loss': 0.8213608100829337}
2022-11-22 20:53:35,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:35,820 INFO:     Epoch: 12
2022-11-22 20:53:36,602 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7848877405578439, 'Total loss': 0.7848877405578439} | train loss {'Reaction outcome loss': 0.8131947365366978, 'Total loss': 0.8131947365366978}
2022-11-22 20:53:36,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:36,602 INFO:     Epoch: 13
2022-11-22 20:53:37,363 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8152291293848645, 'Total loss': 0.8152291293848645} | train loss {'Reaction outcome loss': 0.8141948340634103, 'Total loss': 0.8141948340634103}
2022-11-22 20:53:37,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:37,363 INFO:     Epoch: 14
2022-11-22 20:53:38,136 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.805564590475776, 'Total loss': 0.805564590475776} | train loss {'Reaction outcome loss': 0.8181962719571735, 'Total loss': 0.8181962719571735}
2022-11-22 20:53:38,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:38,136 INFO:     Epoch: 15
2022-11-22 20:53:38,904 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7810108722610907, 'Total loss': 0.7810108722610907} | train loss {'Reaction outcome loss': 0.8108464456521548, 'Total loss': 0.8108464456521548}
2022-11-22 20:53:38,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:38,904 INFO:     Epoch: 16
2022-11-22 20:53:39,604 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7708538161082701, 'Total loss': 0.7708538161082701} | train loss {'Reaction outcome loss': 0.806700176955295, 'Total loss': 0.806700176955295}
2022-11-22 20:53:39,604 INFO:     Found new best model at epoch 16
2022-11-22 20:53:39,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:39,605 INFO:     Epoch: 17
2022-11-22 20:53:40,363 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7875747985460542, 'Total loss': 0.7875747985460542} | train loss {'Reaction outcome loss': 0.8071778955367895, 'Total loss': 0.8071778955367895}
2022-11-22 20:53:40,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:40,363 INFO:     Epoch: 18
2022-11-22 20:53:41,086 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7773343121463602, 'Total loss': 0.7773343121463602} | train loss {'Reaction outcome loss': 0.8071664294250581, 'Total loss': 0.8071664294250581}
2022-11-22 20:53:41,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:41,087 INFO:     Epoch: 19
2022-11-22 20:53:41,819 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7925644049590285, 'Total loss': 0.7925644049590285} | train loss {'Reaction outcome loss': 0.8127608091725029, 'Total loss': 0.8127608091725029}
2022-11-22 20:53:41,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:41,819 INFO:     Epoch: 20
2022-11-22 20:53:42,581 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.804518075151877, 'Total loss': 0.804518075151877} | train loss {'Reaction outcome loss': 0.8043233427381226, 'Total loss': 0.8043233427381226}
2022-11-22 20:53:42,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:42,581 INFO:     Epoch: 21
2022-11-22 20:53:43,295 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.79814174906774, 'Total loss': 0.79814174906774} | train loss {'Reaction outcome loss': 0.8089997118059923, 'Total loss': 0.8089997118059923}
2022-11-22 20:53:43,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:43,295 INFO:     Epoch: 22
2022-11-22 20:53:44,090 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7797496542334557, 'Total loss': 0.7797496542334557} | train loss {'Reaction outcome loss': 0.8061818855132169, 'Total loss': 0.8061818855132169}
2022-11-22 20:53:44,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:44,090 INFO:     Epoch: 23
2022-11-22 20:53:44,847 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7698421481658112, 'Total loss': 0.7698421481658112} | train loss {'Reaction outcome loss': 0.8084501544775268, 'Total loss': 0.8084501544775268}
2022-11-22 20:53:44,848 INFO:     Found new best model at epoch 23
2022-11-22 20:53:44,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:44,848 INFO:     Epoch: 24
2022-11-22 20:53:45,616 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8067099783908237, 'Total loss': 0.8067099783908237} | train loss {'Reaction outcome loss': 0.8060184472244278, 'Total loss': 0.8060184472244278}
2022-11-22 20:53:45,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:45,617 INFO:     Epoch: 25
2022-11-22 20:53:46,381 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7926419892094352, 'Total loss': 0.7926419892094352} | train loss {'Reaction outcome loss': 0.8156202615272661, 'Total loss': 0.8156202615272661}
2022-11-22 20:53:46,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:46,381 INFO:     Epoch: 26
2022-11-22 20:53:47,107 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8088205538012765, 'Total loss': 0.8088205538012765} | train loss {'Reaction outcome loss': 0.7994195514392515, 'Total loss': 0.7994195514392515}
2022-11-22 20:53:47,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:47,107 INFO:     Epoch: 27
2022-11-22 20:53:47,856 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7807017886503176, 'Total loss': 0.7807017886503176} | train loss {'Reaction outcome loss': 0.7990752584659137, 'Total loss': 0.7990752584659137}
2022-11-22 20:53:47,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:47,856 INFO:     Epoch: 28
2022-11-22 20:53:48,583 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.796180784702301, 'Total loss': 0.796180784702301} | train loss {'Reaction outcome loss': 0.8049648237614496, 'Total loss': 0.8049648237614496}
2022-11-22 20:53:48,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:48,583 INFO:     Epoch: 29
2022-11-22 20:53:49,351 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7632672983137044, 'Total loss': 0.7632672983137044} | train loss {'Reaction outcome loss': 0.8040266928643833, 'Total loss': 0.8040266928643833}
2022-11-22 20:53:49,351 INFO:     Found new best model at epoch 29
2022-11-22 20:53:49,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:49,352 INFO:     Epoch: 30
2022-11-22 20:53:50,101 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7694224207238718, 'Total loss': 0.7694224207238718} | train loss {'Reaction outcome loss': 0.8015642485879211, 'Total loss': 0.8015642485879211}
2022-11-22 20:53:50,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:50,101 INFO:     Epoch: 31
2022-11-22 20:53:50,855 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7795539857311682, 'Total loss': 0.7795539857311682} | train loss {'Reaction outcome loss': 0.8074705429405336, 'Total loss': 0.8074705429405336}
2022-11-22 20:53:50,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:50,855 INFO:     Epoch: 32
2022-11-22 20:53:51,630 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7835770845413208, 'Total loss': 0.7835770845413208} | train loss {'Reaction outcome loss': 0.8144177252705763, 'Total loss': 0.8144177252705763}
2022-11-22 20:53:51,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:51,631 INFO:     Epoch: 33
2022-11-22 20:53:52,366 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7737742648883299, 'Total loss': 0.7737742648883299} | train loss {'Reaction outcome loss': 0.800601878388208, 'Total loss': 0.800601878388208}
2022-11-22 20:53:52,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:52,367 INFO:     Epoch: 34
2022-11-22 20:53:53,116 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7688229382038116, 'Total loss': 0.7688229382038116} | train loss {'Reaction outcome loss': 0.8013987039264879, 'Total loss': 0.8013987039264879}
2022-11-22 20:53:53,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:53,116 INFO:     Epoch: 35
2022-11-22 20:53:53,826 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7553615617481145, 'Total loss': 0.7553615617481145} | train loss {'Reaction outcome loss': 0.8050427111054239, 'Total loss': 0.8050427111054239}
2022-11-22 20:53:53,827 INFO:     Found new best model at epoch 35
2022-11-22 20:53:53,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:53,827 INFO:     Epoch: 36
2022-11-22 20:53:54,543 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.771055054935542, 'Total loss': 0.771055054935542} | train loss {'Reaction outcome loss': 0.7999400117016031, 'Total loss': 0.7999400117016031}
2022-11-22 20:53:54,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:54,543 INFO:     Epoch: 37
2022-11-22 20:53:55,278 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.771810261363333, 'Total loss': 0.771810261363333} | train loss {'Reaction outcome loss': 0.8022593393740867, 'Total loss': 0.8022593393740867}
2022-11-22 20:53:55,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:55,279 INFO:     Epoch: 38
2022-11-22 20:53:56,053 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8343580480326306, 'Total loss': 0.8343580480326306} | train loss {'Reaction outcome loss': 0.8001852093437906, 'Total loss': 0.8001852093437906}
2022-11-22 20:53:56,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:56,053 INFO:     Epoch: 39
2022-11-22 20:53:56,783 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7935466353188861, 'Total loss': 0.7935466353188861} | train loss {'Reaction outcome loss': 0.8028695369780305, 'Total loss': 0.8028695369780305}
2022-11-22 20:53:56,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:56,784 INFO:     Epoch: 40
2022-11-22 20:53:57,507 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7980537942864678, 'Total loss': 0.7980537942864678} | train loss {'Reaction outcome loss': 0.8045781201679214, 'Total loss': 0.8045781201679214}
2022-11-22 20:53:57,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:57,507 INFO:     Epoch: 41
2022-11-22 20:53:58,213 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7642048624428835, 'Total loss': 0.7642048624428835} | train loss {'Reaction outcome loss': 0.80212829035786, 'Total loss': 0.80212829035786}
2022-11-22 20:53:58,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:58,213 INFO:     Epoch: 42
2022-11-22 20:53:58,938 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7667099962180312, 'Total loss': 0.7667099962180312} | train loss {'Reaction outcome loss': 0.8048171750929675, 'Total loss': 0.8048171750929675}
2022-11-22 20:53:58,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:58,938 INFO:     Epoch: 43
2022-11-22 20:53:59,687 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7916877919977362, 'Total loss': 0.7916877919977362} | train loss {'Reaction outcome loss': 0.7955455048846812, 'Total loss': 0.7955455048846812}
2022-11-22 20:53:59,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:53:59,687 INFO:     Epoch: 44
2022-11-22 20:54:00,436 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7629747201095928, 'Total loss': 0.7629747201095928} | train loss {'Reaction outcome loss': 0.8022798973056469, 'Total loss': 0.8022798973056469}
2022-11-22 20:54:00,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:00,436 INFO:     Epoch: 45
2022-11-22 20:54:01,180 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7818127409978346, 'Total loss': 0.7818127409978346} | train loss {'Reaction outcome loss': 0.7949382567453963, 'Total loss': 0.7949382567453963}
2022-11-22 20:54:01,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:01,180 INFO:     Epoch: 46
2022-11-22 20:54:01,911 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7948004786263813, 'Total loss': 0.7948004786263813} | train loss {'Reaction outcome loss': 0.8050340634849873, 'Total loss': 0.8050340634849873}
2022-11-22 20:54:01,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:01,912 INFO:     Epoch: 47
2022-11-22 20:54:02,663 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7751510346477682, 'Total loss': 0.7751510346477682} | train loss {'Reaction outcome loss': 0.8024039612366602, 'Total loss': 0.8024039612366602}
2022-11-22 20:54:02,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:02,663 INFO:     Epoch: 48
2022-11-22 20:54:03,429 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7761537161740389, 'Total loss': 0.7761537161740389} | train loss {'Reaction outcome loss': 0.8051461079101331, 'Total loss': 0.8051461079101331}
2022-11-22 20:54:03,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:03,430 INFO:     Epoch: 49
2022-11-22 20:54:04,217 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7717320763251998, 'Total loss': 0.7717320763251998} | train loss {'Reaction outcome loss': 0.8053980900449791, 'Total loss': 0.8053980900449791}
2022-11-22 20:54:04,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:04,218 INFO:     Epoch: 50
2022-11-22 20:54:04,968 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7561666931618344, 'Total loss': 0.7561666931618344} | train loss {'Reaction outcome loss': 0.7953368920666969, 'Total loss': 0.7953368920666969}
2022-11-22 20:54:04,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:04,968 INFO:     Epoch: 51
2022-11-22 20:54:05,702 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7586859904906966, 'Total loss': 0.7586859904906966} | train loss {'Reaction outcome loss': 0.7960297216167335, 'Total loss': 0.7960297216167335}
2022-11-22 20:54:05,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:05,703 INFO:     Epoch: 52
2022-11-22 20:54:06,470 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7843421656977047, 'Total loss': 0.7843421656977047} | train loss {'Reaction outcome loss': 0.7980303059705356, 'Total loss': 0.7980303059705356}
2022-11-22 20:54:06,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:06,470 INFO:     Epoch: 53
2022-11-22 20:54:07,242 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7708408453247764, 'Total loss': 0.7708408453247764} | train loss {'Reaction outcome loss': 0.8050745629105973, 'Total loss': 0.8050745629105973}
2022-11-22 20:54:07,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:07,243 INFO:     Epoch: 54
2022-11-22 20:54:08,008 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7816151719201695, 'Total loss': 0.7816151719201695} | train loss {'Reaction outcome loss': 0.7947983553836703, 'Total loss': 0.7947983553836703}
2022-11-22 20:54:08,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:08,009 INFO:     Epoch: 55
2022-11-22 20:54:08,716 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7671063427220691, 'Total loss': 0.7671063427220691} | train loss {'Reaction outcome loss': 0.7947451205630052, 'Total loss': 0.7947451205630052}
2022-11-22 20:54:08,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:08,716 INFO:     Epoch: 56
2022-11-22 20:54:09,488 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7685397389260206, 'Total loss': 0.7685397389260206} | train loss {'Reaction outcome loss': 0.7920381345216804, 'Total loss': 0.7920381345216804}
2022-11-22 20:54:09,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:09,488 INFO:     Epoch: 57
2022-11-22 20:54:10,293 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7747567255388607, 'Total loss': 0.7747567255388607} | train loss {'Reaction outcome loss': 0.7982922811739841, 'Total loss': 0.7982922811739841}
2022-11-22 20:54:10,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:10,293 INFO:     Epoch: 58
2022-11-22 20:54:11,028 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7925543642856858, 'Total loss': 0.7925543642856858} | train loss {'Reaction outcome loss': 0.7973907598358417, 'Total loss': 0.7973907598358417}
2022-11-22 20:54:11,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:11,028 INFO:     Epoch: 59
2022-11-22 20:54:11,815 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7722211663018573, 'Total loss': 0.7722211663018573} | train loss {'Reaction outcome loss': 0.7981564719908634, 'Total loss': 0.7981564719908634}
2022-11-22 20:54:11,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:11,815 INFO:     Epoch: 60
2022-11-22 20:54:12,580 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7580638852986422, 'Total loss': 0.7580638852986422} | train loss {'Reaction outcome loss': 0.7964456200840985, 'Total loss': 0.7964456200840985}
2022-11-22 20:54:12,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:12,581 INFO:     Epoch: 61
2022-11-22 20:54:13,336 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7921964458443902, 'Total loss': 0.7921964458443902} | train loss {'Reaction outcome loss': 0.7983562356305991, 'Total loss': 0.7983562356305991}
2022-11-22 20:54:13,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:13,337 INFO:     Epoch: 62
2022-11-22 20:54:14,062 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7737370878458023, 'Total loss': 0.7737370878458023} | train loss {'Reaction outcome loss': 0.8029023159129417, 'Total loss': 0.8029023159129417}
2022-11-22 20:54:14,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:14,062 INFO:     Epoch: 63
2022-11-22 20:54:14,785 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7928482029925693, 'Total loss': 0.7928482029925693} | train loss {'Reaction outcome loss': 0.8005298184238465, 'Total loss': 0.8005298184238465}
2022-11-22 20:54:14,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:14,785 INFO:     Epoch: 64
2022-11-22 20:54:15,537 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7622149234468286, 'Total loss': 0.7622149234468286} | train loss {'Reaction outcome loss': 0.8080416567895093, 'Total loss': 0.8080416567895093}
2022-11-22 20:54:15,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:15,538 INFO:     Epoch: 65
2022-11-22 20:54:16,292 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8034127862616018, 'Total loss': 0.8034127862616018} | train loss {'Reaction outcome loss': 0.7918808877709423, 'Total loss': 0.7918808877709423}
2022-11-22 20:54:16,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:16,294 INFO:     Epoch: 66
2022-11-22 20:54:17,014 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7591496035456657, 'Total loss': 0.7591496035456657} | train loss {'Reaction outcome loss': 0.7984878436515206, 'Total loss': 0.7984878436515206}
2022-11-22 20:54:17,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:17,014 INFO:     Epoch: 67
2022-11-22 20:54:17,756 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7687932361255992, 'Total loss': 0.7687932361255992} | train loss {'Reaction outcome loss': 0.7965958531086261, 'Total loss': 0.7965958531086261}
2022-11-22 20:54:17,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:17,756 INFO:     Epoch: 68
2022-11-22 20:54:18,506 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7619016556577249, 'Total loss': 0.7619016556577249} | train loss {'Reaction outcome loss': 0.8044670042600709, 'Total loss': 0.8044670042600709}
2022-11-22 20:54:18,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:18,507 INFO:     Epoch: 69
2022-11-22 20:54:19,220 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7748494757847353, 'Total loss': 0.7748494757847353} | train loss {'Reaction outcome loss': 0.7915507539322502, 'Total loss': 0.7915507539322502}
2022-11-22 20:54:19,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:19,220 INFO:     Epoch: 70
2022-11-22 20:54:19,935 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8050404353575273, 'Total loss': 0.8050404353575273} | train loss {'Reaction outcome loss': 0.8000354722202548, 'Total loss': 0.8000354722202548}
2022-11-22 20:54:19,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:19,936 INFO:     Epoch: 71
2022-11-22 20:54:20,648 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7558043890378692, 'Total loss': 0.7558043890378692} | train loss {'Reaction outcome loss': 0.8013918179008159, 'Total loss': 0.8013918179008159}
2022-11-22 20:54:20,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:20,649 INFO:     Epoch: 72
2022-11-22 20:54:21,385 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7606759579344229, 'Total loss': 0.7606759579344229} | train loss {'Reaction outcome loss': 0.7926513173198892, 'Total loss': 0.7926513173198892}
2022-11-22 20:54:21,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:21,386 INFO:     Epoch: 73
2022-11-22 20:54:22,142 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.807471127672629, 'Total loss': 0.807471127672629} | train loss {'Reaction outcome loss': 0.7859753334087881, 'Total loss': 0.7859753334087881}
2022-11-22 20:54:22,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:22,142 INFO:     Epoch: 74
2022-11-22 20:54:22,864 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7823052548549392, 'Total loss': 0.7823052548549392} | train loss {'Reaction outcome loss': 0.7945645459991718, 'Total loss': 0.7945645459991718}
2022-11-22 20:54:22,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:22,865 INFO:     Epoch: 75
2022-11-22 20:54:23,605 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7732678482478316, 'Total loss': 0.7732678482478316} | train loss {'Reaction outcome loss': 0.7813857547667346, 'Total loss': 0.7813857547667346}
2022-11-22 20:54:23,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:23,605 INFO:     Epoch: 76
2022-11-22 20:54:24,383 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7468811293894594, 'Total loss': 0.7468811293894594} | train loss {'Reaction outcome loss': 0.7951899705386838, 'Total loss': 0.7951899705386838}
2022-11-22 20:54:24,383 INFO:     Found new best model at epoch 76
2022-11-22 20:54:24,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:24,384 INFO:     Epoch: 77
2022-11-22 20:54:25,125 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7921325273134492, 'Total loss': 0.7921325273134492} | train loss {'Reaction outcome loss': 0.7806979399400684, 'Total loss': 0.7806979399400684}
2022-11-22 20:54:25,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:25,125 INFO:     Epoch: 78
2022-11-22 20:54:25,853 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.792348671365868, 'Total loss': 0.792348671365868} | train loss {'Reaction outcome loss': 0.7774954035214567, 'Total loss': 0.7774954035214567}
2022-11-22 20:54:25,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:25,853 INFO:     Epoch: 79
2022-11-22 20:54:26,601 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7836581312797286, 'Total loss': 0.7836581312797286} | train loss {'Reaction outcome loss': 0.7798354766267513, 'Total loss': 0.7798354766267513}
2022-11-22 20:54:26,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:26,601 INFO:     Epoch: 80
2022-11-22 20:54:27,361 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7414700260216539, 'Total loss': 0.7414700260216539} | train loss {'Reaction outcome loss': 0.7815664475444357, 'Total loss': 0.7815664475444357}
2022-11-22 20:54:27,361 INFO:     Found new best model at epoch 80
2022-11-22 20:54:27,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:27,362 INFO:     Epoch: 81
2022-11-22 20:54:28,155 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7824380580674518, 'Total loss': 0.7824380580674518} | train loss {'Reaction outcome loss': 0.7786022687730519, 'Total loss': 0.7786022687730519}
2022-11-22 20:54:28,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:28,155 INFO:     Epoch: 82
2022-11-22 20:54:28,916 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7714139351790602, 'Total loss': 0.7714139351790602} | train loss {'Reaction outcome loss': 0.7869391498054087, 'Total loss': 0.7869391498054087}
2022-11-22 20:54:28,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:28,916 INFO:     Epoch: 83
2022-11-22 20:54:29,743 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7957590412009846, 'Total loss': 0.7957590412009846} | train loss {'Reaction outcome loss': 0.7934769211027787, 'Total loss': 0.7934769211027787}
2022-11-22 20:54:29,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:29,743 INFO:     Epoch: 84
2022-11-22 20:54:30,513 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7302242957732894, 'Total loss': 0.7302242957732894} | train loss {'Reaction outcome loss': 0.7825754955316694, 'Total loss': 0.7825754955316694}
2022-11-22 20:54:30,514 INFO:     Found new best model at epoch 84
2022-11-22 20:54:30,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:30,514 INFO:     Epoch: 85
2022-11-22 20:54:31,268 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7638478590683504, 'Total loss': 0.7638478590683504} | train loss {'Reaction outcome loss': 0.7705748795497755, 'Total loss': 0.7705748795497755}
2022-11-22 20:54:31,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:31,269 INFO:     Epoch: 86
2022-11-22 20:54:31,978 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7442869205366481, 'Total loss': 0.7442869205366481} | train loss {'Reaction outcome loss': 0.7761055089925465, 'Total loss': 0.7761055089925465}
2022-11-22 20:54:31,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:31,979 INFO:     Epoch: 87
2022-11-22 20:54:32,719 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7681466219100085, 'Total loss': 0.7681466219100085} | train loss {'Reaction outcome loss': 0.7858510167009918, 'Total loss': 0.7858510167009918}
2022-11-22 20:54:32,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:32,719 INFO:     Epoch: 88
2022-11-22 20:54:33,478 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7396840263496746, 'Total loss': 0.7396840263496746} | train loss {'Reaction outcome loss': 0.7818165765358851, 'Total loss': 0.7818165765358851}
2022-11-22 20:54:33,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:33,479 INFO:     Epoch: 89
2022-11-22 20:54:34,242 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7498136542060159, 'Total loss': 0.7498136542060159} | train loss {'Reaction outcome loss': 0.7686807075251452, 'Total loss': 0.7686807075251452}
2022-11-22 20:54:34,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:34,242 INFO:     Epoch: 90
2022-11-22 20:54:35,012 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7762159102342345, 'Total loss': 0.7762159102342345} | train loss {'Reaction outcome loss': 0.7794073897938014, 'Total loss': 0.7794073897938014}
2022-11-22 20:54:35,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:35,013 INFO:     Epoch: 91
2022-11-22 20:54:35,739 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7185420055281032, 'Total loss': 0.7185420055281032} | train loss {'Reaction outcome loss': 0.772969863796041, 'Total loss': 0.772969863796041}
2022-11-22 20:54:35,739 INFO:     Found new best model at epoch 91
2022-11-22 20:54:35,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:35,740 INFO:     Epoch: 92
2022-11-22 20:54:36,509 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7578722042116252, 'Total loss': 0.7578722042116252} | train loss {'Reaction outcome loss': 0.7654509736820754, 'Total loss': 0.7654509736820754}
2022-11-22 20:54:36,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:36,509 INFO:     Epoch: 93
2022-11-22 20:54:37,256 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7445490204475143, 'Total loss': 0.7445490204475143} | train loss {'Reaction outcome loss': 0.7704058430696789, 'Total loss': 0.7704058430696789}
2022-11-22 20:54:37,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:37,257 INFO:     Epoch: 94
2022-11-22 20:54:37,994 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7336335690184073, 'Total loss': 0.7336335690184073} | train loss {'Reaction outcome loss': 0.7624380096250217, 'Total loss': 0.7624380096250217}
2022-11-22 20:54:37,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:37,994 INFO:     Epoch: 95
2022-11-22 20:54:38,710 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7517767785625025, 'Total loss': 0.7517767785625025} | train loss {'Reaction outcome loss': 0.7631714841584686, 'Total loss': 0.7631714841584686}
2022-11-22 20:54:38,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:38,711 INFO:     Epoch: 96
2022-11-22 20:54:39,451 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7295463897965171, 'Total loss': 0.7295463897965171} | train loss {'Reaction outcome loss': 0.7562573663136254, 'Total loss': 0.7562573663136254}
2022-11-22 20:54:39,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:39,451 INFO:     Epoch: 97
2022-11-22 20:54:40,188 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7330042882399126, 'Total loss': 0.7330042882399126} | train loss {'Reaction outcome loss': 0.7617056280495185, 'Total loss': 0.7617056280495185}
2022-11-22 20:54:40,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:40,189 INFO:     Epoch: 98
2022-11-22 20:54:40,946 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7326866090297699, 'Total loss': 0.7326866090297699} | train loss {'Reaction outcome loss': 0.7652053896956116, 'Total loss': 0.7652053896956116}
2022-11-22 20:54:40,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:40,946 INFO:     Epoch: 99
2022-11-22 20:54:41,658 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7175813290205869, 'Total loss': 0.7175813290205869} | train loss {'Reaction outcome loss': 0.7594650192299353, 'Total loss': 0.7594650192299353}
2022-11-22 20:54:41,658 INFO:     Found new best model at epoch 99
2022-11-22 20:54:41,659 INFO:     Best model found after epoch 100 of 100.
2022-11-22 20:54:41,659 INFO:   Done with stage: TRAINING
2022-11-22 20:54:41,659 INFO:   Starting stage: EVALUATION
2022-11-22 20:54:41,778 INFO:   Done with stage: EVALUATION
2022-11-22 20:54:41,778 INFO:   Leaving out SEQ value Fold_5
2022-11-22 20:54:41,791 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 20:54:41,791 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:54:42,455 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:54:42,456 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:54:42,524 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:54:42,524 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:54:42,524 INFO:     No hyperparam tuning for this model
2022-11-22 20:54:42,524 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:54:42,525 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:54:42,525 INFO:     None feature selector for col prot
2022-11-22 20:54:42,525 INFO:     None feature selector for col prot
2022-11-22 20:54:42,526 INFO:     None feature selector for col prot
2022-11-22 20:54:42,526 INFO:     None feature selector for col chem
2022-11-22 20:54:42,526 INFO:     None feature selector for col chem
2022-11-22 20:54:42,526 INFO:     None feature selector for col chem
2022-11-22 20:54:42,526 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:54:42,526 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:54:42,528 INFO:     Number of params in model 126091
2022-11-22 20:54:42,531 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:54:42,531 INFO:   Starting stage: TRAINING
2022-11-22 20:54:42,580 INFO:     Val loss before train {'Reaction outcome loss': 0.974065555090254, 'Total loss': 0.974065555090254}
2022-11-22 20:54:42,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:42,581 INFO:     Epoch: 0
2022-11-22 20:54:43,361 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.83671704611995, 'Total loss': 0.83671704611995} | train loss {'Reaction outcome loss': 0.8849224235501981, 'Total loss': 0.8849224235501981}
2022-11-22 20:54:43,361 INFO:     Found new best model at epoch 0
2022-11-22 20:54:43,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:43,362 INFO:     Epoch: 1
2022-11-22 20:54:44,140 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.837909000841054, 'Total loss': 0.837909000841054} | train loss {'Reaction outcome loss': 0.8458097507396052, 'Total loss': 0.8458097507396052}
2022-11-22 20:54:44,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:44,141 INFO:     Epoch: 2
2022-11-22 20:54:44,867 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8343645110726357, 'Total loss': 0.8343645110726357} | train loss {'Reaction outcome loss': 0.8326980965512414, 'Total loss': 0.8326980965512414}
2022-11-22 20:54:44,867 INFO:     Found new best model at epoch 2
2022-11-22 20:54:44,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:44,868 INFO:     Epoch: 3
2022-11-22 20:54:45,617 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8222942135550759, 'Total loss': 0.8222942135550759} | train loss {'Reaction outcome loss': 0.8294416045349452, 'Total loss': 0.8294416045349452}
2022-11-22 20:54:45,617 INFO:     Found new best model at epoch 3
2022-11-22 20:54:45,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:45,618 INFO:     Epoch: 4
2022-11-22 20:54:46,402 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8282469043677504, 'Total loss': 0.8282469043677504} | train loss {'Reaction outcome loss': 0.8265018503992788, 'Total loss': 0.8265018503992788}
2022-11-22 20:54:46,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:46,403 INFO:     Epoch: 5
2022-11-22 20:54:47,117 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8120445649732243, 'Total loss': 0.8120445649732243} | train loss {'Reaction outcome loss': 0.8196243652172627, 'Total loss': 0.8196243652172627}
2022-11-22 20:54:47,118 INFO:     Found new best model at epoch 5
2022-11-22 20:54:47,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:47,119 INFO:     Epoch: 6
2022-11-22 20:54:47,839 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8122433850711043, 'Total loss': 0.8122433850711043} | train loss {'Reaction outcome loss': 0.8151798966911531, 'Total loss': 0.8151798966911531}
2022-11-22 20:54:47,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:47,839 INFO:     Epoch: 7
2022-11-22 20:54:48,614 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8177130757407709, 'Total loss': 0.8177130757407709} | train loss {'Reaction outcome loss': 0.8151203088702694, 'Total loss': 0.8151203088702694}
2022-11-22 20:54:48,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:48,614 INFO:     Epoch: 8
2022-11-22 20:54:49,385 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8015452393076636, 'Total loss': 0.8015452393076636} | train loss {'Reaction outcome loss': 0.8109898286000374, 'Total loss': 0.8109898286000374}
2022-11-22 20:54:49,385 INFO:     Found new best model at epoch 8
2022-11-22 20:54:49,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:49,386 INFO:     Epoch: 9
2022-11-22 20:54:50,151 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8073689951138063, 'Total loss': 0.8073689951138063} | train loss {'Reaction outcome loss': 0.8127524707346193, 'Total loss': 0.8127524707346193}
2022-11-22 20:54:50,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:50,152 INFO:     Epoch: 10
2022-11-22 20:54:50,908 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8063879080794074, 'Total loss': 0.8063879080794074} | train loss {'Reaction outcome loss': 0.808904763912001, 'Total loss': 0.808904763912001}
2022-11-22 20:54:50,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:50,908 INFO:     Epoch: 11
2022-11-22 20:54:51,662 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8018161728978157, 'Total loss': 0.8018161728978157} | train loss {'Reaction outcome loss': 0.8071620059349844, 'Total loss': 0.8071620059349844}
2022-11-22 20:54:51,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:51,662 INFO:     Epoch: 12
2022-11-22 20:54:52,380 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8138473413207314, 'Total loss': 0.8138473413207314} | train loss {'Reaction outcome loss': 0.8070448665849624, 'Total loss': 0.8070448665849624}
2022-11-22 20:54:52,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:52,380 INFO:     Epoch: 13
2022-11-22 20:54:53,164 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8057296208359979, 'Total loss': 0.8057296208359979} | train loss {'Reaction outcome loss': 0.8086715215636838, 'Total loss': 0.8086715215636838}
2022-11-22 20:54:53,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:53,165 INFO:     Epoch: 14
2022-11-22 20:54:53,893 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7982169362631711, 'Total loss': 0.7982169362631711} | train loss {'Reaction outcome loss': 0.804190412644417, 'Total loss': 0.804190412644417}
2022-11-22 20:54:53,893 INFO:     Found new best model at epoch 14
2022-11-22 20:54:53,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:53,894 INFO:     Epoch: 15
2022-11-22 20:54:54,628 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8135675191879272, 'Total loss': 0.8135675191879272} | train loss {'Reaction outcome loss': 0.7998520679050877, 'Total loss': 0.7998520679050877}
2022-11-22 20:54:54,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:54,629 INFO:     Epoch: 16
2022-11-22 20:54:55,378 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8014024557037787, 'Total loss': 0.8014024557037787} | train loss {'Reaction outcome loss': 0.8061340359910842, 'Total loss': 0.8061340359910842}
2022-11-22 20:54:55,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:55,379 INFO:     Epoch: 17
2022-11-22 20:54:56,073 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8005661991509524, 'Total loss': 0.8005661991509524} | train loss {'Reaction outcome loss': 0.8030621041693995, 'Total loss': 0.8030621041693995}
2022-11-22 20:54:56,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:56,074 INFO:     Epoch: 18
2022-11-22 20:54:56,823 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8089578713883053, 'Total loss': 0.8089578713883053} | train loss {'Reaction outcome loss': 0.8022862305083582, 'Total loss': 0.8022862305083582}
2022-11-22 20:54:56,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:56,823 INFO:     Epoch: 19
2022-11-22 20:54:57,528 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7967144657265056, 'Total loss': 0.7967144657265056} | train loss {'Reaction outcome loss': 0.7961997602495455, 'Total loss': 0.7961997602495455}
2022-11-22 20:54:57,528 INFO:     Found new best model at epoch 19
2022-11-22 20:54:57,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:57,529 INFO:     Epoch: 20
2022-11-22 20:54:58,258 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8236197869886052, 'Total loss': 0.8236197869886052} | train loss {'Reaction outcome loss': 0.7968239164160144, 'Total loss': 0.7968239164160144}
2022-11-22 20:54:58,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:58,258 INFO:     Epoch: 21
2022-11-22 20:54:58,983 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8165644732388583, 'Total loss': 0.8165644732388583} | train loss {'Reaction outcome loss': 0.7961258318635726, 'Total loss': 0.7961258318635726}
2022-11-22 20:54:58,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:58,984 INFO:     Epoch: 22
2022-11-22 20:54:59,677 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.816489927470684, 'Total loss': 0.816489927470684} | train loss {'Reaction outcome loss': 0.8010432654090466, 'Total loss': 0.8010432654090466}
2022-11-22 20:54:59,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:54:59,677 INFO:     Epoch: 23
2022-11-22 20:55:00,446 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8013912202282385, 'Total loss': 0.8013912202282385} | train loss {'Reaction outcome loss': 0.7988642057584178, 'Total loss': 0.7988642057584178}
2022-11-22 20:55:00,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:00,446 INFO:     Epoch: 24
2022-11-22 20:55:01,198 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7932627932591871, 'Total loss': 0.7932627932591871} | train loss {'Reaction outcome loss': 0.8035584506728957, 'Total loss': 0.8035584506728957}
2022-11-22 20:55:01,198 INFO:     Found new best model at epoch 24
2022-11-22 20:55:01,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:01,199 INFO:     Epoch: 25
2022-11-22 20:55:01,966 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8338530497117476, 'Total loss': 0.8338530497117476} | train loss {'Reaction outcome loss': 0.8027657734290246, 'Total loss': 0.8027657734290246}
2022-11-22 20:55:01,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:01,966 INFO:     Epoch: 26
2022-11-22 20:55:02,695 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7983962798660452, 'Total loss': 0.7983962798660452} | train loss {'Reaction outcome loss': 0.801591437790663, 'Total loss': 0.801591437790663}
2022-11-22 20:55:02,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:02,696 INFO:     Epoch: 27
2022-11-22 20:55:03,419 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7892008857293562, 'Total loss': 0.7892008857293562} | train loss {'Reaction outcome loss': 0.7973922676136417, 'Total loss': 0.7973922676136417}
2022-11-22 20:55:03,419 INFO:     Found new best model at epoch 27
2022-11-22 20:55:03,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:03,420 INFO:     Epoch: 28
2022-11-22 20:55:04,185 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8089124743234027, 'Total loss': 0.8089124743234027} | train loss {'Reaction outcome loss': 0.7963833184011521, 'Total loss': 0.7963833184011521}
2022-11-22 20:55:04,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:04,185 INFO:     Epoch: 29
2022-11-22 20:55:04,926 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8066304183819077, 'Total loss': 0.8066304183819077} | train loss {'Reaction outcome loss': 0.8014756109445326, 'Total loss': 0.8014756109445326}
2022-11-22 20:55:04,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:04,927 INFO:     Epoch: 30
2022-11-22 20:55:05,659 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7982186268676411, 'Total loss': 0.7982186268676411} | train loss {'Reaction outcome loss': 0.8001348306575129, 'Total loss': 0.8001348306575129}
2022-11-22 20:55:05,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:05,660 INFO:     Epoch: 31
2022-11-22 20:55:06,386 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7820282429456711, 'Total loss': 0.7820282429456711} | train loss {'Reaction outcome loss': 0.7997595471960883, 'Total loss': 0.7997595471960883}
2022-11-22 20:55:06,386 INFO:     Found new best model at epoch 31
2022-11-22 20:55:06,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:06,387 INFO:     Epoch: 32
2022-11-22 20:55:07,108 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7959376072341745, 'Total loss': 0.7959376072341745} | train loss {'Reaction outcome loss': 0.7990611008098049, 'Total loss': 0.7990611008098049}
2022-11-22 20:55:07,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:07,108 INFO:     Epoch: 33
2022-11-22 20:55:07,854 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8016744967211377, 'Total loss': 0.8016744967211377} | train loss {'Reaction outcome loss': 0.7965687585453833, 'Total loss': 0.7965687585453833}
2022-11-22 20:55:07,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:07,854 INFO:     Epoch: 34
2022-11-22 20:55:08,611 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7965977815064517, 'Total loss': 0.7965977815064517} | train loss {'Reaction outcome loss': 0.7988611906766891, 'Total loss': 0.7988611906766891}
2022-11-22 20:55:08,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:08,611 INFO:     Epoch: 35
2022-11-22 20:55:09,420 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7801774631847035, 'Total loss': 0.7801774631847035} | train loss {'Reaction outcome loss': 0.7905814048022993, 'Total loss': 0.7905814048022993}
2022-11-22 20:55:09,421 INFO:     Found new best model at epoch 35
2022-11-22 20:55:09,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:09,421 INFO:     Epoch: 36
2022-11-22 20:55:10,207 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7889959798617796, 'Total loss': 0.7889959798617796} | train loss {'Reaction outcome loss': 0.7972631072325091, 'Total loss': 0.7972631072325091}
2022-11-22 20:55:10,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:10,207 INFO:     Epoch: 37
2022-11-22 20:55:10,924 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8262816301800988, 'Total loss': 0.8262816301800988} | train loss {'Reaction outcome loss': 0.7945039758999501, 'Total loss': 0.7945039758999501}
2022-11-22 20:55:10,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:10,925 INFO:     Epoch: 38
2022-11-22 20:55:11,708 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.803428937765685, 'Total loss': 0.803428937765685} | train loss {'Reaction outcome loss': 0.7983336269615158, 'Total loss': 0.7983336269615158}
2022-11-22 20:55:11,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:11,708 INFO:     Epoch: 39
2022-11-22 20:55:12,486 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8062744032252919, 'Total loss': 0.8062744032252919} | train loss {'Reaction outcome loss': 0.7925079764137345, 'Total loss': 0.7925079764137345}
2022-11-22 20:55:12,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:12,487 INFO:     Epoch: 40
2022-11-22 20:55:13,255 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.791024697097865, 'Total loss': 0.791024697097865} | train loss {'Reaction outcome loss': 0.7925558311323966, 'Total loss': 0.7925558311323966}
2022-11-22 20:55:13,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:13,255 INFO:     Epoch: 41
2022-11-22 20:55:13,986 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7988839914852922, 'Total loss': 0.7988839914852922} | train loss {'Reaction outcome loss': 0.7970419386702199, 'Total loss': 0.7970419386702199}
2022-11-22 20:55:13,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:13,986 INFO:     Epoch: 42
2022-11-22 20:55:14,769 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.792760893702507, 'Total loss': 0.792760893702507} | train loss {'Reaction outcome loss': 0.7936057006159136, 'Total loss': 0.7936057006159136}
2022-11-22 20:55:14,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:14,769 INFO:     Epoch: 43
2022-11-22 20:55:15,509 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7965981282971122, 'Total loss': 0.7965981282971122} | train loss {'Reaction outcome loss': 0.7926383749732087, 'Total loss': 0.7926383749732087}
2022-11-22 20:55:15,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:15,510 INFO:     Epoch: 44
2022-11-22 20:55:16,251 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8009556017138741, 'Total loss': 0.8009556017138741} | train loss {'Reaction outcome loss': 0.7941291981166408, 'Total loss': 0.7941291981166408}
2022-11-22 20:55:16,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:16,251 INFO:     Epoch: 45
2022-11-22 20:55:16,964 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8002856665036895, 'Total loss': 0.8002856665036895} | train loss {'Reaction outcome loss': 0.7923954105184924, 'Total loss': 0.7923954105184924}
2022-11-22 20:55:16,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:16,964 INFO:     Epoch: 46
2022-11-22 20:55:17,664 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7987147244540128, 'Total loss': 0.7987147244540128} | train loss {'Reaction outcome loss': 0.791636316045638, 'Total loss': 0.791636316045638}
2022-11-22 20:55:17,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:17,664 INFO:     Epoch: 47
2022-11-22 20:55:18,399 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7871178178624674, 'Total loss': 0.7871178178624674} | train loss {'Reaction outcome loss': 0.7955596674113504, 'Total loss': 0.7955596674113504}
2022-11-22 20:55:18,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:18,400 INFO:     Epoch: 48
2022-11-22 20:55:19,144 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7927436205473813, 'Total loss': 0.7927436205473813} | train loss {'Reaction outcome loss': 0.7911561461946657, 'Total loss': 0.7911561461946657}
2022-11-22 20:55:19,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:19,145 INFO:     Epoch: 49
2022-11-22 20:55:19,885 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8036265129392798, 'Total loss': 0.8036265129392798} | train loss {'Reaction outcome loss': 0.7936931164754976, 'Total loss': 0.7936931164754976}
2022-11-22 20:55:19,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:19,886 INFO:     Epoch: 50
2022-11-22 20:55:20,597 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7970419912175699, 'Total loss': 0.7970419912175699} | train loss {'Reaction outcome loss': 0.7931354669553619, 'Total loss': 0.7931354669553619}
2022-11-22 20:55:20,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:20,597 INFO:     Epoch: 51
2022-11-22 20:55:21,380 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7939592782746662, 'Total loss': 0.7939592782746662} | train loss {'Reaction outcome loss': 0.7954636993667772, 'Total loss': 0.7954636993667772}
2022-11-22 20:55:21,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:21,380 INFO:     Epoch: 52
2022-11-22 20:55:22,096 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7986479537053541, 'Total loss': 0.7986479537053541} | train loss {'Reaction outcome loss': 0.7903862841908009, 'Total loss': 0.7903862841908009}
2022-11-22 20:55:22,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:22,096 INFO:     Epoch: 53
2022-11-22 20:55:22,841 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8094766776670109, 'Total loss': 0.8094766776670109} | train loss {'Reaction outcome loss': 0.7899469049467195, 'Total loss': 0.7899469049467195}
2022-11-22 20:55:22,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:22,841 INFO:     Epoch: 54
2022-11-22 20:55:23,590 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7958570244637403, 'Total loss': 0.7958570244637403} | train loss {'Reaction outcome loss': 0.7952388026300938, 'Total loss': 0.7952388026300938}
2022-11-22 20:55:23,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:23,590 INFO:     Epoch: 55
2022-11-22 20:55:24,347 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7907305996526371, 'Total loss': 0.7907305996526371} | train loss {'Reaction outcome loss': 0.7937619770246167, 'Total loss': 0.7937619770246167}
2022-11-22 20:55:24,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:24,348 INFO:     Epoch: 56
2022-11-22 20:55:25,055 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7803339754993265, 'Total loss': 0.7803339754993265} | train loss {'Reaction outcome loss': 0.7864463673003258, 'Total loss': 0.7864463673003258}
2022-11-22 20:55:25,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:25,056 INFO:     Epoch: 57
2022-11-22 20:55:25,771 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7973855429074981, 'Total loss': 0.7973855429074981} | train loss {'Reaction outcome loss': 0.7895331700001994, 'Total loss': 0.7895331700001994}
2022-11-22 20:55:25,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:25,772 INFO:     Epoch: 58
2022-11-22 20:55:26,481 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8044026859781959, 'Total loss': 0.8044026859781959} | train loss {'Reaction outcome loss': 0.7940507050483457, 'Total loss': 0.7940507050483457}
2022-11-22 20:55:26,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:26,481 INFO:     Epoch: 59
2022-11-22 20:55:27,213 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8018295101144097, 'Total loss': 0.8018295101144097} | train loss {'Reaction outcome loss': 0.7878330377561431, 'Total loss': 0.7878330377561431}
2022-11-22 20:55:27,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:27,213 INFO:     Epoch: 60
2022-11-22 20:55:27,948 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7991260533983057, 'Total loss': 0.7991260533983057} | train loss {'Reaction outcome loss': 0.7946018874645233, 'Total loss': 0.7946018874645233}
2022-11-22 20:55:27,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:27,949 INFO:     Epoch: 61
2022-11-22 20:55:28,692 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7776210341941227, 'Total loss': 0.7776210341941227} | train loss {'Reaction outcome loss': 0.7853199118568052, 'Total loss': 0.7853199118568052}
2022-11-22 20:55:28,692 INFO:     Found new best model at epoch 61
2022-11-22 20:55:28,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:28,693 INFO:     Epoch: 62
2022-11-22 20:55:29,423 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.908023749562827, 'Total loss': 0.908023749562827} | train loss {'Reaction outcome loss': 0.7881239378644574, 'Total loss': 0.7881239378644574}
2022-11-22 20:55:29,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:29,423 INFO:     Epoch: 63
2022-11-22 20:55:30,131 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8169009360400113, 'Total loss': 0.8169009360400113} | train loss {'Reaction outcome loss': 0.7912971109392182, 'Total loss': 0.7912971109392182}
2022-11-22 20:55:30,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:30,131 INFO:     Epoch: 64
2022-11-22 20:55:30,887 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7836895673112436, 'Total loss': 0.7836895673112436} | train loss {'Reaction outcome loss': 0.7840809883369554, 'Total loss': 0.7840809883369554}
2022-11-22 20:55:30,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:30,887 INFO:     Epoch: 65
2022-11-22 20:55:31,687 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7863028232346881, 'Total loss': 0.7863028232346881} | train loss {'Reaction outcome loss': 0.7778553712752557, 'Total loss': 0.7778553712752557}
2022-11-22 20:55:31,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:31,688 INFO:     Epoch: 66
2022-11-22 20:55:32,448 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7970489134842699, 'Total loss': 0.7970489134842699} | train loss {'Reaction outcome loss': 0.7822274714708328, 'Total loss': 0.7822274714708328}
2022-11-22 20:55:32,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:32,448 INFO:     Epoch: 67
2022-11-22 20:55:33,208 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7844330167228525, 'Total loss': 0.7844330167228525} | train loss {'Reaction outcome loss': 0.7803892010762807, 'Total loss': 0.7803892010762807}
2022-11-22 20:55:33,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:33,208 INFO:     Epoch: 68
2022-11-22 20:55:33,979 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7698312411931428, 'Total loss': 0.7698312411931428} | train loss {'Reaction outcome loss': 0.7754238402891543, 'Total loss': 0.7754238402891543}
2022-11-22 20:55:33,979 INFO:     Found new best model at epoch 68
2022-11-22 20:55:33,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:33,980 INFO:     Epoch: 69
2022-11-22 20:55:34,749 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7783991640264337, 'Total loss': 0.7783991640264337} | train loss {'Reaction outcome loss': 0.7782310174117165, 'Total loss': 0.7782310174117165}
2022-11-22 20:55:34,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:34,750 INFO:     Epoch: 70
2022-11-22 20:55:35,500 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7711697335947644, 'Total loss': 0.7711697335947644} | train loss {'Reaction outcome loss': 0.772726855090549, 'Total loss': 0.772726855090549}
2022-11-22 20:55:35,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:35,500 INFO:     Epoch: 71
2022-11-22 20:55:36,263 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7616563459688966, 'Total loss': 0.7616563459688966} | train loss {'Reaction outcome loss': 0.7762594863532051, 'Total loss': 0.7762594863532051}
2022-11-22 20:55:36,263 INFO:     Found new best model at epoch 71
2022-11-22 20:55:36,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:36,264 INFO:     Epoch: 72
2022-11-22 20:55:36,981 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7748120847073469, 'Total loss': 0.7748120847073469} | train loss {'Reaction outcome loss': 0.7732240365397546, 'Total loss': 0.7732240365397546}
2022-11-22 20:55:36,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:36,982 INFO:     Epoch: 73
2022-11-22 20:55:37,793 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7864450392397967, 'Total loss': 0.7864450392397967} | train loss {'Reaction outcome loss': 0.7711310491206185, 'Total loss': 0.7711310491206185}
2022-11-22 20:55:37,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:37,794 INFO:     Epoch: 74
2022-11-22 20:55:38,548 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.759934738278389, 'Total loss': 0.759934738278389} | train loss {'Reaction outcome loss': 0.7746565924777139, 'Total loss': 0.7746565924777139}
2022-11-22 20:55:38,548 INFO:     Found new best model at epoch 74
2022-11-22 20:55:38,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:38,549 INFO:     Epoch: 75
2022-11-22 20:55:39,336 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7971253821795637, 'Total loss': 0.7971253821795637} | train loss {'Reaction outcome loss': 0.7699413591575238, 'Total loss': 0.7699413591575238}
2022-11-22 20:55:39,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:39,336 INFO:     Epoch: 76
2022-11-22 20:55:40,126 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7663895616477187, 'Total loss': 0.7663895616477187} | train loss {'Reaction outcome loss': 0.7724421524232433, 'Total loss': 0.7724421524232433}
2022-11-22 20:55:40,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:40,126 INFO:     Epoch: 77
2022-11-22 20:55:40,879 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7810620645230467, 'Total loss': 0.7810620645230467} | train loss {'Reaction outcome loss': 0.7652878632708904, 'Total loss': 0.7652878632708904}
2022-11-22 20:55:40,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:40,880 INFO:     Epoch: 78
2022-11-22 20:55:41,620 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7626011974432252, 'Total loss': 0.7626011974432252} | train loss {'Reaction outcome loss': 0.7696362044061383, 'Total loss': 0.7696362044061383}
2022-11-22 20:55:41,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:41,620 INFO:     Epoch: 79
2022-11-22 20:55:42,369 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7644680772315372, 'Total loss': 0.7644680772315372} | train loss {'Reaction outcome loss': 0.7663667986710225, 'Total loss': 0.7663667986710225}
2022-11-22 20:55:42,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:42,369 INFO:     Epoch: 80
2022-11-22 20:55:43,150 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7709247246384621, 'Total loss': 0.7709247246384621} | train loss {'Reaction outcome loss': 0.7606767805353287, 'Total loss': 0.7606767805353287}
2022-11-22 20:55:43,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:43,150 INFO:     Epoch: 81
2022-11-22 20:55:43,902 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7536726756529375, 'Total loss': 0.7536726756529375} | train loss {'Reaction outcome loss': 0.7618086134954807, 'Total loss': 0.7618086134954807}
2022-11-22 20:55:43,902 INFO:     Found new best model at epoch 81
2022-11-22 20:55:43,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:43,903 INFO:     Epoch: 82
2022-11-22 20:55:44,693 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8073670532215725, 'Total loss': 0.8073670532215725} | train loss {'Reaction outcome loss': 0.7557927463804522, 'Total loss': 0.7557927463804522}
2022-11-22 20:55:44,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:44,693 INFO:     Epoch: 83
2022-11-22 20:55:45,457 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7888589481061156, 'Total loss': 0.7888589481061156} | train loss {'Reaction outcome loss': 0.7567809323870367, 'Total loss': 0.7567809323870367}
2022-11-22 20:55:45,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:45,457 INFO:     Epoch: 84
2022-11-22 20:55:46,188 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7667313285849311, 'Total loss': 0.7667313285849311} | train loss {'Reaction outcome loss': 0.760663669316038, 'Total loss': 0.760663669316038}
2022-11-22 20:55:46,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:46,189 INFO:     Epoch: 85
2022-11-22 20:55:46,965 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7736198082566261, 'Total loss': 0.7736198082566261} | train loss {'Reaction outcome loss': 0.7516777314726384, 'Total loss': 0.7516777314726384}
2022-11-22 20:55:46,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:46,965 INFO:     Epoch: 86
2022-11-22 20:55:47,728 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7598145001313903, 'Total loss': 0.7598145001313903} | train loss {'Reaction outcome loss': 0.7576125574208075, 'Total loss': 0.7576125574208075}
2022-11-22 20:55:47,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:47,728 INFO:     Epoch: 87
2022-11-22 20:55:48,467 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7522154619747942, 'Total loss': 0.7522154619747942} | train loss {'Reaction outcome loss': 0.7445636175332531, 'Total loss': 0.7445636175332531}
2022-11-22 20:55:48,467 INFO:     Found new best model at epoch 87
2022-11-22 20:55:48,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:48,468 INFO:     Epoch: 88
2022-11-22 20:55:49,179 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7949444969946687, 'Total loss': 0.7949444969946687} | train loss {'Reaction outcome loss': 0.747705121434504, 'Total loss': 0.747705121434504}
2022-11-22 20:55:49,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:49,180 INFO:     Epoch: 89
2022-11-22 20:55:49,939 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.763380222699859, 'Total loss': 0.763380222699859} | train loss {'Reaction outcome loss': 0.7421901891789129, 'Total loss': 0.7421901891789129}
2022-11-22 20:55:49,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:49,940 INFO:     Epoch: 90
2022-11-22 20:55:50,734 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7857512012124062, 'Total loss': 0.7857512012124062} | train loss {'Reaction outcome loss': 0.7518728117067968, 'Total loss': 0.7518728117067968}
2022-11-22 20:55:50,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:50,734 INFO:     Epoch: 91
2022-11-22 20:55:51,487 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.731416602703658, 'Total loss': 0.731416602703658} | train loss {'Reaction outcome loss': 0.7435221480986764, 'Total loss': 0.7435221480986764}
2022-11-22 20:55:51,487 INFO:     Found new best model at epoch 91
2022-11-22 20:55:51,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:51,488 INFO:     Epoch: 92
2022-11-22 20:55:52,254 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7500822395086288, 'Total loss': 0.7500822395086288} | train loss {'Reaction outcome loss': 0.7391467718707938, 'Total loss': 0.7391467718707938}
2022-11-22 20:55:52,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:52,254 INFO:     Epoch: 93
2022-11-22 20:55:53,010 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.827821403064511, 'Total loss': 0.827821403064511} | train loss {'Reaction outcome loss': 0.7410626442682359, 'Total loss': 0.7410626442682359}
2022-11-22 20:55:53,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:53,011 INFO:     Epoch: 94
2022-11-22 20:55:53,749 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7307705865664915, 'Total loss': 0.7307705865664915} | train loss {'Reaction outcome loss': 0.733099416799603, 'Total loss': 0.733099416799603}
2022-11-22 20:55:53,749 INFO:     Found new best model at epoch 94
2022-11-22 20:55:53,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:53,750 INFO:     Epoch: 95
2022-11-22 20:55:54,505 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7406450083309953, 'Total loss': 0.7406450083309953} | train loss {'Reaction outcome loss': 0.7323949296147593, 'Total loss': 0.7323949296147593}
2022-11-22 20:55:54,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:54,506 INFO:     Epoch: 96
2022-11-22 20:55:55,301 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7383032888174057, 'Total loss': 0.7383032888174057} | train loss {'Reaction outcome loss': 0.7216937112952432, 'Total loss': 0.7216937112952432}
2022-11-22 20:55:55,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:55,302 INFO:     Epoch: 97
2022-11-22 20:55:56,041 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.747572464699095, 'Total loss': 0.747572464699095} | train loss {'Reaction outcome loss': 0.7275149622751821, 'Total loss': 0.7275149622751821}
2022-11-22 20:55:56,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:56,041 INFO:     Epoch: 98
2022-11-22 20:55:56,761 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7672928619113836, 'Total loss': 0.7672928619113836} | train loss {'Reaction outcome loss': 0.7214989070930788, 'Total loss': 0.7214989070930788}
2022-11-22 20:55:56,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:56,762 INFO:     Epoch: 99
2022-11-22 20:55:57,517 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7354279465296052, 'Total loss': 0.7354279465296052} | train loss {'Reaction outcome loss': 0.7237954644426223, 'Total loss': 0.7237954644426223}
2022-11-22 20:55:57,517 INFO:     Best model found after epoch 95 of 100.
2022-11-22 20:55:57,517 INFO:   Done with stage: TRAINING
2022-11-22 20:55:57,517 INFO:   Starting stage: EVALUATION
2022-11-22 20:55:57,633 INFO:   Done with stage: EVALUATION
2022-11-22 20:55:57,634 INFO:   Leaving out SEQ value Fold_6
2022-11-22 20:55:57,647 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:55:57,647 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:55:58,318 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:55:58,318 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:55:58,387 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:55:58,387 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:55:58,387 INFO:     No hyperparam tuning for this model
2022-11-22 20:55:58,387 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:55:58,387 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:55:58,388 INFO:     None feature selector for col prot
2022-11-22 20:55:58,388 INFO:     None feature selector for col prot
2022-11-22 20:55:58,388 INFO:     None feature selector for col prot
2022-11-22 20:55:58,389 INFO:     None feature selector for col chem
2022-11-22 20:55:58,389 INFO:     None feature selector for col chem
2022-11-22 20:55:58,389 INFO:     None feature selector for col chem
2022-11-22 20:55:58,389 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:55:58,389 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:55:58,391 INFO:     Number of params in model 126091
2022-11-22 20:55:58,394 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:55:58,394 INFO:   Starting stage: TRAINING
2022-11-22 20:55:58,443 INFO:     Val loss before train {'Reaction outcome loss': 1.0167195986617694, 'Total loss': 1.0167195986617694}
2022-11-22 20:55:58,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:58,444 INFO:     Epoch: 0
2022-11-22 20:55:59,187 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8432093181393363, 'Total loss': 0.8432093181393363} | train loss {'Reaction outcome loss': 0.8844318829084697, 'Total loss': 0.8844318829084697}
2022-11-22 20:55:59,187 INFO:     Found new best model at epoch 0
2022-11-22 20:55:59,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:59,188 INFO:     Epoch: 1
2022-11-22 20:55:59,922 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8449757715517824, 'Total loss': 0.8449757715517824} | train loss {'Reaction outcome loss': 0.8543066826426549, 'Total loss': 0.8543066826426549}
2022-11-22 20:55:59,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:55:59,922 INFO:     Epoch: 2
2022-11-22 20:56:00,640 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8349901600317522, 'Total loss': 0.8349901600317522} | train loss {'Reaction outcome loss': 0.8409649397921466, 'Total loss': 0.8409649397921466}
2022-11-22 20:56:00,640 INFO:     Found new best model at epoch 2
2022-11-22 20:56:00,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:00,641 INFO:     Epoch: 3
2022-11-22 20:56:01,366 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8057755286043341, 'Total loss': 0.8057755286043341} | train loss {'Reaction outcome loss': 0.8465526262034289, 'Total loss': 0.8465526262034289}
2022-11-22 20:56:01,366 INFO:     Found new best model at epoch 3
2022-11-22 20:56:01,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:01,367 INFO:     Epoch: 4
2022-11-22 20:56:02,092 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8202533928508108, 'Total loss': 0.8202533928508108} | train loss {'Reaction outcome loss': 0.8292271126257745, 'Total loss': 0.8292271126257745}
2022-11-22 20:56:02,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:02,093 INFO:     Epoch: 5
2022-11-22 20:56:02,863 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8119441385973584, 'Total loss': 0.8119441385973584} | train loss {'Reaction outcome loss': 0.8212605586901367, 'Total loss': 0.8212605586901367}
2022-11-22 20:56:02,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:02,863 INFO:     Epoch: 6
2022-11-22 20:56:03,646 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7913129153576764, 'Total loss': 0.7913129153576764} | train loss {'Reaction outcome loss': 0.8196395041971554, 'Total loss': 0.8196395041971554}
2022-11-22 20:56:03,646 INFO:     Found new best model at epoch 6
2022-11-22 20:56:03,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:03,647 INFO:     Epoch: 7
2022-11-22 20:56:04,455 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7957181016152556, 'Total loss': 0.7957181016152556} | train loss {'Reaction outcome loss': 0.8182631984413394, 'Total loss': 0.8182631984413394}
2022-11-22 20:56:04,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:04,455 INFO:     Epoch: 8
2022-11-22 20:56:05,249 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7948230118914084, 'Total loss': 0.7948230118914084} | train loss {'Reaction outcome loss': 0.8100376955048758, 'Total loss': 0.8100376955048758}
2022-11-22 20:56:05,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:05,249 INFO:     Epoch: 9
2022-11-22 20:56:06,038 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7914811579341238, 'Total loss': 0.7914811579341238} | train loss {'Reaction outcome loss': 0.813055626776537, 'Total loss': 0.813055626776537}
2022-11-22 20:56:06,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:06,038 INFO:     Epoch: 10
2022-11-22 20:56:06,806 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8027923323891379, 'Total loss': 0.8027923323891379} | train loss {'Reaction outcome loss': 0.8113445077347852, 'Total loss': 0.8113445077347852}
2022-11-22 20:56:06,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:06,806 INFO:     Epoch: 11
2022-11-22 20:56:07,530 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7868710810487921, 'Total loss': 0.7868710810487921} | train loss {'Reaction outcome loss': 0.8133313753887227, 'Total loss': 0.8133313753887227}
2022-11-22 20:56:07,531 INFO:     Found new best model at epoch 11
2022-11-22 20:56:07,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:07,532 INFO:     Epoch: 12
2022-11-22 20:56:08,267 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8017080521041696, 'Total loss': 0.8017080521041696} | train loss {'Reaction outcome loss': 0.808009032295783, 'Total loss': 0.808009032295783}
2022-11-22 20:56:08,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:08,267 INFO:     Epoch: 13
2022-11-22 20:56:08,998 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8149622712622989, 'Total loss': 0.8149622712622989} | train loss {'Reaction outcome loss': 0.7996270206986893, 'Total loss': 0.7996270206986893}
2022-11-22 20:56:08,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:08,999 INFO:     Epoch: 14
2022-11-22 20:56:09,778 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7921076687899503, 'Total loss': 0.7921076687899503} | train loss {'Reaction outcome loss': 0.8075917164082469, 'Total loss': 0.8075917164082469}
2022-11-22 20:56:09,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:09,779 INFO:     Epoch: 15
2022-11-22 20:56:10,550 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7968088733879003, 'Total loss': 0.7968088733879003} | train loss {'Reaction outcome loss': 0.8059976696968079, 'Total loss': 0.8059976696968079}
2022-11-22 20:56:10,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:10,550 INFO:     Epoch: 16
2022-11-22 20:56:11,321 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8018528778444637, 'Total loss': 0.8018528778444637} | train loss {'Reaction outcome loss': 0.8019681312294624, 'Total loss': 0.8019681312294624}
2022-11-22 20:56:11,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:11,322 INFO:     Epoch: 17
2022-11-22 20:56:12,054 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7898248481479558, 'Total loss': 0.7898248481479558} | train loss {'Reaction outcome loss': 0.8052278927221954, 'Total loss': 0.8052278927221954}
2022-11-22 20:56:12,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:12,054 INFO:     Epoch: 18
2022-11-22 20:56:12,808 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8026121990247206, 'Total loss': 0.8026121990247206} | train loss {'Reaction outcome loss': 0.8070411163303051, 'Total loss': 0.8070411163303051}
2022-11-22 20:56:12,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:12,809 INFO:     Epoch: 19
2022-11-22 20:56:13,593 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8005551316521384, 'Total loss': 0.8005551316521384} | train loss {'Reaction outcome loss': 0.8106884599214623, 'Total loss': 0.8106884599214623}
2022-11-22 20:56:13,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:13,593 INFO:     Epoch: 20
2022-11-22 20:56:14,348 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7965346076949076, 'Total loss': 0.7965346076949076} | train loss {'Reaction outcome loss': 0.8016392458984365, 'Total loss': 0.8016392458984365}
2022-11-22 20:56:14,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:14,349 INFO:     Epoch: 21
2022-11-22 20:56:15,072 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.800415725870566, 'Total loss': 0.800415725870566} | train loss {'Reaction outcome loss': 0.8128450815735558, 'Total loss': 0.8128450815735558}
2022-11-22 20:56:15,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:15,072 INFO:     Epoch: 22
2022-11-22 20:56:15,808 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.774244870651852, 'Total loss': 0.774244870651852} | train loss {'Reaction outcome loss': 0.7976303521679481, 'Total loss': 0.7976303521679481}
2022-11-22 20:56:15,808 INFO:     Found new best model at epoch 22
2022-11-22 20:56:15,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:15,809 INFO:     Epoch: 23
2022-11-22 20:56:16,592 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7961185154589739, 'Total loss': 0.7961185154589739} | train loss {'Reaction outcome loss': 0.8009495987643597, 'Total loss': 0.8009495987643597}
2022-11-22 20:56:16,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:16,592 INFO:     Epoch: 24
2022-11-22 20:56:17,390 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7852807810360735, 'Total loss': 0.7852807810360735} | train loss {'Reaction outcome loss': 0.79438089292783, 'Total loss': 0.79438089292783}
2022-11-22 20:56:17,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:17,390 INFO:     Epoch: 25
2022-11-22 20:56:18,139 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7833173837174069, 'Total loss': 0.7833173837174069} | train loss {'Reaction outcome loss': 0.8068130453105881, 'Total loss': 0.8068130453105881}
2022-11-22 20:56:18,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:18,139 INFO:     Epoch: 26
2022-11-22 20:56:18,928 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7967554513703693, 'Total loss': 0.7967554513703693} | train loss {'Reaction outcome loss': 0.8019756669336967, 'Total loss': 0.8019756669336967}
2022-11-22 20:56:18,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:18,928 INFO:     Epoch: 27
2022-11-22 20:56:19,669 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7824408019130881, 'Total loss': 0.7824408019130881} | train loss {'Reaction outcome loss': 0.7994575788557288, 'Total loss': 0.7994575788557288}
2022-11-22 20:56:19,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:19,669 INFO:     Epoch: 28
2022-11-22 20:56:20,407 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7896443998271768, 'Total loss': 0.7896443998271768} | train loss {'Reaction outcome loss': 0.8000568298675753, 'Total loss': 0.8000568298675753}
2022-11-22 20:56:20,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:20,408 INFO:     Epoch: 29
2022-11-22 20:56:21,157 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7836624295874075, 'Total loss': 0.7836624295874075} | train loss {'Reaction outcome loss': 0.8054746318201305, 'Total loss': 0.8054746318201305}
2022-11-22 20:56:21,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:21,158 INFO:     Epoch: 30
2022-11-22 20:56:21,899 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8004216240210966, 'Total loss': 0.8004216240210966} | train loss {'Reaction outcome loss': 0.8036177326672473, 'Total loss': 0.8036177326672473}
2022-11-22 20:56:21,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:21,899 INFO:     Epoch: 31
2022-11-22 20:56:22,596 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7999620031226765, 'Total loss': 0.7999620031226765} | train loss {'Reaction outcome loss': 0.8046772826297081, 'Total loss': 0.8046772826297081}
2022-11-22 20:56:22,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:22,597 INFO:     Epoch: 32
2022-11-22 20:56:23,381 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8465482165867632, 'Total loss': 0.8465482165867632} | train loss {'Reaction outcome loss': 0.80078242182249, 'Total loss': 0.80078242182249}
2022-11-22 20:56:23,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:23,381 INFO:     Epoch: 33
2022-11-22 20:56:24,141 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.775742959569801, 'Total loss': 0.775742959569801} | train loss {'Reaction outcome loss': 0.7973574466309566, 'Total loss': 0.7973574466309566}
2022-11-22 20:56:24,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:24,141 INFO:     Epoch: 34
2022-11-22 20:56:24,890 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7873456850647926, 'Total loss': 0.7873456850647926} | train loss {'Reaction outcome loss': 0.7954361103324272, 'Total loss': 0.7954361103324272}
2022-11-22 20:56:24,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:24,890 INFO:     Epoch: 35
2022-11-22 20:56:25,670 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7922934578223662, 'Total loss': 0.7922934578223662} | train loss {'Reaction outcome loss': 0.8086984852547587, 'Total loss': 0.8086984852547587}
2022-11-22 20:56:25,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:25,670 INFO:     Epoch: 36
2022-11-22 20:56:26,447 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7821605476466092, 'Total loss': 0.7821605476466092} | train loss {'Reaction outcome loss': 0.8043685703866394, 'Total loss': 0.8043685703866394}
2022-11-22 20:56:26,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:26,448 INFO:     Epoch: 37
2022-11-22 20:56:27,187 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7769162905487147, 'Total loss': 0.7769162905487147} | train loss {'Reaction outcome loss': 0.7968413853934901, 'Total loss': 0.7968413853934901}
2022-11-22 20:56:27,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:27,188 INFO:     Epoch: 38
2022-11-22 20:56:27,907 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.811835727231069, 'Total loss': 0.811835727231069} | train loss {'Reaction outcome loss': 0.7994596164236184, 'Total loss': 0.7994596164236184}
2022-11-22 20:56:27,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:27,908 INFO:     Epoch: 39
2022-11-22 20:56:28,678 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7919390770522031, 'Total loss': 0.7919390770522031} | train loss {'Reaction outcome loss': 0.8034473968903545, 'Total loss': 0.8034473968903545}
2022-11-22 20:56:28,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:28,679 INFO:     Epoch: 40
2022-11-22 20:56:29,433 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7961781593886289, 'Total loss': 0.7961781593886289} | train loss {'Reaction outcome loss': 0.7993083234258026, 'Total loss': 0.7993083234258026}
2022-11-22 20:56:29,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:29,433 INFO:     Epoch: 41
2022-11-22 20:56:30,151 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7856900990009308, 'Total loss': 0.7856900990009308} | train loss {'Reaction outcome loss': 0.7959619258579455, 'Total loss': 0.7959619258579455}
2022-11-22 20:56:30,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:30,151 INFO:     Epoch: 42
2022-11-22 20:56:30,854 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7974629971114072, 'Total loss': 0.7974629971114072} | train loss {'Reaction outcome loss': 0.803785820238986, 'Total loss': 0.803785820238986}
2022-11-22 20:56:30,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:30,854 INFO:     Epoch: 43
2022-11-22 20:56:31,618 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7846219769933007, 'Total loss': 0.7846219769933007} | train loss {'Reaction outcome loss': 0.8036356201538672, 'Total loss': 0.8036356201538672}
2022-11-22 20:56:31,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:31,618 INFO:     Epoch: 44
2022-11-22 20:56:32,349 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8033884181217714, 'Total loss': 0.8033884181217714} | train loss {'Reaction outcome loss': 0.8090647469286011, 'Total loss': 0.8090647469286011}
2022-11-22 20:56:32,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:32,350 INFO:     Epoch: 45
2022-11-22 20:56:33,103 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7778265713290735, 'Total loss': 0.7778265713290735} | train loss {'Reaction outcome loss': 0.8004072484247357, 'Total loss': 0.8004072484247357}
2022-11-22 20:56:33,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:33,104 INFO:     Epoch: 46
2022-11-22 20:56:33,895 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7732769149270925, 'Total loss': 0.7732769149270925} | train loss {'Reaction outcome loss': 0.7950862292577381, 'Total loss': 0.7950862292577381}
2022-11-22 20:56:33,895 INFO:     Found new best model at epoch 46
2022-11-22 20:56:33,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:33,896 INFO:     Epoch: 47
2022-11-22 20:56:34,679 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7688873356038873, 'Total loss': 0.7688873356038873} | train loss {'Reaction outcome loss': 0.7985569309850453, 'Total loss': 0.7985569309850453}
2022-11-22 20:56:34,679 INFO:     Found new best model at epoch 47
2022-11-22 20:56:34,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:34,680 INFO:     Epoch: 48
2022-11-22 20:56:35,394 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7661845684051514, 'Total loss': 0.7661845684051514} | train loss {'Reaction outcome loss': 0.7951065191192183, 'Total loss': 0.7951065191192183}
2022-11-22 20:56:35,394 INFO:     Found new best model at epoch 48
2022-11-22 20:56:35,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:35,395 INFO:     Epoch: 49
2022-11-22 20:56:36,159 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.790868608111685, 'Total loss': 0.790868608111685} | train loss {'Reaction outcome loss': 0.8020502943017704, 'Total loss': 0.8020502943017704}
2022-11-22 20:56:36,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:36,159 INFO:     Epoch: 50
2022-11-22 20:56:36,878 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7929607832973654, 'Total loss': 0.7929607832973654} | train loss {'Reaction outcome loss': 0.7995516786932463, 'Total loss': 0.7995516786932463}
2022-11-22 20:56:36,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:36,878 INFO:     Epoch: 51
2022-11-22 20:56:37,663 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7564305771480907, 'Total loss': 0.7564305771480907} | train loss {'Reaction outcome loss': 0.7993160787864253, 'Total loss': 0.7993160787864253}
2022-11-22 20:56:37,663 INFO:     Found new best model at epoch 51
2022-11-22 20:56:37,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:37,664 INFO:     Epoch: 52
2022-11-22 20:56:38,418 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7653437968004834, 'Total loss': 0.7653437968004834} | train loss {'Reaction outcome loss': 0.8013887816233191, 'Total loss': 0.8013887816233191}
2022-11-22 20:56:38,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:38,418 INFO:     Epoch: 53
2022-11-22 20:56:39,150 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7711512006141923, 'Total loss': 0.7711512006141923} | train loss {'Reaction outcome loss': 0.7954407742526005, 'Total loss': 0.7954407742526005}
2022-11-22 20:56:39,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:39,151 INFO:     Epoch: 54
2022-11-22 20:56:39,938 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7804238762367856, 'Total loss': 0.7804238762367856} | train loss {'Reaction outcome loss': 0.7958505538552396, 'Total loss': 0.7958505538552396}
2022-11-22 20:56:39,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:39,938 INFO:     Epoch: 55
2022-11-22 20:56:40,740 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8013687309893694, 'Total loss': 0.8013687309893694} | train loss {'Reaction outcome loss': 0.7960521937743855, 'Total loss': 0.7960521937743855}
2022-11-22 20:56:40,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:40,740 INFO:     Epoch: 56
2022-11-22 20:56:41,499 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7828234887935899, 'Total loss': 0.7828234887935899} | train loss {'Reaction outcome loss': 0.7944326526843585, 'Total loss': 0.7944326526843585}
2022-11-22 20:56:41,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:41,499 INFO:     Epoch: 57
2022-11-22 20:56:42,278 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7765295261686499, 'Total loss': 0.7765295261686499} | train loss {'Reaction outcome loss': 0.8009245331712097, 'Total loss': 0.8009245331712097}
2022-11-22 20:56:42,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:42,279 INFO:     Epoch: 58
2022-11-22 20:56:43,104 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7681669294834137, 'Total loss': 0.7681669294834137} | train loss {'Reaction outcome loss': 0.7997681733205734, 'Total loss': 0.7997681733205734}
2022-11-22 20:56:43,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:43,104 INFO:     Epoch: 59
2022-11-22 20:56:43,868 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7745249244299802, 'Total loss': 0.7745249244299802} | train loss {'Reaction outcome loss': 0.7988929090953549, 'Total loss': 0.7988929090953549}
2022-11-22 20:56:43,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:43,869 INFO:     Epoch: 60
2022-11-22 20:56:44,625 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7943700206550685, 'Total loss': 0.7943700206550685} | train loss {'Reaction outcome loss': 0.7953509772837404, 'Total loss': 0.7953509772837404}
2022-11-22 20:56:44,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:44,626 INFO:     Epoch: 61
2022-11-22 20:56:45,401 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8102332401004705, 'Total loss': 0.8102332401004705} | train loss {'Reaction outcome loss': 0.7980330674513149, 'Total loss': 0.7980330674513149}
2022-11-22 20:56:45,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:45,401 INFO:     Epoch: 62
2022-11-22 20:56:46,192 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7887077162211592, 'Total loss': 0.7887077162211592} | train loss {'Reaction outcome loss': 0.7962516899020807, 'Total loss': 0.7962516899020807}
2022-11-22 20:56:46,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:46,192 INFO:     Epoch: 63
2022-11-22 20:56:46,950 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7918586568398909, 'Total loss': 0.7918586568398909} | train loss {'Reaction outcome loss': 0.8049790564818904, 'Total loss': 0.8049790564818904}
2022-11-22 20:56:46,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:46,950 INFO:     Epoch: 64
2022-11-22 20:56:47,684 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7874855934218927, 'Total loss': 0.7874855934218927} | train loss {'Reaction outcome loss': 0.8018314629672509, 'Total loss': 0.8018314629672509}
2022-11-22 20:56:47,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:47,685 INFO:     Epoch: 65
2022-11-22 20:56:48,443 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7753597863695838, 'Total loss': 0.7753597863695838} | train loss {'Reaction outcome loss': 0.7969530466114462, 'Total loss': 0.7969530466114462}
2022-11-22 20:56:48,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:48,443 INFO:     Epoch: 66
2022-11-22 20:56:49,190 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7813775918700478, 'Total loss': 0.7813775918700478} | train loss {'Reaction outcome loss': 0.7927472196851182, 'Total loss': 0.7927472196851182}
2022-11-22 20:56:49,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:49,190 INFO:     Epoch: 67
2022-11-22 20:56:49,928 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.823722047561949, 'Total loss': 0.823722047561949} | train loss {'Reaction outcome loss': 0.7964033082670529, 'Total loss': 0.7964033082670529}
2022-11-22 20:56:49,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:49,928 INFO:     Epoch: 68
2022-11-22 20:56:50,718 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7733007235960527, 'Total loss': 0.7733007235960527} | train loss {'Reaction outcome loss': 0.7901700631326992, 'Total loss': 0.7901700631326992}
2022-11-22 20:56:50,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:50,718 INFO:     Epoch: 69
2022-11-22 20:56:51,451 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7802528603510424, 'Total loss': 0.7802528603510424} | train loss {'Reaction outcome loss': 0.8085809421201466, 'Total loss': 0.8085809421201466}
2022-11-22 20:56:51,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:51,452 INFO:     Epoch: 70
2022-11-22 20:56:52,213 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7703612900593064, 'Total loss': 0.7703612900593064} | train loss {'Reaction outcome loss': 0.7915905834088924, 'Total loss': 0.7915905834088924}
2022-11-22 20:56:52,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:52,213 INFO:     Epoch: 71
2022-11-22 20:56:52,958 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7898630313575268, 'Total loss': 0.7898630313575268} | train loss {'Reaction outcome loss': 0.7952031720022441, 'Total loss': 0.7952031720022441}
2022-11-22 20:56:52,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:52,958 INFO:     Epoch: 72
2022-11-22 20:56:53,750 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8042760721661828, 'Total loss': 0.8042760721661828} | train loss {'Reaction outcome loss': 0.7954986423615985, 'Total loss': 0.7954986423615985}
2022-11-22 20:56:53,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:53,751 INFO:     Epoch: 73
2022-11-22 20:56:54,482 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8357013328508898, 'Total loss': 0.8357013328508898} | train loss {'Reaction outcome loss': 0.7956954019996318, 'Total loss': 0.7956954019996318}
2022-11-22 20:56:54,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:54,482 INFO:     Epoch: 74
2022-11-22 20:56:55,239 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7861415493217382, 'Total loss': 0.7861415493217382} | train loss {'Reaction outcome loss': 0.799731857139572, 'Total loss': 0.799731857139572}
2022-11-22 20:56:55,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:55,239 INFO:     Epoch: 75
2022-11-22 20:56:55,987 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7677334526723082, 'Total loss': 0.7677334526723082} | train loss {'Reaction outcome loss': 0.7974527538546666, 'Total loss': 0.7974527538546666}
2022-11-22 20:56:55,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:55,988 INFO:     Epoch: 76
2022-11-22 20:56:56,703 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7704205045645888, 'Total loss': 0.7704205045645888} | train loss {'Reaction outcome loss': 0.7998006627385915, 'Total loss': 0.7998006627385915}
2022-11-22 20:56:56,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:56,704 INFO:     Epoch: 77
2022-11-22 20:56:57,437 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7697774449532683, 'Total loss': 0.7697774449532683} | train loss {'Reaction outcome loss': 0.7918430431651683, 'Total loss': 0.7918430431651683}
2022-11-22 20:56:57,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:57,437 INFO:     Epoch: 78
2022-11-22 20:56:58,179 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7864975279027765, 'Total loss': 0.7864975279027765} | train loss {'Reaction outcome loss': 0.7862642715696381, 'Total loss': 0.7862642715696381}
2022-11-22 20:56:58,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:58,180 INFO:     Epoch: 79
2022-11-22 20:56:58,969 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7847112159837376, 'Total loss': 0.7847112159837376} | train loss {'Reaction outcome loss': 0.7884281088224789, 'Total loss': 0.7884281088224789}
2022-11-22 20:56:58,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:58,970 INFO:     Epoch: 80
2022-11-22 20:56:59,720 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7731028036637739, 'Total loss': 0.7731028036637739} | train loss {'Reaction outcome loss': 0.7949662708077836, 'Total loss': 0.7949662708077836}
2022-11-22 20:56:59,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:56:59,720 INFO:     Epoch: 81
2022-11-22 20:57:00,451 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7911987446925857, 'Total loss': 0.7911987446925857} | train loss {'Reaction outcome loss': 0.7959032654762268, 'Total loss': 0.7959032654762268}
2022-11-22 20:57:00,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:00,451 INFO:     Epoch: 82
2022-11-22 20:57:01,189 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7751666713844646, 'Total loss': 0.7751666713844646} | train loss {'Reaction outcome loss': 0.7991120388150698, 'Total loss': 0.7991120388150698}
2022-11-22 20:57:01,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:01,190 INFO:     Epoch: 83
2022-11-22 20:57:01,955 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7810272445732896, 'Total loss': 0.7810272445732896} | train loss {'Reaction outcome loss': 0.7916442217373172, 'Total loss': 0.7916442217373172}
2022-11-22 20:57:01,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:01,955 INFO:     Epoch: 84
2022-11-22 20:57:02,740 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7629218548536301, 'Total loss': 0.7629218548536301} | train loss {'Reaction outcome loss': 0.7867795834657152, 'Total loss': 0.7867795834657152}
2022-11-22 20:57:02,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:02,740 INFO:     Epoch: 85
2022-11-22 20:57:03,507 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7704826241189783, 'Total loss': 0.7704826241189783} | train loss {'Reaction outcome loss': 0.7892564660624454, 'Total loss': 0.7892564660624454}
2022-11-22 20:57:03,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:03,507 INFO:     Epoch: 86
2022-11-22 20:57:04,293 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7870920198884878, 'Total loss': 0.7870920198884878} | train loss {'Reaction outcome loss': 0.7810353339924986, 'Total loss': 0.7810353339924986}
2022-11-22 20:57:04,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:04,293 INFO:     Epoch: 87
2022-11-22 20:57:05,051 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.794202321632342, 'Total loss': 0.794202321632342} | train loss {'Reaction outcome loss': 0.7793253900913092, 'Total loss': 0.7793253900913092}
2022-11-22 20:57:05,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:05,051 INFO:     Epoch: 88
2022-11-22 20:57:05,825 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7724374146624045, 'Total loss': 0.7724374146624045} | train loss {'Reaction outcome loss': 0.7826464444036908, 'Total loss': 0.7826464444036908}
2022-11-22 20:57:05,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:05,825 INFO:     Epoch: 89
2022-11-22 20:57:06,612 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7667128497903998, 'Total loss': 0.7667128497903998} | train loss {'Reaction outcome loss': 0.7796058113034438, 'Total loss': 0.7796058113034438}
2022-11-22 20:57:06,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:06,612 INFO:     Epoch: 90
2022-11-22 20:57:07,363 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7994237867268649, 'Total loss': 0.7994237867268649} | train loss {'Reaction outcome loss': 0.7790126633879385, 'Total loss': 0.7790126633879385}
2022-11-22 20:57:07,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:07,363 INFO:     Epoch: 91
2022-11-22 20:57:08,075 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.752873955802484, 'Total loss': 0.752873955802484} | train loss {'Reaction outcome loss': 0.77916572402846, 'Total loss': 0.77916572402846}
2022-11-22 20:57:08,075 INFO:     Found new best model at epoch 91
2022-11-22 20:57:08,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:08,076 INFO:     Epoch: 92
2022-11-22 20:57:08,828 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8210655708204616, 'Total loss': 0.8210655708204616} | train loss {'Reaction outcome loss': 0.7787293461170274, 'Total loss': 0.7787293461170274}
2022-11-22 20:57:08,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:08,828 INFO:     Epoch: 93
2022-11-22 20:57:09,626 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7812322202053937, 'Total loss': 0.7812322202053937} | train loss {'Reaction outcome loss': 0.7806781794619464, 'Total loss': 0.7806781794619464}
2022-11-22 20:57:09,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:09,626 INFO:     Epoch: 94
2022-11-22 20:57:10,423 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7587868395176801, 'Total loss': 0.7587868395176801} | train loss {'Reaction outcome loss': 0.7778199442364426, 'Total loss': 0.7778199442364426}
2022-11-22 20:57:10,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:10,424 INFO:     Epoch: 95
2022-11-22 20:57:11,171 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7570128508589484, 'Total loss': 0.7570128508589484} | train loss {'Reaction outcome loss': 0.7749214751819368, 'Total loss': 0.7749214751819368}
2022-11-22 20:57:11,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:11,171 INFO:     Epoch: 96
2022-11-22 20:57:11,944 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7479684359648011, 'Total loss': 0.7479684359648011} | train loss {'Reaction outcome loss': 0.7725117878633955, 'Total loss': 0.7725117878633955}
2022-11-22 20:57:11,944 INFO:     Found new best model at epoch 96
2022-11-22 20:57:11,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:11,945 INFO:     Epoch: 97
2022-11-22 20:57:12,691 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7474592558362267, 'Total loss': 0.7474592558362267} | train loss {'Reaction outcome loss': 0.7736061759564558, 'Total loss': 0.7736061759564558}
2022-11-22 20:57:12,691 INFO:     Found new best model at epoch 97
2022-11-22 20:57:12,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:12,692 INFO:     Epoch: 98
2022-11-22 20:57:13,417 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7521663904190063, 'Total loss': 0.7521663904190063} | train loss {'Reaction outcome loss': 0.7719934062677839, 'Total loss': 0.7719934062677839}
2022-11-22 20:57:13,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:13,417 INFO:     Epoch: 99
2022-11-22 20:57:14,180 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7406075949018652, 'Total loss': 0.7406075949018652} | train loss {'Reaction outcome loss': 0.7744162588225685, 'Total loss': 0.7744162588225685}
2022-11-22 20:57:14,181 INFO:     Found new best model at epoch 99
2022-11-22 20:57:14,181 INFO:     Best model found after epoch 100 of 100.
2022-11-22 20:57:14,182 INFO:   Done with stage: TRAINING
2022-11-22 20:57:14,182 INFO:   Starting stage: EVALUATION
2022-11-22 20:57:14,301 INFO:   Done with stage: EVALUATION
2022-11-22 20:57:14,301 INFO:   Leaving out SEQ value Fold_7
2022-11-22 20:57:14,314 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:57:14,314 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:57:14,988 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:57:14,988 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:57:15,059 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:57:15,060 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:57:15,060 INFO:     No hyperparam tuning for this model
2022-11-22 20:57:15,060 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:57:15,060 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:57:15,061 INFO:     None feature selector for col prot
2022-11-22 20:57:15,061 INFO:     None feature selector for col prot
2022-11-22 20:57:15,061 INFO:     None feature selector for col prot
2022-11-22 20:57:15,062 INFO:     None feature selector for col chem
2022-11-22 20:57:15,062 INFO:     None feature selector for col chem
2022-11-22 20:57:15,062 INFO:     None feature selector for col chem
2022-11-22 20:57:15,062 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:57:15,062 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:57:15,063 INFO:     Number of params in model 126091
2022-11-22 20:57:15,067 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:57:15,067 INFO:   Starting stage: TRAINING
2022-11-22 20:57:15,117 INFO:     Val loss before train {'Reaction outcome loss': 1.025277847593481, 'Total loss': 1.025277847593481}
2022-11-22 20:57:15,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:15,117 INFO:     Epoch: 0
2022-11-22 20:57:15,886 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9009525979107077, 'Total loss': 0.9009525979107077} | train loss {'Reaction outcome loss': 0.8740338352527696, 'Total loss': 0.8740338352527696}
2022-11-22 20:57:15,886 INFO:     Found new best model at epoch 0
2022-11-22 20:57:15,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:15,887 INFO:     Epoch: 1
2022-11-22 20:57:16,662 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.893351056359031, 'Total loss': 0.893351056359031} | train loss {'Reaction outcome loss': 0.8341506272252754, 'Total loss': 0.8341506272252754}
2022-11-22 20:57:16,662 INFO:     Found new best model at epoch 1
2022-11-22 20:57:16,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:16,663 INFO:     Epoch: 2
2022-11-22 20:57:17,403 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8656990338455547, 'Total loss': 0.8656990338455547} | train loss {'Reaction outcome loss': 0.8280499546151412, 'Total loss': 0.8280499546151412}
2022-11-22 20:57:17,403 INFO:     Found new best model at epoch 2
2022-11-22 20:57:17,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:17,404 INFO:     Epoch: 3
2022-11-22 20:57:18,116 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8889298601584001, 'Total loss': 0.8889298601584001} | train loss {'Reaction outcome loss': 0.8114497641078856, 'Total loss': 0.8114497641078856}
2022-11-22 20:57:18,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:18,116 INFO:     Epoch: 4
2022-11-22 20:57:18,838 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8577670360153372, 'Total loss': 0.8577670360153372} | train loss {'Reaction outcome loss': 0.8156745696840016, 'Total loss': 0.8156745696840016}
2022-11-22 20:57:18,838 INFO:     Found new best model at epoch 4
2022-11-22 20:57:18,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:18,839 INFO:     Epoch: 5
2022-11-22 20:57:19,644 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.9086884395642714, 'Total loss': 0.9086884395642714} | train loss {'Reaction outcome loss': 0.8070163276755375, 'Total loss': 0.8070163276755375}
2022-11-22 20:57:19,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:19,644 INFO:     Epoch: 6
2022-11-22 20:57:20,412 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8485010598193515, 'Total loss': 0.8485010598193515} | train loss {'Reaction outcome loss': 0.806507031565253, 'Total loss': 0.806507031565253}
2022-11-22 20:57:20,412 INFO:     Found new best model at epoch 6
2022-11-22 20:57:20,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:20,413 INFO:     Epoch: 7
2022-11-22 20:57:21,152 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8775588118217208, 'Total loss': 0.8775588118217208} | train loss {'Reaction outcome loss': 0.8008625199678938, 'Total loss': 0.8008625199678938}
2022-11-22 20:57:21,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:21,152 INFO:     Epoch: 8
2022-11-22 20:57:21,881 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8567020486701619, 'Total loss': 0.8567020486701619} | train loss {'Reaction outcome loss': 0.8000711548907554, 'Total loss': 0.8000711548907554}
2022-11-22 20:57:21,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:21,882 INFO:     Epoch: 9
2022-11-22 20:57:22,640 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.840661811557683, 'Total loss': 0.840661811557683} | train loss {'Reaction outcome loss': 0.800353521760176, 'Total loss': 0.800353521760176}
2022-11-22 20:57:22,641 INFO:     Found new best model at epoch 9
2022-11-22 20:57:22,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:22,642 INFO:     Epoch: 10
2022-11-22 20:57:23,365 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8651596842841669, 'Total loss': 0.8651596842841669} | train loss {'Reaction outcome loss': 0.8100196739681337, 'Total loss': 0.8100196739681337}
2022-11-22 20:57:23,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:23,365 INFO:     Epoch: 11
2022-11-22 20:57:24,163 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8387144505977631, 'Total loss': 0.8387144505977631} | train loss {'Reaction outcome loss': 0.8031011077797847, 'Total loss': 0.8031011077797847}
2022-11-22 20:57:24,163 INFO:     Found new best model at epoch 11
2022-11-22 20:57:24,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:24,165 INFO:     Epoch: 12
2022-11-22 20:57:24,920 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8675902032039382, 'Total loss': 0.8675902032039382} | train loss {'Reaction outcome loss': 0.8005637111451461, 'Total loss': 0.8005637111451461}
2022-11-22 20:57:24,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:24,920 INFO:     Epoch: 13
2022-11-22 20:57:25,657 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.844675129110163, 'Total loss': 0.844675129110163} | train loss {'Reaction outcome loss': 0.7919528903024882, 'Total loss': 0.7919528903024882}
2022-11-22 20:57:25,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:25,657 INFO:     Epoch: 14
2022-11-22 20:57:26,409 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.866626197641546, 'Total loss': 0.866626197641546} | train loss {'Reaction outcome loss': 0.7879510149133471, 'Total loss': 0.7879510149133471}
2022-11-22 20:57:26,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:26,410 INFO:     Epoch: 15
2022-11-22 20:57:27,171 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8448768109083176, 'Total loss': 0.8448768109083176} | train loss {'Reaction outcome loss': 0.7922321059684522, 'Total loss': 0.7922321059684522}
2022-11-22 20:57:27,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:27,171 INFO:     Epoch: 16
2022-11-22 20:57:27,912 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8360814059322531, 'Total loss': 0.8360814059322531} | train loss {'Reaction outcome loss': 0.7964776674745536, 'Total loss': 0.7964776674745536}
2022-11-22 20:57:27,912 INFO:     Found new best model at epoch 16
2022-11-22 20:57:27,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:27,913 INFO:     Epoch: 17
2022-11-22 20:57:28,710 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8664963448589499, 'Total loss': 0.8664963448589499} | train loss {'Reaction outcome loss': 0.7841845480536642, 'Total loss': 0.7841845480536642}
2022-11-22 20:57:28,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:28,711 INFO:     Epoch: 18
2022-11-22 20:57:29,467 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8631407781080767, 'Total loss': 0.8631407781080767} | train loss {'Reaction outcome loss': 0.786602382355856, 'Total loss': 0.786602382355856}
2022-11-22 20:57:29,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:29,467 INFO:     Epoch: 19
2022-11-22 20:57:30,233 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8291779749772765, 'Total loss': 0.8291779749772765} | train loss {'Reaction outcome loss': 0.7895980384728687, 'Total loss': 0.7895980384728687}
2022-11-22 20:57:30,234 INFO:     Found new best model at epoch 19
2022-11-22 20:57:30,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:30,234 INFO:     Epoch: 20
2022-11-22 20:57:31,014 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8427413539452986, 'Total loss': 0.8427413539452986} | train loss {'Reaction outcome loss': 0.7842215744228016, 'Total loss': 0.7842215744228016}
2022-11-22 20:57:31,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:31,015 INFO:     Epoch: 21
2022-11-22 20:57:31,796 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8416574949567969, 'Total loss': 0.8416574949567969} | train loss {'Reaction outcome loss': 0.7923013637905661, 'Total loss': 0.7923013637905661}
2022-11-22 20:57:31,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:31,797 INFO:     Epoch: 22
2022-11-22 20:57:32,509 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8402901969172738, 'Total loss': 0.8402901969172738} | train loss {'Reaction outcome loss': 0.7920702376105042, 'Total loss': 0.7920702376105042}
2022-11-22 20:57:32,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:32,509 INFO:     Epoch: 23
2022-11-22 20:57:33,270 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8450897376645695, 'Total loss': 0.8450897376645695} | train loss {'Reaction outcome loss': 0.7873559404420949, 'Total loss': 0.7873559404420949}
2022-11-22 20:57:33,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:33,270 INFO:     Epoch: 24
2022-11-22 20:57:34,038 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8381154374642805, 'Total loss': 0.8381154374642805} | train loss {'Reaction outcome loss': 0.7878481288429214, 'Total loss': 0.7878481288429214}
2022-11-22 20:57:34,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:34,038 INFO:     Epoch: 25
2022-11-22 20:57:34,761 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.818333005363291, 'Total loss': 0.818333005363291} | train loss {'Reaction outcome loss': 0.7902340002146809, 'Total loss': 0.7902340002146809}
2022-11-22 20:57:34,761 INFO:     Found new best model at epoch 25
2022-11-22 20:57:34,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:34,762 INFO:     Epoch: 26
2022-11-22 20:57:35,507 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8312680985439908, 'Total loss': 0.8312680985439908} | train loss {'Reaction outcome loss': 0.784320741891861, 'Total loss': 0.784320741891861}
2022-11-22 20:57:35,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:35,507 INFO:     Epoch: 27
2022-11-22 20:57:36,249 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8559796451167627, 'Total loss': 0.8559796451167627} | train loss {'Reaction outcome loss': 0.7859259105404379, 'Total loss': 0.7859259105404379}
2022-11-22 20:57:36,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:36,249 INFO:     Epoch: 28
2022-11-22 20:57:36,972 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8556255495006387, 'Total loss': 0.8556255495006387} | train loss {'Reaction outcome loss': 0.778185426344273, 'Total loss': 0.778185426344273}
2022-11-22 20:57:36,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:36,972 INFO:     Epoch: 29
2022-11-22 20:57:37,724 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8303385769779031, 'Total loss': 0.8303385769779031} | train loss {'Reaction outcome loss': 0.781514611200765, 'Total loss': 0.781514611200765}
2022-11-22 20:57:37,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:37,724 INFO:     Epoch: 30
2022-11-22 20:57:38,465 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8464122861623764, 'Total loss': 0.8464122861623764} | train loss {'Reaction outcome loss': 0.7824008736593521, 'Total loss': 0.7824008736593521}
2022-11-22 20:57:38,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:38,465 INFO:     Epoch: 31
2022-11-22 20:57:39,196 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8420908952301199, 'Total loss': 0.8420908952301199} | train loss {'Reaction outcome loss': 0.7848915620612712, 'Total loss': 0.7848915620612712}
2022-11-22 20:57:39,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:39,196 INFO:     Epoch: 32
2022-11-22 20:57:39,932 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8213884214108641, 'Total loss': 0.8213884214108641} | train loss {'Reaction outcome loss': 0.7810336429821817, 'Total loss': 0.7810336429821817}
2022-11-22 20:57:39,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:39,932 INFO:     Epoch: 33
2022-11-22 20:57:40,690 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8400400267405943, 'Total loss': 0.8400400267405943} | train loss {'Reaction outcome loss': 0.7778057416652137, 'Total loss': 0.7778057416652137}
2022-11-22 20:57:40,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:40,690 INFO:     Epoch: 34
2022-11-22 20:57:41,425 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8668645837090232, 'Total loss': 0.8668645837090232} | train loss {'Reaction outcome loss': 0.7828790959317674, 'Total loss': 0.7828790959317674}
2022-11-22 20:57:41,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:41,426 INFO:     Epoch: 35
2022-11-22 20:57:42,165 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8369456753134727, 'Total loss': 0.8369456753134727} | train loss {'Reaction outcome loss': 0.7850997725479033, 'Total loss': 0.7850997725479033}
2022-11-22 20:57:42,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:42,165 INFO:     Epoch: 36
2022-11-22 20:57:42,926 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8298792866143313, 'Total loss': 0.8298792866143313} | train loss {'Reaction outcome loss': 0.7847000876901603, 'Total loss': 0.7847000876901603}
2022-11-22 20:57:42,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:42,927 INFO:     Epoch: 37
2022-11-22 20:57:43,698 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8317471078851006, 'Total loss': 0.8317471078851006} | train loss {'Reaction outcome loss': 0.7845944695265187, 'Total loss': 0.7845944695265187}
2022-11-22 20:57:43,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:43,699 INFO:     Epoch: 38
2022-11-22 20:57:44,500 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8591253716837276, 'Total loss': 0.8591253716837276} | train loss {'Reaction outcome loss': 0.7895959044998957, 'Total loss': 0.7895959044998957}
2022-11-22 20:57:44,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:44,501 INFO:     Epoch: 39
2022-11-22 20:57:45,297 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8368132229555737, 'Total loss': 0.8368132229555737} | train loss {'Reaction outcome loss': 0.7836525052906531, 'Total loss': 0.7836525052906531}
2022-11-22 20:57:45,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:45,297 INFO:     Epoch: 40
2022-11-22 20:57:46,070 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8494788557291031, 'Total loss': 0.8494788557291031} | train loss {'Reaction outcome loss': 0.7889010154525278, 'Total loss': 0.7889010154525278}
2022-11-22 20:57:46,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:46,070 INFO:     Epoch: 41
2022-11-22 20:57:46,908 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8477674248543653, 'Total loss': 0.8477674248543653} | train loss {'Reaction outcome loss': 0.7885414012047925, 'Total loss': 0.7885414012047925}
2022-11-22 20:57:46,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:46,908 INFO:     Epoch: 42
2022-11-22 20:57:47,724 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8423916534944014, 'Total loss': 0.8423916534944014} | train loss {'Reaction outcome loss': 0.7762691460640324, 'Total loss': 0.7762691460640324}
2022-11-22 20:57:47,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:47,724 INFO:     Epoch: 43
2022-11-22 20:57:48,540 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8621223948218606, 'Total loss': 0.8621223948218606} | train loss {'Reaction outcome loss': 0.7824381760016144, 'Total loss': 0.7824381760016144}
2022-11-22 20:57:48,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:48,540 INFO:     Epoch: 44
2022-11-22 20:57:49,387 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.818656562404199, 'Total loss': 0.818656562404199} | train loss {'Reaction outcome loss': 0.7865441728096741, 'Total loss': 0.7865441728096741}
2022-11-22 20:57:49,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:49,388 INFO:     Epoch: 45
2022-11-22 20:57:50,216 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.9143898114562035, 'Total loss': 0.9143898114562035} | train loss {'Reaction outcome loss': 0.7776610294191039, 'Total loss': 0.7776610294191039}
2022-11-22 20:57:50,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:50,216 INFO:     Epoch: 46
2022-11-22 20:57:51,023 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8374486782334067, 'Total loss': 0.8374486782334067} | train loss {'Reaction outcome loss': 0.7776640151676378, 'Total loss': 0.7776640151676378}
2022-11-22 20:57:51,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:51,024 INFO:     Epoch: 47
2022-11-22 20:57:51,859 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8372944837266748, 'Total loss': 0.8372944837266748} | train loss {'Reaction outcome loss': 0.7832939487237197, 'Total loss': 0.7832939487237197}
2022-11-22 20:57:51,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:51,859 INFO:     Epoch: 48
2022-11-22 20:57:52,677 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8477494479580359, 'Total loss': 0.8477494479580359} | train loss {'Reaction outcome loss': 0.7889184779242465, 'Total loss': 0.7889184779242465}
2022-11-22 20:57:52,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:52,677 INFO:     Epoch: 49
2022-11-22 20:57:53,536 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8388655930757523, 'Total loss': 0.8388655930757523} | train loss {'Reaction outcome loss': 0.7844287975114367, 'Total loss': 0.7844287975114367}
2022-11-22 20:57:53,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:53,538 INFO:     Epoch: 50
2022-11-22 20:57:54,345 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8282333416017619, 'Total loss': 0.8282333416017619} | train loss {'Reaction outcome loss': 0.7834512170268456, 'Total loss': 0.7834512170268456}
2022-11-22 20:57:54,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:54,345 INFO:     Epoch: 51
2022-11-22 20:57:55,222 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8459899425506592, 'Total loss': 0.8459899425506592} | train loss {'Reaction outcome loss': 0.7760550625893751, 'Total loss': 0.7760550625893751}
2022-11-22 20:57:55,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:55,222 INFO:     Epoch: 52
2022-11-22 20:57:56,026 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8467733751643788, 'Total loss': 0.8467733751643788} | train loss {'Reaction outcome loss': 0.7812387942061251, 'Total loss': 0.7812387942061251}
2022-11-22 20:57:56,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:56,026 INFO:     Epoch: 53
2022-11-22 20:57:56,880 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8188285306096077, 'Total loss': 0.8188285306096077} | train loss {'Reaction outcome loss': 0.782560795440003, 'Total loss': 0.782560795440003}
2022-11-22 20:57:56,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:56,880 INFO:     Epoch: 54
2022-11-22 20:57:57,714 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8419547446749427, 'Total loss': 0.8419547446749427} | train loss {'Reaction outcome loss': 0.7773780287036046, 'Total loss': 0.7773780287036046}
2022-11-22 20:57:57,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:57,714 INFO:     Epoch: 55
2022-11-22 20:57:58,559 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8573773510076783, 'Total loss': 0.8573773510076783} | train loss {'Reaction outcome loss': 0.7847673266764111, 'Total loss': 0.7847673266764111}
2022-11-22 20:57:58,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:58,559 INFO:     Epoch: 56
2022-11-22 20:57:59,341 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8527015217325904, 'Total loss': 0.8527015217325904} | train loss {'Reaction outcome loss': 0.7802728023606273, 'Total loss': 0.7802728023606273}
2022-11-22 20:57:59,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:57:59,342 INFO:     Epoch: 57
2022-11-22 20:58:00,097 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8279715999960899, 'Total loss': 0.8279715999960899} | train loss {'Reaction outcome loss': 0.7887422197502152, 'Total loss': 0.7887422197502152}
2022-11-22 20:58:00,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:00,098 INFO:     Epoch: 58
2022-11-22 20:58:00,950 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8365150486881082, 'Total loss': 0.8365150486881082} | train loss {'Reaction outcome loss': 0.7817180928913688, 'Total loss': 0.7817180928913688}
2022-11-22 20:58:00,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:00,950 INFO:     Epoch: 59
2022-11-22 20:58:01,817 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8207067081874068, 'Total loss': 0.8207067081874068} | train loss {'Reaction outcome loss': 0.7686965321963616, 'Total loss': 0.7686965321963616}
2022-11-22 20:58:01,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:01,818 INFO:     Epoch: 60
2022-11-22 20:58:02,659 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8180231702598658, 'Total loss': 0.8180231702598658} | train loss {'Reaction outcome loss': 0.776326691573448, 'Total loss': 0.776326691573448}
2022-11-22 20:58:02,660 INFO:     Found new best model at epoch 60
2022-11-22 20:58:02,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:02,661 INFO:     Epoch: 61
2022-11-22 20:58:03,486 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8298811194571581, 'Total loss': 0.8298811194571581} | train loss {'Reaction outcome loss': 0.7730148748347634, 'Total loss': 0.7730148748347634}
2022-11-22 20:58:03,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:03,486 INFO:     Epoch: 62
2022-11-22 20:58:04,331 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8249662653966383, 'Total loss': 0.8249662653966383} | train loss {'Reaction outcome loss': 0.7718788140457169, 'Total loss': 0.7718788140457169}
2022-11-22 20:58:04,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:04,331 INFO:     Epoch: 63
2022-11-22 20:58:05,136 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8268728933551095, 'Total loss': 0.8268728933551095} | train loss {'Reaction outcome loss': 0.7694264247349882, 'Total loss': 0.7694264247349882}
2022-11-22 20:58:05,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:05,136 INFO:     Epoch: 64
2022-11-22 20:58:05,967 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8207344141873446, 'Total loss': 0.8207344141873446} | train loss {'Reaction outcome loss': 0.7704739823997745, 'Total loss': 0.7704739823997745}
2022-11-22 20:58:05,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:05,968 INFO:     Epoch: 65
2022-11-22 20:58:06,742 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8314216699112545, 'Total loss': 0.8314216699112545} | train loss {'Reaction outcome loss': 0.7755640188933384, 'Total loss': 0.7755640188933384}
2022-11-22 20:58:06,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:06,742 INFO:     Epoch: 66
2022-11-22 20:58:07,553 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8431583432988687, 'Total loss': 0.8431583432988687} | train loss {'Reaction outcome loss': 0.7698002569829887, 'Total loss': 0.7698002569829887}
2022-11-22 20:58:07,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:07,554 INFO:     Epoch: 67
2022-11-22 20:58:08,373 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8071901920166883, 'Total loss': 0.8071901920166883} | train loss {'Reaction outcome loss': 0.7718331863281698, 'Total loss': 0.7718331863281698}
2022-11-22 20:58:08,373 INFO:     Found new best model at epoch 67
2022-11-22 20:58:08,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:08,374 INFO:     Epoch: 68
2022-11-22 20:58:09,198 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8471994968977842, 'Total loss': 0.8471994968977842} | train loss {'Reaction outcome loss': 0.7665712146865211, 'Total loss': 0.7665712146865211}
2022-11-22 20:58:09,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:09,199 INFO:     Epoch: 69
2022-11-22 20:58:09,998 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8126428777521307, 'Total loss': 0.8126428777521307} | train loss {'Reaction outcome loss': 0.7804328717804148, 'Total loss': 0.7804328717804148}
2022-11-22 20:58:09,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:09,998 INFO:     Epoch: 70
2022-11-22 20:58:10,817 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8281051685864275, 'Total loss': 0.8281051685864275} | train loss {'Reaction outcome loss': 0.7755244033418687, 'Total loss': 0.7755244033418687}
2022-11-22 20:58:10,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:10,817 INFO:     Epoch: 71
2022-11-22 20:58:11,674 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8157248259945349, 'Total loss': 0.8157248259945349} | train loss {'Reaction outcome loss': 0.7687511339120054, 'Total loss': 0.7687511339120054}
2022-11-22 20:58:11,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:11,674 INFO:     Epoch: 72
2022-11-22 20:58:12,490 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8187448213046248, 'Total loss': 0.8187448213046248} | train loss {'Reaction outcome loss': 0.7727496926842431, 'Total loss': 0.7727496926842431}
2022-11-22 20:58:12,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:12,491 INFO:     Epoch: 73
2022-11-22 20:58:13,312 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8060394464568659, 'Total loss': 0.8060394464568659} | train loss {'Reaction outcome loss': 0.7785856134978383, 'Total loss': 0.7785856134978383}
2022-11-22 20:58:13,312 INFO:     Found new best model at epoch 73
2022-11-22 20:58:13,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:13,313 INFO:     Epoch: 74
2022-11-22 20:58:14,054 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8221634822812948, 'Total loss': 0.8221634822812948} | train loss {'Reaction outcome loss': 0.7637324396837578, 'Total loss': 0.7637324396837578}
2022-11-22 20:58:14,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:14,055 INFO:     Epoch: 75
2022-11-22 20:58:14,873 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.823624119839885, 'Total loss': 0.823624119839885} | train loss {'Reaction outcome loss': 0.7663446250956069, 'Total loss': 0.7663446250956069}
2022-11-22 20:58:14,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:14,873 INFO:     Epoch: 76
2022-11-22 20:58:15,723 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.83339447053996, 'Total loss': 0.83339447053996} | train loss {'Reaction outcome loss': 0.7645695975676239, 'Total loss': 0.7645695975676239}
2022-11-22 20:58:15,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:15,724 INFO:     Epoch: 77
2022-11-22 20:58:16,505 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8166459839452397, 'Total loss': 0.8166459839452397} | train loss {'Reaction outcome loss': 0.7650494142341228, 'Total loss': 0.7650494142341228}
2022-11-22 20:58:16,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:16,505 INFO:     Epoch: 78
2022-11-22 20:58:17,316 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8329346098683097, 'Total loss': 0.8329346098683097} | train loss {'Reaction outcome loss': 0.7687197641322487, 'Total loss': 0.7687197641322487}
2022-11-22 20:58:17,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:17,316 INFO:     Epoch: 79
2022-11-22 20:58:18,123 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.85289851101962, 'Total loss': 0.85289851101962} | train loss {'Reaction outcome loss': 0.7645286792203, 'Total loss': 0.7645286792203}
2022-11-22 20:58:18,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:18,123 INFO:     Epoch: 80
2022-11-22 20:58:18,932 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8259860615838658, 'Total loss': 0.8259860615838658} | train loss {'Reaction outcome loss': 0.7571170521289231, 'Total loss': 0.7571170521289231}
2022-11-22 20:58:18,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:18,932 INFO:     Epoch: 81
2022-11-22 20:58:19,704 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8006054610013962, 'Total loss': 0.8006054610013962} | train loss {'Reaction outcome loss': 0.761165079438252, 'Total loss': 0.761165079438252}
2022-11-22 20:58:19,705 INFO:     Found new best model at epoch 81
2022-11-22 20:58:19,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:19,706 INFO:     Epoch: 82
2022-11-22 20:58:20,474 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8204316422343254, 'Total loss': 0.8204316422343254} | train loss {'Reaction outcome loss': 0.756552671975935, 'Total loss': 0.756552671975935}
2022-11-22 20:58:20,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:20,474 INFO:     Epoch: 83
2022-11-22 20:58:21,285 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8431483303958719, 'Total loss': 0.8431483303958719} | train loss {'Reaction outcome loss': 0.7642414514352436, 'Total loss': 0.7642414514352436}
2022-11-22 20:58:21,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:21,285 INFO:     Epoch: 84
2022-11-22 20:58:22,093 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8743991960178722, 'Total loss': 0.8743991960178722} | train loss {'Reaction outcome loss': 0.7539225781132818, 'Total loss': 0.7539225781132818}
2022-11-22 20:58:22,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:22,093 INFO:     Epoch: 85
2022-11-22 20:58:22,899 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.840158916332505, 'Total loss': 0.840158916332505} | train loss {'Reaction outcome loss': 0.7663557940890432, 'Total loss': 0.7663557940890432}
2022-11-22 20:58:22,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:22,899 INFO:     Epoch: 86
2022-11-22 20:58:23,684 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8028222586620938, 'Total loss': 0.8028222586620938} | train loss {'Reaction outcome loss': 0.7494482763624384, 'Total loss': 0.7494482763624384}
2022-11-22 20:58:23,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:23,684 INFO:     Epoch: 87
2022-11-22 20:58:24,505 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8191972611980005, 'Total loss': 0.8191972611980005} | train loss {'Reaction outcome loss': 0.7538658445663298, 'Total loss': 0.7538658445663298}
2022-11-22 20:58:24,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:24,505 INFO:     Epoch: 88
2022-11-22 20:58:25,284 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8059494400566275, 'Total loss': 0.8059494400566275} | train loss {'Reaction outcome loss': 0.7565556501570018, 'Total loss': 0.7565556501570018}
2022-11-22 20:58:25,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:25,285 INFO:     Epoch: 89
2022-11-22 20:58:26,100 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8241969414732673, 'Total loss': 0.8241969414732673} | train loss {'Reaction outcome loss': 0.7473480989817183, 'Total loss': 0.7473480989817183}
2022-11-22 20:58:26,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:26,100 INFO:     Epoch: 90
2022-11-22 20:58:26,930 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.831009950150143, 'Total loss': 0.831009950150143} | train loss {'Reaction outcome loss': 0.7464219139896424, 'Total loss': 0.7464219139896424}
2022-11-22 20:58:26,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:26,931 INFO:     Epoch: 91
2022-11-22 20:58:27,706 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.813476870005781, 'Total loss': 0.813476870005781} | train loss {'Reaction outcome loss': 0.76909943196455, 'Total loss': 0.76909943196455}
2022-11-22 20:58:27,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:27,707 INFO:     Epoch: 92
2022-11-22 20:58:28,506 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7876827777786688, 'Total loss': 0.7876827777786688} | train loss {'Reaction outcome loss': 0.7413511859622561, 'Total loss': 0.7413511859622561}
2022-11-22 20:58:28,507 INFO:     Found new best model at epoch 92
2022-11-22 20:58:28,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:28,508 INFO:     Epoch: 93
2022-11-22 20:58:29,337 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8108765923164107, 'Total loss': 0.8108765923164107} | train loss {'Reaction outcome loss': 0.737591259754621, 'Total loss': 0.737591259754621}
2022-11-22 20:58:29,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:29,337 INFO:     Epoch: 94
2022-11-22 20:58:30,071 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8189627623016184, 'Total loss': 0.8189627623016184} | train loss {'Reaction outcome loss': 0.7345529726521689, 'Total loss': 0.7345529726521689}
2022-11-22 20:58:30,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:30,071 INFO:     Epoch: 95
2022-11-22 20:58:30,861 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7832071469588713, 'Total loss': 0.7832071469588713} | train loss {'Reaction outcome loss': 0.7297660090361047, 'Total loss': 0.7297660090361047}
2022-11-22 20:58:30,862 INFO:     Found new best model at epoch 95
2022-11-22 20:58:30,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:30,862 INFO:     Epoch: 96
2022-11-22 20:58:31,671 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8278873048045419, 'Total loss': 0.8278873048045419} | train loss {'Reaction outcome loss': 0.7235312750223677, 'Total loss': 0.7235312750223677}
2022-11-22 20:58:31,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:31,672 INFO:     Epoch: 97
2022-11-22 20:58:32,429 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8162756609645757, 'Total loss': 0.8162756609645757} | train loss {'Reaction outcome loss': 0.7394209672444263, 'Total loss': 0.7394209672444263}
2022-11-22 20:58:32,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:32,429 INFO:     Epoch: 98
2022-11-22 20:58:33,261 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8478555496443402, 'Total loss': 0.8478555496443402} | train loss {'Reaction outcome loss': 0.7365874101517171, 'Total loss': 0.7365874101517171}
2022-11-22 20:58:33,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:33,261 INFO:     Epoch: 99
2022-11-22 20:58:34,049 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8114973916248842, 'Total loss': 0.8114973916248842} | train loss {'Reaction outcome loss': 0.7306280623563388, 'Total loss': 0.7306280623563388}
2022-11-22 20:58:34,049 INFO:     Best model found after epoch 96 of 100.
2022-11-22 20:58:34,049 INFO:   Done with stage: TRAINING
2022-11-22 20:58:34,049 INFO:   Starting stage: EVALUATION
2022-11-22 20:58:34,168 INFO:   Done with stage: EVALUATION
2022-11-22 20:58:34,169 INFO:   Leaving out SEQ value Fold_8
2022-11-22 20:58:34,183 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-22 20:58:34,183 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:58:34,861 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:58:34,861 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:58:34,933 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:58:34,933 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:58:34,933 INFO:     No hyperparam tuning for this model
2022-11-22 20:58:34,933 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:58:34,933 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:58:34,934 INFO:     None feature selector for col prot
2022-11-22 20:58:34,934 INFO:     None feature selector for col prot
2022-11-22 20:58:34,934 INFO:     None feature selector for col prot
2022-11-22 20:58:34,935 INFO:     None feature selector for col chem
2022-11-22 20:58:34,935 INFO:     None feature selector for col chem
2022-11-22 20:58:34,935 INFO:     None feature selector for col chem
2022-11-22 20:58:34,935 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:58:34,935 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:58:34,936 INFO:     Number of params in model 126091
2022-11-22 20:58:34,940 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:58:34,940 INFO:   Starting stage: TRAINING
2022-11-22 20:58:34,990 INFO:     Val loss before train {'Reaction outcome loss': 1.005760908126831, 'Total loss': 1.005760908126831}
2022-11-22 20:58:34,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:34,990 INFO:     Epoch: 0
2022-11-22 20:58:35,771 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8454233574312787, 'Total loss': 0.8454233574312787} | train loss {'Reaction outcome loss': 0.8720710320306606, 'Total loss': 0.8720710320306606}
2022-11-22 20:58:35,771 INFO:     Found new best model at epoch 0
2022-11-22 20:58:35,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:35,772 INFO:     Epoch: 1
2022-11-22 20:58:36,563 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8206930167453234, 'Total loss': 0.8206930167453234} | train loss {'Reaction outcome loss': 0.8271888674038356, 'Total loss': 0.8271888674038356}
2022-11-22 20:58:36,563 INFO:     Found new best model at epoch 1
2022-11-22 20:58:36,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:36,564 INFO:     Epoch: 2
2022-11-22 20:58:37,343 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8380538952905078, 'Total loss': 0.8380538952905078} | train loss {'Reaction outcome loss': 0.8130888996309922, 'Total loss': 0.8130888996309922}
2022-11-22 20:58:37,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:37,344 INFO:     Epoch: 3
2022-11-22 20:58:38,147 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8643422417862471, 'Total loss': 0.8643422417862471} | train loss {'Reaction outcome loss': 0.8087766616315138, 'Total loss': 0.8087766616315138}
2022-11-22 20:58:38,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:38,147 INFO:     Epoch: 4
2022-11-22 20:58:38,954 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.809233407641566, 'Total loss': 0.809233407641566} | train loss {'Reaction outcome loss': 0.8038970630188458, 'Total loss': 0.8038970630188458}
2022-11-22 20:58:38,954 INFO:     Found new best model at epoch 4
2022-11-22 20:58:38,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:38,955 INFO:     Epoch: 5
2022-11-22 20:58:39,698 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8208607462949531, 'Total loss': 0.8208607462949531} | train loss {'Reaction outcome loss': 0.7994796499365666, 'Total loss': 0.7994796499365666}
2022-11-22 20:58:39,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:39,699 INFO:     Epoch: 6
2022-11-22 20:58:40,481 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8145566485648932, 'Total loss': 0.8145566485648932} | train loss {'Reaction outcome loss': 0.7960971492480059, 'Total loss': 0.7960971492480059}
2022-11-22 20:58:40,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:40,481 INFO:     Epoch: 7
2022-11-22 20:58:41,276 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8088693993036137, 'Total loss': 0.8088693993036137} | train loss {'Reaction outcome loss': 0.7913001711007024, 'Total loss': 0.7913001711007024}
2022-11-22 20:58:41,277 INFO:     Found new best model at epoch 7
2022-11-22 20:58:41,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:41,278 INFO:     Epoch: 8
2022-11-22 20:58:42,092 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8150356786195622, 'Total loss': 0.8150356786195622} | train loss {'Reaction outcome loss': 0.7919922085081945, 'Total loss': 0.7919922085081945}
2022-11-22 20:58:42,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:42,092 INFO:     Epoch: 9
2022-11-22 20:58:42,884 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8098179919775143, 'Total loss': 0.8098179919775143} | train loss {'Reaction outcome loss': 0.7934026273547626, 'Total loss': 0.7934026273547626}
2022-11-22 20:58:42,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:42,884 INFO:     Epoch: 10
2022-11-22 20:58:43,653 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8370435605215472, 'Total loss': 0.8370435605215472} | train loss {'Reaction outcome loss': 0.78521037907874, 'Total loss': 0.78521037907874}
2022-11-22 20:58:43,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:43,653 INFO:     Epoch: 11
2022-11-22 20:58:44,412 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8165969342686409, 'Total loss': 0.8165969342686409} | train loss {'Reaction outcome loss': 0.7884057166635013, 'Total loss': 0.7884057166635013}
2022-11-22 20:58:44,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:44,413 INFO:     Epoch: 12
2022-11-22 20:58:45,193 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8156391430732816, 'Total loss': 0.8156391430732816} | train loss {'Reaction outcome loss': 0.7879453032720284, 'Total loss': 0.7879453032720284}
2022-11-22 20:58:45,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:45,193 INFO:     Epoch: 13
2022-11-22 20:58:45,936 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8227563784566037, 'Total loss': 0.8227563784566037} | train loss {'Reaction outcome loss': 0.7870102457580019, 'Total loss': 0.7870102457580019}
2022-11-22 20:58:45,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:45,937 INFO:     Epoch: 14
2022-11-22 20:58:46,713 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7963814887889596, 'Total loss': 0.7963814887889596} | train loss {'Reaction outcome loss': 0.7886824372117637, 'Total loss': 0.7886824372117637}
2022-11-22 20:58:46,714 INFO:     Found new best model at epoch 14
2022-11-22 20:58:46,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:46,714 INFO:     Epoch: 15
2022-11-22 20:58:47,447 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8152406991914262, 'Total loss': 0.8152406991914262} | train loss {'Reaction outcome loss': 0.7810637077591458, 'Total loss': 0.7810637077591458}
2022-11-22 20:58:47,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:47,447 INFO:     Epoch: 16
2022-11-22 20:58:48,206 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8161970515583836, 'Total loss': 0.8161970515583836} | train loss {'Reaction outcome loss': 0.781426165436135, 'Total loss': 0.781426165436135}
2022-11-22 20:58:48,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:48,206 INFO:     Epoch: 17
2022-11-22 20:58:48,943 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.812476190023644, 'Total loss': 0.812476190023644} | train loss {'Reaction outcome loss': 0.7800574281909427, 'Total loss': 0.7800574281909427}
2022-11-22 20:58:48,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:48,944 INFO:     Epoch: 18
2022-11-22 20:58:49,700 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7919268275416175, 'Total loss': 0.7919268275416175} | train loss {'Reaction outcome loss': 0.7852495433609994, 'Total loss': 0.7852495433609994}
2022-11-22 20:58:49,700 INFO:     Found new best model at epoch 18
2022-11-22 20:58:49,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:49,701 INFO:     Epoch: 19
2022-11-22 20:58:50,433 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8072360372820566, 'Total loss': 0.8072360372820566} | train loss {'Reaction outcome loss': 0.7822697375152932, 'Total loss': 0.7822697375152932}
2022-11-22 20:58:50,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:50,434 INFO:     Epoch: 20
2022-11-22 20:58:51,200 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8114664318949677, 'Total loss': 0.8114664318949677} | train loss {'Reaction outcome loss': 0.7823434362157446, 'Total loss': 0.7823434362157446}
2022-11-22 20:58:51,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:51,200 INFO:     Epoch: 21
2022-11-22 20:58:51,988 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8150143845136776, 'Total loss': 0.8150143845136776} | train loss {'Reaction outcome loss': 0.7788254823841032, 'Total loss': 0.7788254823841032}
2022-11-22 20:58:51,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:51,989 INFO:     Epoch: 22
2022-11-22 20:58:52,714 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8333719677703325, 'Total loss': 0.8333719677703325} | train loss {'Reaction outcome loss': 0.7833658267484337, 'Total loss': 0.7833658267484337}
2022-11-22 20:58:52,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:52,715 INFO:     Epoch: 23
2022-11-22 20:58:53,438 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7962772908598877, 'Total loss': 0.7962772908598877} | train loss {'Reaction outcome loss': 0.7784911335491743, 'Total loss': 0.7784911335491743}
2022-11-22 20:58:53,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:53,439 INFO:     Epoch: 24
2022-11-22 20:58:54,187 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.788127158963403, 'Total loss': 0.788127158963403} | train loss {'Reaction outcome loss': 0.776428715249554, 'Total loss': 0.776428715249554}
2022-11-22 20:58:54,187 INFO:     Found new best model at epoch 24
2022-11-22 20:58:54,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:54,188 INFO:     Epoch: 25
2022-11-22 20:58:54,944 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7896339352740798, 'Total loss': 0.7896339352740798} | train loss {'Reaction outcome loss': 0.7824124389740287, 'Total loss': 0.7824124389740287}
2022-11-22 20:58:54,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:54,944 INFO:     Epoch: 26
2022-11-22 20:58:55,710 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8180569271708644, 'Total loss': 0.8180569271708644} | train loss {'Reaction outcome loss': 0.7781558625522207, 'Total loss': 0.7781558625522207}
2022-11-22 20:58:55,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:55,710 INFO:     Epoch: 27
2022-11-22 20:58:56,461 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7989299900309984, 'Total loss': 0.7989299900309984} | train loss {'Reaction outcome loss': 0.7750992805498546, 'Total loss': 0.7750992805498546}
2022-11-22 20:58:56,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:56,462 INFO:     Epoch: 28
2022-11-22 20:58:57,191 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7915122190187144, 'Total loss': 0.7915122190187144} | train loss {'Reaction outcome loss': 0.7780262341753381, 'Total loss': 0.7780262341753381}
2022-11-22 20:58:57,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:57,192 INFO:     Epoch: 29
2022-11-22 20:58:57,957 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7908153741858727, 'Total loss': 0.7908153741858727} | train loss {'Reaction outcome loss': 0.7777008552287445, 'Total loss': 0.7777008552287445}
2022-11-22 20:58:57,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:57,957 INFO:     Epoch: 30
2022-11-22 20:58:58,725 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8267391379489455, 'Total loss': 0.8267391379489455} | train loss {'Reaction outcome loss': 0.7733625452049443, 'Total loss': 0.7733625452049443}
2022-11-22 20:58:58,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:58,725 INFO:     Epoch: 31
2022-11-22 20:58:59,441 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8067809870076734, 'Total loss': 0.8067809870076734} | train loss {'Reaction outcome loss': 0.7748360957522862, 'Total loss': 0.7748360957522862}
2022-11-22 20:58:59,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:58:59,441 INFO:     Epoch: 32
2022-11-22 20:59:00,200 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8338400756203851, 'Total loss': 0.8338400756203851} | train loss {'Reaction outcome loss': 0.7707290374597565, 'Total loss': 0.7707290374597565}
2022-11-22 20:59:00,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:00,200 INFO:     Epoch: 33
2022-11-22 20:59:00,918 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7887697337671767, 'Total loss': 0.7887697337671767} | train loss {'Reaction outcome loss': 0.7728090909172277, 'Total loss': 0.7728090909172277}
2022-11-22 20:59:00,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:00,918 INFO:     Epoch: 34
2022-11-22 20:59:01,643 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7927248671997426, 'Total loss': 0.7927248671997426} | train loss {'Reaction outcome loss': 0.7757474919323062, 'Total loss': 0.7757474919323062}
2022-11-22 20:59:01,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:01,643 INFO:     Epoch: 35
2022-11-22 20:59:02,394 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7944553140984025, 'Total loss': 0.7944553140984025} | train loss {'Reaction outcome loss': 0.7687927329393683, 'Total loss': 0.7687927329393683}
2022-11-22 20:59:02,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:02,394 INFO:     Epoch: 36
2022-11-22 20:59:03,097 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7899670011775438, 'Total loss': 0.7899670011775438} | train loss {'Reaction outcome loss': 0.7747412256774355, 'Total loss': 0.7747412256774355}
2022-11-22 20:59:03,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:03,098 INFO:     Epoch: 37
2022-11-22 20:59:03,826 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7867671369120132, 'Total loss': 0.7867671369120132} | train loss {'Reaction outcome loss': 0.773534717618442, 'Total loss': 0.773534717618442}
2022-11-22 20:59:03,826 INFO:     Found new best model at epoch 37
2022-11-22 20:59:03,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:03,827 INFO:     Epoch: 38
2022-11-22 20:59:04,574 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8083396928254948, 'Total loss': 0.8083396928254948} | train loss {'Reaction outcome loss': 0.7753617552215936, 'Total loss': 0.7753617552215936}
2022-11-22 20:59:04,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:04,574 INFO:     Epoch: 39
2022-11-22 20:59:05,316 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7978069213933723, 'Total loss': 0.7978069213933723} | train loss {'Reaction outcome loss': 0.7752199959559519, 'Total loss': 0.7752199959559519}
2022-11-22 20:59:05,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:05,317 INFO:     Epoch: 40
2022-11-22 20:59:06,084 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8199207172837368, 'Total loss': 0.8199207172837368} | train loss {'Reaction outcome loss': 0.770588893626557, 'Total loss': 0.770588893626557}
2022-11-22 20:59:06,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:06,084 INFO:     Epoch: 41
2022-11-22 20:59:06,797 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7931425384310788, 'Total loss': 0.7931425384310788} | train loss {'Reaction outcome loss': 0.7698316543561513, 'Total loss': 0.7698316543561513}
2022-11-22 20:59:06,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:06,798 INFO:     Epoch: 42
2022-11-22 20:59:07,552 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7957277388073677, 'Total loss': 0.7957277388073677} | train loss {'Reaction outcome loss': 0.7730984845366634, 'Total loss': 0.7730984845366634}
2022-11-22 20:59:07,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:07,553 INFO:     Epoch: 43
2022-11-22 20:59:08,290 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8129599142906277, 'Total loss': 0.8129599142906277} | train loss {'Reaction outcome loss': 0.7722219454094035, 'Total loss': 0.7722219454094035}
2022-11-22 20:59:08,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:08,290 INFO:     Epoch: 44
2022-11-22 20:59:09,093 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8195433817630591, 'Total loss': 0.8195433817630591} | train loss {'Reaction outcome loss': 0.7753536861206665, 'Total loss': 0.7753536861206665}
2022-11-22 20:59:09,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:09,093 INFO:     Epoch: 45
2022-11-22 20:59:09,886 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8070331555466319, 'Total loss': 0.8070331555466319} | train loss {'Reaction outcome loss': 0.772056872361019, 'Total loss': 0.772056872361019}
2022-11-22 20:59:09,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:09,886 INFO:     Epoch: 46
2022-11-22 20:59:10,669 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7909292086612346, 'Total loss': 0.7909292086612346} | train loss {'Reaction outcome loss': 0.7713286594533529, 'Total loss': 0.7713286594533529}
2022-11-22 20:59:10,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:10,669 INFO:     Epoch: 47
2022-11-22 20:59:11,400 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7924544651841008, 'Total loss': 0.7924544651841008} | train loss {'Reaction outcome loss': 0.7678274031056732, 'Total loss': 0.7678274031056732}
2022-11-22 20:59:11,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:11,400 INFO:     Epoch: 48
2022-11-22 20:59:12,197 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7979611823725146, 'Total loss': 0.7979611823725146} | train loss {'Reaction outcome loss': 0.7695933019772905, 'Total loss': 0.7695933019772905}
2022-11-22 20:59:12,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:12,197 INFO:     Epoch: 49
2022-11-22 20:59:12,910 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.814655180587325, 'Total loss': 0.814655180587325} | train loss {'Reaction outcome loss': 0.7714693211629743, 'Total loss': 0.7714693211629743}
2022-11-22 20:59:12,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:12,910 INFO:     Epoch: 50
2022-11-22 20:59:13,656 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7914809376694435, 'Total loss': 0.7914809376694435} | train loss {'Reaction outcome loss': 0.7717740462451684, 'Total loss': 0.7717740462451684}
2022-11-22 20:59:13,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:13,656 INFO:     Epoch: 51
2022-11-22 20:59:14,412 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7951816403588583, 'Total loss': 0.7951816403588583} | train loss {'Reaction outcome loss': 0.7749402216467701, 'Total loss': 0.7749402216467701}
2022-11-22 20:59:14,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:14,412 INFO:     Epoch: 52
2022-11-22 20:59:15,150 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.788437681142674, 'Total loss': 0.788437681142674} | train loss {'Reaction outcome loss': 0.7700083309509715, 'Total loss': 0.7700083309509715}
2022-11-22 20:59:15,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:15,151 INFO:     Epoch: 53
2022-11-22 20:59:15,870 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7989222448925639, 'Total loss': 0.7989222448925639} | train loss {'Reaction outcome loss': 0.7694533447750279, 'Total loss': 0.7694533447750279}
2022-11-22 20:59:15,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:15,870 INFO:     Epoch: 54
2022-11-22 20:59:16,607 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7992127849612125, 'Total loss': 0.7992127849612125} | train loss {'Reaction outcome loss': 0.7709402192811496, 'Total loss': 0.7709402192811496}
2022-11-22 20:59:16,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:16,607 INFO:     Epoch: 55
2022-11-22 20:59:17,343 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7937136957811755, 'Total loss': 0.7937136957811755} | train loss {'Reaction outcome loss': 0.7664093950488529, 'Total loss': 0.7664093950488529}
2022-11-22 20:59:17,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:17,344 INFO:     Epoch: 56
2022-11-22 20:59:18,044 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8682150729866915, 'Total loss': 0.8682150729866915} | train loss {'Reaction outcome loss': 0.7670424863940379, 'Total loss': 0.7670424863940379}
2022-11-22 20:59:18,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:18,045 INFO:     Epoch: 57
2022-11-22 20:59:18,790 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7900168251159579, 'Total loss': 0.7900168251159579} | train loss {'Reaction outcome loss': 0.764949730429493, 'Total loss': 0.764949730429493}
2022-11-22 20:59:18,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:18,791 INFO:     Epoch: 58
2022-11-22 20:59:19,547 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.78680363921232, 'Total loss': 0.78680363921232} | train loss {'Reaction outcome loss': 0.7671369951768, 'Total loss': 0.7671369951768}
2022-11-22 20:59:19,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:19,547 INFO:     Epoch: 59
2022-11-22 20:59:20,294 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7949565524278686, 'Total loss': 0.7949565524278686} | train loss {'Reaction outcome loss': 0.7685060532855206, 'Total loss': 0.7685060532855206}
2022-11-22 20:59:20,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:20,295 INFO:     Epoch: 60
2022-11-22 20:59:21,043 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8246369812377664, 'Total loss': 0.8246369812377664} | train loss {'Reaction outcome loss': 0.7633855153546959, 'Total loss': 0.7633855153546959}
2022-11-22 20:59:21,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:21,043 INFO:     Epoch: 61
2022-11-22 20:59:21,788 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.786741784838743, 'Total loss': 0.786741784838743} | train loss {'Reaction outcome loss': 0.7640152314647299, 'Total loss': 0.7640152314647299}
2022-11-22 20:59:21,788 INFO:     Found new best model at epoch 61
2022-11-22 20:59:21,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:21,789 INFO:     Epoch: 62
2022-11-22 20:59:22,580 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7862326828546302, 'Total loss': 0.7862326828546302} | train loss {'Reaction outcome loss': 0.7675367575444159, 'Total loss': 0.7675367575444159}
2022-11-22 20:59:22,581 INFO:     Found new best model at epoch 62
2022-11-22 20:59:22,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:22,581 INFO:     Epoch: 63
2022-11-22 20:59:23,306 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7778124289457188, 'Total loss': 0.7778124289457188} | train loss {'Reaction outcome loss': 0.7608002513402798, 'Total loss': 0.7608002513402798}
2022-11-22 20:59:23,306 INFO:     Found new best model at epoch 63
2022-11-22 20:59:23,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:23,307 INFO:     Epoch: 64
2022-11-22 20:59:24,034 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7784225580304168, 'Total loss': 0.7784225580304168} | train loss {'Reaction outcome loss': 0.7636115602293952, 'Total loss': 0.7636115602293952}
2022-11-22 20:59:24,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:24,034 INFO:     Epoch: 65
2022-11-22 20:59:24,753 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7793777924637462, 'Total loss': 0.7793777924637462} | train loss {'Reaction outcome loss': 0.755158174355499, 'Total loss': 0.755158174355499}
2022-11-22 20:59:24,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:24,753 INFO:     Epoch: 66
2022-11-22 20:59:25,539 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7857468197512072, 'Total loss': 0.7857468197512072} | train loss {'Reaction outcome loss': 0.7629061675951129, 'Total loss': 0.7629061675951129}
2022-11-22 20:59:25,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:25,540 INFO:     Epoch: 67
2022-11-22 20:59:26,263 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7946369745010553, 'Total loss': 0.7946369745010553} | train loss {'Reaction outcome loss': 0.7581844527701862, 'Total loss': 0.7581844527701862}
2022-11-22 20:59:26,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:26,263 INFO:     Epoch: 68
2022-11-22 20:59:26,996 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7697824613992558, 'Total loss': 0.7697824613992558} | train loss {'Reaction outcome loss': 0.7543873437603966, 'Total loss': 0.7543873437603966}
2022-11-22 20:59:26,996 INFO:     Found new best model at epoch 68
2022-11-22 20:59:26,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:26,997 INFO:     Epoch: 69
2022-11-22 20:59:27,717 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7821052206117053, 'Total loss': 0.7821052206117053} | train loss {'Reaction outcome loss': 0.7469763185401432, 'Total loss': 0.7469763185401432}
2022-11-22 20:59:27,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:27,718 INFO:     Epoch: 70
2022-11-22 20:59:28,455 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8139043602832529, 'Total loss': 0.8139043602832529} | train loss {'Reaction outcome loss': 0.7447190780620105, 'Total loss': 0.7447190780620105}
2022-11-22 20:59:28,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:28,456 INFO:     Epoch: 71
2022-11-22 20:59:29,202 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7824581320895705, 'Total loss': 0.7824581320895705} | train loss {'Reaction outcome loss': 0.7449899447745965, 'Total loss': 0.7449899447745965}
2022-11-22 20:59:29,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:29,203 INFO:     Epoch: 72
2022-11-22 20:59:30,003 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7860612259354702, 'Total loss': 0.7860612259354702} | train loss {'Reaction outcome loss': 0.7414132868413066, 'Total loss': 0.7414132868413066}
2022-11-22 20:59:30,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:30,004 INFO:     Epoch: 73
2022-11-22 20:59:30,746 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7622360919797143, 'Total loss': 0.7622360919797143} | train loss {'Reaction outcome loss': 0.740773012403582, 'Total loss': 0.740773012403582}
2022-11-22 20:59:30,746 INFO:     Found new best model at epoch 73
2022-11-22 20:59:30,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:30,747 INFO:     Epoch: 74
2022-11-22 20:59:31,480 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7780113247937934, 'Total loss': 0.7780113247937934} | train loss {'Reaction outcome loss': 0.7372816760764748, 'Total loss': 0.7372816760764748}
2022-11-22 20:59:31,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:31,480 INFO:     Epoch: 75
2022-11-22 20:59:32,222 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8063331371129945, 'Total loss': 0.8063331371129945} | train loss {'Reaction outcome loss': 0.7359235840009861, 'Total loss': 0.7359235840009861}
2022-11-22 20:59:32,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:32,222 INFO:     Epoch: 76
2022-11-22 20:59:32,944 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7740461597608965, 'Total loss': 0.7740461597608965} | train loss {'Reaction outcome loss': 0.7309522576263694, 'Total loss': 0.7309522576263694}
2022-11-22 20:59:32,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:32,944 INFO:     Epoch: 77
2022-11-22 20:59:33,747 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7688750860302948, 'Total loss': 0.7688750860302948} | train loss {'Reaction outcome loss': 0.7359931186818686, 'Total loss': 0.7359931186818686}
2022-11-22 20:59:33,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:33,748 INFO:     Epoch: 78
2022-11-22 20:59:34,460 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7424214114976484, 'Total loss': 0.7424214114976484} | train loss {'Reaction outcome loss': 0.7317046988450113, 'Total loss': 0.7317046988450113}
2022-11-22 20:59:34,460 INFO:     Found new best model at epoch 78
2022-11-22 20:59:34,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:34,461 INFO:     Epoch: 79
2022-11-22 20:59:35,231 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7704468154629995, 'Total loss': 0.7704468154629995} | train loss {'Reaction outcome loss': 0.7286109482167197, 'Total loss': 0.7286109482167197}
2022-11-22 20:59:35,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:35,232 INFO:     Epoch: 80
2022-11-22 20:59:35,956 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7507728837257208, 'Total loss': 0.7507728837257208} | train loss {'Reaction outcome loss': 0.7214026914023962, 'Total loss': 0.7214026914023962}
2022-11-22 20:59:35,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:35,956 INFO:     Epoch: 81
2022-11-22 20:59:36,699 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7552673213703688, 'Total loss': 0.7552673213703688} | train loss {'Reaction outcome loss': 0.7266810702495887, 'Total loss': 0.7266810702495887}
2022-11-22 20:59:36,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:36,699 INFO:     Epoch: 82
2022-11-22 20:59:37,472 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7351386886696483, 'Total loss': 0.7351386886696483} | train loss {'Reaction outcome loss': 0.7249882731769905, 'Total loss': 0.7249882731769905}
2022-11-22 20:59:37,472 INFO:     Found new best model at epoch 82
2022-11-22 20:59:37,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:37,473 INFO:     Epoch: 83
2022-11-22 20:59:38,217 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7428312911543735, 'Total loss': 0.7428312911543735} | train loss {'Reaction outcome loss': 0.7225940615915861, 'Total loss': 0.7225940615915861}
2022-11-22 20:59:38,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:38,218 INFO:     Epoch: 84
2022-11-22 20:59:38,968 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7933698435162388, 'Total loss': 0.7933698435162388} | train loss {'Reaction outcome loss': 0.7161685137963686, 'Total loss': 0.7161685137963686}
2022-11-22 20:59:38,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:38,968 INFO:     Epoch: 85
2022-11-22 20:59:39,685 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.786191466242768, 'Total loss': 0.786191466242768} | train loss {'Reaction outcome loss': 0.7210189607299742, 'Total loss': 0.7210189607299742}
2022-11-22 20:59:39,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:39,686 INFO:     Epoch: 86
2022-11-22 20:59:40,443 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7417916004047838, 'Total loss': 0.7417916004047838} | train loss {'Reaction outcome loss': 0.7176572035570614, 'Total loss': 0.7176572035570614}
2022-11-22 20:59:40,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:40,444 INFO:     Epoch: 87
2022-11-22 20:59:41,188 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7550137243991675, 'Total loss': 0.7550137243991675} | train loss {'Reaction outcome loss': 0.7144569311840613, 'Total loss': 0.7144569311840613}
2022-11-22 20:59:41,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:41,188 INFO:     Epoch: 88
2022-11-22 20:59:41,873 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7385839404061784, 'Total loss': 0.7385839404061784} | train loss {'Reaction outcome loss': 0.7181258266333674, 'Total loss': 0.7181258266333674}
2022-11-22 20:59:41,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:41,873 INFO:     Epoch: 89
2022-11-22 20:59:42,637 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7432318808034409, 'Total loss': 0.7432318808034409} | train loss {'Reaction outcome loss': 0.7050572772983645, 'Total loss': 0.7050572772983645}
2022-11-22 20:59:42,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:42,637 INFO:     Epoch: 90
2022-11-22 20:59:43,395 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7260918638040853, 'Total loss': 0.7260918638040853} | train loss {'Reaction outcome loss': 0.710392073407525, 'Total loss': 0.710392073407525}
2022-11-22 20:59:43,395 INFO:     Found new best model at epoch 90
2022-11-22 20:59:43,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:43,396 INFO:     Epoch: 91
2022-11-22 20:59:44,149 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7958821273127268, 'Total loss': 0.7958821273127268} | train loss {'Reaction outcome loss': 0.7059515516777508, 'Total loss': 0.7059515516777508}
2022-11-22 20:59:44,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:44,149 INFO:     Epoch: 92
2022-11-22 20:59:44,869 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7736747646054556, 'Total loss': 0.7736747646054556} | train loss {'Reaction outcome loss': 0.7104448972911132, 'Total loss': 0.7104448972911132}
2022-11-22 20:59:44,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:44,869 INFO:     Epoch: 93
2022-11-22 20:59:45,618 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7318914463353712, 'Total loss': 0.7318914463353712} | train loss {'Reaction outcome loss': 0.7057006471469754, 'Total loss': 0.7057006471469754}
2022-11-22 20:59:45,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:45,619 INFO:     Epoch: 94
2022-11-22 20:59:46,333 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7497469872929329, 'Total loss': 0.7497469872929329} | train loss {'Reaction outcome loss': 0.7088851121361138, 'Total loss': 0.7088851121361138}
2022-11-22 20:59:46,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:46,334 INFO:     Epoch: 95
2022-11-22 20:59:47,033 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7252533220967581, 'Total loss': 0.7252533220967581} | train loss {'Reaction outcome loss': 0.710881483725837, 'Total loss': 0.710881483725837}
2022-11-22 20:59:47,033 INFO:     Found new best model at epoch 95
2022-11-22 20:59:47,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:47,034 INFO:     Epoch: 96
2022-11-22 20:59:47,778 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7812517701193343, 'Total loss': 0.7812517701193343} | train loss {'Reaction outcome loss': 0.7061107968453502, 'Total loss': 0.7061107968453502}
2022-11-22 20:59:47,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:47,778 INFO:     Epoch: 97
2022-11-22 20:59:48,533 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.777527834093848, 'Total loss': 0.777527834093848} | train loss {'Reaction outcome loss': 0.7025739891362972, 'Total loss': 0.7025739891362972}
2022-11-22 20:59:48,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:48,533 INFO:     Epoch: 98
2022-11-22 20:59:49,304 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7464981023655382, 'Total loss': 0.7464981023655382} | train loss {'Reaction outcome loss': 0.699650688493838, 'Total loss': 0.699650688493838}
2022-11-22 20:59:49,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:49,304 INFO:     Epoch: 99
2022-11-22 20:59:50,060 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7214925905992818, 'Total loss': 0.7214925905992818} | train loss {'Reaction outcome loss': 0.7074006887488677, 'Total loss': 0.7074006887488677}
2022-11-22 20:59:50,060 INFO:     Found new best model at epoch 99
2022-11-22 20:59:50,061 INFO:     Best model found after epoch 100 of 100.
2022-11-22 20:59:50,061 INFO:   Done with stage: TRAINING
2022-11-22 20:59:50,061 INFO:   Starting stage: EVALUATION
2022-11-22 20:59:50,191 INFO:   Done with stage: EVALUATION
2022-11-22 20:59:50,191 INFO:   Leaving out SEQ value Fold_9
2022-11-22 20:59:50,204 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 20:59:50,204 INFO:   Starting stage: FEATURE SCALING
2022-11-22 20:59:50,878 INFO:   Done with stage: FEATURE SCALING
2022-11-22 20:59:50,878 INFO:   Starting stage: SCALING TARGETS
2022-11-22 20:59:50,948 INFO:   Done with stage: SCALING TARGETS
2022-11-22 20:59:50,949 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:59:50,949 INFO:     No hyperparam tuning for this model
2022-11-22 20:59:50,949 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 20:59:50,949 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 20:59:50,950 INFO:     None feature selector for col prot
2022-11-22 20:59:50,950 INFO:     None feature selector for col prot
2022-11-22 20:59:50,950 INFO:     None feature selector for col prot
2022-11-22 20:59:50,950 INFO:     None feature selector for col chem
2022-11-22 20:59:50,951 INFO:     None feature selector for col chem
2022-11-22 20:59:50,951 INFO:     None feature selector for col chem
2022-11-22 20:59:50,951 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 20:59:50,951 INFO:   Starting stage: BUILD MODEL
2022-11-22 20:59:50,952 INFO:     Number of params in model 126091
2022-11-22 20:59:50,955 INFO:   Done with stage: BUILD MODEL
2022-11-22 20:59:50,956 INFO:   Starting stage: TRAINING
2022-11-22 20:59:51,005 INFO:     Val loss before train {'Reaction outcome loss': 1.112427523190325, 'Total loss': 1.112427523190325}
2022-11-22 20:59:51,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:51,005 INFO:     Epoch: 0
2022-11-22 20:59:51,775 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8652941320430149, 'Total loss': 0.8652941320430149} | train loss {'Reaction outcome loss': 0.8592877120443201, 'Total loss': 0.8592877120443201}
2022-11-22 20:59:51,775 INFO:     Found new best model at epoch 0
2022-11-22 20:59:51,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:51,776 INFO:     Epoch: 1
2022-11-22 20:59:52,486 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8452666591514241, 'Total loss': 0.8452666591514241} | train loss {'Reaction outcome loss': 0.8331287937608325, 'Total loss': 0.8331287937608325}
2022-11-22 20:59:52,487 INFO:     Found new best model at epoch 1
2022-11-22 20:59:52,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:52,487 INFO:     Epoch: 2
2022-11-22 20:59:53,240 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8418648066845807, 'Total loss': 0.8418648066845807} | train loss {'Reaction outcome loss': 0.8306561894262368, 'Total loss': 0.8306561894262368}
2022-11-22 20:59:53,240 INFO:     Found new best model at epoch 2
2022-11-22 20:59:53,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:53,241 INFO:     Epoch: 3
2022-11-22 20:59:54,015 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8463470048525117, 'Total loss': 0.8463470048525117} | train loss {'Reaction outcome loss': 0.8167280358100227, 'Total loss': 0.8167280358100227}
2022-11-22 20:59:54,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:54,015 INFO:     Epoch: 4
2022-11-22 20:59:54,738 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8587481542067095, 'Total loss': 0.8587481542067095} | train loss {'Reaction outcome loss': 0.8121195964002417, 'Total loss': 0.8121195964002417}
2022-11-22 20:59:54,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:54,738 INFO:     Epoch: 5
2022-11-22 20:59:55,485 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8326086720282381, 'Total loss': 0.8326086720282381} | train loss {'Reaction outcome loss': 0.8071795905891218, 'Total loss': 0.8071795905891218}
2022-11-22 20:59:55,485 INFO:     Found new best model at epoch 5
2022-11-22 20:59:55,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:55,486 INFO:     Epoch: 6
2022-11-22 20:59:56,239 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8621344010938298, 'Total loss': 0.8621344010938298} | train loss {'Reaction outcome loss': 0.8046143626877171, 'Total loss': 0.8046143626877171}
2022-11-22 20:59:56,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:56,240 INFO:     Epoch: 7
2022-11-22 20:59:56,964 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8233438811518929, 'Total loss': 0.8233438811518929} | train loss {'Reaction outcome loss': 0.8038576121031031, 'Total loss': 0.8038576121031031}
2022-11-22 20:59:56,964 INFO:     Found new best model at epoch 7
2022-11-22 20:59:56,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:56,965 INFO:     Epoch: 8
2022-11-22 20:59:57,707 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8312178396365859, 'Total loss': 0.8312178396365859} | train loss {'Reaction outcome loss': 0.7962452242007623, 'Total loss': 0.7962452242007623}
2022-11-22 20:59:57,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:57,707 INFO:     Epoch: 9
2022-11-22 20:59:58,474 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8373283811590888, 'Total loss': 0.8373283811590888} | train loss {'Reaction outcome loss': 0.7964499659142513, 'Total loss': 0.7964499659142513}
2022-11-22 20:59:58,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:58,474 INFO:     Epoch: 10
2022-11-22 20:59:59,228 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8331562429666519, 'Total loss': 0.8331562429666519} | train loss {'Reaction outcome loss': 0.7991626168552198, 'Total loss': 0.7991626168552198}
2022-11-22 20:59:59,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:59,230 INFO:     Epoch: 11
2022-11-22 20:59:59,993 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8249675800854509, 'Total loss': 0.8249675800854509} | train loss {'Reaction outcome loss': 0.8091881092984666, 'Total loss': 0.8091881092984666}
2022-11-22 20:59:59,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 20:59:59,993 INFO:     Epoch: 12
2022-11-22 21:00:00,752 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8048043176531792, 'Total loss': 0.8048043176531792} | train loss {'Reaction outcome loss': 0.79450825460044, 'Total loss': 0.79450825460044}
2022-11-22 21:00:00,752 INFO:     Found new best model at epoch 12
2022-11-22 21:00:00,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:00,753 INFO:     Epoch: 13
2022-11-22 21:00:01,520 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.919448278167031, 'Total loss': 0.919448278167031} | train loss {'Reaction outcome loss': 0.7921111688681459, 'Total loss': 0.7921111688681459}
2022-11-22 21:00:01,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:01,520 INFO:     Epoch: 14
2022-11-22 21:00:02,248 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8053693202408877, 'Total loss': 0.8053693202408877} | train loss {'Reaction outcome loss': 0.7887047902202076, 'Total loss': 0.7887047902202076}
2022-11-22 21:00:02,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:02,249 INFO:     Epoch: 15
2022-11-22 21:00:03,033 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8425042317672209, 'Total loss': 0.8425042317672209} | train loss {'Reaction outcome loss': 0.7865982223980823, 'Total loss': 0.7865982223980823}
2022-11-22 21:00:03,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:03,034 INFO:     Epoch: 16
2022-11-22 21:00:03,786 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8290303274989128, 'Total loss': 0.8290303274989128} | train loss {'Reaction outcome loss': 0.7950691735213585, 'Total loss': 0.7950691735213585}
2022-11-22 21:00:03,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:03,787 INFO:     Epoch: 17
2022-11-22 21:00:04,548 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8319121226668358, 'Total loss': 0.8319121226668358} | train loss {'Reaction outcome loss': 0.7884458820165893, 'Total loss': 0.7884458820165893}
2022-11-22 21:00:04,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:04,548 INFO:     Epoch: 18
2022-11-22 21:00:05,343 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8079565546729348, 'Total loss': 0.8079565546729348} | train loss {'Reaction outcome loss': 0.785522107894604, 'Total loss': 0.785522107894604}
2022-11-22 21:00:05,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:05,344 INFO:     Epoch: 19
2022-11-22 21:00:06,105 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8332317525690253, 'Total loss': 0.8332317525690253} | train loss {'Reaction outcome loss': 0.7860972787204542, 'Total loss': 0.7860972787204542}
2022-11-22 21:00:06,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:06,106 INFO:     Epoch: 20
2022-11-22 21:00:06,873 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8121624026786197, 'Total loss': 0.8121624026786197} | train loss {'Reaction outcome loss': 0.7954514884514364, 'Total loss': 0.7954514884514364}
2022-11-22 21:00:06,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:06,874 INFO:     Epoch: 21
2022-11-22 21:00:07,597 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8001011081717231, 'Total loss': 0.8001011081717231} | train loss {'Reaction outcome loss': 0.78493267671782, 'Total loss': 0.78493267671782}
2022-11-22 21:00:07,597 INFO:     Found new best model at epoch 21
2022-11-22 21:00:07,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:07,598 INFO:     Epoch: 22
2022-11-22 21:00:08,326 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8132610043341463, 'Total loss': 0.8132610043341463} | train loss {'Reaction outcome loss': 0.7837439046697579, 'Total loss': 0.7837439046697579}
2022-11-22 21:00:08,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:08,326 INFO:     Epoch: 23
2022-11-22 21:00:09,102 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8206072375178337, 'Total loss': 0.8206072375178337} | train loss {'Reaction outcome loss': 0.784366741836795, 'Total loss': 0.784366741836795}
2022-11-22 21:00:09,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:09,102 INFO:     Epoch: 24
2022-11-22 21:00:09,855 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8207066458734599, 'Total loss': 0.8207066458734599} | train loss {'Reaction outcome loss': 0.782039819850854, 'Total loss': 0.782039819850854}
2022-11-22 21:00:09,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:09,856 INFO:     Epoch: 25
2022-11-22 21:00:10,628 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8144300288774751, 'Total loss': 0.8144300288774751} | train loss {'Reaction outcome loss': 0.7766826250232183, 'Total loss': 0.7766826250232183}
2022-11-22 21:00:10,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:10,628 INFO:     Epoch: 26
2022-11-22 21:00:11,424 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7988132136789236, 'Total loss': 0.7988132136789236} | train loss {'Reaction outcome loss': 0.7848765550837343, 'Total loss': 0.7848765550837343}
2022-11-22 21:00:11,424 INFO:     Found new best model at epoch 26
2022-11-22 21:00:11,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:11,425 INFO:     Epoch: 27
2022-11-22 21:00:12,180 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8072082515467297, 'Total loss': 0.8072082515467297} | train loss {'Reaction outcome loss': 0.7865314921628126, 'Total loss': 0.7865314921628126}
2022-11-22 21:00:12,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:12,180 INFO:     Epoch: 28
2022-11-22 21:00:12,953 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8082462867552583, 'Total loss': 0.8082462867552583} | train loss {'Reaction outcome loss': 0.7901739422608967, 'Total loss': 0.7901739422608967}
2022-11-22 21:00:12,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:12,953 INFO:     Epoch: 29
2022-11-22 21:00:13,696 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8124992407181046, 'Total loss': 0.8124992407181046} | train loss {'Reaction outcome loss': 0.7910605342040661, 'Total loss': 0.7910605342040661}
2022-11-22 21:00:13,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:13,696 INFO:     Epoch: 30
2022-11-22 21:00:14,471 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.831458178433505, 'Total loss': 0.831458178433505} | train loss {'Reaction outcome loss': 0.7872386919824701, 'Total loss': 0.7872386919824701}
2022-11-22 21:00:14,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:14,472 INFO:     Epoch: 31
2022-11-22 21:00:15,228 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8007876933975653, 'Total loss': 0.8007876933975653} | train loss {'Reaction outcome loss': 0.783831004430408, 'Total loss': 0.783831004430408}
2022-11-22 21:00:15,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:15,228 INFO:     Epoch: 32
2022-11-22 21:00:15,956 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8546194671229883, 'Total loss': 0.8546194671229883} | train loss {'Reaction outcome loss': 0.7829645720088048, 'Total loss': 0.7829645720088048}
2022-11-22 21:00:15,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:15,956 INFO:     Epoch: 33
2022-11-22 21:00:16,711 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8121767938137054, 'Total loss': 0.8121767938137054} | train loss {'Reaction outcome loss': 0.7829827624505107, 'Total loss': 0.7829827624505107}
2022-11-22 21:00:16,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:16,711 INFO:     Epoch: 34
2022-11-22 21:00:17,440 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8160236620090224, 'Total loss': 0.8160236620090224} | train loss {'Reaction outcome loss': 0.781009418460039, 'Total loss': 0.781009418460039}
2022-11-22 21:00:17,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:17,441 INFO:     Epoch: 35
2022-11-22 21:00:18,181 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7961483516476371, 'Total loss': 0.7961483516476371} | train loss {'Reaction outcome loss': 0.7879547144961261, 'Total loss': 0.7879547144961261}
2022-11-22 21:00:18,181 INFO:     Found new best model at epoch 35
2022-11-22 21:00:18,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:18,182 INFO:     Epoch: 36
2022-11-22 21:00:18,912 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8140576204115694, 'Total loss': 0.8140576204115694} | train loss {'Reaction outcome loss': 0.7907742029018248, 'Total loss': 0.7907742029018248}
2022-11-22 21:00:18,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:18,913 INFO:     Epoch: 37
2022-11-22 21:00:19,600 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7928057340058413, 'Total loss': 0.7928057340058413} | train loss {'Reaction outcome loss': 0.7799023632337208, 'Total loss': 0.7799023632337208}
2022-11-22 21:00:19,600 INFO:     Found new best model at epoch 37
2022-11-22 21:00:19,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:19,601 INFO:     Epoch: 38
2022-11-22 21:00:20,334 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8053775842894207, 'Total loss': 0.8053775842894207} | train loss {'Reaction outcome loss': 0.7859294526731437, 'Total loss': 0.7859294526731437}
2022-11-22 21:00:20,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:20,334 INFO:     Epoch: 39
2022-11-22 21:00:21,095 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8267010829665444, 'Total loss': 0.8267010829665444} | train loss {'Reaction outcome loss': 0.7881361866286891, 'Total loss': 0.7881361866286891}
2022-11-22 21:00:21,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:21,095 INFO:     Epoch: 40
2022-11-22 21:00:21,880 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8039640581065958, 'Total loss': 0.8039640581065958} | train loss {'Reaction outcome loss': 0.7848364372967709, 'Total loss': 0.7848364372967709}
2022-11-22 21:00:21,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:21,881 INFO:     Epoch: 41
2022-11-22 21:00:22,649 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8112142478877847, 'Total loss': 0.8112142478877847} | train loss {'Reaction outcome loss': 0.7850703550012488, 'Total loss': 0.7850703550012488}
2022-11-22 21:00:22,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:22,650 INFO:     Epoch: 42
2022-11-22 21:00:23,401 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.804128075865182, 'Total loss': 0.804128075865182} | train loss {'Reaction outcome loss': 0.7784312201535654, 'Total loss': 0.7784312201535654}
2022-11-22 21:00:23,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:23,402 INFO:     Epoch: 43
2022-11-22 21:00:24,188 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8144709501754154, 'Total loss': 0.8144709501754154} | train loss {'Reaction outcome loss': 0.7830731849438748, 'Total loss': 0.7830731849438748}
2022-11-22 21:00:24,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:24,188 INFO:     Epoch: 44
2022-11-22 21:00:24,955 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7930083193562247, 'Total loss': 0.7930083193562247} | train loss {'Reaction outcome loss': 0.7777864134263414, 'Total loss': 0.7777864134263414}
2022-11-22 21:00:24,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:24,955 INFO:     Epoch: 45
2022-11-22 21:00:25,723 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8431459238583391, 'Total loss': 0.8431459238583391} | train loss {'Reaction outcome loss': 0.7851590424896735, 'Total loss': 0.7851590424896735}
2022-11-22 21:00:25,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:25,723 INFO:     Epoch: 46
2022-11-22 21:00:26,468 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8048565827987411, 'Total loss': 0.8048565827987411} | train loss {'Reaction outcome loss': 0.7838750007422829, 'Total loss': 0.7838750007422829}
2022-11-22 21:00:26,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:26,468 INFO:     Epoch: 47
2022-11-22 21:00:27,216 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8435068096626889, 'Total loss': 0.8435068096626889} | train loss {'Reaction outcome loss': 0.7812423702434972, 'Total loss': 0.7812423702434972}
2022-11-22 21:00:27,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:27,217 INFO:     Epoch: 48
2022-11-22 21:00:27,948 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7953269068490375, 'Total loss': 0.7953269068490375} | train loss {'Reaction outcome loss': 0.7881199354343569, 'Total loss': 0.7881199354343569}
2022-11-22 21:00:27,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:27,949 INFO:     Epoch: 49
2022-11-22 21:00:28,704 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7978473177010362, 'Total loss': 0.7978473177010362} | train loss {'Reaction outcome loss': 0.7801712359252729, 'Total loss': 0.7801712359252729}
2022-11-22 21:00:28,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:28,704 INFO:     Epoch: 50
2022-11-22 21:00:29,443 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8225555745038119, 'Total loss': 0.8225555745038119} | train loss {'Reaction outcome loss': 0.7923708724589483, 'Total loss': 0.7923708724589483}
2022-11-22 21:00:29,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:29,443 INFO:     Epoch: 51
2022-11-22 21:00:30,221 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7999281998385083, 'Total loss': 0.7999281998385083} | train loss {'Reaction outcome loss': 0.777441637236097, 'Total loss': 0.777441637236097}
2022-11-22 21:00:30,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:30,222 INFO:     Epoch: 52
2022-11-22 21:00:31,018 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7978262271393429, 'Total loss': 0.7978262271393429} | train loss {'Reaction outcome loss': 0.7855840388097262, 'Total loss': 0.7855840388097262}
2022-11-22 21:00:31,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:31,018 INFO:     Epoch: 53
2022-11-22 21:00:31,746 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7938533621755514, 'Total loss': 0.7938533621755514} | train loss {'Reaction outcome loss': 0.7726933926585232, 'Total loss': 0.7726933926585232}
2022-11-22 21:00:31,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:31,746 INFO:     Epoch: 54
2022-11-22 21:00:32,494 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8101845783266154, 'Total loss': 0.8101845783266154} | train loss {'Reaction outcome loss': 0.7737797731571352, 'Total loss': 0.7737797731571352}
2022-11-22 21:00:32,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:32,494 INFO:     Epoch: 55
2022-11-22 21:00:33,245 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8079402216456153, 'Total loss': 0.8079402216456153} | train loss {'Reaction outcome loss': 0.7771215730229852, 'Total loss': 0.7771215730229852}
2022-11-22 21:00:33,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:33,245 INFO:     Epoch: 56
2022-11-22 21:00:33,959 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8028673360293562, 'Total loss': 0.8028673360293562} | train loss {'Reaction outcome loss': 0.7806003677700213, 'Total loss': 0.7806003677700213}
2022-11-22 21:00:33,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:33,960 INFO:     Epoch: 57
2022-11-22 21:00:34,708 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.803060185502876, 'Total loss': 0.803060185502876} | train loss {'Reaction outcome loss': 0.7778594752072323, 'Total loss': 0.7778594752072323}
2022-11-22 21:00:34,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:34,709 INFO:     Epoch: 58
2022-11-22 21:00:35,492 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8051030845804648, 'Total loss': 0.8051030845804648} | train loss {'Reaction outcome loss': 0.7705553288643177, 'Total loss': 0.7705553288643177}
2022-11-22 21:00:35,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:35,492 INFO:     Epoch: 59
2022-11-22 21:00:36,253 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8372849774631587, 'Total loss': 0.8372849774631587} | train loss {'Reaction outcome loss': 0.7823217501524489, 'Total loss': 0.7823217501524489}
2022-11-22 21:00:36,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:36,254 INFO:     Epoch: 60
2022-11-22 21:00:37,035 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8100238056345419, 'Total loss': 0.8100238056345419} | train loss {'Reaction outcome loss': 0.7881504141608713, 'Total loss': 0.7881504141608713}
2022-11-22 21:00:37,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:37,035 INFO:     Epoch: 61
2022-11-22 21:00:37,783 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8165884072130377, 'Total loss': 0.8165884072130377} | train loss {'Reaction outcome loss': 0.788927748799324, 'Total loss': 0.788927748799324}
2022-11-22 21:00:37,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:37,783 INFO:     Epoch: 62
2022-11-22 21:00:38,516 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8040712055834857, 'Total loss': 0.8040712055834857} | train loss {'Reaction outcome loss': 0.7787418864999223, 'Total loss': 0.7787418864999223}
2022-11-22 21:00:38,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:38,516 INFO:     Epoch: 63
2022-11-22 21:00:39,310 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8338599970394914, 'Total loss': 0.8338599970394914} | train loss {'Reaction outcome loss': 0.7824456519202182, 'Total loss': 0.7824456519202182}
2022-11-22 21:00:39,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:39,311 INFO:     Epoch: 64
2022-11-22 21:00:40,058 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7929263250394301, 'Total loss': 0.7929263250394301} | train loss {'Reaction outcome loss': 0.779490303655385, 'Total loss': 0.779490303655385}
2022-11-22 21:00:40,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:40,058 INFO:     Epoch: 65
2022-11-22 21:00:40,800 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7964247065511617, 'Total loss': 0.7964247065511617} | train loss {'Reaction outcome loss': 0.7713593992627101, 'Total loss': 0.7713593992627101}
2022-11-22 21:00:40,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:40,801 INFO:     Epoch: 66
2022-11-22 21:00:41,549 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7899361144412648, 'Total loss': 0.7899361144412648} | train loss {'Reaction outcome loss': 0.7791519488400294, 'Total loss': 0.7791519488400294}
2022-11-22 21:00:41,549 INFO:     Found new best model at epoch 66
2022-11-22 21:00:41,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:41,550 INFO:     Epoch: 67
2022-11-22 21:00:42,318 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8097459998997775, 'Total loss': 0.8097459998997775} | train loss {'Reaction outcome loss': 0.769094260266194, 'Total loss': 0.769094260266194}
2022-11-22 21:00:42,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:42,318 INFO:     Epoch: 68
2022-11-22 21:00:43,112 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.787738863717426, 'Total loss': 0.787738863717426} | train loss {'Reaction outcome loss': 0.7793691821909143, 'Total loss': 0.7793691821909143}
2022-11-22 21:00:43,112 INFO:     Found new best model at epoch 68
2022-11-22 21:00:43,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:43,113 INFO:     Epoch: 69
2022-11-22 21:00:43,847 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7936310002749617, 'Total loss': 0.7936310002749617} | train loss {'Reaction outcome loss': 0.7794297309780893, 'Total loss': 0.7794297309780893}
2022-11-22 21:00:43,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:43,847 INFO:     Epoch: 70
2022-11-22 21:00:44,616 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7880087440664117, 'Total loss': 0.7880087440664117} | train loss {'Reaction outcome loss': 0.7774194774598728, 'Total loss': 0.7774194774598728}
2022-11-22 21:00:44,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:44,617 INFO:     Epoch: 71
2022-11-22 21:00:45,336 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7916632775555957, 'Total loss': 0.7916632775555957} | train loss {'Reaction outcome loss': 0.7753681588752067, 'Total loss': 0.7753681588752067}
2022-11-22 21:00:45,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:45,337 INFO:     Epoch: 72
2022-11-22 21:00:46,110 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8024790280244567, 'Total loss': 0.8024790280244567} | train loss {'Reaction outcome loss': 0.7760128680511043, 'Total loss': 0.7760128680511043}
2022-11-22 21:00:46,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:46,110 INFO:     Epoch: 73
2022-11-22 21:00:46,831 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8053291555155407, 'Total loss': 0.8053291555155407} | train loss {'Reaction outcome loss': 0.7698972059285593, 'Total loss': 0.7698972059285593}
2022-11-22 21:00:46,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:46,832 INFO:     Epoch: 74
2022-11-22 21:00:47,578 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7909739464521408, 'Total loss': 0.7909739464521408} | train loss {'Reaction outcome loss': 0.7684037251028455, 'Total loss': 0.7684037251028455}
2022-11-22 21:00:47,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:47,578 INFO:     Epoch: 75
2022-11-22 21:00:48,373 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8226207772439177, 'Total loss': 0.8226207772439177} | train loss {'Reaction outcome loss': 0.7649351674535496, 'Total loss': 0.7649351674535496}
2022-11-22 21:00:48,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:48,374 INFO:     Epoch: 76
2022-11-22 21:00:49,133 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8089389577507973, 'Total loss': 0.8089389577507973} | train loss {'Reaction outcome loss': 0.7699681479740239, 'Total loss': 0.7699681479740239}
2022-11-22 21:00:49,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:49,133 INFO:     Epoch: 77
2022-11-22 21:00:49,918 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7760885215618394, 'Total loss': 0.7760885215618394} | train loss {'Reaction outcome loss': 0.7615781823844321, 'Total loss': 0.7615781823844321}
2022-11-22 21:00:49,918 INFO:     Found new best model at epoch 77
2022-11-22 21:00:49,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:49,919 INFO:     Epoch: 78
2022-11-22 21:00:50,686 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7753260135650635, 'Total loss': 0.7753260135650635} | train loss {'Reaction outcome loss': 0.7639524507438124, 'Total loss': 0.7639524507438124}
2022-11-22 21:00:50,686 INFO:     Found new best model at epoch 78
2022-11-22 21:00:50,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:50,687 INFO:     Epoch: 79
2022-11-22 21:00:51,415 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8439623002301563, 'Total loss': 0.8439623002301563} | train loss {'Reaction outcome loss': 0.7696216334456857, 'Total loss': 0.7696216334456857}
2022-11-22 21:00:51,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:51,415 INFO:     Epoch: 80
2022-11-22 21:00:52,166 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8075879283926704, 'Total loss': 0.8075879283926704} | train loss {'Reaction outcome loss': 0.7720627742498992, 'Total loss': 0.7720627742498992}
2022-11-22 21:00:52,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:52,166 INFO:     Epoch: 81
2022-11-22 21:00:52,900 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8229349743236195, 'Total loss': 0.8229349743236195} | train loss {'Reaction outcome loss': 0.7612034293562777, 'Total loss': 0.7612034293562777}
2022-11-22 21:00:52,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:52,901 INFO:     Epoch: 82
2022-11-22 21:00:53,668 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7805365493351762, 'Total loss': 0.7805365493351762} | train loss {'Reaction outcome loss': 0.7621737962309648, 'Total loss': 0.7621737962309648}
2022-11-22 21:00:53,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:53,669 INFO:     Epoch: 83
2022-11-22 21:00:54,426 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8095737140287053, 'Total loss': 0.8095737140287053} | train loss {'Reaction outcome loss': 0.7686838096211314, 'Total loss': 0.7686838096211314}
2022-11-22 21:00:54,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:54,426 INFO:     Epoch: 84
2022-11-22 21:00:55,171 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7712664373896339, 'Total loss': 0.7712664373896339} | train loss {'Reaction outcome loss': 0.7656988776647128, 'Total loss': 0.7656988776647128}
2022-11-22 21:00:55,171 INFO:     Found new best model at epoch 84
2022-11-22 21:00:55,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:55,172 INFO:     Epoch: 85
2022-11-22 21:00:55,917 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7665362486785109, 'Total loss': 0.7665362486785109} | train loss {'Reaction outcome loss': 0.7572799154862702, 'Total loss': 0.7572799154862702}
2022-11-22 21:00:55,918 INFO:     Found new best model at epoch 85
2022-11-22 21:00:55,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:55,918 INFO:     Epoch: 86
2022-11-22 21:00:56,673 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7796085050160234, 'Total loss': 0.7796085050160234} | train loss {'Reaction outcome loss': 0.7650749790765013, 'Total loss': 0.7650749790765013}
2022-11-22 21:00:56,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:56,673 INFO:     Epoch: 87
2022-11-22 21:00:57,412 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7721585448492657, 'Total loss': 0.7721585448492657} | train loss {'Reaction outcome loss': 0.765270628909833, 'Total loss': 0.765270628909833}
2022-11-22 21:00:57,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:57,412 INFO:     Epoch: 88
2022-11-22 21:00:58,189 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8371186852455139, 'Total loss': 0.8371186852455139} | train loss {'Reaction outcome loss': 0.7665153207325259, 'Total loss': 0.7665153207325259}
2022-11-22 21:00:58,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:58,190 INFO:     Epoch: 89
2022-11-22 21:00:58,963 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7605466402389787, 'Total loss': 0.7605466402389787} | train loss {'Reaction outcome loss': 0.7567628044408825, 'Total loss': 0.7567628044408825}
2022-11-22 21:00:58,963 INFO:     Found new best model at epoch 89
2022-11-22 21:00:58,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:58,964 INFO:     Epoch: 90
2022-11-22 21:00:59,726 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7710536156188358, 'Total loss': 0.7710536156188358} | train loss {'Reaction outcome loss': 0.7432945285610825, 'Total loss': 0.7432945285610825}
2022-11-22 21:00:59,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:00:59,727 INFO:     Epoch: 91
2022-11-22 21:01:00,501 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7884792617776177, 'Total loss': 0.7884792617776177} | train loss {'Reaction outcome loss': 0.7550227993171708, 'Total loss': 0.7550227993171708}
2022-11-22 21:01:00,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:00,501 INFO:     Epoch: 92
2022-11-22 21:01:01,268 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7790688506581567, 'Total loss': 0.7790688506581567} | train loss {'Reaction outcome loss': 0.7777443802067143, 'Total loss': 0.7777443802067143}
2022-11-22 21:01:01,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:01,269 INFO:     Epoch: 93
2022-11-22 21:01:01,987 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8359058194539764, 'Total loss': 0.8359058194539764} | train loss {'Reaction outcome loss': 0.7626207771330227, 'Total loss': 0.7626207771330227}
2022-11-22 21:01:01,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:01,988 INFO:     Epoch: 94
2022-11-22 21:01:02,768 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7392721128734675, 'Total loss': 0.7392721128734675} | train loss {'Reaction outcome loss': 0.7497809722355986, 'Total loss': 0.7497809722355986}
2022-11-22 21:01:02,768 INFO:     Found new best model at epoch 94
2022-11-22 21:01:02,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:02,769 INFO:     Epoch: 95
2022-11-22 21:01:03,548 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7803068093278192, 'Total loss': 0.7803068093278192} | train loss {'Reaction outcome loss': 0.7488906721354496, 'Total loss': 0.7488906721354496}
2022-11-22 21:01:03,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:03,548 INFO:     Epoch: 96
2022-11-22 21:01:04,327 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7529486187479713, 'Total loss': 0.7529486187479713} | train loss {'Reaction outcome loss': 0.7447688249345145, 'Total loss': 0.7447688249345145}
2022-11-22 21:01:04,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:04,328 INFO:     Epoch: 97
2022-11-22 21:01:05,087 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7429958131502975, 'Total loss': 0.7429958131502975} | train loss {'Reaction outcome loss': 0.7365247641015149, 'Total loss': 0.7365247641015149}
2022-11-22 21:01:05,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:05,088 INFO:     Epoch: 98
2022-11-22 21:01:05,922 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7375546808947216, 'Total loss': 0.7375546808947216} | train loss {'Reaction outcome loss': 0.7371807076557264, 'Total loss': 0.7371807076557264}
2022-11-22 21:01:05,922 INFO:     Found new best model at epoch 98
2022-11-22 21:01:05,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:05,923 INFO:     Epoch: 99
2022-11-22 21:01:06,766 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7858088531277396, 'Total loss': 0.7858088531277396} | train loss {'Reaction outcome loss': 0.734738815771906, 'Total loss': 0.734738815771906}
2022-11-22 21:01:06,766 INFO:     Best model found after epoch 99 of 100.
2022-11-22 21:01:06,766 INFO:   Done with stage: TRAINING
2022-11-22 21:01:06,766 INFO:   Starting stage: EVALUATION
2022-11-22 21:01:06,886 INFO:   Done with stage: EVALUATION
2022-11-22 21:01:06,895 INFO:   Leaving out SEQ value Fold_0
2022-11-22 21:01:06,909 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 21:01:06,909 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:01:07,582 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:01:07,583 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:01:07,652 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:01:07,652 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:01:07,652 INFO:     No hyperparam tuning for this model
2022-11-22 21:01:07,652 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:01:07,652 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:01:07,653 INFO:     None feature selector for col prot
2022-11-22 21:01:07,653 INFO:     None feature selector for col prot
2022-11-22 21:01:07,653 INFO:     None feature selector for col prot
2022-11-22 21:01:07,654 INFO:     None feature selector for col chem
2022-11-22 21:01:07,654 INFO:     None feature selector for col chem
2022-11-22 21:01:07,654 INFO:     None feature selector for col chem
2022-11-22 21:01:07,654 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:01:07,654 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:01:07,656 INFO:     Number of params in model 126091
2022-11-22 21:01:07,659 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:01:07,659 INFO:   Starting stage: TRAINING
2022-11-22 21:01:07,708 INFO:     Val loss before train {'Reaction outcome loss': 0.9579052925109863, 'Total loss': 0.9579052925109863}
2022-11-22 21:01:07,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:07,708 INFO:     Epoch: 0
2022-11-22 21:01:08,481 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8007485941052437, 'Total loss': 0.8007485941052437} | train loss {'Reaction outcome loss': 0.8809108115159549, 'Total loss': 0.8809108115159549}
2022-11-22 21:01:08,481 INFO:     Found new best model at epoch 0
2022-11-22 21:01:08,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:08,482 INFO:     Epoch: 1
2022-11-22 21:01:09,261 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8039095394990661, 'Total loss': 0.8039095394990661} | train loss {'Reaction outcome loss': 0.8542405411540738, 'Total loss': 0.8542405411540738}
2022-11-22 21:01:09,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:09,262 INFO:     Epoch: 2
2022-11-22 21:01:09,991 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7885421981865709, 'Total loss': 0.7885421981865709} | train loss {'Reaction outcome loss': 0.8477676731613484, 'Total loss': 0.8477676731613484}
2022-11-22 21:01:09,991 INFO:     Found new best model at epoch 2
2022-11-22 21:01:09,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:09,992 INFO:     Epoch: 3
2022-11-22 21:01:10,720 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7821792174469341, 'Total loss': 0.7821792174469341} | train loss {'Reaction outcome loss': 0.8356013281142664, 'Total loss': 0.8356013281142664}
2022-11-22 21:01:10,720 INFO:     Found new best model at epoch 3
2022-11-22 21:01:10,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:10,721 INFO:     Epoch: 4
2022-11-22 21:01:11,496 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8235518566586755, 'Total loss': 0.8235518566586755} | train loss {'Reaction outcome loss': 0.8344004070951871, 'Total loss': 0.8344004070951871}
2022-11-22 21:01:11,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:11,496 INFO:     Epoch: 5
2022-11-22 21:01:12,290 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8011245409196074, 'Total loss': 0.8011245409196074} | train loss {'Reaction outcome loss': 0.8272670127964212, 'Total loss': 0.8272670127964212}
2022-11-22 21:01:12,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:12,291 INFO:     Epoch: 6
2022-11-22 21:01:13,050 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7859626690095122, 'Total loss': 0.7859626690095122} | train loss {'Reaction outcome loss': 0.8249182079726385, 'Total loss': 0.8249182079726385}
2022-11-22 21:01:13,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:13,050 INFO:     Epoch: 7
2022-11-22 21:01:13,799 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7691836032000455, 'Total loss': 0.7691836032000455} | train loss {'Reaction outcome loss': 0.8285962942882106, 'Total loss': 0.8285962942882106}
2022-11-22 21:01:13,799 INFO:     Found new best model at epoch 7
2022-11-22 21:01:13,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:13,801 INFO:     Epoch: 8
2022-11-22 21:01:14,541 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7969398688186299, 'Total loss': 0.7969398688186299} | train loss {'Reaction outcome loss': 0.8208641775465204, 'Total loss': 0.8208641775465204}
2022-11-22 21:01:14,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:14,542 INFO:     Epoch: 9
2022-11-22 21:01:15,316 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7671740258281882, 'Total loss': 0.7671740258281882} | train loss {'Reaction outcome loss': 0.8130034474950087, 'Total loss': 0.8130034474950087}
2022-11-22 21:01:15,316 INFO:     Found new best model at epoch 9
2022-11-22 21:01:15,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:15,317 INFO:     Epoch: 10
2022-11-22 21:01:16,074 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7642393803054636, 'Total loss': 0.7642393803054636} | train loss {'Reaction outcome loss': 0.8181060141759363, 'Total loss': 0.8181060141759363}
2022-11-22 21:01:16,074 INFO:     Found new best model at epoch 10
2022-11-22 21:01:16,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:16,075 INFO:     Epoch: 11
2022-11-22 21:01:16,833 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7837397341023792, 'Total loss': 0.7837397341023792} | train loss {'Reaction outcome loss': 0.8210151273953287, 'Total loss': 0.8210151273953287}
2022-11-22 21:01:16,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:16,833 INFO:     Epoch: 12
2022-11-22 21:01:17,595 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8143121315674349, 'Total loss': 0.8143121315674349} | train loss {'Reaction outcome loss': 0.8074803307260338, 'Total loss': 0.8074803307260338}
2022-11-22 21:01:17,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:17,596 INFO:     Epoch: 13
2022-11-22 21:01:18,367 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7860519655726173, 'Total loss': 0.7860519655726173} | train loss {'Reaction outcome loss': 0.8134945824078703, 'Total loss': 0.8134945824078703}
2022-11-22 21:01:18,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:18,367 INFO:     Epoch: 14
2022-11-22 21:01:19,117 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7837803411212835, 'Total loss': 0.7837803411212835} | train loss {'Reaction outcome loss': 0.8069395024766807, 'Total loss': 0.8069395024766807}
2022-11-22 21:01:19,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:19,117 INFO:     Epoch: 15
2022-11-22 21:01:19,899 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7711521949280392, 'Total loss': 0.7711521949280392} | train loss {'Reaction outcome loss': 0.8118652347852344, 'Total loss': 0.8118652347852344}
2022-11-22 21:01:19,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:19,901 INFO:     Epoch: 16
2022-11-22 21:01:20,669 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8084776916287162, 'Total loss': 0.8084776916287162} | train loss {'Reaction outcome loss': 0.8277706015206542, 'Total loss': 0.8277706015206542}
2022-11-22 21:01:20,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:20,669 INFO:     Epoch: 17
2022-11-22 21:01:21,420 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7842143448916349, 'Total loss': 0.7842143448916349} | train loss {'Reaction outcome loss': 0.8145142023259329, 'Total loss': 0.8145142023259329}
2022-11-22 21:01:21,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:21,420 INFO:     Epoch: 18
2022-11-22 21:01:22,148 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7633963145992972, 'Total loss': 0.7633963145992972} | train loss {'Reaction outcome loss': 0.7999845370348648, 'Total loss': 0.7999845370348648}
2022-11-22 21:01:22,148 INFO:     Found new best model at epoch 18
2022-11-22 21:01:22,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:22,149 INFO:     Epoch: 19
2022-11-22 21:01:22,925 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7722406143491919, 'Total loss': 0.7722406143491919} | train loss {'Reaction outcome loss': 0.8016881743664683, 'Total loss': 0.8016881743664683}
2022-11-22 21:01:22,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:22,925 INFO:     Epoch: 20
2022-11-22 21:01:23,698 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.781308883970434, 'Total loss': 0.781308883970434} | train loss {'Reaction outcome loss': 0.7970360783550904, 'Total loss': 0.7970360783550904}
2022-11-22 21:01:23,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:23,698 INFO:     Epoch: 21
2022-11-22 21:01:24,438 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7592800205404108, 'Total loss': 0.7592800205404108} | train loss {'Reaction outcome loss': 0.8013669154663318, 'Total loss': 0.8013669154663318}
2022-11-22 21:01:24,439 INFO:     Found new best model at epoch 21
2022-11-22 21:01:24,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:24,439 INFO:     Epoch: 22
2022-11-22 21:01:25,204 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7655409709973768, 'Total loss': 0.7655409709973768} | train loss {'Reaction outcome loss': 0.8064514368410535, 'Total loss': 0.8064514368410535}
2022-11-22 21:01:25,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:25,204 INFO:     Epoch: 23
2022-11-22 21:01:25,959 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7816816432909532, 'Total loss': 0.7816816432909532} | train loss {'Reaction outcome loss': 0.8060928053158497, 'Total loss': 0.8060928053158497}
2022-11-22 21:01:25,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:25,959 INFO:     Epoch: 24
2022-11-22 21:01:26,664 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7553492059761827, 'Total loss': 0.7553492059761827} | train loss {'Reaction outcome loss': 0.7971905466274694, 'Total loss': 0.7971905466274694}
2022-11-22 21:01:26,664 INFO:     Found new best model at epoch 24
2022-11-22 21:01:26,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:26,665 INFO:     Epoch: 25
2022-11-22 21:01:27,406 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7646937228061936, 'Total loss': 0.7646937228061936} | train loss {'Reaction outcome loss': 0.8030699180205342, 'Total loss': 0.8030699180205342}
2022-11-22 21:01:27,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:27,406 INFO:     Epoch: 26
2022-11-22 21:01:28,164 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7662630318240686, 'Total loss': 0.7662630318240686} | train loss {'Reaction outcome loss': 0.8027573115671212, 'Total loss': 0.8027573115671212}
2022-11-22 21:01:28,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:28,164 INFO:     Epoch: 27
2022-11-22 21:01:28,905 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7747382616454904, 'Total loss': 0.7747382616454904} | train loss {'Reaction outcome loss': 0.794553682389047, 'Total loss': 0.794553682389047}
2022-11-22 21:01:28,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:28,905 INFO:     Epoch: 28
2022-11-22 21:01:29,658 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7896074815229936, 'Total loss': 0.7896074815229936} | train loss {'Reaction outcome loss': 0.7921302106744244, 'Total loss': 0.7921302106744244}
2022-11-22 21:01:29,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:29,659 INFO:     Epoch: 29
2022-11-22 21:01:30,381 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.770021144639362, 'Total loss': 0.770021144639362} | train loss {'Reaction outcome loss': 0.7905687241087317, 'Total loss': 0.7905687241087317}
2022-11-22 21:01:30,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:30,382 INFO:     Epoch: 30
2022-11-22 21:01:31,129 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.762759538536722, 'Total loss': 0.762759538536722} | train loss {'Reaction outcome loss': 0.7989386066734067, 'Total loss': 0.7989386066734067}
2022-11-22 21:01:31,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:31,129 INFO:     Epoch: 31
2022-11-22 21:01:31,879 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7515328201380643, 'Total loss': 0.7515328201380643} | train loss {'Reaction outcome loss': 0.7912099909203255, 'Total loss': 0.7912099909203255}
2022-11-22 21:01:31,879 INFO:     Found new best model at epoch 31
2022-11-22 21:01:31,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:31,880 INFO:     Epoch: 32
2022-11-22 21:01:32,611 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7679069529880177, 'Total loss': 0.7679069529880177} | train loss {'Reaction outcome loss': 0.7919273668455209, 'Total loss': 0.7919273668455209}
2022-11-22 21:01:32,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:32,613 INFO:     Epoch: 33
2022-11-22 21:01:33,366 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7663703533736143, 'Total loss': 0.7663703533736143} | train loss {'Reaction outcome loss': 0.7995409394806696, 'Total loss': 0.7995409394806696}
2022-11-22 21:01:33,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:33,367 INFO:     Epoch: 34
2022-11-22 21:01:34,092 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7988190285184167, 'Total loss': 0.7988190285184167} | train loss {'Reaction outcome loss': 0.7900976309409509, 'Total loss': 0.7900976309409509}
2022-11-22 21:01:34,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:34,093 INFO:     Epoch: 35
2022-11-22 21:01:34,859 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7985315160317854, 'Total loss': 0.7985315160317854} | train loss {'Reaction outcome loss': 0.789566760241744, 'Total loss': 0.789566760241744}
2022-11-22 21:01:34,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:34,859 INFO:     Epoch: 36
2022-11-22 21:01:35,607 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7740395556796681, 'Total loss': 0.7740395556796681} | train loss {'Reaction outcome loss': 0.7827412220630569, 'Total loss': 0.7827412220630569}
2022-11-22 21:01:35,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:35,607 INFO:     Epoch: 37
2022-11-22 21:01:36,370 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7952176454392347, 'Total loss': 0.7952176454392347} | train loss {'Reaction outcome loss': 0.7930608355564627, 'Total loss': 0.7930608355564627}
2022-11-22 21:01:36,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:36,371 INFO:     Epoch: 38
2022-11-22 21:01:37,125 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7514368329535831, 'Total loss': 0.7514368329535831} | train loss {'Reaction outcome loss': 0.7896021342108607, 'Total loss': 0.7896021342108607}
2022-11-22 21:01:37,126 INFO:     Found new best model at epoch 38
2022-11-22 21:01:37,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:37,127 INFO:     Epoch: 39
2022-11-22 21:01:37,857 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7628142237663269, 'Total loss': 0.7628142237663269} | train loss {'Reaction outcome loss': 0.785681932078682, 'Total loss': 0.785681932078682}
2022-11-22 21:01:37,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:37,857 INFO:     Epoch: 40
2022-11-22 21:01:38,612 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7532123943621462, 'Total loss': 0.7532123943621462} | train loss {'Reaction outcome loss': 0.787853166883291, 'Total loss': 0.787853166883291}
2022-11-22 21:01:38,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:38,613 INFO:     Epoch: 41
2022-11-22 21:01:39,400 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7471434352072802, 'Total loss': 0.7471434352072802} | train loss {'Reaction outcome loss': 0.7893809048753035, 'Total loss': 0.7893809048753035}
2022-11-22 21:01:39,400 INFO:     Found new best model at epoch 41
2022-11-22 21:01:39,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:39,401 INFO:     Epoch: 42
2022-11-22 21:01:40,144 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7585747634822672, 'Total loss': 0.7585747634822672} | train loss {'Reaction outcome loss': 0.7823359651362848, 'Total loss': 0.7823359651362848}
2022-11-22 21:01:40,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:40,144 INFO:     Epoch: 43
2022-11-22 21:01:40,897 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7487803941423242, 'Total loss': 0.7487803941423242} | train loss {'Reaction outcome loss': 0.7939184501103544, 'Total loss': 0.7939184501103544}
2022-11-22 21:01:40,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:40,897 INFO:     Epoch: 44
2022-11-22 21:01:41,682 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8080062094059858, 'Total loss': 0.8080062094059858} | train loss {'Reaction outcome loss': 0.7943098932082354, 'Total loss': 0.7943098932082354}
2022-11-22 21:01:41,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:41,683 INFO:     Epoch: 45
2022-11-22 21:01:42,442 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7448597834868864, 'Total loss': 0.7448597834868864} | train loss {'Reaction outcome loss': 0.7779024261151731, 'Total loss': 0.7779024261151731}
2022-11-22 21:01:42,442 INFO:     Found new best model at epoch 45
2022-11-22 21:01:42,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:42,443 INFO:     Epoch: 46
2022-11-22 21:01:43,165 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7610949691046368, 'Total loss': 0.7610949691046368} | train loss {'Reaction outcome loss': 0.7834587933322196, 'Total loss': 0.7834587933322196}
2022-11-22 21:01:43,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:43,165 INFO:     Epoch: 47
2022-11-22 21:01:43,924 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.757843286476352, 'Total loss': 0.757843286476352} | train loss {'Reaction outcome loss': 0.7856244008369774, 'Total loss': 0.7856244008369774}
2022-11-22 21:01:43,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:43,924 INFO:     Epoch: 48
2022-11-22 21:01:44,690 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7735480313951318, 'Total loss': 0.7735480313951318} | train loss {'Reaction outcome loss': 0.7783574711697304, 'Total loss': 0.7783574711697304}
2022-11-22 21:01:44,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:44,690 INFO:     Epoch: 49
2022-11-22 21:01:45,430 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7731643427502025, 'Total loss': 0.7731643427502025} | train loss {'Reaction outcome loss': 0.7838431316529691, 'Total loss': 0.7838431316529691}
2022-11-22 21:01:45,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:45,431 INFO:     Epoch: 50
2022-11-22 21:01:46,188 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.74820637838407, 'Total loss': 0.74820637838407} | train loss {'Reaction outcome loss': 0.7790701648122386, 'Total loss': 0.7790701648122386}
2022-11-22 21:01:46,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:46,189 INFO:     Epoch: 51
2022-11-22 21:01:46,959 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7751877978444099, 'Total loss': 0.7751877978444099} | train loss {'Reaction outcome loss': 0.7757490087858578, 'Total loss': 0.7757490087858578}
2022-11-22 21:01:46,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:46,959 INFO:     Epoch: 52
2022-11-22 21:01:47,748 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7418405738743868, 'Total loss': 0.7418405738743868} | train loss {'Reaction outcome loss': 0.789630141818089, 'Total loss': 0.789630141818089}
2022-11-22 21:01:47,748 INFO:     Found new best model at epoch 52
2022-11-22 21:01:47,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:47,749 INFO:     Epoch: 53
2022-11-22 21:01:48,552 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7532008425755934, 'Total loss': 0.7532008425755934} | train loss {'Reaction outcome loss': 0.7742859117897899, 'Total loss': 0.7742859117897899}
2022-11-22 21:01:48,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:48,552 INFO:     Epoch: 54
2022-11-22 21:01:49,319 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7405152679844336, 'Total loss': 0.7405152679844336} | train loss {'Reaction outcome loss': 0.7743097164852899, 'Total loss': 0.7743097164852899}
2022-11-22 21:01:49,319 INFO:     Found new best model at epoch 54
2022-11-22 21:01:49,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:49,320 INFO:     Epoch: 55
2022-11-22 21:01:50,083 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7607243806123734, 'Total loss': 0.7607243806123734} | train loss {'Reaction outcome loss': 0.774060093198228, 'Total loss': 0.774060093198228}
2022-11-22 21:01:50,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:50,083 INFO:     Epoch: 56
2022-11-22 21:01:50,891 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.800372146747329, 'Total loss': 0.800372146747329} | train loss {'Reaction outcome loss': 0.7737497217983369, 'Total loss': 0.7737497217983369}
2022-11-22 21:01:50,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:50,892 INFO:     Epoch: 57
2022-11-22 21:01:51,640 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.736175453121012, 'Total loss': 0.736175453121012} | train loss {'Reaction outcome loss': 0.7766869439769853, 'Total loss': 0.7766869439769853}
2022-11-22 21:01:51,640 INFO:     Found new best model at epoch 57
2022-11-22 21:01:51,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:51,641 INFO:     Epoch: 58
2022-11-22 21:01:52,408 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7340190146457065, 'Total loss': 0.7340190146457065} | train loss {'Reaction outcome loss': 0.773476916165487, 'Total loss': 0.773476916165487}
2022-11-22 21:01:52,408 INFO:     Found new best model at epoch 58
2022-11-22 21:01:52,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:52,409 INFO:     Epoch: 59
2022-11-22 21:01:53,171 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7369919873096726, 'Total loss': 0.7369919873096726} | train loss {'Reaction outcome loss': 0.77122269890569, 'Total loss': 0.77122269890569}
2022-11-22 21:01:53,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:53,172 INFO:     Epoch: 60
2022-11-22 21:01:53,927 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7364699136127125, 'Total loss': 0.7364699136127125} | train loss {'Reaction outcome loss': 0.7753394786645527, 'Total loss': 0.7753394786645527}
2022-11-22 21:01:53,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:53,927 INFO:     Epoch: 61
2022-11-22 21:01:54,691 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7861685224554755, 'Total loss': 0.7861685224554755} | train loss {'Reaction outcome loss': 0.7734216677273816, 'Total loss': 0.7734216677273816}
2022-11-22 21:01:54,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:54,691 INFO:     Epoch: 62
2022-11-22 21:01:55,429 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7453313232822851, 'Total loss': 0.7453313232822851} | train loss {'Reaction outcome loss': 0.7802899518476324, 'Total loss': 0.7802899518476324}
2022-11-22 21:01:55,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:55,429 INFO:     Epoch: 63
2022-11-22 21:01:56,142 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7261386418884451, 'Total loss': 0.7261386418884451} | train loss {'Reaction outcome loss': 0.7646548369152826, 'Total loss': 0.7646548369152826}
2022-11-22 21:01:56,142 INFO:     Found new best model at epoch 63
2022-11-22 21:01:56,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:56,143 INFO:     Epoch: 64
2022-11-22 21:01:56,907 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7661920352415605, 'Total loss': 0.7661920352415605} | train loss {'Reaction outcome loss': 0.7730201163634598, 'Total loss': 0.7730201163634598}
2022-11-22 21:01:56,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:56,907 INFO:     Epoch: 65
2022-11-22 21:01:57,661 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7431066354567354, 'Total loss': 0.7431066354567354} | train loss {'Reaction outcome loss': 0.7722006159031439, 'Total loss': 0.7722006159031439}
2022-11-22 21:01:57,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:57,661 INFO:     Epoch: 66
2022-11-22 21:01:58,453 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7612312734127045, 'Total loss': 0.7612312734127045} | train loss {'Reaction outcome loss': 0.7731204585507814, 'Total loss': 0.7731204585507814}
2022-11-22 21:01:58,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:58,453 INFO:     Epoch: 67
2022-11-22 21:01:59,262 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7750744914466684, 'Total loss': 0.7750744914466684} | train loss {'Reaction outcome loss': 0.76284041490994, 'Total loss': 0.76284041490994}
2022-11-22 21:01:59,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:01:59,262 INFO:     Epoch: 68
2022-11-22 21:02:00,048 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7462337626652285, 'Total loss': 0.7462337626652285} | train loss {'Reaction outcome loss': 0.7612672714810622, 'Total loss': 0.7612672714810622}
2022-11-22 21:02:00,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:00,048 INFO:     Epoch: 69
2022-11-22 21:02:00,815 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7426818643103946, 'Total loss': 0.7426818643103946} | train loss {'Reaction outcome loss': 0.7702381230800258, 'Total loss': 0.7702381230800258}
2022-11-22 21:02:00,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:00,815 INFO:     Epoch: 70
2022-11-22 21:02:01,549 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7293338511477817, 'Total loss': 0.7293338511477817} | train loss {'Reaction outcome loss': 0.764631860893265, 'Total loss': 0.764631860893265}
2022-11-22 21:02:01,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:01,550 INFO:     Epoch: 71
2022-11-22 21:02:02,334 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7355947372588244, 'Total loss': 0.7355947372588244} | train loss {'Reaction outcome loss': 0.770499705182396, 'Total loss': 0.770499705182396}
2022-11-22 21:02:02,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:02,335 INFO:     Epoch: 72
2022-11-22 21:02:03,126 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7205875143408775, 'Total loss': 0.7205875143408775} | train loss {'Reaction outcome loss': 0.7694177056855036, 'Total loss': 0.7694177056855036}
2022-11-22 21:02:03,126 INFO:     Found new best model at epoch 72
2022-11-22 21:02:03,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:03,127 INFO:     Epoch: 73
2022-11-22 21:02:03,937 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7321750961921432, 'Total loss': 0.7321750961921432} | train loss {'Reaction outcome loss': 0.7658345750514192, 'Total loss': 0.7658345750514192}
2022-11-22 21:02:03,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:03,938 INFO:     Epoch: 74
2022-11-22 21:02:04,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7507147653536363, 'Total loss': 0.7507147653536363} | train loss {'Reaction outcome loss': 0.7552634731598711, 'Total loss': 0.7552634731598711}
2022-11-22 21:02:04,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:04,716 INFO:     Epoch: 75
2022-11-22 21:02:05,513 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7322608936916698, 'Total loss': 0.7322608936916698} | train loss {'Reaction outcome loss': 0.760953432212957, 'Total loss': 0.760953432212957}
2022-11-22 21:02:05,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:05,513 INFO:     Epoch: 76
2022-11-22 21:02:06,299 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7246642783284187, 'Total loss': 0.7246642783284187} | train loss {'Reaction outcome loss': 0.7654413339580118, 'Total loss': 0.7654413339580118}
2022-11-22 21:02:06,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:06,300 INFO:     Epoch: 77
2022-11-22 21:02:07,072 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8362282697450031, 'Total loss': 0.8362282697450031} | train loss {'Reaction outcome loss': 0.7629877653440483, 'Total loss': 0.7629877653440483}
2022-11-22 21:02:07,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:07,072 INFO:     Epoch: 78
2022-11-22 21:02:07,850 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7254974855618044, 'Total loss': 0.7254974855618044} | train loss {'Reaction outcome loss': 0.7556792168127682, 'Total loss': 0.7556792168127682}
2022-11-22 21:02:07,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:07,851 INFO:     Epoch: 79
2022-11-22 21:02:08,676 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7179484184492718, 'Total loss': 0.7179484184492718} | train loss {'Reaction outcome loss': 0.7542478475976087, 'Total loss': 0.7542478475976087}
2022-11-22 21:02:08,676 INFO:     Found new best model at epoch 79
2022-11-22 21:02:08,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:08,677 INFO:     Epoch: 80
2022-11-22 21:02:09,451 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7172832495786927, 'Total loss': 0.7172832495786927} | train loss {'Reaction outcome loss': 0.7504477465321661, 'Total loss': 0.7504477465321661}
2022-11-22 21:02:09,451 INFO:     Found new best model at epoch 80
2022-11-22 21:02:09,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:09,452 INFO:     Epoch: 81
2022-11-22 21:02:10,241 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.734257426451553, 'Total loss': 0.734257426451553} | train loss {'Reaction outcome loss': 0.7663533826347305, 'Total loss': 0.7663533826347305}
2022-11-22 21:02:10,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:10,242 INFO:     Epoch: 82
2022-11-22 21:02:11,059 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7275719378482212, 'Total loss': 0.7275719378482212} | train loss {'Reaction outcome loss': 0.7470935398056681, 'Total loss': 0.7470935398056681}
2022-11-22 21:02:11,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:11,059 INFO:     Epoch: 83
2022-11-22 21:02:11,871 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.755987590009516, 'Total loss': 0.755987590009516} | train loss {'Reaction outcome loss': 0.7543895577612193, 'Total loss': 0.7543895577612193}
2022-11-22 21:02:11,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:11,872 INFO:     Epoch: 84
2022-11-22 21:02:12,679 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7212946611371908, 'Total loss': 0.7212946611371908} | train loss {'Reaction outcome loss': 0.758323574838368, 'Total loss': 0.758323574838368}
2022-11-22 21:02:12,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:12,679 INFO:     Epoch: 85
2022-11-22 21:02:13,466 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7199143069711599, 'Total loss': 0.7199143069711599} | train loss {'Reaction outcome loss': 0.7597021573950887, 'Total loss': 0.7597021573950887}
2022-11-22 21:02:13,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:13,466 INFO:     Epoch: 86
2022-11-22 21:02:14,252 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7214342992414128, 'Total loss': 0.7214342992414128} | train loss {'Reaction outcome loss': 0.7537933569326092, 'Total loss': 0.7537933569326092}
2022-11-22 21:02:14,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:14,253 INFO:     Epoch: 87
2022-11-22 21:02:15,043 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7299209304831245, 'Total loss': 0.7299209304831245} | train loss {'Reaction outcome loss': 0.7514269074749368, 'Total loss': 0.7514269074749368}
2022-11-22 21:02:15,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:15,044 INFO:     Epoch: 88
2022-11-22 21:02:15,844 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.765718550844626, 'Total loss': 0.765718550844626} | train loss {'Reaction outcome loss': 0.7449925897816415, 'Total loss': 0.7449925897816415}
2022-11-22 21:02:15,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:15,845 INFO:     Epoch: 89
2022-11-22 21:02:16,612 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7654113336042925, 'Total loss': 0.7654113336042925} | train loss {'Reaction outcome loss': 0.7547775345292651, 'Total loss': 0.7547775345292651}
2022-11-22 21:02:16,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:16,612 INFO:     Epoch: 90
2022-11-22 21:02:17,371 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7044301920316436, 'Total loss': 0.7044301920316436} | train loss {'Reaction outcome loss': 0.7546756542645968, 'Total loss': 0.7546756542645968}
2022-11-22 21:02:17,371 INFO:     Found new best model at epoch 90
2022-11-22 21:02:17,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:17,372 INFO:     Epoch: 91
2022-11-22 21:02:18,176 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.723448631438342, 'Total loss': 0.723448631438342} | train loss {'Reaction outcome loss': 0.7359992930220689, 'Total loss': 0.7359992930220689}
2022-11-22 21:02:18,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:18,176 INFO:     Epoch: 92
2022-11-22 21:02:18,966 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7673120173540983, 'Total loss': 0.7673120173540983} | train loss {'Reaction outcome loss': 0.7562730753952674, 'Total loss': 0.7562730753952674}
2022-11-22 21:02:18,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:18,966 INFO:     Epoch: 93
2022-11-22 21:02:19,744 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7177583040161566, 'Total loss': 0.7177583040161566} | train loss {'Reaction outcome loss': 0.7607375028644979, 'Total loss': 0.7607375028644979}
2022-11-22 21:02:19,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:19,744 INFO:     Epoch: 94
2022-11-22 21:02:20,545 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7134511213410984, 'Total loss': 0.7134511213410984} | train loss {'Reaction outcome loss': 0.7416477202690444, 'Total loss': 0.7416477202690444}
2022-11-22 21:02:20,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:20,546 INFO:     Epoch: 95
2022-11-22 21:02:21,352 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7047986320473931, 'Total loss': 0.7047986320473931} | train loss {'Reaction outcome loss': 0.7407405407842897, 'Total loss': 0.7407405407842897}
2022-11-22 21:02:21,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:21,353 INFO:     Epoch: 96
2022-11-22 21:02:22,136 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7248802781105042, 'Total loss': 0.7248802781105042} | train loss {'Reaction outcome loss': 0.7342652262222429, 'Total loss': 0.7342652262222429}
2022-11-22 21:02:22,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:22,136 INFO:     Epoch: 97
2022-11-22 21:02:22,934 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7203399965708907, 'Total loss': 0.7203399965708907} | train loss {'Reaction outcome loss': 0.7397705696010397, 'Total loss': 0.7397705696010397}
2022-11-22 21:02:22,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:22,935 INFO:     Epoch: 98
2022-11-22 21:02:23,704 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7145519215952266, 'Total loss': 0.7145519215952266} | train loss {'Reaction outcome loss': 0.740940372470902, 'Total loss': 0.740940372470902}
2022-11-22 21:02:23,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:23,704 INFO:     Epoch: 99
2022-11-22 21:02:24,443 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7303058328953657, 'Total loss': 0.7303058328953657} | train loss {'Reaction outcome loss': 0.7431753500692757, 'Total loss': 0.7431753500692757}
2022-11-22 21:02:24,443 INFO:     Best model found after epoch 91 of 100.
2022-11-22 21:02:24,443 INFO:   Done with stage: TRAINING
2022-11-22 21:02:24,443 INFO:   Starting stage: EVALUATION
2022-11-22 21:02:24,562 INFO:   Done with stage: EVALUATION
2022-11-22 21:02:24,562 INFO:   Leaving out SEQ value Fold_1
2022-11-22 21:02:24,577 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 21:02:24,577 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:02:25,257 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:02:25,258 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:02:25,329 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:02:25,329 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:02:25,329 INFO:     No hyperparam tuning for this model
2022-11-22 21:02:25,329 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:02:25,329 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:02:25,330 INFO:     None feature selector for col prot
2022-11-22 21:02:25,330 INFO:     None feature selector for col prot
2022-11-22 21:02:25,331 INFO:     None feature selector for col prot
2022-11-22 21:02:25,331 INFO:     None feature selector for col chem
2022-11-22 21:02:25,331 INFO:     None feature selector for col chem
2022-11-22 21:02:25,331 INFO:     None feature selector for col chem
2022-11-22 21:02:25,331 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:02:25,331 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:02:25,333 INFO:     Number of params in model 126091
2022-11-22 21:02:25,336 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:02:25,336 INFO:   Starting stage: TRAINING
2022-11-22 21:02:25,386 INFO:     Val loss before train {'Reaction outcome loss': 0.9922346879135479, 'Total loss': 0.9922346879135479}
2022-11-22 21:02:25,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:25,387 INFO:     Epoch: 0
2022-11-22 21:02:26,127 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8201499120755629, 'Total loss': 0.8201499120755629} | train loss {'Reaction outcome loss': 0.8797089424934464, 'Total loss': 0.8797089424934464}
2022-11-22 21:02:26,127 INFO:     Found new best model at epoch 0
2022-11-22 21:02:26,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:26,128 INFO:     Epoch: 1
2022-11-22 21:02:26,884 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8261969055641781, 'Total loss': 0.8261969055641781} | train loss {'Reaction outcome loss': 0.84496849105667, 'Total loss': 0.84496849105667}
2022-11-22 21:02:26,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:26,884 INFO:     Epoch: 2
2022-11-22 21:02:27,631 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8282753188501705, 'Total loss': 0.8282753188501705} | train loss {'Reaction outcome loss': 0.8394876138612568, 'Total loss': 0.8394876138612568}
2022-11-22 21:02:27,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:27,631 INFO:     Epoch: 3
2022-11-22 21:02:28,385 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8045581145720049, 'Total loss': 0.8045581145720049} | train loss {'Reaction outcome loss': 0.8283722783600994, 'Total loss': 0.8283722783600994}
2022-11-22 21:02:28,385 INFO:     Found new best model at epoch 3
2022-11-22 21:02:28,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:28,386 INFO:     Epoch: 4
2022-11-22 21:02:29,159 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8014361655170267, 'Total loss': 0.8014361655170267} | train loss {'Reaction outcome loss': 0.8239875622244499, 'Total loss': 0.8239875622244499}
2022-11-22 21:02:29,159 INFO:     Found new best model at epoch 4
2022-11-22 21:02:29,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:29,160 INFO:     Epoch: 5
2022-11-22 21:02:29,932 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7948662476106123, 'Total loss': 0.7948662476106123} | train loss {'Reaction outcome loss': 0.8217527740880063, 'Total loss': 0.8217527740880063}
2022-11-22 21:02:29,932 INFO:     Found new best model at epoch 5
2022-11-22 21:02:29,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:29,933 INFO:     Epoch: 6
2022-11-22 21:02:30,679 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7937450185418129, 'Total loss': 0.7937450185418129} | train loss {'Reaction outcome loss': 0.8176118861808468, 'Total loss': 0.8176118861808468}
2022-11-22 21:02:30,679 INFO:     Found new best model at epoch 6
2022-11-22 21:02:30,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:30,681 INFO:     Epoch: 7
2022-11-22 21:02:31,464 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8184675438837572, 'Total loss': 0.8184675438837572} | train loss {'Reaction outcome loss': 0.8124756793593347, 'Total loss': 0.8124756793593347}
2022-11-22 21:02:31,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:31,464 INFO:     Epoch: 8
2022-11-22 21:02:32,230 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8096799315376715, 'Total loss': 0.8096799315376715} | train loss {'Reaction outcome loss': 0.8165169129004846, 'Total loss': 0.8165169129004846}
2022-11-22 21:02:32,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:32,230 INFO:     Epoch: 9
2022-11-22 21:02:33,011 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8134125484661623, 'Total loss': 0.8134125484661623} | train loss {'Reaction outcome loss': 0.8093313258669155, 'Total loss': 0.8093313258669155}
2022-11-22 21:02:33,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:33,011 INFO:     Epoch: 10
2022-11-22 21:02:33,780 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8143376741896976, 'Total loss': 0.8143376741896976} | train loss {'Reaction outcome loss': 0.8126601847077188, 'Total loss': 0.8126601847077188}
2022-11-22 21:02:33,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:33,780 INFO:     Epoch: 11
2022-11-22 21:02:34,529 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8384025340730493, 'Total loss': 0.8384025340730493} | train loss {'Reaction outcome loss': 0.8097301430789082, 'Total loss': 0.8097301430789082}
2022-11-22 21:02:34,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:34,529 INFO:     Epoch: 12
2022-11-22 21:02:35,305 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8046867610378698, 'Total loss': 0.8046867610378698} | train loss {'Reaction outcome loss': 0.814542161670291, 'Total loss': 0.814542161670291}
2022-11-22 21:02:35,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:35,306 INFO:     Epoch: 13
2022-11-22 21:02:36,065 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8111416385932402, 'Total loss': 0.8111416385932402} | train loss {'Reaction outcome loss': 0.8027153216332559, 'Total loss': 0.8027153216332559}
2022-11-22 21:02:36,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:36,065 INFO:     Epoch: 14
2022-11-22 21:02:36,803 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7822179726578973, 'Total loss': 0.7822179726578973} | train loss {'Reaction outcome loss': 0.8040517829207756, 'Total loss': 0.8040517829207756}
2022-11-22 21:02:36,803 INFO:     Found new best model at epoch 14
2022-11-22 21:02:36,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:36,804 INFO:     Epoch: 15
2022-11-22 21:02:37,564 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7975481701168147, 'Total loss': 0.7975481701168147} | train loss {'Reaction outcome loss': 0.8082569132932285, 'Total loss': 0.8082569132932285}
2022-11-22 21:02:37,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:37,564 INFO:     Epoch: 16
2022-11-22 21:02:38,378 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7974795421416109, 'Total loss': 0.7974795421416109} | train loss {'Reaction outcome loss': 0.8027669185327615, 'Total loss': 0.8027669185327615}
2022-11-22 21:02:38,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:38,378 INFO:     Epoch: 17
2022-11-22 21:02:39,161 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8019671399484981, 'Total loss': 0.8019671399484981} | train loss {'Reaction outcome loss': 0.8157490314501017, 'Total loss': 0.8157490314501017}
2022-11-22 21:02:39,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:39,161 INFO:     Epoch: 18
2022-11-22 21:02:39,933 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8117848506028001, 'Total loss': 0.8117848506028001} | train loss {'Reaction outcome loss': 0.8123414900138793, 'Total loss': 0.8123414900138793}
2022-11-22 21:02:39,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:39,933 INFO:     Epoch: 19
2022-11-22 21:02:40,687 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8254490860483863, 'Total loss': 0.8254490860483863} | train loss {'Reaction outcome loss': 0.8086587028947436, 'Total loss': 0.8086587028947436}
2022-11-22 21:02:40,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:40,688 INFO:     Epoch: 20
2022-11-22 21:02:41,451 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8144769797270949, 'Total loss': 0.8144769797270949} | train loss {'Reaction outcome loss': 0.7975242156610798, 'Total loss': 0.7975242156610798}
2022-11-22 21:02:41,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:41,452 INFO:     Epoch: 21
2022-11-22 21:02:42,210 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7828906998038292, 'Total loss': 0.7828906998038292} | train loss {'Reaction outcome loss': 0.7989039457278696, 'Total loss': 0.7989039457278696}
2022-11-22 21:02:42,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:42,210 INFO:     Epoch: 22
2022-11-22 21:02:43,006 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8006082685156302, 'Total loss': 0.8006082685156302} | train loss {'Reaction outcome loss': 0.7965610133039083, 'Total loss': 0.7965610133039083}
2022-11-22 21:02:43,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:43,006 INFO:     Epoch: 23
2022-11-22 21:02:43,746 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8016821552406658, 'Total loss': 0.8016821552406658} | train loss {'Reaction outcome loss': 0.7924383318255305, 'Total loss': 0.7924383318255305}
2022-11-22 21:02:43,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:43,746 INFO:     Epoch: 24
2022-11-22 21:02:44,508 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7896164628592405, 'Total loss': 0.7896164628592405} | train loss {'Reaction outcome loss': 0.8026463485922408, 'Total loss': 0.8026463485922408}
2022-11-22 21:02:44,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:44,508 INFO:     Epoch: 25
2022-11-22 21:02:45,301 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.787223414263942, 'Total loss': 0.787223414263942} | train loss {'Reaction outcome loss': 0.8003701133585652, 'Total loss': 0.8003701133585652}
2022-11-22 21:02:45,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:45,302 INFO:     Epoch: 26
2022-11-22 21:02:46,105 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7859542044726285, 'Total loss': 0.7859542044726285} | train loss {'Reaction outcome loss': 0.8029141032744033, 'Total loss': 0.8029141032744033}
2022-11-22 21:02:46,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:46,105 INFO:     Epoch: 27
2022-11-22 21:02:46,845 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7830244329842654, 'Total loss': 0.7830244329842654} | train loss {'Reaction outcome loss': 0.8004462769639636, 'Total loss': 0.8004462769639636}
2022-11-22 21:02:46,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:46,845 INFO:     Epoch: 28
2022-11-22 21:02:47,599 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7994491268288005, 'Total loss': 0.7994491268288005} | train loss {'Reaction outcome loss': 0.799812614797098, 'Total loss': 0.799812614797098}
2022-11-22 21:02:47,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:47,599 INFO:     Epoch: 29
2022-11-22 21:02:48,375 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8082842474633997, 'Total loss': 0.8082842474633997} | train loss {'Reaction outcome loss': 0.8025720438011262, 'Total loss': 0.8025720438011262}
2022-11-22 21:02:48,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:48,375 INFO:     Epoch: 30
2022-11-22 21:02:49,116 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8074869533831422, 'Total loss': 0.8074869533831422} | train loss {'Reaction outcome loss': 0.7954361861352979, 'Total loss': 0.7954361861352979}
2022-11-22 21:02:49,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:49,116 INFO:     Epoch: 31
2022-11-22 21:02:49,866 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8084399916908958, 'Total loss': 0.8084399916908958} | train loss {'Reaction outcome loss': 0.7921830593091757, 'Total loss': 0.7921830593091757}
2022-11-22 21:02:49,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:49,867 INFO:     Epoch: 32
2022-11-22 21:02:50,647 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7870118184523149, 'Total loss': 0.7870118184523149} | train loss {'Reaction outcome loss': 0.8009707191242621, 'Total loss': 0.8009707191242621}
2022-11-22 21:02:50,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:50,647 INFO:     Epoch: 33
2022-11-22 21:02:51,419 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7946384251117706, 'Total loss': 0.7946384251117706} | train loss {'Reaction outcome loss': 0.7978939149785138, 'Total loss': 0.7978939149785138}
2022-11-22 21:02:51,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:51,419 INFO:     Epoch: 34
2022-11-22 21:02:52,180 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7856501110575416, 'Total loss': 0.7856501110575416} | train loss {'Reaction outcome loss': 0.8130713462346961, 'Total loss': 0.8130713462346961}
2022-11-22 21:02:52,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:52,180 INFO:     Epoch: 35
2022-11-22 21:02:52,968 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8036405715075406, 'Total loss': 0.8036405715075406} | train loss {'Reaction outcome loss': 0.8032260829137887, 'Total loss': 0.8032260829137887}
2022-11-22 21:02:52,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:52,968 INFO:     Epoch: 36
2022-11-22 21:02:53,739 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7898911285129461, 'Total loss': 0.7898911285129461} | train loss {'Reaction outcome loss': 0.7999543758478724, 'Total loss': 0.7999543758478724}
2022-11-22 21:02:53,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:53,740 INFO:     Epoch: 37
2022-11-22 21:02:54,481 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7891041494228623, 'Total loss': 0.7891041494228623} | train loss {'Reaction outcome loss': 0.7931937225434461, 'Total loss': 0.7931937225434461}
2022-11-22 21:02:54,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:54,482 INFO:     Epoch: 38
2022-11-22 21:02:55,259 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8011978539553556, 'Total loss': 0.8011978539553556} | train loss {'Reaction outcome loss': 0.7913046518137098, 'Total loss': 0.7913046518137098}
2022-11-22 21:02:55,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:55,260 INFO:     Epoch: 39
2022-11-22 21:02:55,989 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8123904920437119, 'Total loss': 0.8123904920437119} | train loss {'Reaction outcome loss': 0.7968881244842823, 'Total loss': 0.7968881244842823}
2022-11-22 21:02:55,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:55,989 INFO:     Epoch: 40
2022-11-22 21:02:56,750 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7724773822860285, 'Total loss': 0.7724773822860285} | train loss {'Reaction outcome loss': 0.8005478137176529, 'Total loss': 0.8005478137176529}
2022-11-22 21:02:56,750 INFO:     Found new best model at epoch 40
2022-11-22 21:02:56,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:56,751 INFO:     Epoch: 41
2022-11-22 21:02:57,489 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7823154797608202, 'Total loss': 0.7823154797608202} | train loss {'Reaction outcome loss': 0.791804537395777, 'Total loss': 0.791804537395777}
2022-11-22 21:02:57,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:57,490 INFO:     Epoch: 42
2022-11-22 21:02:58,276 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7686617882414297, 'Total loss': 0.7686617882414297} | train loss {'Reaction outcome loss': 0.7986616901299248, 'Total loss': 0.7986616901299248}
2022-11-22 21:02:58,276 INFO:     Found new best model at epoch 42
2022-11-22 21:02:58,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:58,277 INFO:     Epoch: 43
2022-11-22 21:02:59,057 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8062210523269393, 'Total loss': 0.8062210523269393} | train loss {'Reaction outcome loss': 0.7929553358781676, 'Total loss': 0.7929553358781676}
2022-11-22 21:02:59,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:59,057 INFO:     Epoch: 44
2022-11-22 21:02:59,861 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8048110421408307, 'Total loss': 0.8048110421408307} | train loss {'Reaction outcome loss': 0.7896863867638082, 'Total loss': 0.7896863867638082}
2022-11-22 21:02:59,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:02:59,862 INFO:     Epoch: 45
2022-11-22 21:03:00,644 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7703474827788093, 'Total loss': 0.7703474827788093} | train loss {'Reaction outcome loss': 0.7843992036846485, 'Total loss': 0.7843992036846485}
2022-11-22 21:03:00,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:00,645 INFO:     Epoch: 46
2022-11-22 21:03:01,432 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7781609696420756, 'Total loss': 0.7781609696420756} | train loss {'Reaction outcome loss': 0.7962662181873553, 'Total loss': 0.7962662181873553}
2022-11-22 21:03:01,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:01,432 INFO:     Epoch: 47
2022-11-22 21:03:02,224 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7672193036838011, 'Total loss': 0.7672193036838011} | train loss {'Reaction outcome loss': 0.7933757769486863, 'Total loss': 0.7933757769486863}
2022-11-22 21:03:02,225 INFO:     Found new best model at epoch 47
2022-11-22 21:03:02,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:02,226 INFO:     Epoch: 48
2022-11-22 21:03:02,986 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8089924515648321, 'Total loss': 0.8089924515648321} | train loss {'Reaction outcome loss': 0.7858270176267816, 'Total loss': 0.7858270176267816}
2022-11-22 21:03:02,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:02,986 INFO:     Epoch: 49
2022-11-22 21:03:03,746 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8005679073658857, 'Total loss': 0.8005679073658857} | train loss {'Reaction outcome loss': 0.794248659118467, 'Total loss': 0.794248659118467}
2022-11-22 21:03:03,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:03,747 INFO:     Epoch: 50
2022-11-22 21:03:04,488 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7946387075565078, 'Total loss': 0.7946387075565078} | train loss {'Reaction outcome loss': 0.7912733505370646, 'Total loss': 0.7912733505370646}
2022-11-22 21:03:04,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:04,488 INFO:     Epoch: 51
2022-11-22 21:03:05,228 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7785833782770417, 'Total loss': 0.7785833782770417} | train loss {'Reaction outcome loss': 0.7884793536141816, 'Total loss': 0.7884793536141816}
2022-11-22 21:03:05,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:05,228 INFO:     Epoch: 52
2022-11-22 21:03:05,948 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7862480723045089, 'Total loss': 0.7862480723045089} | train loss {'Reaction outcome loss': 0.789937653039631, 'Total loss': 0.789937653039631}
2022-11-22 21:03:05,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:05,950 INFO:     Epoch: 53
2022-11-22 21:03:06,695 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7748295468362895, 'Total loss': 0.7748295468362895} | train loss {'Reaction outcome loss': 0.7912811344934378, 'Total loss': 0.7912811344934378}
2022-11-22 21:03:06,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:06,695 INFO:     Epoch: 54
2022-11-22 21:03:07,446 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7869503186507658, 'Total loss': 0.7869503186507658} | train loss {'Reaction outcome loss': 0.7969724277735721, 'Total loss': 0.7969724277735721}
2022-11-22 21:03:07,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:07,446 INFO:     Epoch: 55
2022-11-22 21:03:08,165 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7909500991756265, 'Total loss': 0.7909500991756265} | train loss {'Reaction outcome loss': 0.7961158347033296, 'Total loss': 0.7961158347033296}
2022-11-22 21:03:08,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:08,165 INFO:     Epoch: 56
2022-11-22 21:03:08,929 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7798825725913048, 'Total loss': 0.7798825725913048} | train loss {'Reaction outcome loss': 0.7912919927644826, 'Total loss': 0.7912919927644826}
2022-11-22 21:03:08,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:08,929 INFO:     Epoch: 57
2022-11-22 21:03:09,696 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7991271276365627, 'Total loss': 0.7991271276365627} | train loss {'Reaction outcome loss': 0.7892779744030373, 'Total loss': 0.7892779744030373}
2022-11-22 21:03:09,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:09,696 INFO:     Epoch: 58
2022-11-22 21:03:10,446 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7950002672997388, 'Total loss': 0.7950002672997388} | train loss {'Reaction outcome loss': 0.7933711704877224, 'Total loss': 0.7933711704877224}
2022-11-22 21:03:10,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:10,446 INFO:     Epoch: 59
2022-11-22 21:03:11,188 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7695997729897499, 'Total loss': 0.7695997729897499} | train loss {'Reaction outcome loss': 0.793847921285552, 'Total loss': 0.793847921285552}
2022-11-22 21:03:11,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:11,188 INFO:     Epoch: 60
2022-11-22 21:03:11,891 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7796869752081957, 'Total loss': 0.7796869752081957} | train loss {'Reaction outcome loss': 0.7892963887467558, 'Total loss': 0.7892963887467558}
2022-11-22 21:03:11,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:11,891 INFO:     Epoch: 61
2022-11-22 21:03:12,638 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7853567871180448, 'Total loss': 0.7853567871180448} | train loss {'Reaction outcome loss': 0.7920953456448158, 'Total loss': 0.7920953456448158}
2022-11-22 21:03:12,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:12,639 INFO:     Epoch: 62
2022-11-22 21:03:13,400 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7776524539698254, 'Total loss': 0.7776524539698254} | train loss {'Reaction outcome loss': 0.7954638771682616, 'Total loss': 0.7954638771682616}
2022-11-22 21:03:13,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:13,400 INFO:     Epoch: 63
2022-11-22 21:03:14,164 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8016620149666612, 'Total loss': 0.8016620149666612} | train loss {'Reaction outcome loss': 0.7938941940363602, 'Total loss': 0.7938941940363602}
2022-11-22 21:03:14,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:14,164 INFO:     Epoch: 64
2022-11-22 21:03:14,926 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7804893099448897, 'Total loss': 0.7804893099448897} | train loss {'Reaction outcome loss': 0.7948589014862231, 'Total loss': 0.7948589014862231}
2022-11-22 21:03:14,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:14,926 INFO:     Epoch: 65
2022-11-22 21:03:15,637 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7953952218998562, 'Total loss': 0.7953952218998562} | train loss {'Reaction outcome loss': 0.7887009249525032, 'Total loss': 0.7887009249525032}
2022-11-22 21:03:15,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:15,637 INFO:     Epoch: 66
2022-11-22 21:03:16,404 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8437747318636287, 'Total loss': 0.8437747318636287} | train loss {'Reaction outcome loss': 0.7876674953983863, 'Total loss': 0.7876674953983863}
2022-11-22 21:03:16,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:16,404 INFO:     Epoch: 67
2022-11-22 21:03:17,164 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7695068493485451, 'Total loss': 0.7695068493485451} | train loss {'Reaction outcome loss': 0.7908925254817917, 'Total loss': 0.7908925254817917}
2022-11-22 21:03:17,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:17,164 INFO:     Epoch: 68
2022-11-22 21:03:17,918 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7950450317426161, 'Total loss': 0.7950450317426161} | train loss {'Reaction outcome loss': 0.785616937587377, 'Total loss': 0.785616937587377}
2022-11-22 21:03:17,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:17,918 INFO:     Epoch: 69
2022-11-22 21:03:18,611 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7994522845203226, 'Total loss': 0.7994522845203226} | train loss {'Reaction outcome loss': 0.7854584859691651, 'Total loss': 0.7854584859691651}
2022-11-22 21:03:18,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:18,611 INFO:     Epoch: 70
2022-11-22 21:03:19,343 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7999745634469119, 'Total loss': 0.7999745634469119} | train loss {'Reaction outcome loss': 0.7852989901535907, 'Total loss': 0.7852989901535907}
2022-11-22 21:03:19,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:19,343 INFO:     Epoch: 71
2022-11-22 21:03:20,133 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7824521146037362, 'Total loss': 0.7824521146037362} | train loss {'Reaction outcome loss': 0.7972855064791706, 'Total loss': 0.7972855064791706}
2022-11-22 21:03:20,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:20,133 INFO:     Epoch: 72
2022-11-22 21:03:20,868 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.756286179816181, 'Total loss': 0.756286179816181} | train loss {'Reaction outcome loss': 0.7818867055706771, 'Total loss': 0.7818867055706771}
2022-11-22 21:03:20,868 INFO:     Found new best model at epoch 72
2022-11-22 21:03:20,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:20,869 INFO:     Epoch: 73
2022-11-22 21:03:21,637 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.793012141504071, 'Total loss': 0.793012141504071} | train loss {'Reaction outcome loss': 0.789370269427898, 'Total loss': 0.789370269427898}
2022-11-22 21:03:21,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:21,637 INFO:     Epoch: 74
2022-11-22 21:03:22,405 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8460969870740717, 'Total loss': 0.8460969870740717} | train loss {'Reaction outcome loss': 0.783568990496006, 'Total loss': 0.783568990496006}
2022-11-22 21:03:22,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:22,405 INFO:     Epoch: 75
2022-11-22 21:03:23,201 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8731240169568495, 'Total loss': 0.8731240169568495} | train loss {'Reaction outcome loss': 0.7950983538560057, 'Total loss': 0.7950983538560057}
2022-11-22 21:03:23,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:23,202 INFO:     Epoch: 76
2022-11-22 21:03:23,972 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7700626863674684, 'Total loss': 0.7700626863674684} | train loss {'Reaction outcome loss': 0.7876678535088837, 'Total loss': 0.7876678535088837}
2022-11-22 21:03:23,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:23,972 INFO:     Epoch: 77
2022-11-22 21:03:24,756 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7876225181601264, 'Total loss': 0.7876225181601264} | train loss {'Reaction outcome loss': 0.7847022848573291, 'Total loss': 0.7847022848573291}
2022-11-22 21:03:24,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:24,757 INFO:     Epoch: 78
2022-11-22 21:03:25,546 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8059926940636202, 'Total loss': 0.8059926940636202} | train loss {'Reaction outcome loss': 0.7909597610896416, 'Total loss': 0.7909597610896416}
2022-11-22 21:03:25,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:25,547 INFO:     Epoch: 79
2022-11-22 21:03:26,312 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7789857665246184, 'Total loss': 0.7789857665246184} | train loss {'Reaction outcome loss': 0.7829113536276798, 'Total loss': 0.7829113536276798}
2022-11-22 21:03:26,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:26,312 INFO:     Epoch: 80
2022-11-22 21:03:27,023 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7687303979288448, 'Total loss': 0.7687303979288448} | train loss {'Reaction outcome loss': 0.7798858276504254, 'Total loss': 0.7798858276504254}
2022-11-22 21:03:27,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:27,024 INFO:     Epoch: 81
2022-11-22 21:03:27,757 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7964527065103705, 'Total loss': 0.7964527065103705} | train loss {'Reaction outcome loss': 0.789199779270149, 'Total loss': 0.789199779270149}
2022-11-22 21:03:27,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:27,757 INFO:     Epoch: 82
2022-11-22 21:03:28,486 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8069293485446409, 'Total loss': 0.8069293485446409} | train loss {'Reaction outcome loss': 0.7850849868556266, 'Total loss': 0.7850849868556266}
2022-11-22 21:03:28,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:28,487 INFO:     Epoch: 83
2022-11-22 21:03:29,225 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7872797548770905, 'Total loss': 0.7872797548770905} | train loss {'Reaction outcome loss': 0.794364887451836, 'Total loss': 0.794364887451836}
2022-11-22 21:03:29,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:29,225 INFO:     Epoch: 84
2022-11-22 21:03:29,956 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7686465700918977, 'Total loss': 0.7686465700918977} | train loss {'Reaction outcome loss': 0.7777733581389493, 'Total loss': 0.7777733581389493}
2022-11-22 21:03:29,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:29,956 INFO:     Epoch: 85
2022-11-22 21:03:30,690 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.761155252429572, 'Total loss': 0.761155252429572} | train loss {'Reaction outcome loss': 0.7877546857725753, 'Total loss': 0.7877546857725753}
2022-11-22 21:03:30,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:30,690 INFO:     Epoch: 86
2022-11-22 21:03:31,475 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7827734412117437, 'Total loss': 0.7827734412117437} | train loss {'Reaction outcome loss': 0.7852094645200953, 'Total loss': 0.7852094645200953}
2022-11-22 21:03:31,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:31,475 INFO:     Epoch: 87
2022-11-22 21:03:32,257 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7959489409219135, 'Total loss': 0.7959489409219135} | train loss {'Reaction outcome loss': 0.7769027360779072, 'Total loss': 0.7769027360779072}
2022-11-22 21:03:32,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:32,257 INFO:     Epoch: 88
2022-11-22 21:03:33,039 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8016532774675976, 'Total loss': 0.8016532774675976} | train loss {'Reaction outcome loss': 0.7842984968110135, 'Total loss': 0.7842984968110135}
2022-11-22 21:03:33,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:33,039 INFO:     Epoch: 89
2022-11-22 21:03:33,827 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7895499630407854, 'Total loss': 0.7895499630407854} | train loss {'Reaction outcome loss': 0.780736955191925, 'Total loss': 0.780736955191925}
2022-11-22 21:03:33,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:33,827 INFO:     Epoch: 90
2022-11-22 21:03:34,554 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7639670514247634, 'Total loss': 0.7639670514247634} | train loss {'Reaction outcome loss': 0.7788524486818295, 'Total loss': 0.7788524486818295}
2022-11-22 21:03:34,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:34,555 INFO:     Epoch: 91
2022-11-22 21:03:35,300 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7527581568468701, 'Total loss': 0.7527581568468701} | train loss {'Reaction outcome loss': 0.7743928520544338, 'Total loss': 0.7743928520544338}
2022-11-22 21:03:35,300 INFO:     Found new best model at epoch 91
2022-11-22 21:03:35,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:35,301 INFO:     Epoch: 92
2022-11-22 21:03:36,035 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7744095772504807, 'Total loss': 0.7744095772504807} | train loss {'Reaction outcome loss': 0.7741816817266256, 'Total loss': 0.7741816817266256}
2022-11-22 21:03:36,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:36,035 INFO:     Epoch: 93
2022-11-22 21:03:36,810 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7928235016085885, 'Total loss': 0.7928235016085885} | train loss {'Reaction outcome loss': 0.7796243541395134, 'Total loss': 0.7796243541395134}
2022-11-22 21:03:36,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:36,812 INFO:     Epoch: 94
2022-11-22 21:03:37,574 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7652092603119937, 'Total loss': 0.7652092603119937} | train loss {'Reaction outcome loss': 0.7799805197638539, 'Total loss': 0.7799805197638539}
2022-11-22 21:03:37,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:37,574 INFO:     Epoch: 95
2022-11-22 21:03:38,288 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7994770285758105, 'Total loss': 0.7994770285758105} | train loss {'Reaction outcome loss': 0.7766395637139618, 'Total loss': 0.7766395637139618}
2022-11-22 21:03:38,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:38,288 INFO:     Epoch: 96
2022-11-22 21:03:39,030 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7781296846541491, 'Total loss': 0.7781296846541491} | train loss {'Reaction outcome loss': 0.7703870824474072, 'Total loss': 0.7703870824474072}
2022-11-22 21:03:39,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:39,030 INFO:     Epoch: 97
2022-11-22 21:03:39,754 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7494523254307833, 'Total loss': 0.7494523254307833} | train loss {'Reaction outcome loss': 0.7674974797949617, 'Total loss': 0.7674974797949617}
2022-11-22 21:03:39,754 INFO:     Found new best model at epoch 97
2022-11-22 21:03:39,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:39,755 INFO:     Epoch: 98
2022-11-22 21:03:40,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7441559576175429, 'Total loss': 0.7441559576175429} | train loss {'Reaction outcome loss': 0.773076963448814, 'Total loss': 0.773076963448814}
2022-11-22 21:03:40,481 INFO:     Found new best model at epoch 98
2022-11-22 21:03:40,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:40,481 INFO:     Epoch: 99
2022-11-22 21:03:41,251 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.77701796726747, 'Total loss': 0.77701796726747} | train loss {'Reaction outcome loss': 0.7693867922217589, 'Total loss': 0.7693867922217589}
2022-11-22 21:03:41,252 INFO:     Best model found after epoch 99 of 100.
2022-11-22 21:03:41,252 INFO:   Done with stage: TRAINING
2022-11-22 21:03:41,252 INFO:   Starting stage: EVALUATION
2022-11-22 21:03:41,371 INFO:   Done with stage: EVALUATION
2022-11-22 21:03:41,371 INFO:   Leaving out SEQ value Fold_2
2022-11-22 21:03:41,384 INFO:   examples: 20,544| examples in train: 15,422 | examples in val: 2,722| examples in test: 2,400
2022-11-22 21:03:41,384 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:03:42,042 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:03:42,042 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:03:42,110 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:03:42,110 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:03:42,110 INFO:     No hyperparam tuning for this model
2022-11-22 21:03:42,110 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:03:42,110 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:03:42,111 INFO:     None feature selector for col prot
2022-11-22 21:03:42,111 INFO:     None feature selector for col prot
2022-11-22 21:03:42,111 INFO:     None feature selector for col prot
2022-11-22 21:03:42,112 INFO:     None feature selector for col chem
2022-11-22 21:03:42,112 INFO:     None feature selector for col chem
2022-11-22 21:03:42,112 INFO:     None feature selector for col chem
2022-11-22 21:03:42,112 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:03:42,112 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:03:42,113 INFO:     Number of params in model 126091
2022-11-22 21:03:42,117 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:03:42,117 INFO:   Starting stage: TRAINING
2022-11-22 21:03:42,164 INFO:     Val loss before train {'Reaction outcome loss': 1.029046053110167, 'Total loss': 1.029046053110167}
2022-11-22 21:03:42,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:42,165 INFO:     Epoch: 0
2022-11-22 21:03:42,906 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8196095623249231, 'Total loss': 0.8196095623249231} | train loss {'Reaction outcome loss': 0.8710063432509474, 'Total loss': 0.8710063432509474}
2022-11-22 21:03:42,907 INFO:     Found new best model at epoch 0
2022-11-22 21:03:42,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:42,908 INFO:     Epoch: 1
2022-11-22 21:03:43,654 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8284136285615522, 'Total loss': 0.8284136285615522} | train loss {'Reaction outcome loss': 0.8310352792631046, 'Total loss': 0.8310352792631046}
2022-11-22 21:03:43,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:43,654 INFO:     Epoch: 2
2022-11-22 21:03:44,371 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8157044614470282, 'Total loss': 0.8157044614470282} | train loss {'Reaction outcome loss': 0.8207268257358756, 'Total loss': 0.8207268257358756}
2022-11-22 21:03:44,371 INFO:     Found new best model at epoch 2
2022-11-22 21:03:44,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:44,372 INFO:     Epoch: 3
2022-11-22 21:03:45,130 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.799288623554762, 'Total loss': 0.799288623554762} | train loss {'Reaction outcome loss': 0.8081315967304578, 'Total loss': 0.8081315967304578}
2022-11-22 21:03:45,130 INFO:     Found new best model at epoch 3
2022-11-22 21:03:45,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:45,131 INFO:     Epoch: 4
2022-11-22 21:03:45,878 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.799851810516313, 'Total loss': 0.799851810516313} | train loss {'Reaction outcome loss': 0.8133745716567851, 'Total loss': 0.8133745716567851}
2022-11-22 21:03:45,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:45,879 INFO:     Epoch: 5
2022-11-22 21:03:46,616 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7907640850821207, 'Total loss': 0.7907640850821207} | train loss {'Reaction outcome loss': 0.8019656468476497, 'Total loss': 0.8019656468476497}
2022-11-22 21:03:46,616 INFO:     Found new best model at epoch 5
2022-11-22 21:03:46,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:46,617 INFO:     Epoch: 6
2022-11-22 21:03:47,322 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7983364490575569, 'Total loss': 0.7983364490575569} | train loss {'Reaction outcome loss': 0.8004957684837436, 'Total loss': 0.8004957684837436}
2022-11-22 21:03:47,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:47,323 INFO:     Epoch: 7
2022-11-22 21:03:48,049 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7819178852924081, 'Total loss': 0.7819178852924081} | train loss {'Reaction outcome loss': 0.7978268328791337, 'Total loss': 0.7978268328791337}
2022-11-22 21:03:48,049 INFO:     Found new best model at epoch 7
2022-11-22 21:03:48,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:48,050 INFO:     Epoch: 8
2022-11-22 21:03:48,829 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7884133936360825, 'Total loss': 0.7884133936360825} | train loss {'Reaction outcome loss': 0.792128206165005, 'Total loss': 0.792128206165005}
2022-11-22 21:03:48,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:48,830 INFO:     Epoch: 9
2022-11-22 21:03:49,592 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8084368560203287, 'Total loss': 0.8084368560203287} | train loss {'Reaction outcome loss': 0.7976159969058769, 'Total loss': 0.7976159969058769}
2022-11-22 21:03:49,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:49,593 INFO:     Epoch: 10
2022-11-22 21:03:50,308 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7822746682998746, 'Total loss': 0.7822746682998746} | train loss {'Reaction outcome loss': 0.794569694525968, 'Total loss': 0.794569694525968}
2022-11-22 21:03:50,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:50,309 INFO:     Epoch: 11
2022-11-22 21:03:51,026 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.788553596235985, 'Total loss': 0.788553596235985} | train loss {'Reaction outcome loss': 0.7925069734021342, 'Total loss': 0.7925069734021342}
2022-11-22 21:03:51,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:51,027 INFO:     Epoch: 12
2022-11-22 21:03:51,759 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7880730102228564, 'Total loss': 0.7880730102228564} | train loss {'Reaction outcome loss': 0.7867022017596669, 'Total loss': 0.7867022017596669}
2022-11-22 21:03:51,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:51,759 INFO:     Epoch: 13
2022-11-22 21:03:52,503 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7903304100036621, 'Total loss': 0.7903304100036621} | train loss {'Reaction outcome loss': 0.7927110725665982, 'Total loss': 0.7927110725665982}
2022-11-22 21:03:52,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:52,504 INFO:     Epoch: 14
2022-11-22 21:03:53,220 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8058740150096805, 'Total loss': 0.8058740150096805} | train loss {'Reaction outcome loss': 0.7814295226360257, 'Total loss': 0.7814295226360257}
2022-11-22 21:03:53,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:53,220 INFO:     Epoch: 15
2022-11-22 21:03:53,970 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7782338809135348, 'Total loss': 0.7782338809135348} | train loss {'Reaction outcome loss': 0.7877098696607772, 'Total loss': 0.7877098696607772}
2022-11-22 21:03:53,970 INFO:     Found new best model at epoch 15
2022-11-22 21:03:53,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:53,971 INFO:     Epoch: 16
2022-11-22 21:03:54,694 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7860007133594779, 'Total loss': 0.7860007133594779} | train loss {'Reaction outcome loss': 0.7879803335270941, 'Total loss': 0.7879803335270941}
2022-11-22 21:03:54,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:54,694 INFO:     Epoch: 17
2022-11-22 21:03:55,419 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7778077569118765, 'Total loss': 0.7778077569118765} | train loss {'Reaction outcome loss': 0.7903937873009329, 'Total loss': 0.7903937873009329}
2022-11-22 21:03:55,419 INFO:     Found new best model at epoch 17
2022-11-22 21:03:55,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:55,420 INFO:     Epoch: 18
2022-11-22 21:03:56,169 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7825682440469431, 'Total loss': 0.7825682440469431} | train loss {'Reaction outcome loss': 0.7814600179551549, 'Total loss': 0.7814600179551549}
2022-11-22 21:03:56,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:56,169 INFO:     Epoch: 19
2022-11-22 21:03:56,842 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7918596766715826, 'Total loss': 0.7918596766715826} | train loss {'Reaction outcome loss': 0.7837813292548864, 'Total loss': 0.7837813292548864}
2022-11-22 21:03:56,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:56,842 INFO:     Epoch: 20
2022-11-22 21:03:57,589 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7875700114771377, 'Total loss': 0.7875700114771377} | train loss {'Reaction outcome loss': 0.786018437988036, 'Total loss': 0.786018437988036}
2022-11-22 21:03:57,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:57,589 INFO:     Epoch: 21
2022-11-22 21:03:58,358 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8013138840364855, 'Total loss': 0.8013138840364855} | train loss {'Reaction outcome loss': 0.7877180923812123, 'Total loss': 0.7877180923812123}
2022-11-22 21:03:58,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:58,358 INFO:     Epoch: 22
2022-11-22 21:03:59,043 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7825881159582804, 'Total loss': 0.7825881159582804} | train loss {'Reaction outcome loss': 0.7799769842773058, 'Total loss': 0.7799769842773058}
2022-11-22 21:03:59,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:59,043 INFO:     Epoch: 23
2022-11-22 21:03:59,784 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8352599435074385, 'Total loss': 0.8352599435074385} | train loss {'Reaction outcome loss': 0.7837777263890658, 'Total loss': 0.7837777263890658}
2022-11-22 21:03:59,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:03:59,784 INFO:     Epoch: 24
2022-11-22 21:04:00,499 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7994883240655412, 'Total loss': 0.7994883240655412} | train loss {'Reaction outcome loss': 0.7891757642827093, 'Total loss': 0.7891757642827093}
2022-11-22 21:04:00,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:00,499 INFO:     Epoch: 25
2022-11-22 21:04:01,201 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7690906566242839, 'Total loss': 0.7690906566242839} | train loss {'Reaction outcome loss': 0.7847559544802701, 'Total loss': 0.7847559544802701}
2022-11-22 21:04:01,201 INFO:     Found new best model at epoch 25
2022-11-22 21:04:01,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:01,202 INFO:     Epoch: 26
2022-11-22 21:04:01,943 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7749074607394463, 'Total loss': 0.7749074607394463} | train loss {'Reaction outcome loss': 0.7854081321801387, 'Total loss': 0.7854081321801387}
2022-11-22 21:04:01,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:01,944 INFO:     Epoch: 27
2022-11-22 21:04:02,696 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7690149407054103, 'Total loss': 0.7690149407054103} | train loss {'Reaction outcome loss': 0.7826985523908465, 'Total loss': 0.7826985523908465}
2022-11-22 21:04:02,696 INFO:     Found new best model at epoch 27
2022-11-22 21:04:02,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:02,697 INFO:     Epoch: 28
2022-11-22 21:04:03,435 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.787078627320223, 'Total loss': 0.787078627320223} | train loss {'Reaction outcome loss': 0.7875781007327479, 'Total loss': 0.7875781007327479}
2022-11-22 21:04:03,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:03,435 INFO:     Epoch: 29
2022-11-22 21:04:04,135 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7793731855791669, 'Total loss': 0.7793731855791669} | train loss {'Reaction outcome loss': 0.7850482175088027, 'Total loss': 0.7850482175088027}
2022-11-22 21:04:04,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:04,135 INFO:     Epoch: 30
2022-11-22 21:04:04,869 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.77793686819631, 'Total loss': 0.77793686819631} | train loss {'Reaction outcome loss': 0.7778967290003764, 'Total loss': 0.7778967290003764}
2022-11-22 21:04:04,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:04,869 INFO:     Epoch: 31
2022-11-22 21:04:05,587 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.780772773332374, 'Total loss': 0.780772773332374} | train loss {'Reaction outcome loss': 0.7826398186911191, 'Total loss': 0.7826398186911191}
2022-11-22 21:04:05,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:05,587 INFO:     Epoch: 32
2022-11-22 21:04:06,318 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7645497800305833, 'Total loss': 0.7645497800305833} | train loss {'Reaction outcome loss': 0.7820747303022884, 'Total loss': 0.7820747303022884}
2022-11-22 21:04:06,318 INFO:     Found new best model at epoch 32
2022-11-22 21:04:06,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:06,319 INFO:     Epoch: 33
2022-11-22 21:04:07,058 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7970534119495126, 'Total loss': 0.7970534119495126} | train loss {'Reaction outcome loss': 0.7719428044631768, 'Total loss': 0.7719428044631768}
2022-11-22 21:04:07,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:07,058 INFO:     Epoch: 34
2022-11-22 21:04:07,828 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7606102138064629, 'Total loss': 0.7606102138064629} | train loss {'Reaction outcome loss': 0.7795102804651893, 'Total loss': 0.7795102804651893}
2022-11-22 21:04:07,829 INFO:     Found new best model at epoch 34
2022-11-22 21:04:07,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:07,830 INFO:     Epoch: 35
2022-11-22 21:04:08,553 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8177999029325884, 'Total loss': 0.8177999029325884} | train loss {'Reaction outcome loss': 0.7714734888670356, 'Total loss': 0.7714734888670356}
2022-11-22 21:04:08,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:08,554 INFO:     Epoch: 36
2022-11-22 21:04:09,283 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7791144785492919, 'Total loss': 0.7791144785492919} | train loss {'Reaction outcome loss': 0.7742858888944649, 'Total loss': 0.7742858888944649}
2022-11-22 21:04:09,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:09,283 INFO:     Epoch: 37
2022-11-22 21:04:10,049 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8157476734283359, 'Total loss': 0.8157476734283359} | train loss {'Reaction outcome loss': 0.763964080031482, 'Total loss': 0.763964080031482}
2022-11-22 21:04:10,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:10,050 INFO:     Epoch: 38
2022-11-22 21:04:10,761 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7645418789497641, 'Total loss': 0.7645418789497641} | train loss {'Reaction outcome loss': 0.7716909948720971, 'Total loss': 0.7716909948720971}
2022-11-22 21:04:10,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:10,761 INFO:     Epoch: 39
2022-11-22 21:04:11,488 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7511840074561363, 'Total loss': 0.7511840074561363} | train loss {'Reaction outcome loss': 0.7661085398365353, 'Total loss': 0.7661085398365353}
2022-11-22 21:04:11,488 INFO:     Found new best model at epoch 39
2022-11-22 21:04:11,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:11,489 INFO:     Epoch: 40
2022-11-22 21:04:12,181 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7604018664637278, 'Total loss': 0.7604018664637278} | train loss {'Reaction outcome loss': 0.7671753809907129, 'Total loss': 0.7671753809907129}
2022-11-22 21:04:12,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:12,181 INFO:     Epoch: 41
2022-11-22 21:04:12,878 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7413346864456354, 'Total loss': 0.7413346864456354} | train loss {'Reaction outcome loss': 0.7650978217728405, 'Total loss': 0.7650978217728405}
2022-11-22 21:04:12,878 INFO:     Found new best model at epoch 41
2022-11-22 21:04:12,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:12,879 INFO:     Epoch: 42
2022-11-22 21:04:13,622 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7433473682680796, 'Total loss': 0.7433473682680796} | train loss {'Reaction outcome loss': 0.7624160386467376, 'Total loss': 0.7624160386467376}
2022-11-22 21:04:13,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:13,622 INFO:     Epoch: 43
2022-11-22 21:04:14,373 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7799741348554922, 'Total loss': 0.7799741348554922} | train loss {'Reaction outcome loss': 0.7577776085291661, 'Total loss': 0.7577776085291661}
2022-11-22 21:04:14,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:14,374 INFO:     Epoch: 44
2022-11-22 21:04:15,083 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7501743733882904, 'Total loss': 0.7501743733882904} | train loss {'Reaction outcome loss': 0.7607660371485587, 'Total loss': 0.7607660371485587}
2022-11-22 21:04:15,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:15,083 INFO:     Epoch: 45
2022-11-22 21:04:15,779 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7505881723969482, 'Total loss': 0.7505881723969482} | train loss {'Reaction outcome loss': 0.7605265795689895, 'Total loss': 0.7605265795689895}
2022-11-22 21:04:15,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:15,779 INFO:     Epoch: 46
2022-11-22 21:04:16,537 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7440941340701525, 'Total loss': 0.7440941340701525} | train loss {'Reaction outcome loss': 0.7549830567539975, 'Total loss': 0.7549830567539975}
2022-11-22 21:04:16,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:16,537 INFO:     Epoch: 47
2022-11-22 21:04:17,285 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7519899793835574, 'Total loss': 0.7519899793835574} | train loss {'Reaction outcome loss': 0.7502940609989325, 'Total loss': 0.7502940609989325}
2022-11-22 21:04:17,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:17,285 INFO:     Epoch: 48
2022-11-22 21:04:17,990 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7383579265239627, 'Total loss': 0.7383579265239627} | train loss {'Reaction outcome loss': 0.7550972806467555, 'Total loss': 0.7550972806467555}
2022-11-22 21:04:17,990 INFO:     Found new best model at epoch 48
2022-11-22 21:04:17,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:17,991 INFO:     Epoch: 49
2022-11-22 21:04:18,701 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7613968225412591, 'Total loss': 0.7613968225412591} | train loss {'Reaction outcome loss': 0.7435698056616724, 'Total loss': 0.7435698056616724}
2022-11-22 21:04:18,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:18,702 INFO:     Epoch: 50
2022-11-22 21:04:19,475 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.73164158435755, 'Total loss': 0.73164158435755} | train loss {'Reaction outcome loss': 0.7423375529619668, 'Total loss': 0.7423375529619668}
2022-11-22 21:04:19,475 INFO:     Found new best model at epoch 50
2022-11-22 21:04:19,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:19,476 INFO:     Epoch: 51
2022-11-22 21:04:20,201 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7348188432150109, 'Total loss': 0.7348188432150109} | train loss {'Reaction outcome loss': 0.7440162199661445, 'Total loss': 0.7440162199661445}
2022-11-22 21:04:20,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:20,201 INFO:     Epoch: 52
2022-11-22 21:04:20,937 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.74917869235194, 'Total loss': 0.74917869235194} | train loss {'Reaction outcome loss': 0.7416773160216225, 'Total loss': 0.7416773160216225}
2022-11-22 21:04:20,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:20,938 INFO:     Epoch: 53
2022-11-22 21:04:21,690 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7187769981317742, 'Total loss': 0.7187769981317742} | train loss {'Reaction outcome loss': 0.7373678336746959, 'Total loss': 0.7373678336746959}
2022-11-22 21:04:21,690 INFO:     Found new best model at epoch 53
2022-11-22 21:04:21,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:21,691 INFO:     Epoch: 54
2022-11-22 21:04:22,464 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7213438818621081, 'Total loss': 0.7213438818621081} | train loss {'Reaction outcome loss': 0.7396135703038378, 'Total loss': 0.7396135703038378}
2022-11-22 21:04:22,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:22,464 INFO:     Epoch: 55
2022-11-22 21:04:23,196 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7103750400764998, 'Total loss': 0.7103750400764998} | train loss {'Reaction outcome loss': 0.7293013887039359, 'Total loss': 0.7293013887039359}
2022-11-22 21:04:23,196 INFO:     Found new best model at epoch 55
2022-11-22 21:04:23,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:23,197 INFO:     Epoch: 56
2022-11-22 21:04:23,923 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7255638622960379, 'Total loss': 0.7255638622960379} | train loss {'Reaction outcome loss': 0.732648437448557, 'Total loss': 0.732648437448557}
2022-11-22 21:04:23,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:23,923 INFO:     Epoch: 57
2022-11-22 21:04:24,680 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7195862122746401, 'Total loss': 0.7195862122746401} | train loss {'Reaction outcome loss': 0.723036737981179, 'Total loss': 0.723036737981179}
2022-11-22 21:04:24,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:24,680 INFO:     Epoch: 58
2022-11-22 21:04:25,385 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7134181947209114, 'Total loss': 0.7134181947209114} | train loss {'Reaction outcome loss': 0.721323682064832, 'Total loss': 0.721323682064832}
2022-11-22 21:04:25,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:25,385 INFO:     Epoch: 59
2022-11-22 21:04:26,101 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7397805646408436, 'Total loss': 0.7397805646408436} | train loss {'Reaction outcome loss': 0.7217359605913835, 'Total loss': 0.7217359605913835}
2022-11-22 21:04:26,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:26,101 INFO:     Epoch: 60
2022-11-22 21:04:26,851 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7086091450480527, 'Total loss': 0.7086091450480527} | train loss {'Reaction outcome loss': 0.7242961915449483, 'Total loss': 0.7242961915449483}
2022-11-22 21:04:26,852 INFO:     Found new best model at epoch 60
2022-11-22 21:04:26,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:26,853 INFO:     Epoch: 61
2022-11-22 21:04:27,602 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.6906906463379083, 'Total loss': 0.6906906463379083} | train loss {'Reaction outcome loss': 0.7206363400977677, 'Total loss': 0.7206363400977677}
2022-11-22 21:04:27,602 INFO:     Found new best model at epoch 61
2022-11-22 21:04:27,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:27,603 INFO:     Epoch: 62
2022-11-22 21:04:28,345 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.6909912505815196, 'Total loss': 0.6909912505815196} | train loss {'Reaction outcome loss': 0.7117026764822204, 'Total loss': 0.7117026764822204}
2022-11-22 21:04:28,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:28,345 INFO:     Epoch: 63
2022-11-22 21:04:29,085 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.6753994469032731, 'Total loss': 0.6753994469032731} | train loss {'Reaction outcome loss': 0.7203578493283498, 'Total loss': 0.7203578493283498}
2022-11-22 21:04:29,086 INFO:     Found new best model at epoch 63
2022-11-22 21:04:29,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:29,086 INFO:     Epoch: 64
2022-11-22 21:04:29,834 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7557364639847778, 'Total loss': 0.7557364639847778} | train loss {'Reaction outcome loss': 0.7157909084899792, 'Total loss': 0.7157909084899792}
2022-11-22 21:04:29,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:29,834 INFO:     Epoch: 65
2022-11-22 21:04:30,613 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7467734051305194, 'Total loss': 0.7467734051305194} | train loss {'Reaction outcome loss': 0.7121665258872558, 'Total loss': 0.7121665258872558}
2022-11-22 21:04:30,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:30,613 INFO:     Epoch: 66
2022-11-22 21:04:31,345 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.6965087437352468, 'Total loss': 0.6965087437352468} | train loss {'Reaction outcome loss': 0.7151736682628695, 'Total loss': 0.7151736682628695}
2022-11-22 21:04:31,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:31,345 INFO:     Epoch: 67
2022-11-22 21:04:32,131 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7118463183558265, 'Total loss': 0.7118463183558265} | train loss {'Reaction outcome loss': 0.7110485041289903, 'Total loss': 0.7110485041289903}
2022-11-22 21:04:32,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:32,132 INFO:     Epoch: 68
2022-11-22 21:04:32,865 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.6901908835699392, 'Total loss': 0.6901908835699392} | train loss {'Reaction outcome loss': 0.7144657295521859, 'Total loss': 0.7144657295521859}
2022-11-22 21:04:32,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:32,865 INFO:     Epoch: 69
2022-11-22 21:04:33,614 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6932956437731899, 'Total loss': 0.6932956437731899} | train loss {'Reaction outcome loss': 0.7084722109602695, 'Total loss': 0.7084722109602695}
2022-11-22 21:04:33,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:33,614 INFO:     Epoch: 70
2022-11-22 21:04:34,312 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7299471254958663, 'Total loss': 0.7299471254958663} | train loss {'Reaction outcome loss': 0.7094460795034512, 'Total loss': 0.7094460795034512}
2022-11-22 21:04:34,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:34,312 INFO:     Epoch: 71
2022-11-22 21:04:35,030 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.685531965521879, 'Total loss': 0.685531965521879} | train loss {'Reaction outcome loss': 0.7033729936572032, 'Total loss': 0.7033729936572032}
2022-11-22 21:04:35,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:35,030 INFO:     Epoch: 72
2022-11-22 21:04:35,748 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6935711357482645, 'Total loss': 0.6935711357482645} | train loss {'Reaction outcome loss': 0.7090543841177992, 'Total loss': 0.7090543841177992}
2022-11-22 21:04:35,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:35,748 INFO:     Epoch: 73
2022-11-22 21:04:36,473 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7053847763427469, 'Total loss': 0.7053847763427469} | train loss {'Reaction outcome loss': 0.7012093382504966, 'Total loss': 0.7012093382504966}
2022-11-22 21:04:36,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:36,474 INFO:     Epoch: 74
2022-11-22 21:04:37,199 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.6992851329404254, 'Total loss': 0.6992851329404254} | train loss {'Reaction outcome loss': 0.7047417916326602, 'Total loss': 0.7047417916326602}
2022-11-22 21:04:37,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:37,199 INFO:     Epoch: 75
2022-11-22 21:04:37,903 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.6809883096883463, 'Total loss': 0.6809883096883463} | train loss {'Reaction outcome loss': 0.7069499253979362, 'Total loss': 0.7069499253979362}
2022-11-22 21:04:37,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:37,903 INFO:     Epoch: 76
2022-11-22 21:04:38,621 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.6821636107078818, 'Total loss': 0.6821636107078818} | train loss {'Reaction outcome loss': 0.7038299401766037, 'Total loss': 0.7038299401766037}
2022-11-22 21:04:38,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:38,623 INFO:     Epoch: 77
2022-11-22 21:04:39,323 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7433040128197781, 'Total loss': 0.7433040128197781} | train loss {'Reaction outcome loss': 0.7082362469301184, 'Total loss': 0.7082362469301184}
2022-11-22 21:04:39,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:39,323 INFO:     Epoch: 78
2022-11-22 21:04:40,058 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6899368049100388, 'Total loss': 0.6899368049100388} | train loss {'Reaction outcome loss': 0.7017669033460102, 'Total loss': 0.7017669033460102}
2022-11-22 21:04:40,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:40,059 INFO:     Epoch: 79
2022-11-22 21:04:40,786 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7159314675386562, 'Total loss': 0.7159314675386562} | train loss {'Reaction outcome loss': 0.6987202644842789, 'Total loss': 0.6987202644842789}
2022-11-22 21:04:40,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:40,786 INFO:     Epoch: 80
2022-11-22 21:04:41,494 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7165836615617885, 'Total loss': 0.7165836615617885} | train loss {'Reaction outcome loss': 0.6934104428251749, 'Total loss': 0.6934104428251749}
2022-11-22 21:04:41,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:41,494 INFO:     Epoch: 81
2022-11-22 21:04:42,210 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6973833725895993, 'Total loss': 0.6973833725895993} | train loss {'Reaction outcome loss': 0.7023420750600173, 'Total loss': 0.7023420750600173}
2022-11-22 21:04:42,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:42,211 INFO:     Epoch: 82
2022-11-22 21:04:42,920 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.6878916136054105, 'Total loss': 0.6878916136054105} | train loss {'Reaction outcome loss': 0.7036899707253048, 'Total loss': 0.7036899707253048}
2022-11-22 21:04:42,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:42,920 INFO:     Epoch: 83
2022-11-22 21:04:43,641 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6994743319444878, 'Total loss': 0.6994743319444878} | train loss {'Reaction outcome loss': 0.6981782095189906, 'Total loss': 0.6981782095189906}
2022-11-22 21:04:43,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:43,641 INFO:     Epoch: 84
2022-11-22 21:04:44,319 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6826971000017121, 'Total loss': 0.6826971000017121} | train loss {'Reaction outcome loss': 0.6986487788530801, 'Total loss': 0.6986487788530801}
2022-11-22 21:04:44,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:44,319 INFO:     Epoch: 85
2022-11-22 21:04:45,006 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6922570993733961, 'Total loss': 0.6922570993733961} | train loss {'Reaction outcome loss': 0.7057388246801384, 'Total loss': 0.7057388246801384}
2022-11-22 21:04:45,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:45,007 INFO:     Epoch: 86
2022-11-22 21:04:45,701 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6995730670385583, 'Total loss': 0.6995730670385583} | train loss {'Reaction outcome loss': 0.694035208200518, 'Total loss': 0.694035208200518}
2022-11-22 21:04:45,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:45,702 INFO:     Epoch: 87
2022-11-22 21:04:46,413 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.688361608011778, 'Total loss': 0.688361608011778} | train loss {'Reaction outcome loss': 0.7011202100154276, 'Total loss': 0.7011202100154276}
2022-11-22 21:04:46,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:46,413 INFO:     Epoch: 88
2022-11-22 21:04:47,125 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6983750926893811, 'Total loss': 0.6983750926893811} | train loss {'Reaction outcome loss': 0.6972477272214731, 'Total loss': 0.6972477272214731}
2022-11-22 21:04:47,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:47,125 INFO:     Epoch: 89
2022-11-22 21:04:47,864 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7020856585613516, 'Total loss': 0.7020856585613516} | train loss {'Reaction outcome loss': 0.6904591764651888, 'Total loss': 0.6904591764651888}
2022-11-22 21:04:47,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:47,865 INFO:     Epoch: 90
2022-11-22 21:04:48,581 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7197182885436124, 'Total loss': 0.7197182885436124} | train loss {'Reaction outcome loss': 0.6983183624833451, 'Total loss': 0.6983183624833451}
2022-11-22 21:04:48,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:48,581 INFO:     Epoch: 91
2022-11-22 21:04:49,299 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.6980899392172347, 'Total loss': 0.6980899392172347} | train loss {'Reaction outcome loss': 0.6999405235423092, 'Total loss': 0.6999405235423092}
2022-11-22 21:04:49,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:49,299 INFO:     Epoch: 92
2022-11-22 21:04:50,036 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6854748919952748, 'Total loss': 0.6854748919952748} | train loss {'Reaction outcome loss': 0.6992103713429321, 'Total loss': 0.6992103713429321}
2022-11-22 21:04:50,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:50,036 INFO:     Epoch: 93
2022-11-22 21:04:50,773 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6900616322838983, 'Total loss': 0.6900616322838983} | train loss {'Reaction outcome loss': 0.6978998801272934, 'Total loss': 0.6978998801272934}
2022-11-22 21:04:50,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:50,773 INFO:     Epoch: 94
2022-11-22 21:04:51,548 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6937877494235372, 'Total loss': 0.6937877494235372} | train loss {'Reaction outcome loss': 0.6906631287202796, 'Total loss': 0.6906631287202796}
2022-11-22 21:04:51,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:51,549 INFO:     Epoch: 95
2022-11-22 21:04:52,244 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6850832638352417, 'Total loss': 0.6850832638352417} | train loss {'Reaction outcome loss': 0.695672388887999, 'Total loss': 0.695672388887999}
2022-11-22 21:04:52,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:52,244 INFO:     Epoch: 96
2022-11-22 21:04:52,946 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6993989182073016, 'Total loss': 0.6993989182073016} | train loss {'Reaction outcome loss': 0.6920246103492516, 'Total loss': 0.6920246103492516}
2022-11-22 21:04:52,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:52,947 INFO:     Epoch: 97
2022-11-22 21:04:53,677 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6924371913421986, 'Total loss': 0.6924371913421986} | train loss {'Reaction outcome loss': 0.689479061058448, 'Total loss': 0.689479061058448}
2022-11-22 21:04:53,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:53,677 INFO:     Epoch: 98
2022-11-22 21:04:54,383 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6648290843464607, 'Total loss': 0.6648290843464607} | train loss {'Reaction outcome loss': 0.6958306623445012, 'Total loss': 0.6958306623445012}
2022-11-22 21:04:54,383 INFO:     Found new best model at epoch 98
2022-11-22 21:04:54,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:54,384 INFO:     Epoch: 99
2022-11-22 21:04:55,079 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7240492611430412, 'Total loss': 0.7240492611430412} | train loss {'Reaction outcome loss': 0.7005175366935888, 'Total loss': 0.7005175366935888}
2022-11-22 21:04:55,079 INFO:     Best model found after epoch 99 of 100.
2022-11-22 21:04:55,079 INFO:   Done with stage: TRAINING
2022-11-22 21:04:55,079 INFO:   Starting stage: EVALUATION
2022-11-22 21:04:55,219 INFO:   Done with stage: EVALUATION
2022-11-22 21:04:55,219 INFO:   Leaving out SEQ value Fold_3
2022-11-22 21:04:55,233 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-22 21:04:55,233 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:04:55,901 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:04:55,901 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:04:55,970 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:04:55,970 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:04:55,970 INFO:     No hyperparam tuning for this model
2022-11-22 21:04:55,970 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:04:55,970 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:04:55,971 INFO:     None feature selector for col prot
2022-11-22 21:04:55,971 INFO:     None feature selector for col prot
2022-11-22 21:04:55,971 INFO:     None feature selector for col prot
2022-11-22 21:04:55,972 INFO:     None feature selector for col chem
2022-11-22 21:04:55,972 INFO:     None feature selector for col chem
2022-11-22 21:04:55,972 INFO:     None feature selector for col chem
2022-11-22 21:04:55,972 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:04:55,972 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:04:55,974 INFO:     Number of params in model 126091
2022-11-22 21:04:55,977 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:04:55,977 INFO:   Starting stage: TRAINING
2022-11-22 21:04:56,026 INFO:     Val loss before train {'Reaction outcome loss': 1.0044901620510012, 'Total loss': 1.0044901620510012}
2022-11-22 21:04:56,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:56,026 INFO:     Epoch: 0
2022-11-22 21:04:56,763 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8169319615807644, 'Total loss': 0.8169319615807644} | train loss {'Reaction outcome loss': 0.8748341395718152, 'Total loss': 0.8748341395718152}
2022-11-22 21:04:56,763 INFO:     Found new best model at epoch 0
2022-11-22 21:04:56,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:56,763 INFO:     Epoch: 1
2022-11-22 21:04:57,472 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8122718666875085, 'Total loss': 0.8122718666875085} | train loss {'Reaction outcome loss': 0.838302524485549, 'Total loss': 0.838302524485549}
2022-11-22 21:04:57,473 INFO:     Found new best model at epoch 1
2022-11-22 21:04:57,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:57,474 INFO:     Epoch: 2
2022-11-22 21:04:58,224 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.78417370485705, 'Total loss': 0.78417370485705} | train loss {'Reaction outcome loss': 0.8301759981473938, 'Total loss': 0.8301759981473938}
2022-11-22 21:04:58,224 INFO:     Found new best model at epoch 2
2022-11-22 21:04:58,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:58,225 INFO:     Epoch: 3
2022-11-22 21:04:58,955 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8181835995164028, 'Total loss': 0.8181835995164028} | train loss {'Reaction outcome loss': 0.8271847999975329, 'Total loss': 0.8271847999975329}
2022-11-22 21:04:58,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:58,956 INFO:     Epoch: 4
2022-11-22 21:04:59,681 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7764578413131625, 'Total loss': 0.7764578413131625} | train loss {'Reaction outcome loss': 0.8156489306053177, 'Total loss': 0.8156489306053177}
2022-11-22 21:04:59,681 INFO:     Found new best model at epoch 4
2022-11-22 21:04:59,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:04:59,682 INFO:     Epoch: 5
2022-11-22 21:05:00,425 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7942341635393542, 'Total loss': 0.7942341635393542} | train loss {'Reaction outcome loss': 0.8115498731370832, 'Total loss': 0.8115498731370832}
2022-11-22 21:05:00,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:00,425 INFO:     Epoch: 6
2022-11-22 21:05:01,155 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7831536961156268, 'Total loss': 0.7831536961156268} | train loss {'Reaction outcome loss': 0.8087047239551779, 'Total loss': 0.8087047239551779}
2022-11-22 21:05:01,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:01,155 INFO:     Epoch: 7
2022-11-22 21:05:01,880 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8057763673538385, 'Total loss': 0.8057763673538385} | train loss {'Reaction outcome loss': 0.8059968978899424, 'Total loss': 0.8059968978899424}
2022-11-22 21:05:01,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:01,880 INFO:     Epoch: 8
2022-11-22 21:05:02,610 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7723193889440492, 'Total loss': 0.7723193889440492} | train loss {'Reaction outcome loss': 0.8018217659631713, 'Total loss': 0.8018217659631713}
2022-11-22 21:05:02,610 INFO:     Found new best model at epoch 8
2022-11-22 21:05:02,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:02,611 INFO:     Epoch: 9
2022-11-22 21:05:03,368 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7584118094555167, 'Total loss': 0.7584118094555167} | train loss {'Reaction outcome loss': 0.8018197999870191, 'Total loss': 0.8018197999870191}
2022-11-22 21:05:03,368 INFO:     Found new best model at epoch 9
2022-11-22 21:05:03,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:03,369 INFO:     Epoch: 10
2022-11-22 21:05:04,115 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7728408180003943, 'Total loss': 0.7728408180003943} | train loss {'Reaction outcome loss': 0.7954871548248119, 'Total loss': 0.7954871548248119}
2022-11-22 21:05:04,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:04,115 INFO:     Epoch: 11
2022-11-22 21:05:04,837 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7711847050245418, 'Total loss': 0.7711847050245418} | train loss {'Reaction outcome loss': 0.7962046551411269, 'Total loss': 0.7962046551411269}
2022-11-22 21:05:04,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:04,837 INFO:     Epoch: 12
2022-11-22 21:05:05,567 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7746631849643796, 'Total loss': 0.7746631849643796} | train loss {'Reaction outcome loss': 0.7988498995050055, 'Total loss': 0.7988498995050055}
2022-11-22 21:05:05,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:05,567 INFO:     Epoch: 13
2022-11-22 21:05:06,277 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.772734418164852, 'Total loss': 0.772734418164852} | train loss {'Reaction outcome loss': 0.7952969201275559, 'Total loss': 0.7952969201275559}
2022-11-22 21:05:06,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:06,277 INFO:     Epoch: 14
2022-11-22 21:05:07,002 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7524536397568015, 'Total loss': 0.7524536397568015} | train loss {'Reaction outcome loss': 0.791175545483339, 'Total loss': 0.791175545483339}
2022-11-22 21:05:07,003 INFO:     Found new best model at epoch 14
2022-11-22 21:05:07,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:07,003 INFO:     Epoch: 15
2022-11-22 21:05:07,723 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7921897547189579, 'Total loss': 0.7921897547189579} | train loss {'Reaction outcome loss': 0.7931375088261776, 'Total loss': 0.7931375088261776}
2022-11-22 21:05:07,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:07,723 INFO:     Epoch: 16
2022-11-22 21:05:08,486 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.769062104613282, 'Total loss': 0.769062104613282} | train loss {'Reaction outcome loss': 0.792347464160841, 'Total loss': 0.792347464160841}
2022-11-22 21:05:08,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:08,486 INFO:     Epoch: 17
2022-11-22 21:05:09,256 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7709514443264451, 'Total loss': 0.7709514443264451} | train loss {'Reaction outcome loss': 0.7893987406716972, 'Total loss': 0.7893987406716972}
2022-11-22 21:05:09,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:09,256 INFO:     Epoch: 18
2022-11-22 21:05:10,035 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7581091661785924, 'Total loss': 0.7581091661785924} | train loss {'Reaction outcome loss': 0.7923930408280404, 'Total loss': 0.7923930408280404}
2022-11-22 21:05:10,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:10,036 INFO:     Epoch: 19
2022-11-22 21:05:10,798 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7587576155052629, 'Total loss': 0.7587576155052629} | train loss {'Reaction outcome loss': 0.7852624601028004, 'Total loss': 0.7852624601028004}
2022-11-22 21:05:10,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:10,798 INFO:     Epoch: 20
2022-11-22 21:05:11,529 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7662383518939795, 'Total loss': 0.7662383518939795} | train loss {'Reaction outcome loss': 0.7886534961032086, 'Total loss': 0.7886534961032086}
2022-11-22 21:05:11,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:11,530 INFO:     Epoch: 21
2022-11-22 21:05:12,268 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7562216970809671, 'Total loss': 0.7562216970809671} | train loss {'Reaction outcome loss': 0.7922728778641732, 'Total loss': 0.7922728778641732}
2022-11-22 21:05:12,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:12,268 INFO:     Epoch: 22
2022-11-22 21:05:12,989 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7598482508992039, 'Total loss': 0.7598482508992039} | train loss {'Reaction outcome loss': 0.7903942063939376, 'Total loss': 0.7903942063939376}
2022-11-22 21:05:12,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:12,990 INFO:     Epoch: 23
2022-11-22 21:05:13,773 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7616038939287496, 'Total loss': 0.7616038939287496} | train loss {'Reaction outcome loss': 0.7868255673617613, 'Total loss': 0.7868255673617613}
2022-11-22 21:05:13,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:13,773 INFO:     Epoch: 24
2022-11-22 21:05:14,538 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7585030690182087, 'Total loss': 0.7585030690182087} | train loss {'Reaction outcome loss': 0.7944348664557348, 'Total loss': 0.7944348664557348}
2022-11-22 21:05:14,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:14,538 INFO:     Epoch: 25
2022-11-22 21:05:15,268 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7589190214179283, 'Total loss': 0.7589190214179283} | train loss {'Reaction outcome loss': 0.7846032981989813, 'Total loss': 0.7846032981989813}
2022-11-22 21:05:15,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:15,268 INFO:     Epoch: 26
2022-11-22 21:05:16,000 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7512289216352064, 'Total loss': 0.7512289216352064} | train loss {'Reaction outcome loss': 0.7805273126139015, 'Total loss': 0.7805273126139015}
2022-11-22 21:05:16,001 INFO:     Found new best model at epoch 26
2022-11-22 21:05:16,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:16,002 INFO:     Epoch: 27
2022-11-22 21:05:16,746 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.773210849179778, 'Total loss': 0.773210849179778} | train loss {'Reaction outcome loss': 0.7857795561679074, 'Total loss': 0.7857795561679074}
2022-11-22 21:05:16,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:16,747 INFO:     Epoch: 28
2022-11-22 21:05:17,535 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.760902417260547, 'Total loss': 0.760902417260547} | train loss {'Reaction outcome loss': 0.7823683944393377, 'Total loss': 0.7823683944393377}
2022-11-22 21:05:17,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:17,536 INFO:     Epoch: 29
2022-11-22 21:05:18,244 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7782159794208615, 'Total loss': 0.7782159794208615} | train loss {'Reaction outcome loss': 0.7877718100293738, 'Total loss': 0.7877718100293738}
2022-11-22 21:05:18,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:18,244 INFO:     Epoch: 30
2022-11-22 21:05:18,952 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7805645978728006, 'Total loss': 0.7805645978728006} | train loss {'Reaction outcome loss': 0.7862176036492723, 'Total loss': 0.7862176036492723}
2022-11-22 21:05:18,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:18,952 INFO:     Epoch: 31
2022-11-22 21:05:19,696 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.756353827409966, 'Total loss': 0.756353827409966} | train loss {'Reaction outcome loss': 0.7874701315017997, 'Total loss': 0.7874701315017997}
2022-11-22 21:05:19,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:19,696 INFO:     Epoch: 32
2022-11-22 21:05:20,463 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7606333182301632, 'Total loss': 0.7606333182301632} | train loss {'Reaction outcome loss': 0.7813201106962611, 'Total loss': 0.7813201106962611}
2022-11-22 21:05:20,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:20,463 INFO:     Epoch: 33
2022-11-22 21:05:21,174 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7611394871112912, 'Total loss': 0.7611394871112912} | train loss {'Reaction outcome loss': 0.7872620745271933, 'Total loss': 0.7872620745271933}
2022-11-22 21:05:21,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:21,175 INFO:     Epoch: 34
2022-11-22 21:05:21,898 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7671802612238152, 'Total loss': 0.7671802612238152} | train loss {'Reaction outcome loss': 0.7821229389700733, 'Total loss': 0.7821229389700733}
2022-11-22 21:05:21,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:21,898 INFO:     Epoch: 35
2022-11-22 21:05:22,616 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7596192380716634, 'Total loss': 0.7596192380716634} | train loss {'Reaction outcome loss': 0.7851243398961474, 'Total loss': 0.7851243398961474}
2022-11-22 21:05:22,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:22,616 INFO:     Epoch: 36
2022-11-22 21:05:23,316 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.754195383121801, 'Total loss': 0.754195383121801} | train loss {'Reaction outcome loss': 0.7855227516322839, 'Total loss': 0.7855227516322839}
2022-11-22 21:05:23,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:23,316 INFO:     Epoch: 37
2022-11-22 21:05:24,053 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7546843394290569, 'Total loss': 0.7546843394290569} | train loss {'Reaction outcome loss': 0.7792626547275997, 'Total loss': 0.7792626547275997}
2022-11-22 21:05:24,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:24,053 INFO:     Epoch: 38
2022-11-22 21:05:24,746 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7668957897396975, 'Total loss': 0.7668957897396975} | train loss {'Reaction outcome loss': 0.7900708057597036, 'Total loss': 0.7900708057597036}
2022-11-22 21:05:24,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:24,747 INFO:     Epoch: 39
2022-11-22 21:05:25,422 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7510543243829594, 'Total loss': 0.7510543243829594} | train loss {'Reaction outcome loss': 0.7823877440857105, 'Total loss': 0.7823877440857105}
2022-11-22 21:05:25,422 INFO:     Found new best model at epoch 39
2022-11-22 21:05:25,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:25,423 INFO:     Epoch: 40
2022-11-22 21:05:26,202 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7549647661142571, 'Total loss': 0.7549647661142571} | train loss {'Reaction outcome loss': 0.785323754319402, 'Total loss': 0.785323754319402}
2022-11-22 21:05:26,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:26,203 INFO:     Epoch: 41
2022-11-22 21:05:26,897 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7508989094301711, 'Total loss': 0.7508989094301711} | train loss {'Reaction outcome loss': 0.7821086729403401, 'Total loss': 0.7821086729403401}
2022-11-22 21:05:26,898 INFO:     Found new best model at epoch 41
2022-11-22 21:05:26,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:26,899 INFO:     Epoch: 42
2022-11-22 21:05:27,603 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7717573829861575, 'Total loss': 0.7717573829861575} | train loss {'Reaction outcome loss': 0.7887627664403837, 'Total loss': 0.7887627664403837}
2022-11-22 21:05:27,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:27,603 INFO:     Epoch: 43
2022-11-22 21:05:28,304 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7508998735006466, 'Total loss': 0.7508998735006466} | train loss {'Reaction outcome loss': 0.7820737879784381, 'Total loss': 0.7820737879784381}
2022-11-22 21:05:28,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:28,304 INFO:     Epoch: 44
2022-11-22 21:05:29,003 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7459120396957841, 'Total loss': 0.7459120396957841} | train loss {'Reaction outcome loss': 0.7823248111077996, 'Total loss': 0.7823248111077996}
2022-11-22 21:05:29,004 INFO:     Found new best model at epoch 44
2022-11-22 21:05:29,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:29,005 INFO:     Epoch: 45
2022-11-22 21:05:29,719 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7448404403619988, 'Total loss': 0.7448404403619988} | train loss {'Reaction outcome loss': 0.7843339605653872, 'Total loss': 0.7843339605653872}
2022-11-22 21:05:29,719 INFO:     Found new best model at epoch 45
2022-11-22 21:05:29,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:29,720 INFO:     Epoch: 46
2022-11-22 21:05:30,461 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7632497715395551, 'Total loss': 0.7632497715395551} | train loss {'Reaction outcome loss': 0.7784569644537128, 'Total loss': 0.7784569644537128}
2022-11-22 21:05:30,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:30,461 INFO:     Epoch: 47
2022-11-22 21:05:31,203 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7754152361736741, 'Total loss': 0.7754152361736741} | train loss {'Reaction outcome loss': 0.7822386416011169, 'Total loss': 0.7822386416011169}
2022-11-22 21:05:31,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:31,203 INFO:     Epoch: 48
2022-11-22 21:05:31,917 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7770101545855056, 'Total loss': 0.7770101545855056} | train loss {'Reaction outcome loss': 0.7861833093596287, 'Total loss': 0.7861833093596287}
2022-11-22 21:05:31,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:31,917 INFO:     Epoch: 49
2022-11-22 21:05:32,659 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7685108815514764, 'Total loss': 0.7685108815514764} | train loss {'Reaction outcome loss': 0.7847272866084928, 'Total loss': 0.7847272866084928}
2022-11-22 21:05:32,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:32,660 INFO:     Epoch: 50
2022-11-22 21:05:33,386 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7588752126970957, 'Total loss': 0.7588752126970957} | train loss {'Reaction outcome loss': 0.7842637059874222, 'Total loss': 0.7842637059874222}
2022-11-22 21:05:33,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:33,386 INFO:     Epoch: 51
2022-11-22 21:05:34,085 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7577054348102835, 'Total loss': 0.7577054348102835} | train loss {'Reaction outcome loss': 0.7860671394183988, 'Total loss': 0.7860671394183988}
2022-11-22 21:05:34,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:34,085 INFO:     Epoch: 52
2022-11-22 21:05:34,802 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7602571048015772, 'Total loss': 0.7602571048015772} | train loss {'Reaction outcome loss': 0.778281107911321, 'Total loss': 0.778281107911321}
2022-11-22 21:05:34,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:34,802 INFO:     Epoch: 53
2022-11-22 21:05:35,484 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7489677127017531, 'Total loss': 0.7489677127017531} | train loss {'Reaction outcome loss': 0.7727350376424242, 'Total loss': 0.7727350376424242}
2022-11-22 21:05:35,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:35,485 INFO:     Epoch: 54
2022-11-22 21:05:36,205 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7549746091975722, 'Total loss': 0.7549746091975722} | train loss {'Reaction outcome loss': 0.7806545442245045, 'Total loss': 0.7806545442245045}
2022-11-22 21:05:36,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:36,205 INFO:     Epoch: 55
2022-11-22 21:05:36,906 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8230990192224813, 'Total loss': 0.8230990192224813} | train loss {'Reaction outcome loss': 0.7751502290856643, 'Total loss': 0.7751502290856643}
2022-11-22 21:05:36,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:36,907 INFO:     Epoch: 56
2022-11-22 21:05:37,614 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7383007635903913, 'Total loss': 0.7383007635903913} | train loss {'Reaction outcome loss': 0.7795469538598764, 'Total loss': 0.7795469538598764}
2022-11-22 21:05:37,614 INFO:     Found new best model at epoch 56
2022-11-22 21:05:37,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:37,615 INFO:     Epoch: 57
2022-11-22 21:05:38,349 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7736168261184249, 'Total loss': 0.7736168261184249} | train loss {'Reaction outcome loss': 0.7806419678887383, 'Total loss': 0.7806419678887383}
2022-11-22 21:05:38,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:38,349 INFO:     Epoch: 58
2022-11-22 21:05:39,076 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7672351328439491, 'Total loss': 0.7672351328439491} | train loss {'Reaction outcome loss': 0.7804915409107678, 'Total loss': 0.7804915409107678}
2022-11-22 21:05:39,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:39,077 INFO:     Epoch: 59
2022-11-22 21:05:39,781 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7447056992109432, 'Total loss': 0.7447056992109432} | train loss {'Reaction outcome loss': 0.7770421851853855, 'Total loss': 0.7770421851853855}
2022-11-22 21:05:39,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:39,781 INFO:     Epoch: 60
2022-11-22 21:05:40,507 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7573539607746657, 'Total loss': 0.7573539607746657} | train loss {'Reaction outcome loss': 0.7768198591275294, 'Total loss': 0.7768198591275294}
2022-11-22 21:05:40,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:40,508 INFO:     Epoch: 61
2022-11-22 21:05:41,237 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7434176393719607, 'Total loss': 0.7434176393719607} | train loss {'Reaction outcome loss': 0.7751160813648192, 'Total loss': 0.7751160813648192}
2022-11-22 21:05:41,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:41,239 INFO:     Epoch: 62
2022-11-22 21:05:41,954 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8110910536244859, 'Total loss': 0.8110910536244859} | train loss {'Reaction outcome loss': 0.7718238693768861, 'Total loss': 0.7718238693768861}
2022-11-22 21:05:41,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:41,955 INFO:     Epoch: 63
2022-11-22 21:05:42,680 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7906685138857642, 'Total loss': 0.7906685138857642} | train loss {'Reaction outcome loss': 0.7756594228939931, 'Total loss': 0.7756594228939931}
2022-11-22 21:05:42,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:42,680 INFO:     Epoch: 64
2022-11-22 21:05:43,431 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7449873637321384, 'Total loss': 0.7449873637321384} | train loss {'Reaction outcome loss': 0.7710249868572735, 'Total loss': 0.7710249868572735}
2022-11-22 21:05:43,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:43,432 INFO:     Epoch: 65
2022-11-22 21:05:44,164 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7366642508395883, 'Total loss': 0.7366642508395883} | train loss {'Reaction outcome loss': 0.7741551953749578, 'Total loss': 0.7741551953749578}
2022-11-22 21:05:44,164 INFO:     Found new best model at epoch 65
2022-11-22 21:05:44,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:44,165 INFO:     Epoch: 66
2022-11-22 21:05:44,882 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7284537061702373, 'Total loss': 0.7284537061702373} | train loss {'Reaction outcome loss': 0.7617740452778144, 'Total loss': 0.7617740452778144}
2022-11-22 21:05:44,882 INFO:     Found new best model at epoch 66
2022-11-22 21:05:44,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:44,883 INFO:     Epoch: 67
2022-11-22 21:05:45,607 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.746018054180367, 'Total loss': 0.746018054180367} | train loss {'Reaction outcome loss': 0.7638706667501418, 'Total loss': 0.7638706667501418}
2022-11-22 21:05:45,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:45,607 INFO:     Epoch: 68
2022-11-22 21:05:46,341 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7558068432087122, 'Total loss': 0.7558068432087122} | train loss {'Reaction outcome loss': 0.7638439749840831, 'Total loss': 0.7638439749840831}
2022-11-22 21:05:46,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:46,341 INFO:     Epoch: 69
2022-11-22 21:05:47,065 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7346309194731158, 'Total loss': 0.7346309194731158} | train loss {'Reaction outcome loss': 0.7602121801894219, 'Total loss': 0.7602121801894219}
2022-11-22 21:05:47,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:47,065 INFO:     Epoch: 70
2022-11-22 21:05:47,763 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.734374767126039, 'Total loss': 0.734374767126039} | train loss {'Reaction outcome loss': 0.7660273508947404, 'Total loss': 0.7660273508947404}
2022-11-22 21:05:47,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:47,764 INFO:     Epoch: 71
2022-11-22 21:05:48,491 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7150215111499609, 'Total loss': 0.7150215111499609} | train loss {'Reaction outcome loss': 0.7584148353484811, 'Total loss': 0.7584148353484811}
2022-11-22 21:05:48,492 INFO:     Found new best model at epoch 71
2022-11-22 21:05:48,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:48,492 INFO:     Epoch: 72
2022-11-22 21:05:49,200 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7208550191202829, 'Total loss': 0.7208550191202829} | train loss {'Reaction outcome loss': 0.7483100353694353, 'Total loss': 0.7483100353694353}
2022-11-22 21:05:49,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:49,200 INFO:     Epoch: 73
2022-11-22 21:05:49,917 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7242370684479558, 'Total loss': 0.7242370684479558} | train loss {'Reaction outcome loss': 0.7512733659050503, 'Total loss': 0.7512733659050503}
2022-11-22 21:05:49,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:49,917 INFO:     Epoch: 74
2022-11-22 21:05:50,648 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7216144814047702, 'Total loss': 0.7216144814047702} | train loss {'Reaction outcome loss': 0.7484390604935709, 'Total loss': 0.7484390604935709}
2022-11-22 21:05:50,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:50,648 INFO:     Epoch: 75
2022-11-22 21:05:51,375 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7267719978509948, 'Total loss': 0.7267719978509948} | train loss {'Reaction outcome loss': 0.7512834360975711, 'Total loss': 0.7512834360975711}
2022-11-22 21:05:51,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:51,376 INFO:     Epoch: 76
2022-11-22 21:05:52,090 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7165164517801862, 'Total loss': 0.7165164517801862} | train loss {'Reaction outcome loss': 0.7471846772632638, 'Total loss': 0.7471846772632638}
2022-11-22 21:05:52,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:52,090 INFO:     Epoch: 77
2022-11-22 21:05:52,813 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7081055301566457, 'Total loss': 0.7081055301566457} | train loss {'Reaction outcome loss': 0.7406651363021037, 'Total loss': 0.7406651363021037}
2022-11-22 21:05:52,813 INFO:     Found new best model at epoch 77
2022-11-22 21:05:52,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:52,814 INFO:     Epoch: 78
2022-11-22 21:05:53,593 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7131008803844452, 'Total loss': 0.7131008803844452} | train loss {'Reaction outcome loss': 0.7388372084156412, 'Total loss': 0.7388372084156412}
2022-11-22 21:05:53,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:53,593 INFO:     Epoch: 79
2022-11-22 21:05:54,349 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7523176774036052, 'Total loss': 0.7523176774036052} | train loss {'Reaction outcome loss': 0.7379290501846641, 'Total loss': 0.7379290501846641}
2022-11-22 21:05:54,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:54,350 INFO:     Epoch: 80
2022-11-22 21:05:55,077 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.720748957506446, 'Total loss': 0.720748957506446} | train loss {'Reaction outcome loss': 0.7340571836369937, 'Total loss': 0.7340571836369937}
2022-11-22 21:05:55,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:55,077 INFO:     Epoch: 81
2022-11-22 21:05:55,820 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7152208526467168, 'Total loss': 0.7152208526467168} | train loss {'Reaction outcome loss': 0.729195623124232, 'Total loss': 0.729195623124232}
2022-11-22 21:05:55,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:55,821 INFO:     Epoch: 82
2022-11-22 21:05:56,647 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7274443160655887, 'Total loss': 0.7274443160655887} | train loss {'Reaction outcome loss': 0.7274856541733272, 'Total loss': 0.7274856541733272}
2022-11-22 21:05:56,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:56,648 INFO:     Epoch: 83
2022-11-22 21:05:57,399 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7260291167469912, 'Total loss': 0.7260291167469912} | train loss {'Reaction outcome loss': 0.7292568585911735, 'Total loss': 0.7292568585911735}
2022-11-22 21:05:57,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:57,399 INFO:     Epoch: 84
2022-11-22 21:05:58,185 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7096838306548984, 'Total loss': 0.7096838306548984} | train loss {'Reaction outcome loss': 0.7266367025306968, 'Total loss': 0.7266367025306968}
2022-11-22 21:05:58,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:58,186 INFO:     Epoch: 85
2022-11-22 21:05:58,945 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6997861675051755, 'Total loss': 0.6997861675051755} | train loss {'Reaction outcome loss': 0.7246324007139832, 'Total loss': 0.7246324007139832}
2022-11-22 21:05:58,945 INFO:     Found new best model at epoch 85
2022-11-22 21:05:58,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:58,946 INFO:     Epoch: 86
2022-11-22 21:05:59,772 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7483870075192562, 'Total loss': 0.7483870075192562} | train loss {'Reaction outcome loss': 0.7158508876674488, 'Total loss': 0.7158508876674488}
2022-11-22 21:05:59,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:05:59,773 INFO:     Epoch: 87
2022-11-22 21:06:00,585 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7496133744716644, 'Total loss': 0.7496133744716644} | train loss {'Reaction outcome loss': 0.7299824884680451, 'Total loss': 0.7299824884680451}
2022-11-22 21:06:00,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:00,585 INFO:     Epoch: 88
2022-11-22 21:06:01,415 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6901454398798388, 'Total loss': 0.6901454398798388} | train loss {'Reaction outcome loss': 0.7238942359070308, 'Total loss': 0.7238942359070308}
2022-11-22 21:06:01,415 INFO:     Found new best model at epoch 88
2022-11-22 21:06:01,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:01,416 INFO:     Epoch: 89
2022-11-22 21:06:02,195 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7057987888192021, 'Total loss': 0.7057987888192021} | train loss {'Reaction outcome loss': 0.7160748409443214, 'Total loss': 0.7160748409443214}
2022-11-22 21:06:02,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:02,195 INFO:     Epoch: 90
2022-11-22 21:06:02,997 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7181238379589346, 'Total loss': 0.7181238379589346} | train loss {'Reaction outcome loss': 0.7150799285192959, 'Total loss': 0.7150799285192959}
2022-11-22 21:06:02,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:02,998 INFO:     Epoch: 91
2022-11-22 21:06:03,779 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7133750201657761, 'Total loss': 0.7133750201657761} | train loss {'Reaction outcome loss': 0.7066656132457686, 'Total loss': 0.7066656132457686}
2022-11-22 21:06:03,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:03,780 INFO:     Epoch: 92
2022-11-22 21:06:04,497 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6963917599167935, 'Total loss': 0.6963917599167935} | train loss {'Reaction outcome loss': 0.716681251393967, 'Total loss': 0.716681251393967}
2022-11-22 21:06:04,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:04,497 INFO:     Epoch: 93
2022-11-22 21:06:05,218 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.699217090773028, 'Total loss': 0.699217090773028} | train loss {'Reaction outcome loss': 0.7131105861702903, 'Total loss': 0.7131105861702903}
2022-11-22 21:06:05,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:05,218 INFO:     Epoch: 94
2022-11-22 21:06:05,922 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7000987238662187, 'Total loss': 0.7000987238662187} | train loss {'Reaction outcome loss': 0.7138773520461849, 'Total loss': 0.7138773520461849}
2022-11-22 21:06:05,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:05,922 INFO:     Epoch: 95
2022-11-22 21:06:06,695 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6872834570186083, 'Total loss': 0.6872834570186083} | train loss {'Reaction outcome loss': 0.7170949836002022, 'Total loss': 0.7170949836002022}
2022-11-22 21:06:06,695 INFO:     Found new best model at epoch 95
2022-11-22 21:06:06,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:06,696 INFO:     Epoch: 96
2022-11-22 21:06:07,432 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7124134551647098, 'Total loss': 0.7124134551647098} | train loss {'Reaction outcome loss': 0.7094938558388929, 'Total loss': 0.7094938558388929}
2022-11-22 21:06:07,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:07,432 INFO:     Epoch: 97
2022-11-22 21:06:08,182 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6995810152486314, 'Total loss': 0.6995810152486314} | train loss {'Reaction outcome loss': 0.7084114607728895, 'Total loss': 0.7084114607728895}
2022-11-22 21:06:08,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:08,183 INFO:     Epoch: 98
2022-11-22 21:06:08,913 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6958521382753239, 'Total loss': 0.6958521382753239} | train loss {'Reaction outcome loss': 0.7087454093528576, 'Total loss': 0.7087454093528576}
2022-11-22 21:06:08,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:08,914 INFO:     Epoch: 99
2022-11-22 21:06:09,688 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7110552545203719, 'Total loss': 0.7110552545203719} | train loss {'Reaction outcome loss': 0.717732908784366, 'Total loss': 0.717732908784366}
2022-11-22 21:06:09,689 INFO:     Best model found after epoch 96 of 100.
2022-11-22 21:06:09,689 INFO:   Done with stage: TRAINING
2022-11-22 21:06:09,689 INFO:   Starting stage: EVALUATION
2022-11-22 21:06:09,819 INFO:   Done with stage: EVALUATION
2022-11-22 21:06:09,819 INFO:   Leaving out SEQ value Fold_4
2022-11-22 21:06:09,832 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 21:06:09,832 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:06:10,507 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:06:10,507 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:06:10,576 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:06:10,576 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:06:10,576 INFO:     No hyperparam tuning for this model
2022-11-22 21:06:10,576 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:06:10,576 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:06:10,577 INFO:     None feature selector for col prot
2022-11-22 21:06:10,577 INFO:     None feature selector for col prot
2022-11-22 21:06:10,577 INFO:     None feature selector for col prot
2022-11-22 21:06:10,578 INFO:     None feature selector for col chem
2022-11-22 21:06:10,578 INFO:     None feature selector for col chem
2022-11-22 21:06:10,578 INFO:     None feature selector for col chem
2022-11-22 21:06:10,578 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:06:10,578 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:06:10,580 INFO:     Number of params in model 126091
2022-11-22 21:06:10,583 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:06:10,583 INFO:   Starting stage: TRAINING
2022-11-22 21:06:10,633 INFO:     Val loss before train {'Reaction outcome loss': 0.9586399807171389, 'Total loss': 0.9586399807171389}
2022-11-22 21:06:10,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:10,633 INFO:     Epoch: 0
2022-11-22 21:06:11,377 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.841473826630549, 'Total loss': 0.841473826630549} | train loss {'Reaction outcome loss': 0.875099008141259, 'Total loss': 0.875099008141259}
2022-11-22 21:06:11,377 INFO:     Found new best model at epoch 0
2022-11-22 21:06:11,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:11,378 INFO:     Epoch: 1
2022-11-22 21:06:12,140 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8105383454398676, 'Total loss': 0.8105383454398676} | train loss {'Reaction outcome loss': 0.8408270791052324, 'Total loss': 0.8408270791052324}
2022-11-22 21:06:12,141 INFO:     Found new best model at epoch 1
2022-11-22 21:06:12,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:12,142 INFO:     Epoch: 2
2022-11-22 21:06:12,900 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8037782717834819, 'Total loss': 0.8037782717834819} | train loss {'Reaction outcome loss': 0.8438918355264162, 'Total loss': 0.8438918355264162}
2022-11-22 21:06:12,900 INFO:     Found new best model at epoch 2
2022-11-22 21:06:12,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:12,901 INFO:     Epoch: 3
2022-11-22 21:06:13,648 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7942702370611104, 'Total loss': 0.7942702370611104} | train loss {'Reaction outcome loss': 0.8320317287676731, 'Total loss': 0.8320317287676731}
2022-11-22 21:06:13,648 INFO:     Found new best model at epoch 3
2022-11-22 21:06:13,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:13,649 INFO:     Epoch: 4
2022-11-22 21:06:14,430 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8053367733955383, 'Total loss': 0.8053367733955383} | train loss {'Reaction outcome loss': 0.8214441516138764, 'Total loss': 0.8214441516138764}
2022-11-22 21:06:14,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:14,431 INFO:     Epoch: 5
2022-11-22 21:06:15,184 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7745924185622822, 'Total loss': 0.7745924185622822} | train loss {'Reaction outcome loss': 0.8252209639742307, 'Total loss': 0.8252209639742307}
2022-11-22 21:06:15,184 INFO:     Found new best model at epoch 5
2022-11-22 21:06:15,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:15,185 INFO:     Epoch: 6
2022-11-22 21:06:15,956 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7895306511358782, 'Total loss': 0.7895306511358782} | train loss {'Reaction outcome loss': 0.8187421960869299, 'Total loss': 0.8187421960869299}
2022-11-22 21:06:15,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:15,956 INFO:     Epoch: 7
2022-11-22 21:06:16,704 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7730244818058881, 'Total loss': 0.7730244818058881} | train loss {'Reaction outcome loss': 0.8258824102309069, 'Total loss': 0.8258824102309069}
2022-11-22 21:06:16,704 INFO:     Found new best model at epoch 7
2022-11-22 21:06:16,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:16,705 INFO:     Epoch: 8
2022-11-22 21:06:17,434 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7575491863218221, 'Total loss': 0.7575491863218221} | train loss {'Reaction outcome loss': 0.823368675192358, 'Total loss': 0.823368675192358}
2022-11-22 21:06:17,435 INFO:     Found new best model at epoch 8
2022-11-22 21:06:17,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:17,436 INFO:     Epoch: 9
2022-11-22 21:06:18,210 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7734668099067428, 'Total loss': 0.7734668099067428} | train loss {'Reaction outcome loss': 0.8096452374689975, 'Total loss': 0.8096452374689975}
2022-11-22 21:06:18,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:18,211 INFO:     Epoch: 10
2022-11-22 21:06:18,922 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7763498791239478, 'Total loss': 0.7763498791239478} | train loss {'Reaction outcome loss': 0.8107475469469542, 'Total loss': 0.8107475469469542}
2022-11-22 21:06:18,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:18,922 INFO:     Epoch: 11
2022-11-22 21:06:19,603 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7753196141936562, 'Total loss': 0.7753196141936562} | train loss {'Reaction outcome loss': 0.8054982766448727, 'Total loss': 0.8054982766448727}
2022-11-22 21:06:19,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:19,603 INFO:     Epoch: 12
2022-11-22 21:06:20,381 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7834884625944224, 'Total loss': 0.7834884625944224} | train loss {'Reaction outcome loss': 0.7998109780221816, 'Total loss': 0.7998109780221816}
2022-11-22 21:06:20,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:20,381 INFO:     Epoch: 13
2022-11-22 21:06:21,099 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7898230369795453, 'Total loss': 0.7898230369795453} | train loss {'Reaction outcome loss': 0.8050897482797684, 'Total loss': 0.8050897482797684}
2022-11-22 21:06:21,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:21,100 INFO:     Epoch: 14
2022-11-22 21:06:21,832 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.783279800279574, 'Total loss': 0.783279800279574} | train loss {'Reaction outcome loss': 0.8076192539954475, 'Total loss': 0.8076192539954475}
2022-11-22 21:06:21,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:21,833 INFO:     Epoch: 15
2022-11-22 21:06:22,579 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7613230659203096, 'Total loss': 0.7613230659203096} | train loss {'Reaction outcome loss': 0.7932307348560225, 'Total loss': 0.7932307348560225}
2022-11-22 21:06:22,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:22,579 INFO:     Epoch: 16
2022-11-22 21:06:23,300 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7878771790049293, 'Total loss': 0.7878771790049293} | train loss {'Reaction outcome loss': 0.7987280881356614, 'Total loss': 0.7987280881356614}
2022-11-22 21:06:23,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:23,300 INFO:     Epoch: 17
2022-11-22 21:06:24,068 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7911831790750677, 'Total loss': 0.7911831790750677} | train loss {'Reaction outcome loss': 0.7938811525642148, 'Total loss': 0.7938811525642148}
2022-11-22 21:06:24,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:24,068 INFO:     Epoch: 18
2022-11-22 21:06:24,814 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.827068761668422, 'Total loss': 0.827068761668422} | train loss {'Reaction outcome loss': 0.8029542927317291, 'Total loss': 0.8029542927317291}
2022-11-22 21:06:24,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:24,814 INFO:     Epoch: 19
2022-11-22 21:06:25,579 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7830946377732537, 'Total loss': 0.7830946377732537} | train loss {'Reaction outcome loss': 0.799260469824679, 'Total loss': 0.799260469824679}
2022-11-22 21:06:25,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:25,579 INFO:     Epoch: 20
2022-11-22 21:06:26,320 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7709600769660689, 'Total loss': 0.7709600769660689} | train loss {'Reaction outcome loss': 0.7984465272561742, 'Total loss': 0.7984465272561742}
2022-11-22 21:06:26,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:26,320 INFO:     Epoch: 21
2022-11-22 21:06:27,107 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7654717144641009, 'Total loss': 0.7654717144641009} | train loss {'Reaction outcome loss': 0.7989859624430236, 'Total loss': 0.7989859624430236}
2022-11-22 21:06:27,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:27,107 INFO:     Epoch: 22
2022-11-22 21:06:27,865 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7724908908659761, 'Total loss': 0.7724908908659761} | train loss {'Reaction outcome loss': 0.8023271937119333, 'Total loss': 0.8023271937119333}
2022-11-22 21:06:27,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:27,866 INFO:     Epoch: 23
2022-11-22 21:06:28,650 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7734909999099645, 'Total loss': 0.7734909999099645} | train loss {'Reaction outcome loss': 0.7997318312586078, 'Total loss': 0.7997318312586078}
2022-11-22 21:06:28,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:28,651 INFO:     Epoch: 24
2022-11-22 21:06:29,409 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8010418862104416, 'Total loss': 0.8010418862104416} | train loss {'Reaction outcome loss': 0.8035668236041359, 'Total loss': 0.8035668236041359}
2022-11-22 21:06:29,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:29,409 INFO:     Epoch: 25
2022-11-22 21:06:30,169 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7867168960246173, 'Total loss': 0.7867168960246173} | train loss {'Reaction outcome loss': 0.7999366075403778, 'Total loss': 0.7999366075403778}
2022-11-22 21:06:30,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:30,169 INFO:     Epoch: 26
2022-11-22 21:06:30,923 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7628916339440779, 'Total loss': 0.7628916339440779} | train loss {'Reaction outcome loss': 0.7957510868547416, 'Total loss': 0.7957510868547416}
2022-11-22 21:06:30,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:30,923 INFO:     Epoch: 27
2022-11-22 21:06:31,640 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7694394033063542, 'Total loss': 0.7694394033063542} | train loss {'Reaction outcome loss': 0.7905915939675169, 'Total loss': 0.7905915939675169}
2022-11-22 21:06:31,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:31,640 INFO:     Epoch: 28
2022-11-22 21:06:32,410 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8060602674430067, 'Total loss': 0.8060602674430067} | train loss {'Reaction outcome loss': 0.7993726824459276, 'Total loss': 0.7993726824459276}
2022-11-22 21:06:32,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:32,410 INFO:     Epoch: 29
2022-11-22 21:06:33,140 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7753533971580592, 'Total loss': 0.7753533971580592} | train loss {'Reaction outcome loss': 0.7938023420721896, 'Total loss': 0.7938023420721896}
2022-11-22 21:06:33,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:33,140 INFO:     Epoch: 30
2022-11-22 21:06:33,886 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7684936943379316, 'Total loss': 0.7684936943379316} | train loss {'Reaction outcome loss': 0.7986200060921642, 'Total loss': 0.7986200060921642}
2022-11-22 21:06:33,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:33,887 INFO:     Epoch: 31
2022-11-22 21:06:34,625 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7786612795157866, 'Total loss': 0.7786612795157866} | train loss {'Reaction outcome loss': 0.801771321398044, 'Total loss': 0.801771321398044}
2022-11-22 21:06:34,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:34,626 INFO:     Epoch: 32
2022-11-22 21:06:35,403 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7686706733974543, 'Total loss': 0.7686706733974543} | train loss {'Reaction outcome loss': 0.7933278808950895, 'Total loss': 0.7933278808950895}
2022-11-22 21:06:35,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:35,403 INFO:     Epoch: 33
2022-11-22 21:06:36,168 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.765785969116471, 'Total loss': 0.765785969116471} | train loss {'Reaction outcome loss': 0.787836662127904, 'Total loss': 0.787836662127904}
2022-11-22 21:06:36,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:36,169 INFO:     Epoch: 34
2022-11-22 21:06:36,902 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7592018829150633, 'Total loss': 0.7592018829150633} | train loss {'Reaction outcome loss': 0.793240649316475, 'Total loss': 0.793240649316475}
2022-11-22 21:06:36,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:36,903 INFO:     Epoch: 35
2022-11-22 21:06:37,656 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7829549874771725, 'Total loss': 0.7829549874771725} | train loss {'Reaction outcome loss': 0.7907176051545239, 'Total loss': 0.7907176051545239}
2022-11-22 21:06:37,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:37,656 INFO:     Epoch: 36
2022-11-22 21:06:38,379 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7691508131948385, 'Total loss': 0.7691508131948385} | train loss {'Reaction outcome loss': 0.8047460187301945, 'Total loss': 0.8047460187301945}
2022-11-22 21:06:38,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:38,379 INFO:     Epoch: 37
2022-11-22 21:06:39,116 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8290487744591453, 'Total loss': 0.8290487744591453} | train loss {'Reaction outcome loss': 0.7884281512938047, 'Total loss': 0.7884281512938047}
2022-11-22 21:06:39,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:39,117 INFO:     Epoch: 38
2022-11-22 21:06:39,862 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7627064822749658, 'Total loss': 0.7627064822749658} | train loss {'Reaction outcome loss': 0.7982956097434889, 'Total loss': 0.7982956097434889}
2022-11-22 21:06:39,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:39,862 INFO:     Epoch: 39
2022-11-22 21:06:40,620 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7675868198275566, 'Total loss': 0.7675868198275566} | train loss {'Reaction outcome loss': 0.8096268694651755, 'Total loss': 0.8096268694651755}
2022-11-22 21:06:40,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:40,620 INFO:     Epoch: 40
2022-11-22 21:06:41,418 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7596484111113981, 'Total loss': 0.7596484111113981} | train loss {'Reaction outcome loss': 0.7902144077818404, 'Total loss': 0.7902144077818404}
2022-11-22 21:06:41,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:41,418 INFO:     Epoch: 41
2022-11-22 21:06:42,196 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7796752168373628, 'Total loss': 0.7796752168373628} | train loss {'Reaction outcome loss': 0.7912758659978627, 'Total loss': 0.7912758659978627}
2022-11-22 21:06:42,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:42,197 INFO:     Epoch: 42
2022-11-22 21:06:42,964 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7630612802776423, 'Total loss': 0.7630612802776423} | train loss {'Reaction outcome loss': 0.7934549563085502, 'Total loss': 0.7934549563085502}
2022-11-22 21:06:42,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:42,964 INFO:     Epoch: 43
2022-11-22 21:06:43,708 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7811779969117858, 'Total loss': 0.7811779969117858} | train loss {'Reaction outcome loss': 0.7892756200572739, 'Total loss': 0.7892756200572739}
2022-11-22 21:06:43,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:43,709 INFO:     Epoch: 44
2022-11-22 21:06:44,470 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7625024935061281, 'Total loss': 0.7625024935061281} | train loss {'Reaction outcome loss': 0.7922642442137606, 'Total loss': 0.7922642442137606}
2022-11-22 21:06:44,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:44,470 INFO:     Epoch: 45
2022-11-22 21:06:45,229 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7697941200299696, 'Total loss': 0.7697941200299696} | train loss {'Reaction outcome loss': 0.7972101835828078, 'Total loss': 0.7972101835828078}
2022-11-22 21:06:45,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:45,229 INFO:     Epoch: 46
2022-11-22 21:06:45,968 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7577402320775118, 'Total loss': 0.7577402320775118} | train loss {'Reaction outcome loss': 0.7943792091267794, 'Total loss': 0.7943792091267794}
2022-11-22 21:06:45,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:45,969 INFO:     Epoch: 47
2022-11-22 21:06:46,701 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7548632405020974, 'Total loss': 0.7548632405020974} | train loss {'Reaction outcome loss': 0.7878498879849518, 'Total loss': 0.7878498879849518}
2022-11-22 21:06:46,701 INFO:     Found new best model at epoch 47
2022-11-22 21:06:46,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:46,702 INFO:     Epoch: 48
2022-11-22 21:06:47,439 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7571947513656183, 'Total loss': 0.7571947513656183} | train loss {'Reaction outcome loss': 0.7919338974151534, 'Total loss': 0.7919338974151534}
2022-11-22 21:06:47,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:47,439 INFO:     Epoch: 49
2022-11-22 21:06:48,191 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8051376776261763, 'Total loss': 0.8051376776261763} | train loss {'Reaction outcome loss': 0.7904438066337756, 'Total loss': 0.7904438066337756}
2022-11-22 21:06:48,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:48,191 INFO:     Epoch: 50
2022-11-22 21:06:48,939 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7698175500739705, 'Total loss': 0.7698175500739705} | train loss {'Reaction outcome loss': 0.7944684178240387, 'Total loss': 0.7944684178240387}
2022-11-22 21:06:48,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:48,940 INFO:     Epoch: 51
2022-11-22 21:06:49,663 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8344372700561177, 'Total loss': 0.8344372700561177} | train loss {'Reaction outcome loss': 0.780762452556778, 'Total loss': 0.780762452556778}
2022-11-22 21:06:49,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:49,663 INFO:     Epoch: 52
2022-11-22 21:06:50,371 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7577978718009862, 'Total loss': 0.7577978718009862} | train loss {'Reaction outcome loss': 0.787958108341163, 'Total loss': 0.787958108341163}
2022-11-22 21:06:50,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:50,372 INFO:     Epoch: 53
2022-11-22 21:06:51,143 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7645397579128091, 'Total loss': 0.7645397579128091} | train loss {'Reaction outcome loss': 0.7900813379992357, 'Total loss': 0.7900813379992357}
2022-11-22 21:06:51,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:51,143 INFO:     Epoch: 54
2022-11-22 21:06:51,888 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7633170180700042, 'Total loss': 0.7633170180700042} | train loss {'Reaction outcome loss': 0.7839776832565122, 'Total loss': 0.7839776832565122}
2022-11-22 21:06:51,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:51,888 INFO:     Epoch: 55
2022-11-22 21:06:52,664 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.769359518181194, 'Total loss': 0.769359518181194} | train loss {'Reaction outcome loss': 0.7865813576016831, 'Total loss': 0.7865813576016831}
2022-11-22 21:06:52,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:52,665 INFO:     Epoch: 56
2022-11-22 21:06:53,381 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7946622608737512, 'Total loss': 0.7946622608737512} | train loss {'Reaction outcome loss': 0.7790968842834596, 'Total loss': 0.7790968842834596}
2022-11-22 21:06:53,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:53,381 INFO:     Epoch: 57
2022-11-22 21:06:54,155 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7580266107212413, 'Total loss': 0.7580266107212413} | train loss {'Reaction outcome loss': 0.78369252552629, 'Total loss': 0.78369252552629}
2022-11-22 21:06:54,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:54,155 INFO:     Epoch: 58
2022-11-22 21:06:54,908 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7479361329566349, 'Total loss': 0.7479361329566349} | train loss {'Reaction outcome loss': 0.7779812535293672, 'Total loss': 0.7779812535293672}
2022-11-22 21:06:54,908 INFO:     Found new best model at epoch 58
2022-11-22 21:06:54,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:54,909 INFO:     Epoch: 59
2022-11-22 21:06:55,672 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.751408152282238, 'Total loss': 0.751408152282238} | train loss {'Reaction outcome loss': 0.7737486434625349, 'Total loss': 0.7737486434625349}
2022-11-22 21:06:55,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:55,672 INFO:     Epoch: 60
2022-11-22 21:06:56,447 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7393565801056948, 'Total loss': 0.7393565801056948} | train loss {'Reaction outcome loss': 0.772505505968202, 'Total loss': 0.772505505968202}
2022-11-22 21:06:56,447 INFO:     Found new best model at epoch 60
2022-11-22 21:06:56,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:56,448 INFO:     Epoch: 61
2022-11-22 21:06:57,242 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7583590231158517, 'Total loss': 0.7583590231158517} | train loss {'Reaction outcome loss': 0.7812785887525149, 'Total loss': 0.7812785887525149}
2022-11-22 21:06:57,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:57,242 INFO:     Epoch: 62
2022-11-22 21:06:58,030 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7398976304314353, 'Total loss': 0.7398976304314353} | train loss {'Reaction outcome loss': 0.7759127334996998, 'Total loss': 0.7759127334996998}
2022-11-22 21:06:58,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:58,030 INFO:     Epoch: 63
2022-11-22 21:06:58,858 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7663536471399394, 'Total loss': 0.7663536471399394} | train loss {'Reaction outcome loss': 0.7726324216315621, 'Total loss': 0.7726324216315621}
2022-11-22 21:06:58,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:58,858 INFO:     Epoch: 64
2022-11-22 21:06:59,646 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.770803539590402, 'Total loss': 0.770803539590402} | train loss {'Reaction outcome loss': 0.7732855736726691, 'Total loss': 0.7732855736726691}
2022-11-22 21:06:59,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:06:59,647 INFO:     Epoch: 65
2022-11-22 21:07:00,438 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7395057922059839, 'Total loss': 0.7395057922059839} | train loss {'Reaction outcome loss': 0.7696364645050605, 'Total loss': 0.7696364645050605}
2022-11-22 21:07:00,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:00,439 INFO:     Epoch: 66
2022-11-22 21:07:01,246 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7376420511440798, 'Total loss': 0.7376420511440798} | train loss {'Reaction outcome loss': 0.7610821994587116, 'Total loss': 0.7610821994587116}
2022-11-22 21:07:01,246 INFO:     Found new best model at epoch 66
2022-11-22 21:07:01,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:01,247 INFO:     Epoch: 67
2022-11-22 21:07:02,051 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7626159346916459, 'Total loss': 0.7626159346916459} | train loss {'Reaction outcome loss': 0.7650026525804389, 'Total loss': 0.7650026525804389}
2022-11-22 21:07:02,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:02,051 INFO:     Epoch: 68
2022-11-22 21:07:02,841 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7206118906086142, 'Total loss': 0.7206118906086142} | train loss {'Reaction outcome loss': 0.7612120366772177, 'Total loss': 0.7612120366772177}
2022-11-22 21:07:02,842 INFO:     Found new best model at epoch 68
2022-11-22 21:07:02,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:02,843 INFO:     Epoch: 69
2022-11-22 21:07:03,678 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7177756293253466, 'Total loss': 0.7177756293253466} | train loss {'Reaction outcome loss': 0.765113679262308, 'Total loss': 0.765113679262308}
2022-11-22 21:07:03,678 INFO:     Found new best model at epoch 69
2022-11-22 21:07:03,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:03,679 INFO:     Epoch: 70
2022-11-22 21:07:04,490 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7565714594992724, 'Total loss': 0.7565714594992724} | train loss {'Reaction outcome loss': 0.7583520586493044, 'Total loss': 0.7583520586493044}
2022-11-22 21:07:04,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:04,491 INFO:     Epoch: 71
2022-11-22 21:07:05,322 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7398877895691178, 'Total loss': 0.7398877895691178} | train loss {'Reaction outcome loss': 0.7538120064974917, 'Total loss': 0.7538120064974917}
2022-11-22 21:07:05,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:05,322 INFO:     Epoch: 72
2022-11-22 21:07:06,156 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7315524261106144, 'Total loss': 0.7315524261106144} | train loss {'Reaction outcome loss': 0.7657089629153974, 'Total loss': 0.7657089629153974}
2022-11-22 21:07:06,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:06,156 INFO:     Epoch: 73
2022-11-22 21:07:06,992 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7228776440024376, 'Total loss': 0.7228776440024376} | train loss {'Reaction outcome loss': 0.7547623826424602, 'Total loss': 0.7547623826424602}
2022-11-22 21:07:06,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:06,992 INFO:     Epoch: 74
2022-11-22 21:07:07,812 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7450444014234976, 'Total loss': 0.7450444014234976} | train loss {'Reaction outcome loss': 0.7565788763013446, 'Total loss': 0.7565788763013446}
2022-11-22 21:07:07,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:07,813 INFO:     Epoch: 75
2022-11-22 21:07:08,637 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7580094340850007, 'Total loss': 0.7580094340850007} | train loss {'Reaction outcome loss': 0.7587640223504319, 'Total loss': 0.7587640223504319}
2022-11-22 21:07:08,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:08,637 INFO:     Epoch: 76
2022-11-22 21:07:09,470 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7247344119982286, 'Total loss': 0.7247344119982286} | train loss {'Reaction outcome loss': 0.745523598799218, 'Total loss': 0.745523598799218}
2022-11-22 21:07:09,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:09,471 INFO:     Epoch: 77
2022-11-22 21:07:10,263 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7031168680299412, 'Total loss': 0.7031168680299412} | train loss {'Reaction outcome loss': 0.7499832277099493, 'Total loss': 0.7499832277099493}
2022-11-22 21:07:10,263 INFO:     Found new best model at epoch 77
2022-11-22 21:07:10,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:10,264 INFO:     Epoch: 78
2022-11-22 21:07:11,095 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7080730816180055, 'Total loss': 0.7080730816180055} | train loss {'Reaction outcome loss': 0.7420194594242312, 'Total loss': 0.7420194594242312}
2022-11-22 21:07:11,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:11,095 INFO:     Epoch: 79
2022-11-22 21:07:11,924 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7093916813080962, 'Total loss': 0.7093916813080962} | train loss {'Reaction outcome loss': 0.7438497517393668, 'Total loss': 0.7438497517393668}
2022-11-22 21:07:11,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:11,925 INFO:     Epoch: 80
2022-11-22 21:07:12,763 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7521836087107658, 'Total loss': 0.7521836087107658} | train loss {'Reaction outcome loss': 0.7420818909459751, 'Total loss': 0.7420818909459751}
2022-11-22 21:07:12,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:12,764 INFO:     Epoch: 81
2022-11-22 21:07:13,551 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7727860564535315, 'Total loss': 0.7727860564535315} | train loss {'Reaction outcome loss': 0.737612855337892, 'Total loss': 0.737612855337892}
2022-11-22 21:07:13,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:13,551 INFO:     Epoch: 82
2022-11-22 21:07:14,360 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7084894458001311, 'Total loss': 0.7084894458001311} | train loss {'Reaction outcome loss': 0.747340303321599, 'Total loss': 0.747340303321599}
2022-11-22 21:07:14,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:14,360 INFO:     Epoch: 83
2022-11-22 21:07:15,196 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7075073448094454, 'Total loss': 0.7075073448094454} | train loss {'Reaction outcome loss': 0.7438548847143105, 'Total loss': 0.7438548847143105}
2022-11-22 21:07:15,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:15,198 INFO:     Epoch: 84
2022-11-22 21:07:16,042 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7342373945496299, 'Total loss': 0.7342373945496299} | train loss {'Reaction outcome loss': 0.7304471244937495, 'Total loss': 0.7304471244937495}
2022-11-22 21:07:16,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:16,043 INFO:     Epoch: 85
2022-11-22 21:07:16,875 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6930229487744245, 'Total loss': 0.6930229487744245} | train loss {'Reaction outcome loss': 0.7355969848360128, 'Total loss': 0.7355969848360128}
2022-11-22 21:07:16,875 INFO:     Found new best model at epoch 85
2022-11-22 21:07:16,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:16,876 INFO:     Epoch: 86
2022-11-22 21:07:17,724 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.73041602156379, 'Total loss': 0.73041602156379} | train loss {'Reaction outcome loss': 0.73640098347355, 'Total loss': 0.73640098347355}
2022-11-22 21:07:17,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:17,724 INFO:     Epoch: 87
2022-11-22 21:07:18,537 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7316965697841211, 'Total loss': 0.7316965697841211} | train loss {'Reaction outcome loss': 0.7427789573727349, 'Total loss': 0.7427789573727349}
2022-11-22 21:07:18,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:18,538 INFO:     Epoch: 88
2022-11-22 21:07:19,329 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7252080982381647, 'Total loss': 0.7252080982381647} | train loss {'Reaction outcome loss': 0.7348469388388429, 'Total loss': 0.7348469388388429}
2022-11-22 21:07:19,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:19,330 INFO:     Epoch: 89
2022-11-22 21:07:20,160 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7375299469991163, 'Total loss': 0.7375299469991163} | train loss {'Reaction outcome loss': 0.7300196145227563, 'Total loss': 0.7300196145227563}
2022-11-22 21:07:20,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:20,160 INFO:     Epoch: 90
2022-11-22 21:07:21,027 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6872684298591181, 'Total loss': 0.6872684298591181} | train loss {'Reaction outcome loss': 0.7174639924455751, 'Total loss': 0.7174639924455751}
2022-11-22 21:07:21,027 INFO:     Found new best model at epoch 90
2022-11-22 21:07:21,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:21,028 INFO:     Epoch: 91
2022-11-22 21:07:21,848 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7007538750767708, 'Total loss': 0.7007538750767708} | train loss {'Reaction outcome loss': 0.7304972706415392, 'Total loss': 0.7304972706415392}
2022-11-22 21:07:21,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:21,849 INFO:     Epoch: 92
2022-11-22 21:07:22,677 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.706192588264292, 'Total loss': 0.706192588264292} | train loss {'Reaction outcome loss': 0.7350424470206504, 'Total loss': 0.7350424470206504}
2022-11-22 21:07:22,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:22,677 INFO:     Epoch: 93
2022-11-22 21:07:23,453 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6877663149075075, 'Total loss': 0.6877663149075075} | train loss {'Reaction outcome loss': 0.7262611380714153, 'Total loss': 0.7262611380714153}
2022-11-22 21:07:23,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:23,454 INFO:     Epoch: 94
2022-11-22 21:07:24,261 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6909003440629352, 'Total loss': 0.6909003440629352} | train loss {'Reaction outcome loss': 0.7272365470888161, 'Total loss': 0.7272365470888161}
2022-11-22 21:07:24,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:24,262 INFO:     Epoch: 95
2022-11-22 21:07:25,056 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7195681174370375, 'Total loss': 0.7195681174370375} | train loss {'Reaction outcome loss': 0.7337658519928272, 'Total loss': 0.7337658519928272}
2022-11-22 21:07:25,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:25,056 INFO:     Epoch: 96
2022-11-22 21:07:25,875 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7143417400392619, 'Total loss': 0.7143417400392619} | train loss {'Reaction outcome loss': 0.7320319931758078, 'Total loss': 0.7320319931758078}
2022-11-22 21:07:25,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:25,875 INFO:     Epoch: 97
2022-11-22 21:07:26,690 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7092425586147741, 'Total loss': 0.7092425586147741} | train loss {'Reaction outcome loss': 0.7225226071561396, 'Total loss': 0.7225226071561396}
2022-11-22 21:07:26,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:26,690 INFO:     Epoch: 98
2022-11-22 21:07:27,492 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.72618900408799, 'Total loss': 0.72618900408799} | train loss {'Reaction outcome loss': 0.7343771345460945, 'Total loss': 0.7343771345460945}
2022-11-22 21:07:27,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:27,493 INFO:     Epoch: 99
2022-11-22 21:07:28,282 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7150236551057209, 'Total loss': 0.7150236551057209} | train loss {'Reaction outcome loss': 0.7297468659607506, 'Total loss': 0.7297468659607506}
2022-11-22 21:07:28,283 INFO:     Best model found after epoch 91 of 100.
2022-11-22 21:07:28,283 INFO:   Done with stage: TRAINING
2022-11-22 21:07:28,283 INFO:   Starting stage: EVALUATION
2022-11-22 21:07:28,402 INFO:   Done with stage: EVALUATION
2022-11-22 21:07:28,403 INFO:   Leaving out SEQ value Fold_5
2022-11-22 21:07:28,416 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 21:07:28,416 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:07:29,098 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:07:29,098 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:07:29,171 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:07:29,171 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:07:29,171 INFO:     No hyperparam tuning for this model
2022-11-22 21:07:29,171 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:07:29,171 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:07:29,172 INFO:     None feature selector for col prot
2022-11-22 21:07:29,172 INFO:     None feature selector for col prot
2022-11-22 21:07:29,172 INFO:     None feature selector for col prot
2022-11-22 21:07:29,173 INFO:     None feature selector for col chem
2022-11-22 21:07:29,173 INFO:     None feature selector for col chem
2022-11-22 21:07:29,173 INFO:     None feature selector for col chem
2022-11-22 21:07:29,173 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:07:29,173 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:07:29,175 INFO:     Number of params in model 126091
2022-11-22 21:07:29,178 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:07:29,178 INFO:   Starting stage: TRAINING
2022-11-22 21:07:29,229 INFO:     Val loss before train {'Reaction outcome loss': 1.056910434907133, 'Total loss': 1.056910434907133}
2022-11-22 21:07:29,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:29,229 INFO:     Epoch: 0
2022-11-22 21:07:30,023 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.912315393036062, 'Total loss': 0.912315393036062} | train loss {'Reaction outcome loss': 0.8853045858834919, 'Total loss': 0.8853045858834919}
2022-11-22 21:07:30,023 INFO:     Found new best model at epoch 0
2022-11-22 21:07:30,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:30,024 INFO:     Epoch: 1
2022-11-22 21:07:30,815 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9130591045726429, 'Total loss': 0.9130591045726429} | train loss {'Reaction outcome loss': 0.8453501216795763, 'Total loss': 0.8453501216795763}
2022-11-22 21:07:30,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:30,816 INFO:     Epoch: 2
2022-11-22 21:07:31,650 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9063736904751171, 'Total loss': 0.9063736904751171} | train loss {'Reaction outcome loss': 0.8356108204555898, 'Total loss': 0.8356108204555898}
2022-11-22 21:07:31,651 INFO:     Found new best model at epoch 2
2022-11-22 21:07:31,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:31,651 INFO:     Epoch: 3
2022-11-22 21:07:32,454 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8666764877059243, 'Total loss': 0.8666764877059243} | train loss {'Reaction outcome loss': 0.8208105745404838, 'Total loss': 0.8208105745404838}
2022-11-22 21:07:32,454 INFO:     Found new best model at epoch 3
2022-11-22 21:07:32,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:32,455 INFO:     Epoch: 4
2022-11-22 21:07:33,301 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8772344291210175, 'Total loss': 0.8772344291210175} | train loss {'Reaction outcome loss': 0.8106698502413174, 'Total loss': 0.8106698502413174}
2022-11-22 21:07:33,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:33,301 INFO:     Epoch: 5
2022-11-22 21:07:34,113 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.872260490601713, 'Total loss': 0.872260490601713} | train loss {'Reaction outcome loss': 0.8141501491610338, 'Total loss': 0.8141501491610338}
2022-11-22 21:07:34,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:34,114 INFO:     Epoch: 6
2022-11-22 21:07:34,917 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8599838993766091, 'Total loss': 0.8599838993766091} | train loss {'Reaction outcome loss': 0.8124502951558302, 'Total loss': 0.8124502951558302}
2022-11-22 21:07:34,917 INFO:     Found new best model at epoch 6
2022-11-22 21:07:34,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:34,918 INFO:     Epoch: 7
2022-11-22 21:07:35,697 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8433829356323589, 'Total loss': 0.8433829356323589} | train loss {'Reaction outcome loss': 0.8082179828935306, 'Total loss': 0.8082179828935306}
2022-11-22 21:07:35,698 INFO:     Found new best model at epoch 7
2022-11-22 21:07:35,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:35,699 INFO:     Epoch: 8
2022-11-22 21:07:36,527 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8565314181826331, 'Total loss': 0.8565314181826331} | train loss {'Reaction outcome loss': 0.81347028301795, 'Total loss': 0.81347028301795}
2022-11-22 21:07:36,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:36,528 INFO:     Epoch: 9
2022-11-22 21:07:37,310 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8471693979068236, 'Total loss': 0.8471693979068236} | train loss {'Reaction outcome loss': 0.8039269514894678, 'Total loss': 0.8039269514894678}
2022-11-22 21:07:37,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:37,311 INFO:     Epoch: 10
2022-11-22 21:07:38,074 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.842499705878171, 'Total loss': 0.842499705878171} | train loss {'Reaction outcome loss': 0.8014759174001361, 'Total loss': 0.8014759174001361}
2022-11-22 21:07:38,074 INFO:     Found new best model at epoch 10
2022-11-22 21:07:38,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:38,075 INFO:     Epoch: 11
2022-11-22 21:07:38,849 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8670581403103742, 'Total loss': 0.8670581403103742} | train loss {'Reaction outcome loss': 0.8050875106321173, 'Total loss': 0.8050875106321173}
2022-11-22 21:07:38,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:38,850 INFO:     Epoch: 12
2022-11-22 21:07:39,674 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8420009321787141, 'Total loss': 0.8420009321787141} | train loss {'Reaction outcome loss': 0.7990968702474104, 'Total loss': 0.7990968702474104}
2022-11-22 21:07:39,674 INFO:     Found new best model at epoch 12
2022-11-22 21:07:39,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:39,675 INFO:     Epoch: 13
2022-11-22 21:07:40,463 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8316646936264905, 'Total loss': 0.8316646936264905} | train loss {'Reaction outcome loss': 0.8081929133488581, 'Total loss': 0.8081929133488581}
2022-11-22 21:07:40,463 INFO:     Found new best model at epoch 13
2022-11-22 21:07:40,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:40,464 INFO:     Epoch: 14
2022-11-22 21:07:41,284 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8291131528941068, 'Total loss': 0.8291131528941068} | train loss {'Reaction outcome loss': 0.8066502060243476, 'Total loss': 0.8066502060243476}
2022-11-22 21:07:41,284 INFO:     Found new best model at epoch 14
2022-11-22 21:07:41,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:41,285 INFO:     Epoch: 15
2022-11-22 21:07:42,108 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8278413875536486, 'Total loss': 0.8278413875536486} | train loss {'Reaction outcome loss': 0.812343920049397, 'Total loss': 0.812343920049397}
2022-11-22 21:07:42,108 INFO:     Found new best model at epoch 15
2022-11-22 21:07:42,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:42,109 INFO:     Epoch: 16
2022-11-22 21:07:42,891 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8390280922705476, 'Total loss': 0.8390280922705476} | train loss {'Reaction outcome loss': 0.7991962400887177, 'Total loss': 0.7991962400887177}
2022-11-22 21:07:42,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:42,891 INFO:     Epoch: 17
2022-11-22 21:07:43,708 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8378508504141461, 'Total loss': 0.8378508504141461} | train loss {'Reaction outcome loss': 0.7918784294111526, 'Total loss': 0.7918784294111526}
2022-11-22 21:07:43,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:43,709 INFO:     Epoch: 18
2022-11-22 21:07:44,482 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8625431860035117, 'Total loss': 0.8625431860035117} | train loss {'Reaction outcome loss': 0.7975751357643228, 'Total loss': 0.7975751357643228}
2022-11-22 21:07:44,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:44,482 INFO:     Epoch: 19
2022-11-22 21:07:45,262 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8165233880281448, 'Total loss': 0.8165233880281448} | train loss {'Reaction outcome loss': 0.7949905770148343, 'Total loss': 0.7949905770148343}
2022-11-22 21:07:45,262 INFO:     Found new best model at epoch 19
2022-11-22 21:07:45,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:45,263 INFO:     Epoch: 20
2022-11-22 21:07:46,061 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8508258387446404, 'Total loss': 0.8508258387446404} | train loss {'Reaction outcome loss': 0.8045271324966601, 'Total loss': 0.8045271324966601}
2022-11-22 21:07:46,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:46,062 INFO:     Epoch: 21
2022-11-22 21:07:46,844 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.838583301414143, 'Total loss': 0.838583301414143} | train loss {'Reaction outcome loss': 0.7960989559710268, 'Total loss': 0.7960989559710268}
2022-11-22 21:07:46,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:46,845 INFO:     Epoch: 22
2022-11-22 21:07:47,605 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8599927709861235, 'Total loss': 0.8599927709861235} | train loss {'Reaction outcome loss': 0.7948965458915784, 'Total loss': 0.7948965458915784}
2022-11-22 21:07:47,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:47,606 INFO:     Epoch: 23
2022-11-22 21:07:48,379 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8261476253921335, 'Total loss': 0.8261476253921335} | train loss {'Reaction outcome loss': 0.7921325435884569, 'Total loss': 0.7921325435884569}
2022-11-22 21:07:48,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:48,379 INFO:     Epoch: 24
2022-11-22 21:07:49,174 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8178093074397608, 'Total loss': 0.8178093074397608} | train loss {'Reaction outcome loss': 0.7924908936506341, 'Total loss': 0.7924908936506341}
2022-11-22 21:07:49,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:49,174 INFO:     Epoch: 25
2022-11-22 21:07:49,963 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.843594725836407, 'Total loss': 0.843594725836407} | train loss {'Reaction outcome loss': 0.7948997672270184, 'Total loss': 0.7948997672270184}
2022-11-22 21:07:49,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:49,964 INFO:     Epoch: 26
2022-11-22 21:07:50,770 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8173784058202397, 'Total loss': 0.8173784058202397} | train loss {'Reaction outcome loss': 0.7962148480328471, 'Total loss': 0.7962148480328471}
2022-11-22 21:07:50,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:50,770 INFO:     Epoch: 27
2022-11-22 21:07:51,544 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8582550971345468, 'Total loss': 0.8582550971345468} | train loss {'Reaction outcome loss': 0.796362217621282, 'Total loss': 0.796362217621282}
2022-11-22 21:07:51,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:51,544 INFO:     Epoch: 28
2022-11-22 21:07:52,299 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.810093682597984, 'Total loss': 0.810093682597984} | train loss {'Reaction outcome loss': 0.7883835430087348, 'Total loss': 0.7883835430087348}
2022-11-22 21:07:52,299 INFO:     Found new best model at epoch 28
2022-11-22 21:07:52,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:52,300 INFO:     Epoch: 29
2022-11-22 21:07:53,117 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8251105086369948, 'Total loss': 0.8251105086369948} | train loss {'Reaction outcome loss': 0.7883528837790856, 'Total loss': 0.7883528837790856}
2022-11-22 21:07:53,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:53,117 INFO:     Epoch: 30
2022-11-22 21:07:53,961 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8158402090722864, 'Total loss': 0.8158402090722864} | train loss {'Reaction outcome loss': 0.7904589460023984, 'Total loss': 0.7904589460023984}
2022-11-22 21:07:53,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:53,961 INFO:     Epoch: 31
2022-11-22 21:07:54,741 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8327662646770477, 'Total loss': 0.8327662646770477} | train loss {'Reaction outcome loss': 0.7913370798473899, 'Total loss': 0.7913370798473899}
2022-11-22 21:07:54,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:54,742 INFO:     Epoch: 32
2022-11-22 21:07:55,508 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8704507140950724, 'Total loss': 0.8704507140950724} | train loss {'Reaction outcome loss': 0.796260983234475, 'Total loss': 0.796260983234475}
2022-11-22 21:07:55,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:55,508 INFO:     Epoch: 33
2022-11-22 21:07:56,267 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8535186783833937, 'Total loss': 0.8535186783833937} | train loss {'Reaction outcome loss': 0.8003834054055001, 'Total loss': 0.8003834054055001}
2022-11-22 21:07:56,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:56,267 INFO:     Epoch: 34
2022-11-22 21:07:57,092 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8272957767952572, 'Total loss': 0.8272957767952572} | train loss {'Reaction outcome loss': 0.7921661627799393, 'Total loss': 0.7921661627799393}
2022-11-22 21:07:57,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:57,092 INFO:     Epoch: 35
2022-11-22 21:07:57,892 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8265734260732477, 'Total loss': 0.8265734260732477} | train loss {'Reaction outcome loss': 0.7976844075479006, 'Total loss': 0.7976844075479006}
2022-11-22 21:07:57,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:57,893 INFO:     Epoch: 36
2022-11-22 21:07:58,675 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8153371282599189, 'Total loss': 0.8153371282599189} | train loss {'Reaction outcome loss': 0.7913702435580342, 'Total loss': 0.7913702435580342}
2022-11-22 21:07:58,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:58,675 INFO:     Epoch: 37
2022-11-22 21:07:59,446 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8176627619699999, 'Total loss': 0.8176627619699999} | train loss {'Reaction outcome loss': 0.7914852224863492, 'Total loss': 0.7914852224863492}
2022-11-22 21:07:59,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:07:59,446 INFO:     Epoch: 38
2022-11-22 21:08:00,223 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8244202055714347, 'Total loss': 0.8244202055714347} | train loss {'Reaction outcome loss': 0.8019310401277504, 'Total loss': 0.8019310401277504}
2022-11-22 21:08:00,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:00,223 INFO:     Epoch: 39
2022-11-22 21:08:00,959 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8172378282655369, 'Total loss': 0.8172378282655369} | train loss {'Reaction outcome loss': 0.7933730135562449, 'Total loss': 0.7933730135562449}
2022-11-22 21:08:00,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:00,959 INFO:     Epoch: 40
2022-11-22 21:08:01,772 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8399342975833199, 'Total loss': 0.8399342975833199} | train loss {'Reaction outcome loss': 0.7966503342877516, 'Total loss': 0.7966503342877516}
2022-11-22 21:08:01,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:01,772 INFO:     Epoch: 41
2022-11-22 21:08:02,561 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8346240852366794, 'Total loss': 0.8346240852366794} | train loss {'Reaction outcome loss': 0.7969823403638384, 'Total loss': 0.7969823403638384}
2022-11-22 21:08:02,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:02,561 INFO:     Epoch: 42
2022-11-22 21:08:03,331 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8438629433512688, 'Total loss': 0.8438629433512688} | train loss {'Reaction outcome loss': 0.800351638301664, 'Total loss': 0.800351638301664}
2022-11-22 21:08:03,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:03,331 INFO:     Epoch: 43
2022-11-22 21:08:04,095 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8439187001098286, 'Total loss': 0.8439187001098286} | train loss {'Reaction outcome loss': 0.7975375628181798, 'Total loss': 0.7975375628181798}
2022-11-22 21:08:04,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:04,096 INFO:     Epoch: 44
2022-11-22 21:08:04,869 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8929633288220926, 'Total loss': 0.8929633288220926} | train loss {'Reaction outcome loss': 0.7898160942456862, 'Total loss': 0.7898160942456862}
2022-11-22 21:08:04,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:04,870 INFO:     Epoch: 45
2022-11-22 21:08:05,624 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8238546162505042, 'Total loss': 0.8238546162505042} | train loss {'Reaction outcome loss': 0.7843443472617069, 'Total loss': 0.7843443472617069}
2022-11-22 21:08:05,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:05,625 INFO:     Epoch: 46
2022-11-22 21:08:06,360 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8381041017445651, 'Total loss': 0.8381041017445651} | train loss {'Reaction outcome loss': 0.7901864574264418, 'Total loss': 0.7901864574264418}
2022-11-22 21:08:06,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:06,360 INFO:     Epoch: 47
2022-11-22 21:08:07,092 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8466993841257963, 'Total loss': 0.8466993841257963} | train loss {'Reaction outcome loss': 0.7985953593302352, 'Total loss': 0.7985953593302352}
2022-11-22 21:08:07,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:07,092 INFO:     Epoch: 48
2022-11-22 21:08:07,838 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8194064768877897, 'Total loss': 0.8194064768877897} | train loss {'Reaction outcome loss': 0.7962832707263198, 'Total loss': 0.7962832707263198}
2022-11-22 21:08:07,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:07,838 INFO:     Epoch: 49
2022-11-22 21:08:08,599 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8537626185200431, 'Total loss': 0.8537626185200431} | train loss {'Reaction outcome loss': 0.7848678058699557, 'Total loss': 0.7848678058699557}
2022-11-22 21:08:08,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:08,599 INFO:     Epoch: 50
2022-11-22 21:08:09,327 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8251687647266821, 'Total loss': 0.8251687647266821} | train loss {'Reaction outcome loss': 0.7983615315153532, 'Total loss': 0.7983615315153532}
2022-11-22 21:08:09,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:09,328 INFO:     Epoch: 51
2022-11-22 21:08:10,094 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8548555265773427, 'Total loss': 0.8548555265773427} | train loss {'Reaction outcome loss': 0.8143514873769119, 'Total loss': 0.8143514873769119}
2022-11-22 21:08:10,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:10,095 INFO:     Epoch: 52
2022-11-22 21:08:10,866 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8179438249631361, 'Total loss': 0.8179438249631361} | train loss {'Reaction outcome loss': 0.7985685793494406, 'Total loss': 0.7985685793494406}
2022-11-22 21:08:10,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:10,867 INFO:     Epoch: 53
2022-11-22 21:08:11,639 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8093075901269913, 'Total loss': 0.8093075901269913} | train loss {'Reaction outcome loss': 0.7806477773829028, 'Total loss': 0.7806477773829028}
2022-11-22 21:08:11,639 INFO:     Found new best model at epoch 53
2022-11-22 21:08:11,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:11,640 INFO:     Epoch: 54
2022-11-22 21:08:12,427 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8530390946702524, 'Total loss': 0.8530390946702524} | train loss {'Reaction outcome loss': 0.7917098713065931, 'Total loss': 0.7917098713065931}
2022-11-22 21:08:12,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:12,427 INFO:     Epoch: 55
2022-11-22 21:08:13,172 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8325836604291742, 'Total loss': 0.8325836604291742} | train loss {'Reaction outcome loss': 0.7945998605446294, 'Total loss': 0.7945998605446294}
2022-11-22 21:08:13,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:13,173 INFO:     Epoch: 56
2022-11-22 21:08:13,951 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8239656964486296, 'Total loss': 0.8239656964486296} | train loss {'Reaction outcome loss': 0.7947086636957369, 'Total loss': 0.7947086636957369}
2022-11-22 21:08:13,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:13,951 INFO:     Epoch: 57
2022-11-22 21:08:14,689 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8162700188430873, 'Total loss': 0.8162700188430873} | train loss {'Reaction outcome loss': 0.7844154848019603, 'Total loss': 0.7844154848019603}
2022-11-22 21:08:14,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:14,689 INFO:     Epoch: 58
2022-11-22 21:08:15,442 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8216129778461023, 'Total loss': 0.8216129778461023} | train loss {'Reaction outcome loss': 0.7918918530950662, 'Total loss': 0.7918918530950662}
2022-11-22 21:08:15,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:15,442 INFO:     Epoch: 59
2022-11-22 21:08:16,221 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8707323372364044, 'Total loss': 0.8707323372364044} | train loss {'Reaction outcome loss': 0.7804130742454577, 'Total loss': 0.7804130742454577}
2022-11-22 21:08:16,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:16,221 INFO:     Epoch: 60
2022-11-22 21:08:16,966 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8331690952181816, 'Total loss': 0.8331690952181816} | train loss {'Reaction outcome loss': 0.7893060582128131, 'Total loss': 0.7893060582128131}
2022-11-22 21:08:16,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:16,967 INFO:     Epoch: 61
2022-11-22 21:08:17,740 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8364693495360288, 'Total loss': 0.8364693495360288} | train loss {'Reaction outcome loss': 0.7859230297297118, 'Total loss': 0.7859230297297118}
2022-11-22 21:08:17,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:17,740 INFO:     Epoch: 62
2022-11-22 21:08:18,521 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8099595884030516, 'Total loss': 0.8099595884030516} | train loss {'Reaction outcome loss': 0.7882024037089908, 'Total loss': 0.7882024037089908}
2022-11-22 21:08:18,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:18,521 INFO:     Epoch: 63
2022-11-22 21:08:19,288 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8487822576002642, 'Total loss': 0.8487822576002642} | train loss {'Reaction outcome loss': 0.7882757459574865, 'Total loss': 0.7882757459574865}
2022-11-22 21:08:19,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:19,288 INFO:     Epoch: 64
2022-11-22 21:08:20,044 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8299921066923575, 'Total loss': 0.8299921066923575} | train loss {'Reaction outcome loss': 0.796661166768325, 'Total loss': 0.796661166768325}
2022-11-22 21:08:20,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:20,044 INFO:     Epoch: 65
2022-11-22 21:08:20,826 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8046357983892615, 'Total loss': 0.8046357983892615} | train loss {'Reaction outcome loss': 0.7869920150229806, 'Total loss': 0.7869920150229806}
2022-11-22 21:08:20,827 INFO:     Found new best model at epoch 65
2022-11-22 21:08:20,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:20,827 INFO:     Epoch: 66
2022-11-22 21:08:21,544 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.837004654109478, 'Total loss': 0.837004654109478} | train loss {'Reaction outcome loss': 0.7852072663876691, 'Total loss': 0.7852072663876691}
2022-11-22 21:08:21,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:21,544 INFO:     Epoch: 67
2022-11-22 21:08:22,300 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8291736556725069, 'Total loss': 0.8291736556725069} | train loss {'Reaction outcome loss': 0.7907622165766804, 'Total loss': 0.7907622165766804}
2022-11-22 21:08:22,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:22,300 INFO:     Epoch: 68
2022-11-22 21:08:23,028 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.821855438026515, 'Total loss': 0.821855438026515} | train loss {'Reaction outcome loss': 0.7829896769060297, 'Total loss': 0.7829896769060297}
2022-11-22 21:08:23,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:23,029 INFO:     Epoch: 69
2022-11-22 21:08:23,797 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8294303755868565, 'Total loss': 0.8294303755868565} | train loss {'Reaction outcome loss': 0.7799589690650522, 'Total loss': 0.7799589690650522}
2022-11-22 21:08:23,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:23,797 INFO:     Epoch: 70
2022-11-22 21:08:24,544 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8107896772297946, 'Total loss': 0.8107896772297946} | train loss {'Reaction outcome loss': 0.786904606621275, 'Total loss': 0.786904606621275}
2022-11-22 21:08:24,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:24,544 INFO:     Epoch: 71
2022-11-22 21:08:25,257 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8138539547269995, 'Total loss': 0.8138539547269995} | train loss {'Reaction outcome loss': 0.7845533001519408, 'Total loss': 0.7845533001519408}
2022-11-22 21:08:25,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:25,258 INFO:     Epoch: 72
2022-11-22 21:08:25,975 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8154939948157831, 'Total loss': 0.8154939948157831} | train loss {'Reaction outcome loss': 0.7765527389159328, 'Total loss': 0.7765527389159328}
2022-11-22 21:08:25,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:25,976 INFO:     Epoch: 73
2022-11-22 21:08:26,743 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8132864717732776, 'Total loss': 0.8132864717732776} | train loss {'Reaction outcome loss': 0.7861509533063603, 'Total loss': 0.7861509533063603}
2022-11-22 21:08:26,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:26,743 INFO:     Epoch: 74
2022-11-22 21:08:27,541 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8243267102675005, 'Total loss': 0.8243267102675005} | train loss {'Reaction outcome loss': 0.7872176510602357, 'Total loss': 0.7872176510602357}
2022-11-22 21:08:27,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:27,542 INFO:     Epoch: 75
2022-11-22 21:08:28,285 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8274837000803514, 'Total loss': 0.8274837000803514} | train loss {'Reaction outcome loss': 0.7899195749750022, 'Total loss': 0.7899195749750022}
2022-11-22 21:08:28,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:28,285 INFO:     Epoch: 76
2022-11-22 21:08:29,053 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8155711421912367, 'Total loss': 0.8155711421912367} | train loss {'Reaction outcome loss': 0.7804938564416368, 'Total loss': 0.7804938564416368}
2022-11-22 21:08:29,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:29,053 INFO:     Epoch: 77
2022-11-22 21:08:29,823 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8143772509965029, 'Total loss': 0.8143772509965029} | train loss {'Reaction outcome loss': 0.7753093561180208, 'Total loss': 0.7753093561180208}
2022-11-22 21:08:29,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:29,824 INFO:     Epoch: 78
2022-11-22 21:08:30,589 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.813676355914636, 'Total loss': 0.813676355914636} | train loss {'Reaction outcome loss': 0.7740214955710206, 'Total loss': 0.7740214955710206}
2022-11-22 21:08:30,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:30,590 INFO:     Epoch: 79
2022-11-22 21:08:31,318 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8163264840841293, 'Total loss': 0.8163264840841293} | train loss {'Reaction outcome loss': 0.7719039569499522, 'Total loss': 0.7719039569499522}
2022-11-22 21:08:31,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:31,318 INFO:     Epoch: 80
2022-11-22 21:08:32,043 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8146481751040979, 'Total loss': 0.8146481751040979} | train loss {'Reaction outcome loss': 0.7723461095138118, 'Total loss': 0.7723461095138118}
2022-11-22 21:08:32,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:32,044 INFO:     Epoch: 81
2022-11-22 21:08:32,807 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.838465534827926, 'Total loss': 0.838465534827926} | train loss {'Reaction outcome loss': 0.767407416452763, 'Total loss': 0.767407416452763}
2022-11-22 21:08:32,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:32,807 INFO:     Epoch: 82
2022-11-22 21:08:33,499 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8284417871724475, 'Total loss': 0.8284417871724475} | train loss {'Reaction outcome loss': 0.7668809990892526, 'Total loss': 0.7668809990892526}
2022-11-22 21:08:33,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:33,500 INFO:     Epoch: 83
2022-11-22 21:08:34,292 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7941830733960326, 'Total loss': 0.7941830733960326} | train loss {'Reaction outcome loss': 0.7625795798263086, 'Total loss': 0.7625795798263086}
2022-11-22 21:08:34,292 INFO:     Found new best model at epoch 83
2022-11-22 21:08:34,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:34,293 INFO:     Epoch: 84
2022-11-22 21:08:35,057 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.778344299305569, 'Total loss': 0.778344299305569} | train loss {'Reaction outcome loss': 0.7543691021921904, 'Total loss': 0.7543691021921904}
2022-11-22 21:08:35,058 INFO:     Found new best model at epoch 84
2022-11-22 21:08:35,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:35,060 INFO:     Epoch: 85
2022-11-22 21:08:35,805 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8051888068968599, 'Total loss': 0.8051888068968599} | train loss {'Reaction outcome loss': 0.7538570954732084, 'Total loss': 0.7538570954732084}
2022-11-22 21:08:35,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:35,805 INFO:     Epoch: 86
2022-11-22 21:08:36,576 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8204377659342506, 'Total loss': 0.8204377659342506} | train loss {'Reaction outcome loss': 0.7599039421631739, 'Total loss': 0.7599039421631739}
2022-11-22 21:08:36,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:36,576 INFO:     Epoch: 87
2022-11-22 21:08:37,382 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7910248379815709, 'Total loss': 0.7910248379815709} | train loss {'Reaction outcome loss': 0.7567705816102896, 'Total loss': 0.7567705816102896}
2022-11-22 21:08:37,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:37,382 INFO:     Epoch: 88
2022-11-22 21:08:38,178 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7806946662339297, 'Total loss': 0.7806946662339297} | train loss {'Reaction outcome loss': 0.7573092623278197, 'Total loss': 0.7573092623278197}
2022-11-22 21:08:38,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:38,178 INFO:     Epoch: 89
2022-11-22 21:08:38,962 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8155024681578983, 'Total loss': 0.8155024681578983} | train loss {'Reaction outcome loss': 0.7472366547656928, 'Total loss': 0.7472366547656928}
2022-11-22 21:08:38,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:38,962 INFO:     Epoch: 90
2022-11-22 21:08:39,807 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8408345742659136, 'Total loss': 0.8408345742659136} | train loss {'Reaction outcome loss': 0.7512204227177238, 'Total loss': 0.7512204227177238}
2022-11-22 21:08:39,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:39,808 INFO:     Epoch: 91
2022-11-22 21:08:40,524 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8115725368261337, 'Total loss': 0.8115725368261337} | train loss {'Reaction outcome loss': 0.7522786286195763, 'Total loss': 0.7522786286195763}
2022-11-22 21:08:40,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:40,524 INFO:     Epoch: 92
2022-11-22 21:08:41,257 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7936912720853632, 'Total loss': 0.7936912720853632} | train loss {'Reaction outcome loss': 0.7509534769212669, 'Total loss': 0.7509534769212669}
2022-11-22 21:08:41,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:41,257 INFO:     Epoch: 93
2022-11-22 21:08:41,976 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7999844036319039, 'Total loss': 0.7999844036319039} | train loss {'Reaction outcome loss': 0.7405199641399538, 'Total loss': 0.7405199641399538}
2022-11-22 21:08:41,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:41,976 INFO:     Epoch: 94
2022-11-22 21:08:42,704 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8426594591953538, 'Total loss': 0.8426594591953538} | train loss {'Reaction outcome loss': 0.7349547693121289, 'Total loss': 0.7349547693121289}
2022-11-22 21:08:42,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:42,704 INFO:     Epoch: 95
2022-11-22 21:08:43,549 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7817789458415725, 'Total loss': 0.7817789458415725} | train loss {'Reaction outcome loss': 0.7414433228583471, 'Total loss': 0.7414433228583471}
2022-11-22 21:08:43,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:43,549 INFO:     Epoch: 96
2022-11-22 21:08:44,376 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7690583284605633, 'Total loss': 0.7690583284605633} | train loss {'Reaction outcome loss': 0.7370881991770103, 'Total loss': 0.7370881991770103}
2022-11-22 21:08:44,376 INFO:     Found new best model at epoch 96
2022-11-22 21:08:44,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:44,377 INFO:     Epoch: 97
2022-11-22 21:08:45,135 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7974010130221193, 'Total loss': 0.7974010130221193} | train loss {'Reaction outcome loss': 0.7402514329082087, 'Total loss': 0.7402514329082087}
2022-11-22 21:08:45,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:45,136 INFO:     Epoch: 98
2022-11-22 21:08:45,933 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.775592369789427, 'Total loss': 0.775592369789427} | train loss {'Reaction outcome loss': 0.7363877236119166, 'Total loss': 0.7363877236119166}
2022-11-22 21:08:45,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:45,933 INFO:     Epoch: 99
2022-11-22 21:08:46,764 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7680975449356165, 'Total loss': 0.7680975449356165} | train loss {'Reaction outcome loss': 0.7264194772371396, 'Total loss': 0.7264194772371396}
2022-11-22 21:08:46,764 INFO:     Found new best model at epoch 99
2022-11-22 21:08:46,765 INFO:     Best model found after epoch 100 of 100.
2022-11-22 21:08:46,765 INFO:   Done with stage: TRAINING
2022-11-22 21:08:46,765 INFO:   Starting stage: EVALUATION
2022-11-22 21:08:46,887 INFO:   Done with stage: EVALUATION
2022-11-22 21:08:46,887 INFO:   Leaving out SEQ value Fold_6
2022-11-22 21:08:46,900 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 21:08:46,901 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:08:47,584 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:08:47,585 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:08:47,657 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:08:47,658 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:08:47,658 INFO:     No hyperparam tuning for this model
2022-11-22 21:08:47,658 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:08:47,658 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:08:47,659 INFO:     None feature selector for col prot
2022-11-22 21:08:47,659 INFO:     None feature selector for col prot
2022-11-22 21:08:47,659 INFO:     None feature selector for col prot
2022-11-22 21:08:47,660 INFO:     None feature selector for col chem
2022-11-22 21:08:47,660 INFO:     None feature selector for col chem
2022-11-22 21:08:47,660 INFO:     None feature selector for col chem
2022-11-22 21:08:47,660 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:08:47,660 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:08:47,661 INFO:     Number of params in model 126091
2022-11-22 21:08:47,665 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:08:47,665 INFO:   Starting stage: TRAINING
2022-11-22 21:08:47,716 INFO:     Val loss before train {'Reaction outcome loss': 1.0277555097233166, 'Total loss': 1.0277555097233166}
2022-11-22 21:08:47,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:47,716 INFO:     Epoch: 0
2022-11-22 21:08:48,503 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8789748224345121, 'Total loss': 0.8789748224345121} | train loss {'Reaction outcome loss': 0.8719374589350543, 'Total loss': 0.8719374589350543}
2022-11-22 21:08:48,503 INFO:     Found new best model at epoch 0
2022-11-22 21:08:48,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:48,504 INFO:     Epoch: 1
2022-11-22 21:08:49,324 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8604627732526172, 'Total loss': 0.8604627732526172} | train loss {'Reaction outcome loss': 0.8244148522826583, 'Total loss': 0.8244148522826583}
2022-11-22 21:08:49,324 INFO:     Found new best model at epoch 1
2022-11-22 21:08:49,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:49,325 INFO:     Epoch: 2
2022-11-22 21:08:50,158 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8501313139091838, 'Total loss': 0.8501313139091838} | train loss {'Reaction outcome loss': 0.8274802867217586, 'Total loss': 0.8274802867217586}
2022-11-22 21:08:50,158 INFO:     Found new best model at epoch 2
2022-11-22 21:08:50,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:50,159 INFO:     Epoch: 3
2022-11-22 21:08:50,918 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8283171091567386, 'Total loss': 0.8283171091567386} | train loss {'Reaction outcome loss': 0.8127573303848143, 'Total loss': 0.8127573303848143}
2022-11-22 21:08:50,918 INFO:     Found new best model at epoch 3
2022-11-22 21:08:50,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:50,919 INFO:     Epoch: 4
2022-11-22 21:08:51,746 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8604460399259221, 'Total loss': 0.8604460399259221} | train loss {'Reaction outcome loss': 0.799837316578699, 'Total loss': 0.799837316578699}
2022-11-22 21:08:51,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:51,746 INFO:     Epoch: 5
2022-11-22 21:08:52,539 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8141747076403011, 'Total loss': 0.8141747076403011} | train loss {'Reaction outcome loss': 0.8013068686130076, 'Total loss': 0.8013068686130076}
2022-11-22 21:08:52,539 INFO:     Found new best model at epoch 5
2022-11-22 21:08:52,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:52,540 INFO:     Epoch: 6
2022-11-22 21:08:53,271 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8578699800101194, 'Total loss': 0.8578699800101194} | train loss {'Reaction outcome loss': 0.801009299663397, 'Total loss': 0.801009299663397}
2022-11-22 21:08:53,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:53,272 INFO:     Epoch: 7
2022-11-22 21:08:54,103 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8196621686220169, 'Total loss': 0.8196621686220169} | train loss {'Reaction outcome loss': 0.7921647567015427, 'Total loss': 0.7921647567015427}
2022-11-22 21:08:54,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:54,104 INFO:     Epoch: 8
2022-11-22 21:08:54,959 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8279720930890604, 'Total loss': 0.8279720930890604} | train loss {'Reaction outcome loss': 0.7946470235040796, 'Total loss': 0.7946470235040796}
2022-11-22 21:08:54,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:54,959 INFO:     Epoch: 9
2022-11-22 21:08:55,721 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8495691147717562, 'Total loss': 0.8495691147717562} | train loss {'Reaction outcome loss': 0.7871506797971755, 'Total loss': 0.7871506797971755}
2022-11-22 21:08:55,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:55,721 INFO:     Epoch: 10
2022-11-22 21:08:56,465 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8206169510429556, 'Total loss': 0.8206169510429556} | train loss {'Reaction outcome loss': 0.7928224441252256, 'Total loss': 0.7928224441252256}
2022-11-22 21:08:56,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:56,465 INFO:     Epoch: 11
2022-11-22 21:08:57,276 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8125424920157953, 'Total loss': 0.8125424920157953} | train loss {'Reaction outcome loss': 0.7928957285186057, 'Total loss': 0.7928957285186057}
2022-11-22 21:08:57,276 INFO:     Found new best model at epoch 11
2022-11-22 21:08:57,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:57,277 INFO:     Epoch: 12
2022-11-22 21:08:58,063 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8009087944572623, 'Total loss': 0.8009087944572623} | train loss {'Reaction outcome loss': 0.7911603347613261, 'Total loss': 0.7911603347613261}
2022-11-22 21:08:58,063 INFO:     Found new best model at epoch 12
2022-11-22 21:08:58,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:58,064 INFO:     Epoch: 13
2022-11-22 21:08:58,890 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8078138137405569, 'Total loss': 0.8078138137405569} | train loss {'Reaction outcome loss': 0.7858283777951229, 'Total loss': 0.7858283777951229}
2022-11-22 21:08:58,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:58,891 INFO:     Epoch: 14
2022-11-22 21:08:59,685 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8079932386224921, 'Total loss': 0.8079932386224921} | train loss {'Reaction outcome loss': 0.7806920089008595, 'Total loss': 0.7806920089008595}
2022-11-22 21:08:59,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:08:59,685 INFO:     Epoch: 15
2022-11-22 21:09:00,472 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.814425794238394, 'Total loss': 0.814425794238394} | train loss {'Reaction outcome loss': 0.7783813326947602, 'Total loss': 0.7783813326947602}
2022-11-22 21:09:00,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:00,473 INFO:     Epoch: 16
2022-11-22 21:09:01,306 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8136778202923861, 'Total loss': 0.8136778202923861} | train loss {'Reaction outcome loss': 0.7833459838199229, 'Total loss': 0.7833459838199229}
2022-11-22 21:09:01,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:01,306 INFO:     Epoch: 17
2022-11-22 21:09:02,131 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.841945615681735, 'Total loss': 0.841945615681735} | train loss {'Reaction outcome loss': 0.7816595126712612, 'Total loss': 0.7816595126712612}
2022-11-22 21:09:02,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:02,131 INFO:     Epoch: 18
2022-11-22 21:09:02,950 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8271480453285304, 'Total loss': 0.8271480453285304} | train loss {'Reaction outcome loss': 0.7873435996563328, 'Total loss': 0.7873435996563328}
2022-11-22 21:09:02,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:02,950 INFO:     Epoch: 19
2022-11-22 21:09:03,770 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8216789879582145, 'Total loss': 0.8216789879582145} | train loss {'Reaction outcome loss': 0.7881699562796697, 'Total loss': 0.7881699562796697}
2022-11-22 21:09:03,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:03,770 INFO:     Epoch: 20
2022-11-22 21:09:04,542 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8178163116628473, 'Total loss': 0.8178163116628473} | train loss {'Reaction outcome loss': 0.7819208273520837, 'Total loss': 0.7819208273520837}
2022-11-22 21:09:04,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:04,542 INFO:     Epoch: 21
2022-11-22 21:09:05,324 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8376837332140316, 'Total loss': 0.8376837332140316} | train loss {'Reaction outcome loss': 0.784547965807712, 'Total loss': 0.784547965807712}
2022-11-22 21:09:05,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:05,325 INFO:     Epoch: 22
2022-11-22 21:09:06,128 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8066602288322016, 'Total loss': 0.8066602288322016} | train loss {'Reaction outcome loss': 0.7770559074779452, 'Total loss': 0.7770559074779452}
2022-11-22 21:09:06,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:06,129 INFO:     Epoch: 23
2022-11-22 21:09:06,928 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8011370280926878, 'Total loss': 0.8011370280926878} | train loss {'Reaction outcome loss': 0.7814618299605876, 'Total loss': 0.7814618299605876}
2022-11-22 21:09:06,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:06,928 INFO:     Epoch: 24
2022-11-22 21:09:07,742 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8333909213542938, 'Total loss': 0.8333909213542938} | train loss {'Reaction outcome loss': 0.7795345775994212, 'Total loss': 0.7795345775994212}
2022-11-22 21:09:07,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:07,742 INFO:     Epoch: 25
2022-11-22 21:09:08,591 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8378820338032462, 'Total loss': 0.8378820338032462} | train loss {'Reaction outcome loss': 0.7820351080976518, 'Total loss': 0.7820351080976518}
2022-11-22 21:09:08,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:08,591 INFO:     Epoch: 26
2022-11-22 21:09:09,334 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8415728509426117, 'Total loss': 0.8415728509426117} | train loss {'Reaction outcome loss': 0.7883463010855531, 'Total loss': 0.7883463010855531}
2022-11-22 21:09:09,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:09,334 INFO:     Epoch: 27
2022-11-22 21:09:10,141 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8056383945725181, 'Total loss': 0.8056383945725181} | train loss {'Reaction outcome loss': 0.7815016804919069, 'Total loss': 0.7815016804919069}
2022-11-22 21:09:10,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:10,141 INFO:     Epoch: 28
2022-11-22 21:09:10,914 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8032441701401364, 'Total loss': 0.8032441701401364} | train loss {'Reaction outcome loss': 0.7820846275520711, 'Total loss': 0.7820846275520711}
2022-11-22 21:09:10,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:10,914 INFO:     Epoch: 29
2022-11-22 21:09:11,710 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8169938901608641, 'Total loss': 0.8169938901608641} | train loss {'Reaction outcome loss': 0.7794012673470655, 'Total loss': 0.7794012673470655}
2022-11-22 21:09:11,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:11,710 INFO:     Epoch: 30
2022-11-22 21:09:12,508 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7979227101260965, 'Total loss': 0.7979227101260965} | train loss {'Reaction outcome loss': 0.7753023447898718, 'Total loss': 0.7753023447898718}
2022-11-22 21:09:12,508 INFO:     Found new best model at epoch 30
2022-11-22 21:09:12,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:12,509 INFO:     Epoch: 31
2022-11-22 21:09:13,286 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8475638113238595, 'Total loss': 0.8475638113238595} | train loss {'Reaction outcome loss': 0.7833706118799897, 'Total loss': 0.7833706118799897}
2022-11-22 21:09:13,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:13,286 INFO:     Epoch: 32
2022-11-22 21:09:14,040 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.828760793263262, 'Total loss': 0.828760793263262} | train loss {'Reaction outcome loss': 0.7847882378921818, 'Total loss': 0.7847882378921818}
2022-11-22 21:09:14,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:14,040 INFO:     Epoch: 33
2022-11-22 21:09:14,817 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8219163363630121, 'Total loss': 0.8219163363630121} | train loss {'Reaction outcome loss': 0.7816339466977216, 'Total loss': 0.7816339466977216}
2022-11-22 21:09:14,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:14,817 INFO:     Epoch: 34
2022-11-22 21:09:15,577 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8016308485106989, 'Total loss': 0.8016308485106989} | train loss {'Reaction outcome loss': 0.7916299700737, 'Total loss': 0.7916299700737}
2022-11-22 21:09:15,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:15,577 INFO:     Epoch: 35
2022-11-22 21:09:16,382 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8338040235367689, 'Total loss': 0.8338040235367689} | train loss {'Reaction outcome loss': 0.7765829074177665, 'Total loss': 0.7765829074177665}
2022-11-22 21:09:16,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:16,382 INFO:     Epoch: 36
2022-11-22 21:09:17,193 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8291732140562751, 'Total loss': 0.8291732140562751} | train loss {'Reaction outcome loss': 0.7780940872937562, 'Total loss': 0.7780940872937562}
2022-11-22 21:09:17,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:17,194 INFO:     Epoch: 37
2022-11-22 21:09:17,962 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8082831231030551, 'Total loss': 0.8082831231030551} | train loss {'Reaction outcome loss': 0.802976946719745, 'Total loss': 0.802976946719745}
2022-11-22 21:09:17,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:17,963 INFO:     Epoch: 38
2022-11-22 21:09:18,722 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8147652095014398, 'Total loss': 0.8147652095014398} | train loss {'Reaction outcome loss': 0.7920360732899021, 'Total loss': 0.7920360732899021}
2022-11-22 21:09:18,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:18,722 INFO:     Epoch: 39
2022-11-22 21:09:19,512 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.809818759560585, 'Total loss': 0.809818759560585} | train loss {'Reaction outcome loss': 0.7855179396718137, 'Total loss': 0.7855179396718137}
2022-11-22 21:09:19,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:19,513 INFO:     Epoch: 40
2022-11-22 21:09:20,306 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8242091373963789, 'Total loss': 0.8242091373963789} | train loss {'Reaction outcome loss': 0.7805043245375398, 'Total loss': 0.7805043245375398}
2022-11-22 21:09:20,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:20,306 INFO:     Epoch: 41
2022-11-22 21:09:21,085 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8089347264983437, 'Total loss': 0.8089347264983437} | train loss {'Reaction outcome loss': 0.7896767595277624, 'Total loss': 0.7896767595277624}
2022-11-22 21:09:21,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:21,085 INFO:     Epoch: 42
2022-11-22 21:09:21,874 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8146354027769782, 'Total loss': 0.8146354027769782} | train loss {'Reaction outcome loss': 0.7743095586657042, 'Total loss': 0.7743095586657042}
2022-11-22 21:09:21,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:21,874 INFO:     Epoch: 43
2022-11-22 21:09:22,688 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.822736872190779, 'Total loss': 0.822736872190779} | train loss {'Reaction outcome loss': 0.776890878373312, 'Total loss': 0.776890878373312}
2022-11-22 21:09:22,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:22,689 INFO:     Epoch: 44
2022-11-22 21:09:23,479 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8048014363104646, 'Total loss': 0.8048014363104646} | train loss {'Reaction outcome loss': 0.7811381523667077, 'Total loss': 0.7811381523667077}
2022-11-22 21:09:23,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:23,479 INFO:     Epoch: 45
2022-11-22 21:09:24,238 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8387926518917084, 'Total loss': 0.8387926518917084} | train loss {'Reaction outcome loss': 0.7838090512192684, 'Total loss': 0.7838090512192684}
2022-11-22 21:09:24,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:24,239 INFO:     Epoch: 46
2022-11-22 21:09:25,003 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7945824712514877, 'Total loss': 0.7945824712514877} | train loss {'Reaction outcome loss': 0.778770547284771, 'Total loss': 0.778770547284771}
2022-11-22 21:09:25,003 INFO:     Found new best model at epoch 46
2022-11-22 21:09:25,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:25,004 INFO:     Epoch: 47
2022-11-22 21:09:25,829 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.792160065336661, 'Total loss': 0.792160065336661} | train loss {'Reaction outcome loss': 0.7779651594306776, 'Total loss': 0.7779651594306776}
2022-11-22 21:09:25,830 INFO:     Found new best model at epoch 47
2022-11-22 21:09:25,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:25,831 INFO:     Epoch: 48
2022-11-22 21:09:26,668 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.816168790513819, 'Total loss': 0.816168790513819} | train loss {'Reaction outcome loss': 0.7822776623824348, 'Total loss': 0.7822776623824348}
2022-11-22 21:09:26,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:26,668 INFO:     Epoch: 49
2022-11-22 21:09:27,460 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8694365146485242, 'Total loss': 0.8694365146485242} | train loss {'Reaction outcome loss': 0.7872596264850755, 'Total loss': 0.7872596264850755}
2022-11-22 21:09:27,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:27,460 INFO:     Epoch: 50
2022-11-22 21:09:28,210 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7947639816186645, 'Total loss': 0.7947639816186645} | train loss {'Reaction outcome loss': 0.7796155141915387, 'Total loss': 0.7796155141915387}
2022-11-22 21:09:28,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:28,210 INFO:     Epoch: 51
2022-11-22 21:09:28,961 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7949435399337248, 'Total loss': 0.7949435399337248} | train loss {'Reaction outcome loss': 0.7759605278129037, 'Total loss': 0.7759605278129037}
2022-11-22 21:09:28,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:28,961 INFO:     Epoch: 52
2022-11-22 21:09:29,725 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8026930012486198, 'Total loss': 0.8026930012486198} | train loss {'Reaction outcome loss': 0.7779332507808923, 'Total loss': 0.7779332507808923}
2022-11-22 21:09:29,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:29,726 INFO:     Epoch: 53
2022-11-22 21:09:30,459 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8112265542149544, 'Total loss': 0.8112265542149544} | train loss {'Reaction outcome loss': 0.7708535909894024, 'Total loss': 0.7708535909894024}
2022-11-22 21:09:30,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:30,459 INFO:     Epoch: 54
2022-11-22 21:09:31,253 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7919720147143711, 'Total loss': 0.7919720147143711} | train loss {'Reaction outcome loss': 0.7781892254164344, 'Total loss': 0.7781892254164344}
2022-11-22 21:09:31,253 INFO:     Found new best model at epoch 54
2022-11-22 21:09:31,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:31,254 INFO:     Epoch: 55
2022-11-22 21:09:32,004 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8050142201510343, 'Total loss': 0.8050142201510343} | train loss {'Reaction outcome loss': 0.7779822253022599, 'Total loss': 0.7779822253022599}
2022-11-22 21:09:32,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:32,004 INFO:     Epoch: 56
2022-11-22 21:09:32,815 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8048434494571253, 'Total loss': 0.8048434494571253} | train loss {'Reaction outcome loss': 0.7738108470854972, 'Total loss': 0.7738108470854972}
2022-11-22 21:09:32,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:32,815 INFO:     Epoch: 57
2022-11-22 21:09:33,606 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7990170337937095, 'Total loss': 0.7990170337937095} | train loss {'Reaction outcome loss': 0.7734439389908362, 'Total loss': 0.7734439389908362}
2022-11-22 21:09:33,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:33,606 INFO:     Epoch: 58
2022-11-22 21:09:34,401 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7925160303711891, 'Total loss': 0.7925160303711891} | train loss {'Reaction outcome loss': 0.7799556619725246, 'Total loss': 0.7799556619725246}
2022-11-22 21:09:34,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:34,402 INFO:     Epoch: 59
2022-11-22 21:09:35,176 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8474340730092742, 'Total loss': 0.8474340730092742} | train loss {'Reaction outcome loss': 0.7731763733784679, 'Total loss': 0.7731763733784679}
2022-11-22 21:09:35,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:35,177 INFO:     Epoch: 60
2022-11-22 21:09:35,908 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7937744964252819, 'Total loss': 0.7937744964252819} | train loss {'Reaction outcome loss': 0.789819591320478, 'Total loss': 0.789819591320478}
2022-11-22 21:09:35,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:35,908 INFO:     Epoch: 61
2022-11-22 21:09:36,676 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7978317615660754, 'Total loss': 0.7978317615660754} | train loss {'Reaction outcome loss': 0.7725354227339208, 'Total loss': 0.7725354227339208}
2022-11-22 21:09:36,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:36,677 INFO:     Epoch: 62
2022-11-22 21:09:37,446 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8046148419380188, 'Total loss': 0.8046148419380188} | train loss {'Reaction outcome loss': 0.7702046188748317, 'Total loss': 0.7702046188748317}
2022-11-22 21:09:37,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:37,447 INFO:     Epoch: 63
2022-11-22 21:09:38,194 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8130908154628493, 'Total loss': 0.8130908154628493} | train loss {'Reaction outcome loss': 0.7794070555130962, 'Total loss': 0.7794070555130962}
2022-11-22 21:09:38,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:38,196 INFO:     Epoch: 64
2022-11-22 21:09:38,956 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8465038551525637, 'Total loss': 0.8465038551525637} | train loss {'Reaction outcome loss': 0.7857344158989216, 'Total loss': 0.7857344158989216}
2022-11-22 21:09:38,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:38,957 INFO:     Epoch: 65
2022-11-22 21:09:39,747 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8114711452614177, 'Total loss': 0.8114711452614177} | train loss {'Reaction outcome loss': 0.7835201396633257, 'Total loss': 0.7835201396633257}
2022-11-22 21:09:39,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:39,748 INFO:     Epoch: 66
2022-11-22 21:09:40,526 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.788987623019652, 'Total loss': 0.788987623019652} | train loss {'Reaction outcome loss': 0.7710328046609516, 'Total loss': 0.7710328046609516}
2022-11-22 21:09:40,526 INFO:     Found new best model at epoch 66
2022-11-22 21:09:40,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:40,527 INFO:     Epoch: 67
2022-11-22 21:09:41,319 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8189143260771578, 'Total loss': 0.8189143260771578} | train loss {'Reaction outcome loss': 0.7750613444488541, 'Total loss': 0.7750613444488541}
2022-11-22 21:09:41,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:41,319 INFO:     Epoch: 68
2022-11-22 21:09:42,067 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7943056625398722, 'Total loss': 0.7943056625398722} | train loss {'Reaction outcome loss': 0.7775870023468728, 'Total loss': 0.7775870023468728}
2022-11-22 21:09:42,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:42,067 INFO:     Epoch: 69
2022-11-22 21:09:42,867 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8429950340227648, 'Total loss': 0.8429950340227648} | train loss {'Reaction outcome loss': 0.7707955616447124, 'Total loss': 0.7707955616447124}
2022-11-22 21:09:42,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:42,867 INFO:     Epoch: 70
2022-11-22 21:09:43,663 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8077416094866666, 'Total loss': 0.8077416094866666} | train loss {'Reaction outcome loss': 0.7767937326962165, 'Total loss': 0.7767937326962165}
2022-11-22 21:09:43,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:43,663 INFO:     Epoch: 71
2022-11-22 21:09:44,498 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7965260168368166, 'Total loss': 0.7965260168368166} | train loss {'Reaction outcome loss': 0.7703369518040646, 'Total loss': 0.7703369518040646}
2022-11-22 21:09:44,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:44,499 INFO:     Epoch: 72
2022-11-22 21:09:45,240 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8320945027199659, 'Total loss': 0.8320945027199659} | train loss {'Reaction outcome loss': 0.7691428443409412, 'Total loss': 0.7691428443409412}
2022-11-22 21:09:45,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:45,240 INFO:     Epoch: 73
2022-11-22 21:09:46,031 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.804966463284059, 'Total loss': 0.804966463284059} | train loss {'Reaction outcome loss': 0.7716622755595064, 'Total loss': 0.7716622755595064}
2022-11-22 21:09:46,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:46,031 INFO:     Epoch: 74
2022-11-22 21:09:46,776 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8082795204086737, 'Total loss': 0.8082795204086737} | train loss {'Reaction outcome loss': 0.7774164833520588, 'Total loss': 0.7774164833520588}
2022-11-22 21:09:46,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:46,776 INFO:     Epoch: 75
2022-11-22 21:09:47,532 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7850000655109232, 'Total loss': 0.7850000655109232} | train loss {'Reaction outcome loss': 0.7754429038236981, 'Total loss': 0.7754429038236981}
2022-11-22 21:09:47,533 INFO:     Found new best model at epoch 75
2022-11-22 21:09:47,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:47,534 INFO:     Epoch: 76
2022-11-22 21:09:48,354 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8602094365791841, 'Total loss': 0.8602094365791841} | train loss {'Reaction outcome loss': 0.7687338476600917, 'Total loss': 0.7687338476600917}
2022-11-22 21:09:48,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:48,354 INFO:     Epoch: 77
2022-11-22 21:09:49,123 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7971323843706738, 'Total loss': 0.7971323843706738} | train loss {'Reaction outcome loss': 0.7660271771523633, 'Total loss': 0.7660271771523633}
2022-11-22 21:09:49,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:49,123 INFO:     Epoch: 78
2022-11-22 21:09:49,867 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8157891942696138, 'Total loss': 0.8157891942696138} | train loss {'Reaction outcome loss': 0.7658726504215827, 'Total loss': 0.7658726504215827}
2022-11-22 21:09:49,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:49,867 INFO:     Epoch: 79
2022-11-22 21:09:50,630 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8018797060305421, 'Total loss': 0.8018797060305421} | train loss {'Reaction outcome loss': 0.7794621940325146, 'Total loss': 0.7794621940325146}
2022-11-22 21:09:50,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:50,631 INFO:     Epoch: 80
2022-11-22 21:09:51,382 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7810333743691444, 'Total loss': 0.7810333743691444} | train loss {'Reaction outcome loss': 0.7681632057918228, 'Total loss': 0.7681632057918228}
2022-11-22 21:09:51,382 INFO:     Found new best model at epoch 80
2022-11-22 21:09:51,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:51,383 INFO:     Epoch: 81
2022-11-22 21:09:52,146 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8199082159183242, 'Total loss': 0.8199082159183242} | train loss {'Reaction outcome loss': 0.7690760683916841, 'Total loss': 0.7690760683916841}
2022-11-22 21:09:52,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:52,146 INFO:     Epoch: 82
2022-11-22 21:09:52,877 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7905794402415102, 'Total loss': 0.7905794402415102} | train loss {'Reaction outcome loss': 0.7666443960386732, 'Total loss': 0.7666443960386732}
2022-11-22 21:09:52,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:52,878 INFO:     Epoch: 83
2022-11-22 21:09:53,648 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8134913458065554, 'Total loss': 0.8134913458065554} | train loss {'Reaction outcome loss': 0.7629318503957045, 'Total loss': 0.7629318503957045}
2022-11-22 21:09:53,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:53,648 INFO:     Epoch: 84
2022-11-22 21:09:54,406 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7854995429515839, 'Total loss': 0.7854995429515839} | train loss {'Reaction outcome loss': 0.761790762304777, 'Total loss': 0.761790762304777}
2022-11-22 21:09:54,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:54,407 INFO:     Epoch: 85
2022-11-22 21:09:55,188 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7883516631343148, 'Total loss': 0.7883516631343148} | train loss {'Reaction outcome loss': 0.7649160892012631, 'Total loss': 0.7649160892012631}
2022-11-22 21:09:55,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:55,188 INFO:     Epoch: 86
2022-11-22 21:09:55,947 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7850020920688455, 'Total loss': 0.7850020920688455} | train loss {'Reaction outcome loss': 0.7589441401665269, 'Total loss': 0.7589441401665269}
2022-11-22 21:09:55,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:55,947 INFO:     Epoch: 87
2022-11-22 21:09:56,704 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7846736826679923, 'Total loss': 0.7846736826679923} | train loss {'Reaction outcome loss': 0.761369252373815, 'Total loss': 0.761369252373815}
2022-11-22 21:09:56,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:56,705 INFO:     Epoch: 88
2022-11-22 21:09:57,512 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7955155115235936, 'Total loss': 0.7955155115235936} | train loss {'Reaction outcome loss': 0.7634310659609342, 'Total loss': 0.7634310659609342}
2022-11-22 21:09:57,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:57,512 INFO:     Epoch: 89
2022-11-22 21:09:58,271 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7823070233518427, 'Total loss': 0.7823070233518427} | train loss {'Reaction outcome loss': 0.7583175731393007, 'Total loss': 0.7583175731393007}
2022-11-22 21:09:58,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:58,272 INFO:     Epoch: 90
2022-11-22 21:09:59,006 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.760992515493523, 'Total loss': 0.760992515493523} | train loss {'Reaction outcome loss': 0.7591593984650215, 'Total loss': 0.7591593984650215}
2022-11-22 21:09:59,006 INFO:     Found new best model at epoch 90
2022-11-22 21:09:59,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:59,007 INFO:     Epoch: 91
2022-11-22 21:09:59,780 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7804897779768164, 'Total loss': 0.7804897779768164} | train loss {'Reaction outcome loss': 0.7486721837086233, 'Total loss': 0.7486721837086233}
2022-11-22 21:09:59,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:09:59,780 INFO:     Epoch: 92
2022-11-22 21:10:00,517 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7759625220840628, 'Total loss': 0.7759625220840628} | train loss {'Reaction outcome loss': 0.76152443596226, 'Total loss': 0.76152443596226}
2022-11-22 21:10:00,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:00,517 INFO:     Epoch: 93
2022-11-22 21:10:01,287 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7846468172290109, 'Total loss': 0.7846468172290109} | train loss {'Reaction outcome loss': 0.750590408620564, 'Total loss': 0.750590408620564}
2022-11-22 21:10:01,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:01,287 INFO:     Epoch: 94
2022-11-22 21:10:02,054 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7618268938227133, 'Total loss': 0.7618268938227133} | train loss {'Reaction outcome loss': 0.7478912895628316, 'Total loss': 0.7478912895628316}
2022-11-22 21:10:02,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:02,054 INFO:     Epoch: 95
2022-11-22 21:10:02,795 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7750579599629749, 'Total loss': 0.7750579599629749} | train loss {'Reaction outcome loss': 0.7407408951506441, 'Total loss': 0.7407408951506441}
2022-11-22 21:10:02,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:02,796 INFO:     Epoch: 96
2022-11-22 21:10:03,615 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7934536845846609, 'Total loss': 0.7934536845846609} | train loss {'Reaction outcome loss': 0.7419402751362758, 'Total loss': 0.7419402751362758}
2022-11-22 21:10:03,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:03,615 INFO:     Epoch: 97
2022-11-22 21:10:04,362 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7504423030398109, 'Total loss': 0.7504423030398109} | train loss {'Reaction outcome loss': 0.7330092905232539, 'Total loss': 0.7330092905232539}
2022-11-22 21:10:04,363 INFO:     Found new best model at epoch 97
2022-11-22 21:10:04,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:04,364 INFO:     Epoch: 98
2022-11-22 21:10:05,125 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7594844123179262, 'Total loss': 0.7594844123179262} | train loss {'Reaction outcome loss': 0.7340152771608067, 'Total loss': 0.7340152771608067}
2022-11-22 21:10:05,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:05,125 INFO:     Epoch: 99
2022-11-22 21:10:05,856 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7660045813430439, 'Total loss': 0.7660045813430439} | train loss {'Reaction outcome loss': 0.7401684555809508, 'Total loss': 0.7401684555809508}
2022-11-22 21:10:05,856 INFO:     Best model found after epoch 98 of 100.
2022-11-22 21:10:05,856 INFO:   Done with stage: TRAINING
2022-11-22 21:10:05,856 INFO:   Starting stage: EVALUATION
2022-11-22 21:10:05,974 INFO:   Done with stage: EVALUATION
2022-11-22 21:10:05,974 INFO:   Leaving out SEQ value Fold_7
2022-11-22 21:10:05,987 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 21:10:05,988 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:10:06,660 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:10:06,660 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:10:06,734 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:10:06,734 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:10:06,734 INFO:     No hyperparam tuning for this model
2022-11-22 21:10:06,734 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:10:06,734 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:10:06,735 INFO:     None feature selector for col prot
2022-11-22 21:10:06,735 INFO:     None feature selector for col prot
2022-11-22 21:10:06,735 INFO:     None feature selector for col prot
2022-11-22 21:10:06,736 INFO:     None feature selector for col chem
2022-11-22 21:10:06,736 INFO:     None feature selector for col chem
2022-11-22 21:10:06,736 INFO:     None feature selector for col chem
2022-11-22 21:10:06,736 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:10:06,736 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:10:06,737 INFO:     Number of params in model 126091
2022-11-22 21:10:06,740 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:10:06,740 INFO:   Starting stage: TRAINING
2022-11-22 21:10:06,789 INFO:     Val loss before train {'Reaction outcome loss': 0.9578861634839665, 'Total loss': 0.9578861634839665}
2022-11-22 21:10:06,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:06,790 INFO:     Epoch: 0
2022-11-22 21:10:07,561 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7945138744332574, 'Total loss': 0.7945138744332574} | train loss {'Reaction outcome loss': 0.882355005750733, 'Total loss': 0.882355005750733}
2022-11-22 21:10:07,561 INFO:     Found new best model at epoch 0
2022-11-22 21:10:07,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:07,562 INFO:     Epoch: 1
2022-11-22 21:10:08,320 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8023248260671442, 'Total loss': 0.8023248260671442} | train loss {'Reaction outcome loss': 0.8500655744104616, 'Total loss': 0.8500655744104616}
2022-11-22 21:10:08,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:08,320 INFO:     Epoch: 2
2022-11-22 21:10:09,080 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7829417139291763, 'Total loss': 0.7829417139291763} | train loss {'Reaction outcome loss': 0.8406016597103688, 'Total loss': 0.8406016597103688}
2022-11-22 21:10:09,080 INFO:     Found new best model at epoch 2
2022-11-22 21:10:09,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:09,081 INFO:     Epoch: 3
2022-11-22 21:10:09,841 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7699965008280494, 'Total loss': 0.7699965008280494} | train loss {'Reaction outcome loss': 0.8265074278798795, 'Total loss': 0.8265074278798795}
2022-11-22 21:10:09,841 INFO:     Found new best model at epoch 3
2022-11-22 21:10:09,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:09,842 INFO:     Epoch: 4
2022-11-22 21:10:10,611 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.76474825699221, 'Total loss': 0.76474825699221} | train loss {'Reaction outcome loss': 0.8214236253932599, 'Total loss': 0.8214236253932599}
2022-11-22 21:10:10,611 INFO:     Found new best model at epoch 4
2022-11-22 21:10:10,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:10,612 INFO:     Epoch: 5
2022-11-22 21:10:11,373 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7659907002340663, 'Total loss': 0.7659907002340663} | train loss {'Reaction outcome loss': 0.8157154415403643, 'Total loss': 0.8157154415403643}
2022-11-22 21:10:11,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:11,373 INFO:     Epoch: 6
2022-11-22 21:10:12,093 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.741586372256279, 'Total loss': 0.741586372256279} | train loss {'Reaction outcome loss': 0.8065902811264799, 'Total loss': 0.8065902811264799}
2022-11-22 21:10:12,094 INFO:     Found new best model at epoch 6
2022-11-22 21:10:12,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:12,094 INFO:     Epoch: 7
2022-11-22 21:10:12,869 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7435459494590759, 'Total loss': 0.7435459494590759} | train loss {'Reaction outcome loss': 0.8122608203801417, 'Total loss': 0.8122608203801417}
2022-11-22 21:10:12,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:12,869 INFO:     Epoch: 8
2022-11-22 21:10:13,623 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7478790730237961, 'Total loss': 0.7478790730237961} | train loss {'Reaction outcome loss': 0.8095423329261041, 'Total loss': 0.8095423329261041}
2022-11-22 21:10:13,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:13,624 INFO:     Epoch: 9
2022-11-22 21:10:14,370 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7539443082430146, 'Total loss': 0.7539443082430146} | train loss {'Reaction outcome loss': 0.8051157468749631, 'Total loss': 0.8051157468749631}
2022-11-22 21:10:14,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:14,371 INFO:     Epoch: 10
2022-11-22 21:10:15,122 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7517388557845895, 'Total loss': 0.7517388557845895} | train loss {'Reaction outcome loss': 0.8067101270200745, 'Total loss': 0.8067101270200745}
2022-11-22 21:10:15,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:15,122 INFO:     Epoch: 11
2022-11-22 21:10:15,873 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7455373866991564, 'Total loss': 0.7455373866991564} | train loss {'Reaction outcome loss': 0.8026003251152654, 'Total loss': 0.8026003251152654}
2022-11-22 21:10:15,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:15,874 INFO:     Epoch: 12
2022-11-22 21:10:16,619 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7546255588531494, 'Total loss': 0.7546255588531494} | train loss {'Reaction outcome loss': 0.8015439735064583, 'Total loss': 0.8015439735064583}
2022-11-22 21:10:16,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:16,619 INFO:     Epoch: 13
2022-11-22 21:10:17,375 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7406974258747968, 'Total loss': 0.7406974258747968} | train loss {'Reaction outcome loss': 0.8064335946354174, 'Total loss': 0.8064335946354174}
2022-11-22 21:10:17,375 INFO:     Found new best model at epoch 13
2022-11-22 21:10:17,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:17,376 INFO:     Epoch: 14
2022-11-22 21:10:18,122 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7378231761130419, 'Total loss': 0.7378231761130419} | train loss {'Reaction outcome loss': 0.8011960574696141, 'Total loss': 0.8011960574696141}
2022-11-22 21:10:18,122 INFO:     Found new best model at epoch 14
2022-11-22 21:10:18,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:18,123 INFO:     Epoch: 15
2022-11-22 21:10:18,884 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7424617389386351, 'Total loss': 0.7424617389386351} | train loss {'Reaction outcome loss': 0.8004107918710478, 'Total loss': 0.8004107918710478}
2022-11-22 21:10:18,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:18,884 INFO:     Epoch: 16
2022-11-22 21:10:19,605 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7503509812734344, 'Total loss': 0.7503509812734344} | train loss {'Reaction outcome loss': 0.7971744609455909, 'Total loss': 0.7971744609455909}
2022-11-22 21:10:19,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:19,606 INFO:     Epoch: 17
2022-11-22 21:10:20,359 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7760222879323092, 'Total loss': 0.7760222879323092} | train loss {'Reaction outcome loss': 0.8004807660416249, 'Total loss': 0.8004807660416249}
2022-11-22 21:10:20,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:20,359 INFO:     Epoch: 18
2022-11-22 21:10:21,121 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7442520599473607, 'Total loss': 0.7442520599473607} | train loss {'Reaction outcome loss': 0.7980964863973279, 'Total loss': 0.7980964863973279}
2022-11-22 21:10:21,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:21,122 INFO:     Epoch: 19
2022-11-22 21:10:21,903 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.73860064284368, 'Total loss': 0.73860064284368} | train loss {'Reaction outcome loss': 0.7949022618272612, 'Total loss': 0.7949022618272612}
2022-11-22 21:10:21,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:21,904 INFO:     Epoch: 20
2022-11-22 21:10:22,688 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7398953939026053, 'Total loss': 0.7398953939026053} | train loss {'Reaction outcome loss': 0.7962669084870047, 'Total loss': 0.7962669084870047}
2022-11-22 21:10:22,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:22,688 INFO:     Epoch: 21
2022-11-22 21:10:23,490 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7734194831414656, 'Total loss': 0.7734194831414656} | train loss {'Reaction outcome loss': 0.7982572541842538, 'Total loss': 0.7982572541842538}
2022-11-22 21:10:23,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:23,490 INFO:     Epoch: 22
2022-11-22 21:10:24,266 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7421908161856912, 'Total loss': 0.7421908161856912} | train loss {'Reaction outcome loss': 0.7952694783528005, 'Total loss': 0.7952694783528005}
2022-11-22 21:10:24,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:24,266 INFO:     Epoch: 23
2022-11-22 21:10:25,034 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7448812533508647, 'Total loss': 0.7448812533508647} | train loss {'Reaction outcome loss': 0.792817568466548, 'Total loss': 0.792817568466548}
2022-11-22 21:10:25,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:25,034 INFO:     Epoch: 24
2022-11-22 21:10:25,819 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7499299503185533, 'Total loss': 0.7499299503185533} | train loss {'Reaction outcome loss': 0.7905778257596877, 'Total loss': 0.7905778257596877}
2022-11-22 21:10:25,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:25,819 INFO:     Epoch: 25
2022-11-22 21:10:26,559 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.740511573173783, 'Total loss': 0.740511573173783} | train loss {'Reaction outcome loss': 0.7984800980456414, 'Total loss': 0.7984800980456414}
2022-11-22 21:10:26,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:26,559 INFO:     Epoch: 26
2022-11-22 21:10:27,319 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7411817860874262, 'Total loss': 0.7411817860874262} | train loss {'Reaction outcome loss': 0.7955976352095604, 'Total loss': 0.7955976352095604}
2022-11-22 21:10:27,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:27,319 INFO:     Epoch: 27
2022-11-22 21:10:28,063 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7332384369590066, 'Total loss': 0.7332384369590066} | train loss {'Reaction outcome loss': 0.7939543125610198, 'Total loss': 0.7939543125610198}
2022-11-22 21:10:28,064 INFO:     Found new best model at epoch 27
2022-11-22 21:10:28,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:28,065 INFO:     Epoch: 28
2022-11-22 21:10:28,805 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7391217926686461, 'Total loss': 0.7391217926686461} | train loss {'Reaction outcome loss': 0.7889704823253616, 'Total loss': 0.7889704823253616}
2022-11-22 21:10:28,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:28,805 INFO:     Epoch: 29
2022-11-22 21:10:29,551 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7492212328043851, 'Total loss': 0.7492212328043851} | train loss {'Reaction outcome loss': 0.793276694272795, 'Total loss': 0.793276694272795}
2022-11-22 21:10:29,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:29,551 INFO:     Epoch: 30
2022-11-22 21:10:30,325 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7565121088515628, 'Total loss': 0.7565121088515628} | train loss {'Reaction outcome loss': 0.788552867188569, 'Total loss': 0.788552867188569}
2022-11-22 21:10:30,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:30,325 INFO:     Epoch: 31
2022-11-22 21:10:31,114 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7217177694494074, 'Total loss': 0.7217177694494074} | train loss {'Reaction outcome loss': 0.7910814951023748, 'Total loss': 0.7910814951023748}
2022-11-22 21:10:31,115 INFO:     Found new best model at epoch 31
2022-11-22 21:10:31,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:31,115 INFO:     Epoch: 32
2022-11-22 21:10:31,836 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7420591170137579, 'Total loss': 0.7420591170137579} | train loss {'Reaction outcome loss': 0.7845221777116099, 'Total loss': 0.7845221777116099}
2022-11-22 21:10:31,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:31,837 INFO:     Epoch: 33
2022-11-22 21:10:32,611 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7444076978347518, 'Total loss': 0.7444076978347518} | train loss {'Reaction outcome loss': 0.786888829162044, 'Total loss': 0.786888829162044}
2022-11-22 21:10:32,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:32,612 INFO:     Epoch: 34
2022-11-22 21:10:33,347 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7263320840217851, 'Total loss': 0.7263320840217851} | train loss {'Reaction outcome loss': 0.7897987293620263, 'Total loss': 0.7897987293620263}
2022-11-22 21:10:33,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:33,347 INFO:     Epoch: 35
2022-11-22 21:10:34,100 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7599080083045092, 'Total loss': 0.7599080083045092} | train loss {'Reaction outcome loss': 0.7872753843905465, 'Total loss': 0.7872753843905465}
2022-11-22 21:10:34,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:34,100 INFO:     Epoch: 36
2022-11-22 21:10:34,876 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.761310492049564, 'Total loss': 0.761310492049564} | train loss {'Reaction outcome loss': 0.7868298435163114, 'Total loss': 0.7868298435163114}
2022-11-22 21:10:34,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:34,876 INFO:     Epoch: 37
2022-11-22 21:10:35,658 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7264762927185405, 'Total loss': 0.7264762927185405} | train loss {'Reaction outcome loss': 0.7886725655726848, 'Total loss': 0.7886725655726848}
2022-11-22 21:10:35,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:35,658 INFO:     Epoch: 38
2022-11-22 21:10:36,465 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7243897095322609, 'Total loss': 0.7243897095322609} | train loss {'Reaction outcome loss': 0.7889533830025504, 'Total loss': 0.7889533830025504}
2022-11-22 21:10:36,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:36,465 INFO:     Epoch: 39
2022-11-22 21:10:37,210 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7337758534333922, 'Total loss': 0.7337758534333922} | train loss {'Reaction outcome loss': 0.7894963515141318, 'Total loss': 0.7894963515141318}
2022-11-22 21:10:37,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:37,210 INFO:     Epoch: 40
2022-11-22 21:10:37,923 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7502732244743542, 'Total loss': 0.7502732244743542} | train loss {'Reaction outcome loss': 0.779825329660408, 'Total loss': 0.779825329660408}
2022-11-22 21:10:37,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:37,923 INFO:     Epoch: 41
2022-11-22 21:10:38,700 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7357174435799773, 'Total loss': 0.7357174435799773} | train loss {'Reaction outcome loss': 0.779212526376209, 'Total loss': 0.779212526376209}
2022-11-22 21:10:38,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:38,700 INFO:     Epoch: 42
2022-11-22 21:10:39,465 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7293251576748762, 'Total loss': 0.7293251576748762} | train loss {'Reaction outcome loss': 0.7791996533952413, 'Total loss': 0.7791996533952413}
2022-11-22 21:10:39,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:39,465 INFO:     Epoch: 43
2022-11-22 21:10:40,182 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7170751555399462, 'Total loss': 0.7170751555399462} | train loss {'Reaction outcome loss': 0.7802722865054684, 'Total loss': 0.7802722865054684}
2022-11-22 21:10:40,183 INFO:     Found new best model at epoch 43
2022-11-22 21:10:40,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:40,184 INFO:     Epoch: 44
2022-11-22 21:10:40,956 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7622941996563565, 'Total loss': 0.7622941996563565} | train loss {'Reaction outcome loss': 0.7799304986913358, 'Total loss': 0.7799304986913358}
2022-11-22 21:10:40,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:40,956 INFO:     Epoch: 45
2022-11-22 21:10:41,739 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7521053031086922, 'Total loss': 0.7521053031086922} | train loss {'Reaction outcome loss': 0.7735751838453354, 'Total loss': 0.7735751838453354}
2022-11-22 21:10:41,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:41,740 INFO:     Epoch: 46
2022-11-22 21:10:42,478 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7335904132236134, 'Total loss': 0.7335904132236134} | train loss {'Reaction outcome loss': 0.7725897652487601, 'Total loss': 0.7725897652487601}
2022-11-22 21:10:42,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:42,478 INFO:     Epoch: 47
2022-11-22 21:10:43,236 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7490985881198536, 'Total loss': 0.7490985881198536} | train loss {'Reaction outcome loss': 0.7676808229617534, 'Total loss': 0.7676808229617534}
2022-11-22 21:10:43,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:43,236 INFO:     Epoch: 48
2022-11-22 21:10:44,008 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7119766616008498, 'Total loss': 0.7119766616008498} | train loss {'Reaction outcome loss': 0.7695612453164593, 'Total loss': 0.7695612453164593}
2022-11-22 21:10:44,009 INFO:     Found new best model at epoch 48
2022-11-22 21:10:44,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:44,009 INFO:     Epoch: 49
2022-11-22 21:10:44,756 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7315726232799616, 'Total loss': 0.7315726232799616} | train loss {'Reaction outcome loss': 0.7633508293619079, 'Total loss': 0.7633508293619079}
2022-11-22 21:10:44,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:44,756 INFO:     Epoch: 50
2022-11-22 21:10:45,468 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7036683261394501, 'Total loss': 0.7036683261394501} | train loss {'Reaction outcome loss': 0.766332374465081, 'Total loss': 0.766332374465081}
2022-11-22 21:10:45,468 INFO:     Found new best model at epoch 50
2022-11-22 21:10:45,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:45,469 INFO:     Epoch: 51
2022-11-22 21:10:46,243 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7023827745155855, 'Total loss': 0.7023827745155855} | train loss {'Reaction outcome loss': 0.7604957898297617, 'Total loss': 0.7604957898297617}
2022-11-22 21:10:46,243 INFO:     Found new best model at epoch 51
2022-11-22 21:10:46,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:46,244 INFO:     Epoch: 52
2022-11-22 21:10:46,964 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7829866355115717, 'Total loss': 0.7829866355115717} | train loss {'Reaction outcome loss': 0.7487806171899841, 'Total loss': 0.7487806171899841}
2022-11-22 21:10:46,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:46,964 INFO:     Epoch: 53
2022-11-22 21:10:47,713 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7015570117668672, 'Total loss': 0.7015570117668672} | train loss {'Reaction outcome loss': 0.7532885167146882, 'Total loss': 0.7532885167146882}
2022-11-22 21:10:47,713 INFO:     Found new best model at epoch 53
2022-11-22 21:10:47,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:47,714 INFO:     Epoch: 54
2022-11-22 21:10:48,464 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.6996558254415338, 'Total loss': 0.6996558254415338} | train loss {'Reaction outcome loss': 0.746565118071533, 'Total loss': 0.746565118071533}
2022-11-22 21:10:48,464 INFO:     Found new best model at epoch 54
2022-11-22 21:10:48,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:48,465 INFO:     Epoch: 55
2022-11-22 21:10:49,242 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.6949135573072867, 'Total loss': 0.6949135573072867} | train loss {'Reaction outcome loss': 0.7461706211249675, 'Total loss': 0.7461706211249675}
2022-11-22 21:10:49,242 INFO:     Found new best model at epoch 55
2022-11-22 21:10:49,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:49,243 INFO:     Epoch: 56
2022-11-22 21:10:50,007 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.727807685055516, 'Total loss': 0.727807685055516} | train loss {'Reaction outcome loss': 0.7367248856011899, 'Total loss': 0.7367248856011899}
2022-11-22 21:10:50,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:50,008 INFO:     Epoch: 57
2022-11-22 21:10:50,768 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.6956513910131021, 'Total loss': 0.6956513910131021} | train loss {'Reaction outcome loss': 0.7482051214263323, 'Total loss': 0.7482051214263323}
2022-11-22 21:10:50,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:50,768 INFO:     Epoch: 58
2022-11-22 21:10:51,505 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.677052225578915, 'Total loss': 0.677052225578915} | train loss {'Reaction outcome loss': 0.7400604976160873, 'Total loss': 0.7400604976160873}
2022-11-22 21:10:51,505 INFO:     Found new best model at epoch 58
2022-11-22 21:10:51,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:51,506 INFO:     Epoch: 59
2022-11-22 21:10:52,304 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.6927787871523337, 'Total loss': 0.6927787871523337} | train loss {'Reaction outcome loss': 0.7379142327174064, 'Total loss': 0.7379142327174064}
2022-11-22 21:10:52,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:52,304 INFO:     Epoch: 60
2022-11-22 21:10:53,082 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.6885581301017241, 'Total loss': 0.6885581301017241} | train loss {'Reaction outcome loss': 0.7313186818313214, 'Total loss': 0.7313186818313214}
2022-11-22 21:10:53,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:53,083 INFO:     Epoch: 61
2022-11-22 21:10:53,850 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7252431152896448, 'Total loss': 0.7252431152896448} | train loss {'Reaction outcome loss': 0.7378772423272172, 'Total loss': 0.7378772423272172}
2022-11-22 21:10:53,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:53,851 INFO:     Epoch: 62
2022-11-22 21:10:54,662 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.6853134469552473, 'Total loss': 0.6853134469552473} | train loss {'Reaction outcome loss': 0.7362338788807392, 'Total loss': 0.7362338788807392}
2022-11-22 21:10:54,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:54,662 INFO:     Epoch: 63
2022-11-22 21:10:55,477 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7122398418459025, 'Total loss': 0.7122398418459025} | train loss {'Reaction outcome loss': 0.7283358203787957, 'Total loss': 0.7283358203787957}
2022-11-22 21:10:55,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:55,477 INFO:     Epoch: 64
2022-11-22 21:10:56,338 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.6896985850550912, 'Total loss': 0.6896985850550912} | train loss {'Reaction outcome loss': 0.7292490090814329, 'Total loss': 0.7292490090814329}
2022-11-22 21:10:56,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:56,338 INFO:     Epoch: 65
2022-11-22 21:10:57,200 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7073167115449905, 'Total loss': 0.7073167115449905} | train loss {'Reaction outcome loss': 0.7390048524304744, 'Total loss': 0.7390048524304744}
2022-11-22 21:10:57,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:57,200 INFO:     Epoch: 66
2022-11-22 21:10:58,010 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7091567380861803, 'Total loss': 0.7091567380861803} | train loss {'Reaction outcome loss': 0.7328349612052402, 'Total loss': 0.7328349612052402}
2022-11-22 21:10:58,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:58,010 INFO:     Epoch: 67
2022-11-22 21:10:58,789 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.6847231198440898, 'Total loss': 0.6847231198440898} | train loss {'Reaction outcome loss': 0.7205149754881859, 'Total loss': 0.7205149754881859}
2022-11-22 21:10:58,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:58,789 INFO:     Epoch: 68
2022-11-22 21:10:59,576 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.731008339334618, 'Total loss': 0.731008339334618} | train loss {'Reaction outcome loss': 0.7315727173080367, 'Total loss': 0.7315727173080367}
2022-11-22 21:10:59,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:10:59,577 INFO:     Epoch: 69
2022-11-22 21:11:00,423 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6670330414040522, 'Total loss': 0.6670330414040522} | train loss {'Reaction outcome loss': 0.723761037352585, 'Total loss': 0.723761037352585}
2022-11-22 21:11:00,423 INFO:     Found new best model at epoch 69
2022-11-22 21:11:00,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:00,424 INFO:     Epoch: 70
2022-11-22 21:11:01,272 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7416904351928018, 'Total loss': 0.7416904351928018} | train loss {'Reaction outcome loss': 0.7207347045262014, 'Total loss': 0.7207347045262014}
2022-11-22 21:11:01,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:01,272 INFO:     Epoch: 71
2022-11-22 21:11:02,107 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7187297520312396, 'Total loss': 0.7187297520312396} | train loss {'Reaction outcome loss': 0.7288046049014214, 'Total loss': 0.7288046049014214}
2022-11-22 21:11:02,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:02,108 INFO:     Epoch: 72
2022-11-22 21:11:02,917 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6877125996080312, 'Total loss': 0.6877125996080312} | train loss {'Reaction outcome loss': 0.716362958834056, 'Total loss': 0.716362958834056}
2022-11-22 21:11:02,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:02,918 INFO:     Epoch: 73
2022-11-22 21:11:03,679 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.692069685594602, 'Total loss': 0.692069685594602} | train loss {'Reaction outcome loss': 0.7116733659659663, 'Total loss': 0.7116733659659663}
2022-11-22 21:11:03,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:03,679 INFO:     Epoch: 74
2022-11-22 21:11:04,450 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.6881078874522989, 'Total loss': 0.6881078874522989} | train loss {'Reaction outcome loss': 0.7220846008389227, 'Total loss': 0.7220846008389227}
2022-11-22 21:11:04,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:04,451 INFO:     Epoch: 75
2022-11-22 21:11:05,224 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.6624715802344409, 'Total loss': 0.6624715802344409} | train loss {'Reaction outcome loss': 0.71298291642339, 'Total loss': 0.71298291642339}
2022-11-22 21:11:05,224 INFO:     Found new best model at epoch 75
2022-11-22 21:11:05,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:05,225 INFO:     Epoch: 76
2022-11-22 21:11:05,980 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.6520331955768845, 'Total loss': 0.6520331955768845} | train loss {'Reaction outcome loss': 0.7215448119226964, 'Total loss': 0.7215448119226964}
2022-11-22 21:11:05,980 INFO:     Found new best model at epoch 76
2022-11-22 21:11:05,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:05,981 INFO:     Epoch: 77
2022-11-22 21:11:06,716 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.6749586280096661, 'Total loss': 0.6749586280096661} | train loss {'Reaction outcome loss': 0.723649708614234, 'Total loss': 0.723649708614234}
2022-11-22 21:11:06,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:06,716 INFO:     Epoch: 78
2022-11-22 21:11:07,450 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6824300827627833, 'Total loss': 0.6824300827627833} | train loss {'Reaction outcome loss': 0.7158344613928949, 'Total loss': 0.7158344613928949}
2022-11-22 21:11:07,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:07,450 INFO:     Epoch: 79
2022-11-22 21:11:08,245 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6730972856960513, 'Total loss': 0.6730972856960513} | train loss {'Reaction outcome loss': 0.7233606538464946, 'Total loss': 0.7233606538464946}
2022-11-22 21:11:08,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:08,245 INFO:     Epoch: 80
2022-11-22 21:11:09,043 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.6613149791955948, 'Total loss': 0.6613149791955948} | train loss {'Reaction outcome loss': 0.716042879848711, 'Total loss': 0.716042879848711}
2022-11-22 21:11:09,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:09,043 INFO:     Epoch: 81
2022-11-22 21:11:09,816 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6710868152705106, 'Total loss': 0.6710868152705106} | train loss {'Reaction outcome loss': 0.7056267150948125, 'Total loss': 0.7056267150948125}
2022-11-22 21:11:09,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:09,816 INFO:     Epoch: 82
2022-11-22 21:11:10,543 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.712186227467927, 'Total loss': 0.712186227467927} | train loss {'Reaction outcome loss': 0.714980297661837, 'Total loss': 0.714980297661837}
2022-11-22 21:11:10,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:10,543 INFO:     Epoch: 83
2022-11-22 21:11:11,315 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6934523900801485, 'Total loss': 0.6934523900801485} | train loss {'Reaction outcome loss': 0.7159816659986973, 'Total loss': 0.7159816659986973}
2022-11-22 21:11:11,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:11,316 INFO:     Epoch: 84
2022-11-22 21:11:12,074 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6629326688972387, 'Total loss': 0.6629326688972387} | train loss {'Reaction outcome loss': 0.7225989185033306, 'Total loss': 0.7225989185033306}
2022-11-22 21:11:12,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:12,075 INFO:     Epoch: 85
2022-11-22 21:11:12,868 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6542484218424017, 'Total loss': 0.6542484218424017} | train loss {'Reaction outcome loss': 0.7070271122840143, 'Total loss': 0.7070271122840143}
2022-11-22 21:11:12,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:12,869 INFO:     Epoch: 86
2022-11-22 21:11:13,657 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6685145023194227, 'Total loss': 0.6685145023194227} | train loss {'Reaction outcome loss': 0.7133868977187141, 'Total loss': 0.7133868977187141}
2022-11-22 21:11:13,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:13,657 INFO:     Epoch: 87
2022-11-22 21:11:14,405 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6683125089515339, 'Total loss': 0.6683125089515339} | train loss {'Reaction outcome loss': 0.7084013920637869, 'Total loss': 0.7084013920637869}
2022-11-22 21:11:14,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:14,406 INFO:     Epoch: 88
2022-11-22 21:11:15,152 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6740713329477743, 'Total loss': 0.6740713329477743} | train loss {'Reaction outcome loss': 0.7038787223639027, 'Total loss': 0.7038787223639027}
2022-11-22 21:11:15,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:15,152 INFO:     Epoch: 89
2022-11-22 21:11:15,885 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6746226088567213, 'Total loss': 0.6746226088567213} | train loss {'Reaction outcome loss': 0.7020757267431866, 'Total loss': 0.7020757267431866}
2022-11-22 21:11:15,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:15,886 INFO:     Epoch: 90
2022-11-22 21:11:16,593 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7011926126751032, 'Total loss': 0.7011926126751032} | train loss {'Reaction outcome loss': 0.7030604939547277, 'Total loss': 0.7030604939547277}
2022-11-22 21:11:16,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:16,593 INFO:     Epoch: 91
2022-11-22 21:11:17,357 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.6904086436737668, 'Total loss': 0.6904086436737668} | train loss {'Reaction outcome loss': 0.7085599556805626, 'Total loss': 0.7085599556805626}
2022-11-22 21:11:17,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:17,357 INFO:     Epoch: 92
2022-11-22 21:11:18,098 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6753214618021791, 'Total loss': 0.6753214618021791} | train loss {'Reaction outcome loss': 0.710969460467177, 'Total loss': 0.710969460467177}
2022-11-22 21:11:18,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:18,098 INFO:     Epoch: 93
2022-11-22 21:11:18,903 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6967001360925761, 'Total loss': 0.6967001360925761} | train loss {'Reaction outcome loss': 0.7123066177892108, 'Total loss': 0.7123066177892108}
2022-11-22 21:11:18,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:18,903 INFO:     Epoch: 94
2022-11-22 21:11:19,694 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6568045121702281, 'Total loss': 0.6568045121702281} | train loss {'Reaction outcome loss': 0.710420215081784, 'Total loss': 0.710420215081784}
2022-11-22 21:11:19,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:19,695 INFO:     Epoch: 95
2022-11-22 21:11:20,434 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6658614630048926, 'Total loss': 0.6658614630048926} | train loss {'Reaction outcome loss': 0.7067179919611062, 'Total loss': 0.7067179919611062}
2022-11-22 21:11:20,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:20,435 INFO:     Epoch: 96
2022-11-22 21:11:21,165 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6533287262374704, 'Total loss': 0.6533287262374704} | train loss {'Reaction outcome loss': 0.7122388514539888, 'Total loss': 0.7122388514539888}
2022-11-22 21:11:21,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:21,165 INFO:     Epoch: 97
2022-11-22 21:11:21,887 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6891689158298753, 'Total loss': 0.6891689158298753} | train loss {'Reaction outcome loss': 0.7104466126090095, 'Total loss': 0.7104466126090095}
2022-11-22 21:11:21,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:21,887 INFO:     Epoch: 98
2022-11-22 21:11:22,607 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6791823960163377, 'Total loss': 0.6791823960163377} | train loss {'Reaction outcome loss': 0.7107975425258759, 'Total loss': 0.7107975425258759}
2022-11-22 21:11:22,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:22,607 INFO:     Epoch: 99
2022-11-22 21:11:23,392 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6928980533372272, 'Total loss': 0.6928980533372272} | train loss {'Reaction outcome loss': 0.7075456789424343, 'Total loss': 0.7075456789424343}
2022-11-22 21:11:23,392 INFO:     Best model found after epoch 77 of 100.
2022-11-22 21:11:23,392 INFO:   Done with stage: TRAINING
2022-11-22 21:11:23,392 INFO:   Starting stage: EVALUATION
2022-11-22 21:11:23,506 INFO:   Done with stage: EVALUATION
2022-11-22 21:11:23,506 INFO:   Leaving out SEQ value Fold_8
2022-11-22 21:11:23,519 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 21:11:23,519 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:11:24,203 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:11:24,204 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:11:24,275 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:11:24,275 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:11:24,275 INFO:     No hyperparam tuning for this model
2022-11-22 21:11:24,275 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:11:24,275 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:11:24,276 INFO:     None feature selector for col prot
2022-11-22 21:11:24,276 INFO:     None feature selector for col prot
2022-11-22 21:11:24,276 INFO:     None feature selector for col prot
2022-11-22 21:11:24,277 INFO:     None feature selector for col chem
2022-11-22 21:11:24,277 INFO:     None feature selector for col chem
2022-11-22 21:11:24,277 INFO:     None feature selector for col chem
2022-11-22 21:11:24,277 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:11:24,277 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:11:24,278 INFO:     Number of params in model 126091
2022-11-22 21:11:24,282 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:11:24,282 INFO:   Starting stage: TRAINING
2022-11-22 21:11:24,331 INFO:     Val loss before train {'Reaction outcome loss': 1.034881373698061, 'Total loss': 1.034881373698061}
2022-11-22 21:11:24,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:24,331 INFO:     Epoch: 0
2022-11-22 21:11:25,088 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8702834627845071, 'Total loss': 0.8702834627845071} | train loss {'Reaction outcome loss': 0.8865373526369372, 'Total loss': 0.8865373526369372}
2022-11-22 21:11:25,088 INFO:     Found new best model at epoch 0
2022-11-22 21:11:25,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:25,089 INFO:     Epoch: 1
2022-11-22 21:11:25,916 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9033761098980904, 'Total loss': 0.9033761098980904} | train loss {'Reaction outcome loss': 0.8540880687294468, 'Total loss': 0.8540880687294468}
2022-11-22 21:11:25,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:25,917 INFO:     Epoch: 2
2022-11-22 21:11:26,681 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8604790012944828, 'Total loss': 0.8604790012944828} | train loss {'Reaction outcome loss': 0.8388114704359924, 'Total loss': 0.8388114704359924}
2022-11-22 21:11:26,681 INFO:     Found new best model at epoch 2
2022-11-22 21:11:26,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:26,682 INFO:     Epoch: 3
2022-11-22 21:11:27,468 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8700935705141588, 'Total loss': 0.8700935705141588} | train loss {'Reaction outcome loss': 0.8299189434657174, 'Total loss': 0.8299189434657174}
2022-11-22 21:11:27,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:27,468 INFO:     Epoch: 4
2022-11-22 21:11:28,239 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.866108166900548, 'Total loss': 0.866108166900548} | train loss {'Reaction outcome loss': 0.8325518301177409, 'Total loss': 0.8325518301177409}
2022-11-22 21:11:28,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:28,239 INFO:     Epoch: 5
2022-11-22 21:11:28,996 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8520872667431831, 'Total loss': 0.8520872667431831} | train loss {'Reaction outcome loss': 0.8281939136645486, 'Total loss': 0.8281939136645486}
2022-11-22 21:11:28,996 INFO:     Found new best model at epoch 5
2022-11-22 21:11:28,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:28,997 INFO:     Epoch: 6
2022-11-22 21:11:29,736 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8420747369527817, 'Total loss': 0.8420747369527817} | train loss {'Reaction outcome loss': 0.8182528789245314, 'Total loss': 0.8182528789245314}
2022-11-22 21:11:29,736 INFO:     Found new best model at epoch 6
2022-11-22 21:11:29,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:29,737 INFO:     Epoch: 7
2022-11-22 21:11:30,479 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8591340509327975, 'Total loss': 0.8591340509327975} | train loss {'Reaction outcome loss': 0.8165029954285391, 'Total loss': 0.8165029954285391}
2022-11-22 21:11:30,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:30,481 INFO:     Epoch: 8
2022-11-22 21:11:31,221 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8521211993965235, 'Total loss': 0.8521211993965235} | train loss {'Reaction outcome loss': 0.8155834165311628, 'Total loss': 0.8155834165311628}
2022-11-22 21:11:31,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:31,221 INFO:     Epoch: 9
2022-11-22 21:11:31,985 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8645474314689636, 'Total loss': 0.8645474314689636} | train loss {'Reaction outcome loss': 0.8165493718678912, 'Total loss': 0.8165493718678912}
2022-11-22 21:11:31,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:31,985 INFO:     Epoch: 10
2022-11-22 21:11:32,732 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8302011279897257, 'Total loss': 0.8302011279897257} | train loss {'Reaction outcome loss': 0.8134906049216947, 'Total loss': 0.8134906049216947}
2022-11-22 21:11:32,732 INFO:     Found new best model at epoch 10
2022-11-22 21:11:32,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:32,733 INFO:     Epoch: 11
2022-11-22 21:11:33,465 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8398983451453123, 'Total loss': 0.8398983451453123} | train loss {'Reaction outcome loss': 0.8114353069855321, 'Total loss': 0.8114353069855321}
2022-11-22 21:11:33,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:33,465 INFO:     Epoch: 12
2022-11-22 21:11:34,252 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8335529836741361, 'Total loss': 0.8335529836741361} | train loss {'Reaction outcome loss': 0.8138684337177584, 'Total loss': 0.8138684337177584}
2022-11-22 21:11:34,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:34,252 INFO:     Epoch: 13
2022-11-22 21:11:35,048 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.840938463807106, 'Total loss': 0.840938463807106} | train loss {'Reaction outcome loss': 0.8065581208755893, 'Total loss': 0.8065581208755893}
2022-11-22 21:11:35,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:35,049 INFO:     Epoch: 14
2022-11-22 21:11:35,780 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8569909754124555, 'Total loss': 0.8569909754124555} | train loss {'Reaction outcome loss': 0.8096684073248217, 'Total loss': 0.8096684073248217}
2022-11-22 21:11:35,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:35,780 INFO:     Epoch: 15
2022-11-22 21:11:36,528 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8221363242376934, 'Total loss': 0.8221363242376934} | train loss {'Reaction outcome loss': 0.8056163644838717, 'Total loss': 0.8056163644838717}
2022-11-22 21:11:36,528 INFO:     Found new best model at epoch 15
2022-11-22 21:11:36,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:36,529 INFO:     Epoch: 16
2022-11-22 21:11:37,298 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8832970193841241, 'Total loss': 0.8832970193841241} | train loss {'Reaction outcome loss': 0.8084323402614363, 'Total loss': 0.8084323402614363}
2022-11-22 21:11:37,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:37,298 INFO:     Epoch: 17
2022-11-22 21:11:38,056 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8280851170420647, 'Total loss': 0.8280851170420647} | train loss {'Reaction outcome loss': 0.8067977144833534, 'Total loss': 0.8067977144833534}
2022-11-22 21:11:38,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:38,056 INFO:     Epoch: 18
2022-11-22 21:11:38,840 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8467383831739426, 'Total loss': 0.8467383831739426} | train loss {'Reaction outcome loss': 0.8094788182887339, 'Total loss': 0.8094788182887339}
2022-11-22 21:11:38,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:38,840 INFO:     Epoch: 19
2022-11-22 21:11:39,546 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8277171897617254, 'Total loss': 0.8277171897617254} | train loss {'Reaction outcome loss': 0.8040920026119678, 'Total loss': 0.8040920026119678}
2022-11-22 21:11:39,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:39,547 INFO:     Epoch: 20
2022-11-22 21:11:40,294 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8389121341434392, 'Total loss': 0.8389121341434392} | train loss {'Reaction outcome loss': 0.8050226170209146, 'Total loss': 0.8050226170209146}
2022-11-22 21:11:40,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:40,294 INFO:     Epoch: 21
2022-11-22 21:11:41,052 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8377831815318628, 'Total loss': 0.8377831815318628} | train loss {'Reaction outcome loss': 0.804621147172105, 'Total loss': 0.804621147172105}
2022-11-22 21:11:41,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:41,053 INFO:     Epoch: 22
2022-11-22 21:11:41,807 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.84635306623849, 'Total loss': 0.84635306623849} | train loss {'Reaction outcome loss': 0.8025644882431915, 'Total loss': 0.8025644882431915}
2022-11-22 21:11:41,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:41,807 INFO:     Epoch: 23
2022-11-22 21:11:42,582 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8293734822760929, 'Total loss': 0.8293734822760929} | train loss {'Reaction outcome loss': 0.808355038444842, 'Total loss': 0.808355038444842}
2022-11-22 21:11:42,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:42,583 INFO:     Epoch: 24
2022-11-22 21:11:43,315 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8316253653981469, 'Total loss': 0.8316253653981469} | train loss {'Reaction outcome loss': 0.7994626282203582, 'Total loss': 0.7994626282203582}
2022-11-22 21:11:43,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:43,315 INFO:     Epoch: 25
2022-11-22 21:11:44,045 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8226428147066723, 'Total loss': 0.8226428147066723} | train loss {'Reaction outcome loss': 0.7999558339436208, 'Total loss': 0.7999558339436208}
2022-11-22 21:11:44,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:44,045 INFO:     Epoch: 26
2022-11-22 21:11:44,802 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.814076034182852, 'Total loss': 0.814076034182852} | train loss {'Reaction outcome loss': 0.8016979867412198, 'Total loss': 0.8016979867412198}
2022-11-22 21:11:44,802 INFO:     Found new best model at epoch 26
2022-11-22 21:11:44,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:44,803 INFO:     Epoch: 27
2022-11-22 21:11:45,627 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8428305631334131, 'Total loss': 0.8428305631334131} | train loss {'Reaction outcome loss': 0.7991033618248278, 'Total loss': 0.7991033618248278}
2022-11-22 21:11:45,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:45,627 INFO:     Epoch: 28
2022-11-22 21:11:46,378 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8304431777108799, 'Total loss': 0.8304431777108799} | train loss {'Reaction outcome loss': 0.8044131162666506, 'Total loss': 0.8044131162666506}
2022-11-22 21:11:46,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:46,378 INFO:     Epoch: 29
2022-11-22 21:11:47,094 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8415482355789705, 'Total loss': 0.8415482355789705} | train loss {'Reaction outcome loss': 0.7972224467704373, 'Total loss': 0.7972224467704373}
2022-11-22 21:11:47,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:47,094 INFO:     Epoch: 30
2022-11-22 21:11:47,859 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8538580530069091, 'Total loss': 0.8538580530069091} | train loss {'Reaction outcome loss': 0.7986782672664812, 'Total loss': 0.7986782672664812}
2022-11-22 21:11:47,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:47,859 INFO:     Epoch: 31
2022-11-22 21:11:48,572 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8121227357875217, 'Total loss': 0.8121227357875217} | train loss {'Reaction outcome loss': 0.8044573650244744, 'Total loss': 0.8044573650244744}
2022-11-22 21:11:48,572 INFO:     Found new best model at epoch 31
2022-11-22 21:11:48,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:48,573 INFO:     Epoch: 32
2022-11-22 21:11:49,414 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.830975509502671, 'Total loss': 0.830975509502671} | train loss {'Reaction outcome loss': 0.7996954932328193, 'Total loss': 0.7996954932328193}
2022-11-22 21:11:49,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:49,414 INFO:     Epoch: 33
2022-11-22 21:11:50,163 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8253618424588983, 'Total loss': 0.8253618424588983} | train loss {'Reaction outcome loss': 0.7974329809508016, 'Total loss': 0.7974329809508016}
2022-11-22 21:11:50,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:50,163 INFO:     Epoch: 34
2022-11-22 21:11:50,925 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8389154740355231, 'Total loss': 0.8389154740355231} | train loss {'Reaction outcome loss': 0.8017650013489108, 'Total loss': 0.8017650013489108}
2022-11-22 21:11:50,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:50,926 INFO:     Epoch: 35
2022-11-22 21:11:51,700 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8249593797055158, 'Total loss': 0.8249593797055158} | train loss {'Reaction outcome loss': 0.8005775629032043, 'Total loss': 0.8005775629032043}
2022-11-22 21:11:51,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:51,700 INFO:     Epoch: 36
2022-11-22 21:11:52,447 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8109061521562663, 'Total loss': 0.8109061521562663} | train loss {'Reaction outcome loss': 0.8053776910228114, 'Total loss': 0.8053776910228114}
2022-11-22 21:11:52,447 INFO:     Found new best model at epoch 36
2022-11-22 21:11:52,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:52,448 INFO:     Epoch: 37
2022-11-22 21:11:53,177 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8204790407961066, 'Total loss': 0.8204790407961066} | train loss {'Reaction outcome loss': 0.7978841251423282, 'Total loss': 0.7978841251423282}
2022-11-22 21:11:53,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:53,177 INFO:     Epoch: 38
2022-11-22 21:11:53,902 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8517726876518943, 'Total loss': 0.8517726876518943} | train loss {'Reaction outcome loss': 0.8004655619302103, 'Total loss': 0.8004655619302103}
2022-11-22 21:11:53,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:53,902 INFO:     Epoch: 39
2022-11-22 21:11:54,676 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.826971213248643, 'Total loss': 0.826971213248643} | train loss {'Reaction outcome loss': 0.7997103138796745, 'Total loss': 0.7997103138796745}
2022-11-22 21:11:54,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:54,677 INFO:     Epoch: 40
2022-11-22 21:11:55,446 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8208634826270017, 'Total loss': 0.8208634826270017} | train loss {'Reaction outcome loss': 0.7964106512165838, 'Total loss': 0.7964106512165838}
2022-11-22 21:11:55,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:55,447 INFO:     Epoch: 41
2022-11-22 21:11:56,188 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8241060355847533, 'Total loss': 0.8241060355847533} | train loss {'Reaction outcome loss': 0.7953752674643071, 'Total loss': 0.7953752674643071}
2022-11-22 21:11:56,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:56,188 INFO:     Epoch: 42
2022-11-22 21:11:56,963 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8251899873668497, 'Total loss': 0.8251899873668497} | train loss {'Reaction outcome loss': 0.7940435568171162, 'Total loss': 0.7940435568171162}
2022-11-22 21:11:56,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:56,964 INFO:     Epoch: 43
2022-11-22 21:11:57,747 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8176567879590121, 'Total loss': 0.8176567879590121} | train loss {'Reaction outcome loss': 0.7942719821247363, 'Total loss': 0.7942719821247363}
2022-11-22 21:11:57,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:57,747 INFO:     Epoch: 44
2022-11-22 21:11:58,534 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8254933607849207, 'Total loss': 0.8254933607849207} | train loss {'Reaction outcome loss': 0.7940497206103417, 'Total loss': 0.7940497206103417}
2022-11-22 21:11:58,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:58,534 INFO:     Epoch: 45
2022-11-22 21:11:59,255 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8329433981667865, 'Total loss': 0.8329433981667865} | train loss {'Reaction outcome loss': 0.790999868223744, 'Total loss': 0.790999868223744}
2022-11-22 21:11:59,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:11:59,256 INFO:     Epoch: 46
2022-11-22 21:12:00,047 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8459364744749936, 'Total loss': 0.8459364744749936} | train loss {'Reaction outcome loss': 0.7988961396678802, 'Total loss': 0.7988961396678802}
2022-11-22 21:12:00,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:00,047 INFO:     Epoch: 47
2022-11-22 21:12:00,761 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.809321287680756, 'Total loss': 0.809321287680756} | train loss {'Reaction outcome loss': 0.7959721255446633, 'Total loss': 0.7959721255446633}
2022-11-22 21:12:00,761 INFO:     Found new best model at epoch 47
2022-11-22 21:12:00,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:00,762 INFO:     Epoch: 48
2022-11-22 21:12:01,487 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8554429032585837, 'Total loss': 0.8554429032585837} | train loss {'Reaction outcome loss': 0.7858068584314277, 'Total loss': 0.7858068584314277}
2022-11-22 21:12:01,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:01,488 INFO:     Epoch: 49
2022-11-22 21:12:02,213 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.814294466918165, 'Total loss': 0.814294466918165} | train loss {'Reaction outcome loss': 0.7961057888404015, 'Total loss': 0.7961057888404015}
2022-11-22 21:12:02,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:02,214 INFO:     Epoch: 50
2022-11-22 21:12:02,933 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8170628269964998, 'Total loss': 0.8170628269964998} | train loss {'Reaction outcome loss': 0.7935508945055546, 'Total loss': 0.7935508945055546}
2022-11-22 21:12:02,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:02,934 INFO:     Epoch: 51
2022-11-22 21:12:03,668 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8366416638547723, 'Total loss': 0.8366416638547723} | train loss {'Reaction outcome loss': 0.793069165921019, 'Total loss': 0.793069165921019}
2022-11-22 21:12:03,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:03,669 INFO:     Epoch: 52
2022-11-22 21:12:04,402 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8123174831271172, 'Total loss': 0.8123174831271172} | train loss {'Reaction outcome loss': 0.7894455119967461, 'Total loss': 0.7894455119967461}
2022-11-22 21:12:04,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:04,402 INFO:     Epoch: 53
2022-11-22 21:12:05,124 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8365452784028921, 'Total loss': 0.8365452784028921} | train loss {'Reaction outcome loss': 0.7895813650421558, 'Total loss': 0.7895813650421558}
2022-11-22 21:12:05,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:05,124 INFO:     Epoch: 54
2022-11-22 21:12:05,912 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8197053311900659, 'Total loss': 0.8197053311900659} | train loss {'Reaction outcome loss': 0.7928702212389438, 'Total loss': 0.7928702212389438}
2022-11-22 21:12:05,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:05,912 INFO:     Epoch: 55
2022-11-22 21:12:06,680 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.849468665366823, 'Total loss': 0.849468665366823} | train loss {'Reaction outcome loss': 0.785347991653027, 'Total loss': 0.785347991653027}
2022-11-22 21:12:06,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:06,681 INFO:     Epoch: 56
2022-11-22 21:12:07,457 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8005152087319981, 'Total loss': 0.8005152087319981} | train loss {'Reaction outcome loss': 0.7901753089841335, 'Total loss': 0.7901753089841335}
2022-11-22 21:12:07,458 INFO:     Found new best model at epoch 56
2022-11-22 21:12:07,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:07,458 INFO:     Epoch: 57
2022-11-22 21:12:08,226 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7956267622384158, 'Total loss': 0.7956267622384158} | train loss {'Reaction outcome loss': 0.78233004349374, 'Total loss': 0.78233004349374}
2022-11-22 21:12:08,227 INFO:     Found new best model at epoch 57
2022-11-22 21:12:08,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:08,227 INFO:     Epoch: 58
2022-11-22 21:12:08,971 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8136510781266473, 'Total loss': 0.8136510781266473} | train loss {'Reaction outcome loss': 0.7796844596103314, 'Total loss': 0.7796844596103314}
2022-11-22 21:12:08,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:08,971 INFO:     Epoch: 59
2022-11-22 21:12:09,778 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8221734132279049, 'Total loss': 0.8221734132279049} | train loss {'Reaction outcome loss': 0.7767906184158018, 'Total loss': 0.7767906184158018}
2022-11-22 21:12:09,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:09,778 INFO:     Epoch: 60
2022-11-22 21:12:10,594 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.792610414326191, 'Total loss': 0.792610414326191} | train loss {'Reaction outcome loss': 0.7882375565748061, 'Total loss': 0.7882375565748061}
2022-11-22 21:12:10,594 INFO:     Found new best model at epoch 60
2022-11-22 21:12:10,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:10,595 INFO:     Epoch: 61
2022-11-22 21:12:11,391 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7989941564473239, 'Total loss': 0.7989941564473239} | train loss {'Reaction outcome loss': 0.7788519134684917, 'Total loss': 0.7788519134684917}
2022-11-22 21:12:11,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:11,391 INFO:     Epoch: 62
2022-11-22 21:12:12,233 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8360082798383452, 'Total loss': 0.8360082798383452} | train loss {'Reaction outcome loss': 0.7814577461010025, 'Total loss': 0.7814577461010025}
2022-11-22 21:12:12,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:12,234 INFO:     Epoch: 63
2022-11-22 21:12:13,033 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8028206845576112, 'Total loss': 0.8028206845576112} | train loss {'Reaction outcome loss': 0.78142981483571, 'Total loss': 0.78142981483571}
2022-11-22 21:12:13,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:13,033 INFO:     Epoch: 64
2022-11-22 21:12:13,837 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8083913658152927, 'Total loss': 0.8083913658152927} | train loss {'Reaction outcome loss': 0.774844441562891, 'Total loss': 0.774844441562891}
2022-11-22 21:12:13,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:13,838 INFO:     Epoch: 65
2022-11-22 21:12:14,645 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8004400106993589, 'Total loss': 0.8004400106993589} | train loss {'Reaction outcome loss': 0.7781828516913999, 'Total loss': 0.7781828516913999}
2022-11-22 21:12:14,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:14,646 INFO:     Epoch: 66
2022-11-22 21:12:15,494 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7935930612412366, 'Total loss': 0.7935930612412366} | train loss {'Reaction outcome loss': 0.7707831621650727, 'Total loss': 0.7707831621650727}
2022-11-22 21:12:15,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:15,495 INFO:     Epoch: 67
2022-11-22 21:12:16,305 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8297121341932904, 'Total loss': 0.8297121341932904} | train loss {'Reaction outcome loss': 0.7680562784474704, 'Total loss': 0.7680562784474704}
2022-11-22 21:12:16,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:16,306 INFO:     Epoch: 68
2022-11-22 21:12:17,136 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7837161828171123, 'Total loss': 0.7837161828171123} | train loss {'Reaction outcome loss': 0.7645457599672579, 'Total loss': 0.7645457599672579}
2022-11-22 21:12:17,136 INFO:     Found new best model at epoch 68
2022-11-22 21:12:17,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:17,137 INFO:     Epoch: 69
2022-11-22 21:12:17,943 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.823638073422692, 'Total loss': 0.823638073422692} | train loss {'Reaction outcome loss': 0.7680114648274837, 'Total loss': 0.7680114648274837}
2022-11-22 21:12:17,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:17,943 INFO:     Epoch: 70
2022-11-22 21:12:18,764 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.802995269948786, 'Total loss': 0.802995269948786} | train loss {'Reaction outcome loss': 0.7670037766858455, 'Total loss': 0.7670037766858455}
2022-11-22 21:12:18,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:18,764 INFO:     Epoch: 71
2022-11-22 21:12:19,587 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7793772437355735, 'Total loss': 0.7793772437355735} | train loss {'Reaction outcome loss': 0.7559354779941421, 'Total loss': 0.7559354779941421}
2022-11-22 21:12:19,588 INFO:     Found new best model at epoch 71
2022-11-22 21:12:19,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:19,589 INFO:     Epoch: 72
2022-11-22 21:12:20,420 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.767838102850047, 'Total loss': 0.767838102850047} | train loss {'Reaction outcome loss': 0.7577625812301713, 'Total loss': 0.7577625812301713}
2022-11-22 21:12:20,420 INFO:     Found new best model at epoch 72
2022-11-22 21:12:20,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:20,421 INFO:     Epoch: 73
2022-11-22 21:12:21,228 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7872699329798872, 'Total loss': 0.7872699329798872} | train loss {'Reaction outcome loss': 0.7591355881623684, 'Total loss': 0.7591355881623684}
2022-11-22 21:12:21,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:21,229 INFO:     Epoch: 74
2022-11-22 21:12:22,104 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.777481348677115, 'Total loss': 0.777481348677115} | train loss {'Reaction outcome loss': 0.7502261419450084, 'Total loss': 0.7502261419450084}
2022-11-22 21:12:22,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:22,104 INFO:     Epoch: 75
2022-11-22 21:12:22,927 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.791517315263098, 'Total loss': 0.791517315263098} | train loss {'Reaction outcome loss': 0.7520550968305718, 'Total loss': 0.7520550968305718}
2022-11-22 21:12:22,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:22,927 INFO:     Epoch: 76
2022-11-22 21:12:23,733 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.756120116873221, 'Total loss': 0.756120116873221} | train loss {'Reaction outcome loss': 0.742912732064724, 'Total loss': 0.742912732064724}
2022-11-22 21:12:23,733 INFO:     Found new best model at epoch 76
2022-11-22 21:12:23,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:23,734 INFO:     Epoch: 77
2022-11-22 21:12:24,574 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7930488322268833, 'Total loss': 0.7930488322268833} | train loss {'Reaction outcome loss': 0.7446294922021127, 'Total loss': 0.7446294922021127}
2022-11-22 21:12:24,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:24,575 INFO:     Epoch: 78
2022-11-22 21:12:25,409 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7755198979919607, 'Total loss': 0.7755198979919607} | train loss {'Reaction outcome loss': 0.7497103128942751, 'Total loss': 0.7497103128942751}
2022-11-22 21:12:25,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:25,409 INFO:     Epoch: 79
2022-11-22 21:12:26,281 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7585099183700301, 'Total loss': 0.7585099183700301} | train loss {'Reaction outcome loss': 0.7405034500745035, 'Total loss': 0.7405034500745035}
2022-11-22 21:12:26,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:26,282 INFO:     Epoch: 80
2022-11-22 21:12:27,161 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7622297487475655, 'Total loss': 0.7622297487475655} | train loss {'Reaction outcome loss': 0.7458771617422181, 'Total loss': 0.7458771617422181}
2022-11-22 21:12:27,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:27,162 INFO:     Epoch: 81
2022-11-22 21:12:28,010 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7645278451117602, 'Total loss': 0.7645278451117602} | train loss {'Reaction outcome loss': 0.7388385331198093, 'Total loss': 0.7388385331198093}
2022-11-22 21:12:28,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:28,010 INFO:     Epoch: 82
2022-11-22 21:12:28,897 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.75229492851279, 'Total loss': 0.75229492851279} | train loss {'Reaction outcome loss': 0.7365331074162837, 'Total loss': 0.7365331074162837}
2022-11-22 21:12:28,897 INFO:     Found new best model at epoch 82
2022-11-22 21:12:28,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:28,898 INFO:     Epoch: 83
2022-11-22 21:12:29,728 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7606594183228232, 'Total loss': 0.7606594183228232} | train loss {'Reaction outcome loss': 0.7360501174003847, 'Total loss': 0.7360501174003847}
2022-11-22 21:12:29,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:29,729 INFO:     Epoch: 84
2022-11-22 21:12:30,500 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.780076989396052, 'Total loss': 0.780076989396052} | train loss {'Reaction outcome loss': 0.7323472617614654, 'Total loss': 0.7323472617614654}
2022-11-22 21:12:30,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:30,500 INFO:     Epoch: 85
2022-11-22 21:12:31,320 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.811576749113473, 'Total loss': 0.811576749113473} | train loss {'Reaction outcome loss': 0.7287494283049337, 'Total loss': 0.7287494283049337}
2022-11-22 21:12:31,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:31,320 INFO:     Epoch: 86
2022-11-22 21:12:32,151 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7628442367369478, 'Total loss': 0.7628442367369478} | train loss {'Reaction outcome loss': 0.7226631368600553, 'Total loss': 0.7226631368600553}
2022-11-22 21:12:32,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:32,152 INFO:     Epoch: 87
2022-11-22 21:12:32,997 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7806253738024018, 'Total loss': 0.7806253738024018} | train loss {'Reaction outcome loss': 0.7309878134439068, 'Total loss': 0.7309878134439068}
2022-11-22 21:12:32,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:32,998 INFO:     Epoch: 88
2022-11-22 21:12:33,875 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.749993119050156, 'Total loss': 0.749993119050156} | train loss {'Reaction outcome loss': 0.7246701048026162, 'Total loss': 0.7246701048026162}
2022-11-22 21:12:33,875 INFO:     Found new best model at epoch 88
2022-11-22 21:12:33,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:33,876 INFO:     Epoch: 89
2022-11-22 21:12:34,658 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8260993964292787, 'Total loss': 0.8260993964292787} | train loss {'Reaction outcome loss': 0.7197843558124958, 'Total loss': 0.7197843558124958}
2022-11-22 21:12:34,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:34,658 INFO:     Epoch: 90
2022-11-22 21:12:35,521 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7451335936784744, 'Total loss': 0.7451335936784744} | train loss {'Reaction outcome loss': 0.721097407682288, 'Total loss': 0.721097407682288}
2022-11-22 21:12:35,521 INFO:     Found new best model at epoch 90
2022-11-22 21:12:35,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:35,522 INFO:     Epoch: 91
2022-11-22 21:12:36,302 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7383980046619069, 'Total loss': 0.7383980046619069} | train loss {'Reaction outcome loss': 0.7152797281742096, 'Total loss': 0.7152797281742096}
2022-11-22 21:12:36,303 INFO:     Found new best model at epoch 91
2022-11-22 21:12:36,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:36,304 INFO:     Epoch: 92
2022-11-22 21:12:37,080 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.772568173029206, 'Total loss': 0.772568173029206} | train loss {'Reaction outcome loss': 0.7264387701307574, 'Total loss': 0.7264387701307574}
2022-11-22 21:12:37,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:37,080 INFO:     Epoch: 93
2022-11-22 21:12:37,877 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7638362768021497, 'Total loss': 0.7638362768021497} | train loss {'Reaction outcome loss': 0.7210220486646698, 'Total loss': 0.7210220486646698}
2022-11-22 21:12:37,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:37,877 INFO:     Epoch: 94
2022-11-22 21:12:38,657 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7670685581185601, 'Total loss': 0.7670685581185601} | train loss {'Reaction outcome loss': 0.7241614803431495, 'Total loss': 0.7241614803431495}
2022-11-22 21:12:38,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:38,657 INFO:     Epoch: 95
2022-11-22 21:12:39,480 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7843482738191431, 'Total loss': 0.7843482738191431} | train loss {'Reaction outcome loss': 0.7184689787607039, 'Total loss': 0.7184689787607039}
2022-11-22 21:12:39,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:39,480 INFO:     Epoch: 96
2022-11-22 21:12:40,343 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7545229271054268, 'Total loss': 0.7545229271054268} | train loss {'Reaction outcome loss': 0.7262725741151841, 'Total loss': 0.7262725741151841}
2022-11-22 21:12:40,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:40,343 INFO:     Epoch: 97
2022-11-22 21:12:41,159 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8023677387020804, 'Total loss': 0.8023677387020804} | train loss {'Reaction outcome loss': 0.7206996845141533, 'Total loss': 0.7206996845141533}
2022-11-22 21:12:41,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:41,159 INFO:     Epoch: 98
2022-11-22 21:12:41,945 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8369542617689479, 'Total loss': 0.8369542617689479} | train loss {'Reaction outcome loss': 0.7274811384418318, 'Total loss': 0.7274811384418318}
2022-11-22 21:12:41,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:41,946 INFO:     Epoch: 99
2022-11-22 21:12:42,798 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7482637004418806, 'Total loss': 0.7482637004418806} | train loss {'Reaction outcome loss': 0.7262185203932947, 'Total loss': 0.7262185203932947}
2022-11-22 21:12:42,798 INFO:     Best model found after epoch 92 of 100.
2022-11-22 21:12:42,798 INFO:   Done with stage: TRAINING
2022-11-22 21:12:42,798 INFO:   Starting stage: EVALUATION
2022-11-22 21:12:42,913 INFO:   Done with stage: EVALUATION
2022-11-22 21:12:42,914 INFO:   Leaving out SEQ value Fold_9
2022-11-22 21:12:42,927 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 21:12:42,927 INFO:   Starting stage: FEATURE SCALING
2022-11-22 21:12:43,620 INFO:   Done with stage: FEATURE SCALING
2022-11-22 21:12:43,620 INFO:   Starting stage: SCALING TARGETS
2022-11-22 21:12:43,691 INFO:   Done with stage: SCALING TARGETS
2022-11-22 21:12:43,692 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:12:43,692 INFO:     No hyperparam tuning for this model
2022-11-22 21:12:43,692 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 21:12:43,692 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 21:12:43,693 INFO:     None feature selector for col prot
2022-11-22 21:12:43,693 INFO:     None feature selector for col prot
2022-11-22 21:12:43,693 INFO:     None feature selector for col prot
2022-11-22 21:12:43,694 INFO:     None feature selector for col chem
2022-11-22 21:12:43,694 INFO:     None feature selector for col chem
2022-11-22 21:12:43,694 INFO:     None feature selector for col chem
2022-11-22 21:12:43,694 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 21:12:43,694 INFO:   Starting stage: BUILD MODEL
2022-11-22 21:12:43,695 INFO:     Number of params in model 126091
2022-11-22 21:12:43,699 INFO:   Done with stage: BUILD MODEL
2022-11-22 21:12:43,699 INFO:   Starting stage: TRAINING
2022-11-22 21:12:43,750 INFO:     Val loss before train {'Reaction outcome loss': 1.0046157403425737, 'Total loss': 1.0046157403425737}
2022-11-22 21:12:43,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:43,750 INFO:     Epoch: 0
2022-11-22 21:12:44,591 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8072130612351678, 'Total loss': 0.8072130612351678} | train loss {'Reaction outcome loss': 0.8924883978086927, 'Total loss': 0.8924883978086927}
2022-11-22 21:12:44,592 INFO:     Found new best model at epoch 0
2022-11-22 21:12:44,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:44,593 INFO:     Epoch: 1
2022-11-22 21:12:45,397 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8100533945993944, 'Total loss': 0.8100533945993944} | train loss {'Reaction outcome loss': 0.8499617052946978, 'Total loss': 0.8499617052946978}
2022-11-22 21:12:45,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:45,397 INFO:     Epoch: 2
2022-11-22 21:12:46,214 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8300569863481955, 'Total loss': 0.8300569863481955} | train loss {'Reaction outcome loss': 0.8438292082987333, 'Total loss': 0.8438292082987333}
2022-11-22 21:12:46,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:46,215 INFO:     Epoch: 3
2022-11-22 21:12:47,016 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8035620694810693, 'Total loss': 0.8035620694810693} | train loss {'Reaction outcome loss': 0.8428744969339024, 'Total loss': 0.8428744969339024}
2022-11-22 21:12:47,016 INFO:     Found new best model at epoch 3
2022-11-22 21:12:47,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:47,017 INFO:     Epoch: 4
2022-11-22 21:12:47,828 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7776059779253873, 'Total loss': 0.7776059779253873} | train loss {'Reaction outcome loss': 0.8367443047313072, 'Total loss': 0.8367443047313072}
2022-11-22 21:12:47,828 INFO:     Found new best model at epoch 4
2022-11-22 21:12:47,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:47,829 INFO:     Epoch: 5
2022-11-22 21:12:48,626 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8022386851635847, 'Total loss': 0.8022386851635847} | train loss {'Reaction outcome loss': 0.830114643221442, 'Total loss': 0.830114643221442}
2022-11-22 21:12:48,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:48,628 INFO:     Epoch: 6
2022-11-22 21:12:49,440 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7930678264661268, 'Total loss': 0.7930678264661268} | train loss {'Reaction outcome loss': 0.8237359266170123, 'Total loss': 0.8237359266170123}
2022-11-22 21:12:49,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:49,440 INFO:     Epoch: 7
2022-11-22 21:12:50,199 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7949106422337618, 'Total loss': 0.7949106422337618} | train loss {'Reaction outcome loss': 0.8278713915270832, 'Total loss': 0.8278713915270832}
2022-11-22 21:12:50,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:50,199 INFO:     Epoch: 8
2022-11-22 21:12:50,972 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7902061993425543, 'Total loss': 0.7902061993425543} | train loss {'Reaction outcome loss': 0.8268070508111344, 'Total loss': 0.8268070508111344}
2022-11-22 21:12:50,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:50,973 INFO:     Epoch: 9
2022-11-22 21:12:51,807 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7890526699748907, 'Total loss': 0.7890526699748907} | train loss {'Reaction outcome loss': 0.8249765638156459, 'Total loss': 0.8249765638156459}
2022-11-22 21:12:51,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:51,807 INFO:     Epoch: 10
2022-11-22 21:12:52,599 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7885349345478144, 'Total loss': 0.7885349345478144} | train loss {'Reaction outcome loss': 0.8239152009187922, 'Total loss': 0.8239152009187922}
2022-11-22 21:12:52,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:52,599 INFO:     Epoch: 11
2022-11-22 21:12:53,392 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7824752520431172, 'Total loss': 0.7824752520431172} | train loss {'Reaction outcome loss': 0.8144852893072584, 'Total loss': 0.8144852893072584}
2022-11-22 21:12:53,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:53,392 INFO:     Epoch: 12
2022-11-22 21:12:54,139 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7968340096148577, 'Total loss': 0.7968340096148577} | train loss {'Reaction outcome loss': 0.8181358346572289, 'Total loss': 0.8181358346572289}
2022-11-22 21:12:54,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:54,140 INFO:     Epoch: 13
2022-11-22 21:12:54,913 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8014934787696059, 'Total loss': 0.8014934787696059} | train loss {'Reaction outcome loss': 0.8285703548053016, 'Total loss': 0.8285703548053016}
2022-11-22 21:12:54,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:54,914 INFO:     Epoch: 14
2022-11-22 21:12:55,671 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7756442718885161, 'Total loss': 0.7756442718885161} | train loss {'Reaction outcome loss': 0.8092220203596571, 'Total loss': 0.8092220203596571}
2022-11-22 21:12:55,671 INFO:     Found new best model at epoch 14
2022-11-22 21:12:55,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:55,672 INFO:     Epoch: 15
2022-11-22 21:12:56,394 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7716539756140925, 'Total loss': 0.7716539756140925} | train loss {'Reaction outcome loss': 0.8134591387592347, 'Total loss': 0.8134591387592347}
2022-11-22 21:12:56,394 INFO:     Found new best model at epoch 15
2022-11-22 21:12:56,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:56,395 INFO:     Epoch: 16
2022-11-22 21:12:57,172 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7687623981725086, 'Total loss': 0.7687623981725086} | train loss {'Reaction outcome loss': 0.8126403463755542, 'Total loss': 0.8126403463755542}
2022-11-22 21:12:57,172 INFO:     Found new best model at epoch 16
2022-11-22 21:12:57,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:57,173 INFO:     Epoch: 17
2022-11-22 21:12:57,942 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7686434293335135, 'Total loss': 0.7686434293335135} | train loss {'Reaction outcome loss': 0.8090428630651733, 'Total loss': 0.8090428630651733}
2022-11-22 21:12:57,943 INFO:     Found new best model at epoch 17
2022-11-22 21:12:57,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:57,944 INFO:     Epoch: 18
2022-11-22 21:12:58,700 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7670909491452303, 'Total loss': 0.7670909491452303} | train loss {'Reaction outcome loss': 0.801117724373273, 'Total loss': 0.801117724373273}
2022-11-22 21:12:58,700 INFO:     Found new best model at epoch 18
2022-11-22 21:12:58,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:58,701 INFO:     Epoch: 19
2022-11-22 21:12:59,466 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7663945372809063, 'Total loss': 0.7663945372809063} | train loss {'Reaction outcome loss': 0.8085571099148106, 'Total loss': 0.8085571099148106}
2022-11-22 21:12:59,466 INFO:     Found new best model at epoch 19
2022-11-22 21:12:59,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:12:59,467 INFO:     Epoch: 20
2022-11-22 21:13:00,213 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7573025172406976, 'Total loss': 0.7573025172406976} | train loss {'Reaction outcome loss': 0.8083039378588982, 'Total loss': 0.8083039378588982}
2022-11-22 21:13:00,213 INFO:     Found new best model at epoch 20
2022-11-22 21:13:00,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:00,214 INFO:     Epoch: 21
2022-11-22 21:13:00,981 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7762038640000604, 'Total loss': 0.7762038640000604} | train loss {'Reaction outcome loss': 0.8138511295502002, 'Total loss': 0.8138511295502002}
2022-11-22 21:13:00,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:00,981 INFO:     Epoch: 22
2022-11-22 21:13:01,734 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7568721906705336, 'Total loss': 0.7568721906705336} | train loss {'Reaction outcome loss': 0.8059197497452318, 'Total loss': 0.8059197497452318}
2022-11-22 21:13:01,734 INFO:     Found new best model at epoch 22
2022-11-22 21:13:01,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:01,735 INFO:     Epoch: 23
2022-11-22 21:13:02,524 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8137668079950593, 'Total loss': 0.8137668079950593} | train loss {'Reaction outcome loss': 0.807490820404489, 'Total loss': 0.807490820404489}
2022-11-22 21:13:02,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:02,524 INFO:     Epoch: 24
2022-11-22 21:13:03,304 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7781207466667349, 'Total loss': 0.7781207466667349} | train loss {'Reaction outcome loss': 0.8038253915696009, 'Total loss': 0.8038253915696009}
2022-11-22 21:13:03,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:03,304 INFO:     Epoch: 25
2022-11-22 21:13:04,070 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7743476818908345, 'Total loss': 0.7743476818908345} | train loss {'Reaction outcome loss': 0.812045850734479, 'Total loss': 0.812045850734479}
2022-11-22 21:13:04,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:04,071 INFO:     Epoch: 26
2022-11-22 21:13:04,858 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7625177638097242, 'Total loss': 0.7625177638097242} | train loss {'Reaction outcome loss': 0.8061184056616022, 'Total loss': 0.8061184056616022}
2022-11-22 21:13:04,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:04,859 INFO:     Epoch: 27
2022-11-22 21:13:05,626 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7563612041148272, 'Total loss': 0.7563612041148272} | train loss {'Reaction outcome loss': 0.8015089833784682, 'Total loss': 0.8015089833784682}
2022-11-22 21:13:05,626 INFO:     Found new best model at epoch 27
2022-11-22 21:13:05,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:05,627 INFO:     Epoch: 28
2022-11-22 21:13:06,389 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7609795182943344, 'Total loss': 0.7609795182943344} | train loss {'Reaction outcome loss': 0.7973205216741754, 'Total loss': 0.7973205216741754}
2022-11-22 21:13:06,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:06,389 INFO:     Epoch: 29
2022-11-22 21:13:07,131 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7633343284780328, 'Total loss': 0.7633343284780328} | train loss {'Reaction outcome loss': 0.7999499173540818, 'Total loss': 0.7999499173540818}
2022-11-22 21:13:07,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:07,132 INFO:     Epoch: 30
2022-11-22 21:13:07,897 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7451800846240737, 'Total loss': 0.7451800846240737} | train loss {'Reaction outcome loss': 0.7947833123296378, 'Total loss': 0.7947833123296378}
2022-11-22 21:13:07,897 INFO:     Found new best model at epoch 30
2022-11-22 21:13:07,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:07,898 INFO:     Epoch: 31
2022-11-22 21:13:08,674 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7522480684247884, 'Total loss': 0.7522480684247884} | train loss {'Reaction outcome loss': 0.7946202124540622, 'Total loss': 0.7946202124540622}
2022-11-22 21:13:08,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:08,674 INFO:     Epoch: 32
2022-11-22 21:13:09,473 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.80881132659587, 'Total loss': 0.80881132659587} | train loss {'Reaction outcome loss': 0.795753934967373, 'Total loss': 0.795753934967373}
2022-11-22 21:13:09,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:09,474 INFO:     Epoch: 33
2022-11-22 21:13:10,275 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7716997584158723, 'Total loss': 0.7716997584158723} | train loss {'Reaction outcome loss': 0.8081446746100298, 'Total loss': 0.8081446746100298}
2022-11-22 21:13:10,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:10,276 INFO:     Epoch: 34
2022-11-22 21:13:11,050 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7658761238509958, 'Total loss': 0.7658761238509958} | train loss {'Reaction outcome loss': 0.7980382532967247, 'Total loss': 0.7980382532967247}
2022-11-22 21:13:11,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:11,050 INFO:     Epoch: 35
2022-11-22 21:13:11,842 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7479388212615793, 'Total loss': 0.7479388212615793} | train loss {'Reaction outcome loss': 0.7950074769224715, 'Total loss': 0.7950074769224715}
2022-11-22 21:13:11,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:11,842 INFO:     Epoch: 36
2022-11-22 21:13:12,601 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7631727741523222, 'Total loss': 0.7631727741523222} | train loss {'Reaction outcome loss': 0.7899955878946704, 'Total loss': 0.7899955878946704}
2022-11-22 21:13:12,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:12,602 INFO:     Epoch: 37
2022-11-22 21:13:13,387 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7444329112768173, 'Total loss': 0.7444329112768173} | train loss {'Reaction outcome loss': 0.8010783154472165, 'Total loss': 0.8010783154472165}
2022-11-22 21:13:13,387 INFO:     Found new best model at epoch 37
2022-11-22 21:13:13,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:13,388 INFO:     Epoch: 38
2022-11-22 21:13:14,146 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7666752528060566, 'Total loss': 0.7666752528060566} | train loss {'Reaction outcome loss': 0.791624189267757, 'Total loss': 0.791624189267757}
2022-11-22 21:13:14,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:14,146 INFO:     Epoch: 39
2022-11-22 21:13:14,998 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7687160962007262, 'Total loss': 0.7687160962007262} | train loss {'Reaction outcome loss': 0.7899703423262607, 'Total loss': 0.7899703423262607}
2022-11-22 21:13:14,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:14,999 INFO:     Epoch: 40
2022-11-22 21:13:15,782 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7974568104202097, 'Total loss': 0.7974568104202097} | train loss {'Reaction outcome loss': 0.7951770150951045, 'Total loss': 0.7951770150951045}
2022-11-22 21:13:15,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:15,782 INFO:     Epoch: 41
2022-11-22 21:13:16,612 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7452137172222137, 'Total loss': 0.7452137172222137} | train loss {'Reaction outcome loss': 0.7876910535912764, 'Total loss': 0.7876910535912764}
2022-11-22 21:13:16,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:16,613 INFO:     Epoch: 42
2022-11-22 21:13:17,358 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7365668470209296, 'Total loss': 0.7365668470209296} | train loss {'Reaction outcome loss': 0.7957686719443151, 'Total loss': 0.7957686719443151}
2022-11-22 21:13:17,358 INFO:     Found new best model at epoch 42
2022-11-22 21:13:17,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:17,359 INFO:     Epoch: 43
2022-11-22 21:13:18,095 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7791370221159675, 'Total loss': 0.7791370221159675} | train loss {'Reaction outcome loss': 0.7848976176036032, 'Total loss': 0.7848976176036032}
2022-11-22 21:13:18,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:18,095 INFO:     Epoch: 44
2022-11-22 21:13:18,869 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7954352037473158, 'Total loss': 0.7954352037473158} | train loss {'Reaction outcome loss': 0.7950714066443656, 'Total loss': 0.7950714066443656}
2022-11-22 21:13:18,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:18,869 INFO:     Epoch: 45
2022-11-22 21:13:19,639 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7372520586306398, 'Total loss': 0.7372520586306398} | train loss {'Reaction outcome loss': 0.7886010089866545, 'Total loss': 0.7886010089866545}
2022-11-22 21:13:19,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:19,639 INFO:     Epoch: 46
2022-11-22 21:13:20,373 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7576723965731534, 'Total loss': 0.7576723965731534} | train loss {'Reaction outcome loss': 0.7883208774120701, 'Total loss': 0.7883208774120701}
2022-11-22 21:13:20,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:20,373 INFO:     Epoch: 47
2022-11-22 21:13:21,168 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7407129887830127, 'Total loss': 0.7407129887830127} | train loss {'Reaction outcome loss': 0.7856670248846294, 'Total loss': 0.7856670248846294}
2022-11-22 21:13:21,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:21,168 INFO:     Epoch: 48
2022-11-22 21:13:21,959 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7339865246956999, 'Total loss': 0.7339865246956999} | train loss {'Reaction outcome loss': 0.8004576096891874, 'Total loss': 0.8004576096891874}
2022-11-22 21:13:21,960 INFO:     Found new best model at epoch 48
2022-11-22 21:13:21,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:21,961 INFO:     Epoch: 49
2022-11-22 21:13:22,751 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7538269107991998, 'Total loss': 0.7538269107991998} | train loss {'Reaction outcome loss': 0.7797278019822078, 'Total loss': 0.7797278019822078}
2022-11-22 21:13:22,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:22,751 INFO:     Epoch: 50
2022-11-22 21:13:23,543 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7437163882634856, 'Total loss': 0.7437163882634856} | train loss {'Reaction outcome loss': 0.7803077499876138, 'Total loss': 0.7803077499876138}
2022-11-22 21:13:23,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:23,544 INFO:     Epoch: 51
2022-11-22 21:13:24,292 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7272653518752619, 'Total loss': 0.7272653518752619} | train loss {'Reaction outcome loss': 0.7834415579674697, 'Total loss': 0.7834415579674697}
2022-11-22 21:13:24,292 INFO:     Found new best model at epoch 51
2022-11-22 21:13:24,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:24,293 INFO:     Epoch: 52
2022-11-22 21:13:25,040 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8024228452281519, 'Total loss': 0.8024228452281519} | train loss {'Reaction outcome loss': 0.7777496768154113, 'Total loss': 0.7777496768154113}
2022-11-22 21:13:25,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:25,040 INFO:     Epoch: 53
2022-11-22 21:13:25,821 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7227823700417172, 'Total loss': 0.7227823700417172} | train loss {'Reaction outcome loss': 0.7886733708352696, 'Total loss': 0.7886733708352696}
2022-11-22 21:13:25,822 INFO:     Found new best model at epoch 53
2022-11-22 21:13:25,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:25,822 INFO:     Epoch: 54
2022-11-22 21:13:26,591 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7503012980927121, 'Total loss': 0.7503012980927121} | train loss {'Reaction outcome loss': 0.7815286021845543, 'Total loss': 0.7815286021845543}
2022-11-22 21:13:26,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:26,592 INFO:     Epoch: 55
2022-11-22 21:13:27,372 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7373972352255475, 'Total loss': 0.7373972352255475} | train loss {'Reaction outcome loss': 0.775500060093065, 'Total loss': 0.775500060093065}
2022-11-22 21:13:27,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:27,372 INFO:     Epoch: 56
2022-11-22 21:13:28,105 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7482817802916873, 'Total loss': 0.7482817802916873} | train loss {'Reaction outcome loss': 0.7723653432328691, 'Total loss': 0.7723653432328691}
2022-11-22 21:13:28,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:28,105 INFO:     Epoch: 57
2022-11-22 21:13:28,864 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7191665375774557, 'Total loss': 0.7191665375774557} | train loss {'Reaction outcome loss': 0.7812599136761809, 'Total loss': 0.7812599136761809}
2022-11-22 21:13:28,865 INFO:     Found new best model at epoch 57
2022-11-22 21:13:28,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:28,866 INFO:     Epoch: 58
2022-11-22 21:13:29,605 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7570345449176702, 'Total loss': 0.7570345449176702} | train loss {'Reaction outcome loss': 0.7653977810914218, 'Total loss': 0.7653977810914218}
2022-11-22 21:13:29,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:29,605 INFO:     Epoch: 59
2022-11-22 21:13:30,336 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7184914377602664, 'Total loss': 0.7184914377602664} | train loss {'Reaction outcome loss': 0.7668080606803238, 'Total loss': 0.7668080606803238}
2022-11-22 21:13:30,336 INFO:     Found new best model at epoch 59
2022-11-22 21:13:30,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:30,337 INFO:     Epoch: 60
2022-11-22 21:13:31,062 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7527941648255695, 'Total loss': 0.7527941648255695} | train loss {'Reaction outcome loss': 0.7782684254501513, 'Total loss': 0.7782684254501513}
2022-11-22 21:13:31,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:31,062 INFO:     Epoch: 61
2022-11-22 21:13:31,788 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7262587628581307, 'Total loss': 0.7262587628581307} | train loss {'Reaction outcome loss': 0.7750679266597578, 'Total loss': 0.7750679266597578}
2022-11-22 21:13:31,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:31,789 INFO:     Epoch: 62
2022-11-22 21:13:32,595 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7405775568702004, 'Total loss': 0.7405775568702004} | train loss {'Reaction outcome loss': 0.7649805701454642, 'Total loss': 0.7649805701454642}
2022-11-22 21:13:32,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:32,595 INFO:     Epoch: 63
2022-11-22 21:13:33,359 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7185165719552473, 'Total loss': 0.7185165719552473} | train loss {'Reaction outcome loss': 0.7700692703608076, 'Total loss': 0.7700692703608076}
2022-11-22 21:13:33,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:33,359 INFO:     Epoch: 64
2022-11-22 21:13:34,111 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7435123412446543, 'Total loss': 0.7435123412446543} | train loss {'Reaction outcome loss': 0.7613778021412823, 'Total loss': 0.7613778021412823}
2022-11-22 21:13:34,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:34,111 INFO:     Epoch: 65
2022-11-22 21:13:34,829 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7259150580926375, 'Total loss': 0.7259150580926375} | train loss {'Reaction outcome loss': 0.7551519955972187, 'Total loss': 0.7551519955972187}
2022-11-22 21:13:34,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:34,829 INFO:     Epoch: 66
2022-11-22 21:13:35,596 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7638612762093544, 'Total loss': 0.7638612762093544} | train loss {'Reaction outcome loss': 0.7510106089385414, 'Total loss': 0.7510106089385414}
2022-11-22 21:13:35,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:35,597 INFO:     Epoch: 67
2022-11-22 21:13:36,376 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7101106555624441, 'Total loss': 0.7101106555624441} | train loss {'Reaction outcome loss': 0.7593600286645927, 'Total loss': 0.7593600286645927}
2022-11-22 21:13:36,376 INFO:     Found new best model at epoch 67
2022-11-22 21:13:36,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:36,377 INFO:     Epoch: 68
2022-11-22 21:13:37,075 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7459840090437369, 'Total loss': 0.7459840090437369} | train loss {'Reaction outcome loss': 0.7486339801477517, 'Total loss': 0.7486339801477517}
2022-11-22 21:13:37,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:37,075 INFO:     Epoch: 69
2022-11-22 21:13:37,848 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7259182022376494, 'Total loss': 0.7259182022376494} | train loss {'Reaction outcome loss': 0.7541705648064131, 'Total loss': 0.7541705648064131}
2022-11-22 21:13:37,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:37,848 INFO:     Epoch: 70
2022-11-22 21:13:38,623 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7409932254390283, 'Total loss': 0.7409932254390283} | train loss {'Reaction outcome loss': 0.7441923027247311, 'Total loss': 0.7441923027247311}
2022-11-22 21:13:38,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:38,623 INFO:     Epoch: 71
2022-11-22 21:13:39,385 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.6945300447669897, 'Total loss': 0.6945300447669897} | train loss {'Reaction outcome loss': 0.7525995280819866, 'Total loss': 0.7525995280819866}
2022-11-22 21:13:39,385 INFO:     Found new best model at epoch 71
2022-11-22 21:13:39,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:39,386 INFO:     Epoch: 72
2022-11-22 21:13:40,130 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7075000500137155, 'Total loss': 0.7075000500137155} | train loss {'Reaction outcome loss': 0.7363106656653678, 'Total loss': 0.7363106656653678}
2022-11-22 21:13:40,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:40,131 INFO:     Epoch: 73
2022-11-22 21:13:40,859 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7219024490226399, 'Total loss': 0.7219024490226399} | train loss {'Reaction outcome loss': 0.7372213390312696, 'Total loss': 0.7372213390312696}
2022-11-22 21:13:40,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:40,859 INFO:     Epoch: 74
2022-11-22 21:13:41,629 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.684112237258391, 'Total loss': 0.684112237258391} | train loss {'Reaction outcome loss': 0.7363766738277698, 'Total loss': 0.7363766738277698}
2022-11-22 21:13:41,629 INFO:     Found new best model at epoch 74
2022-11-22 21:13:41,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:41,630 INFO:     Epoch: 75
2022-11-22 21:13:42,403 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7407706955617125, 'Total loss': 0.7407706955617125} | train loss {'Reaction outcome loss': 0.7525687706373964, 'Total loss': 0.7525687706373964}
2022-11-22 21:13:42,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:42,404 INFO:     Epoch: 76
2022-11-22 21:13:43,137 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7124434147368778, 'Total loss': 0.7124434147368778} | train loss {'Reaction outcome loss': 0.7496204493861449, 'Total loss': 0.7496204493861449}
2022-11-22 21:13:43,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:43,137 INFO:     Epoch: 77
2022-11-22 21:13:43,858 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.6895233934575861, 'Total loss': 0.6895233934575861} | train loss {'Reaction outcome loss': 0.7341704766759988, 'Total loss': 0.7341704766759988}
2022-11-22 21:13:43,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:43,858 INFO:     Epoch: 78
2022-11-22 21:13:44,593 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6914558993144468, 'Total loss': 0.6914558993144468} | train loss {'Reaction outcome loss': 0.7333502016569439, 'Total loss': 0.7333502016569439}
2022-11-22 21:13:44,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:44,594 INFO:     Epoch: 79
2022-11-22 21:13:45,325 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7009571208195253, 'Total loss': 0.7009571208195253} | train loss {'Reaction outcome loss': 0.7401081870200663, 'Total loss': 0.7401081870200663}
2022-11-22 21:13:45,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:45,326 INFO:     Epoch: 80
2022-11-22 21:13:46,068 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7184111442078244, 'Total loss': 0.7184111442078244} | train loss {'Reaction outcome loss': 0.7347816221777969, 'Total loss': 0.7347816221777969}
2022-11-22 21:13:46,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:46,068 INFO:     Epoch: 81
2022-11-22 21:13:46,855 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6888375648043372, 'Total loss': 0.6888375648043372} | train loss {'Reaction outcome loss': 0.7379595589661888, 'Total loss': 0.7379595589661888}
2022-11-22 21:13:46,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:46,855 INFO:     Epoch: 82
2022-11-22 21:13:47,604 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7223499979485165, 'Total loss': 0.7223499979485165} | train loss {'Reaction outcome loss': 0.7242122779973605, 'Total loss': 0.7242122779973605}
2022-11-22 21:13:47,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:47,605 INFO:     Epoch: 83
2022-11-22 21:13:48,357 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7443585128269412, 'Total loss': 0.7443585128269412} | train loss {'Reaction outcome loss': 0.7323983361122579, 'Total loss': 0.7323983361122579}
2022-11-22 21:13:48,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:48,358 INFO:     Epoch: 84
2022-11-22 21:13:49,145 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7043778178366747, 'Total loss': 0.7043778178366747} | train loss {'Reaction outcome loss': 0.7342028494336104, 'Total loss': 0.7342028494336104}
2022-11-22 21:13:49,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:49,146 INFO:     Epoch: 85
2022-11-22 21:13:49,880 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7147127870808948, 'Total loss': 0.7147127870808948} | train loss {'Reaction outcome loss': 0.7344841501083572, 'Total loss': 0.7344841501083572}
2022-11-22 21:13:49,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:49,880 INFO:     Epoch: 86
2022-11-22 21:13:50,623 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6836671178991144, 'Total loss': 0.6836671178991144} | train loss {'Reaction outcome loss': 0.7318603015139036, 'Total loss': 0.7318603015139036}
2022-11-22 21:13:50,624 INFO:     Found new best model at epoch 86
2022-11-22 21:13:50,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:50,624 INFO:     Epoch: 87
2022-11-22 21:13:51,385 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.693281305784529, 'Total loss': 0.693281305784529} | train loss {'Reaction outcome loss': 0.7322505228673881, 'Total loss': 0.7322505228673881}
2022-11-22 21:13:51,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:51,385 INFO:     Epoch: 88
2022-11-22 21:13:52,192 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7299570495432074, 'Total loss': 0.7299570495432074} | train loss {'Reaction outcome loss': 0.7253262027193178, 'Total loss': 0.7253262027193178}
2022-11-22 21:13:52,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:52,192 INFO:     Epoch: 89
2022-11-22 21:13:52,933 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7206228626045313, 'Total loss': 0.7206228626045313} | train loss {'Reaction outcome loss': 0.737335183420162, 'Total loss': 0.737335183420162}
2022-11-22 21:13:52,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:52,933 INFO:     Epoch: 90
2022-11-22 21:13:53,701 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.702248873358423, 'Total loss': 0.702248873358423} | train loss {'Reaction outcome loss': 0.7308483491180396, 'Total loss': 0.7308483491180396}
2022-11-22 21:13:53,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:53,701 INFO:     Epoch: 91
2022-11-22 21:13:54,469 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7557000951333479, 'Total loss': 0.7557000951333479} | train loss {'Reaction outcome loss': 0.7397655372918859, 'Total loss': 0.7397655372918859}
2022-11-22 21:13:54,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:54,469 INFO:     Epoch: 92
2022-11-22 21:13:55,231 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.709205456755378, 'Total loss': 0.709205456755378} | train loss {'Reaction outcome loss': 0.7474325148441531, 'Total loss': 0.7474325148441531}
2022-11-22 21:13:55,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:55,232 INFO:     Epoch: 93
2022-11-22 21:13:55,946 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7017540945248171, 'Total loss': 0.7017540945248171} | train loss {'Reaction outcome loss': 0.7387574567244604, 'Total loss': 0.7387574567244604}
2022-11-22 21:13:55,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:55,946 INFO:     Epoch: 94
2022-11-22 21:13:56,682 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7011634226549756, 'Total loss': 0.7011634226549756} | train loss {'Reaction outcome loss': 0.733578304288841, 'Total loss': 0.733578304288841}
2022-11-22 21:13:56,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:56,682 INFO:     Epoch: 95
2022-11-22 21:13:57,429 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7120201804421165, 'Total loss': 0.7120201804421165} | train loss {'Reaction outcome loss': 0.7186653512088876, 'Total loss': 0.7186653512088876}
2022-11-22 21:13:57,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:57,429 INFO:     Epoch: 96
2022-11-22 21:13:58,148 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7025529857386242, 'Total loss': 0.7025529857386242} | train loss {'Reaction outcome loss': 0.7241493725342306, 'Total loss': 0.7241493725342306}
2022-11-22 21:13:58,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:58,149 INFO:     Epoch: 97
2022-11-22 21:13:58,889 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6915264786644415, 'Total loss': 0.6915264786644415} | train loss {'Reaction outcome loss': 0.726176502733578, 'Total loss': 0.726176502733578}
2022-11-22 21:13:58,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:58,889 INFO:     Epoch: 98
2022-11-22 21:13:59,640 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7041161087426272, 'Total loss': 0.7041161087426272} | train loss {'Reaction outcome loss': 0.7279360202039301, 'Total loss': 0.7279360202039301}
2022-11-22 21:13:59,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 21:13:59,641 INFO:     Epoch: 99
2022-11-22 21:14:00,418 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7153273888609626, 'Total loss': 0.7153273888609626} | train loss {'Reaction outcome loss': 0.7302766978620034, 'Total loss': 0.7302766978620034}
2022-11-22 21:14:00,418 INFO:     Best model found after epoch 87 of 100.
2022-11-22 21:14:00,419 INFO:   Done with stage: TRAINING
2022-11-22 21:14:00,419 INFO:   Starting stage: EVALUATION
2022-11-22 21:14:00,537 INFO:   Done with stage: EVALUATION
2022-11-22 21:14:00,537 INFO: Done with stage: RUNNING SPLITS
2022-11-22 21:14:00,537 INFO: Starting stage: COMPUTE METRICS
2022-11-22 21:14:01,739 INFO: Done with stage: COMPUTE METRICS
2022-11-22 21:14:01,739 INFO: Starting stage: EXPORT RESULTS
2022-11-22 21:14:01,757 INFO:   Final results averaged over 50 folds: 
2022-11-22 21:14:01,760 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.241868           NaN  0.344326       NaN
2022-11-22 21:14:03,429 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-22 21:14:03,435 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-22 21:14:03,437 DEBUG:   interactive is False
2022-11-22 21:14:03,437 DEBUG:   platform is linux
2022-11-22 21:14:03,437 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-22 21:14:03,617 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-22 21:14:03,619 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-22 21:14:04,068 DEBUG:   Loaded backend agg version unknown.
2022-11-22 21:14:04,071 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-22 21:14:04,071 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,071 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,071 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,072 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,073 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,074 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,075 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,075 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,075 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-22 21:14:04,075 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,075 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,075 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,075 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-22 21:14:04,075 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,075 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-22 21:14:04,114 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-22 21:14:04,114 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,114 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,114 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,114 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,114 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,114 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-22 21:14:04,114 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,115 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,116 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-22 21:14:04,117 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,117 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-22 21:14:04,126 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-22 21:14:04,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-22 21:14:04,128 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-22 21:14:04,129 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,129 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,129 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-22 21:14:04,129 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-22 21:14:04,129 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-22 21:14:04,129 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-22 21:14:04,586 INFO: Done with stage: EXPORT RESULTS
2022-11-22 21:14:04,587 INFO: Starting stage: SAVE MODEL
2022-11-22 21:14:04,641 INFO: Done with stage: SAVE MODEL
2022-11-22 21:14:04,642 INFO: Wall time for program:  3866.68 seconds
