2022-11-28 03:48:09,730 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/7d68a6c119fbf75c4513fa61e2eaba68/2022_11_28-003831",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "jtvae",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-28 03:48:09,739 INFO: Starting stage: BUILD FEATURIZERS
2022-11-28 03:48:09,744 INFO:   Creating esm representation model
2022-11-28 03:48:09,744 INFO:   Done esm representation model
2022-11-28 03:48:09,745 INFO: Done with stage: BUILD FEATURIZERS
2022-11-28 03:48:09,745 INFO: Starting stage: BUILDING DATASET
2022-11-28 03:48:09,797 INFO: Done with stage: BUILDING DATASET
2022-11-28 03:48:09,797 INFO: Starting stage: FEATURIZING DATA
2022-11-28 03:48:09,797 INFO:   Featurizing proteins
2022-11-28 03:48:09,799 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-28 03:48:09,817 INFO:   Loaded feature cache of size 204
2022-11-28 03:48:09,818 INFO:   Starting to pool ESM Embeddings
2022-11-28 03:48:09,907 INFO:   Featurizing molecules
2022-11-28 03:48:09,929 INFO: Done with stage: FEATURIZING DATA
2022-11-28 03:48:09,929 INFO: Starting stage: RUNNING SPLITS
2022-11-28 03:48:09,937 INFO:   Leaving out SEQ value Fold_0
2022-11-28 03:48:09,951 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 03:48:09,951 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:48:10,607 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:48:10,607 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:48:10,673 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:48:10,673 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:48:10,673 INFO:     No hyperparam tuning for this model
2022-11-28 03:48:10,673 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:48:10,673 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:48:10,674 INFO:     None feature selector for col prot
2022-11-28 03:48:10,674 INFO:     None feature selector for col prot
2022-11-28 03:48:10,674 INFO:     None feature selector for col prot
2022-11-28 03:48:10,674 INFO:     None feature selector for col chem
2022-11-28 03:48:10,675 INFO:     None feature selector for col chem
2022-11-28 03:48:10,675 INFO:     None feature selector for col chem
2022-11-28 03:48:10,675 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:48:10,675 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:48:10,676 INFO:     Number of params in model 169651
2022-11-28 03:48:10,676 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:48:10,676 INFO:   Starting stage: TRAINING
2022-11-28 03:48:12,716 INFO:     Val loss before train {'Reaction outcome loss': 1.0186892941940662, 'Total loss': 1.0186892941940662}
2022-11-28 03:48:12,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:12,716 INFO:     Epoch: 0
2022-11-28 03:48:13,367 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6000913284545721, 'Total loss': 0.6000913284545721} | train loss {'Reaction outcome loss': 0.6780246360624422, 'Total loss': 0.6780246360624422}
2022-11-28 03:48:13,368 INFO:     Found new best model at epoch 0
2022-11-28 03:48:13,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:13,368 INFO:     Epoch: 1
2022-11-28 03:48:14,015 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5744980781577355, 'Total loss': 0.5744980781577355} | train loss {'Reaction outcome loss': 0.5656023650872902, 'Total loss': 0.5656023650872902}
2022-11-28 03:48:14,015 INFO:     Found new best model at epoch 1
2022-11-28 03:48:14,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:14,016 INFO:     Epoch: 2
2022-11-28 03:48:14,661 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5880238448464593, 'Total loss': 0.5880238448464593} | train loss {'Reaction outcome loss': 0.5411317796736467, 'Total loss': 0.5411317796736467}
2022-11-28 03:48:14,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:14,661 INFO:     Epoch: 3
2022-11-28 03:48:15,306 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5259569800177286, 'Total loss': 0.5259569800177286} | train loss {'Reaction outcome loss': 0.5308074335582921, 'Total loss': 0.5308074335582921}
2022-11-28 03:48:15,306 INFO:     Found new best model at epoch 3
2022-11-28 03:48:15,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:15,307 INFO:     Epoch: 4
2022-11-28 03:48:15,950 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5548293521237928, 'Total loss': 0.5548293521237928} | train loss {'Reaction outcome loss': 0.5102607119278829, 'Total loss': 0.5102607119278829}
2022-11-28 03:48:15,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:15,950 INFO:     Epoch: 5
2022-11-28 03:48:16,595 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5309594550798106, 'Total loss': 0.5309594550798106} | train loss {'Reaction outcome loss': 0.489333589912438, 'Total loss': 0.489333589912438}
2022-11-28 03:48:16,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:16,595 INFO:     Epoch: 6
2022-11-28 03:48:17,240 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5390912394884021, 'Total loss': 0.5390912394884021} | train loss {'Reaction outcome loss': 0.4916533636631536, 'Total loss': 0.4916533636631536}
2022-11-28 03:48:17,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:17,240 INFO:     Epoch: 7
2022-11-28 03:48:17,888 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5379775419484737, 'Total loss': 0.5379775419484737} | train loss {'Reaction outcome loss': 0.4893380989183168, 'Total loss': 0.4893380989183168}
2022-11-28 03:48:17,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:17,888 INFO:     Epoch: 8
2022-11-28 03:48:18,528 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5224015497884085, 'Total loss': 0.5224015497884085} | train loss {'Reaction outcome loss': 0.4744180698619514, 'Total loss': 0.4744180698619514}
2022-11-28 03:48:18,529 INFO:     Found new best model at epoch 8
2022-11-28 03:48:18,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:18,529 INFO:     Epoch: 9
2022-11-28 03:48:19,173 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49335100934949033, 'Total loss': 0.49335100934949033} | train loss {'Reaction outcome loss': 0.47989993603503117, 'Total loss': 0.47989993603503117}
2022-11-28 03:48:19,174 INFO:     Found new best model at epoch 9
2022-11-28 03:48:19,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:19,174 INFO:     Epoch: 10
2022-11-28 03:48:19,820 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5065559006707613, 'Total loss': 0.5065559006707613} | train loss {'Reaction outcome loss': 0.47193379248263406, 'Total loss': 0.47193379248263406}
2022-11-28 03:48:19,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:19,821 INFO:     Epoch: 11
2022-11-28 03:48:20,467 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5089078819335893, 'Total loss': 0.5089078819335893} | train loss {'Reaction outcome loss': 0.4734581328439908, 'Total loss': 0.4734581328439908}
2022-11-28 03:48:20,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:20,467 INFO:     Epoch: 12
2022-11-28 03:48:21,110 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5407557948384174, 'Total loss': 0.5407557948384174} | train loss {'Reaction outcome loss': 0.47424467445396984, 'Total loss': 0.47424467445396984}
2022-11-28 03:48:21,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:21,110 INFO:     Epoch: 13
2022-11-28 03:48:21,750 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4920532110818597, 'Total loss': 0.4920532110818597} | train loss {'Reaction outcome loss': 0.47274303808808327, 'Total loss': 0.47274303808808327}
2022-11-28 03:48:21,750 INFO:     Found new best model at epoch 13
2022-11-28 03:48:21,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:21,751 INFO:     Epoch: 14
2022-11-28 03:48:22,400 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5128573283206584, 'Total loss': 0.5128573283206584} | train loss {'Reaction outcome loss': 0.471498972812637, 'Total loss': 0.471498972812637}
2022-11-28 03:48:22,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:22,400 INFO:     Epoch: 15
2022-11-28 03:48:23,043 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5177060046861338, 'Total loss': 0.5177060046861338} | train loss {'Reaction outcome loss': 0.4722897738340448, 'Total loss': 0.4722897738340448}
2022-11-28 03:48:23,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:23,044 INFO:     Epoch: 16
2022-11-28 03:48:23,688 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5039409461409546, 'Total loss': 0.5039409461409546} | train loss {'Reaction outcome loss': 0.460720313438138, 'Total loss': 0.460720313438138}
2022-11-28 03:48:23,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:23,688 INFO:     Epoch: 17
2022-11-28 03:48:24,335 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5561871608329374, 'Total loss': 0.5561871608329374} | train loss {'Reaction outcome loss': 0.46945854566502765, 'Total loss': 0.46945854566502765}
2022-11-28 03:48:24,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:24,335 INFO:     Epoch: 18
2022-11-28 03:48:24,982 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5408273464025453, 'Total loss': 0.5408273464025453} | train loss {'Reaction outcome loss': 0.46519979633024483, 'Total loss': 0.46519979633024483}
2022-11-28 03:48:24,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:24,982 INFO:     Epoch: 19
2022-11-28 03:48:25,625 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5134646081647207, 'Total loss': 0.5134646081647207} | train loss {'Reaction outcome loss': 0.46878722517705357, 'Total loss': 0.46878722517705357}
2022-11-28 03:48:25,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:25,625 INFO:     Epoch: 20
2022-11-28 03:48:26,271 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5125396750694098, 'Total loss': 0.5125396750694098} | train loss {'Reaction outcome loss': 0.46619266552514715, 'Total loss': 0.46619266552514715}
2022-11-28 03:48:26,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:26,272 INFO:     Epoch: 21
2022-11-28 03:48:26,916 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5146667946909749, 'Total loss': 0.5146667946909749} | train loss {'Reaction outcome loss': 0.46589159623521276, 'Total loss': 0.46589159623521276}
2022-11-28 03:48:26,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:26,916 INFO:     Epoch: 22
2022-11-28 03:48:27,561 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5288826733134514, 'Total loss': 0.5288826733134514} | train loss {'Reaction outcome loss': 0.46523025265482604, 'Total loss': 0.46523025265482604}
2022-11-28 03:48:27,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:27,561 INFO:     Epoch: 23
2022-11-28 03:48:28,208 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49451570212841034, 'Total loss': 0.49451570212841034} | train loss {'Reaction outcome loss': 0.46492573518122804, 'Total loss': 0.46492573518122804}
2022-11-28 03:48:28,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:28,208 INFO:     Epoch: 24
2022-11-28 03:48:28,853 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5014711985754412, 'Total loss': 0.5014711985754412} | train loss {'Reaction outcome loss': 0.4637049252747512, 'Total loss': 0.4637049252747512}
2022-11-28 03:48:28,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:28,853 INFO:     Epoch: 25
2022-11-28 03:48:29,504 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49681316974551176, 'Total loss': 0.49681316974551176} | train loss {'Reaction outcome loss': 0.46143147727993666, 'Total loss': 0.46143147727993666}
2022-11-28 03:48:29,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:29,504 INFO:     Epoch: 26
2022-11-28 03:48:30,150 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5451115432173707, 'Total loss': 0.5451115432173707} | train loss {'Reaction outcome loss': 0.45499159029272734, 'Total loss': 0.45499159029272734}
2022-11-28 03:48:30,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:30,150 INFO:     Epoch: 27
2022-11-28 03:48:30,794 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5057779481244642, 'Total loss': 0.5057779481244642} | train loss {'Reaction outcome loss': 0.47454314648372226, 'Total loss': 0.47454314648372226}
2022-11-28 03:48:30,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:30,794 INFO:     Epoch: 28
2022-11-28 03:48:31,440 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5246471838895664, 'Total loss': 0.5246471838895664} | train loss {'Reaction outcome loss': 0.4716824194202658, 'Total loss': 0.4716824194202658}
2022-11-28 03:48:31,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:31,441 INFO:     Epoch: 29
2022-11-28 03:48:32,084 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49621784548426784, 'Total loss': 0.49621784548426784} | train loss {'Reaction outcome loss': 0.46273425911537935, 'Total loss': 0.46273425911537935}
2022-11-28 03:48:32,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:32,085 INFO:     Epoch: 30
2022-11-28 03:48:32,730 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5277426346789958, 'Total loss': 0.5277426346789958} | train loss {'Reaction outcome loss': 0.4606598180825593, 'Total loss': 0.4606598180825593}
2022-11-28 03:48:32,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:32,730 INFO:     Epoch: 31
2022-11-28 03:48:33,373 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5516610824784567, 'Total loss': 0.5516610824784567} | train loss {'Reaction outcome loss': 0.46374506191884884, 'Total loss': 0.46374506191884884}
2022-11-28 03:48:33,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:33,374 INFO:     Epoch: 32
2022-11-28 03:48:34,018 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5356166688508766, 'Total loss': 0.5356166688508766} | train loss {'Reaction outcome loss': 0.46178979951827254, 'Total loss': 0.46178979951827254}
2022-11-28 03:48:34,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:34,018 INFO:     Epoch: 33
2022-11-28 03:48:34,660 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5400563277477441, 'Total loss': 0.5400563277477441} | train loss {'Reaction outcome loss': 0.4644673267593149, 'Total loss': 0.4644673267593149}
2022-11-28 03:48:34,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:34,660 INFO:     Epoch: 34
2022-11-28 03:48:35,305 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5313552039307218, 'Total loss': 0.5313552039307218} | train loss {'Reaction outcome loss': 0.46727101932295034, 'Total loss': 0.46727101932295034}
2022-11-28 03:48:35,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:35,305 INFO:     Epoch: 35
2022-11-28 03:48:35,949 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5233071585034215, 'Total loss': 0.5233071585034215} | train loss {'Reaction outcome loss': 0.46615690463146225, 'Total loss': 0.46615690463146225}
2022-11-28 03:48:35,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:35,949 INFO:     Epoch: 36
2022-11-28 03:48:36,591 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5381718011096467, 'Total loss': 0.5381718011096467} | train loss {'Reaction outcome loss': 0.4702783929886388, 'Total loss': 0.4702783929886388}
2022-11-28 03:48:36,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:36,592 INFO:     Epoch: 37
2022-11-28 03:48:37,238 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5028890336668769, 'Total loss': 0.5028890336668769} | train loss {'Reaction outcome loss': 0.4658682144201193, 'Total loss': 0.4658682144201193}
2022-11-28 03:48:37,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:37,238 INFO:     Epoch: 38
2022-11-28 03:48:37,884 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5265128286771996, 'Total loss': 0.5265128286771996} | train loss {'Reaction outcome loss': 0.46850753636633763, 'Total loss': 0.46850753636633763}
2022-11-28 03:48:37,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:37,884 INFO:     Epoch: 39
2022-11-28 03:48:38,527 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5003583864417187, 'Total loss': 0.5003583864417187} | train loss {'Reaction outcome loss': 0.46857215177084577, 'Total loss': 0.46857215177084577}
2022-11-28 03:48:38,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:38,527 INFO:     Epoch: 40
2022-11-28 03:48:39,168 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.505459058423375, 'Total loss': 0.505459058423375} | train loss {'Reaction outcome loss': 0.46311587226561834, 'Total loss': 0.46311587226561834}
2022-11-28 03:48:39,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:39,169 INFO:     Epoch: 41
2022-11-28 03:48:39,817 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5204545696114384, 'Total loss': 0.5204545696114384} | train loss {'Reaction outcome loss': 0.46947330480716265, 'Total loss': 0.46947330480716265}
2022-11-28 03:48:39,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:39,817 INFO:     Epoch: 42
2022-11-28 03:48:40,469 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.508813469215881, 'Total loss': 0.508813469215881} | train loss {'Reaction outcome loss': 0.4682949681262501, 'Total loss': 0.4682949681262501}
2022-11-28 03:48:40,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:40,469 INFO:     Epoch: 43
2022-11-28 03:48:41,120 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5303568410318952, 'Total loss': 0.5303568410318952} | train loss {'Reaction outcome loss': 0.47024548783531933, 'Total loss': 0.47024548783531933}
2022-11-28 03:48:41,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:41,123 INFO:     Epoch: 44
2022-11-28 03:48:41,773 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5423893692881562, 'Total loss': 0.5423893692881562} | train loss {'Reaction outcome loss': 0.4699683620548639, 'Total loss': 0.4699683620548639}
2022-11-28 03:48:41,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:41,774 INFO:     Epoch: 45
2022-11-28 03:48:42,430 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4929770252039266, 'Total loss': 0.4929770252039266} | train loss {'Reaction outcome loss': 0.46956934334069, 'Total loss': 0.46956934334069}
2022-11-28 03:48:42,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:42,430 INFO:     Epoch: 46
2022-11-28 03:48:43,084 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48746098543322364, 'Total loss': 0.48746098543322364} | train loss {'Reaction outcome loss': 0.4659382510686018, 'Total loss': 0.4659382510686018}
2022-11-28 03:48:43,084 INFO:     Found new best model at epoch 46
2022-11-28 03:48:43,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:43,085 INFO:     Epoch: 47
2022-11-28 03:48:43,740 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5055878903976706, 'Total loss': 0.5055878903976706} | train loss {'Reaction outcome loss': 0.46046016377503757, 'Total loss': 0.46046016377503757}
2022-11-28 03:48:43,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:43,740 INFO:     Epoch: 48
2022-11-28 03:48:44,387 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4870510226072267, 'Total loss': 0.4870510226072267} | train loss {'Reaction outcome loss': 0.4630737054909839, 'Total loss': 0.4630737054909839}
2022-11-28 03:48:44,389 INFO:     Found new best model at epoch 48
2022-11-28 03:48:44,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:44,389 INFO:     Epoch: 49
2022-11-28 03:48:45,037 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4956419460995253, 'Total loss': 0.4956419460995253} | train loss {'Reaction outcome loss': 0.46206989139318466, 'Total loss': 0.46206989139318466}
2022-11-28 03:48:45,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:45,038 INFO:     Epoch: 50
2022-11-28 03:48:45,687 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5021954812975817, 'Total loss': 0.5021954812975817} | train loss {'Reaction outcome loss': 0.46882591775206267, 'Total loss': 0.46882591775206267}
2022-11-28 03:48:45,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:45,688 INFO:     Epoch: 51
2022-11-28 03:48:46,334 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4874002413694249, 'Total loss': 0.4874002413694249} | train loss {'Reaction outcome loss': 0.46563746358771796, 'Total loss': 0.46563746358771796}
2022-11-28 03:48:46,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:46,335 INFO:     Epoch: 52
2022-11-28 03:48:46,978 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4872512373813363, 'Total loss': 0.4872512373813363} | train loss {'Reaction outcome loss': 0.4620333605858146, 'Total loss': 0.4620333605858146}
2022-11-28 03:48:46,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:46,979 INFO:     Epoch: 53
2022-11-28 03:48:47,623 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4966900979363641, 'Total loss': 0.4966900979363641} | train loss {'Reaction outcome loss': 0.46311131467828986, 'Total loss': 0.46311131467828986}
2022-11-28 03:48:47,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:47,623 INFO:     Epoch: 54
2022-11-28 03:48:48,269 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5316772568364476, 'Total loss': 0.5316772568364476} | train loss {'Reaction outcome loss': 0.473160412101472, 'Total loss': 0.473160412101472}
2022-11-28 03:48:48,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:48,269 INFO:     Epoch: 55
2022-11-28 03:48:48,916 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5431226193904877, 'Total loss': 0.5431226193904877} | train loss {'Reaction outcome loss': 0.46933924138057426, 'Total loss': 0.46933924138057426}
2022-11-28 03:48:48,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:48,916 INFO:     Epoch: 56
2022-11-28 03:48:49,561 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5451717106408851, 'Total loss': 0.5451717106408851} | train loss {'Reaction outcome loss': 0.4730968714126798, 'Total loss': 0.4730968714126798}
2022-11-28 03:48:49,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:49,561 INFO:     Epoch: 57
2022-11-28 03:48:50,207 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5264023857754331, 'Total loss': 0.5264023857754331} | train loss {'Reaction outcome loss': 0.4643752270790397, 'Total loss': 0.4643752270790397}
2022-11-28 03:48:50,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:50,207 INFO:     Epoch: 58
2022-11-28 03:48:50,855 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5425481151702792, 'Total loss': 0.5425481151702792} | train loss {'Reaction outcome loss': 0.4610395407090422, 'Total loss': 0.4610395407090422}
2022-11-28 03:48:50,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:50,855 INFO:     Epoch: 59
2022-11-28 03:48:51,501 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5224079176090485, 'Total loss': 0.5224079176090485} | train loss {'Reaction outcome loss': 0.4653398786045489, 'Total loss': 0.4653398786045489}
2022-11-28 03:48:51,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:51,502 INFO:     Epoch: 60
2022-11-28 03:48:52,149 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49710665608561316, 'Total loss': 0.49710665608561316} | train loss {'Reaction outcome loss': 0.46887786973451007, 'Total loss': 0.46887786973451007}
2022-11-28 03:48:52,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:52,150 INFO:     Epoch: 61
2022-11-28 03:48:52,798 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5675665985706241, 'Total loss': 0.5675665985706241} | train loss {'Reaction outcome loss': 0.4661741632907117, 'Total loss': 0.4661741632907117}
2022-11-28 03:48:52,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:52,798 INFO:     Epoch: 62
2022-11-28 03:48:53,445 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5122235403504483, 'Total loss': 0.5122235403504483} | train loss {'Reaction outcome loss': 0.47251961691702, 'Total loss': 0.47251961691702}
2022-11-28 03:48:53,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:53,445 INFO:     Epoch: 63
2022-11-28 03:48:54,092 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5057304106479468, 'Total loss': 0.5057304106479468} | train loss {'Reaction outcome loss': 0.4654303608370609, 'Total loss': 0.4654303608370609}
2022-11-28 03:48:54,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:54,092 INFO:     Epoch: 64
2022-11-28 03:48:54,741 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5052412679029066, 'Total loss': 0.5052412679029066} | train loss {'Reaction outcome loss': 0.4678308146349231, 'Total loss': 0.4678308146349231}
2022-11-28 03:48:54,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:54,741 INFO:     Epoch: 65
2022-11-28 03:48:55,389 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5217051942681157, 'Total loss': 0.5217051942681157} | train loss {'Reaction outcome loss': 0.46721600557937, 'Total loss': 0.46721600557937}
2022-11-28 03:48:55,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:55,389 INFO:     Epoch: 66
2022-11-28 03:48:56,035 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48901658626489863, 'Total loss': 0.48901658626489863} | train loss {'Reaction outcome loss': 0.4682497357125165, 'Total loss': 0.4682497357125165}
2022-11-28 03:48:56,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:56,035 INFO:     Epoch: 67
2022-11-28 03:48:56,680 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5322371256905932, 'Total loss': 0.5322371256905932} | train loss {'Reaction outcome loss': 0.46547248672510755, 'Total loss': 0.46547248672510755}
2022-11-28 03:48:56,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:56,680 INFO:     Epoch: 68
2022-11-28 03:48:57,327 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5036872556043226, 'Total loss': 0.5036872556043226} | train loss {'Reaction outcome loss': 0.46780635721859387, 'Total loss': 0.46780635721859387}
2022-11-28 03:48:57,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:57,327 INFO:     Epoch: 69
2022-11-28 03:48:57,975 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5317430603642797, 'Total loss': 0.5317430603642797} | train loss {'Reaction outcome loss': 0.4614932715098877, 'Total loss': 0.4614932715098877}
2022-11-28 03:48:57,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:57,975 INFO:     Epoch: 70
2022-11-28 03:48:58,622 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.490481810514317, 'Total loss': 0.490481810514317} | train loss {'Reaction outcome loss': 0.4648089707508439, 'Total loss': 0.4648089707508439}
2022-11-28 03:48:58,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:58,622 INFO:     Epoch: 71
2022-11-28 03:48:59,267 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4902562190626943, 'Total loss': 0.4902562190626943} | train loss {'Reaction outcome loss': 0.4665018338404718, 'Total loss': 0.4665018338404718}
2022-11-28 03:48:59,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:59,267 INFO:     Epoch: 72
2022-11-28 03:48:59,915 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49948342109835425, 'Total loss': 0.49948342109835425} | train loss {'Reaction outcome loss': 0.46287700228515216, 'Total loss': 0.46287700228515216}
2022-11-28 03:48:59,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:48:59,916 INFO:     Epoch: 73
2022-11-28 03:49:00,563 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5012688092714133, 'Total loss': 0.5012688092714133} | train loss {'Reaction outcome loss': 0.45948578783723176, 'Total loss': 0.45948578783723176}
2022-11-28 03:49:00,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:00,563 INFO:     Epoch: 74
2022-11-28 03:49:01,209 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49443971348363297, 'Total loss': 0.49443971348363297} | train loss {'Reaction outcome loss': 0.46831353533951964, 'Total loss': 0.46831353533951964}
2022-11-28 03:49:01,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:01,209 INFO:     Epoch: 75
2022-11-28 03:49:01,855 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.53611146398755, 'Total loss': 0.53611146398755} | train loss {'Reaction outcome loss': 0.4706543112082071, 'Total loss': 0.4706543112082071}
2022-11-28 03:49:01,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:01,855 INFO:     Epoch: 76
2022-11-28 03:49:02,500 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5298511108686758, 'Total loss': 0.5298511108686758} | train loss {'Reaction outcome loss': 0.46733074510073075, 'Total loss': 0.46733074510073075}
2022-11-28 03:49:02,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:02,500 INFO:     Epoch: 77
2022-11-28 03:49:03,146 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.504865501855695, 'Total loss': 0.504865501855695} | train loss {'Reaction outcome loss': 0.4596541190489394, 'Total loss': 0.4596541190489394}
2022-11-28 03:49:03,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:03,147 INFO:     Epoch: 78
2022-11-28 03:49:03,791 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5034384353216305, 'Total loss': 0.5034384353216305} | train loss {'Reaction outcome loss': 0.46486267361973155, 'Total loss': 0.46486267361973155}
2022-11-28 03:49:03,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:03,792 INFO:     Epoch: 79
2022-11-28 03:49:04,442 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5031022145304569, 'Total loss': 0.5031022145304569} | train loss {'Reaction outcome loss': 0.4668677498693349, 'Total loss': 0.4668677498693349}
2022-11-28 03:49:04,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:04,442 INFO:     Epoch: 80
2022-11-28 03:49:05,093 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4966366214807643, 'Total loss': 0.4966366214807643} | train loss {'Reaction outcome loss': 0.4686379045492313, 'Total loss': 0.4686379045492313}
2022-11-28 03:49:05,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:05,093 INFO:     Epoch: 81
2022-11-28 03:49:05,741 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5376962024805158, 'Total loss': 0.5376962024805158} | train loss {'Reaction outcome loss': 0.46492153992418384, 'Total loss': 0.46492153992418384}
2022-11-28 03:49:05,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:05,741 INFO:     Epoch: 82
2022-11-28 03:49:06,388 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5155545750329661, 'Total loss': 0.5155545750329661} | train loss {'Reaction outcome loss': 0.47226803591016864, 'Total loss': 0.47226803591016864}
2022-11-28 03:49:06,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:06,388 INFO:     Epoch: 83
2022-11-28 03:49:07,031 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5077132894549259, 'Total loss': 0.5077132894549259} | train loss {'Reaction outcome loss': 0.4721066076919192, 'Total loss': 0.4721066076919192}
2022-11-28 03:49:07,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:07,032 INFO:     Epoch: 84
2022-11-28 03:49:07,676 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.50539538922698, 'Total loss': 0.50539538922698} | train loss {'Reaction outcome loss': 0.4642662719869223, 'Total loss': 0.4642662719869223}
2022-11-28 03:49:07,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:07,676 INFO:     Epoch: 85
2022-11-28 03:49:08,321 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5298715171425842, 'Total loss': 0.5298715171425842} | train loss {'Reaction outcome loss': 0.4665115102514869, 'Total loss': 0.4665115102514869}
2022-11-28 03:49:08,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:08,322 INFO:     Epoch: 86
2022-11-28 03:49:08,966 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5016413091920143, 'Total loss': 0.5016413091920143} | train loss {'Reaction outcome loss': 0.4733049211199166, 'Total loss': 0.4733049211199166}
2022-11-28 03:49:08,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:08,966 INFO:     Epoch: 87
2022-11-28 03:49:09,613 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5009497788756393, 'Total loss': 0.5009497788756393} | train loss {'Reaction outcome loss': 0.4653805949893154, 'Total loss': 0.4653805949893154}
2022-11-28 03:49:09,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:09,613 INFO:     Epoch: 88
2022-11-28 03:49:10,265 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5332139207180157, 'Total loss': 0.5332139207180157} | train loss {'Reaction outcome loss': 0.47329734436801224, 'Total loss': 0.47329734436801224}
2022-11-28 03:49:10,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:10,265 INFO:     Epoch: 89
2022-11-28 03:49:10,913 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.499828269661859, 'Total loss': 0.499828269661859} | train loss {'Reaction outcome loss': 0.47414644996895167, 'Total loss': 0.47414644996895167}
2022-11-28 03:49:10,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:10,913 INFO:     Epoch: 90
2022-11-28 03:49:11,559 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49055809718231824, 'Total loss': 0.49055809718231824} | train loss {'Reaction outcome loss': 0.46609240306205435, 'Total loss': 0.46609240306205435}
2022-11-28 03:49:11,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:11,559 INFO:     Epoch: 91
2022-11-28 03:49:12,210 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5034697544436122, 'Total loss': 0.5034697544436122} | train loss {'Reaction outcome loss': 0.46756669078938295, 'Total loss': 0.46756669078938295}
2022-11-28 03:49:12,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:12,210 INFO:     Epoch: 92
2022-11-28 03:49:12,856 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5181084046530169, 'Total loss': 0.5181084046530169} | train loss {'Reaction outcome loss': 0.4656335188106435, 'Total loss': 0.4656335188106435}
2022-11-28 03:49:12,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:12,856 INFO:     Epoch: 93
2022-11-28 03:49:13,503 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5033678384714348, 'Total loss': 0.5033678384714348} | train loss {'Reaction outcome loss': 0.46681467431490536, 'Total loss': 0.46681467431490536}
2022-11-28 03:49:13,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:13,503 INFO:     Epoch: 94
2022-11-28 03:49:14,153 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5106067768363065, 'Total loss': 0.5106067768363065} | train loss {'Reaction outcome loss': 0.46741823827634094, 'Total loss': 0.46741823827634094}
2022-11-28 03:49:14,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:14,153 INFO:     Epoch: 95
2022-11-28 03:49:14,799 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5169555794361026, 'Total loss': 0.5169555794361026} | train loss {'Reaction outcome loss': 0.46990418507427467, 'Total loss': 0.46990418507427467}
2022-11-28 03:49:14,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:14,800 INFO:     Epoch: 96
2022-11-28 03:49:15,446 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.502506845912268, 'Total loss': 0.502506845912268} | train loss {'Reaction outcome loss': 0.4657868127353856, 'Total loss': 0.4657868127353856}
2022-11-28 03:49:15,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:15,447 INFO:     Epoch: 97
2022-11-28 03:49:16,096 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4975554069807363, 'Total loss': 0.4975554069807363} | train loss {'Reaction outcome loss': 0.468641671367356, 'Total loss': 0.468641671367356}
2022-11-28 03:49:16,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:16,097 INFO:     Epoch: 98
2022-11-28 03:49:16,745 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5170274342215339, 'Total loss': 0.5170274342215339} | train loss {'Reaction outcome loss': 0.4684503288542638, 'Total loss': 0.4684503288542638}
2022-11-28 03:49:16,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:16,745 INFO:     Epoch: 99
2022-11-28 03:49:17,393 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5320111838884132, 'Total loss': 0.5320111838884132} | train loss {'Reaction outcome loss': 0.46831333478454684, 'Total loss': 0.46831333478454684}
2022-11-28 03:49:17,394 INFO:     Best model found after epoch 49 of 100.
2022-11-28 03:49:17,394 INFO:   Done with stage: TRAINING
2022-11-28 03:49:17,394 INFO:   Starting stage: EVALUATION
2022-11-28 03:49:17,525 INFO:   Done with stage: EVALUATION
2022-11-28 03:49:17,525 INFO:   Leaving out SEQ value Fold_1
2022-11-28 03:49:17,538 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:49:17,538 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:49:18,190 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:49:18,190 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:49:18,258 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:49:18,258 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:49:18,258 INFO:     No hyperparam tuning for this model
2022-11-28 03:49:18,258 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:49:18,258 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:49:18,259 INFO:     None feature selector for col prot
2022-11-28 03:49:18,259 INFO:     None feature selector for col prot
2022-11-28 03:49:18,259 INFO:     None feature selector for col prot
2022-11-28 03:49:18,260 INFO:     None feature selector for col chem
2022-11-28 03:49:18,260 INFO:     None feature selector for col chem
2022-11-28 03:49:18,260 INFO:     None feature selector for col chem
2022-11-28 03:49:18,260 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:49:18,260 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:49:18,261 INFO:     Number of params in model 169651
2022-11-28 03:49:18,264 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:49:18,264 INFO:   Starting stage: TRAINING
2022-11-28 03:49:18,314 INFO:     Val loss before train {'Reaction outcome loss': 1.0275634364648298, 'Total loss': 1.0275634364648298}
2022-11-28 03:49:18,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:18,315 INFO:     Epoch: 0
2022-11-28 03:49:18,970 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6062759343873371, 'Total loss': 0.6062759343873371} | train loss {'Reaction outcome loss': 0.6715902461696733, 'Total loss': 0.6715902461696733}
2022-11-28 03:49:18,970 INFO:     Found new best model at epoch 0
2022-11-28 03:49:18,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:18,971 INFO:     Epoch: 1
2022-11-28 03:49:19,625 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5869947414506566, 'Total loss': 0.5869947414506566} | train loss {'Reaction outcome loss': 0.5798446422043116, 'Total loss': 0.5798446422043116}
2022-11-28 03:49:19,625 INFO:     Found new best model at epoch 1
2022-11-28 03:49:19,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:19,626 INFO:     Epoch: 2
2022-11-28 03:49:20,284 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5795893140814521, 'Total loss': 0.5795893140814521} | train loss {'Reaction outcome loss': 0.5374119935127405, 'Total loss': 0.5374119935127405}
2022-11-28 03:49:20,284 INFO:     Found new best model at epoch 2
2022-11-28 03:49:20,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:20,285 INFO:     Epoch: 3
2022-11-28 03:49:20,938 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5641493756662715, 'Total loss': 0.5641493756662715} | train loss {'Reaction outcome loss': 0.5245908873970149, 'Total loss': 0.5245908873970149}
2022-11-28 03:49:20,938 INFO:     Found new best model at epoch 3
2022-11-28 03:49:20,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:20,939 INFO:     Epoch: 4
2022-11-28 03:49:21,593 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5995495779947801, 'Total loss': 0.5995495779947801} | train loss {'Reaction outcome loss': 0.5106652330169793, 'Total loss': 0.5106652330169793}
2022-11-28 03:49:21,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:21,594 INFO:     Epoch: 5
2022-11-28 03:49:22,254 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5270860974084247, 'Total loss': 0.5270860974084247} | train loss {'Reaction outcome loss': 0.5072303673154429, 'Total loss': 0.5072303673154429}
2022-11-28 03:49:22,254 INFO:     Found new best model at epoch 5
2022-11-28 03:49:22,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:22,255 INFO:     Epoch: 6
2022-11-28 03:49:22,913 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5160704380409284, 'Total loss': 0.5160704380409284} | train loss {'Reaction outcome loss': 0.5080457708161128, 'Total loss': 0.5080457708161128}
2022-11-28 03:49:22,913 INFO:     Found new best model at epoch 6
2022-11-28 03:49:22,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:22,914 INFO:     Epoch: 7
2022-11-28 03:49:23,572 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5367214286869223, 'Total loss': 0.5367214286869223} | train loss {'Reaction outcome loss': 0.49052912331665094, 'Total loss': 0.49052912331665094}
2022-11-28 03:49:23,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:23,573 INFO:     Epoch: 8
2022-11-28 03:49:24,229 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5732213475487449, 'Total loss': 0.5732213475487449} | train loss {'Reaction outcome loss': 0.4878312761363713, 'Total loss': 0.4878312761363713}
2022-11-28 03:49:24,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:24,229 INFO:     Epoch: 9
2022-11-28 03:49:24,887 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5092853395776316, 'Total loss': 0.5092853395776316} | train loss {'Reaction outcome loss': 0.48380852264431323, 'Total loss': 0.48380852264431323}
2022-11-28 03:49:24,887 INFO:     Found new best model at epoch 9
2022-11-28 03:49:24,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:24,888 INFO:     Epoch: 10
2022-11-28 03:49:25,544 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5277278443629091, 'Total loss': 0.5277278443629091} | train loss {'Reaction outcome loss': 0.4797523443394827, 'Total loss': 0.4797523443394827}
2022-11-28 03:49:25,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:25,544 INFO:     Epoch: 11
2022-11-28 03:49:26,201 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5121516466818072, 'Total loss': 0.5121516466818072} | train loss {'Reaction outcome loss': 0.49342373842825954, 'Total loss': 0.49342373842825954}
2022-11-28 03:49:26,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:26,201 INFO:     Epoch: 12
2022-11-28 03:49:26,858 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5048137730495497, 'Total loss': 0.5048137730495497} | train loss {'Reaction outcome loss': 0.4734728158364894, 'Total loss': 0.4734728158364894}
2022-11-28 03:49:26,858 INFO:     Found new best model at epoch 12
2022-11-28 03:49:26,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:26,859 INFO:     Epoch: 13
2022-11-28 03:49:27,518 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5378046530214223, 'Total loss': 0.5378046530214223} | train loss {'Reaction outcome loss': 0.47764596946326343, 'Total loss': 0.47764596946326343}
2022-11-28 03:49:27,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:27,518 INFO:     Epoch: 14
2022-11-28 03:49:28,174 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5001460791311481, 'Total loss': 0.5001460791311481} | train loss {'Reaction outcome loss': 0.46905907910121114, 'Total loss': 0.46905907910121114}
2022-11-28 03:49:28,175 INFO:     Found new best model at epoch 14
2022-11-28 03:49:28,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:28,176 INFO:     Epoch: 15
2022-11-28 03:49:28,832 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5086072534322739, 'Total loss': 0.5086072534322739} | train loss {'Reaction outcome loss': 0.47231066876057126, 'Total loss': 0.47231066876057126}
2022-11-28 03:49:28,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:28,833 INFO:     Epoch: 16
2022-11-28 03:49:29,493 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5321038626134396, 'Total loss': 0.5321038626134396} | train loss {'Reaction outcome loss': 0.45847651724390653, 'Total loss': 0.45847651724390653}
2022-11-28 03:49:29,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:29,493 INFO:     Epoch: 17
2022-11-28 03:49:30,150 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5206701487980105, 'Total loss': 0.5206701487980105} | train loss {'Reaction outcome loss': 0.4677162993951938, 'Total loss': 0.4677162993951938}
2022-11-28 03:49:30,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:30,150 INFO:     Epoch: 18
2022-11-28 03:49:30,808 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.604510014707392, 'Total loss': 0.604510014707392} | train loss {'Reaction outcome loss': 0.46215892317686, 'Total loss': 0.46215892317686}
2022-11-28 03:49:30,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:30,808 INFO:     Epoch: 19
2022-11-28 03:49:31,465 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4897351258180358, 'Total loss': 0.4897351258180358} | train loss {'Reaction outcome loss': 0.46264616239190043, 'Total loss': 0.46264616239190043}
2022-11-28 03:49:31,465 INFO:     Found new best model at epoch 19
2022-11-28 03:49:31,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:31,466 INFO:     Epoch: 20
2022-11-28 03:49:32,126 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5198692953722044, 'Total loss': 0.5198692953722044} | train loss {'Reaction outcome loss': 0.4583148269684088, 'Total loss': 0.4583148269684088}
2022-11-28 03:49:32,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:32,126 INFO:     Epoch: 21
2022-11-28 03:49:32,783 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5153478756546974, 'Total loss': 0.5153478756546974} | train loss {'Reaction outcome loss': 0.45903869483314513, 'Total loss': 0.45903869483314513}
2022-11-28 03:49:32,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:32,783 INFO:     Epoch: 22
2022-11-28 03:49:33,441 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5284225693480535, 'Total loss': 0.5284225693480535} | train loss {'Reaction outcome loss': 0.45992335478062574, 'Total loss': 0.45992335478062574}
2022-11-28 03:49:33,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:33,441 INFO:     Epoch: 23
2022-11-28 03:49:34,097 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5876731750640002, 'Total loss': 0.5876731750640002} | train loss {'Reaction outcome loss': 0.4622612680621475, 'Total loss': 0.4622612680621475}
2022-11-28 03:49:34,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:34,098 INFO:     Epoch: 24
2022-11-28 03:49:34,751 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4896968741985885, 'Total loss': 0.4896968741985885} | train loss {'Reaction outcome loss': 0.46698703824991156, 'Total loss': 0.46698703824991156}
2022-11-28 03:49:34,751 INFO:     Found new best model at epoch 24
2022-11-28 03:49:34,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:34,752 INFO:     Epoch: 25
2022-11-28 03:49:35,407 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4801793159409003, 'Total loss': 0.4801793159409003} | train loss {'Reaction outcome loss': 0.4667300240472261, 'Total loss': 0.4667300240472261}
2022-11-28 03:49:35,407 INFO:     Found new best model at epoch 25
2022-11-28 03:49:35,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:35,408 INFO:     Epoch: 26
2022-11-28 03:49:36,062 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5210729132999073, 'Total loss': 0.5210729132999073} | train loss {'Reaction outcome loss': 0.46298259647510315, 'Total loss': 0.46298259647510315}
2022-11-28 03:49:36,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:36,063 INFO:     Epoch: 27
2022-11-28 03:49:36,717 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49748107994144614, 'Total loss': 0.49748107994144614} | train loss {'Reaction outcome loss': 0.4751916677664649, 'Total loss': 0.4751916677664649}
2022-11-28 03:49:36,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:36,718 INFO:     Epoch: 28
2022-11-28 03:49:37,375 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4970233548771251, 'Total loss': 0.4970233548771251} | train loss {'Reaction outcome loss': 0.478341719339251, 'Total loss': 0.478341719339251}
2022-11-28 03:49:37,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:37,375 INFO:     Epoch: 29
2022-11-28 03:49:38,033 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.625783538276499, 'Total loss': 0.625783538276499} | train loss {'Reaction outcome loss': 0.4651783285474005, 'Total loss': 0.4651783285474005}
2022-11-28 03:49:38,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:38,033 INFO:     Epoch: 30
2022-11-28 03:49:38,691 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5178696479309689, 'Total loss': 0.5178696479309689} | train loss {'Reaction outcome loss': 0.467273285099671, 'Total loss': 0.467273285099671}
2022-11-28 03:49:38,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:38,691 INFO:     Epoch: 31
2022-11-28 03:49:39,346 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5102609873495318, 'Total loss': 0.5102609873495318} | train loss {'Reaction outcome loss': 0.4628863803408889, 'Total loss': 0.4628863803408889}
2022-11-28 03:49:39,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:39,347 INFO:     Epoch: 32
2022-11-28 03:49:40,004 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.526037219573151, 'Total loss': 0.526037219573151} | train loss {'Reaction outcome loss': 0.4563476912496302, 'Total loss': 0.4563476912496302}
2022-11-28 03:49:40,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:40,005 INFO:     Epoch: 33
2022-11-28 03:49:40,660 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5079872950234197, 'Total loss': 0.5079872950234197} | train loss {'Reaction outcome loss': 0.4643703251473817, 'Total loss': 0.4643703251473817}
2022-11-28 03:49:40,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:40,660 INFO:     Epoch: 34
2022-11-28 03:49:41,316 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5137402428822084, 'Total loss': 0.5137402428822084} | train loss {'Reaction outcome loss': 0.45528767167624495, 'Total loss': 0.45528767167624495}
2022-11-28 03:49:41,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:41,316 INFO:     Epoch: 35
2022-11-28 03:49:41,975 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5653045878491618, 'Total loss': 0.5653045878491618} | train loss {'Reaction outcome loss': 0.46120694629576525, 'Total loss': 0.46120694629576525}
2022-11-28 03:49:41,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:41,976 INFO:     Epoch: 36
2022-11-28 03:49:42,636 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4935551004653627, 'Total loss': 0.4935551004653627} | train loss {'Reaction outcome loss': 0.46243359329488115, 'Total loss': 0.46243359329488115}
2022-11-28 03:49:42,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:42,636 INFO:     Epoch: 37
2022-11-28 03:49:43,293 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4661074263805693, 'Total loss': 0.4661074263805693} | train loss {'Reaction outcome loss': 0.4625974260119774, 'Total loss': 0.4625974260119774}
2022-11-28 03:49:43,293 INFO:     Found new best model at epoch 37
2022-11-28 03:49:43,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:43,294 INFO:     Epoch: 38
2022-11-28 03:49:43,951 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49011498215523636, 'Total loss': 0.49011498215523636} | train loss {'Reaction outcome loss': 0.4592956110292118, 'Total loss': 0.4592956110292118}
2022-11-28 03:49:43,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:43,951 INFO:     Epoch: 39
2022-11-28 03:49:44,607 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4915315132926811, 'Total loss': 0.4915315132926811} | train loss {'Reaction outcome loss': 0.4556815715936514, 'Total loss': 0.4556815715936514}
2022-11-28 03:49:44,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:44,608 INFO:     Epoch: 40
2022-11-28 03:49:45,261 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.503062520514835, 'Total loss': 0.503062520514835} | train loss {'Reaction outcome loss': 0.45582799004157065, 'Total loss': 0.45582799004157065}
2022-11-28 03:49:45,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:45,261 INFO:     Epoch: 41
2022-11-28 03:49:45,915 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5295071876184507, 'Total loss': 0.5295071876184507} | train loss {'Reaction outcome loss': 0.4542794656536357, 'Total loss': 0.4542794656536357}
2022-11-28 03:49:45,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:45,916 INFO:     Epoch: 42
2022-11-28 03:49:46,573 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5185610054230149, 'Total loss': 0.5185610054230149} | train loss {'Reaction outcome loss': 0.4560906409252028, 'Total loss': 0.4560906409252028}
2022-11-28 03:49:46,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:46,573 INFO:     Epoch: 43
2022-11-28 03:49:47,230 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5039052976803347, 'Total loss': 0.5039052976803347} | train loss {'Reaction outcome loss': 0.4589177918458274, 'Total loss': 0.4589177918458274}
2022-11-28 03:49:47,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:47,230 INFO:     Epoch: 44
2022-11-28 03:49:47,888 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47394388829442585, 'Total loss': 0.47394388829442585} | train loss {'Reaction outcome loss': 0.4541243066792546, 'Total loss': 0.4541243066792546}
2022-11-28 03:49:47,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:47,888 INFO:     Epoch: 45
2022-11-28 03:49:48,541 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48053597049279645, 'Total loss': 0.48053597049279645} | train loss {'Reaction outcome loss': 0.45921850994772273, 'Total loss': 0.45921850994772273}
2022-11-28 03:49:48,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:48,541 INFO:     Epoch: 46
2022-11-28 03:49:49,200 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49293947423046286, 'Total loss': 0.49293947423046286} | train loss {'Reaction outcome loss': 0.4689784115142668, 'Total loss': 0.4689784115142668}
2022-11-28 03:49:49,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:49,200 INFO:     Epoch: 47
2022-11-28 03:49:49,857 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4899666675112464, 'Total loss': 0.4899666675112464} | train loss {'Reaction outcome loss': 0.455607956184851, 'Total loss': 0.455607956184851}
2022-11-28 03:49:49,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:49,858 INFO:     Epoch: 48
2022-11-28 03:49:50,513 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.506679272109812, 'Total loss': 0.506679272109812} | train loss {'Reaction outcome loss': 0.45634030104993734, 'Total loss': 0.45634030104993734}
2022-11-28 03:49:50,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:50,513 INFO:     Epoch: 49
2022-11-28 03:49:51,169 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4950847066938877, 'Total loss': 0.4950847066938877} | train loss {'Reaction outcome loss': 0.45931827859115987, 'Total loss': 0.45931827859115987}
2022-11-28 03:49:51,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:51,169 INFO:     Epoch: 50
2022-11-28 03:49:51,824 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.523542507128282, 'Total loss': 0.523542507128282} | train loss {'Reaction outcome loss': 0.46092095965074625, 'Total loss': 0.46092095965074625}
2022-11-28 03:49:51,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:51,824 INFO:     Epoch: 51
2022-11-28 03:49:52,480 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5316882675344293, 'Total loss': 0.5316882675344293} | train loss {'Reaction outcome loss': 0.516138498841027, 'Total loss': 0.516138498841027}
2022-11-28 03:49:52,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:52,481 INFO:     Epoch: 52
2022-11-28 03:49:53,140 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5388825918463144, 'Total loss': 0.5388825918463144} | train loss {'Reaction outcome loss': 0.5041598584125881, 'Total loss': 0.5041598584125881}
2022-11-28 03:49:53,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:53,140 INFO:     Epoch: 53
2022-11-28 03:49:53,797 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5763627961277962, 'Total loss': 0.5763627961277962} | train loss {'Reaction outcome loss': 0.46440898918693785, 'Total loss': 0.46440898918693785}
2022-11-28 03:49:53,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:53,797 INFO:     Epoch: 54
2022-11-28 03:49:54,455 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5061335001479496, 'Total loss': 0.5061335001479496} | train loss {'Reaction outcome loss': 0.459270672307082, 'Total loss': 0.459270672307082}
2022-11-28 03:49:54,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:54,455 INFO:     Epoch: 55
2022-11-28 03:49:55,117 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5252851166508414, 'Total loss': 0.5252851166508414} | train loss {'Reaction outcome loss': 0.4557680008020478, 'Total loss': 0.4557680008020478}
2022-11-28 03:49:55,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:55,117 INFO:     Epoch: 56
2022-11-28 03:49:55,776 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5013006668199192, 'Total loss': 0.5013006668199192} | train loss {'Reaction outcome loss': 0.47614180124722993, 'Total loss': 0.47614180124722993}
2022-11-28 03:49:55,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:55,776 INFO:     Epoch: 57
2022-11-28 03:49:56,431 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5345867726613175, 'Total loss': 0.5345867726613175} | train loss {'Reaction outcome loss': 0.46105441058182767, 'Total loss': 0.46105441058182767}
2022-11-28 03:49:56,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:56,431 INFO:     Epoch: 58
2022-11-28 03:49:57,087 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5271694247018207, 'Total loss': 0.5271694247018207} | train loss {'Reaction outcome loss': 0.46632258690561845, 'Total loss': 0.46632258690561845}
2022-11-28 03:49:57,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:57,087 INFO:     Epoch: 59
2022-11-28 03:49:57,746 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.512097033587369, 'Total loss': 0.512097033587369} | train loss {'Reaction outcome loss': 0.45846965194110445, 'Total loss': 0.45846965194110445}
2022-11-28 03:49:57,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:57,746 INFO:     Epoch: 60
2022-11-28 03:49:58,403 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5176708813418042, 'Total loss': 0.5176708813418042} | train loss {'Reaction outcome loss': 0.46666289322259213, 'Total loss': 0.46666289322259213}
2022-11-28 03:49:58,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:58,403 INFO:     Epoch: 61
2022-11-28 03:49:59,060 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5408074473115531, 'Total loss': 0.5408074473115531} | train loss {'Reaction outcome loss': 0.4485729724651406, 'Total loss': 0.4485729724651406}
2022-11-28 03:49:59,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:59,060 INFO:     Epoch: 62
2022-11-28 03:49:59,716 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5169314599849961, 'Total loss': 0.5169314599849961} | train loss {'Reaction outcome loss': 0.4664209073613047, 'Total loss': 0.4664209073613047}
2022-11-28 03:49:59,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:49:59,716 INFO:     Epoch: 63
2022-11-28 03:50:00,368 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5136288905685599, 'Total loss': 0.5136288905685599} | train loss {'Reaction outcome loss': 0.45546254778077244, 'Total loss': 0.45546254778077244}
2022-11-28 03:50:00,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:00,369 INFO:     Epoch: 64
2022-11-28 03:50:01,024 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5468935621055689, 'Total loss': 0.5468935621055689} | train loss {'Reaction outcome loss': 0.4607584904803921, 'Total loss': 0.4607584904803921}
2022-11-28 03:50:01,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:01,024 INFO:     Epoch: 65
2022-11-28 03:50:01,681 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5068529045039957, 'Total loss': 0.5068529045039957} | train loss {'Reaction outcome loss': 0.4582693286028951, 'Total loss': 0.4582693286028951}
2022-11-28 03:50:01,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:01,681 INFO:     Epoch: 66
2022-11-28 03:50:02,334 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.509810596704483, 'Total loss': 0.509810596704483} | train loss {'Reaction outcome loss': 0.4606569614299094, 'Total loss': 0.4606569614299094}
2022-11-28 03:50:02,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:02,335 INFO:     Epoch: 67
2022-11-28 03:50:02,988 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5001447742635553, 'Total loss': 0.5001447742635553} | train loss {'Reaction outcome loss': 0.4521791957891904, 'Total loss': 0.4521791957891904}
2022-11-28 03:50:02,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:02,988 INFO:     Epoch: 68
2022-11-28 03:50:03,642 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4997524233026938, 'Total loss': 0.4997524233026938} | train loss {'Reaction outcome loss': 0.45371988542408115, 'Total loss': 0.45371988542408115}
2022-11-28 03:50:03,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:03,642 INFO:     Epoch: 69
2022-11-28 03:50:04,300 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5147520997984842, 'Total loss': 0.5147520997984842} | train loss {'Reaction outcome loss': 0.4584643961051064, 'Total loss': 0.4584643961051064}
2022-11-28 03:50:04,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:04,300 INFO:     Epoch: 70
2022-11-28 03:50:04,958 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4978067194196311, 'Total loss': 0.4978067194196311} | train loss {'Reaction outcome loss': 0.4488141312752191, 'Total loss': 0.4488141312752191}
2022-11-28 03:50:04,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:04,959 INFO:     Epoch: 71
2022-11-28 03:50:05,614 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5018946636806835, 'Total loss': 0.5018946636806835} | train loss {'Reaction outcome loss': 0.4601358981267643, 'Total loss': 0.4601358981267643}
2022-11-28 03:50:05,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:05,615 INFO:     Epoch: 72
2022-11-28 03:50:06,271 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49501504681327124, 'Total loss': 0.49501504681327124} | train loss {'Reaction outcome loss': 0.4804755816394501, 'Total loss': 0.4804755816394501}
2022-11-28 03:50:06,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:06,271 INFO:     Epoch: 73
2022-11-28 03:50:06,927 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5115996230054985, 'Total loss': 0.5115996230054985} | train loss {'Reaction outcome loss': 0.45483514244257195, 'Total loss': 0.45483514244257195}
2022-11-28 03:50:06,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:06,928 INFO:     Epoch: 74
2022-11-28 03:50:07,586 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5144573091105982, 'Total loss': 0.5144573091105982} | train loss {'Reaction outcome loss': 0.4601612664374564, 'Total loss': 0.4601612664374564}
2022-11-28 03:50:07,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:07,586 INFO:     Epoch: 75
2022-11-28 03:50:08,246 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5205878781324084, 'Total loss': 0.5205878781324084} | train loss {'Reaction outcome loss': 0.46081300109986834, 'Total loss': 0.46081300109986834}
2022-11-28 03:50:08,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:08,246 INFO:     Epoch: 76
2022-11-28 03:50:08,902 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49460549788041547, 'Total loss': 0.49460549788041547} | train loss {'Reaction outcome loss': 0.45888189416423986, 'Total loss': 0.45888189416423986}
2022-11-28 03:50:08,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:08,903 INFO:     Epoch: 77
2022-11-28 03:50:09,558 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5184560333463278, 'Total loss': 0.5184560333463278} | train loss {'Reaction outcome loss': 0.457733588421393, 'Total loss': 0.457733588421393}
2022-11-28 03:50:09,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:09,558 INFO:     Epoch: 78
2022-11-28 03:50:10,215 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4986899627203291, 'Total loss': 0.4986899627203291} | train loss {'Reaction outcome loss': 0.4542312494776992, 'Total loss': 0.4542312494776992}
2022-11-28 03:50:10,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:10,215 INFO:     Epoch: 79
2022-11-28 03:50:10,873 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5095246881246567, 'Total loss': 0.5095246881246567} | train loss {'Reaction outcome loss': 0.4531852670451287, 'Total loss': 0.4531852670451287}
2022-11-28 03:50:10,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:10,873 INFO:     Epoch: 80
2022-11-28 03:50:11,529 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5136314630508423, 'Total loss': 0.5136314630508423} | train loss {'Reaction outcome loss': 0.4502970187016103, 'Total loss': 0.4502970187016103}
2022-11-28 03:50:11,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:11,529 INFO:     Epoch: 81
2022-11-28 03:50:12,187 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5275120308453386, 'Total loss': 0.5275120308453386} | train loss {'Reaction outcome loss': 0.4540793277956696, 'Total loss': 0.4540793277956696}
2022-11-28 03:50:12,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:12,187 INFO:     Epoch: 82
2022-11-28 03:50:12,843 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49731285633011296, 'Total loss': 0.49731285633011296} | train loss {'Reaction outcome loss': 0.46090446653877676, 'Total loss': 0.46090446653877676}
2022-11-28 03:50:12,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:12,843 INFO:     Epoch: 83
2022-11-28 03:50:13,502 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5153429152613337, 'Total loss': 0.5153429152613337} | train loss {'Reaction outcome loss': 0.4556890733027265, 'Total loss': 0.4556890733027265}
2022-11-28 03:50:13,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:13,503 INFO:     Epoch: 84
2022-11-28 03:50:14,161 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49147928235205735, 'Total loss': 0.49147928235205735} | train loss {'Reaction outcome loss': 0.4585678849203384, 'Total loss': 0.4585678849203384}
2022-11-28 03:50:14,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:14,162 INFO:     Epoch: 85
2022-11-28 03:50:14,821 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4955086941746148, 'Total loss': 0.4955086941746148} | train loss {'Reaction outcome loss': 0.46301159455708646, 'Total loss': 0.46301159455708646}
2022-11-28 03:50:14,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:14,821 INFO:     Epoch: 86
2022-11-28 03:50:15,477 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5119843418625268, 'Total loss': 0.5119843418625268} | train loss {'Reaction outcome loss': 0.4631208609714199, 'Total loss': 0.4631208609714199}
2022-11-28 03:50:15,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:15,477 INFO:     Epoch: 87
2022-11-28 03:50:16,134 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5022690709341656, 'Total loss': 0.5022690709341656} | train loss {'Reaction outcome loss': 0.45025007855071714, 'Total loss': 0.45025007855071714}
2022-11-28 03:50:16,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:16,135 INFO:     Epoch: 88
2022-11-28 03:50:16,790 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5304006412625313, 'Total loss': 0.5304006412625313} | train loss {'Reaction outcome loss': 0.45779925946764616, 'Total loss': 0.45779925946764616}
2022-11-28 03:50:16,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:16,791 INFO:     Epoch: 89
2022-11-28 03:50:17,447 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5023429461500861, 'Total loss': 0.5023429461500861} | train loss {'Reaction outcome loss': 0.4544178640190889, 'Total loss': 0.4544178640190889}
2022-11-28 03:50:17,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:17,448 INFO:     Epoch: 90
2022-11-28 03:50:18,102 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4967173442921855, 'Total loss': 0.4967173442921855} | train loss {'Reaction outcome loss': 0.4608221156635748, 'Total loss': 0.4608221156635748}
2022-11-28 03:50:18,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:18,102 INFO:     Epoch: 91
2022-11-28 03:50:18,755 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.522691241719506, 'Total loss': 0.522691241719506} | train loss {'Reaction outcome loss': 0.46382784390980414, 'Total loss': 0.46382784390980414}
2022-11-28 03:50:18,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:18,756 INFO:     Epoch: 92
2022-11-28 03:50:19,409 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4967652589760043, 'Total loss': 0.4967652589760043} | train loss {'Reaction outcome loss': 0.46234888580405276, 'Total loss': 0.46234888580405276}
2022-11-28 03:50:19,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:19,409 INFO:     Epoch: 93
2022-11-28 03:50:20,063 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5102184282785113, 'Total loss': 0.5102184282785113} | train loss {'Reaction outcome loss': 0.46063018366996095, 'Total loss': 0.46063018366996095}
2022-11-28 03:50:20,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:20,063 INFO:     Epoch: 94
2022-11-28 03:50:20,718 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5445359223945574, 'Total loss': 0.5445359223945574} | train loss {'Reaction outcome loss': 0.4569639900905695, 'Total loss': 0.4569639900905695}
2022-11-28 03:50:20,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:20,718 INFO:     Epoch: 95
2022-11-28 03:50:21,373 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5102703849023039, 'Total loss': 0.5102703849023039} | train loss {'Reaction outcome loss': 0.45198632088991314, 'Total loss': 0.45198632088991314}
2022-11-28 03:50:21,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:21,373 INFO:     Epoch: 96
2022-11-28 03:50:22,029 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5161185291680422, 'Total loss': 0.5161185291680422} | train loss {'Reaction outcome loss': 0.45267245480894425, 'Total loss': 0.45267245480894425}
2022-11-28 03:50:22,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:22,029 INFO:     Epoch: 97
2022-11-28 03:50:22,683 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5335961624302648, 'Total loss': 0.5335961624302648} | train loss {'Reaction outcome loss': 0.45978971272103697, 'Total loss': 0.45978971272103697}
2022-11-28 03:50:22,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:22,683 INFO:     Epoch: 98
2022-11-28 03:50:23,341 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5260740708221089, 'Total loss': 0.5260740708221089} | train loss {'Reaction outcome loss': 0.46163271246892723, 'Total loss': 0.46163271246892723}
2022-11-28 03:50:23,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:23,342 INFO:     Epoch: 99
2022-11-28 03:50:23,997 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5353884039954706, 'Total loss': 0.5353884039954706} | train loss {'Reaction outcome loss': 0.46069527052433384, 'Total loss': 0.46069527052433384}
2022-11-28 03:50:23,998 INFO:     Best model found after epoch 38 of 100.
2022-11-28 03:50:23,998 INFO:   Done with stage: TRAINING
2022-11-28 03:50:23,998 INFO:   Starting stage: EVALUATION
2022-11-28 03:50:24,116 INFO:   Done with stage: EVALUATION
2022-11-28 03:50:24,116 INFO:   Leaving out SEQ value Fold_2
2022-11-28 03:50:24,129 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:50:24,129 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:50:24,769 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:50:24,769 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:50:24,837 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:50:24,837 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:50:24,837 INFO:     No hyperparam tuning for this model
2022-11-28 03:50:24,837 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:50:24,837 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:50:24,838 INFO:     None feature selector for col prot
2022-11-28 03:50:24,838 INFO:     None feature selector for col prot
2022-11-28 03:50:24,838 INFO:     None feature selector for col prot
2022-11-28 03:50:24,839 INFO:     None feature selector for col chem
2022-11-28 03:50:24,839 INFO:     None feature selector for col chem
2022-11-28 03:50:24,839 INFO:     None feature selector for col chem
2022-11-28 03:50:24,839 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:50:24,839 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:50:24,840 INFO:     Number of params in model 169651
2022-11-28 03:50:24,843 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:50:24,843 INFO:   Starting stage: TRAINING
2022-11-28 03:50:24,893 INFO:     Val loss before train {'Reaction outcome loss': 0.9253753078254786, 'Total loss': 0.9253753078254786}
2022-11-28 03:50:24,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:24,893 INFO:     Epoch: 0
2022-11-28 03:50:25,546 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.548736952922561, 'Total loss': 0.548736952922561} | train loss {'Reaction outcome loss': 0.6962924641005847, 'Total loss': 0.6962924641005847}
2022-11-28 03:50:25,546 INFO:     Found new best model at epoch 0
2022-11-28 03:50:25,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:25,547 INFO:     Epoch: 1
2022-11-28 03:50:26,198 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.508124110034921, 'Total loss': 0.508124110034921} | train loss {'Reaction outcome loss': 0.5855921395579163, 'Total loss': 0.5855921395579163}
2022-11-28 03:50:26,199 INFO:     Found new best model at epoch 1
2022-11-28 03:50:26,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:26,199 INFO:     Epoch: 2
2022-11-28 03:50:26,851 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48536937624554743, 'Total loss': 0.48536937624554743} | train loss {'Reaction outcome loss': 0.5597404588850177, 'Total loss': 0.5597404588850177}
2022-11-28 03:50:26,851 INFO:     Found new best model at epoch 2
2022-11-28 03:50:26,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:26,852 INFO:     Epoch: 3
2022-11-28 03:50:27,503 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4672986929389564, 'Total loss': 0.4672986929389564} | train loss {'Reaction outcome loss': 0.5434801113848784, 'Total loss': 0.5434801113848784}
2022-11-28 03:50:27,503 INFO:     Found new best model at epoch 3
2022-11-28 03:50:27,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:27,504 INFO:     Epoch: 4
2022-11-28 03:50:28,153 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4774845357645642, 'Total loss': 0.4774845357645642} | train loss {'Reaction outcome loss': 0.5363567089547916, 'Total loss': 0.5363567089547916}
2022-11-28 03:50:28,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:28,154 INFO:     Epoch: 5
2022-11-28 03:50:28,801 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45996402542699466, 'Total loss': 0.45996402542699466} | train loss {'Reaction outcome loss': 0.5185408216349933, 'Total loss': 0.5185408216349933}
2022-11-28 03:50:28,801 INFO:     Found new best model at epoch 5
2022-11-28 03:50:28,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:28,802 INFO:     Epoch: 6
2022-11-28 03:50:29,451 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4378297952088443, 'Total loss': 0.4378297952088443} | train loss {'Reaction outcome loss': 0.5183336786469634, 'Total loss': 0.5183336786469634}
2022-11-28 03:50:29,451 INFO:     Found new best model at epoch 6
2022-11-28 03:50:29,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:29,452 INFO:     Epoch: 7
2022-11-28 03:50:30,099 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44601828300140123, 'Total loss': 0.44601828300140123} | train loss {'Reaction outcome loss': 0.5151472332526227, 'Total loss': 0.5151472332526227}
2022-11-28 03:50:30,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:30,100 INFO:     Epoch: 8
2022-11-28 03:50:30,750 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4443167288872329, 'Total loss': 0.4443167288872329} | train loss {'Reaction outcome loss': 0.49563172465684463, 'Total loss': 0.49563172465684463}
2022-11-28 03:50:30,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:30,750 INFO:     Epoch: 9
2022-11-28 03:50:31,400 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42813375490632927, 'Total loss': 0.42813375490632927} | train loss {'Reaction outcome loss': 0.4946595152421873, 'Total loss': 0.4946595152421873}
2022-11-28 03:50:31,400 INFO:     Found new best model at epoch 9
2022-11-28 03:50:31,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:31,401 INFO:     Epoch: 10
2022-11-28 03:50:32,054 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4378695230592381, 'Total loss': 0.4378695230592381} | train loss {'Reaction outcome loss': 0.5004904131500089, 'Total loss': 0.5004904131500089}
2022-11-28 03:50:32,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:32,055 INFO:     Epoch: 11
2022-11-28 03:50:32,706 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4549671252342788, 'Total loss': 0.4549671252342788} | train loss {'Reaction outcome loss': 0.4942001711957309, 'Total loss': 0.4942001711957309}
2022-11-28 03:50:32,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:32,706 INFO:     Epoch: 12
2022-11-28 03:50:33,357 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4432829540561546, 'Total loss': 0.4432829540561546} | train loss {'Reaction outcome loss': 0.4916322748879997, 'Total loss': 0.4916322748879997}
2022-11-28 03:50:33,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:33,357 INFO:     Epoch: 13
2022-11-28 03:50:34,003 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43477575751868164, 'Total loss': 0.43477575751868164} | train loss {'Reaction outcome loss': 0.49314301123424453, 'Total loss': 0.49314301123424453}
2022-11-28 03:50:34,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:34,004 INFO:     Epoch: 14
2022-11-28 03:50:34,649 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45210751823403617, 'Total loss': 0.45210751823403617} | train loss {'Reaction outcome loss': 0.4763667130348634, 'Total loss': 0.4763667130348634}
2022-11-28 03:50:34,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:34,649 INFO:     Epoch: 15
2022-11-28 03:50:35,298 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4220570044761354, 'Total loss': 0.4220570044761354} | train loss {'Reaction outcome loss': 0.48390419318967937, 'Total loss': 0.48390419318967937}
2022-11-28 03:50:35,298 INFO:     Found new best model at epoch 15
2022-11-28 03:50:35,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:35,299 INFO:     Epoch: 16
2022-11-28 03:50:35,950 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43608372285962105, 'Total loss': 0.43608372285962105} | train loss {'Reaction outcome loss': 0.48569194996843534, 'Total loss': 0.48569194996843534}
2022-11-28 03:50:35,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:35,950 INFO:     Epoch: 17
2022-11-28 03:50:36,603 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44222338328307326, 'Total loss': 0.44222338328307326} | train loss {'Reaction outcome loss': 0.47498428347159405, 'Total loss': 0.47498428347159405}
2022-11-28 03:50:36,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:36,603 INFO:     Epoch: 18
2022-11-28 03:50:37,255 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4510577724061229, 'Total loss': 0.4510577724061229} | train loss {'Reaction outcome loss': 0.4753632659206585, 'Total loss': 0.4753632659206585}
2022-11-28 03:50:37,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:37,255 INFO:     Epoch: 19
2022-11-28 03:50:37,906 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4146171518686143, 'Total loss': 0.4146171518686143} | train loss {'Reaction outcome loss': 0.4749621838331223, 'Total loss': 0.4749621838331223}
2022-11-28 03:50:37,906 INFO:     Found new best model at epoch 19
2022-11-28 03:50:37,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:37,907 INFO:     Epoch: 20
2022-11-28 03:50:38,558 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45078990642320027, 'Total loss': 0.45078990642320027} | train loss {'Reaction outcome loss': 0.48086899263518196, 'Total loss': 0.48086899263518196}
2022-11-28 03:50:38,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:38,558 INFO:     Epoch: 21
2022-11-28 03:50:39,210 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4536910998550328, 'Total loss': 0.4536910998550328} | train loss {'Reaction outcome loss': 0.4802174470254353, 'Total loss': 0.4802174470254353}
2022-11-28 03:50:39,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:39,210 INFO:     Epoch: 22
2022-11-28 03:50:39,863 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4862948872826316, 'Total loss': 0.4862948872826316} | train loss {'Reaction outcome loss': 0.4753872438352935, 'Total loss': 0.4753872438352935}
2022-11-28 03:50:39,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:39,864 INFO:     Epoch: 23
2022-11-28 03:50:40,515 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46766658940098504, 'Total loss': 0.46766658940098504} | train loss {'Reaction outcome loss': 0.4760523577125705, 'Total loss': 0.4760523577125705}
2022-11-28 03:50:40,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:40,515 INFO:     Epoch: 24
2022-11-28 03:50:41,167 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4287774247879332, 'Total loss': 0.4287774247879332} | train loss {'Reaction outcome loss': 0.466936583178384, 'Total loss': 0.466936583178384}
2022-11-28 03:50:41,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:41,167 INFO:     Epoch: 25
2022-11-28 03:50:41,821 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46283105320551177, 'Total loss': 0.46283105320551177} | train loss {'Reaction outcome loss': 0.4668703029958569, 'Total loss': 0.4668703029958569}
2022-11-28 03:50:41,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:41,822 INFO:     Epoch: 26
2022-11-28 03:50:42,473 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43048288740895013, 'Total loss': 0.43048288740895013} | train loss {'Reaction outcome loss': 0.4676349169745737, 'Total loss': 0.4676349169745737}
2022-11-28 03:50:42,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:42,473 INFO:     Epoch: 27
2022-11-28 03:50:43,125 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4176274822516875, 'Total loss': 0.4176274822516875} | train loss {'Reaction outcome loss': 0.4737009468735481, 'Total loss': 0.4737009468735481}
2022-11-28 03:50:43,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:43,126 INFO:     Epoch: 28
2022-11-28 03:50:43,777 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47160091674463317, 'Total loss': 0.47160091674463317} | train loss {'Reaction outcome loss': 0.4747107828758201, 'Total loss': 0.4747107828758201}
2022-11-28 03:50:43,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:43,777 INFO:     Epoch: 29
2022-11-28 03:50:44,428 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4278178035535596, 'Total loss': 0.4278178035535596} | train loss {'Reaction outcome loss': 0.4639550710819205, 'Total loss': 0.4639550710819205}
2022-11-28 03:50:44,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:44,428 INFO:     Epoch: 30
2022-11-28 03:50:45,081 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43876609206199646, 'Total loss': 0.43876609206199646} | train loss {'Reaction outcome loss': 0.46573807694474045, 'Total loss': 0.46573807694474045}
2022-11-28 03:50:45,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:45,081 INFO:     Epoch: 31
2022-11-28 03:50:45,733 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4288949360224334, 'Total loss': 0.4288949360224334} | train loss {'Reaction outcome loss': 0.47558221449049154, 'Total loss': 0.47558221449049154}
2022-11-28 03:50:45,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:45,733 INFO:     Epoch: 32
2022-11-28 03:50:46,385 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4210604466497898, 'Total loss': 0.4210604466497898} | train loss {'Reaction outcome loss': 0.4615404434958283, 'Total loss': 0.4615404434958283}
2022-11-28 03:50:46,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:46,386 INFO:     Epoch: 33
2022-11-28 03:50:47,037 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41678187826817686, 'Total loss': 0.41678187826817686} | train loss {'Reaction outcome loss': 0.4555653013136922, 'Total loss': 0.4555653013136922}
2022-11-28 03:50:47,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:47,037 INFO:     Epoch: 34
2022-11-28 03:50:47,690 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4244166378947822, 'Total loss': 0.4244166378947822} | train loss {'Reaction outcome loss': 0.46180972092005673, 'Total loss': 0.46180972092005673}
2022-11-28 03:50:47,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:47,690 INFO:     Epoch: 35
2022-11-28 03:50:48,343 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43181859430941666, 'Total loss': 0.43181859430941666} | train loss {'Reaction outcome loss': 0.47161606033237613, 'Total loss': 0.47161606033237613}
2022-11-28 03:50:48,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:48,344 INFO:     Epoch: 36
2022-11-28 03:50:48,998 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4624172594736923, 'Total loss': 0.4624172594736923} | train loss {'Reaction outcome loss': 0.46938607869099597, 'Total loss': 0.46938607869099597}
2022-11-28 03:50:48,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:48,998 INFO:     Epoch: 37
2022-11-28 03:50:49,651 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4282314574176615, 'Total loss': 0.4282314574176615} | train loss {'Reaction outcome loss': 0.46225719816830696, 'Total loss': 0.46225719816830696}
2022-11-28 03:50:49,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:49,651 INFO:     Epoch: 38
2022-11-28 03:50:50,304 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42600587876090273, 'Total loss': 0.42600587876090273} | train loss {'Reaction outcome loss': 0.4578594792254117, 'Total loss': 0.4578594792254117}
2022-11-28 03:50:50,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:50,305 INFO:     Epoch: 39
2022-11-28 03:50:50,956 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4471110606735403, 'Total loss': 0.4471110606735403} | train loss {'Reaction outcome loss': 0.45949166027867067, 'Total loss': 0.45949166027867067}
2022-11-28 03:50:50,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:50,957 INFO:     Epoch: 40
2022-11-28 03:50:51,607 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40671204165978864, 'Total loss': 0.40671204165978864} | train loss {'Reaction outcome loss': 0.46162253764210914, 'Total loss': 0.46162253764210914}
2022-11-28 03:50:51,607 INFO:     Found new best model at epoch 40
2022-11-28 03:50:51,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:51,608 INFO:     Epoch: 41
2022-11-28 03:50:52,260 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4093779193406755, 'Total loss': 0.4093779193406755} | train loss {'Reaction outcome loss': 0.465932832323775, 'Total loss': 0.465932832323775}
2022-11-28 03:50:52,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:52,261 INFO:     Epoch: 42
2022-11-28 03:50:52,916 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4561879448592663, 'Total loss': 0.4561879448592663} | train loss {'Reaction outcome loss': 0.4544089989394558, 'Total loss': 0.4544089989394558}
2022-11-28 03:50:52,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:52,916 INFO:     Epoch: 43
2022-11-28 03:50:53,570 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45915103229609405, 'Total loss': 0.45915103229609405} | train loss {'Reaction outcome loss': 0.45993534253568064, 'Total loss': 0.45993534253568064}
2022-11-28 03:50:53,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:53,570 INFO:     Epoch: 44
2022-11-28 03:50:54,222 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4410888647491282, 'Total loss': 0.4410888647491282} | train loss {'Reaction outcome loss': 0.4588144026240524, 'Total loss': 0.4588144026240524}
2022-11-28 03:50:54,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:54,222 INFO:     Epoch: 45
2022-11-28 03:50:54,873 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4202871356498111, 'Total loss': 0.4202871356498111} | train loss {'Reaction outcome loss': 0.4592888595498338, 'Total loss': 0.4592888595498338}
2022-11-28 03:50:54,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:54,874 INFO:     Epoch: 46
2022-11-28 03:50:55,527 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4336140731518919, 'Total loss': 0.4336140731518919} | train loss {'Reaction outcome loss': 0.45927175988956376, 'Total loss': 0.45927175988956376}
2022-11-28 03:50:55,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:55,528 INFO:     Epoch: 47
2022-11-28 03:50:56,181 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43942387334325095, 'Total loss': 0.43942387334325095} | train loss {'Reaction outcome loss': 0.45535742239076266, 'Total loss': 0.45535742239076266}
2022-11-28 03:50:56,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:56,182 INFO:     Epoch: 48
2022-11-28 03:50:56,833 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47214883362705057, 'Total loss': 0.47214883362705057} | train loss {'Reaction outcome loss': 0.46234678285462516, 'Total loss': 0.46234678285462516}
2022-11-28 03:50:56,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:56,833 INFO:     Epoch: 49
2022-11-28 03:50:57,486 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4166239575398239, 'Total loss': 0.4166239575398239} | train loss {'Reaction outcome loss': 0.4556670555654837, 'Total loss': 0.4556670555654837}
2022-11-28 03:50:57,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:57,486 INFO:     Epoch: 50
2022-11-28 03:50:58,136 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4330336509103125, 'Total loss': 0.4330336509103125} | train loss {'Reaction outcome loss': 0.45270079091495397, 'Total loss': 0.45270079091495397}
2022-11-28 03:50:58,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:58,136 INFO:     Epoch: 51
2022-11-28 03:50:58,786 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44221087071028625, 'Total loss': 0.44221087071028625} | train loss {'Reaction outcome loss': 0.4610229277489137, 'Total loss': 0.4610229277489137}
2022-11-28 03:50:58,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:58,786 INFO:     Epoch: 52
2022-11-28 03:50:59,439 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4346119998530908, 'Total loss': 0.4346119998530908} | train loss {'Reaction outcome loss': 0.4603298748026089, 'Total loss': 0.4603298748026089}
2022-11-28 03:50:59,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:50:59,439 INFO:     Epoch: 53
2022-11-28 03:51:00,095 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41162929142063315, 'Total loss': 0.41162929142063315} | train loss {'Reaction outcome loss': 0.4588290868365035, 'Total loss': 0.4588290868365035}
2022-11-28 03:51:00,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:00,095 INFO:     Epoch: 54
2022-11-28 03:51:00,751 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.431526493281126, 'Total loss': 0.431526493281126} | train loss {'Reaction outcome loss': 0.465416231751442, 'Total loss': 0.465416231751442}
2022-11-28 03:51:00,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:00,752 INFO:     Epoch: 55
2022-11-28 03:51:01,401 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41790877079421823, 'Total loss': 0.41790877079421823} | train loss {'Reaction outcome loss': 0.46122497989206895, 'Total loss': 0.46122497989206895}
2022-11-28 03:51:01,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:01,401 INFO:     Epoch: 56
2022-11-28 03:51:02,049 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45613877644593065, 'Total loss': 0.45613877644593065} | train loss {'Reaction outcome loss': 0.4634567440164333, 'Total loss': 0.4634567440164333}
2022-11-28 03:51:02,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:02,049 INFO:     Epoch: 57
2022-11-28 03:51:02,696 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4131253453140909, 'Total loss': 0.4131253453140909} | train loss {'Reaction outcome loss': 0.45145726903360717, 'Total loss': 0.45145726903360717}
2022-11-28 03:51:02,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:02,697 INFO:     Epoch: 58
2022-11-28 03:51:03,352 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41248942708427255, 'Total loss': 0.41248942708427255} | train loss {'Reaction outcome loss': 0.4573215928612923, 'Total loss': 0.4573215928612923}
2022-11-28 03:51:03,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:03,353 INFO:     Epoch: 59
2022-11-28 03:51:04,005 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4502591209655458, 'Total loss': 0.4502591209655458} | train loss {'Reaction outcome loss': 0.45728360061742823, 'Total loss': 0.45728360061742823}
2022-11-28 03:51:04,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:04,005 INFO:     Epoch: 60
2022-11-28 03:51:04,653 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4617126705971631, 'Total loss': 0.4617126705971631} | train loss {'Reaction outcome loss': 0.4573776423931122, 'Total loss': 0.4573776423931122}
2022-11-28 03:51:04,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:04,653 INFO:     Epoch: 61
2022-11-28 03:51:05,304 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4114054851233959, 'Total loss': 0.4114054851233959} | train loss {'Reaction outcome loss': 0.4558858203644655, 'Total loss': 0.4558858203644655}
2022-11-28 03:51:05,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:05,305 INFO:     Epoch: 62
2022-11-28 03:51:05,955 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4558021646331657, 'Total loss': 0.4558021646331657} | train loss {'Reaction outcome loss': 0.46111666733513074, 'Total loss': 0.46111666733513074}
2022-11-28 03:51:05,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:05,956 INFO:     Epoch: 63
2022-11-28 03:51:06,603 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45355143364180217, 'Total loss': 0.45355143364180217} | train loss {'Reaction outcome loss': 0.46011306071768, 'Total loss': 0.46011306071768}
2022-11-28 03:51:06,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:06,603 INFO:     Epoch: 64
2022-11-28 03:51:07,255 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4536314389075745, 'Total loss': 0.4536314389075745} | train loss {'Reaction outcome loss': 0.45497587572555154, 'Total loss': 0.45497587572555154}
2022-11-28 03:51:07,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:07,256 INFO:     Epoch: 65
2022-11-28 03:51:07,908 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43624636192213406, 'Total loss': 0.43624636192213406} | train loss {'Reaction outcome loss': 0.45239414396334665, 'Total loss': 0.45239414396334665}
2022-11-28 03:51:07,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:07,909 INFO:     Epoch: 66
2022-11-28 03:51:08,557 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44594974849711766, 'Total loss': 0.44594974849711766} | train loss {'Reaction outcome loss': 0.45726809963888054, 'Total loss': 0.45726809963888054}
2022-11-28 03:51:08,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:08,557 INFO:     Epoch: 67
2022-11-28 03:51:09,205 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4269166626036167, 'Total loss': 0.4269166626036167} | train loss {'Reaction outcome loss': 0.4566067496124579, 'Total loss': 0.4566067496124579}
2022-11-28 03:51:09,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:09,206 INFO:     Epoch: 68
2022-11-28 03:51:09,856 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40742374753410165, 'Total loss': 0.40742374753410165} | train loss {'Reaction outcome loss': 0.46075538725269083, 'Total loss': 0.46075538725269083}
2022-11-28 03:51:09,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:09,857 INFO:     Epoch: 69
2022-11-28 03:51:10,508 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43878655779090797, 'Total loss': 0.43878655779090797} | train loss {'Reaction outcome loss': 0.45582766684950615, 'Total loss': 0.45582766684950615}
2022-11-28 03:51:10,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:10,508 INFO:     Epoch: 70
2022-11-28 03:51:11,160 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45134178549051285, 'Total loss': 0.45134178549051285} | train loss {'Reaction outcome loss': 0.45324290492096725, 'Total loss': 0.45324290492096725}
2022-11-28 03:51:11,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:11,160 INFO:     Epoch: 71
2022-11-28 03:51:11,813 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44799975475127046, 'Total loss': 0.44799975475127046} | train loss {'Reaction outcome loss': 0.45940714861665455, 'Total loss': 0.45940714861665455}
2022-11-28 03:51:11,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:11,813 INFO:     Epoch: 72
2022-11-28 03:51:12,466 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4363148649307815, 'Total loss': 0.4363148649307815} | train loss {'Reaction outcome loss': 0.45481536643845694, 'Total loss': 0.45481536643845694}
2022-11-28 03:51:12,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:12,466 INFO:     Epoch: 73
2022-11-28 03:51:13,120 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43595118956132367, 'Total loss': 0.43595118956132367} | train loss {'Reaction outcome loss': 0.4562437711929788, 'Total loss': 0.4562437711929788}
2022-11-28 03:51:13,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:13,120 INFO:     Epoch: 74
2022-11-28 03:51:13,774 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43474981967698445, 'Total loss': 0.43474981967698445} | train loss {'Reaction outcome loss': 0.45293289465563635, 'Total loss': 0.45293289465563635}
2022-11-28 03:51:13,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:13,774 INFO:     Epoch: 75
2022-11-28 03:51:14,429 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.456843822855841, 'Total loss': 0.456843822855841} | train loss {'Reaction outcome loss': 0.4503790744105164, 'Total loss': 0.4503790744105164}
2022-11-28 03:51:14,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:14,429 INFO:     Epoch: 76
2022-11-28 03:51:15,083 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4430119738152081, 'Total loss': 0.4430119738152081} | train loss {'Reaction outcome loss': 0.45537429874648855, 'Total loss': 0.45537429874648855}
2022-11-28 03:51:15,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:15,083 INFO:     Epoch: 77
2022-11-28 03:51:15,734 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46685297651724383, 'Total loss': 0.46685297651724383} | train loss {'Reaction outcome loss': 0.45722443260708634, 'Total loss': 0.45722443260708634}
2022-11-28 03:51:15,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:15,734 INFO:     Epoch: 78
2022-11-28 03:51:16,386 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40954064002091234, 'Total loss': 0.40954064002091234} | train loss {'Reaction outcome loss': 0.4520395108631679, 'Total loss': 0.4520395108631679}
2022-11-28 03:51:16,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:16,386 INFO:     Epoch: 79
2022-11-28 03:51:17,035 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4042259475046938, 'Total loss': 0.4042259475046938} | train loss {'Reaction outcome loss': 0.4623543606728924, 'Total loss': 0.4623543606728924}
2022-11-28 03:51:17,035 INFO:     Found new best model at epoch 79
2022-11-28 03:51:17,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:17,036 INFO:     Epoch: 80
2022-11-28 03:51:17,686 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47318274358456786, 'Total loss': 0.47318274358456786} | train loss {'Reaction outcome loss': 0.45961542038285, 'Total loss': 0.45961542038285}
2022-11-28 03:51:17,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:17,687 INFO:     Epoch: 81
2022-11-28 03:51:18,339 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5186760621992025, 'Total loss': 0.5186760621992025} | train loss {'Reaction outcome loss': 0.4576606597827405, 'Total loss': 0.4576606597827405}
2022-11-28 03:51:18,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:18,339 INFO:     Epoch: 82
2022-11-28 03:51:18,992 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4285686961163513, 'Total loss': 0.4285686961163513} | train loss {'Reaction outcome loss': 0.4555346880032092, 'Total loss': 0.4555346880032092}
2022-11-28 03:51:18,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:18,993 INFO:     Epoch: 83
2022-11-28 03:51:19,644 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4235822209580378, 'Total loss': 0.4235822209580378} | train loss {'Reaction outcome loss': 0.45492093484012447, 'Total loss': 0.45492093484012447}
2022-11-28 03:51:19,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:19,644 INFO:     Epoch: 84
2022-11-28 03:51:20,296 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42403817854144354, 'Total loss': 0.42403817854144354} | train loss {'Reaction outcome loss': 0.4539641925266811, 'Total loss': 0.4539641925266811}
2022-11-28 03:51:20,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:20,297 INFO:     Epoch: 85
2022-11-28 03:51:20,946 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43282982910221274, 'Total loss': 0.43282982910221274} | train loss {'Reaction outcome loss': 0.45933523883624955, 'Total loss': 0.45933523883624955}
2022-11-28 03:51:20,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:20,946 INFO:     Epoch: 86
2022-11-28 03:51:21,597 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42026325399902736, 'Total loss': 0.42026325399902736} | train loss {'Reaction outcome loss': 0.4561893644685648, 'Total loss': 0.4561893644685648}
2022-11-28 03:51:21,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:21,597 INFO:     Epoch: 87
2022-11-28 03:51:22,248 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43643933602354745, 'Total loss': 0.43643933602354745} | train loss {'Reaction outcome loss': 0.45410530773960817, 'Total loss': 0.45410530773960817}
2022-11-28 03:51:22,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:22,249 INFO:     Epoch: 88
2022-11-28 03:51:22,899 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4200658473101529, 'Total loss': 0.4200658473101529} | train loss {'Reaction outcome loss': 0.45102110845702037, 'Total loss': 0.45102110845702037}
2022-11-28 03:51:22,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:22,899 INFO:     Epoch: 89
2022-11-28 03:51:23,551 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5133142864162271, 'Total loss': 0.5133142864162271} | train loss {'Reaction outcome loss': 0.4606444844177791, 'Total loss': 0.4606444844177791}
2022-11-28 03:51:23,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:23,551 INFO:     Epoch: 90
2022-11-28 03:51:24,199 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4550211988389492, 'Total loss': 0.4550211988389492} | train loss {'Reaction outcome loss': 0.46762333956299995, 'Total loss': 0.46762333956299995}
2022-11-28 03:51:24,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:24,199 INFO:     Epoch: 91
2022-11-28 03:51:24,847 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47507074543020944, 'Total loss': 0.47507074543020944} | train loss {'Reaction outcome loss': 0.4570084054859317, 'Total loss': 0.4570084054859317}
2022-11-28 03:51:24,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:24,847 INFO:     Epoch: 92
2022-11-28 03:51:25,496 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43149303644895554, 'Total loss': 0.43149303644895554} | train loss {'Reaction outcome loss': 0.4673752167395183, 'Total loss': 0.4673752167395183}
2022-11-28 03:51:25,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:25,497 INFO:     Epoch: 93
2022-11-28 03:51:26,147 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4230788927525282, 'Total loss': 0.4230788927525282} | train loss {'Reaction outcome loss': 0.4572945493216417, 'Total loss': 0.4572945493216417}
2022-11-28 03:51:26,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:26,147 INFO:     Epoch: 94
2022-11-28 03:51:26,795 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42514005743644456, 'Total loss': 0.42514005743644456} | train loss {'Reaction outcome loss': 0.46031298083918437, 'Total loss': 0.46031298083918437}
2022-11-28 03:51:26,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:26,795 INFO:     Epoch: 95
2022-11-28 03:51:27,446 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4511432684957981, 'Total loss': 0.4511432684957981} | train loss {'Reaction outcome loss': 0.457943910968547, 'Total loss': 0.457943910968547}
2022-11-28 03:51:27,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:27,446 INFO:     Epoch: 96
2022-11-28 03:51:28,095 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47436578097668564, 'Total loss': 0.47436578097668564} | train loss {'Reaction outcome loss': 0.4638953443084444, 'Total loss': 0.4638953443084444}
2022-11-28 03:51:28,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:28,095 INFO:     Epoch: 97
2022-11-28 03:51:28,745 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.422359709712592, 'Total loss': 0.422359709712592} | train loss {'Reaction outcome loss': 0.4597212450844901, 'Total loss': 0.4597212450844901}
2022-11-28 03:51:28,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:28,745 INFO:     Epoch: 98
2022-11-28 03:51:29,396 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44568569314750756, 'Total loss': 0.44568569314750756} | train loss {'Reaction outcome loss': 0.46236515811511447, 'Total loss': 0.46236515811511447}
2022-11-28 03:51:29,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:29,396 INFO:     Epoch: 99
2022-11-28 03:51:30,047 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4041344184767116, 'Total loss': 0.4041344184767116} | train loss {'Reaction outcome loss': 0.4604734316772344, 'Total loss': 0.4604734316772344}
2022-11-28 03:51:30,047 INFO:     Found new best model at epoch 99
2022-11-28 03:51:30,048 INFO:     Best model found after epoch 100 of 100.
2022-11-28 03:51:30,048 INFO:   Done with stage: TRAINING
2022-11-28 03:51:30,048 INFO:   Starting stage: EVALUATION
2022-11-28 03:51:30,173 INFO:   Done with stage: EVALUATION
2022-11-28 03:51:30,173 INFO:   Leaving out SEQ value Fold_3
2022-11-28 03:51:30,185 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:51:30,186 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:51:30,826 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:51:30,826 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:51:30,893 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:51:30,893 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:51:30,893 INFO:     No hyperparam tuning for this model
2022-11-28 03:51:30,893 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:51:30,893 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:51:30,894 INFO:     None feature selector for col prot
2022-11-28 03:51:30,894 INFO:     None feature selector for col prot
2022-11-28 03:51:30,894 INFO:     None feature selector for col prot
2022-11-28 03:51:30,895 INFO:     None feature selector for col chem
2022-11-28 03:51:30,895 INFO:     None feature selector for col chem
2022-11-28 03:51:30,895 INFO:     None feature selector for col chem
2022-11-28 03:51:30,895 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:51:30,895 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:51:30,897 INFO:     Number of params in model 169651
2022-11-28 03:51:30,899 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:51:30,899 INFO:   Starting stage: TRAINING
2022-11-28 03:51:30,949 INFO:     Val loss before train {'Reaction outcome loss': 0.9839260510422967, 'Total loss': 0.9839260510422967}
2022-11-28 03:51:30,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:30,950 INFO:     Epoch: 0
2022-11-28 03:51:31,600 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5813463042405519, 'Total loss': 0.5813463042405519} | train loss {'Reaction outcome loss': 0.7022419299398149, 'Total loss': 0.7022419299398149}
2022-11-28 03:51:31,600 INFO:     Found new best model at epoch 0
2022-11-28 03:51:31,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:31,601 INFO:     Epoch: 1
2022-11-28 03:51:32,252 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.57367303120819, 'Total loss': 0.57367303120819} | train loss {'Reaction outcome loss': 0.587740203190823, 'Total loss': 0.587740203190823}
2022-11-28 03:51:32,252 INFO:     Found new best model at epoch 1
2022-11-28 03:51:32,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:32,253 INFO:     Epoch: 2
2022-11-28 03:51:32,904 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5429262356324629, 'Total loss': 0.5429262356324629} | train loss {'Reaction outcome loss': 0.5534855764739367, 'Total loss': 0.5534855764739367}
2022-11-28 03:51:32,905 INFO:     Found new best model at epoch 2
2022-11-28 03:51:32,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:32,905 INFO:     Epoch: 3
2022-11-28 03:51:33,556 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5482618592002175, 'Total loss': 0.5482618592002175} | train loss {'Reaction outcome loss': 0.5429062447985824, 'Total loss': 0.5429062447985824}
2022-11-28 03:51:33,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:33,556 INFO:     Epoch: 4
2022-11-28 03:51:34,206 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5193128944797949, 'Total loss': 0.5193128944797949} | train loss {'Reaction outcome loss': 0.5279145436323419, 'Total loss': 0.5279145436323419}
2022-11-28 03:51:34,206 INFO:     Found new best model at epoch 4
2022-11-28 03:51:34,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:34,207 INFO:     Epoch: 5
2022-11-28 03:51:34,857 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5193918340585448, 'Total loss': 0.5193918340585448} | train loss {'Reaction outcome loss': 0.5187087021311935, 'Total loss': 0.5187087021311935}
2022-11-28 03:51:34,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:34,858 INFO:     Epoch: 6
2022-11-28 03:51:35,507 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4981649565425786, 'Total loss': 0.4981649565425786} | train loss {'Reaction outcome loss': 0.5122143780090371, 'Total loss': 0.5122143780090371}
2022-11-28 03:51:35,507 INFO:     Found new best model at epoch 6
2022-11-28 03:51:35,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:35,508 INFO:     Epoch: 7
2022-11-28 03:51:36,157 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4985203356905417, 'Total loss': 0.4985203356905417} | train loss {'Reaction outcome loss': 0.5013656381441622, 'Total loss': 0.5013656381441622}
2022-11-28 03:51:36,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:36,157 INFO:     Epoch: 8
2022-11-28 03:51:36,806 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5111128376288847, 'Total loss': 0.5111128376288847} | train loss {'Reaction outcome loss': 0.49317754963222815, 'Total loss': 0.49317754963222815}
2022-11-28 03:51:36,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:36,806 INFO:     Epoch: 9
2022-11-28 03:51:37,455 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48976201699538663, 'Total loss': 0.48976201699538663} | train loss {'Reaction outcome loss': 0.4964618819708727, 'Total loss': 0.4964618819708727}
2022-11-28 03:51:37,455 INFO:     Found new best model at epoch 9
2022-11-28 03:51:37,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:37,456 INFO:     Epoch: 10
2022-11-28 03:51:38,106 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5219569402662191, 'Total loss': 0.5219569402662191} | train loss {'Reaction outcome loss': 0.48887611141010207, 'Total loss': 0.48887611141010207}
2022-11-28 03:51:38,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:38,106 INFO:     Epoch: 11
2022-11-28 03:51:38,755 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4783145013180646, 'Total loss': 0.4783145013180646} | train loss {'Reaction outcome loss': 0.48889077841019146, 'Total loss': 0.48889077841019146}
2022-11-28 03:51:38,755 INFO:     Found new best model at epoch 11
2022-11-28 03:51:38,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:38,756 INFO:     Epoch: 12
2022-11-28 03:51:39,405 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47508397935466334, 'Total loss': 0.47508397935466334} | train loss {'Reaction outcome loss': 0.48707153602522246, 'Total loss': 0.48707153602522246}
2022-11-28 03:51:39,405 INFO:     Found new best model at epoch 12
2022-11-28 03:51:39,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:39,406 INFO:     Epoch: 13
2022-11-28 03:51:40,058 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5488293394446373, 'Total loss': 0.5488293394446373} | train loss {'Reaction outcome loss': 0.48154292398569537, 'Total loss': 0.48154292398569537}
2022-11-28 03:51:40,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:40,059 INFO:     Epoch: 14
2022-11-28 03:51:40,710 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.475580596788363, 'Total loss': 0.475580596788363} | train loss {'Reaction outcome loss': 0.48186741976105435, 'Total loss': 0.48186741976105435}
2022-11-28 03:51:40,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:40,710 INFO:     Epoch: 15
2022-11-28 03:51:41,361 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45809087563644757, 'Total loss': 0.45809087563644757} | train loss {'Reaction outcome loss': 0.47387552340419925, 'Total loss': 0.47387552340419925}
2022-11-28 03:51:41,361 INFO:     Found new best model at epoch 15
2022-11-28 03:51:41,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:41,362 INFO:     Epoch: 16
2022-11-28 03:51:42,012 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47326086326078937, 'Total loss': 0.47326086326078937} | train loss {'Reaction outcome loss': 0.47193314183731466, 'Total loss': 0.47193314183731466}
2022-11-28 03:51:42,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:42,012 INFO:     Epoch: 17
2022-11-28 03:51:42,667 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.501595885577527, 'Total loss': 0.501595885577527} | train loss {'Reaction outcome loss': 0.4795068001260563, 'Total loss': 0.4795068001260563}
2022-11-28 03:51:42,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:42,667 INFO:     Epoch: 18
2022-11-28 03:51:43,325 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5097516683692281, 'Total loss': 0.5097516683692281} | train loss {'Reaction outcome loss': 0.47385423931540277, 'Total loss': 0.47385423931540277}
2022-11-28 03:51:43,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:43,325 INFO:     Epoch: 19
2022-11-28 03:51:43,989 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4917535013095899, 'Total loss': 0.4917535013095899} | train loss {'Reaction outcome loss': 0.47696755704831106, 'Total loss': 0.47696755704831106}
2022-11-28 03:51:43,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:43,989 INFO:     Epoch: 20
2022-11-28 03:51:44,651 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5116176500239156, 'Total loss': 0.5116176500239156} | train loss {'Reaction outcome loss': 0.4772846889739134, 'Total loss': 0.4772846889739134}
2022-11-28 03:51:44,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:44,651 INFO:     Epoch: 21
2022-11-28 03:51:45,313 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4747285431420261, 'Total loss': 0.4747285431420261} | train loss {'Reaction outcome loss': 0.47716473742407195, 'Total loss': 0.47716473742407195}
2022-11-28 03:51:45,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:45,313 INFO:     Epoch: 22
2022-11-28 03:51:45,972 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47333917157216504, 'Total loss': 0.47333917157216504} | train loss {'Reaction outcome loss': 0.47658836744269545, 'Total loss': 0.47658836744269545}
2022-11-28 03:51:45,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:45,972 INFO:     Epoch: 23
2022-11-28 03:51:46,632 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4622883010994304, 'Total loss': 0.4622883010994304} | train loss {'Reaction outcome loss': 0.46655034389422867, 'Total loss': 0.46655034389422867}
2022-11-28 03:51:46,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:46,632 INFO:     Epoch: 24
2022-11-28 03:51:47,289 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48196639493107796, 'Total loss': 0.48196639493107796} | train loss {'Reaction outcome loss': 0.4827242201688338, 'Total loss': 0.4827242201688338}
2022-11-28 03:51:47,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:47,289 INFO:     Epoch: 25
2022-11-28 03:51:47,953 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49704232202334836, 'Total loss': 0.49704232202334836} | train loss {'Reaction outcome loss': 0.4709961847383149, 'Total loss': 0.4709961847383149}
2022-11-28 03:51:47,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:47,953 INFO:     Epoch: 26
2022-11-28 03:51:48,614 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49774298893118446, 'Total loss': 0.49774298893118446} | train loss {'Reaction outcome loss': 0.4633244124602298, 'Total loss': 0.4633244124602298}
2022-11-28 03:51:48,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:48,614 INFO:     Epoch: 27
2022-11-28 03:51:49,273 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.55070530555465, 'Total loss': 0.55070530555465} | train loss {'Reaction outcome loss': 0.4764786357782325, 'Total loss': 0.4764786357782325}
2022-11-28 03:51:49,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:49,273 INFO:     Epoch: 28
2022-11-28 03:51:49,935 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47874049029567023, 'Total loss': 0.47874049029567023} | train loss {'Reaction outcome loss': 0.47457189559936525, 'Total loss': 0.47457189559936525}
2022-11-28 03:51:49,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:49,935 INFO:     Epoch: 29
2022-11-28 03:51:50,595 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49350195852192963, 'Total loss': 0.49350195852192963} | train loss {'Reaction outcome loss': 0.46521908993623695, 'Total loss': 0.46521908993623695}
2022-11-28 03:51:50,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:50,597 INFO:     Epoch: 30
2022-11-28 03:51:51,253 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.528477358547124, 'Total loss': 0.528477358547124} | train loss {'Reaction outcome loss': 0.4722378024641348, 'Total loss': 0.4722378024641348}
2022-11-28 03:51:51,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:51,253 INFO:     Epoch: 31
2022-11-28 03:51:51,910 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4912962791594592, 'Total loss': 0.4912962791594592} | train loss {'Reaction outcome loss': 0.46636064861501964, 'Total loss': 0.46636064861501964}
2022-11-28 03:51:51,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:51,910 INFO:     Epoch: 32
2022-11-28 03:51:52,572 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5111192681572654, 'Total loss': 0.5111192681572654} | train loss {'Reaction outcome loss': 0.46778105077694876, 'Total loss': 0.46778105077694876}
2022-11-28 03:51:52,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:52,573 INFO:     Epoch: 33
2022-11-28 03:51:53,231 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49020410667766223, 'Total loss': 0.49020410667766223} | train loss {'Reaction outcome loss': 0.4636403344723643, 'Total loss': 0.4636403344723643}
2022-11-28 03:51:53,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:53,232 INFO:     Epoch: 34
2022-11-28 03:51:53,889 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47647776861082425, 'Total loss': 0.47647776861082425} | train loss {'Reaction outcome loss': 0.46477818960437967, 'Total loss': 0.46477818960437967}
2022-11-28 03:51:53,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:53,890 INFO:     Epoch: 35
2022-11-28 03:51:54,548 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47329111566597765, 'Total loss': 0.47329111566597765} | train loss {'Reaction outcome loss': 0.4634626799092001, 'Total loss': 0.4634626799092001}
2022-11-28 03:51:54,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:54,548 INFO:     Epoch: 36
2022-11-28 03:51:55,205 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5141504290090366, 'Total loss': 0.5141504290090366} | train loss {'Reaction outcome loss': 0.4720563021849613, 'Total loss': 0.4720563021849613}
2022-11-28 03:51:55,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:55,206 INFO:     Epoch: 37
2022-11-28 03:51:55,862 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47381819412112236, 'Total loss': 0.47381819412112236} | train loss {'Reaction outcome loss': 0.46314403186647257, 'Total loss': 0.46314403186647257}
2022-11-28 03:51:55,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:55,862 INFO:     Epoch: 38
2022-11-28 03:51:56,517 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5274897095831957, 'Total loss': 0.5274897095831957} | train loss {'Reaction outcome loss': 0.4700503719704492, 'Total loss': 0.4700503719704492}
2022-11-28 03:51:56,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:56,517 INFO:     Epoch: 39
2022-11-28 03:51:57,165 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47276882420886646, 'Total loss': 0.47276882420886646} | train loss {'Reaction outcome loss': 0.45797614473469406, 'Total loss': 0.45797614473469406}
2022-11-28 03:51:57,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:57,166 INFO:     Epoch: 40
2022-11-28 03:51:57,812 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46658327701416885, 'Total loss': 0.46658327701416885} | train loss {'Reaction outcome loss': 0.4606279960700444, 'Total loss': 0.4606279960700444}
2022-11-28 03:51:57,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:57,813 INFO:     Epoch: 41
2022-11-28 03:51:58,459 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5000841052017428, 'Total loss': 0.5000841052017428} | train loss {'Reaction outcome loss': 0.457702633920981, 'Total loss': 0.457702633920981}
2022-11-28 03:51:58,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:58,459 INFO:     Epoch: 42
2022-11-28 03:51:59,108 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5117628523571924, 'Total loss': 0.5117628523571924} | train loss {'Reaction outcome loss': 0.46091715553585366, 'Total loss': 0.46091715553585366}
2022-11-28 03:51:59,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:59,108 INFO:     Epoch: 43
2022-11-28 03:51:59,762 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4667327515780926, 'Total loss': 0.4667327515780926} | train loss {'Reaction outcome loss': 0.4709389029412853, 'Total loss': 0.4709389029412853}
2022-11-28 03:51:59,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:51:59,763 INFO:     Epoch: 44
2022-11-28 03:52:00,412 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49566211246631364, 'Total loss': 0.49566211246631364} | train loss {'Reaction outcome loss': 0.4646988544537097, 'Total loss': 0.4646988544537097}
2022-11-28 03:52:00,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:00,412 INFO:     Epoch: 45
2022-11-28 03:52:01,060 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5030574808743867, 'Total loss': 0.5030574808743867} | train loss {'Reaction outcome loss': 0.46507699082092363, 'Total loss': 0.46507699082092363}
2022-11-28 03:52:01,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:01,060 INFO:     Epoch: 46
2022-11-28 03:52:01,705 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.552114952694286, 'Total loss': 0.552114952694286} | train loss {'Reaction outcome loss': 0.4623242606313861, 'Total loss': 0.4623242606313861}
2022-11-28 03:52:01,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:01,705 INFO:     Epoch: 47
2022-11-28 03:52:02,350 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4992035173557021, 'Total loss': 0.4992035173557021} | train loss {'Reaction outcome loss': 0.47037542699551094, 'Total loss': 0.47037542699551094}
2022-11-28 03:52:02,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:02,350 INFO:     Epoch: 48
2022-11-28 03:52:02,995 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4859135150909424, 'Total loss': 0.4859135150909424} | train loss {'Reaction outcome loss': 0.46070737498147146, 'Total loss': 0.46070737498147146}
2022-11-28 03:52:02,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:02,995 INFO:     Epoch: 49
2022-11-28 03:52:03,644 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4881078458645127, 'Total loss': 0.4881078458645127} | train loss {'Reaction outcome loss': 0.4677930590449547, 'Total loss': 0.4677930590449547}
2022-11-28 03:52:03,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:03,644 INFO:     Epoch: 50
2022-11-28 03:52:04,291 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4684214994988658, 'Total loss': 0.4684214994988658} | train loss {'Reaction outcome loss': 0.46226923100802364, 'Total loss': 0.46226923100802364}
2022-11-28 03:52:04,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:04,291 INFO:     Epoch: 51
2022-11-28 03:52:04,935 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5052680393511598, 'Total loss': 0.5052680393511598} | train loss {'Reaction outcome loss': 0.4601629195164661, 'Total loss': 0.4601629195164661}
2022-11-28 03:52:04,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:04,936 INFO:     Epoch: 52
2022-11-28 03:52:05,576 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4601217427036979, 'Total loss': 0.4601217427036979} | train loss {'Reaction outcome loss': 0.47050205049466115, 'Total loss': 0.47050205049466115}
2022-11-28 03:52:05,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:05,576 INFO:     Epoch: 53
2022-11-28 03:52:06,218 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49963452260602603, 'Total loss': 0.49963452260602603} | train loss {'Reaction outcome loss': 0.46084542703263615, 'Total loss': 0.46084542703263615}
2022-11-28 03:52:06,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:06,219 INFO:     Epoch: 54
2022-11-28 03:52:06,868 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4759388477964835, 'Total loss': 0.4759388477964835} | train loss {'Reaction outcome loss': 0.4735171689670913, 'Total loss': 0.4735171689670913}
2022-11-28 03:52:06,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:06,868 INFO:     Epoch: 55
2022-11-28 03:52:07,514 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46641178395260463, 'Total loss': 0.46641178395260463} | train loss {'Reaction outcome loss': 0.4662238838417189, 'Total loss': 0.4662238838417189}
2022-11-28 03:52:07,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:07,515 INFO:     Epoch: 56
2022-11-28 03:52:08,161 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5085552158680829, 'Total loss': 0.5085552158680829} | train loss {'Reaction outcome loss': 0.45932076579453995, 'Total loss': 0.45932076579453995}
2022-11-28 03:52:08,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:08,161 INFO:     Epoch: 57
2022-11-28 03:52:08,807 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5049778680232438, 'Total loss': 0.5049778680232438} | train loss {'Reaction outcome loss': 0.45972371755205854, 'Total loss': 0.45972371755205854}
2022-11-28 03:52:08,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:08,807 INFO:     Epoch: 58
2022-11-28 03:52:09,455 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4814400363882834, 'Total loss': 0.4814400363882834} | train loss {'Reaction outcome loss': 0.466344849552427, 'Total loss': 0.466344849552427}
2022-11-28 03:52:09,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:09,456 INFO:     Epoch: 59
2022-11-28 03:52:10,102 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4652616462924264, 'Total loss': 0.4652616462924264} | train loss {'Reaction outcome loss': 0.4578292915103387, 'Total loss': 0.4578292915103387}
2022-11-28 03:52:10,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:10,102 INFO:     Epoch: 60
2022-11-28 03:52:10,751 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.487081512470137, 'Total loss': 0.487081512470137} | train loss {'Reaction outcome loss': 0.45888740827842633, 'Total loss': 0.45888740827842633}
2022-11-28 03:52:10,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:10,751 INFO:     Epoch: 61
2022-11-28 03:52:11,398 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48469139500097796, 'Total loss': 0.48469139500097796} | train loss {'Reaction outcome loss': 0.46012737282684874, 'Total loss': 0.46012737282684874}
2022-11-28 03:52:11,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:11,398 INFO:     Epoch: 62
2022-11-28 03:52:12,045 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48611564663323487, 'Total loss': 0.48611564663323487} | train loss {'Reaction outcome loss': 0.4648101733959451, 'Total loss': 0.4648101733959451}
2022-11-28 03:52:12,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:12,045 INFO:     Epoch: 63
2022-11-28 03:52:12,691 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46252045170827344, 'Total loss': 0.46252045170827344} | train loss {'Reaction outcome loss': 0.4600780249858389, 'Total loss': 0.4600780249858389}
2022-11-28 03:52:12,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:12,691 INFO:     Epoch: 64
2022-11-28 03:52:13,336 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46610022539442236, 'Total loss': 0.46610022539442236} | train loss {'Reaction outcome loss': 0.46679263376459784, 'Total loss': 0.46679263376459784}
2022-11-28 03:52:13,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:13,336 INFO:     Epoch: 65
2022-11-28 03:52:13,985 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4733738780698993, 'Total loss': 0.4733738780698993} | train loss {'Reaction outcome loss': 0.470375123376749, 'Total loss': 0.470375123376749}
2022-11-28 03:52:13,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:13,985 INFO:     Epoch: 66
2022-11-28 03:52:14,631 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45211368809792807, 'Total loss': 0.45211368809792807} | train loss {'Reaction outcome loss': 0.4583232157692617, 'Total loss': 0.4583232157692617}
2022-11-28 03:52:14,631 INFO:     Found new best model at epoch 66
2022-11-28 03:52:14,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:14,633 INFO:     Epoch: 67
2022-11-28 03:52:15,280 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5174205147407271, 'Total loss': 0.5174205147407271} | train loss {'Reaction outcome loss': 0.4597710541316441, 'Total loss': 0.4597710541316441}
2022-11-28 03:52:15,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:15,281 INFO:     Epoch: 68
2022-11-28 03:52:15,924 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4661300504072146, 'Total loss': 0.4661300504072146} | train loss {'Reaction outcome loss': 0.4578968557168026, 'Total loss': 0.4578968557168026}
2022-11-28 03:52:15,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:15,925 INFO:     Epoch: 69
2022-11-28 03:52:16,571 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5484459853985093, 'Total loss': 0.5484459853985093} | train loss {'Reaction outcome loss': 0.4620526827719747, 'Total loss': 0.4620526827719747}
2022-11-28 03:52:16,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:16,571 INFO:     Epoch: 70
2022-11-28 03:52:17,220 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4928613921458071, 'Total loss': 0.4928613921458071} | train loss {'Reaction outcome loss': 0.4701761593319932, 'Total loss': 0.4701761593319932}
2022-11-28 03:52:17,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:17,220 INFO:     Epoch: 71
2022-11-28 03:52:17,869 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4707255038348111, 'Total loss': 0.4707255038348111} | train loss {'Reaction outcome loss': 0.4563903513307474, 'Total loss': 0.4563903513307474}
2022-11-28 03:52:17,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:17,869 INFO:     Epoch: 72
2022-11-28 03:52:18,520 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45783412795175205, 'Total loss': 0.45783412795175205} | train loss {'Reaction outcome loss': 0.46044457925825705, 'Total loss': 0.46044457925825705}
2022-11-28 03:52:18,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:18,521 INFO:     Epoch: 73
2022-11-28 03:52:19,171 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4813147099180655, 'Total loss': 0.4813147099180655} | train loss {'Reaction outcome loss': 0.4630180889854626, 'Total loss': 0.4630180889854626}
2022-11-28 03:52:19,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:19,172 INFO:     Epoch: 74
2022-11-28 03:52:19,820 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4768095084212043, 'Total loss': 0.4768095084212043} | train loss {'Reaction outcome loss': 0.4500280750345211, 'Total loss': 0.4500280750345211}
2022-11-28 03:52:19,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:19,820 INFO:     Epoch: 75
2022-11-28 03:52:20,467 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4749507724561475, 'Total loss': 0.4749507724561475} | train loss {'Reaction outcome loss': 0.46299533150633987, 'Total loss': 0.46299533150633987}
2022-11-28 03:52:20,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:20,468 INFO:     Epoch: 76
2022-11-28 03:52:21,120 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4646442071958022, 'Total loss': 0.4646442071958022} | train loss {'Reaction outcome loss': 0.45888830028018174, 'Total loss': 0.45888830028018174}
2022-11-28 03:52:21,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:21,121 INFO:     Epoch: 77
2022-11-28 03:52:21,772 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47335366820069874, 'Total loss': 0.47335366820069874} | train loss {'Reaction outcome loss': 0.45977894864520247, 'Total loss': 0.45977894864520247}
2022-11-28 03:52:21,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:21,772 INFO:     Epoch: 78
2022-11-28 03:52:22,424 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5001537881114266, 'Total loss': 0.5001537881114266} | train loss {'Reaction outcome loss': 0.4615110099011538, 'Total loss': 0.4615110099011538}
2022-11-28 03:52:22,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:22,424 INFO:     Epoch: 79
2022-11-28 03:52:23,074 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5013215866955844, 'Total loss': 0.5013215866955844} | train loss {'Reaction outcome loss': 0.4553224538053785, 'Total loss': 0.4553224538053785}
2022-11-28 03:52:23,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:23,074 INFO:     Epoch: 80
2022-11-28 03:52:23,722 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4560553028502248, 'Total loss': 0.4560553028502248} | train loss {'Reaction outcome loss': 0.464277504232465, 'Total loss': 0.464277504232465}
2022-11-28 03:52:23,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:23,722 INFO:     Epoch: 81
2022-11-28 03:52:24,369 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44439012625000696, 'Total loss': 0.44439012625000696} | train loss {'Reaction outcome loss': 0.4575237277210975, 'Total loss': 0.4575237277210975}
2022-11-28 03:52:24,369 INFO:     Found new best model at epoch 81
2022-11-28 03:52:24,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:24,370 INFO:     Epoch: 82
2022-11-28 03:52:25,016 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47424116493626073, 'Total loss': 0.47424116493626073} | train loss {'Reaction outcome loss': 0.45237976501182636, 'Total loss': 0.45237976501182636}
2022-11-28 03:52:25,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:25,017 INFO:     Epoch: 83
2022-11-28 03:52:25,665 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5489861186255108, 'Total loss': 0.5489861186255108} | train loss {'Reaction outcome loss': 0.45277028275387626, 'Total loss': 0.45277028275387626}
2022-11-28 03:52:25,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:25,665 INFO:     Epoch: 84
2022-11-28 03:52:26,316 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46599937484345655, 'Total loss': 0.46599937484345655} | train loss {'Reaction outcome loss': 0.4612310196368062, 'Total loss': 0.4612310196368062}
2022-11-28 03:52:26,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:26,317 INFO:     Epoch: 85
2022-11-28 03:52:26,965 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5020364709198475, 'Total loss': 0.5020364709198475} | train loss {'Reaction outcome loss': 0.4588401874413296, 'Total loss': 0.4588401874413296}
2022-11-28 03:52:26,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:26,965 INFO:     Epoch: 86
2022-11-28 03:52:27,617 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4984200860966336, 'Total loss': 0.4984200860966336} | train loss {'Reaction outcome loss': 0.46183643067369656, 'Total loss': 0.46183643067369656}
2022-11-28 03:52:27,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:27,618 INFO:     Epoch: 87
2022-11-28 03:52:28,269 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4724568394436078, 'Total loss': 0.4724568394436078} | train loss {'Reaction outcome loss': 0.4620224968511231, 'Total loss': 0.4620224968511231}
2022-11-28 03:52:28,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:28,269 INFO:     Epoch: 88
2022-11-28 03:52:28,924 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46173466538841074, 'Total loss': 0.46173466538841074} | train loss {'Reaction outcome loss': 0.45473798835764123, 'Total loss': 0.45473798835764123}
2022-11-28 03:52:28,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:28,924 INFO:     Epoch: 89
2022-11-28 03:52:29,577 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5223035846244205, 'Total loss': 0.5223035846244205} | train loss {'Reaction outcome loss': 0.45539811241383454, 'Total loss': 0.45539811241383454}
2022-11-28 03:52:29,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:29,578 INFO:     Epoch: 90
2022-11-28 03:52:30,229 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46251246841116384, 'Total loss': 0.46251246841116384} | train loss {'Reaction outcome loss': 0.4591343031245835, 'Total loss': 0.4591343031245835}
2022-11-28 03:52:30,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:30,230 INFO:     Epoch: 91
2022-11-28 03:52:30,883 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5445230047811161, 'Total loss': 0.5445230047811161} | train loss {'Reaction outcome loss': 0.4573945998537297, 'Total loss': 0.4573945998537297}
2022-11-28 03:52:30,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:30,883 INFO:     Epoch: 92
2022-11-28 03:52:31,535 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4620828667486256, 'Total loss': 0.4620828667486256} | train loss {'Reaction outcome loss': 0.4546126925215429, 'Total loss': 0.4546126925215429}
2022-11-28 03:52:31,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:31,535 INFO:     Epoch: 93
2022-11-28 03:52:32,181 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45080929283391347, 'Total loss': 0.45080929283391347} | train loss {'Reaction outcome loss': 0.4558172003955257, 'Total loss': 0.4558172003955257}
2022-11-28 03:52:32,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:32,182 INFO:     Epoch: 94
2022-11-28 03:52:32,828 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4537900354374539, 'Total loss': 0.4537900354374539} | train loss {'Reaction outcome loss': 0.4596051720028021, 'Total loss': 0.4596051720028021}
2022-11-28 03:52:32,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:32,828 INFO:     Epoch: 95
2022-11-28 03:52:33,478 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49472758411006496, 'Total loss': 0.49472758411006496} | train loss {'Reaction outcome loss': 0.4617285107471505, 'Total loss': 0.4617285107471505}
2022-11-28 03:52:33,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:33,478 INFO:     Epoch: 96
2022-11-28 03:52:34,124 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4629726301540028, 'Total loss': 0.4629726301540028} | train loss {'Reaction outcome loss': 0.45545173281309553, 'Total loss': 0.45545173281309553}
2022-11-28 03:52:34,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:34,125 INFO:     Epoch: 97
2022-11-28 03:52:34,774 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4570986477827484, 'Total loss': 0.4570986477827484} | train loss {'Reaction outcome loss': 0.4578601177249636, 'Total loss': 0.4578601177249636}
2022-11-28 03:52:34,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:34,774 INFO:     Epoch: 98
2022-11-28 03:52:35,425 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4631044268608093, 'Total loss': 0.4631044268608093} | train loss {'Reaction outcome loss': 0.4519226376803554, 'Total loss': 0.4519226376803554}
2022-11-28 03:52:35,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:35,425 INFO:     Epoch: 99
2022-11-28 03:52:36,071 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.493374609134414, 'Total loss': 0.493374609134414} | train loss {'Reaction outcome loss': 0.45508841701916286, 'Total loss': 0.45508841701916286}
2022-11-28 03:52:36,071 INFO:     Best model found after epoch 82 of 100.
2022-11-28 03:52:36,071 INFO:   Done with stage: TRAINING
2022-11-28 03:52:36,071 INFO:   Starting stage: EVALUATION
2022-11-28 03:52:36,195 INFO:   Done with stage: EVALUATION
2022-11-28 03:52:36,195 INFO:   Leaving out SEQ value Fold_4
2022-11-28 03:52:36,207 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:52:36,207 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:52:36,842 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:52:36,843 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:52:36,909 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:52:36,910 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:52:36,910 INFO:     No hyperparam tuning for this model
2022-11-28 03:52:36,910 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:52:36,910 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:52:36,910 INFO:     None feature selector for col prot
2022-11-28 03:52:36,911 INFO:     None feature selector for col prot
2022-11-28 03:52:36,911 INFO:     None feature selector for col prot
2022-11-28 03:52:36,911 INFO:     None feature selector for col chem
2022-11-28 03:52:36,911 INFO:     None feature selector for col chem
2022-11-28 03:52:36,911 INFO:     None feature selector for col chem
2022-11-28 03:52:36,911 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:52:36,911 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:52:36,913 INFO:     Number of params in model 169651
2022-11-28 03:52:36,916 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:52:36,916 INFO:   Starting stage: TRAINING
2022-11-28 03:52:36,967 INFO:     Val loss before train {'Reaction outcome loss': 0.9764801697297529, 'Total loss': 0.9764801697297529}
2022-11-28 03:52:36,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:36,967 INFO:     Epoch: 0
2022-11-28 03:52:37,623 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6137370013377883, 'Total loss': 0.6137370013377883} | train loss {'Reaction outcome loss': 0.6946310068879809, 'Total loss': 0.6946310068879809}
2022-11-28 03:52:37,623 INFO:     Found new best model at epoch 0
2022-11-28 03:52:37,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:37,624 INFO:     Epoch: 1
2022-11-28 03:52:38,275 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5430508689446882, 'Total loss': 0.5430508689446882} | train loss {'Reaction outcome loss': 0.5659282953763495, 'Total loss': 0.5659282953763495}
2022-11-28 03:52:38,276 INFO:     Found new best model at epoch 1
2022-11-28 03:52:38,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:38,276 INFO:     Epoch: 2
2022-11-28 03:52:38,925 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5020611143078316, 'Total loss': 0.5020611143078316} | train loss {'Reaction outcome loss': 0.5401217391296309, 'Total loss': 0.5401217391296309}
2022-11-28 03:52:38,925 INFO:     Found new best model at epoch 2
2022-11-28 03:52:38,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:38,926 INFO:     Epoch: 3
2022-11-28 03:52:39,574 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5282342074946924, 'Total loss': 0.5282342074946924} | train loss {'Reaction outcome loss': 0.529273658930039, 'Total loss': 0.529273658930039}
2022-11-28 03:52:39,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:39,575 INFO:     Epoch: 4
2022-11-28 03:52:40,223 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4910615242340348, 'Total loss': 0.4910615242340348} | train loss {'Reaction outcome loss': 0.5031518852224155, 'Total loss': 0.5031518852224155}
2022-11-28 03:52:40,224 INFO:     Found new best model at epoch 4
2022-11-28 03:52:40,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:40,225 INFO:     Epoch: 5
2022-11-28 03:52:40,879 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47360406003215094, 'Total loss': 0.47360406003215094} | train loss {'Reaction outcome loss': 0.5025938628887644, 'Total loss': 0.5025938628887644}
2022-11-28 03:52:40,879 INFO:     Found new best model at epoch 5
2022-11-28 03:52:40,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:40,879 INFO:     Epoch: 6
2022-11-28 03:52:41,530 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5159593905237588, 'Total loss': 0.5159593905237588} | train loss {'Reaction outcome loss': 0.4997239103730844, 'Total loss': 0.4997239103730844}
2022-11-28 03:52:41,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:41,530 INFO:     Epoch: 7
2022-11-28 03:52:42,180 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5051217478784648, 'Total loss': 0.5051217478784648} | train loss {'Reaction outcome loss': 0.49149396556372543, 'Total loss': 0.49149396556372543}
2022-11-28 03:52:42,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:42,180 INFO:     Epoch: 8
2022-11-28 03:52:42,829 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5014402886259962, 'Total loss': 0.5014402886259962} | train loss {'Reaction outcome loss': 0.484774928007807, 'Total loss': 0.484774928007807}
2022-11-28 03:52:42,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:42,829 INFO:     Epoch: 9
2022-11-28 03:52:43,478 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5145513076673854, 'Total loss': 0.5145513076673854} | train loss {'Reaction outcome loss': 0.4782096110436381, 'Total loss': 0.4782096110436381}
2022-11-28 03:52:43,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:43,478 INFO:     Epoch: 10
2022-11-28 03:52:44,127 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4719381577927958, 'Total loss': 0.4719381577927958} | train loss {'Reaction outcome loss': 0.4743064160249671, 'Total loss': 0.4743064160249671}
2022-11-28 03:52:44,127 INFO:     Found new best model at epoch 10
2022-11-28 03:52:44,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:44,128 INFO:     Epoch: 11
2022-11-28 03:52:44,777 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4607393998991359, 'Total loss': 0.4607393998991359} | train loss {'Reaction outcome loss': 0.4752540960603831, 'Total loss': 0.4752540960603831}
2022-11-28 03:52:44,777 INFO:     Found new best model at epoch 11
2022-11-28 03:52:44,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:44,778 INFO:     Epoch: 12
2022-11-28 03:52:45,427 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48300831290808593, 'Total loss': 0.48300831290808593} | train loss {'Reaction outcome loss': 0.46557211212965904, 'Total loss': 0.46557211212965904}
2022-11-28 03:52:45,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:45,427 INFO:     Epoch: 13
2022-11-28 03:52:46,076 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49441285770047794, 'Total loss': 0.49441285770047794} | train loss {'Reaction outcome loss': 0.4724975361507766, 'Total loss': 0.4724975361507766}
2022-11-28 03:52:46,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:46,076 INFO:     Epoch: 14
2022-11-28 03:52:46,726 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5111737407066606, 'Total loss': 0.5111737407066606} | train loss {'Reaction outcome loss': 0.4752590766366647, 'Total loss': 0.4752590766366647}
2022-11-28 03:52:46,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:46,726 INFO:     Epoch: 15
2022-11-28 03:52:47,372 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48611510307951405, 'Total loss': 0.48611510307951405} | train loss {'Reaction outcome loss': 0.46867336776791785, 'Total loss': 0.46867336776791785}
2022-11-28 03:52:47,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:47,372 INFO:     Epoch: 16
2022-11-28 03:52:48,018 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47993558340451936, 'Total loss': 0.47993558340451936} | train loss {'Reaction outcome loss': 0.4694728089230401, 'Total loss': 0.4694728089230401}
2022-11-28 03:52:48,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:48,018 INFO:     Epoch: 17
2022-11-28 03:52:48,663 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4727860198102214, 'Total loss': 0.4727860198102214} | train loss {'Reaction outcome loss': 0.4642422028342072, 'Total loss': 0.4642422028342072}
2022-11-28 03:52:48,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:48,663 INFO:     Epoch: 18
2022-11-28 03:52:49,311 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45696267824281345, 'Total loss': 0.45696267824281345} | train loss {'Reaction outcome loss': 0.46884462930718246, 'Total loss': 0.46884462930718246}
2022-11-28 03:52:49,312 INFO:     Found new best model at epoch 18
2022-11-28 03:52:49,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:49,312 INFO:     Epoch: 19
2022-11-28 03:52:49,961 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46104561910033226, 'Total loss': 0.46104561910033226} | train loss {'Reaction outcome loss': 0.46000811919874074, 'Total loss': 0.46000811919874074}
2022-11-28 03:52:49,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:49,961 INFO:     Epoch: 20
2022-11-28 03:52:50,612 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4593499729579145, 'Total loss': 0.4593499729579145} | train loss {'Reaction outcome loss': 0.46590037808126333, 'Total loss': 0.46590037808126333}
2022-11-28 03:52:50,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:50,612 INFO:     Epoch: 21
2022-11-28 03:52:51,263 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46490647982467304, 'Total loss': 0.46490647982467304} | train loss {'Reaction outcome loss': 0.46570699896131246, 'Total loss': 0.46570699896131246}
2022-11-28 03:52:51,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:51,263 INFO:     Epoch: 22
2022-11-28 03:52:51,908 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4605495106767524, 'Total loss': 0.4605495106767524} | train loss {'Reaction outcome loss': 0.4631183638560529, 'Total loss': 0.4631183638560529}
2022-11-28 03:52:51,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:51,908 INFO:     Epoch: 23
2022-11-28 03:52:52,558 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4768634404648434, 'Total loss': 0.4768634404648434} | train loss {'Reaction outcome loss': 0.4636571094089625, 'Total loss': 0.4636571094089625}
2022-11-28 03:52:52,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:52,559 INFO:     Epoch: 24
2022-11-28 03:52:53,206 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4752728129652413, 'Total loss': 0.4752728129652413} | train loss {'Reaction outcome loss': 0.46530328386900377, 'Total loss': 0.46530328386900377}
2022-11-28 03:52:53,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:53,207 INFO:     Epoch: 25
2022-11-28 03:52:53,858 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45726199041713367, 'Total loss': 0.45726199041713367} | train loss {'Reaction outcome loss': 0.4634728173212129, 'Total loss': 0.4634728173212129}
2022-11-28 03:52:53,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:53,858 INFO:     Epoch: 26
2022-11-28 03:52:54,506 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46748109635981644, 'Total loss': 0.46748109635981644} | train loss {'Reaction outcome loss': 0.46265663474189994, 'Total loss': 0.46265663474189994}
2022-11-28 03:52:54,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:54,507 INFO:     Epoch: 27
2022-11-28 03:52:55,152 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4716554128310897, 'Total loss': 0.4716554128310897} | train loss {'Reaction outcome loss': 0.4663122220915191, 'Total loss': 0.4663122220915191}
2022-11-28 03:52:55,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:55,152 INFO:     Epoch: 28
2022-11-28 03:52:55,798 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4771970734000206, 'Total loss': 0.4771970734000206} | train loss {'Reaction outcome loss': 0.4578109170101127, 'Total loss': 0.4578109170101127}
2022-11-28 03:52:55,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:55,799 INFO:     Epoch: 29
2022-11-28 03:52:56,449 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4437790702689778, 'Total loss': 0.4437790702689778} | train loss {'Reaction outcome loss': 0.45447346221427526, 'Total loss': 0.45447346221427526}
2022-11-28 03:52:56,449 INFO:     Found new best model at epoch 29
2022-11-28 03:52:56,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:56,450 INFO:     Epoch: 30
2022-11-28 03:52:57,100 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4732514667240056, 'Total loss': 0.4732514667240056} | train loss {'Reaction outcome loss': 0.4606548700405627, 'Total loss': 0.4606548700405627}
2022-11-28 03:52:57,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:57,100 INFO:     Epoch: 31
2022-11-28 03:52:57,750 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4952522265640172, 'Total loss': 0.4952522265640172} | train loss {'Reaction outcome loss': 0.4664531618356705, 'Total loss': 0.4664531618356705}
2022-11-28 03:52:57,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:57,750 INFO:     Epoch: 32
2022-11-28 03:52:58,397 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48382232236591255, 'Total loss': 0.48382232236591255} | train loss {'Reaction outcome loss': 0.45741273681728206, 'Total loss': 0.45741273681728206}
2022-11-28 03:52:58,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:58,397 INFO:     Epoch: 33
2022-11-28 03:52:59,046 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4662143205377189, 'Total loss': 0.4662143205377189} | train loss {'Reaction outcome loss': 0.4570086817352139, 'Total loss': 0.4570086817352139}
2022-11-28 03:52:59,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:59,047 INFO:     Epoch: 34
2022-11-28 03:52:59,694 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5193172926929864, 'Total loss': 0.5193172926929864} | train loss {'Reaction outcome loss': 0.46048261991568973, 'Total loss': 0.46048261991568973}
2022-11-28 03:52:59,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:52:59,694 INFO:     Epoch: 35
2022-11-28 03:53:00,338 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45351097563450987, 'Total loss': 0.45351097563450987} | train loss {'Reaction outcome loss': 0.46486148195607324, 'Total loss': 0.46486148195607324}
2022-11-28 03:53:00,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:00,339 INFO:     Epoch: 36
2022-11-28 03:53:00,986 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47675763544711197, 'Total loss': 0.47675763544711197} | train loss {'Reaction outcome loss': 0.45378644867819184, 'Total loss': 0.45378644867819184}
2022-11-28 03:53:00,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:00,986 INFO:     Epoch: 37
2022-11-28 03:53:01,634 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44296925768933515, 'Total loss': 0.44296925768933515} | train loss {'Reaction outcome loss': 0.46399217850091506, 'Total loss': 0.46399217850091506}
2022-11-28 03:53:01,634 INFO:     Found new best model at epoch 37
2022-11-28 03:53:01,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:01,635 INFO:     Epoch: 38
2022-11-28 03:53:02,282 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4447108940644698, 'Total loss': 0.4447108940644698} | train loss {'Reaction outcome loss': 0.4579381401441535, 'Total loss': 0.4579381401441535}
2022-11-28 03:53:02,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:02,282 INFO:     Epoch: 39
2022-11-28 03:53:02,931 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4696477529677478, 'Total loss': 0.4696477529677478} | train loss {'Reaction outcome loss': 0.4542422628220247, 'Total loss': 0.4542422628220247}
2022-11-28 03:53:02,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:02,931 INFO:     Epoch: 40
2022-11-28 03:53:03,580 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48305921629071236, 'Total loss': 0.48305921629071236} | train loss {'Reaction outcome loss': 0.4633843097151542, 'Total loss': 0.4633843097151542}
2022-11-28 03:53:03,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:03,580 INFO:     Epoch: 41
2022-11-28 03:53:04,231 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4511867643079974, 'Total loss': 0.4511867643079974} | train loss {'Reaction outcome loss': 0.45551706351795973, 'Total loss': 0.45551706351795973}
2022-11-28 03:53:04,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:04,231 INFO:     Epoch: 42
2022-11-28 03:53:04,878 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4813153303482316, 'Total loss': 0.4813153303482316} | train loss {'Reaction outcome loss': 0.45800652072137715, 'Total loss': 0.45800652072137715}
2022-11-28 03:53:04,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:04,879 INFO:     Epoch: 43
2022-11-28 03:53:05,528 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46584589643911883, 'Total loss': 0.46584589643911883} | train loss {'Reaction outcome loss': 0.45979147523033376, 'Total loss': 0.45979147523033376}
2022-11-28 03:53:05,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:05,528 INFO:     Epoch: 44
2022-11-28 03:53:06,178 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4668433405458927, 'Total loss': 0.4668433405458927} | train loss {'Reaction outcome loss': 0.4625190546926187, 'Total loss': 0.4625190546926187}
2022-11-28 03:53:06,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:06,178 INFO:     Epoch: 45
2022-11-28 03:53:06,825 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4681966785680164, 'Total loss': 0.4681966785680164} | train loss {'Reaction outcome loss': 0.46210976650520247, 'Total loss': 0.46210976650520247}
2022-11-28 03:53:06,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:06,826 INFO:     Epoch: 46
2022-11-28 03:53:07,473 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46429106389934366, 'Total loss': 0.46429106389934366} | train loss {'Reaction outcome loss': 0.4520863440267894, 'Total loss': 0.4520863440267894}
2022-11-28 03:53:07,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:07,473 INFO:     Epoch: 47
2022-11-28 03:53:08,121 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4785663904833861, 'Total loss': 0.4785663904833861} | train loss {'Reaction outcome loss': 0.4602146631600905, 'Total loss': 0.4602146631600905}
2022-11-28 03:53:08,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:08,121 INFO:     Epoch: 48
2022-11-28 03:53:08,769 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45288255404342304, 'Total loss': 0.45288255404342304} | train loss {'Reaction outcome loss': 0.4643982350218053, 'Total loss': 0.4643982350218053}
2022-11-28 03:53:08,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:08,769 INFO:     Epoch: 49
2022-11-28 03:53:09,415 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47672583162784576, 'Total loss': 0.47672583162784576} | train loss {'Reaction outcome loss': 0.4574491139273254, 'Total loss': 0.4574491139273254}
2022-11-28 03:53:09,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:09,416 INFO:     Epoch: 50
2022-11-28 03:53:10,066 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4909502708099105, 'Total loss': 0.4909502708099105} | train loss {'Reaction outcome loss': 0.46240591461561165, 'Total loss': 0.46240591461561165}
2022-11-28 03:53:10,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:10,066 INFO:     Epoch: 51
2022-11-28 03:53:10,714 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4496629796922207, 'Total loss': 0.4496629796922207} | train loss {'Reaction outcome loss': 0.46201339193752833, 'Total loss': 0.46201339193752833}
2022-11-28 03:53:10,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:10,715 INFO:     Epoch: 52
2022-11-28 03:53:11,363 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46180510419336235, 'Total loss': 0.46180510419336235} | train loss {'Reaction outcome loss': 0.4561331753828088, 'Total loss': 0.4561331753828088}
2022-11-28 03:53:11,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:11,364 INFO:     Epoch: 53
2022-11-28 03:53:12,011 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4341183467344804, 'Total loss': 0.4341183467344804} | train loss {'Reaction outcome loss': 0.4601402465786253, 'Total loss': 0.4601402465786253}
2022-11-28 03:53:12,012 INFO:     Found new best model at epoch 53
2022-11-28 03:53:12,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:12,012 INFO:     Epoch: 54
2022-11-28 03:53:12,655 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4618882340463725, 'Total loss': 0.4618882340463725} | train loss {'Reaction outcome loss': 0.4555178414193951, 'Total loss': 0.4555178414193951}
2022-11-28 03:53:12,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:12,655 INFO:     Epoch: 55
2022-11-28 03:53:13,304 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4511191255666993, 'Total loss': 0.4511191255666993} | train loss {'Reaction outcome loss': 0.4544714086517996, 'Total loss': 0.4544714086517996}
2022-11-28 03:53:13,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:13,305 INFO:     Epoch: 56
2022-11-28 03:53:13,953 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.503536616536704, 'Total loss': 0.503536616536704} | train loss {'Reaction outcome loss': 0.456797565763094, 'Total loss': 0.456797565763094}
2022-11-28 03:53:13,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:13,954 INFO:     Epoch: 57
2022-11-28 03:53:14,603 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46738169579343364, 'Total loss': 0.46738169579343364} | train loss {'Reaction outcome loss': 0.4543647583041872, 'Total loss': 0.4543647583041872}
2022-11-28 03:53:14,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:14,603 INFO:     Epoch: 58
2022-11-28 03:53:15,252 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4583812430500984, 'Total loss': 0.4583812430500984} | train loss {'Reaction outcome loss': 0.4649626596849792, 'Total loss': 0.4649626596849792}
2022-11-28 03:53:15,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:15,252 INFO:     Epoch: 59
2022-11-28 03:53:15,902 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45372932675209915, 'Total loss': 0.45372932675209915} | train loss {'Reaction outcome loss': 0.4585856061808917, 'Total loss': 0.4585856061808917}
2022-11-28 03:53:15,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:15,902 INFO:     Epoch: 60
2022-11-28 03:53:16,551 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4498615102334456, 'Total loss': 0.4498615102334456} | train loss {'Reaction outcome loss': 0.45351245716518285, 'Total loss': 0.45351245716518285}
2022-11-28 03:53:16,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:16,551 INFO:     Epoch: 61
2022-11-28 03:53:17,197 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4634067885239016, 'Total loss': 0.4634067885239016} | train loss {'Reaction outcome loss': 0.46067337995889235, 'Total loss': 0.46067337995889235}
2022-11-28 03:53:17,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:17,197 INFO:     Epoch: 62
2022-11-28 03:53:17,846 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4733393138105219, 'Total loss': 0.4733393138105219} | train loss {'Reaction outcome loss': 0.45336221240612923, 'Total loss': 0.45336221240612923}
2022-11-28 03:53:17,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:17,846 INFO:     Epoch: 63
2022-11-28 03:53:18,495 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.457375724545934, 'Total loss': 0.457375724545934} | train loss {'Reaction outcome loss': 0.45968981762321626, 'Total loss': 0.45968981762321626}
2022-11-28 03:53:18,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:18,495 INFO:     Epoch: 64
2022-11-28 03:53:19,144 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4603263071992181, 'Total loss': 0.4603263071992181} | train loss {'Reaction outcome loss': 0.45126073311786263, 'Total loss': 0.45126073311786263}
2022-11-28 03:53:19,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:19,144 INFO:     Epoch: 65
2022-11-28 03:53:19,793 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44769051467830484, 'Total loss': 0.44769051467830484} | train loss {'Reaction outcome loss': 0.46083321331106886, 'Total loss': 0.46083321331106886}
2022-11-28 03:53:19,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:19,793 INFO:     Epoch: 66
2022-11-28 03:53:20,445 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45238443091511726, 'Total loss': 0.45238443091511726} | train loss {'Reaction outcome loss': 0.4533293562276023, 'Total loss': 0.4533293562276023}
2022-11-28 03:53:20,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:20,445 INFO:     Epoch: 67
2022-11-28 03:53:21,098 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46630362641404977, 'Total loss': 0.46630362641404977} | train loss {'Reaction outcome loss': 0.46105870835635127, 'Total loss': 0.46105870835635127}
2022-11-28 03:53:21,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:21,099 INFO:     Epoch: 68
2022-11-28 03:53:21,749 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4525984109125354, 'Total loss': 0.4525984109125354} | train loss {'Reaction outcome loss': 0.45049184007304055, 'Total loss': 0.45049184007304055}
2022-11-28 03:53:21,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:21,749 INFO:     Epoch: 69
2022-11-28 03:53:22,399 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4433868435973471, 'Total loss': 0.4433868435973471} | train loss {'Reaction outcome loss': 0.4551274925774457, 'Total loss': 0.4551274925774457}
2022-11-28 03:53:22,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:22,399 INFO:     Epoch: 70
2022-11-28 03:53:23,051 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4542608637024056, 'Total loss': 0.4542608637024056} | train loss {'Reaction outcome loss': 0.461098003265809, 'Total loss': 0.461098003265809}
2022-11-28 03:53:23,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:23,051 INFO:     Epoch: 71
2022-11-28 03:53:23,698 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46277798678387294, 'Total loss': 0.46277798678387294} | train loss {'Reaction outcome loss': 0.44983635715075904, 'Total loss': 0.44983635715075904}
2022-11-28 03:53:23,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:23,699 INFO:     Epoch: 72
2022-11-28 03:53:24,348 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4758292209695686, 'Total loss': 0.4758292209695686} | train loss {'Reaction outcome loss': 0.4616382098015474, 'Total loss': 0.4616382098015474}
2022-11-28 03:53:24,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:24,348 INFO:     Epoch: 73
2022-11-28 03:53:24,997 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4912461753595959, 'Total loss': 0.4912461753595959} | train loss {'Reaction outcome loss': 0.45469799400592337, 'Total loss': 0.45469799400592337}
2022-11-28 03:53:24,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:24,997 INFO:     Epoch: 74
2022-11-28 03:53:25,645 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44067237627777184, 'Total loss': 0.44067237627777184} | train loss {'Reaction outcome loss': 0.4632337133495175, 'Total loss': 0.4632337133495175}
2022-11-28 03:53:25,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:25,645 INFO:     Epoch: 75
2022-11-28 03:53:26,290 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4834931902587414, 'Total loss': 0.4834931902587414} | train loss {'Reaction outcome loss': 0.45592964109109374, 'Total loss': 0.45592964109109374}
2022-11-28 03:53:26,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:26,290 INFO:     Epoch: 76
2022-11-28 03:53:26,937 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4457713690671054, 'Total loss': 0.4457713690671054} | train loss {'Reaction outcome loss': 0.4594428064263597, 'Total loss': 0.4594428064263597}
2022-11-28 03:53:26,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:26,938 INFO:     Epoch: 77
2022-11-28 03:53:27,586 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47016202861612494, 'Total loss': 0.47016202861612494} | train loss {'Reaction outcome loss': 0.45792861848461386, 'Total loss': 0.45792861848461386}
2022-11-28 03:53:27,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:27,587 INFO:     Epoch: 78
2022-11-28 03:53:28,237 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4399197602813894, 'Total loss': 0.4399197602813894} | train loss {'Reaction outcome loss': 0.45703798693661785, 'Total loss': 0.45703798693661785}
2022-11-28 03:53:28,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:28,238 INFO:     Epoch: 79
2022-11-28 03:53:28,887 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.481170618398623, 'Total loss': 0.481170618398623} | train loss {'Reaction outcome loss': 0.4595630654875113, 'Total loss': 0.4595630654875113}
2022-11-28 03:53:28,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:28,888 INFO:     Epoch: 80
2022-11-28 03:53:29,538 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4865386706184257, 'Total loss': 0.4865386706184257} | train loss {'Reaction outcome loss': 0.45812701503841247, 'Total loss': 0.45812701503841247}
2022-11-28 03:53:29,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:29,538 INFO:     Epoch: 81
2022-11-28 03:53:30,184 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48677684366703033, 'Total loss': 0.48677684366703033} | train loss {'Reaction outcome loss': 0.45204925768229426, 'Total loss': 0.45204925768229426}
2022-11-28 03:53:30,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:30,185 INFO:     Epoch: 82
2022-11-28 03:53:30,832 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4694555869156664, 'Total loss': 0.4694555869156664} | train loss {'Reaction outcome loss': 0.45885768845981484, 'Total loss': 0.45885768845981484}
2022-11-28 03:53:30,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:30,833 INFO:     Epoch: 83
2022-11-28 03:53:31,481 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4587791816077449, 'Total loss': 0.4587791816077449} | train loss {'Reaction outcome loss': 0.4613465557901227, 'Total loss': 0.4613465557901227}
2022-11-28 03:53:31,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:31,481 INFO:     Epoch: 84
2022-11-28 03:53:32,129 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49572926691987296, 'Total loss': 0.49572926691987296} | train loss {'Reaction outcome loss': 0.45646487450113105, 'Total loss': 0.45646487450113105}
2022-11-28 03:53:32,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:32,129 INFO:     Epoch: 85
2022-11-28 03:53:32,777 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48905618488788605, 'Total loss': 0.48905618488788605} | train loss {'Reaction outcome loss': 0.4573592345933525, 'Total loss': 0.4573592345933525}
2022-11-28 03:53:32,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:32,777 INFO:     Epoch: 86
2022-11-28 03:53:33,426 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4613035457970744, 'Total loss': 0.4613035457970744} | train loss {'Reaction outcome loss': 0.4568455188250055, 'Total loss': 0.4568455188250055}
2022-11-28 03:53:33,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:33,426 INFO:     Epoch: 87
2022-11-28 03:53:34,073 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5062884952534329, 'Total loss': 0.5062884952534329} | train loss {'Reaction outcome loss': 0.4604554251748688, 'Total loss': 0.4604554251748688}
2022-11-28 03:53:34,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:34,073 INFO:     Epoch: 88
2022-11-28 03:53:34,721 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5157341489737685, 'Total loss': 0.5157341489737685} | train loss {'Reaction outcome loss': 0.45538807794147607, 'Total loss': 0.45538807794147607}
2022-11-28 03:53:34,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:34,722 INFO:     Epoch: 89
2022-11-28 03:53:35,369 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46033586764877493, 'Total loss': 0.46033586764877493} | train loss {'Reaction outcome loss': 0.45776246384698516, 'Total loss': 0.45776246384698516}
2022-11-28 03:53:35,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:35,370 INFO:     Epoch: 90
2022-11-28 03:53:36,018 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4690363962541927, 'Total loss': 0.4690363962541927} | train loss {'Reaction outcome loss': 0.46200275408978364, 'Total loss': 0.46200275408978364}
2022-11-28 03:53:36,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:36,018 INFO:     Epoch: 91
2022-11-28 03:53:36,667 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4673181792551821, 'Total loss': 0.4673181792551821} | train loss {'Reaction outcome loss': 0.46099743928228104, 'Total loss': 0.46099743928228104}
2022-11-28 03:53:36,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:36,667 INFO:     Epoch: 92
2022-11-28 03:53:37,314 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4639434851706028, 'Total loss': 0.4639434851706028} | train loss {'Reaction outcome loss': 0.4599553757784318, 'Total loss': 0.4599553757784318}
2022-11-28 03:53:37,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:37,314 INFO:     Epoch: 93
2022-11-28 03:53:37,963 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4559007419103926, 'Total loss': 0.4559007419103926} | train loss {'Reaction outcome loss': 0.45591363046242267, 'Total loss': 0.45591363046242267}
2022-11-28 03:53:37,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:37,964 INFO:     Epoch: 94
2022-11-28 03:53:38,613 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46193292093547905, 'Total loss': 0.46193292093547905} | train loss {'Reaction outcome loss': 0.458233222061274, 'Total loss': 0.458233222061274}
2022-11-28 03:53:38,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:38,613 INFO:     Epoch: 95
2022-11-28 03:53:39,260 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47504610500552436, 'Total loss': 0.47504610500552436} | train loss {'Reaction outcome loss': 0.4599138151017987, 'Total loss': 0.4599138151017987}
2022-11-28 03:53:39,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:39,260 INFO:     Epoch: 96
2022-11-28 03:53:39,910 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45233128660104494, 'Total loss': 0.45233128660104494} | train loss {'Reaction outcome loss': 0.4599484804333473, 'Total loss': 0.4599484804333473}
2022-11-28 03:53:39,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:39,911 INFO:     Epoch: 97
2022-11-28 03:53:40,560 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4614281742410226, 'Total loss': 0.4614281742410226} | train loss {'Reaction outcome loss': 0.4556663753426805, 'Total loss': 0.4556663753426805}
2022-11-28 03:53:40,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:40,560 INFO:     Epoch: 98
2022-11-28 03:53:41,208 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47689561715180223, 'Total loss': 0.47689561715180223} | train loss {'Reaction outcome loss': 0.45883532677377975, 'Total loss': 0.45883532677377975}
2022-11-28 03:53:41,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:41,209 INFO:     Epoch: 99
2022-11-28 03:53:41,859 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44183361022309825, 'Total loss': 0.44183361022309825} | train loss {'Reaction outcome loss': 0.45764575436407207, 'Total loss': 0.45764575436407207}
2022-11-28 03:53:41,860 INFO:     Best model found after epoch 54 of 100.
2022-11-28 03:53:41,860 INFO:   Done with stage: TRAINING
2022-11-28 03:53:41,860 INFO:   Starting stage: EVALUATION
2022-11-28 03:53:41,983 INFO:   Done with stage: EVALUATION
2022-11-28 03:53:41,984 INFO:   Leaving out SEQ value Fold_5
2022-11-28 03:53:41,996 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:53:41,996 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:53:42,633 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:53:42,633 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:53:42,701 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:53:42,701 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:53:42,701 INFO:     No hyperparam tuning for this model
2022-11-28 03:53:42,701 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:53:42,701 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:53:42,702 INFO:     None feature selector for col prot
2022-11-28 03:53:42,702 INFO:     None feature selector for col prot
2022-11-28 03:53:42,702 INFO:     None feature selector for col prot
2022-11-28 03:53:42,703 INFO:     None feature selector for col chem
2022-11-28 03:53:42,703 INFO:     None feature selector for col chem
2022-11-28 03:53:42,703 INFO:     None feature selector for col chem
2022-11-28 03:53:42,703 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:53:42,703 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:53:42,704 INFO:     Number of params in model 169651
2022-11-28 03:53:42,707 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:53:42,707 INFO:   Starting stage: TRAINING
2022-11-28 03:53:42,758 INFO:     Val loss before train {'Reaction outcome loss': 1.0419712344353849, 'Total loss': 1.0419712344353849}
2022-11-28 03:53:42,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:42,758 INFO:     Epoch: 0
2022-11-28 03:53:43,409 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6183588084849444, 'Total loss': 0.6183588084849444} | train loss {'Reaction outcome loss': 0.6897140444531614, 'Total loss': 0.6897140444531614}
2022-11-28 03:53:43,410 INFO:     Found new best model at epoch 0
2022-11-28 03:53:43,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:43,410 INFO:     Epoch: 1
2022-11-28 03:53:44,066 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5658116747032512, 'Total loss': 0.5658116747032512} | train loss {'Reaction outcome loss': 0.5725691161054348, 'Total loss': 0.5725691161054348}
2022-11-28 03:53:44,066 INFO:     Found new best model at epoch 1
2022-11-28 03:53:44,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:44,067 INFO:     Epoch: 2
2022-11-28 03:53:44,718 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6065963039344008, 'Total loss': 0.6065963039344008} | train loss {'Reaction outcome loss': 0.5534128997972619, 'Total loss': 0.5534128997972619}
2022-11-28 03:53:44,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:44,719 INFO:     Epoch: 3
2022-11-28 03:53:45,371 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5897955809804526, 'Total loss': 0.5897955809804526} | train loss {'Reaction outcome loss': 0.5330004262990555, 'Total loss': 0.5330004262990555}
2022-11-28 03:53:45,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:45,371 INFO:     Epoch: 4
2022-11-28 03:53:46,023 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5433042889291589, 'Total loss': 0.5433042889291589} | train loss {'Reaction outcome loss': 0.526802582779394, 'Total loss': 0.526802582779394}
2022-11-28 03:53:46,023 INFO:     Found new best model at epoch 4
2022-11-28 03:53:46,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:46,024 INFO:     Epoch: 5
2022-11-28 03:53:46,677 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5251400585878979, 'Total loss': 0.5251400585878979} | train loss {'Reaction outcome loss': 0.5124667448402658, 'Total loss': 0.5124667448402658}
2022-11-28 03:53:46,677 INFO:     Found new best model at epoch 5
2022-11-28 03:53:46,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:46,678 INFO:     Epoch: 6
2022-11-28 03:53:47,329 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5495553920892152, 'Total loss': 0.5495553920892152} | train loss {'Reaction outcome loss': 0.4988805943428867, 'Total loss': 0.4988805943428867}
2022-11-28 03:53:47,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:47,330 INFO:     Epoch: 7
2022-11-28 03:53:47,981 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49945076351816003, 'Total loss': 0.49945076351816003} | train loss {'Reaction outcome loss': 0.5011652657377575, 'Total loss': 0.5011652657377575}
2022-11-28 03:53:47,982 INFO:     Found new best model at epoch 7
2022-11-28 03:53:47,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:47,983 INFO:     Epoch: 8
2022-11-28 03:53:48,638 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5140126046131958, 'Total loss': 0.5140126046131958} | train loss {'Reaction outcome loss': 0.4903433162734093, 'Total loss': 0.4903433162734093}
2022-11-28 03:53:48,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:48,638 INFO:     Epoch: 9
2022-11-28 03:53:49,292 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5307862013578415, 'Total loss': 0.5307862013578415} | train loss {'Reaction outcome loss': 0.48749410291673684, 'Total loss': 0.48749410291673684}
2022-11-28 03:53:49,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:49,292 INFO:     Epoch: 10
2022-11-28 03:53:49,941 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48982556570659985, 'Total loss': 0.48982556570659985} | train loss {'Reaction outcome loss': 0.4866819118945162, 'Total loss': 0.4866819118945162}
2022-11-28 03:53:49,941 INFO:     Found new best model at epoch 10
2022-11-28 03:53:49,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:49,942 INFO:     Epoch: 11
2022-11-28 03:53:50,597 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5340795042839918, 'Total loss': 0.5340795042839918} | train loss {'Reaction outcome loss': 0.4846106706364344, 'Total loss': 0.4846106706364344}
2022-11-28 03:53:50,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:50,597 INFO:     Epoch: 12
2022-11-28 03:53:51,250 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5185175897045569, 'Total loss': 0.5185175897045569} | train loss {'Reaction outcome loss': 0.4858577630147036, 'Total loss': 0.4858577630147036}
2022-11-28 03:53:51,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:51,250 INFO:     Epoch: 13
2022-11-28 03:53:51,902 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48682663521983405, 'Total loss': 0.48682663521983405} | train loss {'Reaction outcome loss': 0.47756682583677623, 'Total loss': 0.47756682583677623}
2022-11-28 03:53:51,902 INFO:     Found new best model at epoch 13
2022-11-28 03:53:51,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:51,903 INFO:     Epoch: 14
2022-11-28 03:53:52,558 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4851214133880355, 'Total loss': 0.4851214133880355} | train loss {'Reaction outcome loss': 0.470876389126546, 'Total loss': 0.470876389126546}
2022-11-28 03:53:52,559 INFO:     Found new best model at epoch 14
2022-11-28 03:53:52,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:52,559 INFO:     Epoch: 15
2022-11-28 03:53:53,212 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5292616750706326, 'Total loss': 0.5292616750706326} | train loss {'Reaction outcome loss': 0.47992403925913063, 'Total loss': 0.47992403925913063}
2022-11-28 03:53:53,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:53,213 INFO:     Epoch: 16
2022-11-28 03:53:53,866 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5002679059451277, 'Total loss': 0.5002679059451277} | train loss {'Reaction outcome loss': 0.47577792858546564, 'Total loss': 0.47577792858546564}
2022-11-28 03:53:53,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:53,866 INFO:     Epoch: 17
2022-11-28 03:53:54,522 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.509959804740819, 'Total loss': 0.509959804740819} | train loss {'Reaction outcome loss': 0.4708921435149575, 'Total loss': 0.4708921435149575}
2022-11-28 03:53:54,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:54,523 INFO:     Epoch: 18
2022-11-28 03:53:55,177 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4934988143769177, 'Total loss': 0.4934988143769177} | train loss {'Reaction outcome loss': 0.4758580253093771, 'Total loss': 0.4758580253093771}
2022-11-28 03:53:55,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:55,177 INFO:     Epoch: 19
2022-11-28 03:53:55,831 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48463732105764473, 'Total loss': 0.48463732105764473} | train loss {'Reaction outcome loss': 0.4627512547259147, 'Total loss': 0.4627512547259147}
2022-11-28 03:53:55,831 INFO:     Found new best model at epoch 19
2022-11-28 03:53:55,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:55,832 INFO:     Epoch: 20
2022-11-28 03:53:56,485 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5042090693658049, 'Total loss': 0.5042090693658049} | train loss {'Reaction outcome loss': 0.4696651006396483, 'Total loss': 0.4696651006396483}
2022-11-28 03:53:56,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:56,485 INFO:     Epoch: 21
2022-11-28 03:53:57,138 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5283119370314208, 'Total loss': 0.5283119370314208} | train loss {'Reaction outcome loss': 0.4696803781909016, 'Total loss': 0.4696803781909016}
2022-11-28 03:53:57,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:57,138 INFO:     Epoch: 22
2022-11-28 03:53:57,787 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4885459938509898, 'Total loss': 0.4885459938509898} | train loss {'Reaction outcome loss': 0.4733682192469898, 'Total loss': 0.4733682192469898}
2022-11-28 03:53:57,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:57,787 INFO:     Epoch: 23
2022-11-28 03:53:58,437 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4949735938148065, 'Total loss': 0.4949735938148065} | train loss {'Reaction outcome loss': 0.4682250472939449, 'Total loss': 0.4682250472939449}
2022-11-28 03:53:58,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:58,438 INFO:     Epoch: 24
2022-11-28 03:53:59,091 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4853565808046948, 'Total loss': 0.4853565808046948} | train loss {'Reaction outcome loss': 0.4674908554083423, 'Total loss': 0.4674908554083423}
2022-11-28 03:53:59,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:59,091 INFO:     Epoch: 25
2022-11-28 03:53:59,743 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48454261029308493, 'Total loss': 0.48454261029308493} | train loss {'Reaction outcome loss': 0.46130960682022426, 'Total loss': 0.46130960682022426}
2022-11-28 03:53:59,743 INFO:     Found new best model at epoch 25
2022-11-28 03:53:59,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:53:59,744 INFO:     Epoch: 26
2022-11-28 03:54:00,396 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4869680499488657, 'Total loss': 0.4869680499488657} | train loss {'Reaction outcome loss': 0.45474877911299344, 'Total loss': 0.45474877911299344}
2022-11-28 03:54:00,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:00,396 INFO:     Epoch: 27
2022-11-28 03:54:01,050 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.585888547314839, 'Total loss': 0.585888547314839} | train loss {'Reaction outcome loss': 0.46539904273714616, 'Total loss': 0.46539904273714616}
2022-11-28 03:54:01,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:01,051 INFO:     Epoch: 28
2022-11-28 03:54:01,713 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5162783522497524, 'Total loss': 0.5162783522497524} | train loss {'Reaction outcome loss': 0.46737194326725084, 'Total loss': 0.46737194326725084}
2022-11-28 03:54:01,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:01,713 INFO:     Epoch: 29
2022-11-28 03:54:02,374 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.525504744188352, 'Total loss': 0.525504744188352} | train loss {'Reaction outcome loss': 0.46475132080435994, 'Total loss': 0.46475132080435994}
2022-11-28 03:54:02,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:02,375 INFO:     Epoch: 30
2022-11-28 03:54:03,034 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.494949129960415, 'Total loss': 0.494949129960415} | train loss {'Reaction outcome loss': 0.4604769330999629, 'Total loss': 0.4604769330999629}
2022-11-28 03:54:03,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:03,035 INFO:     Epoch: 31
2022-11-28 03:54:03,696 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4745184216987003, 'Total loss': 0.4745184216987003} | train loss {'Reaction outcome loss': 0.47177388310915064, 'Total loss': 0.47177388310915064}
2022-11-28 03:54:03,696 INFO:     Found new best model at epoch 31
2022-11-28 03:54:03,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:03,696 INFO:     Epoch: 32
2022-11-28 03:54:04,358 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49121575396169315, 'Total loss': 0.49121575396169315} | train loss {'Reaction outcome loss': 0.4722083326902095, 'Total loss': 0.4722083326902095}
2022-11-28 03:54:04,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:04,359 INFO:     Epoch: 33
2022-11-28 03:54:05,021 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4978778807615692, 'Total loss': 0.4978778807615692} | train loss {'Reaction outcome loss': 0.4619549142747273, 'Total loss': 0.4619549142747273}
2022-11-28 03:54:05,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:05,021 INFO:     Epoch: 34
2022-11-28 03:54:05,678 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4812160726975311, 'Total loss': 0.4812160726975311} | train loss {'Reaction outcome loss': 0.46223257245262145, 'Total loss': 0.46223257245262145}
2022-11-28 03:54:05,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:05,678 INFO:     Epoch: 35
2022-11-28 03:54:06,336 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4937567419626496, 'Total loss': 0.4937567419626496} | train loss {'Reaction outcome loss': 0.46309327222557684, 'Total loss': 0.46309327222557684}
2022-11-28 03:54:06,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:06,337 INFO:     Epoch: 36
2022-11-28 03:54:06,994 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4799736805937507, 'Total loss': 0.4799736805937507} | train loss {'Reaction outcome loss': 0.4596181975202522, 'Total loss': 0.4596181975202522}
2022-11-28 03:54:06,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:06,995 INFO:     Epoch: 37
2022-11-28 03:54:07,649 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.50596809014678, 'Total loss': 0.50596809014678} | train loss {'Reaction outcome loss': 0.4543460039836675, 'Total loss': 0.4543460039836675}
2022-11-28 03:54:07,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:07,650 INFO:     Epoch: 38
2022-11-28 03:54:08,304 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4807120774957267, 'Total loss': 0.4807120774957267} | train loss {'Reaction outcome loss': 0.46627537323621965, 'Total loss': 0.46627537323621965}
2022-11-28 03:54:08,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:08,304 INFO:     Epoch: 39
2022-11-28 03:54:08,961 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4951984513212334, 'Total loss': 0.4951984513212334} | train loss {'Reaction outcome loss': 0.46322727860950746, 'Total loss': 0.46322727860950746}
2022-11-28 03:54:08,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:08,961 INFO:     Epoch: 40
2022-11-28 03:54:09,617 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49077599664980714, 'Total loss': 0.49077599664980714} | train loss {'Reaction outcome loss': 0.4634772785882718, 'Total loss': 0.4634772785882718}
2022-11-28 03:54:09,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:09,617 INFO:     Epoch: 41
2022-11-28 03:54:10,271 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4896967756477269, 'Total loss': 0.4896967756477269} | train loss {'Reaction outcome loss': 0.46141617211253055, 'Total loss': 0.46141617211253055}
2022-11-28 03:54:10,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:10,271 INFO:     Epoch: 42
2022-11-28 03:54:10,927 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5044295804744418, 'Total loss': 0.5044295804744418} | train loss {'Reaction outcome loss': 0.45724775607844714, 'Total loss': 0.45724775607844714}
2022-11-28 03:54:10,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:10,928 INFO:     Epoch: 43
2022-11-28 03:54:11,585 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5633310580795462, 'Total loss': 0.5633310580795462} | train loss {'Reaction outcome loss': 0.46618807683830804, 'Total loss': 0.46618807683830804}
2022-11-28 03:54:11,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:11,585 INFO:     Epoch: 44
2022-11-28 03:54:12,241 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5063073973764073, 'Total loss': 0.5063073973764073} | train loss {'Reaction outcome loss': 0.4627936459259556, 'Total loss': 0.4627936459259556}
2022-11-28 03:54:12,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:12,242 INFO:     Epoch: 45
2022-11-28 03:54:12,898 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5907045392827555, 'Total loss': 0.5907045392827555} | train loss {'Reaction outcome loss': 0.4533895561509287, 'Total loss': 0.4533895561509287}
2022-11-28 03:54:12,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:12,898 INFO:     Epoch: 46
2022-11-28 03:54:13,552 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4914274872703986, 'Total loss': 0.4914274872703986} | train loss {'Reaction outcome loss': 0.47064966023692234, 'Total loss': 0.47064966023692234}
2022-11-28 03:54:13,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:13,553 INFO:     Epoch: 47
2022-11-28 03:54:14,209 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5184328163211996, 'Total loss': 0.5184328163211996} | train loss {'Reaction outcome loss': 0.4653251059504173, 'Total loss': 0.4653251059504173}
2022-11-28 03:54:14,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:14,209 INFO:     Epoch: 48
2022-11-28 03:54:14,868 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49925324659455905, 'Total loss': 0.49925324659455905} | train loss {'Reaction outcome loss': 0.47500547274253385, 'Total loss': 0.47500547274253385}
2022-11-28 03:54:14,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:14,868 INFO:     Epoch: 49
2022-11-28 03:54:15,525 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5278034555641088, 'Total loss': 0.5278034555641088} | train loss {'Reaction outcome loss': 0.46896109039242934, 'Total loss': 0.46896109039242934}
2022-11-28 03:54:15,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:15,525 INFO:     Epoch: 50
2022-11-28 03:54:16,186 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4980114600197835, 'Total loss': 0.4980114600197835} | train loss {'Reaction outcome loss': 0.4594662853098109, 'Total loss': 0.4594662853098109}
2022-11-28 03:54:16,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:16,186 INFO:     Epoch: 51
2022-11-28 03:54:16,845 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4875365776771849, 'Total loss': 0.4875365776771849} | train loss {'Reaction outcome loss': 0.45818228289665963, 'Total loss': 0.45818228289665963}
2022-11-28 03:54:16,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:16,846 INFO:     Epoch: 52
2022-11-28 03:54:17,504 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48957170275124634, 'Total loss': 0.48957170275124634} | train loss {'Reaction outcome loss': 0.46529799259384635, 'Total loss': 0.46529799259384635}
2022-11-28 03:54:17,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:17,505 INFO:     Epoch: 53
2022-11-28 03:54:18,162 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5031197640028867, 'Total loss': 0.5031197640028867} | train loss {'Reaction outcome loss': 0.457200830040673, 'Total loss': 0.457200830040673}
2022-11-28 03:54:18,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:18,162 INFO:     Epoch: 54
2022-11-28 03:54:18,818 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5443534326146949, 'Total loss': 0.5443534326146949} | train loss {'Reaction outcome loss': 0.46056642247597696, 'Total loss': 0.46056642247597696}
2022-11-28 03:54:18,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:18,818 INFO:     Epoch: 55
2022-11-28 03:54:19,473 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5036515380171213, 'Total loss': 0.5036515380171213} | train loss {'Reaction outcome loss': 0.4753673069852099, 'Total loss': 0.4753673069852099}
2022-11-28 03:54:19,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:19,473 INFO:     Epoch: 56
2022-11-28 03:54:20,132 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4659870703789321, 'Total loss': 0.4659870703789321} | train loss {'Reaction outcome loss': 0.45629964080575086, 'Total loss': 0.45629964080575086}
2022-11-28 03:54:20,133 INFO:     Found new best model at epoch 56
2022-11-28 03:54:20,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:20,133 INFO:     Epoch: 57
2022-11-28 03:54:20,790 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48923603174361313, 'Total loss': 0.48923603174361313} | train loss {'Reaction outcome loss': 0.46011160292968095, 'Total loss': 0.46011160292968095}
2022-11-28 03:54:20,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:20,791 INFO:     Epoch: 58
2022-11-28 03:54:21,446 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5240271457216956, 'Total loss': 0.5240271457216956} | train loss {'Reaction outcome loss': 0.45510110571515755, 'Total loss': 0.45510110571515755}
2022-11-28 03:54:21,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:21,447 INFO:     Epoch: 59
2022-11-28 03:54:22,102 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5214046818966215, 'Total loss': 0.5214046818966215} | train loss {'Reaction outcome loss': 0.46786842598798517, 'Total loss': 0.46786842598798517}
2022-11-28 03:54:22,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:22,102 INFO:     Epoch: 60
2022-11-28 03:54:22,759 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5004862536760893, 'Total loss': 0.5004862536760893} | train loss {'Reaction outcome loss': 0.4717347382413231, 'Total loss': 0.4717347382413231}
2022-11-28 03:54:22,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:22,759 INFO:     Epoch: 61
2022-11-28 03:54:23,414 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4753868888047608, 'Total loss': 0.4753868888047608} | train loss {'Reaction outcome loss': 0.4637677048140692, 'Total loss': 0.4637677048140692}
2022-11-28 03:54:23,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:23,414 INFO:     Epoch: 62
2022-11-28 03:54:24,071 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.499228858473626, 'Total loss': 0.499228858473626} | train loss {'Reaction outcome loss': 0.45397844799013753, 'Total loss': 0.45397844799013753}
2022-11-28 03:54:24,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:24,072 INFO:     Epoch: 63
2022-11-28 03:54:24,728 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48094642568718304, 'Total loss': 0.48094642568718304} | train loss {'Reaction outcome loss': 0.4513883832106857, 'Total loss': 0.4513883832106857}
2022-11-28 03:54:24,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:24,728 INFO:     Epoch: 64
2022-11-28 03:54:25,391 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5258310938423331, 'Total loss': 0.5258310938423331} | train loss {'Reaction outcome loss': 0.46848068594449926, 'Total loss': 0.46848068594449926}
2022-11-28 03:54:25,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:25,392 INFO:     Epoch: 65
2022-11-28 03:54:26,052 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5264949717304923, 'Total loss': 0.5264949717304923} | train loss {'Reaction outcome loss': 0.47393917329684804, 'Total loss': 0.47393917329684804}
2022-11-28 03:54:26,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:26,052 INFO:     Epoch: 66
2022-11-28 03:54:26,711 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49388066069646314, 'Total loss': 0.49388066069646314} | train loss {'Reaction outcome loss': 0.45260519133164334, 'Total loss': 0.45260519133164334}
2022-11-28 03:54:26,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:26,712 INFO:     Epoch: 67
2022-11-28 03:54:27,370 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4913202720609578, 'Total loss': 0.4913202720609578} | train loss {'Reaction outcome loss': 0.45707579632761025, 'Total loss': 0.45707579632761025}
2022-11-28 03:54:27,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:27,370 INFO:     Epoch: 68
2022-11-28 03:54:28,029 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48407575488090515, 'Total loss': 0.48407575488090515} | train loss {'Reaction outcome loss': 0.4740642206328601, 'Total loss': 0.4740642206328601}
2022-11-28 03:54:28,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:28,029 INFO:     Epoch: 69
2022-11-28 03:54:28,688 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5336847332390872, 'Total loss': 0.5336847332390872} | train loss {'Reaction outcome loss': 0.4546078894785059, 'Total loss': 0.4546078894785059}
2022-11-28 03:54:28,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:28,688 INFO:     Epoch: 70
2022-11-28 03:54:29,347 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5142508907751604, 'Total loss': 0.5142508907751604} | train loss {'Reaction outcome loss': 0.4615076691032904, 'Total loss': 0.4615076691032904}
2022-11-28 03:54:29,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:29,347 INFO:     Epoch: 71
2022-11-28 03:54:30,008 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4794106673110615, 'Total loss': 0.4794106673110615} | train loss {'Reaction outcome loss': 0.46004687274870065, 'Total loss': 0.46004687274870065}
2022-11-28 03:54:30,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:30,009 INFO:     Epoch: 72
2022-11-28 03:54:30,668 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4925958070565354, 'Total loss': 0.4925958070565354} | train loss {'Reaction outcome loss': 0.4641341713939601, 'Total loss': 0.4641341713939601}
2022-11-28 03:54:30,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:30,668 INFO:     Epoch: 73
2022-11-28 03:54:31,329 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48800540647723456, 'Total loss': 0.48800540647723456} | train loss {'Reaction outcome loss': 0.45704365754311504, 'Total loss': 0.45704365754311504}
2022-11-28 03:54:31,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:31,329 INFO:     Epoch: 74
2022-11-28 03:54:31,985 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5487228357656435, 'Total loss': 0.5487228357656435} | train loss {'Reaction outcome loss': 0.4617522541689969, 'Total loss': 0.4617522541689969}
2022-11-28 03:54:31,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:31,986 INFO:     Epoch: 75
2022-11-28 03:54:32,643 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.509239258413965, 'Total loss': 0.509239258413965} | train loss {'Reaction outcome loss': 0.46420248805993963, 'Total loss': 0.46420248805993963}
2022-11-28 03:54:32,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:32,643 INFO:     Epoch: 76
2022-11-28 03:54:33,302 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4573850360783664, 'Total loss': 0.4573850360783664} | train loss {'Reaction outcome loss': 0.46068097675136227, 'Total loss': 0.46068097675136227}
2022-11-28 03:54:33,302 INFO:     Found new best model at epoch 76
2022-11-28 03:54:33,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:33,303 INFO:     Epoch: 77
2022-11-28 03:54:33,963 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5163504281504587, 'Total loss': 0.5163504281504587} | train loss {'Reaction outcome loss': 0.45993996318052655, 'Total loss': 0.45993996318052655}
2022-11-28 03:54:33,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:33,963 INFO:     Epoch: 78
2022-11-28 03:54:34,621 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4907493598081849, 'Total loss': 0.4907493598081849} | train loss {'Reaction outcome loss': 0.4573579625441478, 'Total loss': 0.4573579625441478}
2022-11-28 03:54:34,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:34,621 INFO:     Epoch: 79
2022-11-28 03:54:35,282 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5220379991964861, 'Total loss': 0.5220379991964861} | train loss {'Reaction outcome loss': 0.4660573626457438, 'Total loss': 0.4660573626457438}
2022-11-28 03:54:35,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:35,282 INFO:     Epoch: 80
2022-11-28 03:54:35,943 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4776268867267804, 'Total loss': 0.4776268867267804} | train loss {'Reaction outcome loss': 0.45926842230338194, 'Total loss': 0.45926842230338194}
2022-11-28 03:54:35,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:35,943 INFO:     Epoch: 81
2022-11-28 03:54:36,606 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.536261784420772, 'Total loss': 0.536261784420772} | train loss {'Reaction outcome loss': 0.45175285733904436, 'Total loss': 0.45175285733904436}
2022-11-28 03:54:36,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:36,607 INFO:     Epoch: 82
2022-11-28 03:54:37,266 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5596333281560377, 'Total loss': 0.5596333281560377} | train loss {'Reaction outcome loss': 0.4610339735902333, 'Total loss': 0.4610339735902333}
2022-11-28 03:54:37,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:37,266 INFO:     Epoch: 83
2022-11-28 03:54:37,924 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5041749711063775, 'Total loss': 0.5041749711063775} | train loss {'Reaction outcome loss': 0.45484712634703167, 'Total loss': 0.45484712634703167}
2022-11-28 03:54:37,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:37,924 INFO:     Epoch: 84
2022-11-28 03:54:38,581 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4666391685605049, 'Total loss': 0.4666391685605049} | train loss {'Reaction outcome loss': 0.46720757169520805, 'Total loss': 0.46720757169520805}
2022-11-28 03:54:38,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:38,581 INFO:     Epoch: 85
2022-11-28 03:54:39,239 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4793689471076835, 'Total loss': 0.4793689471076835} | train loss {'Reaction outcome loss': 0.4611677864664479, 'Total loss': 0.4611677864664479}
2022-11-28 03:54:39,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:39,239 INFO:     Epoch: 86
2022-11-28 03:54:39,899 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48760332370346243, 'Total loss': 0.48760332370346243} | train loss {'Reaction outcome loss': 0.4589402268109051, 'Total loss': 0.4589402268109051}
2022-11-28 03:54:39,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:39,899 INFO:     Epoch: 87
2022-11-28 03:54:40,557 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5030574910342693, 'Total loss': 0.5030574910342693} | train loss {'Reaction outcome loss': 0.45672136804594204, 'Total loss': 0.45672136804594204}
2022-11-28 03:54:40,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:40,557 INFO:     Epoch: 88
2022-11-28 03:54:41,217 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47909608618779614, 'Total loss': 0.47909608618779614} | train loss {'Reaction outcome loss': 0.462626271778416, 'Total loss': 0.462626271778416}
2022-11-28 03:54:41,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:41,217 INFO:     Epoch: 89
2022-11-28 03:54:41,875 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5541162900626659, 'Total loss': 0.5541162900626659} | train loss {'Reaction outcome loss': 0.46085934790401806, 'Total loss': 0.46085934790401806}
2022-11-28 03:54:41,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:41,876 INFO:     Epoch: 90
2022-11-28 03:54:42,532 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4930501160296527, 'Total loss': 0.4930501160296527} | train loss {'Reaction outcome loss': 0.47787671726242253, 'Total loss': 0.47787671726242253}
2022-11-28 03:54:42,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:42,532 INFO:     Epoch: 91
2022-11-28 03:54:43,189 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.573771514675834, 'Total loss': 0.573771514675834} | train loss {'Reaction outcome loss': 0.46411103254508396, 'Total loss': 0.46411103254508396}
2022-11-28 03:54:43,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:43,190 INFO:     Epoch: 92
2022-11-28 03:54:43,847 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4976360648870468, 'Total loss': 0.4976360648870468} | train loss {'Reaction outcome loss': 0.47438079474667305, 'Total loss': 0.47438079474667305}
2022-11-28 03:54:43,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:43,847 INFO:     Epoch: 93
2022-11-28 03:54:44,505 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5348073569211093, 'Total loss': 0.5348073569211093} | train loss {'Reaction outcome loss': 0.46481241026388004, 'Total loss': 0.46481241026388004}
2022-11-28 03:54:44,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:44,506 INFO:     Epoch: 94
2022-11-28 03:54:45,163 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5026281194930727, 'Total loss': 0.5026281194930727} | train loss {'Reaction outcome loss': 0.4726010000235156, 'Total loss': 0.4726010000235156}
2022-11-28 03:54:45,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:45,164 INFO:     Epoch: 95
2022-11-28 03:54:45,823 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5240876339375973, 'Total loss': 0.5240876339375973} | train loss {'Reaction outcome loss': 0.4609589921197428, 'Total loss': 0.4609589921197428}
2022-11-28 03:54:45,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:45,823 INFO:     Epoch: 96
2022-11-28 03:54:46,479 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5220749235965989, 'Total loss': 0.5220749235965989} | train loss {'Reaction outcome loss': 0.47072955537662814, 'Total loss': 0.47072955537662814}
2022-11-28 03:54:46,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:46,480 INFO:     Epoch: 97
2022-11-28 03:54:47,136 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4862101301550865, 'Total loss': 0.4862101301550865} | train loss {'Reaction outcome loss': 0.45872674995528057, 'Total loss': 0.45872674995528057}
2022-11-28 03:54:47,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:47,136 INFO:     Epoch: 98
2022-11-28 03:54:47,795 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4786619039421732, 'Total loss': 0.4786619039421732} | train loss {'Reaction outcome loss': 0.46359357841101734, 'Total loss': 0.46359357841101734}
2022-11-28 03:54:47,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:47,796 INFO:     Epoch: 99
2022-11-28 03:54:48,451 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5201270559971983, 'Total loss': 0.5201270559971983} | train loss {'Reaction outcome loss': 0.45928171129241163, 'Total loss': 0.45928171129241163}
2022-11-28 03:54:48,452 INFO:     Best model found after epoch 77 of 100.
2022-11-28 03:54:48,452 INFO:   Done with stage: TRAINING
2022-11-28 03:54:48,452 INFO:   Starting stage: EVALUATION
2022-11-28 03:54:48,570 INFO:   Done with stage: EVALUATION
2022-11-28 03:54:48,570 INFO:   Leaving out SEQ value Fold_6
2022-11-28 03:54:48,583 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:54:48,583 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:54:49,228 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:54:49,228 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:54:49,296 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:54:49,297 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:54:49,297 INFO:     No hyperparam tuning for this model
2022-11-28 03:54:49,297 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:54:49,297 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:54:49,297 INFO:     None feature selector for col prot
2022-11-28 03:54:49,298 INFO:     None feature selector for col prot
2022-11-28 03:54:49,298 INFO:     None feature selector for col prot
2022-11-28 03:54:49,298 INFO:     None feature selector for col chem
2022-11-28 03:54:49,298 INFO:     None feature selector for col chem
2022-11-28 03:54:49,298 INFO:     None feature selector for col chem
2022-11-28 03:54:49,298 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:54:49,298 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:54:49,300 INFO:     Number of params in model 169651
2022-11-28 03:54:49,303 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:54:49,303 INFO:   Starting stage: TRAINING
2022-11-28 03:54:49,354 INFO:     Val loss before train {'Reaction outcome loss': 0.9974575462666425, 'Total loss': 0.9974575462666425}
2022-11-28 03:54:49,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:49,355 INFO:     Epoch: 0
2022-11-28 03:54:50,014 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5882436629723419, 'Total loss': 0.5882436629723419} | train loss {'Reaction outcome loss': 0.698772304360905, 'Total loss': 0.698772304360905}
2022-11-28 03:54:50,014 INFO:     Found new best model at epoch 0
2022-11-28 03:54:50,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:50,015 INFO:     Epoch: 1
2022-11-28 03:54:50,674 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5718083672902801, 'Total loss': 0.5718083672902801} | train loss {'Reaction outcome loss': 0.5976071288028071, 'Total loss': 0.5976071288028071}
2022-11-28 03:54:50,674 INFO:     Found new best model at epoch 1
2022-11-28 03:54:50,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:50,675 INFO:     Epoch: 2
2022-11-28 03:54:51,335 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5543356084010818, 'Total loss': 0.5543356084010818} | train loss {'Reaction outcome loss': 0.557423363589952, 'Total loss': 0.557423363589952}
2022-11-28 03:54:51,335 INFO:     Found new best model at epoch 2
2022-11-28 03:54:51,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:51,336 INFO:     Epoch: 3
2022-11-28 03:54:51,994 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5447719347747889, 'Total loss': 0.5447719347747889} | train loss {'Reaction outcome loss': 0.5422022137790918, 'Total loss': 0.5422022137790918}
2022-11-28 03:54:51,994 INFO:     Found new best model at epoch 3
2022-11-28 03:54:51,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:51,995 INFO:     Epoch: 4
2022-11-28 03:54:52,656 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5152467076073993, 'Total loss': 0.5152467076073993} | train loss {'Reaction outcome loss': 0.5305640143492529, 'Total loss': 0.5305640143492529}
2022-11-28 03:54:52,656 INFO:     Found new best model at epoch 4
2022-11-28 03:54:52,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:52,657 INFO:     Epoch: 5
2022-11-28 03:54:53,319 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5162808024747805, 'Total loss': 0.5162808024747805} | train loss {'Reaction outcome loss': 0.522921585087334, 'Total loss': 0.522921585087334}
2022-11-28 03:54:53,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:53,319 INFO:     Epoch: 6
2022-11-28 03:54:53,981 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5094585229050029, 'Total loss': 0.5094585229050029} | train loss {'Reaction outcome loss': 0.5117467104066764, 'Total loss': 0.5117467104066764}
2022-11-28 03:54:53,981 INFO:     Found new best model at epoch 6
2022-11-28 03:54:53,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:53,982 INFO:     Epoch: 7
2022-11-28 03:54:54,642 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5105686079372059, 'Total loss': 0.5105686079372059} | train loss {'Reaction outcome loss': 0.5074929372978306, 'Total loss': 0.5074929372978306}
2022-11-28 03:54:54,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:54,642 INFO:     Epoch: 8
2022-11-28 03:54:55,300 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.501081723550504, 'Total loss': 0.501081723550504} | train loss {'Reaction outcome loss': 0.5001909439001353, 'Total loss': 0.5001909439001353}
2022-11-28 03:54:55,300 INFO:     Found new best model at epoch 8
2022-11-28 03:54:55,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:55,301 INFO:     Epoch: 9
2022-11-28 03:54:55,962 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5314258696003393, 'Total loss': 0.5314258696003393} | train loss {'Reaction outcome loss': 0.49910451477814105, 'Total loss': 0.49910451477814105}
2022-11-28 03:54:55,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:55,964 INFO:     Epoch: 10
2022-11-28 03:54:56,624 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5044218091802164, 'Total loss': 0.5044218091802164} | train loss {'Reaction outcome loss': 0.48921443452878344, 'Total loss': 0.48921443452878344}
2022-11-28 03:54:56,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:56,625 INFO:     Epoch: 11
2022-11-28 03:54:57,284 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4876620156521147, 'Total loss': 0.4876620156521147} | train loss {'Reaction outcome loss': 0.49086247156223944, 'Total loss': 0.49086247156223944}
2022-11-28 03:54:57,284 INFO:     Found new best model at epoch 11
2022-11-28 03:54:57,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:57,285 INFO:     Epoch: 12
2022-11-28 03:54:57,950 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48906706138090655, 'Total loss': 0.48906706138090655} | train loss {'Reaction outcome loss': 0.4858184030820285, 'Total loss': 0.4858184030820285}
2022-11-28 03:54:57,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:57,950 INFO:     Epoch: 13
2022-11-28 03:54:58,612 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5087198462675918, 'Total loss': 0.5087198462675918} | train loss {'Reaction outcome loss': 0.4839211026386869, 'Total loss': 0.4839211026386869}
2022-11-28 03:54:58,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:58,612 INFO:     Epoch: 14
2022-11-28 03:54:59,277 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5419298302043568, 'Total loss': 0.5419298302043568} | train loss {'Reaction outcome loss': 0.48354508595601203, 'Total loss': 0.48354508595601203}
2022-11-28 03:54:59,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:59,277 INFO:     Epoch: 15
2022-11-28 03:54:59,940 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.516532218422402, 'Total loss': 0.516532218422402} | train loss {'Reaction outcome loss': 0.48058104442973293, 'Total loss': 0.48058104442973293}
2022-11-28 03:54:59,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:54:59,941 INFO:     Epoch: 16
2022-11-28 03:55:00,601 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5228704024444927, 'Total loss': 0.5228704024444927} | train loss {'Reaction outcome loss': 0.47991477902377805, 'Total loss': 0.47991477902377805}
2022-11-28 03:55:00,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:00,601 INFO:     Epoch: 17
2022-11-28 03:55:01,261 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4879698340188373, 'Total loss': 0.4879698340188373} | train loss {'Reaction outcome loss': 0.47817010435486035, 'Total loss': 0.47817010435486035}
2022-11-28 03:55:01,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:01,261 INFO:     Epoch: 18
2022-11-28 03:55:01,923 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5106099522249266, 'Total loss': 0.5106099522249266} | train loss {'Reaction outcome loss': 0.4731079541266926, 'Total loss': 0.4731079541266926}
2022-11-28 03:55:01,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:01,924 INFO:     Epoch: 19
2022-11-28 03:55:02,581 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49735674837773497, 'Total loss': 0.49735674837773497} | train loss {'Reaction outcome loss': 0.47878884734405625, 'Total loss': 0.47878884734405625}
2022-11-28 03:55:02,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:02,582 INFO:     Epoch: 20
2022-11-28 03:55:03,242 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5041883025657047, 'Total loss': 0.5041883025657047} | train loss {'Reaction outcome loss': 0.4645632211599619, 'Total loss': 0.4645632211599619}
2022-11-28 03:55:03,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:03,242 INFO:     Epoch: 21
2022-11-28 03:55:03,904 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5115805065090006, 'Total loss': 0.5115805065090006} | train loss {'Reaction outcome loss': 0.4783755213983597, 'Total loss': 0.4783755213983597}
2022-11-28 03:55:03,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:03,904 INFO:     Epoch: 22
2022-11-28 03:55:04,566 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4781119213862853, 'Total loss': 0.4781119213862853} | train loss {'Reaction outcome loss': 0.4760558998752986, 'Total loss': 0.4760558998752986}
2022-11-28 03:55:04,566 INFO:     Found new best model at epoch 22
2022-11-28 03:55:04,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:04,567 INFO:     Epoch: 23
2022-11-28 03:55:05,232 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5282184359702197, 'Total loss': 0.5282184359702197} | train loss {'Reaction outcome loss': 0.47306537748344485, 'Total loss': 0.47306537748344485}
2022-11-28 03:55:05,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:05,232 INFO:     Epoch: 24
2022-11-28 03:55:05,895 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4917486482723193, 'Total loss': 0.4917486482723193} | train loss {'Reaction outcome loss': 0.47318690059886825, 'Total loss': 0.47318690059886825}
2022-11-28 03:55:05,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:05,895 INFO:     Epoch: 25
2022-11-28 03:55:06,558 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49501627615906973, 'Total loss': 0.49501627615906973} | train loss {'Reaction outcome loss': 0.46905637935044303, 'Total loss': 0.46905637935044303}
2022-11-28 03:55:06,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:06,558 INFO:     Epoch: 26
2022-11-28 03:55:07,219 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5015815950252793, 'Total loss': 0.5015815950252793} | train loss {'Reaction outcome loss': 0.4697065366612327, 'Total loss': 0.4697065366612327}
2022-11-28 03:55:07,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:07,219 INFO:     Epoch: 27
2022-11-28 03:55:07,880 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48234795609658415, 'Total loss': 0.48234795609658415} | train loss {'Reaction outcome loss': 0.4744599325161788, 'Total loss': 0.4744599325161788}
2022-11-28 03:55:07,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:07,880 INFO:     Epoch: 28
2022-11-28 03:55:08,545 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4977005919949575, 'Total loss': 0.4977005919949575} | train loss {'Reaction outcome loss': 0.47608620547238856, 'Total loss': 0.47608620547238856}
2022-11-28 03:55:08,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:08,545 INFO:     Epoch: 29
2022-11-28 03:55:09,208 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49327504905787384, 'Total loss': 0.49327504905787384} | train loss {'Reaction outcome loss': 0.46609151585688513, 'Total loss': 0.46609151585688513}
2022-11-28 03:55:09,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:09,208 INFO:     Epoch: 30
2022-11-28 03:55:09,872 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.50823874771595, 'Total loss': 0.50823874771595} | train loss {'Reaction outcome loss': 0.46502395815426306, 'Total loss': 0.46502395815426306}
2022-11-28 03:55:09,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:09,872 INFO:     Epoch: 31
2022-11-28 03:55:10,534 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5118925862691619, 'Total loss': 0.5118925862691619} | train loss {'Reaction outcome loss': 0.4716184044917745, 'Total loss': 0.4716184044917745}
2022-11-28 03:55:10,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:10,534 INFO:     Epoch: 32
2022-11-28 03:55:11,196 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49461303651332855, 'Total loss': 0.49461303651332855} | train loss {'Reaction outcome loss': 0.4709099983015368, 'Total loss': 0.4709099983015368}
2022-11-28 03:55:11,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:11,197 INFO:     Epoch: 33
2022-11-28 03:55:11,856 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49090271307663486, 'Total loss': 0.49090271307663486} | train loss {'Reaction outcome loss': 0.47460307631521453, 'Total loss': 0.47460307631521453}
2022-11-28 03:55:11,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:11,856 INFO:     Epoch: 34
2022-11-28 03:55:12,518 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4974610981616107, 'Total loss': 0.4974610981616107} | train loss {'Reaction outcome loss': 0.4773471619813673, 'Total loss': 0.4773471619813673}
2022-11-28 03:55:12,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:12,518 INFO:     Epoch: 35
2022-11-28 03:55:13,176 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49829354882240295, 'Total loss': 0.49829354882240295} | train loss {'Reaction outcome loss': 0.4719790500258246, 'Total loss': 0.4719790500258246}
2022-11-28 03:55:13,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:13,177 INFO:     Epoch: 36
2022-11-28 03:55:13,837 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5047161775556478, 'Total loss': 0.5047161775556478} | train loss {'Reaction outcome loss': 0.47266719352093434, 'Total loss': 0.47266719352093434}
2022-11-28 03:55:13,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:13,838 INFO:     Epoch: 37
2022-11-28 03:55:14,502 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.492245768958872, 'Total loss': 0.492245768958872} | train loss {'Reaction outcome loss': 0.47721435772555487, 'Total loss': 0.47721435772555487}
2022-11-28 03:55:14,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:14,502 INFO:     Epoch: 38
2022-11-28 03:55:15,167 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.485514143651182, 'Total loss': 0.485514143651182} | train loss {'Reaction outcome loss': 0.47442448890257266, 'Total loss': 0.47442448890257266}
2022-11-28 03:55:15,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:15,168 INFO:     Epoch: 39
2022-11-28 03:55:15,828 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4769994928078218, 'Total loss': 0.4769994928078218} | train loss {'Reaction outcome loss': 0.4683538796680589, 'Total loss': 0.4683538796680589}
2022-11-28 03:55:15,828 INFO:     Found new best model at epoch 39
2022-11-28 03:55:15,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:15,829 INFO:     Epoch: 40
2022-11-28 03:55:16,487 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49914436821233144, 'Total loss': 0.49914436821233144} | train loss {'Reaction outcome loss': 0.4726200696801947, 'Total loss': 0.4726200696801947}
2022-11-28 03:55:16,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:16,488 INFO:     Epoch: 41
2022-11-28 03:55:17,147 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5201940245249055, 'Total loss': 0.5201940245249055} | train loss {'Reaction outcome loss': 0.47866990122823944, 'Total loss': 0.47866990122823944}
2022-11-28 03:55:17,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:17,147 INFO:     Epoch: 42
2022-11-28 03:55:17,807 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4795540083538402, 'Total loss': 0.4795540083538402} | train loss {'Reaction outcome loss': 0.47544630094160956, 'Total loss': 0.47544630094160956}
2022-11-28 03:55:17,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:17,807 INFO:     Epoch: 43
2022-11-28 03:55:18,466 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5088362531228499, 'Total loss': 0.5088362531228499} | train loss {'Reaction outcome loss': 0.4835510426050713, 'Total loss': 0.4835510426050713}
2022-11-28 03:55:18,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:18,467 INFO:     Epoch: 44
2022-11-28 03:55:19,124 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5256717733361504, 'Total loss': 0.5256717733361504} | train loss {'Reaction outcome loss': 0.47929399036952564, 'Total loss': 0.47929399036952564}
2022-11-28 03:55:19,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:19,125 INFO:     Epoch: 45
2022-11-28 03:55:19,782 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.502535090866414, 'Total loss': 0.502535090866414} | train loss {'Reaction outcome loss': 0.4711051791786186, 'Total loss': 0.4711051791786186}
2022-11-28 03:55:19,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:19,783 INFO:     Epoch: 46
2022-11-28 03:55:20,443 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49407859349792654, 'Total loss': 0.49407859349792654} | train loss {'Reaction outcome loss': 0.47394578543401533, 'Total loss': 0.47394578543401533}
2022-11-28 03:55:20,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:20,443 INFO:     Epoch: 47
2022-11-28 03:55:21,099 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.500972642139955, 'Total loss': 0.500972642139955} | train loss {'Reaction outcome loss': 0.4757362364701206, 'Total loss': 0.4757362364701206}
2022-11-28 03:55:21,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:21,100 INFO:     Epoch: 48
2022-11-28 03:55:21,757 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46782847900282254, 'Total loss': 0.46782847900282254} | train loss {'Reaction outcome loss': 0.46454283595085144, 'Total loss': 0.46454283595085144}
2022-11-28 03:55:21,757 INFO:     Found new best model at epoch 48
2022-11-28 03:55:21,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:21,758 INFO:     Epoch: 49
2022-11-28 03:55:22,417 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4879603765227578, 'Total loss': 0.4879603765227578} | train loss {'Reaction outcome loss': 0.4811974238724478, 'Total loss': 0.4811974238724478}
2022-11-28 03:55:22,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:22,417 INFO:     Epoch: 50
2022-11-28 03:55:23,071 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5209706940434196, 'Total loss': 0.5209706940434196} | train loss {'Reaction outcome loss': 0.4711803501291621, 'Total loss': 0.4711803501291621}
2022-11-28 03:55:23,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:23,071 INFO:     Epoch: 51
2022-11-28 03:55:23,729 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4875807338817553, 'Total loss': 0.4875807338817553} | train loss {'Reaction outcome loss': 0.46924120175742334, 'Total loss': 0.46924120175742334}
2022-11-28 03:55:23,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:23,729 INFO:     Epoch: 52
2022-11-28 03:55:24,382 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5218387164852836, 'Total loss': 0.5218387164852836} | train loss {'Reaction outcome loss': 0.47371645968767906, 'Total loss': 0.47371645968767906}
2022-11-28 03:55:24,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:24,382 INFO:     Epoch: 53
2022-11-28 03:55:25,035 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5217343792319298, 'Total loss': 0.5217343792319298} | train loss {'Reaction outcome loss': 0.476706225244749, 'Total loss': 0.476706225244749}
2022-11-28 03:55:25,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:25,036 INFO:     Epoch: 54
2022-11-28 03:55:25,692 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49264380166476424, 'Total loss': 0.49264380166476424} | train loss {'Reaction outcome loss': 0.47957638104356104, 'Total loss': 0.47957638104356104}
2022-11-28 03:55:25,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:25,692 INFO:     Epoch: 55
2022-11-28 03:55:26,351 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49685525453903456, 'Total loss': 0.49685525453903456} | train loss {'Reaction outcome loss': 0.46875739229782937, 'Total loss': 0.46875739229782937}
2022-11-28 03:55:26,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:26,351 INFO:     Epoch: 56
2022-11-28 03:55:27,004 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5053581060333685, 'Total loss': 0.5053581060333685} | train loss {'Reaction outcome loss': 0.47555217570475034, 'Total loss': 0.47555217570475034}
2022-11-28 03:55:27,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:27,005 INFO:     Epoch: 57
2022-11-28 03:55:27,660 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4857840490612117, 'Total loss': 0.4857840490612117} | train loss {'Reaction outcome loss': 0.4753281597288386, 'Total loss': 0.4753281597288386}
2022-11-28 03:55:27,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:27,661 INFO:     Epoch: 58
2022-11-28 03:55:28,319 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5324660214510831, 'Total loss': 0.5324660214510831} | train loss {'Reaction outcome loss': 0.4763898375113645, 'Total loss': 0.4763898375113645}
2022-11-28 03:55:28,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:28,319 INFO:     Epoch: 59
2022-11-28 03:55:28,978 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4819225465709513, 'Total loss': 0.4819225465709513} | train loss {'Reaction outcome loss': 0.47785929013644496, 'Total loss': 0.47785929013644496}
2022-11-28 03:55:28,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:28,979 INFO:     Epoch: 60
2022-11-28 03:55:29,639 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49241184680299327, 'Total loss': 0.49241184680299327} | train loss {'Reaction outcome loss': 0.4657825424426025, 'Total loss': 0.4657825424426025}
2022-11-28 03:55:29,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:29,639 INFO:     Epoch: 61
2022-11-28 03:55:30,298 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4865389175035737, 'Total loss': 0.4865389175035737} | train loss {'Reaction outcome loss': 0.4775938610996931, 'Total loss': 0.4775938610996931}
2022-11-28 03:55:30,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:30,299 INFO:     Epoch: 62
2022-11-28 03:55:30,958 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49743679572235455, 'Total loss': 0.49743679572235455} | train loss {'Reaction outcome loss': 0.46967542622118225, 'Total loss': 0.46967542622118225}
2022-11-28 03:55:30,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:30,958 INFO:     Epoch: 63
2022-11-28 03:55:31,616 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5127594210207462, 'Total loss': 0.5127594210207462} | train loss {'Reaction outcome loss': 0.46997271976884336, 'Total loss': 0.46997271976884336}
2022-11-28 03:55:31,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:31,617 INFO:     Epoch: 64
2022-11-28 03:55:32,277 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5589131238785657, 'Total loss': 0.5589131238785657} | train loss {'Reaction outcome loss': 0.47286772667880983, 'Total loss': 0.47286772667880983}
2022-11-28 03:55:32,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:32,277 INFO:     Epoch: 65
2022-11-28 03:55:32,938 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5004277801649137, 'Total loss': 0.5004277801649137} | train loss {'Reaction outcome loss': 0.4771505889873351, 'Total loss': 0.4771505889873351}
2022-11-28 03:55:32,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:32,938 INFO:     Epoch: 66
2022-11-28 03:55:33,597 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.481056096540256, 'Total loss': 0.481056096540256} | train loss {'Reaction outcome loss': 0.4649365527495261, 'Total loss': 0.4649365527495261}
2022-11-28 03:55:33,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:33,597 INFO:     Epoch: 67
2022-11-28 03:55:34,258 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48249088634144177, 'Total loss': 0.48249088634144177} | train loss {'Reaction outcome loss': 0.4791051942494608, 'Total loss': 0.4791051942494608}
2022-11-28 03:55:34,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:34,259 INFO:     Epoch: 68
2022-11-28 03:55:34,920 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4845204705541784, 'Total loss': 0.4845204705541784} | train loss {'Reaction outcome loss': 0.47170096134106, 'Total loss': 0.47170096134106}
2022-11-28 03:55:34,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:34,920 INFO:     Epoch: 69
2022-11-28 03:55:35,582 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4807813868603923, 'Total loss': 0.4807813868603923} | train loss {'Reaction outcome loss': 0.46642766394201784, 'Total loss': 0.46642766394201784}
2022-11-28 03:55:35,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:35,582 INFO:     Epoch: 70
2022-11-28 03:55:36,241 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5443192557855085, 'Total loss': 0.5443192557855085} | train loss {'Reaction outcome loss': 0.46767813273735587, 'Total loss': 0.46767813273735587}
2022-11-28 03:55:36,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:36,241 INFO:     Epoch: 71
2022-11-28 03:55:36,899 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47589287060228264, 'Total loss': 0.47589287060228264} | train loss {'Reaction outcome loss': 0.4795536452964429, 'Total loss': 0.4795536452964429}
2022-11-28 03:55:36,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:36,899 INFO:     Epoch: 72
2022-11-28 03:55:37,560 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4790673194961114, 'Total loss': 0.4790673194961114} | train loss {'Reaction outcome loss': 0.4735160323400651, 'Total loss': 0.4735160323400651}
2022-11-28 03:55:37,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:37,561 INFO:     Epoch: 73
2022-11-28 03:55:38,218 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.484759502790191, 'Total loss': 0.484759502790191} | train loss {'Reaction outcome loss': 0.47593085882404157, 'Total loss': 0.47593085882404157}
2022-11-28 03:55:38,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:38,218 INFO:     Epoch: 74
2022-11-28 03:55:38,881 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4832073294303634, 'Total loss': 0.4832073294303634} | train loss {'Reaction outcome loss': 0.47495683306647885, 'Total loss': 0.47495683306647885}
2022-11-28 03:55:38,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:38,881 INFO:     Epoch: 75
2022-11-28 03:55:39,541 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4712542813609947, 'Total loss': 0.4712542813609947} | train loss {'Reaction outcome loss': 0.47248282262514674, 'Total loss': 0.47248282262514674}
2022-11-28 03:55:39,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:39,542 INFO:     Epoch: 76
2022-11-28 03:55:40,201 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49039905992421234, 'Total loss': 0.49039905992421234} | train loss {'Reaction outcome loss': 0.4782448959566893, 'Total loss': 0.4782448959566893}
2022-11-28 03:55:40,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:40,202 INFO:     Epoch: 77
2022-11-28 03:55:40,860 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4917750439860604, 'Total loss': 0.4917750439860604} | train loss {'Reaction outcome loss': 0.4742550308545751, 'Total loss': 0.4742550308545751}
2022-11-28 03:55:40,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:40,860 INFO:     Epoch: 78
2022-11-28 03:55:41,521 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5139664076268673, 'Total loss': 0.5139664076268673} | train loss {'Reaction outcome loss': 0.4762362057883893, 'Total loss': 0.4762362057883893}
2022-11-28 03:55:41,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:41,521 INFO:     Epoch: 79
2022-11-28 03:55:42,183 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4978985617106611, 'Total loss': 0.4978985617106611} | train loss {'Reaction outcome loss': 0.47025286874944167, 'Total loss': 0.47025286874944167}
2022-11-28 03:55:42,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:42,183 INFO:     Epoch: 80
2022-11-28 03:55:42,843 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4784650948237289, 'Total loss': 0.4784650948237289} | train loss {'Reaction outcome loss': 0.46854635811741313, 'Total loss': 0.46854635811741313}
2022-11-28 03:55:42,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:42,843 INFO:     Epoch: 81
2022-11-28 03:55:43,503 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4961123629049821, 'Total loss': 0.4961123629049821} | train loss {'Reaction outcome loss': 0.47963723576357287, 'Total loss': 0.47963723576357287}
2022-11-28 03:55:43,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:43,504 INFO:     Epoch: 82
2022-11-28 03:55:44,163 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4985691417347301, 'Total loss': 0.4985691417347301} | train loss {'Reaction outcome loss': 0.473271468113507, 'Total loss': 0.473271468113507}
2022-11-28 03:55:44,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:44,163 INFO:     Epoch: 83
2022-11-28 03:55:44,823 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4909155490723523, 'Total loss': 0.4909155490723523} | train loss {'Reaction outcome loss': 0.4709845776519468, 'Total loss': 0.4709845776519468}
2022-11-28 03:55:44,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:44,823 INFO:     Epoch: 84
2022-11-28 03:55:45,482 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48891347782178357, 'Total loss': 0.48891347782178357} | train loss {'Reaction outcome loss': 0.4768519613351072, 'Total loss': 0.4768519613351072}
2022-11-28 03:55:45,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:45,482 INFO:     Epoch: 85
2022-11-28 03:55:46,152 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.533752711659128, 'Total loss': 0.533752711659128} | train loss {'Reaction outcome loss': 0.46684163051747507, 'Total loss': 0.46684163051747507}
2022-11-28 03:55:46,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:46,152 INFO:     Epoch: 86
2022-11-28 03:55:46,810 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4983834021470763, 'Total loss': 0.4983834021470763} | train loss {'Reaction outcome loss': 0.47195915739622807, 'Total loss': 0.47195915739622807}
2022-11-28 03:55:46,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:46,811 INFO:     Epoch: 87
2022-11-28 03:55:47,469 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48670652644200757, 'Total loss': 0.48670652644200757} | train loss {'Reaction outcome loss': 0.475573415177003, 'Total loss': 0.475573415177003}
2022-11-28 03:55:47,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:47,469 INFO:     Epoch: 88
2022-11-28 03:55:48,126 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49336689947680995, 'Total loss': 0.49336689947680995} | train loss {'Reaction outcome loss': 0.4649432162123342, 'Total loss': 0.4649432162123342}
2022-11-28 03:55:48,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:48,126 INFO:     Epoch: 89
2022-11-28 03:55:48,786 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4743640839376233, 'Total loss': 0.4743640839376233} | train loss {'Reaction outcome loss': 0.4694612362692433, 'Total loss': 0.4694612362692433}
2022-11-28 03:55:48,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:48,787 INFO:     Epoch: 90
2022-11-28 03:55:49,447 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.496834740720012, 'Total loss': 0.496834740720012} | train loss {'Reaction outcome loss': 0.4692761312809683, 'Total loss': 0.4692761312809683}
2022-11-28 03:55:49,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:49,447 INFO:     Epoch: 91
2022-11-28 03:55:50,107 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5010204748673872, 'Total loss': 0.5010204748673872} | train loss {'Reaction outcome loss': 0.4758158605545759, 'Total loss': 0.4758158605545759}
2022-11-28 03:55:50,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:50,108 INFO:     Epoch: 92
2022-11-28 03:55:50,765 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.496373848142949, 'Total loss': 0.496373848142949} | train loss {'Reaction outcome loss': 0.4765165523295441, 'Total loss': 0.4765165523295441}
2022-11-28 03:55:50,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:50,765 INFO:     Epoch: 93
2022-11-28 03:55:51,423 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4811052554710345, 'Total loss': 0.4811052554710345} | train loss {'Reaction outcome loss': 0.47506142551860503, 'Total loss': 0.47506142551860503}
2022-11-28 03:55:51,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:51,423 INFO:     Epoch: 94
2022-11-28 03:55:52,083 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47861491990360344, 'Total loss': 0.47861491990360344} | train loss {'Reaction outcome loss': 0.4736242382636955, 'Total loss': 0.4736242382636955}
2022-11-28 03:55:52,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:52,083 INFO:     Epoch: 95
2022-11-28 03:55:52,743 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4885732243684205, 'Total loss': 0.4885732243684205} | train loss {'Reaction outcome loss': 0.4712578277554243, 'Total loss': 0.4712578277554243}
2022-11-28 03:55:52,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:52,743 INFO:     Epoch: 96
2022-11-28 03:55:53,401 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.479870967566967, 'Total loss': 0.479870967566967} | train loss {'Reaction outcome loss': 0.47108949810987516, 'Total loss': 0.47108949810987516}
2022-11-28 03:55:53,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:53,402 INFO:     Epoch: 97
2022-11-28 03:55:54,062 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5491805994375185, 'Total loss': 0.5491805994375185} | train loss {'Reaction outcome loss': 0.46634988186340176, 'Total loss': 0.46634988186340176}
2022-11-28 03:55:54,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:54,062 INFO:     Epoch: 98
2022-11-28 03:55:54,722 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5015760053965178, 'Total loss': 0.5015760053965178} | train loss {'Reaction outcome loss': 0.4733873613539242, 'Total loss': 0.4733873613539242}
2022-11-28 03:55:54,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:54,722 INFO:     Epoch: 99
2022-11-28 03:55:55,382 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5477491430938244, 'Total loss': 0.5477491430938244} | train loss {'Reaction outcome loss': 0.47099513215042893, 'Total loss': 0.47099513215042893}
2022-11-28 03:55:55,382 INFO:     Best model found after epoch 49 of 100.
2022-11-28 03:55:55,382 INFO:   Done with stage: TRAINING
2022-11-28 03:55:55,382 INFO:   Starting stage: EVALUATION
2022-11-28 03:55:55,495 INFO:   Done with stage: EVALUATION
2022-11-28 03:55:55,495 INFO:   Leaving out SEQ value Fold_7
2022-11-28 03:55:55,507 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:55:55,507 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:55:56,144 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:55:56,144 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:55:56,213 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:55:56,213 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:55:56,213 INFO:     No hyperparam tuning for this model
2022-11-28 03:55:56,214 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:55:56,214 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:55:56,214 INFO:     None feature selector for col prot
2022-11-28 03:55:56,214 INFO:     None feature selector for col prot
2022-11-28 03:55:56,215 INFO:     None feature selector for col prot
2022-11-28 03:55:56,215 INFO:     None feature selector for col chem
2022-11-28 03:55:56,215 INFO:     None feature selector for col chem
2022-11-28 03:55:56,215 INFO:     None feature selector for col chem
2022-11-28 03:55:56,215 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:55:56,215 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:55:56,217 INFO:     Number of params in model 169651
2022-11-28 03:55:56,220 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:55:56,220 INFO:   Starting stage: TRAINING
2022-11-28 03:55:56,271 INFO:     Val loss before train {'Reaction outcome loss': 1.0164479681036689, 'Total loss': 1.0164479681036689}
2022-11-28 03:55:56,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:56,271 INFO:     Epoch: 0
2022-11-28 03:55:56,928 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6165923195129092, 'Total loss': 0.6165923195129092} | train loss {'Reaction outcome loss': 0.6769876587487426, 'Total loss': 0.6769876587487426}
2022-11-28 03:55:56,928 INFO:     Found new best model at epoch 0
2022-11-28 03:55:56,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:56,929 INFO:     Epoch: 1
2022-11-28 03:55:57,587 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5913064256310463, 'Total loss': 0.5913064256310463} | train loss {'Reaction outcome loss': 0.5822364116004604, 'Total loss': 0.5822364116004604}
2022-11-28 03:55:57,587 INFO:     Found new best model at epoch 1
2022-11-28 03:55:57,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:57,588 INFO:     Epoch: 2
2022-11-28 03:55:58,246 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5823556821454655, 'Total loss': 0.5823556821454655} | train loss {'Reaction outcome loss': 0.547774407130323, 'Total loss': 0.547774407130323}
2022-11-28 03:55:58,247 INFO:     Found new best model at epoch 2
2022-11-28 03:55:58,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:58,248 INFO:     Epoch: 3
2022-11-28 03:55:58,906 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5735095969655297, 'Total loss': 0.5735095969655297} | train loss {'Reaction outcome loss': 0.5343007440509101, 'Total loss': 0.5343007440509101}
2022-11-28 03:55:58,906 INFO:     Found new best model at epoch 3
2022-11-28 03:55:58,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:58,907 INFO:     Epoch: 4
2022-11-28 03:55:59,563 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5531728027219122, 'Total loss': 0.5531728027219122} | train loss {'Reaction outcome loss': 0.5157090261397574, 'Total loss': 0.5157090261397574}
2022-11-28 03:55:59,563 INFO:     Found new best model at epoch 4
2022-11-28 03:55:59,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:55:59,564 INFO:     Epoch: 5
2022-11-28 03:56:00,224 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5173591073941101, 'Total loss': 0.5173591073941101} | train loss {'Reaction outcome loss': 0.500232854775089, 'Total loss': 0.500232854775089}
2022-11-28 03:56:00,224 INFO:     Found new best model at epoch 5
2022-11-28 03:56:00,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:00,225 INFO:     Epoch: 6
2022-11-28 03:56:00,882 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5098936810073528, 'Total loss': 0.5098936810073528} | train loss {'Reaction outcome loss': 0.49963388800138403, 'Total loss': 0.49963388800138403}
2022-11-28 03:56:00,882 INFO:     Found new best model at epoch 6
2022-11-28 03:56:00,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:00,883 INFO:     Epoch: 7
2022-11-28 03:56:01,538 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5428743985566226, 'Total loss': 0.5428743985566226} | train loss {'Reaction outcome loss': 0.5000962560114107, 'Total loss': 0.5000962560114107}
2022-11-28 03:56:01,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:01,538 INFO:     Epoch: 8
2022-11-28 03:56:02,191 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.548757230354981, 'Total loss': 0.548757230354981} | train loss {'Reaction outcome loss': 0.49695154418226195, 'Total loss': 0.49695154418226195}
2022-11-28 03:56:02,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:02,191 INFO:     Epoch: 9
2022-11-28 03:56:02,845 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49953521889719094, 'Total loss': 0.49953521889719094} | train loss {'Reaction outcome loss': 0.4956465841606561, 'Total loss': 0.4956465841606561}
2022-11-28 03:56:02,845 INFO:     Found new best model at epoch 9
2022-11-28 03:56:02,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:02,846 INFO:     Epoch: 10
2022-11-28 03:56:03,500 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5412881137295202, 'Total loss': 0.5412881137295202} | train loss {'Reaction outcome loss': 0.4918645041191626, 'Total loss': 0.4918645041191626}
2022-11-28 03:56:03,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:03,500 INFO:     Epoch: 11
2022-11-28 03:56:04,157 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.56437751989473, 'Total loss': 0.56437751989473} | train loss {'Reaction outcome loss': 0.4814553055686024, 'Total loss': 0.4814553055686024}
2022-11-28 03:56:04,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:04,157 INFO:     Epoch: 12
2022-11-28 03:56:04,814 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49895631217143754, 'Total loss': 0.49895631217143754} | train loss {'Reaction outcome loss': 0.47286992281796, 'Total loss': 0.47286992281796}
2022-11-28 03:56:04,815 INFO:     Found new best model at epoch 12
2022-11-28 03:56:04,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:04,816 INFO:     Epoch: 13
2022-11-28 03:56:05,473 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5661806857044046, 'Total loss': 0.5661806857044046} | train loss {'Reaction outcome loss': 0.4627649652948867, 'Total loss': 0.4627649652948867}
2022-11-28 03:56:05,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:05,474 INFO:     Epoch: 14
2022-11-28 03:56:06,128 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5084055103361607, 'Total loss': 0.5084055103361607} | train loss {'Reaction outcome loss': 0.47366613643583255, 'Total loss': 0.47366613643583255}
2022-11-28 03:56:06,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:06,128 INFO:     Epoch: 15
2022-11-28 03:56:06,781 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5088598816232248, 'Total loss': 0.5088598816232248} | train loss {'Reaction outcome loss': 0.46991947781943116, 'Total loss': 0.46991947781943116}
2022-11-28 03:56:06,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:06,781 INFO:     Epoch: 16
2022-11-28 03:56:07,433 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5069662816822529, 'Total loss': 0.5069662816822529} | train loss {'Reaction outcome loss': 0.4817159234391533, 'Total loss': 0.4817159234391533}
2022-11-28 03:56:07,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:07,434 INFO:     Epoch: 17
2022-11-28 03:56:08,085 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5470939901742068, 'Total loss': 0.5470939901742068} | train loss {'Reaction outcome loss': 0.4711788460793283, 'Total loss': 0.4711788460793283}
2022-11-28 03:56:08,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:08,085 INFO:     Epoch: 18
2022-11-28 03:56:08,740 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5253169597549872, 'Total loss': 0.5253169597549872} | train loss {'Reaction outcome loss': 0.47309217550735244, 'Total loss': 0.47309217550735244}
2022-11-28 03:56:08,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:08,740 INFO:     Epoch: 19
2022-11-28 03:56:09,395 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48727811872959137, 'Total loss': 0.48727811872959137} | train loss {'Reaction outcome loss': 0.46942829619244736, 'Total loss': 0.46942829619244736}
2022-11-28 03:56:09,395 INFO:     Found new best model at epoch 19
2022-11-28 03:56:09,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:09,396 INFO:     Epoch: 20
2022-11-28 03:56:10,049 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5039673532274637, 'Total loss': 0.5039673532274637} | train loss {'Reaction outcome loss': 0.4627142270314338, 'Total loss': 0.4627142270314338}
2022-11-28 03:56:10,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:10,049 INFO:     Epoch: 21
2022-11-28 03:56:10,704 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5121174744245681, 'Total loss': 0.5121174744245681} | train loss {'Reaction outcome loss': 0.46344145348197535, 'Total loss': 0.46344145348197535}
2022-11-28 03:56:10,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:10,704 INFO:     Epoch: 22
2022-11-28 03:56:11,358 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5121753439307213, 'Total loss': 0.5121753439307213} | train loss {'Reaction outcome loss': 0.46010871291696, 'Total loss': 0.46010871291696}
2022-11-28 03:56:11,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:11,359 INFO:     Epoch: 23
2022-11-28 03:56:12,012 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49141246927055443, 'Total loss': 0.49141246927055443} | train loss {'Reaction outcome loss': 0.46247593378308816, 'Total loss': 0.46247593378308816}
2022-11-28 03:56:12,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:12,012 INFO:     Epoch: 24
2022-11-28 03:56:12,670 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5438995635644956, 'Total loss': 0.5438995635644956} | train loss {'Reaction outcome loss': 0.4686704640868704, 'Total loss': 0.4686704640868704}
2022-11-28 03:56:12,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:12,670 INFO:     Epoch: 25
2022-11-28 03:56:13,325 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5086713277480819, 'Total loss': 0.5086713277480819} | train loss {'Reaction outcome loss': 0.47580956272509417, 'Total loss': 0.47580956272509417}
2022-11-28 03:56:13,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:13,325 INFO:     Epoch: 26
2022-11-28 03:56:13,984 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5132600177418102, 'Total loss': 0.5132600177418102} | train loss {'Reaction outcome loss': 0.47113102511597066, 'Total loss': 0.47113102511597066}
2022-11-28 03:56:13,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:13,985 INFO:     Epoch: 27
2022-11-28 03:56:14,638 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4852120259946043, 'Total loss': 0.4852120259946043} | train loss {'Reaction outcome loss': 0.48087451465216724, 'Total loss': 0.48087451465216724}
2022-11-28 03:56:14,638 INFO:     Found new best model at epoch 27
2022-11-28 03:56:14,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:14,639 INFO:     Epoch: 28
2022-11-28 03:56:15,295 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4916111599992622, 'Total loss': 0.4916111599992622} | train loss {'Reaction outcome loss': 0.46061401455267237, 'Total loss': 0.46061401455267237}
2022-11-28 03:56:15,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:15,295 INFO:     Epoch: 29
2022-11-28 03:56:15,949 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48516458543864166, 'Total loss': 0.48516458543864166} | train loss {'Reaction outcome loss': 0.4710445635714512, 'Total loss': 0.4710445635714512}
2022-11-28 03:56:15,950 INFO:     Found new best model at epoch 29
2022-11-28 03:56:15,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:15,950 INFO:     Epoch: 30
2022-11-28 03:56:16,606 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47172786126082594, 'Total loss': 0.47172786126082594} | train loss {'Reaction outcome loss': 0.46262749426278027, 'Total loss': 0.46262749426278027}
2022-11-28 03:56:16,606 INFO:     Found new best model at epoch 30
2022-11-28 03:56:16,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:16,607 INFO:     Epoch: 31
2022-11-28 03:56:17,259 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49305046620694076, 'Total loss': 0.49305046620694076} | train loss {'Reaction outcome loss': 0.4566540751862622, 'Total loss': 0.4566540751862622}
2022-11-28 03:56:17,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:17,260 INFO:     Epoch: 32
2022-11-28 03:56:17,916 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49927706203677436, 'Total loss': 0.49927706203677436} | train loss {'Reaction outcome loss': 0.459729802074582, 'Total loss': 0.459729802074582}
2022-11-28 03:56:17,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:17,917 INFO:     Epoch: 33
2022-11-28 03:56:18,571 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.519220035861839, 'Total loss': 0.519220035861839} | train loss {'Reaction outcome loss': 0.4564111618860531, 'Total loss': 0.4564111618860531}
2022-11-28 03:56:18,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:18,572 INFO:     Epoch: 34
2022-11-28 03:56:19,227 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48510520227930765, 'Total loss': 0.48510520227930765} | train loss {'Reaction outcome loss': 0.46012240805123983, 'Total loss': 0.46012240805123983}
2022-11-28 03:56:19,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:19,227 INFO:     Epoch: 35
2022-11-28 03:56:19,883 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49577429992231453, 'Total loss': 0.49577429992231453} | train loss {'Reaction outcome loss': 0.45648493506165166, 'Total loss': 0.45648493506165166}
2022-11-28 03:56:19,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:19,884 INFO:     Epoch: 36
2022-11-28 03:56:20,542 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5265320891683752, 'Total loss': 0.5265320891683752} | train loss {'Reaction outcome loss': 0.4650103534884781, 'Total loss': 0.4650103534884781}
2022-11-28 03:56:20,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:20,542 INFO:     Epoch: 37
2022-11-28 03:56:21,199 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.492572431537238, 'Total loss': 0.492572431537238} | train loss {'Reaction outcome loss': 0.4574802809438257, 'Total loss': 0.4574802809438257}
2022-11-28 03:56:21,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:21,199 INFO:     Epoch: 38
2022-11-28 03:56:21,856 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48370159620588477, 'Total loss': 0.48370159620588477} | train loss {'Reaction outcome loss': 0.4585386989600504, 'Total loss': 0.4585386989600504}
2022-11-28 03:56:21,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:21,856 INFO:     Epoch: 39
2022-11-28 03:56:22,515 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.540781439028003, 'Total loss': 0.540781439028003} | train loss {'Reaction outcome loss': 0.46328884282296423, 'Total loss': 0.46328884282296423}
2022-11-28 03:56:22,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:22,515 INFO:     Epoch: 40
2022-11-28 03:56:23,171 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.514881663701751, 'Total loss': 0.514881663701751} | train loss {'Reaction outcome loss': 0.46598853207068885, 'Total loss': 0.46598853207068885}
2022-11-28 03:56:23,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:23,171 INFO:     Epoch: 41
2022-11-28 03:56:23,825 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5095357336103916, 'Total loss': 0.5095357336103916} | train loss {'Reaction outcome loss': 0.46407592133713155, 'Total loss': 0.46407592133713155}
2022-11-28 03:56:23,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:23,825 INFO:     Epoch: 42
2022-11-28 03:56:24,481 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49777859584851697, 'Total loss': 0.49777859584851697} | train loss {'Reaction outcome loss': 0.4684846681139247, 'Total loss': 0.4684846681139247}
2022-11-28 03:56:24,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:24,482 INFO:     Epoch: 43
2022-11-28 03:56:25,136 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4962583687156439, 'Total loss': 0.4962583687156439} | train loss {'Reaction outcome loss': 0.4665721129429968, 'Total loss': 0.4665721129429968}
2022-11-28 03:56:25,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:25,136 INFO:     Epoch: 44
2022-11-28 03:56:25,794 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5052163296125152, 'Total loss': 0.5052163296125152} | train loss {'Reaction outcome loss': 0.45606914762905254, 'Total loss': 0.45606914762905254}
2022-11-28 03:56:25,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:25,794 INFO:     Epoch: 45
2022-11-28 03:56:26,450 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5084870007227767, 'Total loss': 0.5084870007227767} | train loss {'Reaction outcome loss': 0.4579314997924967, 'Total loss': 0.4579314997924967}
2022-11-28 03:56:26,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:26,450 INFO:     Epoch: 46
2022-11-28 03:56:27,106 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48641744323752145, 'Total loss': 0.48641744323752145} | train loss {'Reaction outcome loss': 0.45776833105183806, 'Total loss': 0.45776833105183806}
2022-11-28 03:56:27,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:27,106 INFO:     Epoch: 47
2022-11-28 03:56:27,763 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5046335167505525, 'Total loss': 0.5046335167505525} | train loss {'Reaction outcome loss': 0.4581148498955556, 'Total loss': 0.4581148498955556}
2022-11-28 03:56:27,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:27,764 INFO:     Epoch: 48
2022-11-28 03:56:28,420 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5223183905367147, 'Total loss': 0.5223183905367147} | train loss {'Reaction outcome loss': 0.45892349675840693, 'Total loss': 0.45892349675840693}
2022-11-28 03:56:28,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:28,420 INFO:     Epoch: 49
2022-11-28 03:56:29,076 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5069537142460997, 'Total loss': 0.5069537142460997} | train loss {'Reaction outcome loss': 0.46427737228545973, 'Total loss': 0.46427737228545973}
2022-11-28 03:56:29,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:29,077 INFO:     Epoch: 50
2022-11-28 03:56:29,729 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5083128613504496, 'Total loss': 0.5083128613504496} | train loss {'Reaction outcome loss': 0.4641700131811111, 'Total loss': 0.4641700131811111}
2022-11-28 03:56:29,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:29,729 INFO:     Epoch: 51
2022-11-28 03:56:30,382 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5153997106985613, 'Total loss': 0.5153997106985613} | train loss {'Reaction outcome loss': 0.46041210096231416, 'Total loss': 0.46041210096231416}
2022-11-28 03:56:30,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:30,383 INFO:     Epoch: 52
2022-11-28 03:56:31,039 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5124015113846823, 'Total loss': 0.5124015113846823} | train loss {'Reaction outcome loss': 0.45999718397131817, 'Total loss': 0.45999718397131817}
2022-11-28 03:56:31,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:31,039 INFO:     Epoch: 53
2022-11-28 03:56:31,695 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5031088390810923, 'Total loss': 0.5031088390810923} | train loss {'Reaction outcome loss': 0.4528177799845514, 'Total loss': 0.4528177799845514}
2022-11-28 03:56:31,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:31,695 INFO:     Epoch: 54
2022-11-28 03:56:32,348 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4778934988108548, 'Total loss': 0.4778934988108548} | train loss {'Reaction outcome loss': 0.4719260706894311, 'Total loss': 0.4719260706894311}
2022-11-28 03:56:32,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:32,348 INFO:     Epoch: 55
2022-11-28 03:56:33,004 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49332148784940894, 'Total loss': 0.49332148784940894} | train loss {'Reaction outcome loss': 0.4611902134455288, 'Total loss': 0.4611902134455288}
2022-11-28 03:56:33,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:33,004 INFO:     Epoch: 56
2022-11-28 03:56:33,660 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4880895421586253, 'Total loss': 0.4880895421586253} | train loss {'Reaction outcome loss': 0.4653466550806756, 'Total loss': 0.4653466550806756}
2022-11-28 03:56:33,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:33,660 INFO:     Epoch: 57
2022-11-28 03:56:34,313 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5386706671931527, 'Total loss': 0.5386706671931527} | train loss {'Reaction outcome loss': 0.4670922304032303, 'Total loss': 0.4670922304032303}
2022-11-28 03:56:34,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:34,314 INFO:     Epoch: 58
2022-11-28 03:56:34,971 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4961873469027606, 'Total loss': 0.4961873469027606} | train loss {'Reaction outcome loss': 0.4580522326013518, 'Total loss': 0.4580522326013518}
2022-11-28 03:56:34,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:34,971 INFO:     Epoch: 59
2022-11-28 03:56:35,627 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49671701612797653, 'Total loss': 0.49671701612797653} | train loss {'Reaction outcome loss': 0.4646812964245858, 'Total loss': 0.4646812964245858}
2022-11-28 03:56:35,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:35,628 INFO:     Epoch: 60
2022-11-28 03:56:36,281 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.524690025232055, 'Total loss': 0.524690025232055} | train loss {'Reaction outcome loss': 0.4628234926746924, 'Total loss': 0.4628234926746924}
2022-11-28 03:56:36,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:36,281 INFO:     Epoch: 61
2022-11-28 03:56:36,935 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5788282643664967, 'Total loss': 0.5788282643664967} | train loss {'Reaction outcome loss': 0.4676628146275335, 'Total loss': 0.4676628146275335}
2022-11-28 03:56:36,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:36,935 INFO:     Epoch: 62
2022-11-28 03:56:37,594 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5435313833030787, 'Total loss': 0.5435313833030787} | train loss {'Reaction outcome loss': 0.46005641804774283, 'Total loss': 0.46005641804774283}
2022-11-28 03:56:37,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:37,594 INFO:     Epoch: 63
2022-11-28 03:56:38,252 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4973250851035118, 'Total loss': 0.4973250851035118} | train loss {'Reaction outcome loss': 0.4627695669408752, 'Total loss': 0.4627695669408752}
2022-11-28 03:56:38,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:38,252 INFO:     Epoch: 64
2022-11-28 03:56:38,911 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5552585531364788, 'Total loss': 0.5552585531364788} | train loss {'Reaction outcome loss': 0.4599809312386069, 'Total loss': 0.4599809312386069}
2022-11-28 03:56:38,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:38,911 INFO:     Epoch: 65
2022-11-28 03:56:39,566 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5278620912947438, 'Total loss': 0.5278620912947438} | train loss {'Reaction outcome loss': 0.4670724555065757, 'Total loss': 0.4670724555065757}
2022-11-28 03:56:39,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:39,566 INFO:     Epoch: 66
2022-11-28 03:56:40,223 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.496613548560576, 'Total loss': 0.496613548560576} | train loss {'Reaction outcome loss': 0.4721562368305106, 'Total loss': 0.4721562368305106}
2022-11-28 03:56:40,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:40,224 INFO:     Epoch: 67
2022-11-28 03:56:40,881 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49222368746995926, 'Total loss': 0.49222368746995926} | train loss {'Reaction outcome loss': 0.473023166721649, 'Total loss': 0.473023166721649}
2022-11-28 03:56:40,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:40,881 INFO:     Epoch: 68
2022-11-28 03:56:41,535 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5777682753449137, 'Total loss': 0.5777682753449137} | train loss {'Reaction outcome loss': 0.4745239068976479, 'Total loss': 0.4745239068976479}
2022-11-28 03:56:41,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:41,536 INFO:     Epoch: 69
2022-11-28 03:56:42,188 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5033732104030523, 'Total loss': 0.5033732104030523} | train loss {'Reaction outcome loss': 0.46193733539899834, 'Total loss': 0.46193733539899834}
2022-11-28 03:56:42,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:42,188 INFO:     Epoch: 70
2022-11-28 03:56:42,839 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4910646961493926, 'Total loss': 0.4910646961493926} | train loss {'Reaction outcome loss': 0.4711360637596262, 'Total loss': 0.4711360637596262}
2022-11-28 03:56:42,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:42,840 INFO:     Epoch: 71
2022-11-28 03:56:43,494 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5139996748078953, 'Total loss': 0.5139996748078953} | train loss {'Reaction outcome loss': 0.46424997999117923, 'Total loss': 0.46424997999117923}
2022-11-28 03:56:43,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:43,494 INFO:     Epoch: 72
2022-11-28 03:56:44,149 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5175784914331003, 'Total loss': 0.5175784914331003} | train loss {'Reaction outcome loss': 0.4558489181795101, 'Total loss': 0.4558489181795101}
2022-11-28 03:56:44,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:44,150 INFO:     Epoch: 73
2022-11-28 03:56:44,806 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49375082992694597, 'Total loss': 0.49375082992694597} | train loss {'Reaction outcome loss': 0.4598436282593229, 'Total loss': 0.4598436282593229}
2022-11-28 03:56:44,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:44,806 INFO:     Epoch: 74
2022-11-28 03:56:45,464 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5046638883650303, 'Total loss': 0.5046638883650303} | train loss {'Reaction outcome loss': 0.45450142176769043, 'Total loss': 0.45450142176769043}
2022-11-28 03:56:45,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:45,464 INFO:     Epoch: 75
2022-11-28 03:56:46,121 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.505509417842735, 'Total loss': 0.505509417842735} | train loss {'Reaction outcome loss': 0.4596280309594112, 'Total loss': 0.4596280309594112}
2022-11-28 03:56:46,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:46,121 INFO:     Epoch: 76
2022-11-28 03:56:46,779 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.50433660434051, 'Total loss': 0.50433660434051} | train loss {'Reaction outcome loss': 0.46210810221611004, 'Total loss': 0.46210810221611004}
2022-11-28 03:56:46,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:46,779 INFO:     Epoch: 77
2022-11-28 03:56:47,435 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5062549845738844, 'Total loss': 0.5062549845738844} | train loss {'Reaction outcome loss': 0.45697051594373184, 'Total loss': 0.45697051594373184}
2022-11-28 03:56:47,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:47,436 INFO:     Epoch: 78
2022-11-28 03:56:48,086 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4858998012813655, 'Total loss': 0.4858998012813655} | train loss {'Reaction outcome loss': 0.46471445817455104, 'Total loss': 0.46471445817455104}
2022-11-28 03:56:48,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:48,087 INFO:     Epoch: 79
2022-11-28 03:56:48,739 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49114435945044865, 'Total loss': 0.49114435945044865} | train loss {'Reaction outcome loss': 0.45579529721817746, 'Total loss': 0.45579529721817746}
2022-11-28 03:56:48,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:48,740 INFO:     Epoch: 80
2022-11-28 03:56:49,398 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4983099065721035, 'Total loss': 0.4983099065721035} | train loss {'Reaction outcome loss': 0.4556293669691675, 'Total loss': 0.4556293669691675}
2022-11-28 03:56:49,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:49,398 INFO:     Epoch: 81
2022-11-28 03:56:50,055 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5130775242366574, 'Total loss': 0.5130775242366574} | train loss {'Reaction outcome loss': 0.45744755646960455, 'Total loss': 0.45744755646960455}
2022-11-28 03:56:50,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:50,055 INFO:     Epoch: 82
2022-11-28 03:56:50,707 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5173940306360071, 'Total loss': 0.5173940306360071} | train loss {'Reaction outcome loss': 0.47234269825794434, 'Total loss': 0.47234269825794434}
2022-11-28 03:56:50,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:50,707 INFO:     Epoch: 83
2022-11-28 03:56:51,362 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4907979667186737, 'Total loss': 0.4907979667186737} | train loss {'Reaction outcome loss': 0.4906987179870065, 'Total loss': 0.4906987179870065}
2022-11-28 03:56:51,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:51,363 INFO:     Epoch: 84
2022-11-28 03:56:52,018 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4854910841042345, 'Total loss': 0.4854910841042345} | train loss {'Reaction outcome loss': 0.46747836586736474, 'Total loss': 0.46747836586736474}
2022-11-28 03:56:52,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:52,018 INFO:     Epoch: 85
2022-11-28 03:56:52,675 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47987079925157805, 'Total loss': 0.47987079925157805} | train loss {'Reaction outcome loss': 0.46494779025198824, 'Total loss': 0.46494779025198824}
2022-11-28 03:56:52,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:52,676 INFO:     Epoch: 86
2022-11-28 03:56:53,329 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5406750108708035, 'Total loss': 0.5406750108708035} | train loss {'Reaction outcome loss': 0.4605413951009874, 'Total loss': 0.4605413951009874}
2022-11-28 03:56:53,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:53,329 INFO:     Epoch: 87
2022-11-28 03:56:53,984 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48932058668949385, 'Total loss': 0.48932058668949385} | train loss {'Reaction outcome loss': 0.45861160479154184, 'Total loss': 0.45861160479154184}
2022-11-28 03:56:53,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:53,984 INFO:     Epoch: 88
2022-11-28 03:56:54,639 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5134213458408009, 'Total loss': 0.5134213458408009} | train loss {'Reaction outcome loss': 0.45642133026576115, 'Total loss': 0.45642133026576115}
2022-11-28 03:56:54,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:54,640 INFO:     Epoch: 89
2022-11-28 03:56:55,292 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5198457478122278, 'Total loss': 0.5198457478122278} | train loss {'Reaction outcome loss': 0.45944625742522327, 'Total loss': 0.45944625742522327}
2022-11-28 03:56:55,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:55,292 INFO:     Epoch: 90
2022-11-28 03:56:55,942 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5298426273194227, 'Total loss': 0.5298426273194227} | train loss {'Reaction outcome loss': 0.46459495840284987, 'Total loss': 0.46459495840284987}
2022-11-28 03:56:55,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:55,942 INFO:     Epoch: 91
2022-11-28 03:56:56,600 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5352189937098459, 'Total loss': 0.5352189937098459} | train loss {'Reaction outcome loss': 0.45388417754337373, 'Total loss': 0.45388417754337373}
2022-11-28 03:56:56,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:56,600 INFO:     Epoch: 92
2022-11-28 03:56:57,259 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5118984102525495, 'Total loss': 0.5118984102525495} | train loss {'Reaction outcome loss': 0.46322209626315575, 'Total loss': 0.46322209626315575}
2022-11-28 03:56:57,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:57,259 INFO:     Epoch: 93
2022-11-28 03:56:57,912 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5323158238421787, 'Total loss': 0.5323158238421787} | train loss {'Reaction outcome loss': 0.4872357021010507, 'Total loss': 0.4872357021010507}
2022-11-28 03:56:57,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:57,913 INFO:     Epoch: 94
2022-11-28 03:56:58,569 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.508473835546862, 'Total loss': 0.508473835546862} | train loss {'Reaction outcome loss': 0.4581830211375889, 'Total loss': 0.4581830211375889}
2022-11-28 03:56:58,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:58,569 INFO:     Epoch: 95
2022-11-28 03:56:59,222 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5039974955672567, 'Total loss': 0.5039974955672567} | train loss {'Reaction outcome loss': 0.4724351623762957, 'Total loss': 0.4724351623762957}
2022-11-28 03:56:59,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:59,222 INFO:     Epoch: 96
2022-11-28 03:56:59,877 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4970263655890118, 'Total loss': 0.4970263655890118} | train loss {'Reaction outcome loss': 0.469163738522935, 'Total loss': 0.469163738522935}
2022-11-28 03:56:59,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:56:59,877 INFO:     Epoch: 97
2022-11-28 03:57:00,531 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4790431647138162, 'Total loss': 0.4790431647138162} | train loss {'Reaction outcome loss': 0.48611870269302415, 'Total loss': 0.48611870269302415}
2022-11-28 03:57:00,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:00,532 INFO:     Epoch: 98
2022-11-28 03:57:01,185 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5271379954435609, 'Total loss': 0.5271379954435609} | train loss {'Reaction outcome loss': 0.46753441273924795, 'Total loss': 0.46753441273924795}
2022-11-28 03:57:01,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:01,186 INFO:     Epoch: 99
2022-11-28 03:57:01,843 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49315902360037644, 'Total loss': 0.49315902360037644} | train loss {'Reaction outcome loss': 0.4605358402859344, 'Total loss': 0.4605358402859344}
2022-11-28 03:57:01,843 INFO:     Best model found after epoch 31 of 100.
2022-11-28 03:57:01,843 INFO:   Done with stage: TRAINING
2022-11-28 03:57:01,843 INFO:   Starting stage: EVALUATION
2022-11-28 03:57:01,962 INFO:   Done with stage: EVALUATION
2022-11-28 03:57:01,962 INFO:   Leaving out SEQ value Fold_8
2022-11-28 03:57:01,975 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:57:01,975 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:57:02,678 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:57:02,678 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:57:02,744 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:57:02,744 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:57:02,744 INFO:     No hyperparam tuning for this model
2022-11-28 03:57:02,744 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:57:02,745 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:57:02,745 INFO:     None feature selector for col prot
2022-11-28 03:57:02,745 INFO:     None feature selector for col prot
2022-11-28 03:57:02,745 INFO:     None feature selector for col prot
2022-11-28 03:57:02,746 INFO:     None feature selector for col chem
2022-11-28 03:57:02,746 INFO:     None feature selector for col chem
2022-11-28 03:57:02,746 INFO:     None feature selector for col chem
2022-11-28 03:57:02,746 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:57:02,746 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:57:02,748 INFO:     Number of params in model 169651
2022-11-28 03:57:02,751 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:57:02,751 INFO:   Starting stage: TRAINING
2022-11-28 03:57:02,801 INFO:     Val loss before train {'Reaction outcome loss': 0.9886044101281599, 'Total loss': 0.9886044101281599}
2022-11-28 03:57:02,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:02,801 INFO:     Epoch: 0
2022-11-28 03:57:03,457 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6202710575678132, 'Total loss': 0.6202710575678132} | train loss {'Reaction outcome loss': 0.7054552785780749, 'Total loss': 0.7054552785780749}
2022-11-28 03:57:03,457 INFO:     Found new best model at epoch 0
2022-11-28 03:57:03,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:03,458 INFO:     Epoch: 1
2022-11-28 03:57:04,115 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5517185442149639, 'Total loss': 0.5517185442149639} | train loss {'Reaction outcome loss': 0.5964912833713809, 'Total loss': 0.5964912833713809}
2022-11-28 03:57:04,115 INFO:     Found new best model at epoch 1
2022-11-28 03:57:04,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:04,116 INFO:     Epoch: 2
2022-11-28 03:57:04,774 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6525490615855564, 'Total loss': 0.6525490615855564} | train loss {'Reaction outcome loss': 0.5599963020699227, 'Total loss': 0.5599963020699227}
2022-11-28 03:57:04,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:04,774 INFO:     Epoch: 3
2022-11-28 03:57:05,429 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5076129199428991, 'Total loss': 0.5076129199428991} | train loss {'Reaction outcome loss': 0.5453878577180237, 'Total loss': 0.5453878577180237}
2022-11-28 03:57:05,429 INFO:     Found new best model at epoch 3
2022-11-28 03:57:05,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:05,430 INFO:     Epoch: 4
2022-11-28 03:57:06,084 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.561011942950162, 'Total loss': 0.561011942950162} | train loss {'Reaction outcome loss': 0.520448866884718, 'Total loss': 0.520448866884718}
2022-11-28 03:57:06,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:06,085 INFO:     Epoch: 5
2022-11-28 03:57:06,739 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5205309194597331, 'Total loss': 0.5205309194597331} | train loss {'Reaction outcome loss': 0.5205232383992507, 'Total loss': 0.5205232383992507}
2022-11-28 03:57:06,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:06,740 INFO:     Epoch: 6
2022-11-28 03:57:07,396 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5534989481622522, 'Total loss': 0.5534989481622522} | train loss {'Reaction outcome loss': 0.5197079096004548, 'Total loss': 0.5197079096004548}
2022-11-28 03:57:07,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:07,396 INFO:     Epoch: 7
2022-11-28 03:57:08,050 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49870108609849756, 'Total loss': 0.49870108609849756} | train loss {'Reaction outcome loss': 0.5168052056902334, 'Total loss': 0.5168052056902334}
2022-11-28 03:57:08,050 INFO:     Found new best model at epoch 7
2022-11-28 03:57:08,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:08,051 INFO:     Epoch: 8
2022-11-28 03:57:08,708 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5160591663284735, 'Total loss': 0.5160591663284735} | train loss {'Reaction outcome loss': 0.5177510901983933, 'Total loss': 0.5177510901983933}
2022-11-28 03:57:08,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:08,709 INFO:     Epoch: 9
2022-11-28 03:57:09,364 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5087232941930945, 'Total loss': 0.5087232941930945} | train loss {'Reaction outcome loss': 0.5011057866971019, 'Total loss': 0.5011057866971019}
2022-11-28 03:57:09,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:09,364 INFO:     Epoch: 10
2022-11-28 03:57:10,021 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5044234523719008, 'Total loss': 0.5044234523719008} | train loss {'Reaction outcome loss': 0.5020719296657122, 'Total loss': 0.5020719296657122}
2022-11-28 03:57:10,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:10,022 INFO:     Epoch: 11
2022-11-28 03:57:10,676 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4987610097635876, 'Total loss': 0.4987610097635876} | train loss {'Reaction outcome loss': 0.49144128069040266, 'Total loss': 0.49144128069040266}
2022-11-28 03:57:10,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:10,676 INFO:     Epoch: 12
2022-11-28 03:57:11,333 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5218798951669172, 'Total loss': 0.5218798951669172} | train loss {'Reaction outcome loss': 0.49568129297692765, 'Total loss': 0.49568129297692765}
2022-11-28 03:57:11,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:11,333 INFO:     Epoch: 13
2022-11-28 03:57:11,988 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.6061712835322727, 'Total loss': 0.6061712835322727} | train loss {'Reaction outcome loss': 0.5103624579515534, 'Total loss': 0.5103624579515534}
2022-11-28 03:57:11,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:11,988 INFO:     Epoch: 14
2022-11-28 03:57:12,641 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49202924221754074, 'Total loss': 0.49202924221754074} | train loss {'Reaction outcome loss': 0.5157596019477497, 'Total loss': 0.5157596019477497}
2022-11-28 03:57:12,641 INFO:     Found new best model at epoch 14
2022-11-28 03:57:12,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:12,642 INFO:     Epoch: 15
2022-11-28 03:57:13,296 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.532641260122711, 'Total loss': 0.532641260122711} | train loss {'Reaction outcome loss': 0.48822660309824384, 'Total loss': 0.48822660309824384}
2022-11-28 03:57:13,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:13,296 INFO:     Epoch: 16
2022-11-28 03:57:13,949 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5165023468434811, 'Total loss': 0.5165023468434811} | train loss {'Reaction outcome loss': 0.4977586930165226, 'Total loss': 0.4977586930165226}
2022-11-28 03:57:13,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:13,950 INFO:     Epoch: 17
2022-11-28 03:57:14,604 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5143042569133368, 'Total loss': 0.5143042569133368} | train loss {'Reaction outcome loss': 0.48115125597315095, 'Total loss': 0.48115125597315095}
2022-11-28 03:57:14,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:14,604 INFO:     Epoch: 18
2022-11-28 03:57:15,256 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5091269331222231, 'Total loss': 0.5091269331222231} | train loss {'Reaction outcome loss': 0.4722698061069029, 'Total loss': 0.4722698061069029}
2022-11-28 03:57:15,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:15,257 INFO:     Epoch: 19
2022-11-28 03:57:15,912 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4910586632110856, 'Total loss': 0.4910586632110856} | train loss {'Reaction outcome loss': 0.4851565025294358, 'Total loss': 0.4851565025294358}
2022-11-28 03:57:15,912 INFO:     Found new best model at epoch 19
2022-11-28 03:57:15,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:15,913 INFO:     Epoch: 20
2022-11-28 03:57:16,566 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4785131317648021, 'Total loss': 0.4785131317648021} | train loss {'Reaction outcome loss': 0.487424485596568, 'Total loss': 0.487424485596568}
2022-11-28 03:57:16,566 INFO:     Found new best model at epoch 20
2022-11-28 03:57:16,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:16,567 INFO:     Epoch: 21
2022-11-28 03:57:17,220 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5175437791780992, 'Total loss': 0.5175437791780992} | train loss {'Reaction outcome loss': 0.487510008548918, 'Total loss': 0.487510008548918}
2022-11-28 03:57:17,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:17,220 INFO:     Epoch: 22
2022-11-28 03:57:17,874 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49944214996966446, 'Total loss': 0.49944214996966446} | train loss {'Reaction outcome loss': 0.48619204243976877, 'Total loss': 0.48619204243976877}
2022-11-28 03:57:17,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:17,874 INFO:     Epoch: 23
2022-11-28 03:57:18,527 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4991409975019368, 'Total loss': 0.4991409975019368} | train loss {'Reaction outcome loss': 0.47814162612443994, 'Total loss': 0.47814162612443994}
2022-11-28 03:57:18,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:18,527 INFO:     Epoch: 24
2022-11-28 03:57:19,180 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5041503445668654, 'Total loss': 0.5041503445668654} | train loss {'Reaction outcome loss': 0.4823949162184679, 'Total loss': 0.4823949162184679}
2022-11-28 03:57:19,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:19,181 INFO:     Epoch: 25
2022-11-28 03:57:19,836 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5115035433660854, 'Total loss': 0.5115035433660854} | train loss {'Reaction outcome loss': 0.4794456061684651, 'Total loss': 0.4794456061684651}
2022-11-28 03:57:19,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:19,836 INFO:     Epoch: 26
2022-11-28 03:57:20,490 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47229462692683394, 'Total loss': 0.47229462692683394} | train loss {'Reaction outcome loss': 0.47465480558068945, 'Total loss': 0.47465480558068945}
2022-11-28 03:57:20,490 INFO:     Found new best model at epoch 26
2022-11-28 03:57:20,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:20,491 INFO:     Epoch: 27
2022-11-28 03:57:21,144 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5191022929820147, 'Total loss': 0.5191022929820147} | train loss {'Reaction outcome loss': 0.4869099536284744, 'Total loss': 0.4869099536284744}
2022-11-28 03:57:21,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:21,144 INFO:     Epoch: 28
2022-11-28 03:57:21,797 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.502784671431238, 'Total loss': 0.502784671431238} | train loss {'Reaction outcome loss': 0.4797902567998359, 'Total loss': 0.4797902567998359}
2022-11-28 03:57:21,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:21,797 INFO:     Epoch: 29
2022-11-28 03:57:22,452 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47634934464638884, 'Total loss': 0.47634934464638884} | train loss {'Reaction outcome loss': 0.4748751141417485, 'Total loss': 0.4748751141417485}
2022-11-28 03:57:22,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:22,452 INFO:     Epoch: 30
2022-11-28 03:57:23,107 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4705298488790339, 'Total loss': 0.4705298488790339} | train loss {'Reaction outcome loss': 0.47871516373476036, 'Total loss': 0.47871516373476036}
2022-11-28 03:57:23,107 INFO:     Found new best model at epoch 30
2022-11-28 03:57:23,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:23,108 INFO:     Epoch: 31
2022-11-28 03:57:23,766 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5298357175832445, 'Total loss': 0.5298357175832445} | train loss {'Reaction outcome loss': 0.4817203895946746, 'Total loss': 0.4817203895946746}
2022-11-28 03:57:23,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:23,767 INFO:     Epoch: 32
2022-11-28 03:57:24,419 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.510001520880244, 'Total loss': 0.510001520880244} | train loss {'Reaction outcome loss': 0.4804804224958304, 'Total loss': 0.4804804224958304}
2022-11-28 03:57:24,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:24,420 INFO:     Epoch: 33
2022-11-28 03:57:25,076 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5102460645139217, 'Total loss': 0.5102460645139217} | train loss {'Reaction outcome loss': 0.48126426290886604, 'Total loss': 0.48126426290886604}
2022-11-28 03:57:25,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:25,076 INFO:     Epoch: 34
2022-11-28 03:57:25,732 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49855479530312796, 'Total loss': 0.49855479530312796} | train loss {'Reaction outcome loss': 0.4778436071235641, 'Total loss': 0.4778436071235641}
2022-11-28 03:57:25,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:25,732 INFO:     Epoch: 35
2022-11-28 03:57:26,387 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5198323076421564, 'Total loss': 0.5198323076421564} | train loss {'Reaction outcome loss': 0.478191790757286, 'Total loss': 0.478191790757286}
2022-11-28 03:57:26,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:26,387 INFO:     Epoch: 36
2022-11-28 03:57:27,043 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5801995789462869, 'Total loss': 0.5801995789462869} | train loss {'Reaction outcome loss': 0.48803685490901655, 'Total loss': 0.48803685490901655}
2022-11-28 03:57:27,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:27,043 INFO:     Epoch: 37
2022-11-28 03:57:27,698 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49103940854018385, 'Total loss': 0.49103940854018385} | train loss {'Reaction outcome loss': 0.48636874254898504, 'Total loss': 0.48636874254898504}
2022-11-28 03:57:27,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:27,698 INFO:     Epoch: 38
2022-11-28 03:57:28,351 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5558665235611525, 'Total loss': 0.5558665235611525} | train loss {'Reaction outcome loss': 0.4689874075209865, 'Total loss': 0.4689874075209865}
2022-11-28 03:57:28,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:28,352 INFO:     Epoch: 39
2022-11-28 03:57:29,007 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5196677107702602, 'Total loss': 0.5196677107702602} | train loss {'Reaction outcome loss': 0.4745740084588407, 'Total loss': 0.4745740084588407}
2022-11-28 03:57:29,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:29,007 INFO:     Epoch: 40
2022-11-28 03:57:29,663 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49430692805485293, 'Total loss': 0.49430692805485293} | train loss {'Reaction outcome loss': 0.47188736196712927, 'Total loss': 0.47188736196712927}
2022-11-28 03:57:29,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:29,664 INFO:     Epoch: 41
2022-11-28 03:57:30,319 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49137748032808304, 'Total loss': 0.49137748032808304} | train loss {'Reaction outcome loss': 0.47675461737582314, 'Total loss': 0.47675461737582314}
2022-11-28 03:57:30,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:30,319 INFO:     Epoch: 42
2022-11-28 03:57:30,974 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4790615737438202, 'Total loss': 0.4790615737438202} | train loss {'Reaction outcome loss': 0.4769743865559458, 'Total loss': 0.4769743865559458}
2022-11-28 03:57:30,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:30,975 INFO:     Epoch: 43
2022-11-28 03:57:31,632 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4813653775914149, 'Total loss': 0.4813653775914149} | train loss {'Reaction outcome loss': 0.4751430069386718, 'Total loss': 0.4751430069386718}
2022-11-28 03:57:31,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:31,633 INFO:     Epoch: 44
2022-11-28 03:57:32,288 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48200812393968756, 'Total loss': 0.48200812393968756} | train loss {'Reaction outcome loss': 0.47659698382080323, 'Total loss': 0.47659698382080323}
2022-11-28 03:57:32,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:32,288 INFO:     Epoch: 45
2022-11-28 03:57:32,944 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4632763087072156, 'Total loss': 0.4632763087072156} | train loss {'Reaction outcome loss': 0.4719235609296845, 'Total loss': 0.4719235609296845}
2022-11-28 03:57:32,944 INFO:     Found new best model at epoch 45
2022-11-28 03:57:32,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:32,945 INFO:     Epoch: 46
2022-11-28 03:57:33,603 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4825822907415303, 'Total loss': 0.4825822907415303} | train loss {'Reaction outcome loss': 0.47801504576737097, 'Total loss': 0.47801504576737097}
2022-11-28 03:57:33,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:33,604 INFO:     Epoch: 47
2022-11-28 03:57:34,260 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5078960372643038, 'Total loss': 0.5078960372643038} | train loss {'Reaction outcome loss': 0.46115137709055837, 'Total loss': 0.46115137709055837}
2022-11-28 03:57:34,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:34,260 INFO:     Epoch: 48
2022-11-28 03:57:34,914 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48509015583179216, 'Total loss': 0.48509015583179216} | train loss {'Reaction outcome loss': 0.47130941313046676, 'Total loss': 0.47130941313046676}
2022-11-28 03:57:34,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:34,915 INFO:     Epoch: 49
2022-11-28 03:57:35,574 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4893024042248726, 'Total loss': 0.4893024042248726} | train loss {'Reaction outcome loss': 0.4697379057978088, 'Total loss': 0.4697379057978088}
2022-11-28 03:57:35,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:35,574 INFO:     Epoch: 50
2022-11-28 03:57:36,238 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47778399525718257, 'Total loss': 0.47778399525718257} | train loss {'Reaction outcome loss': 0.47833971365502004, 'Total loss': 0.47833971365502004}
2022-11-28 03:57:36,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:36,239 INFO:     Epoch: 51
2022-11-28 03:57:36,903 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47656181607056747, 'Total loss': 0.47656181607056747} | train loss {'Reaction outcome loss': 0.48152518212071316, 'Total loss': 0.48152518212071316}
2022-11-28 03:57:36,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:36,903 INFO:     Epoch: 52
2022-11-28 03:57:37,565 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4983557506718419, 'Total loss': 0.4983557506718419} | train loss {'Reaction outcome loss': 0.47127339477662133, 'Total loss': 0.47127339477662133}
2022-11-28 03:57:37,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:37,566 INFO:     Epoch: 53
2022-11-28 03:57:38,229 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47372910515828565, 'Total loss': 0.47372910515828565} | train loss {'Reaction outcome loss': 0.47916788834067975, 'Total loss': 0.47916788834067975}
2022-11-28 03:57:38,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:38,229 INFO:     Epoch: 54
2022-11-28 03:57:38,891 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5090675597841089, 'Total loss': 0.5090675597841089} | train loss {'Reaction outcome loss': 0.464914271811604, 'Total loss': 0.464914271811604}
2022-11-28 03:57:38,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:38,891 INFO:     Epoch: 55
2022-11-28 03:57:39,555 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49849198453805665, 'Total loss': 0.49849198453805665} | train loss {'Reaction outcome loss': 0.46935930341361504, 'Total loss': 0.46935930341361504}
2022-11-28 03:57:39,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:39,555 INFO:     Epoch: 56
2022-11-28 03:57:40,218 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4835163124582984, 'Total loss': 0.4835163124582984} | train loss {'Reaction outcome loss': 0.4675766416648139, 'Total loss': 0.4675766416648139}
2022-11-28 03:57:40,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:40,218 INFO:     Epoch: 57
2022-11-28 03:57:40,877 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5765311931344596, 'Total loss': 0.5765311931344596} | train loss {'Reaction outcome loss': 0.4785108958420001, 'Total loss': 0.4785108958420001}
2022-11-28 03:57:40,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:40,878 INFO:     Epoch: 58
2022-11-28 03:57:41,537 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5373098460788076, 'Total loss': 0.5373098460788076} | train loss {'Reaction outcome loss': 0.4933928487151258, 'Total loss': 0.4933928487151258}
2022-11-28 03:57:41,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:41,537 INFO:     Epoch: 59
2022-11-28 03:57:42,195 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4892701929943128, 'Total loss': 0.4892701929943128} | train loss {'Reaction outcome loss': 0.4630853105675776, 'Total loss': 0.4630853105675776}
2022-11-28 03:57:42,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:42,195 INFO:     Epoch: 60
2022-11-28 03:57:42,859 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46455946869470854, 'Total loss': 0.46455946869470854} | train loss {'Reaction outcome loss': 0.47144774980993887, 'Total loss': 0.47144774980993887}
2022-11-28 03:57:42,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:42,859 INFO:     Epoch: 61
2022-11-28 03:57:43,524 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5148238841105591, 'Total loss': 0.5148238841105591} | train loss {'Reaction outcome loss': 0.4674054961333425, 'Total loss': 0.4674054961333425}
2022-11-28 03:57:43,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:43,524 INFO:     Epoch: 62
2022-11-28 03:57:44,185 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48923910849473695, 'Total loss': 0.48923910849473695} | train loss {'Reaction outcome loss': 0.473913380310603, 'Total loss': 0.473913380310603}
2022-11-28 03:57:44,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:44,186 INFO:     Epoch: 63
2022-11-28 03:57:44,843 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5218974870036949, 'Total loss': 0.5218974870036949} | train loss {'Reaction outcome loss': 0.4645993170226634, 'Total loss': 0.4645993170226634}
2022-11-28 03:57:44,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:44,843 INFO:     Epoch: 64
2022-11-28 03:57:45,500 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4781798476522619, 'Total loss': 0.4781798476522619} | train loss {'Reaction outcome loss': 0.4812421158619738, 'Total loss': 0.4812421158619738}
2022-11-28 03:57:45,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:45,500 INFO:     Epoch: 65
2022-11-28 03:57:46,160 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45462428202683275, 'Total loss': 0.45462428202683275} | train loss {'Reaction outcome loss': 0.47010853808177144, 'Total loss': 0.47010853808177144}
2022-11-28 03:57:46,161 INFO:     Found new best model at epoch 65
2022-11-28 03:57:46,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:46,161 INFO:     Epoch: 66
2022-11-28 03:57:46,818 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5089766538955949, 'Total loss': 0.5089766538955949} | train loss {'Reaction outcome loss': 0.4719266248980032, 'Total loss': 0.4719266248980032}
2022-11-28 03:57:46,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:46,818 INFO:     Epoch: 67
2022-11-28 03:57:47,480 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49321358515457675, 'Total loss': 0.49321358515457675} | train loss {'Reaction outcome loss': 0.4717784079342236, 'Total loss': 0.4717784079342236}
2022-11-28 03:57:47,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:47,480 INFO:     Epoch: 68
2022-11-28 03:57:48,142 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4975905655459924, 'Total loss': 0.4975905655459924} | train loss {'Reaction outcome loss': 0.47870279444374053, 'Total loss': 0.47870279444374053}
2022-11-28 03:57:48,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:48,142 INFO:     Epoch: 69
2022-11-28 03:57:48,806 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6069509779865091, 'Total loss': 0.6069509779865091} | train loss {'Reaction outcome loss': 0.4781110626362596, 'Total loss': 0.4781110626362596}
2022-11-28 03:57:48,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:48,807 INFO:     Epoch: 70
2022-11-28 03:57:49,467 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47061554139310663, 'Total loss': 0.47061554139310663} | train loss {'Reaction outcome loss': 0.48383283765933777, 'Total loss': 0.48383283765933777}
2022-11-28 03:57:49,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:49,468 INFO:     Epoch: 71
2022-11-28 03:57:50,123 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4816866733811118, 'Total loss': 0.4816866733811118} | train loss {'Reaction outcome loss': 0.48147714343148207, 'Total loss': 0.48147714343148207}
2022-11-28 03:57:50,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:50,124 INFO:     Epoch: 72
2022-11-28 03:57:50,780 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49928265674547717, 'Total loss': 0.49928265674547717} | train loss {'Reaction outcome loss': 0.4720460993920261, 'Total loss': 0.4720460993920261}
2022-11-28 03:57:50,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:50,781 INFO:     Epoch: 73
2022-11-28 03:57:51,436 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4973291605710983, 'Total loss': 0.4973291605710983} | train loss {'Reaction outcome loss': 0.4803536509876309, 'Total loss': 0.4803536509876309}
2022-11-28 03:57:51,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:51,437 INFO:     Epoch: 74
2022-11-28 03:57:52,093 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4899076731367545, 'Total loss': 0.4899076731367545} | train loss {'Reaction outcome loss': 0.47772460620895574, 'Total loss': 0.47772460620895574}
2022-11-28 03:57:52,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:52,093 INFO:     Epoch: 75
2022-11-28 03:57:52,753 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4881696524945172, 'Total loss': 0.4881696524945172} | train loss {'Reaction outcome loss': 0.4785423646209694, 'Total loss': 0.4785423646209694}
2022-11-28 03:57:52,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:52,753 INFO:     Epoch: 76
2022-11-28 03:57:53,409 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4691967618736354, 'Total loss': 0.4691967618736354} | train loss {'Reaction outcome loss': 0.4697943861305955, 'Total loss': 0.4697943861305955}
2022-11-28 03:57:53,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:53,409 INFO:     Epoch: 77
2022-11-28 03:57:54,066 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4798596548763188, 'Total loss': 0.4798596548763188} | train loss {'Reaction outcome loss': 0.47728187153455215, 'Total loss': 0.47728187153455215}
2022-11-28 03:57:54,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:54,066 INFO:     Epoch: 78
2022-11-28 03:57:54,723 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5152589292688803, 'Total loss': 0.5152589292688803} | train loss {'Reaction outcome loss': 0.4743490256821578, 'Total loss': 0.4743490256821578}
2022-11-28 03:57:54,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:54,723 INFO:     Epoch: 79
2022-11-28 03:57:55,383 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4833014749667861, 'Total loss': 0.4833014749667861} | train loss {'Reaction outcome loss': 0.4705389007503687, 'Total loss': 0.4705389007503687}
2022-11-28 03:57:55,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:55,383 INFO:     Epoch: 80
2022-11-28 03:57:56,041 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5409646521915089, 'Total loss': 0.5409646521915089} | train loss {'Reaction outcome loss': 0.48744320827215787, 'Total loss': 0.48744320827215787}
2022-11-28 03:57:56,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:56,041 INFO:     Epoch: 81
2022-11-28 03:57:56,701 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46552742035551503, 'Total loss': 0.46552742035551503} | train loss {'Reaction outcome loss': 0.4810523747311913, 'Total loss': 0.4810523747311913}
2022-11-28 03:57:56,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:56,701 INFO:     Epoch: 82
2022-11-28 03:57:57,362 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4641888006166978, 'Total loss': 0.4641888006166978} | train loss {'Reaction outcome loss': 0.4766671141149544, 'Total loss': 0.4766671141149544}
2022-11-28 03:57:57,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:57,362 INFO:     Epoch: 83
2022-11-28 03:57:58,023 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4840118343179876, 'Total loss': 0.4840118343179876} | train loss {'Reaction outcome loss': 0.47353958365646937, 'Total loss': 0.47353958365646937}
2022-11-28 03:57:58,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:58,024 INFO:     Epoch: 84
2022-11-28 03:57:58,686 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4928543181581931, 'Total loss': 0.4928543181581931} | train loss {'Reaction outcome loss': 0.4844865879790503, 'Total loss': 0.4844865879790503}
2022-11-28 03:57:58,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:58,686 INFO:     Epoch: 85
2022-11-28 03:57:59,344 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48962393098256807, 'Total loss': 0.48962393098256807} | train loss {'Reaction outcome loss': 0.47244493334897253, 'Total loss': 0.47244493334897253}
2022-11-28 03:57:59,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:57:59,345 INFO:     Epoch: 86
2022-11-28 03:58:00,007 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4803124815225601, 'Total loss': 0.4803124815225601} | train loss {'Reaction outcome loss': 0.46645890996765027, 'Total loss': 0.46645890996765027}
2022-11-28 03:58:00,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:00,007 INFO:     Epoch: 87
2022-11-28 03:58:00,669 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5014366707341238, 'Total loss': 0.5014366707341238} | train loss {'Reaction outcome loss': 0.4717447266193778, 'Total loss': 0.4717447266193778}
2022-11-28 03:58:00,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:00,670 INFO:     Epoch: 88
2022-11-28 03:58:01,329 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4966768574985591, 'Total loss': 0.4966768574985591} | train loss {'Reaction outcome loss': 0.4695533067591277, 'Total loss': 0.4695533067591277}
2022-11-28 03:58:01,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:01,329 INFO:     Epoch: 89
2022-11-28 03:58:01,987 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5084087838503447, 'Total loss': 0.5084087838503447} | train loss {'Reaction outcome loss': 0.48259803713091953, 'Total loss': 0.48259803713091953}
2022-11-28 03:58:01,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:01,987 INFO:     Epoch: 90
2022-11-28 03:58:02,643 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47888597879897465, 'Total loss': 0.47888597879897465} | train loss {'Reaction outcome loss': 0.4748767496723878, 'Total loss': 0.4748767496723878}
2022-11-28 03:58:02,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:02,644 INFO:     Epoch: 91
2022-11-28 03:58:03,301 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5256042697212913, 'Total loss': 0.5256042697212913} | train loss {'Reaction outcome loss': 0.47687374363061386, 'Total loss': 0.47687374363061386}
2022-11-28 03:58:03,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:03,301 INFO:     Epoch: 92
2022-11-28 03:58:03,958 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5144620686769485, 'Total loss': 0.5144620686769485} | train loss {'Reaction outcome loss': 0.4849414056249958, 'Total loss': 0.4849414056249958}
2022-11-28 03:58:03,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:03,958 INFO:     Epoch: 93
2022-11-28 03:58:04,617 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5022179448807781, 'Total loss': 0.5022179448807781} | train loss {'Reaction outcome loss': 0.48140691468107555, 'Total loss': 0.48140691468107555}
2022-11-28 03:58:04,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:04,617 INFO:     Epoch: 94
2022-11-28 03:58:05,274 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4838938374410976, 'Total loss': 0.4838938374410976} | train loss {'Reaction outcome loss': 0.486096922866246, 'Total loss': 0.486096922866246}
2022-11-28 03:58:05,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:05,275 INFO:     Epoch: 95
2022-11-28 03:58:05,935 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48712487959048967, 'Total loss': 0.48712487959048967} | train loss {'Reaction outcome loss': 0.47015068068089877, 'Total loss': 0.47015068068089877}
2022-11-28 03:58:05,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:05,935 INFO:     Epoch: 96
2022-11-28 03:58:06,594 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4907135729762641, 'Total loss': 0.4907135729762641} | train loss {'Reaction outcome loss': 0.4709812724276593, 'Total loss': 0.4709812724276593}
2022-11-28 03:58:06,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:06,595 INFO:     Epoch: 97
2022-11-28 03:58:07,254 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5152960859916427, 'Total loss': 0.5152960859916427} | train loss {'Reaction outcome loss': 0.4700095834218056, 'Total loss': 0.4700095834218056}
2022-11-28 03:58:07,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:07,254 INFO:     Epoch: 98
2022-11-28 03:58:07,912 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5139054415578191, 'Total loss': 0.5139054415578191} | train loss {'Reaction outcome loss': 0.49200126598683386, 'Total loss': 0.49200126598683386}
2022-11-28 03:58:07,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:07,913 INFO:     Epoch: 99
2022-11-28 03:58:08,572 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49840167977593164, 'Total loss': 0.49840167977593164} | train loss {'Reaction outcome loss': 0.46791139981042035, 'Total loss': 0.46791139981042035}
2022-11-28 03:58:08,572 INFO:     Best model found after epoch 66 of 100.
2022-11-28 03:58:08,572 INFO:   Done with stage: TRAINING
2022-11-28 03:58:08,572 INFO:   Starting stage: EVALUATION
2022-11-28 03:58:08,691 INFO:   Done with stage: EVALUATION
2022-11-28 03:58:08,692 INFO:   Leaving out SEQ value Fold_9
2022-11-28 03:58:08,704 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:58:08,704 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:58:09,344 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:58:09,344 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:58:09,413 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:58:09,414 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:58:09,414 INFO:     No hyperparam tuning for this model
2022-11-28 03:58:09,414 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:58:09,414 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:58:09,415 INFO:     None feature selector for col prot
2022-11-28 03:58:09,415 INFO:     None feature selector for col prot
2022-11-28 03:58:09,415 INFO:     None feature selector for col prot
2022-11-28 03:58:09,415 INFO:     None feature selector for col chem
2022-11-28 03:58:09,415 INFO:     None feature selector for col chem
2022-11-28 03:58:09,416 INFO:     None feature selector for col chem
2022-11-28 03:58:09,416 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:58:09,416 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:58:09,417 INFO:     Number of params in model 169651
2022-11-28 03:58:09,420 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:58:09,420 INFO:   Starting stage: TRAINING
2022-11-28 03:58:09,472 INFO:     Val loss before train {'Reaction outcome loss': 1.0126697773283178, 'Total loss': 1.0126697773283178}
2022-11-28 03:58:09,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:09,472 INFO:     Epoch: 0
2022-11-28 03:58:10,131 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5930094989863309, 'Total loss': 0.5930094989863309} | train loss {'Reaction outcome loss': 0.6967770281108284, 'Total loss': 0.6967770281108284}
2022-11-28 03:58:10,132 INFO:     Found new best model at epoch 0
2022-11-28 03:58:10,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:10,132 INFO:     Epoch: 1
2022-11-28 03:58:10,789 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6184466935016892, 'Total loss': 0.6184466935016892} | train loss {'Reaction outcome loss': 0.5963452060816259, 'Total loss': 0.5963452060816259}
2022-11-28 03:58:10,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:10,790 INFO:     Epoch: 2
2022-11-28 03:58:11,446 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5247941311787475, 'Total loss': 0.5247941311787475} | train loss {'Reaction outcome loss': 0.5582832723011372, 'Total loss': 0.5582832723011372}
2022-11-28 03:58:11,446 INFO:     Found new best model at epoch 2
2022-11-28 03:58:11,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:11,447 INFO:     Epoch: 3
2022-11-28 03:58:12,105 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5891053757884286, 'Total loss': 0.5891053757884286} | train loss {'Reaction outcome loss': 0.5402182003988428, 'Total loss': 0.5402182003988428}
2022-11-28 03:58:12,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:12,105 INFO:     Epoch: 4
2022-11-28 03:58:12,768 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6037827879190445, 'Total loss': 0.6037827879190445} | train loss {'Reaction outcome loss': 0.5228200725049745, 'Total loss': 0.5228200725049745}
2022-11-28 03:58:12,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:12,768 INFO:     Epoch: 5
2022-11-28 03:58:13,424 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49391637268391525, 'Total loss': 0.49391637268391525} | train loss {'Reaction outcome loss': 0.5277583434393531, 'Total loss': 0.5277583434393531}
2022-11-28 03:58:13,424 INFO:     Found new best model at epoch 5
2022-11-28 03:58:13,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:13,425 INFO:     Epoch: 6
2022-11-28 03:58:14,079 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5159037031910636, 'Total loss': 0.5159037031910636} | train loss {'Reaction outcome loss': 0.51824583306245, 'Total loss': 0.51824583306245}
2022-11-28 03:58:14,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:14,079 INFO:     Epoch: 7
2022-11-28 03:58:14,738 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4837982180443677, 'Total loss': 0.4837982180443677} | train loss {'Reaction outcome loss': 0.5094873592076514, 'Total loss': 0.5094873592076514}
2022-11-28 03:58:14,738 INFO:     Found new best model at epoch 7
2022-11-28 03:58:14,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:14,739 INFO:     Epoch: 8
2022-11-28 03:58:15,398 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4891296489672227, 'Total loss': 0.4891296489672227} | train loss {'Reaction outcome loss': 0.5049627770100408, 'Total loss': 0.5049627770100408}
2022-11-28 03:58:15,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:15,399 INFO:     Epoch: 9
2022-11-28 03:58:16,057 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4938813353126699, 'Total loss': 0.4938813353126699} | train loss {'Reaction outcome loss': 0.5032338760642387, 'Total loss': 0.5032338760642387}
2022-11-28 03:58:16,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:16,057 INFO:     Epoch: 10
2022-11-28 03:58:16,715 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4715886092321439, 'Total loss': 0.4715886092321439} | train loss {'Reaction outcome loss': 0.5033252217056539, 'Total loss': 0.5033252217056539}
2022-11-28 03:58:16,715 INFO:     Found new best model at epoch 10
2022-11-28 03:58:16,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:16,716 INFO:     Epoch: 11
2022-11-28 03:58:17,375 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5053303228183226, 'Total loss': 0.5053303228183226} | train loss {'Reaction outcome loss': 0.5000479801101723, 'Total loss': 0.5000479801101723}
2022-11-28 03:58:17,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:17,375 INFO:     Epoch: 12
2022-11-28 03:58:18,029 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4794193404642018, 'Total loss': 0.4794193404642018} | train loss {'Reaction outcome loss': 0.5127185839511123, 'Total loss': 0.5127185839511123}
2022-11-28 03:58:18,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:18,029 INFO:     Epoch: 13
2022-11-28 03:58:18,685 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5195954943245108, 'Total loss': 0.5195954943245108} | train loss {'Reaction outcome loss': 0.5001834265374945, 'Total loss': 0.5001834265374945}
2022-11-28 03:58:18,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:18,685 INFO:     Epoch: 14
2022-11-28 03:58:19,342 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4925964688035575, 'Total loss': 0.4925964688035575} | train loss {'Reaction outcome loss': 0.49724101459207803, 'Total loss': 0.49724101459207803}
2022-11-28 03:58:19,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:19,343 INFO:     Epoch: 15
2022-11-28 03:58:19,998 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48227584666826506, 'Total loss': 0.48227584666826506} | train loss {'Reaction outcome loss': 0.49612019720830414, 'Total loss': 0.49612019720830414}
2022-11-28 03:58:19,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:19,998 INFO:     Epoch: 16
2022-11-28 03:58:20,656 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49282806332815776, 'Total loss': 0.49282806332815776} | train loss {'Reaction outcome loss': 0.5078355742972872, 'Total loss': 0.5078355742972872}
2022-11-28 03:58:20,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:20,656 INFO:     Epoch: 17
2022-11-28 03:58:21,312 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5080935088070956, 'Total loss': 0.5080935088070956} | train loss {'Reaction outcome loss': 0.48273705068206496, 'Total loss': 0.48273705068206496}
2022-11-28 03:58:21,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:21,313 INFO:     Epoch: 18
2022-11-28 03:58:21,971 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49721682545813645, 'Total loss': 0.49721682545813645} | train loss {'Reaction outcome loss': 0.48685684474373636, 'Total loss': 0.48685684474373636}
2022-11-28 03:58:21,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:21,972 INFO:     Epoch: 19
2022-11-28 03:58:22,632 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49548461593010207, 'Total loss': 0.49548461593010207} | train loss {'Reaction outcome loss': 0.4884834393315952, 'Total loss': 0.4884834393315952}
2022-11-28 03:58:22,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:22,632 INFO:     Epoch: 20
2022-11-28 03:58:23,292 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4815144210376523, 'Total loss': 0.4815144210376523} | train loss {'Reaction outcome loss': 0.4787949175547492, 'Total loss': 0.4787949175547492}
2022-11-28 03:58:23,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:23,292 INFO:     Epoch: 21
2022-11-28 03:58:23,953 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4684255529533733, 'Total loss': 0.4684255529533733} | train loss {'Reaction outcome loss': 0.48531433746882296, 'Total loss': 0.48531433746882296}
2022-11-28 03:58:23,953 INFO:     Found new best model at epoch 21
2022-11-28 03:58:23,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:23,953 INFO:     Epoch: 22
2022-11-28 03:58:24,611 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4438917525112629, 'Total loss': 0.4438917525112629} | train loss {'Reaction outcome loss': 0.4929798653175836, 'Total loss': 0.4929798653175836}
2022-11-28 03:58:24,611 INFO:     Found new best model at epoch 22
2022-11-28 03:58:24,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:24,612 INFO:     Epoch: 23
2022-11-28 03:58:25,273 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4702583835883574, 'Total loss': 0.4702583835883574} | train loss {'Reaction outcome loss': 0.4809453005088033, 'Total loss': 0.4809453005088033}
2022-11-28 03:58:25,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:25,274 INFO:     Epoch: 24
2022-11-28 03:58:25,937 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5256809761578386, 'Total loss': 0.5256809761578386} | train loss {'Reaction outcome loss': 0.4817523560543292, 'Total loss': 0.4817523560543292}
2022-11-28 03:58:25,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:25,937 INFO:     Epoch: 25
2022-11-28 03:58:26,597 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5203278708187017, 'Total loss': 0.5203278708187017} | train loss {'Reaction outcome loss': 0.48469947175941, 'Total loss': 0.48469947175941}
2022-11-28 03:58:26,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:26,597 INFO:     Epoch: 26
2022-11-28 03:58:27,255 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4758938652547923, 'Total loss': 0.4758938652547923} | train loss {'Reaction outcome loss': 0.49287062991968533, 'Total loss': 0.49287062991968533}
2022-11-28 03:58:27,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:27,255 INFO:     Epoch: 27
2022-11-28 03:58:27,914 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47181527045640076, 'Total loss': 0.47181527045640076} | train loss {'Reaction outcome loss': 0.48324186829209087, 'Total loss': 0.48324186829209087}
2022-11-28 03:58:27,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:27,914 INFO:     Epoch: 28
2022-11-28 03:58:28,573 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46690399877049704, 'Total loss': 0.46690399877049704} | train loss {'Reaction outcome loss': 0.47703251097849025, 'Total loss': 0.47703251097849025}
2022-11-28 03:58:28,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:28,573 INFO:     Epoch: 29
2022-11-28 03:58:29,235 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4514995132657615, 'Total loss': 0.4514995132657615} | train loss {'Reaction outcome loss': 0.47848648973080793, 'Total loss': 0.47848648973080793}
2022-11-28 03:58:29,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:29,236 INFO:     Epoch: 30
2022-11-28 03:58:29,895 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4533559497107159, 'Total loss': 0.4533559497107159} | train loss {'Reaction outcome loss': 0.47069170455700954, 'Total loss': 0.47069170455700954}
2022-11-28 03:58:29,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:29,895 INFO:     Epoch: 31
2022-11-28 03:58:30,560 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4796519655395638, 'Total loss': 0.4796519655395638} | train loss {'Reaction outcome loss': 0.4734063078517373, 'Total loss': 0.4734063078517373}
2022-11-28 03:58:30,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:30,560 INFO:     Epoch: 32
2022-11-28 03:58:31,222 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4554362046447667, 'Total loss': 0.4554362046447667} | train loss {'Reaction outcome loss': 0.48035373051579183, 'Total loss': 0.48035373051579183}
2022-11-28 03:58:31,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:31,222 INFO:     Epoch: 33
2022-11-28 03:58:31,882 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.441046554595232, 'Total loss': 0.441046554595232} | train loss {'Reaction outcome loss': 0.4782890837322845, 'Total loss': 0.4782890837322845}
2022-11-28 03:58:31,882 INFO:     Found new best model at epoch 33
2022-11-28 03:58:31,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:31,883 INFO:     Epoch: 34
2022-11-28 03:58:32,542 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4654615226794373, 'Total loss': 0.4654615226794373} | train loss {'Reaction outcome loss': 0.47156008360115625, 'Total loss': 0.47156008360115625}
2022-11-28 03:58:32,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:32,542 INFO:     Epoch: 35
2022-11-28 03:58:33,204 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4578398679467765, 'Total loss': 0.4578398679467765} | train loss {'Reaction outcome loss': 0.4914762577464284, 'Total loss': 0.4914762577464284}
2022-11-28 03:58:33,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:33,205 INFO:     Epoch: 36
2022-11-28 03:58:33,869 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45694988559592853, 'Total loss': 0.45694988559592853} | train loss {'Reaction outcome loss': 0.47077316896394195, 'Total loss': 0.47077316896394195}
2022-11-28 03:58:33,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:33,869 INFO:     Epoch: 37
2022-11-28 03:58:34,531 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4678379635919224, 'Total loss': 0.4678379635919224} | train loss {'Reaction outcome loss': 0.4729332573380065, 'Total loss': 0.4729332573380065}
2022-11-28 03:58:34,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:34,531 INFO:     Epoch: 38
2022-11-28 03:58:35,191 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46505687792192807, 'Total loss': 0.46505687792192807} | train loss {'Reaction outcome loss': 0.47100625450247785, 'Total loss': 0.47100625450247785}
2022-11-28 03:58:35,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:35,191 INFO:     Epoch: 39
2022-11-28 03:58:35,850 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4868544035337188, 'Total loss': 0.4868544035337188} | train loss {'Reaction outcome loss': 0.46806681983414206, 'Total loss': 0.46806681983414206}
2022-11-28 03:58:35,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:35,850 INFO:     Epoch: 40
2022-11-28 03:58:36,510 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46252784014425496, 'Total loss': 0.46252784014425496} | train loss {'Reaction outcome loss': 0.47662699180334683, 'Total loss': 0.47662699180334683}
2022-11-28 03:58:36,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:36,510 INFO:     Epoch: 41
2022-11-28 03:58:37,175 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48663823103362863, 'Total loss': 0.48663823103362863} | train loss {'Reaction outcome loss': 0.48965791574404066, 'Total loss': 0.48965791574404066}
2022-11-28 03:58:37,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:37,175 INFO:     Epoch: 42
2022-11-28 03:58:37,842 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4806904355910691, 'Total loss': 0.4806904355910691} | train loss {'Reaction outcome loss': 0.4722134222385854, 'Total loss': 0.4722134222385854}
2022-11-28 03:58:37,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:37,842 INFO:     Epoch: 43
2022-11-28 03:58:38,503 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.499501093883406, 'Total loss': 0.499501093883406} | train loss {'Reaction outcome loss': 0.47452545862810813, 'Total loss': 0.47452545862810813}
2022-11-28 03:58:38,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:38,504 INFO:     Epoch: 44
2022-11-28 03:58:39,163 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4627869850532575, 'Total loss': 0.4627869850532575} | train loss {'Reaction outcome loss': 0.46921446026578123, 'Total loss': 0.46921446026578123}
2022-11-28 03:58:39,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:39,163 INFO:     Epoch: 45
2022-11-28 03:58:39,824 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4704187928952954, 'Total loss': 0.4704187928952954} | train loss {'Reaction outcome loss': 0.47912485778769137, 'Total loss': 0.47912485778769137}
2022-11-28 03:58:39,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:39,825 INFO:     Epoch: 46
2022-11-28 03:58:40,483 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44298208064653655, 'Total loss': 0.44298208064653655} | train loss {'Reaction outcome loss': 0.4675158636290052, 'Total loss': 0.4675158636290052}
2022-11-28 03:58:40,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:40,483 INFO:     Epoch: 47
2022-11-28 03:58:41,142 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4687655364925211, 'Total loss': 0.4687655364925211} | train loss {'Reaction outcome loss': 0.46791020531380767, 'Total loss': 0.46791020531380767}
2022-11-28 03:58:41,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:41,142 INFO:     Epoch: 48
2022-11-28 03:58:41,806 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44106278974901547, 'Total loss': 0.44106278974901547} | train loss {'Reaction outcome loss': 0.4736883324167506, 'Total loss': 0.4736883324167506}
2022-11-28 03:58:41,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:41,806 INFO:     Epoch: 49
2022-11-28 03:58:42,470 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47303216430273926, 'Total loss': 0.47303216430273926} | train loss {'Reaction outcome loss': 0.4781919243605996, 'Total loss': 0.4781919243605996}
2022-11-28 03:58:42,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:42,470 INFO:     Epoch: 50
2022-11-28 03:58:43,131 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46351614086465404, 'Total loss': 0.46351614086465404} | train loss {'Reaction outcome loss': 0.4737557493124783, 'Total loss': 0.4737557493124783}
2022-11-28 03:58:43,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:43,132 INFO:     Epoch: 51
2022-11-28 03:58:43,792 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47967535562135954, 'Total loss': 0.47967535562135954} | train loss {'Reaction outcome loss': 0.48053249041078544, 'Total loss': 0.48053249041078544}
2022-11-28 03:58:43,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:43,792 INFO:     Epoch: 52
2022-11-28 03:58:44,447 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4495743164284663, 'Total loss': 0.4495743164284663} | train loss {'Reaction outcome loss': 0.47114181293100155, 'Total loss': 0.47114181293100155}
2022-11-28 03:58:44,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:44,448 INFO:     Epoch: 53
2022-11-28 03:58:45,107 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45747089572250843, 'Total loss': 0.45747089572250843} | train loss {'Reaction outcome loss': 0.47460859799701044, 'Total loss': 0.47460859799701044}
2022-11-28 03:58:45,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:45,107 INFO:     Epoch: 54
2022-11-28 03:58:45,767 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45654192431406543, 'Total loss': 0.45654192431406543} | train loss {'Reaction outcome loss': 0.475289145823915, 'Total loss': 0.475289145823915}
2022-11-28 03:58:45,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:45,768 INFO:     Epoch: 55
2022-11-28 03:58:46,429 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44543880376626144, 'Total loss': 0.44543880376626144} | train loss {'Reaction outcome loss': 0.47720433638887366, 'Total loss': 0.47720433638887366}
2022-11-28 03:58:46,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:46,430 INFO:     Epoch: 56
2022-11-28 03:58:47,090 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45873097821392794, 'Total loss': 0.45873097821392794} | train loss {'Reaction outcome loss': 0.47366770972245137, 'Total loss': 0.47366770972245137}
2022-11-28 03:58:47,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:47,091 INFO:     Epoch: 57
2022-11-28 03:58:47,753 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4455803275447, 'Total loss': 0.4455803275447} | train loss {'Reaction outcome loss': 0.47322696206576537, 'Total loss': 0.47322696206576537}
2022-11-28 03:58:47,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:47,753 INFO:     Epoch: 58
2022-11-28 03:58:48,412 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49932946772737935, 'Total loss': 0.49932946772737935} | train loss {'Reaction outcome loss': 0.4710946469775096, 'Total loss': 0.4710946469775096}
2022-11-28 03:58:48,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:48,412 INFO:     Epoch: 59
2022-11-28 03:58:49,072 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45973205837336456, 'Total loss': 0.45973205837336456} | train loss {'Reaction outcome loss': 0.4760070584322277, 'Total loss': 0.4760070584322277}
2022-11-28 03:58:49,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:49,072 INFO:     Epoch: 60
2022-11-28 03:58:49,731 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.439525555819273, 'Total loss': 0.439525555819273} | train loss {'Reaction outcome loss': 0.48444302355953556, 'Total loss': 0.48444302355953556}
2022-11-28 03:58:49,731 INFO:     Found new best model at epoch 60
2022-11-28 03:58:49,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:49,732 INFO:     Epoch: 61
2022-11-28 03:58:50,390 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4598786878314885, 'Total loss': 0.4598786878314885} | train loss {'Reaction outcome loss': 0.49218962585877796, 'Total loss': 0.49218962585877796}
2022-11-28 03:58:50,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:50,391 INFO:     Epoch: 62
2022-11-28 03:58:51,051 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4659271328286691, 'Total loss': 0.4659271328286691} | train loss {'Reaction outcome loss': 0.4798938962612075, 'Total loss': 0.4798938962612075}
2022-11-28 03:58:51,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:51,051 INFO:     Epoch: 63
2022-11-28 03:58:51,710 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47921809486367484, 'Total loss': 0.47921809486367484} | train loss {'Reaction outcome loss': 0.47463066438552337, 'Total loss': 0.47463066438552337}
2022-11-28 03:58:51,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:51,710 INFO:     Epoch: 64
2022-11-28 03:58:52,369 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4824986850673502, 'Total loss': 0.4824986850673502} | train loss {'Reaction outcome loss': 0.48091566870328384, 'Total loss': 0.48091566870328384}
2022-11-28 03:58:52,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:52,370 INFO:     Epoch: 65
2022-11-28 03:58:53,030 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4776698019016873, 'Total loss': 0.4776698019016873} | train loss {'Reaction outcome loss': 0.4787408835612811, 'Total loss': 0.4787408835612811}
2022-11-28 03:58:53,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:53,031 INFO:     Epoch: 66
2022-11-28 03:58:53,691 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46153541620482097, 'Total loss': 0.46153541620482097} | train loss {'Reaction outcome loss': 0.4847859406036887, 'Total loss': 0.4847859406036887}
2022-11-28 03:58:53,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:53,691 INFO:     Epoch: 67
2022-11-28 03:58:54,351 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45583448017185385, 'Total loss': 0.45583448017185385} | train loss {'Reaction outcome loss': 0.47088974346274787, 'Total loss': 0.47088974346274787}
2022-11-28 03:58:54,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:54,351 INFO:     Epoch: 68
2022-11-28 03:58:55,010 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45424870029091835, 'Total loss': 0.45424870029091835} | train loss {'Reaction outcome loss': 0.46915190313991745, 'Total loss': 0.46915190313991745}
2022-11-28 03:58:55,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:55,010 INFO:     Epoch: 69
2022-11-28 03:58:55,670 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45361987399784004, 'Total loss': 0.45361987399784004} | train loss {'Reaction outcome loss': 0.484432025115017, 'Total loss': 0.484432025115017}
2022-11-28 03:58:55,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:55,671 INFO:     Epoch: 70
2022-11-28 03:58:56,329 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46246045421470294, 'Total loss': 0.46246045421470294} | train loss {'Reaction outcome loss': 0.47203050589995826, 'Total loss': 0.47203050589995826}
2022-11-28 03:58:56,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:56,330 INFO:     Epoch: 71
2022-11-28 03:58:56,991 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4471124474975196, 'Total loss': 0.4471124474975196} | train loss {'Reaction outcome loss': 0.4767816495979846, 'Total loss': 0.4767816495979846}
2022-11-28 03:58:56,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:56,991 INFO:     Epoch: 72
2022-11-28 03:58:57,651 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46187467873096466, 'Total loss': 0.46187467873096466} | train loss {'Reaction outcome loss': 0.45925405975959077, 'Total loss': 0.45925405975959077}
2022-11-28 03:58:57,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:57,651 INFO:     Epoch: 73
2022-11-28 03:58:58,312 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45670232244513254, 'Total loss': 0.45670232244513254} | train loss {'Reaction outcome loss': 0.46924176763909065, 'Total loss': 0.46924176763909065}
2022-11-28 03:58:58,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:58,312 INFO:     Epoch: 74
2022-11-28 03:58:58,971 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4642407333647663, 'Total loss': 0.4642407333647663} | train loss {'Reaction outcome loss': 0.47628178809456495, 'Total loss': 0.47628178809456495}
2022-11-28 03:58:58,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:58,971 INFO:     Epoch: 75
2022-11-28 03:58:59,632 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43349553407593205, 'Total loss': 0.43349553407593205} | train loss {'Reaction outcome loss': 0.4761591259887827, 'Total loss': 0.4761591259887827}
2022-11-28 03:58:59,632 INFO:     Found new best model at epoch 75
2022-11-28 03:58:59,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:58:59,633 INFO:     Epoch: 76
2022-11-28 03:59:00,294 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5059562769125808, 'Total loss': 0.5059562769125808} | train loss {'Reaction outcome loss': 0.47183052187989116, 'Total loss': 0.47183052187989116}
2022-11-28 03:59:00,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:00,294 INFO:     Epoch: 77
2022-11-28 03:59:00,954 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47309025715697894, 'Total loss': 0.47309025715697894} | train loss {'Reaction outcome loss': 0.47850986440413396, 'Total loss': 0.47850986440413396}
2022-11-28 03:59:00,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:00,954 INFO:     Epoch: 78
2022-11-28 03:59:01,618 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4772515351122076, 'Total loss': 0.4772515351122076} | train loss {'Reaction outcome loss': 0.4928386214713336, 'Total loss': 0.4928386214713336}
2022-11-28 03:59:01,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:01,618 INFO:     Epoch: 79
2022-11-28 03:59:02,280 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5005229772491888, 'Total loss': 0.5005229772491888} | train loss {'Reaction outcome loss': 0.4910539117781257, 'Total loss': 0.4910539117781257}
2022-11-28 03:59:02,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:02,280 INFO:     Epoch: 80
2022-11-28 03:59:02,938 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4605257240208713, 'Total loss': 0.4605257240208713} | train loss {'Reaction outcome loss': 0.47600610468250054, 'Total loss': 0.47600610468250054}
2022-11-28 03:59:02,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:02,939 INFO:     Epoch: 81
2022-11-28 03:59:03,597 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4624401551078666, 'Total loss': 0.4624401551078666} | train loss {'Reaction outcome loss': 0.47581381383936416, 'Total loss': 0.47581381383936416}
2022-11-28 03:59:03,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:03,597 INFO:     Epoch: 82
2022-11-28 03:59:04,256 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4468699256804856, 'Total loss': 0.4468699256804856} | train loss {'Reaction outcome loss': 0.47931981792575434, 'Total loss': 0.47931981792575434}
2022-11-28 03:59:04,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:04,256 INFO:     Epoch: 83
2022-11-28 03:59:04,919 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4306019835851409, 'Total loss': 0.4306019835851409} | train loss {'Reaction outcome loss': 0.4731755933633851, 'Total loss': 0.4731755933633851}
2022-11-28 03:59:04,920 INFO:     Found new best model at epoch 83
2022-11-28 03:59:04,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:04,922 INFO:     Epoch: 84
2022-11-28 03:59:05,581 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4456369832835414, 'Total loss': 0.4456369832835414} | train loss {'Reaction outcome loss': 0.46406335379129, 'Total loss': 0.46406335379129}
2022-11-28 03:59:05,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:05,581 INFO:     Epoch: 85
2022-11-28 03:59:06,242 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4536457459696315, 'Total loss': 0.4536457459696315} | train loss {'Reaction outcome loss': 0.4692160490851261, 'Total loss': 0.4692160490851261}
2022-11-28 03:59:06,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:06,242 INFO:     Epoch: 86
2022-11-28 03:59:06,905 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4409436888315461, 'Total loss': 0.4409436888315461} | train loss {'Reaction outcome loss': 0.47167646547078124, 'Total loss': 0.47167646547078124}
2022-11-28 03:59:06,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:06,905 INFO:     Epoch: 87
2022-11-28 03:59:07,567 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44155884059992706, 'Total loss': 0.44155884059992706} | train loss {'Reaction outcome loss': 0.47216824431590704, 'Total loss': 0.47216824431590704}
2022-11-28 03:59:07,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:07,567 INFO:     Epoch: 88
2022-11-28 03:59:08,225 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4757758267223835, 'Total loss': 0.4757758267223835} | train loss {'Reaction outcome loss': 0.4626718561206511, 'Total loss': 0.4626718561206511}
2022-11-28 03:59:08,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:08,226 INFO:     Epoch: 89
2022-11-28 03:59:08,887 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48176545378836716, 'Total loss': 0.48176545378836716} | train loss {'Reaction outcome loss': 0.4647724923455281, 'Total loss': 0.4647724923455281}
2022-11-28 03:59:08,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:08,887 INFO:     Epoch: 90
2022-11-28 03:59:09,549 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48017669130455365, 'Total loss': 0.48017669130455365} | train loss {'Reaction outcome loss': 0.47243964997862997, 'Total loss': 0.47243964997862997}
2022-11-28 03:59:09,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:09,549 INFO:     Epoch: 91
2022-11-28 03:59:10,208 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5969551463018764, 'Total loss': 0.5969551463018764} | train loss {'Reaction outcome loss': 0.48040832446413, 'Total loss': 0.48040832446413}
2022-11-28 03:59:10,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:10,209 INFO:     Epoch: 92
2022-11-28 03:59:10,867 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4396537501703609, 'Total loss': 0.4396537501703609} | train loss {'Reaction outcome loss': 0.4775896459395586, 'Total loss': 0.4775896459395586}
2022-11-28 03:59:10,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:10,867 INFO:     Epoch: 93
2022-11-28 03:59:11,529 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.498800244521011, 'Total loss': 0.498800244521011} | train loss {'Reaction outcome loss': 0.47389650432325087, 'Total loss': 0.47389650432325087}
2022-11-28 03:59:11,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:11,530 INFO:     Epoch: 94
2022-11-28 03:59:12,190 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4380703250115568, 'Total loss': 0.4380703250115568} | train loss {'Reaction outcome loss': 0.4716288183140851, 'Total loss': 0.4716288183140851}
2022-11-28 03:59:12,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:12,190 INFO:     Epoch: 95
2022-11-28 03:59:12,852 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46052652766758745, 'Total loss': 0.46052652766758745} | train loss {'Reaction outcome loss': 0.470569850733647, 'Total loss': 0.470569850733647}
2022-11-28 03:59:12,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:12,852 INFO:     Epoch: 96
2022-11-28 03:59:13,512 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49029532582922414, 'Total loss': 0.49029532582922414} | train loss {'Reaction outcome loss': 0.4723392255936074, 'Total loss': 0.4723392255936074}
2022-11-28 03:59:13,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:13,512 INFO:     Epoch: 97
2022-11-28 03:59:14,173 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.466851586306637, 'Total loss': 0.466851586306637} | train loss {'Reaction outcome loss': 0.4670779033439603, 'Total loss': 0.4670779033439603}
2022-11-28 03:59:14,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:14,173 INFO:     Epoch: 98
2022-11-28 03:59:14,835 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47391760552471335, 'Total loss': 0.47391760552471335} | train loss {'Reaction outcome loss': 0.4756071394392353, 'Total loss': 0.4756071394392353}
2022-11-28 03:59:14,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:14,835 INFO:     Epoch: 99
2022-11-28 03:59:15,495 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.448492668569088, 'Total loss': 0.448492668569088} | train loss {'Reaction outcome loss': 0.4769361151951678, 'Total loss': 0.4769361151951678}
2022-11-28 03:59:15,495 INFO:     Best model found after epoch 84 of 100.
2022-11-28 03:59:15,495 INFO:   Done with stage: TRAINING
2022-11-28 03:59:15,495 INFO:   Starting stage: EVALUATION
2022-11-28 03:59:15,613 INFO:   Done with stage: EVALUATION
2022-11-28 03:59:15,622 INFO:   Leaving out SEQ value Fold_0
2022-11-28 03:59:15,634 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 03:59:15,635 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:59:16,271 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:59:16,271 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:59:16,337 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:59:16,337 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:59:16,337 INFO:     No hyperparam tuning for this model
2022-11-28 03:59:16,337 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:59:16,337 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:59:16,338 INFO:     None feature selector for col prot
2022-11-28 03:59:16,338 INFO:     None feature selector for col prot
2022-11-28 03:59:16,338 INFO:     None feature selector for col prot
2022-11-28 03:59:16,339 INFO:     None feature selector for col chem
2022-11-28 03:59:16,339 INFO:     None feature selector for col chem
2022-11-28 03:59:16,339 INFO:     None feature selector for col chem
2022-11-28 03:59:16,339 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:59:16,339 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:59:16,341 INFO:     Number of params in model 169651
2022-11-28 03:59:16,343 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:59:16,344 INFO:   Starting stage: TRAINING
2022-11-28 03:59:16,393 INFO:     Val loss before train {'Reaction outcome loss': 0.9737439155578613, 'Total loss': 0.9737439155578613}
2022-11-28 03:59:16,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:16,393 INFO:     Epoch: 0
2022-11-28 03:59:17,044 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5794695331606754, 'Total loss': 0.5794695331606754} | train loss {'Reaction outcome loss': 0.6974807415970068, 'Total loss': 0.6974807415970068}
2022-11-28 03:59:17,044 INFO:     Found new best model at epoch 0
2022-11-28 03:59:17,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:17,044 INFO:     Epoch: 1
2022-11-28 03:59:17,692 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5395570158265358, 'Total loss': 0.5395570158265358} | train loss {'Reaction outcome loss': 0.5830615863142681, 'Total loss': 0.5830615863142681}
2022-11-28 03:59:17,692 INFO:     Found new best model at epoch 1
2022-11-28 03:59:17,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:17,693 INFO:     Epoch: 2
2022-11-28 03:59:18,341 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48492560934188755, 'Total loss': 0.48492560934188755} | train loss {'Reaction outcome loss': 0.5508469130399296, 'Total loss': 0.5508469130399296}
2022-11-28 03:59:18,341 INFO:     Found new best model at epoch 2
2022-11-28 03:59:18,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:18,342 INFO:     Epoch: 3
2022-11-28 03:59:18,992 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5211981462184773, 'Total loss': 0.5211981462184773} | train loss {'Reaction outcome loss': 0.5243583960542954, 'Total loss': 0.5243583960542954}
2022-11-28 03:59:18,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:18,992 INFO:     Epoch: 4
2022-11-28 03:59:19,646 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46802240783391996, 'Total loss': 0.46802240783391996} | train loss {'Reaction outcome loss': 0.5091637357026951, 'Total loss': 0.5091637357026951}
2022-11-28 03:59:19,646 INFO:     Found new best model at epoch 4
2022-11-28 03:59:19,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:19,647 INFO:     Epoch: 5
2022-11-28 03:59:20,301 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.491162040205889, 'Total loss': 0.491162040205889} | train loss {'Reaction outcome loss': 0.5164285461598463, 'Total loss': 0.5164285461598463}
2022-11-28 03:59:20,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:20,301 INFO:     Epoch: 6
2022-11-28 03:59:20,951 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45486793978962786, 'Total loss': 0.45486793978962786} | train loss {'Reaction outcome loss': 0.49797335726979336, 'Total loss': 0.49797335726979336}
2022-11-28 03:59:20,951 INFO:     Found new best model at epoch 6
2022-11-28 03:59:20,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:20,952 INFO:     Epoch: 7
2022-11-28 03:59:21,600 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4488532428824624, 'Total loss': 0.4488532428824624} | train loss {'Reaction outcome loss': 0.48610461230385943, 'Total loss': 0.48610461230385943}
2022-11-28 03:59:21,600 INFO:     Found new best model at epoch 7
2022-11-28 03:59:21,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:21,601 INFO:     Epoch: 8
2022-11-28 03:59:22,249 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46799365309781804, 'Total loss': 0.46799365309781804} | train loss {'Reaction outcome loss': 0.49105051208916023, 'Total loss': 0.49105051208916023}
2022-11-28 03:59:22,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:22,249 INFO:     Epoch: 9
2022-11-28 03:59:22,897 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4640768697095472, 'Total loss': 0.4640768697095472} | train loss {'Reaction outcome loss': 0.48381916528621327, 'Total loss': 0.48381916528621327}
2022-11-28 03:59:22,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:22,897 INFO:     Epoch: 10
2022-11-28 03:59:23,545 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4320381242175435, 'Total loss': 0.4320381242175435} | train loss {'Reaction outcome loss': 0.4801474943941022, 'Total loss': 0.4801474943941022}
2022-11-28 03:59:23,546 INFO:     Found new best model at epoch 10
2022-11-28 03:59:23,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:23,547 INFO:     Epoch: 11
2022-11-28 03:59:24,195 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4396173590144446, 'Total loss': 0.4396173590144446} | train loss {'Reaction outcome loss': 0.47833497061896224, 'Total loss': 0.47833497061896224}
2022-11-28 03:59:24,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:24,196 INFO:     Epoch: 12
2022-11-28 03:59:24,844 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4553002035895059, 'Total loss': 0.4553002035895059} | train loss {'Reaction outcome loss': 0.46890075707141265, 'Total loss': 0.46890075707141265}
2022-11-28 03:59:24,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:24,844 INFO:     Epoch: 13
2022-11-28 03:59:25,493 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4498623141715693, 'Total loss': 0.4498623141715693} | train loss {'Reaction outcome loss': 0.4769165850715873, 'Total loss': 0.4769165850715873}
2022-11-28 03:59:25,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:25,493 INFO:     Epoch: 14
2022-11-28 03:59:26,141 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4544967395621677, 'Total loss': 0.4544967395621677} | train loss {'Reaction outcome loss': 0.4685829474816842, 'Total loss': 0.4685829474816842}
2022-11-28 03:59:26,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:26,141 INFO:     Epoch: 15
2022-11-28 03:59:26,788 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45652608538782874, 'Total loss': 0.45652608538782874} | train loss {'Reaction outcome loss': 0.4685097989844687, 'Total loss': 0.4685097989844687}
2022-11-28 03:59:26,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:26,788 INFO:     Epoch: 16
2022-11-28 03:59:27,434 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4736226041649663, 'Total loss': 0.4736226041649663} | train loss {'Reaction outcome loss': 0.46378474348366505, 'Total loss': 0.46378474348366505}
2022-11-28 03:59:27,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:27,435 INFO:     Epoch: 17
2022-11-28 03:59:28,085 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4643730444963588, 'Total loss': 0.4643730444963588} | train loss {'Reaction outcome loss': 0.4721826952671318, 'Total loss': 0.4721826952671318}
2022-11-28 03:59:28,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:28,086 INFO:     Epoch: 18
2022-11-28 03:59:28,732 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4676551569339841, 'Total loss': 0.4676551569339841} | train loss {'Reaction outcome loss': 0.4718126935478101, 'Total loss': 0.4718126935478101}
2022-11-28 03:59:28,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:28,732 INFO:     Epoch: 19
2022-11-28 03:59:29,381 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4270777598369953, 'Total loss': 0.4270777598369953} | train loss {'Reaction outcome loss': 0.4603258401400758, 'Total loss': 0.4603258401400758}
2022-11-28 03:59:29,381 INFO:     Found new best model at epoch 19
2022-11-28 03:59:29,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:29,382 INFO:     Epoch: 20
2022-11-28 03:59:30,034 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4697149749412093, 'Total loss': 0.4697149749412093} | train loss {'Reaction outcome loss': 0.46270230038421145, 'Total loss': 0.46270230038421145}
2022-11-28 03:59:30,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:30,034 INFO:     Epoch: 21
2022-11-28 03:59:30,681 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44007666616938834, 'Total loss': 0.44007666616938834} | train loss {'Reaction outcome loss': 0.46538415023819407, 'Total loss': 0.46538415023819407}
2022-11-28 03:59:30,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:30,681 INFO:     Epoch: 22
2022-11-28 03:59:31,331 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4477261738028637, 'Total loss': 0.4477261738028637} | train loss {'Reaction outcome loss': 0.4641875986454418, 'Total loss': 0.4641875986454418}
2022-11-28 03:59:31,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:31,331 INFO:     Epoch: 23
2022-11-28 03:59:31,983 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4426419939412627, 'Total loss': 0.4426419939412627} | train loss {'Reaction outcome loss': 0.46699725723070373, 'Total loss': 0.46699725723070373}
2022-11-28 03:59:31,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:31,983 INFO:     Epoch: 24
2022-11-28 03:59:32,634 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46417337725328844, 'Total loss': 0.46417337725328844} | train loss {'Reaction outcome loss': 0.4666732360183457, 'Total loss': 0.4666732360183457}
2022-11-28 03:59:32,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:32,635 INFO:     Epoch: 25
2022-11-28 03:59:33,287 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44300720996634907, 'Total loss': 0.44300720996634907} | train loss {'Reaction outcome loss': 0.461763319900497, 'Total loss': 0.461763319900497}
2022-11-28 03:59:33,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:33,288 INFO:     Epoch: 26
2022-11-28 03:59:33,936 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4888813436724419, 'Total loss': 0.4888813436724419} | train loss {'Reaction outcome loss': 0.4586309593155551, 'Total loss': 0.4586309593155551}
2022-11-28 03:59:33,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:33,937 INFO:     Epoch: 27
2022-11-28 03:59:34,586 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4457744082739187, 'Total loss': 0.4457744082739187} | train loss {'Reaction outcome loss': 0.4675866378923502, 'Total loss': 0.4675866378923502}
2022-11-28 03:59:34,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:34,586 INFO:     Epoch: 28
2022-11-28 03:59:35,236 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4374427161244459, 'Total loss': 0.4374427161244459} | train loss {'Reaction outcome loss': 0.4634065456351135, 'Total loss': 0.4634065456351135}
2022-11-28 03:59:35,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:35,236 INFO:     Epoch: 29
2022-11-28 03:59:35,885 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46420397106991257, 'Total loss': 0.46420397106991257} | train loss {'Reaction outcome loss': 0.45612283927913555, 'Total loss': 0.45612283927913555}
2022-11-28 03:59:35,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:35,886 INFO:     Epoch: 30
2022-11-28 03:59:36,537 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4424841109403344, 'Total loss': 0.4424841109403344} | train loss {'Reaction outcome loss': 0.4609825083135087, 'Total loss': 0.4609825083135087}
2022-11-28 03:59:36,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:36,537 INFO:     Epoch: 31
2022-11-28 03:59:37,188 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4646714003973229, 'Total loss': 0.4646714003973229} | train loss {'Reaction outcome loss': 0.4686828331079012, 'Total loss': 0.4686828331079012}
2022-11-28 03:59:37,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:37,188 INFO:     Epoch: 32
2022-11-28 03:59:37,840 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4456251045299131, 'Total loss': 0.4456251045299131} | train loss {'Reaction outcome loss': 0.4691323384090706, 'Total loss': 0.4691323384090706}
2022-11-28 03:59:37,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:37,840 INFO:     Epoch: 33
2022-11-28 03:59:38,488 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4590522948392602, 'Total loss': 0.4590522948392602} | train loss {'Reaction outcome loss': 0.4701487344110944, 'Total loss': 0.4701487344110944}
2022-11-28 03:59:38,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:38,488 INFO:     Epoch: 34
2022-11-28 03:59:39,141 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43786492389301923, 'Total loss': 0.43786492389301923} | train loss {'Reaction outcome loss': 0.4655298661179994, 'Total loss': 0.4655298661179994}
2022-11-28 03:59:39,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:39,141 INFO:     Epoch: 35
2022-11-28 03:59:39,792 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4365204960800881, 'Total loss': 0.4365204960800881} | train loss {'Reaction outcome loss': 0.4627165428895519, 'Total loss': 0.4627165428895519}
2022-11-28 03:59:39,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:39,793 INFO:     Epoch: 36
2022-11-28 03:59:40,441 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44207776528458265, 'Total loss': 0.44207776528458265} | train loss {'Reaction outcome loss': 0.4629549732424104, 'Total loss': 0.4629549732424104}
2022-11-28 03:59:40,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:40,441 INFO:     Epoch: 37
2022-11-28 03:59:41,086 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44481216977502025, 'Total loss': 0.44481216977502025} | train loss {'Reaction outcome loss': 0.46294033996484896, 'Total loss': 0.46294033996484896}
2022-11-28 03:59:41,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:41,086 INFO:     Epoch: 38
2022-11-28 03:59:41,733 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.480621348286784, 'Total loss': 0.480621348286784} | train loss {'Reaction outcome loss': 0.4567296455303828, 'Total loss': 0.4567296455303828}
2022-11-28 03:59:41,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:41,734 INFO:     Epoch: 39
2022-11-28 03:59:42,383 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44494523939698244, 'Total loss': 0.44494523939698244} | train loss {'Reaction outcome loss': 0.4678708058571129, 'Total loss': 0.4678708058571129}
2022-11-28 03:59:42,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:42,384 INFO:     Epoch: 40
2022-11-28 03:59:43,028 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44930838568266046, 'Total loss': 0.44930838568266046} | train loss {'Reaction outcome loss': 0.4638704642224214, 'Total loss': 0.4638704642224214}
2022-11-28 03:59:43,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:43,028 INFO:     Epoch: 41
2022-11-28 03:59:43,675 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4346175235371257, 'Total loss': 0.4346175235371257} | train loss {'Reaction outcome loss': 0.4673432640332744, 'Total loss': 0.4673432640332744}
2022-11-28 03:59:43,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:43,676 INFO:     Epoch: 42
2022-11-28 03:59:44,319 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4474421289078025, 'Total loss': 0.4474421289078025} | train loss {'Reaction outcome loss': 0.46030088216679577, 'Total loss': 0.46030088216679577}
2022-11-28 03:59:44,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:44,319 INFO:     Epoch: 43
2022-11-28 03:59:44,964 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4383170791836672, 'Total loss': 0.4383170791836672} | train loss {'Reaction outcome loss': 0.46016056854047893, 'Total loss': 0.46016056854047893}
2022-11-28 03:59:44,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:44,965 INFO:     Epoch: 44
2022-11-28 03:59:45,604 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4445646654727847, 'Total loss': 0.4445646654727847} | train loss {'Reaction outcome loss': 0.4605646714675451, 'Total loss': 0.4605646714675451}
2022-11-28 03:59:45,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:45,604 INFO:     Epoch: 45
2022-11-28 03:59:46,247 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44522481567637867, 'Total loss': 0.44522481567637867} | train loss {'Reaction outcome loss': 0.4592853269459289, 'Total loss': 0.4592853269459289}
2022-11-28 03:59:46,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:46,247 INFO:     Epoch: 46
2022-11-28 03:59:46,889 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43285641316757645, 'Total loss': 0.43285641316757645} | train loss {'Reaction outcome loss': 0.46439896444234335, 'Total loss': 0.46439896444234335}
2022-11-28 03:59:46,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:46,889 INFO:     Epoch: 47
2022-11-28 03:59:47,535 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4470063579636951, 'Total loss': 0.4470063579636951} | train loss {'Reaction outcome loss': 0.46608302408039815, 'Total loss': 0.46608302408039815}
2022-11-28 03:59:47,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:47,536 INFO:     Epoch: 48
2022-11-28 03:59:48,180 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45540432770584904, 'Total loss': 0.45540432770584904} | train loss {'Reaction outcome loss': 0.4629004787147781, 'Total loss': 0.4629004787147781}
2022-11-28 03:59:48,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:48,181 INFO:     Epoch: 49
2022-11-28 03:59:48,826 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4466471892110137, 'Total loss': 0.4466471892110137} | train loss {'Reaction outcome loss': 0.4633990578935961, 'Total loss': 0.4633990578935961}
2022-11-28 03:59:48,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:48,826 INFO:     Epoch: 50
2022-11-28 03:59:49,470 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4882511122282161, 'Total loss': 0.4882511122282161} | train loss {'Reaction outcome loss': 0.462332909551177, 'Total loss': 0.462332909551177}
2022-11-28 03:59:49,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:49,470 INFO:     Epoch: 51
2022-11-28 03:59:50,117 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44530437193637673, 'Total loss': 0.44530437193637673} | train loss {'Reaction outcome loss': 0.4656229416835946, 'Total loss': 0.4656229416835946}
2022-11-28 03:59:50,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:50,117 INFO:     Epoch: 52
2022-11-28 03:59:50,763 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4729611333026442, 'Total loss': 0.4729611333026442} | train loss {'Reaction outcome loss': 0.462471329013016, 'Total loss': 0.462471329013016}
2022-11-28 03:59:50,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:50,763 INFO:     Epoch: 53
2022-11-28 03:59:51,409 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4329178766455761, 'Total loss': 0.4329178766455761} | train loss {'Reaction outcome loss': 0.46366365315246977, 'Total loss': 0.46366365315246977}
2022-11-28 03:59:51,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:51,410 INFO:     Epoch: 54
2022-11-28 03:59:52,053 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4356750915216845, 'Total loss': 0.4356750915216845} | train loss {'Reaction outcome loss': 0.46235564645425775, 'Total loss': 0.46235564645425775}
2022-11-28 03:59:52,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:52,053 INFO:     Epoch: 55
2022-11-28 03:59:52,695 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4439711740543676, 'Total loss': 0.4439711740543676} | train loss {'Reaction outcome loss': 0.46532623187749966, 'Total loss': 0.46532623187749966}
2022-11-28 03:59:52,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:52,695 INFO:     Epoch: 56
2022-11-28 03:59:53,339 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44237757248933923, 'Total loss': 0.44237757248933923} | train loss {'Reaction outcome loss': 0.45895344730267307, 'Total loss': 0.45895344730267307}
2022-11-28 03:59:53,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:53,339 INFO:     Epoch: 57
2022-11-28 03:59:53,985 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4461836142595424, 'Total loss': 0.4461836142595424} | train loss {'Reaction outcome loss': 0.4633570466757802, 'Total loss': 0.4633570466757802}
2022-11-28 03:59:53,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:53,985 INFO:     Epoch: 58
2022-11-28 03:59:54,631 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43714866007483283, 'Total loss': 0.43714866007483283} | train loss {'Reaction outcome loss': 0.46912787535798894, 'Total loss': 0.46912787535798894}
2022-11-28 03:59:54,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:54,632 INFO:     Epoch: 59
2022-11-28 03:59:55,277 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45216346653394923, 'Total loss': 0.45216346653394923} | train loss {'Reaction outcome loss': 0.4603418051092713, 'Total loss': 0.4603418051092713}
2022-11-28 03:59:55,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:55,277 INFO:     Epoch: 60
2022-11-28 03:59:55,921 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43889876437741654, 'Total loss': 0.43889876437741654} | train loss {'Reaction outcome loss': 0.4644051036900944, 'Total loss': 0.4644051036900944}
2022-11-28 03:59:55,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:55,921 INFO:     Epoch: 61
2022-11-28 03:59:56,568 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4527242693097092, 'Total loss': 0.4527242693097092} | train loss {'Reaction outcome loss': 0.46409865385956234, 'Total loss': 0.46409865385956234}
2022-11-28 03:59:56,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:56,568 INFO:     Epoch: 62
2022-11-28 03:59:57,212 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4479219546151716, 'Total loss': 0.4479219546151716} | train loss {'Reaction outcome loss': 0.46146182824738724, 'Total loss': 0.46146182824738724}
2022-11-28 03:59:57,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:57,212 INFO:     Epoch: 63
2022-11-28 03:59:57,856 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4495031708894774, 'Total loss': 0.4495031708894774} | train loss {'Reaction outcome loss': 0.4677379646419007, 'Total loss': 0.4677379646419007}
2022-11-28 03:59:57,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:57,856 INFO:     Epoch: 64
2022-11-28 03:59:58,502 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4400728171647981, 'Total loss': 0.4400728171647981} | train loss {'Reaction outcome loss': 0.4622184276090237, 'Total loss': 0.4622184276090237}
2022-11-28 03:59:58,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:58,502 INFO:     Epoch: 65
2022-11-28 03:59:59,148 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4502903028976086, 'Total loss': 0.4502903028976086} | train loss {'Reaction outcome loss': 0.4590300599979275, 'Total loss': 0.4590300599979275}
2022-11-28 03:59:59,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:59,148 INFO:     Epoch: 66
2022-11-28 03:59:59,792 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43638166681278584, 'Total loss': 0.43638166681278584} | train loss {'Reaction outcome loss': 0.4621019407554909, 'Total loss': 0.4621019407554909}
2022-11-28 03:59:59,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 03:59:59,792 INFO:     Epoch: 67
2022-11-28 04:00:00,436 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.434118426816408, 'Total loss': 0.434118426816408} | train loss {'Reaction outcome loss': 0.46922130649717747, 'Total loss': 0.46922130649717747}
2022-11-28 04:00:00,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:00,436 INFO:     Epoch: 68
2022-11-28 04:00:01,081 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4299418195042499, 'Total loss': 0.4299418195042499} | train loss {'Reaction outcome loss': 0.46900723917494097, 'Total loss': 0.46900723917494097}
2022-11-28 04:00:01,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:01,081 INFO:     Epoch: 69
2022-11-28 04:00:01,724 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4382992726425792, 'Total loss': 0.4382992726425792} | train loss {'Reaction outcome loss': 0.4650338602409441, 'Total loss': 0.4650338602409441}
2022-11-28 04:00:01,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:01,724 INFO:     Epoch: 70
2022-11-28 04:00:02,368 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.461820991926415, 'Total loss': 0.461820991926415} | train loss {'Reaction outcome loss': 0.46559451955826686, 'Total loss': 0.46559451955826686}
2022-11-28 04:00:02,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:02,369 INFO:     Epoch: 71
2022-11-28 04:00:03,009 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5355982801248861, 'Total loss': 0.5355982801248861} | train loss {'Reaction outcome loss': 0.4651319651324072, 'Total loss': 0.4651319651324072}
2022-11-28 04:00:03,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:03,009 INFO:     Epoch: 72
2022-11-28 04:00:03,653 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4374805467073308, 'Total loss': 0.4374805467073308} | train loss {'Reaction outcome loss': 0.4634471185536051, 'Total loss': 0.4634471185536051}
2022-11-28 04:00:03,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:03,653 INFO:     Epoch: 73
2022-11-28 04:00:04,298 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45720371534658033, 'Total loss': 0.45720371534658033} | train loss {'Reaction outcome loss': 0.4623773033910818, 'Total loss': 0.4623773033910818}
2022-11-28 04:00:04,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:04,298 INFO:     Epoch: 74
2022-11-28 04:00:04,944 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4639839505733446, 'Total loss': 0.4639839505733446} | train loss {'Reaction outcome loss': 0.45968822153752725, 'Total loss': 0.45968822153752725}
2022-11-28 04:00:04,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:04,944 INFO:     Epoch: 75
2022-11-28 04:00:05,590 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45024521510268367, 'Total loss': 0.45024521510268367} | train loss {'Reaction outcome loss': 0.4591396226252548, 'Total loss': 0.4591396226252548}
2022-11-28 04:00:05,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:05,590 INFO:     Epoch: 76
2022-11-28 04:00:06,233 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4894457151030385, 'Total loss': 0.4894457151030385} | train loss {'Reaction outcome loss': 0.462024188152066, 'Total loss': 0.462024188152066}
2022-11-28 04:00:06,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:06,233 INFO:     Epoch: 77
2022-11-28 04:00:06,878 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4628628381462984, 'Total loss': 0.4628628381462984} | train loss {'Reaction outcome loss': 0.46114235147527216, 'Total loss': 0.46114235147527216}
2022-11-28 04:00:06,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:06,879 INFO:     Epoch: 78
2022-11-28 04:00:07,519 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45060804763505624, 'Total loss': 0.45060804763505624} | train loss {'Reaction outcome loss': 0.4700285882493596, 'Total loss': 0.4700285882493596}
2022-11-28 04:00:07,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:07,520 INFO:     Epoch: 79
2022-11-28 04:00:08,167 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45605103810166203, 'Total loss': 0.45605103810166203} | train loss {'Reaction outcome loss': 0.46103402181172076, 'Total loss': 0.46103402181172076}
2022-11-28 04:00:08,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:08,167 INFO:     Epoch: 80
2022-11-28 04:00:08,811 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44414017990578053, 'Total loss': 0.44414017990578053} | train loss {'Reaction outcome loss': 0.465507407124641, 'Total loss': 0.465507407124641}
2022-11-28 04:00:08,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:08,811 INFO:     Epoch: 81
2022-11-28 04:00:09,455 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46177451000657194, 'Total loss': 0.46177451000657194} | train loss {'Reaction outcome loss': 0.467310785971306, 'Total loss': 0.467310785971306}
2022-11-28 04:00:09,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:09,455 INFO:     Epoch: 82
2022-11-28 04:00:10,098 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4637917158908622, 'Total loss': 0.4637917158908622} | train loss {'Reaction outcome loss': 0.4599654551273511, 'Total loss': 0.4599654551273511}
2022-11-28 04:00:10,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:10,098 INFO:     Epoch: 83
2022-11-28 04:00:10,742 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44767163208750793, 'Total loss': 0.44767163208750793} | train loss {'Reaction outcome loss': 0.462844045380506, 'Total loss': 0.462844045380506}
2022-11-28 04:00:10,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:10,742 INFO:     Epoch: 84
2022-11-28 04:00:11,384 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42201716400856193, 'Total loss': 0.42201716400856193} | train loss {'Reaction outcome loss': 0.4655137995081674, 'Total loss': 0.4655137995081674}
2022-11-28 04:00:11,384 INFO:     Found new best model at epoch 84
2022-11-28 04:00:11,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:11,385 INFO:     Epoch: 85
2022-11-28 04:00:12,030 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4842199024765991, 'Total loss': 0.4842199024765991} | train loss {'Reaction outcome loss': 0.4694889336824417, 'Total loss': 0.4694889336824417}
2022-11-28 04:00:12,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:12,030 INFO:     Epoch: 86
2022-11-28 04:00:12,675 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44039839887341786, 'Total loss': 0.44039839887341786} | train loss {'Reaction outcome loss': 0.46417955471654976, 'Total loss': 0.46417955471654976}
2022-11-28 04:00:12,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:12,676 INFO:     Epoch: 87
2022-11-28 04:00:13,319 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43686318744060604, 'Total loss': 0.43686318744060604} | train loss {'Reaction outcome loss': 0.4572213453397829, 'Total loss': 0.4572213453397829}
2022-11-28 04:00:13,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:13,320 INFO:     Epoch: 88
2022-11-28 04:00:13,965 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43790670085785, 'Total loss': 0.43790670085785} | train loss {'Reaction outcome loss': 0.46536049032162247, 'Total loss': 0.46536049032162247}
2022-11-28 04:00:13,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:13,965 INFO:     Epoch: 89
2022-11-28 04:00:14,606 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.444763786917509, 'Total loss': 0.444763786917509} | train loss {'Reaction outcome loss': 0.4733532621475404, 'Total loss': 0.4733532621475404}
2022-11-28 04:00:14,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:14,606 INFO:     Epoch: 90
2022-11-28 04:00:15,249 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4409309043440708, 'Total loss': 0.4409309043440708} | train loss {'Reaction outcome loss': 0.46557819892349556, 'Total loss': 0.46557819892349556}
2022-11-28 04:00:15,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:15,249 INFO:     Epoch: 91
2022-11-28 04:00:15,893 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.469535909419836, 'Total loss': 0.469535909419836} | train loss {'Reaction outcome loss': 0.4605698449376189, 'Total loss': 0.4605698449376189}
2022-11-28 04:00:15,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:15,893 INFO:     Epoch: 92
2022-11-28 04:00:16,536 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45003927516382797, 'Total loss': 0.45003927516382797} | train loss {'Reaction outcome loss': 0.46725618127932766, 'Total loss': 0.46725618127932766}
2022-11-28 04:00:16,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:16,537 INFO:     Epoch: 93
2022-11-28 04:00:17,182 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44341420988703883, 'Total loss': 0.44341420988703883} | train loss {'Reaction outcome loss': 0.46924644451082487, 'Total loss': 0.46924644451082487}
2022-11-28 04:00:17,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:17,182 INFO:     Epoch: 94
2022-11-28 04:00:17,826 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4456191340158152, 'Total loss': 0.4456191340158152} | train loss {'Reaction outcome loss': 0.4686077223025232, 'Total loss': 0.4686077223025232}
2022-11-28 04:00:17,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:17,826 INFO:     Epoch: 95
2022-11-28 04:00:18,473 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4374561223179795, 'Total loss': 0.4374561223179795} | train loss {'Reaction outcome loss': 0.46437691354457244, 'Total loss': 0.46437691354457244}
2022-11-28 04:00:18,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:18,473 INFO:     Epoch: 96
2022-11-28 04:00:19,115 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4550309919340666, 'Total loss': 0.4550309919340666} | train loss {'Reaction outcome loss': 0.4548074906622922, 'Total loss': 0.4548074906622922}
2022-11-28 04:00:19,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:19,115 INFO:     Epoch: 97
2022-11-28 04:00:19,758 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45170639316703, 'Total loss': 0.45170639316703} | train loss {'Reaction outcome loss': 0.46251961104418515, 'Total loss': 0.46251961104418515}
2022-11-28 04:00:19,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:19,758 INFO:     Epoch: 98
2022-11-28 04:00:20,405 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.435955660287724, 'Total loss': 0.435955660287724} | train loss {'Reaction outcome loss': 0.46087708897551394, 'Total loss': 0.46087708897551394}
2022-11-28 04:00:20,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:20,405 INFO:     Epoch: 99
2022-11-28 04:00:21,053 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46875238557194554, 'Total loss': 0.46875238557194554} | train loss {'Reaction outcome loss': 0.4644683093568425, 'Total loss': 0.4644683093568425}
2022-11-28 04:00:21,053 INFO:     Best model found after epoch 85 of 100.
2022-11-28 04:00:21,053 INFO:   Done with stage: TRAINING
2022-11-28 04:00:21,054 INFO:   Starting stage: EVALUATION
2022-11-28 04:00:21,189 INFO:   Done with stage: EVALUATION
2022-11-28 04:00:21,190 INFO:   Leaving out SEQ value Fold_1
2022-11-28 04:00:21,203 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:00:21,203 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:00:21,845 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:00:21,845 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:00:21,912 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:00:21,913 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:00:21,913 INFO:     No hyperparam tuning for this model
2022-11-28 04:00:21,913 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:00:21,913 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:00:21,914 INFO:     None feature selector for col prot
2022-11-28 04:00:21,914 INFO:     None feature selector for col prot
2022-11-28 04:00:21,914 INFO:     None feature selector for col prot
2022-11-28 04:00:21,914 INFO:     None feature selector for col chem
2022-11-28 04:00:21,914 INFO:     None feature selector for col chem
2022-11-28 04:00:21,914 INFO:     None feature selector for col chem
2022-11-28 04:00:21,915 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:00:21,915 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:00:21,916 INFO:     Number of params in model 169651
2022-11-28 04:00:21,919 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:00:21,919 INFO:   Starting stage: TRAINING
2022-11-28 04:00:21,970 INFO:     Val loss before train {'Reaction outcome loss': 1.0409880443052812, 'Total loss': 1.0409880443052812}
2022-11-28 04:00:21,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:21,970 INFO:     Epoch: 0
2022-11-28 04:00:22,629 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5993613837794824, 'Total loss': 0.5993613837794824} | train loss {'Reaction outcome loss': 0.7031697728614575, 'Total loss': 0.7031697728614575}
2022-11-28 04:00:22,629 INFO:     Found new best model at epoch 0
2022-11-28 04:00:22,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:22,630 INFO:     Epoch: 1
2022-11-28 04:00:23,289 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5954348661682822, 'Total loss': 0.5954348661682822} | train loss {'Reaction outcome loss': 0.5997638125651279, 'Total loss': 0.5997638125651279}
2022-11-28 04:00:23,290 INFO:     Found new best model at epoch 1
2022-11-28 04:00:23,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:23,290 INFO:     Epoch: 2
2022-11-28 04:00:23,948 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5266797136176716, 'Total loss': 0.5266797136176716} | train loss {'Reaction outcome loss': 0.5621471547404764, 'Total loss': 0.5621471547404764}
2022-11-28 04:00:23,948 INFO:     Found new best model at epoch 2
2022-11-28 04:00:23,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:23,949 INFO:     Epoch: 3
2022-11-28 04:00:24,609 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5206004259261218, 'Total loss': 0.5206004259261218} | train loss {'Reaction outcome loss': 0.5475000768658603, 'Total loss': 0.5475000768658603}
2022-11-28 04:00:24,609 INFO:     Found new best model at epoch 3
2022-11-28 04:00:24,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:24,609 INFO:     Epoch: 4
2022-11-28 04:00:25,268 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5102307694879445, 'Total loss': 0.5102307694879445} | train loss {'Reaction outcome loss': 0.5318048172875455, 'Total loss': 0.5318048172875455}
2022-11-28 04:00:25,268 INFO:     Found new best model at epoch 4
2022-11-28 04:00:25,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:25,268 INFO:     Epoch: 5
2022-11-28 04:00:25,927 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5475708611986854, 'Total loss': 0.5475708611986854} | train loss {'Reaction outcome loss': 0.5337018687956729, 'Total loss': 0.5337018687956729}
2022-11-28 04:00:25,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:25,928 INFO:     Epoch: 6
2022-11-28 04:00:26,586 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48674011332067574, 'Total loss': 0.48674011332067574} | train loss {'Reaction outcome loss': 0.5238816663962205, 'Total loss': 0.5238816663962205}
2022-11-28 04:00:26,586 INFO:     Found new best model at epoch 6
2022-11-28 04:00:26,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:26,587 INFO:     Epoch: 7
2022-11-28 04:00:27,245 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47771447050300514, 'Total loss': 0.47771447050300514} | train loss {'Reaction outcome loss': 0.5122675170541292, 'Total loss': 0.5122675170541292}
2022-11-28 04:00:27,245 INFO:     Found new best model at epoch 7
2022-11-28 04:00:27,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:27,245 INFO:     Epoch: 8
2022-11-28 04:00:27,906 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48784599554809654, 'Total loss': 0.48784599554809654} | train loss {'Reaction outcome loss': 0.5186896325062643, 'Total loss': 0.5186896325062643}
2022-11-28 04:00:27,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:27,906 INFO:     Epoch: 9
2022-11-28 04:00:28,568 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47201266105879436, 'Total loss': 0.47201266105879436} | train loss {'Reaction outcome loss': 0.5007535340198456, 'Total loss': 0.5007535340198456}
2022-11-28 04:00:28,568 INFO:     Found new best model at epoch 9
2022-11-28 04:00:28,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:28,569 INFO:     Epoch: 10
2022-11-28 04:00:29,229 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4631048393520442, 'Total loss': 0.4631048393520442} | train loss {'Reaction outcome loss': 0.4946081630191822, 'Total loss': 0.4946081630191822}
2022-11-28 04:00:29,229 INFO:     Found new best model at epoch 10
2022-11-28 04:00:29,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:29,230 INFO:     Epoch: 11
2022-11-28 04:00:29,891 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4960347867824815, 'Total loss': 0.4960347867824815} | train loss {'Reaction outcome loss': 0.5065306153465138, 'Total loss': 0.5065306153465138}
2022-11-28 04:00:29,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:29,892 INFO:     Epoch: 12
2022-11-28 04:00:30,551 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.482803731479428, 'Total loss': 0.482803731479428} | train loss {'Reaction outcome loss': 0.4966733292167486, 'Total loss': 0.4966733292167486}
2022-11-28 04:00:30,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:30,551 INFO:     Epoch: 13
2022-11-28 04:00:31,209 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4699356403540481, 'Total loss': 0.4699356403540481} | train loss {'Reaction outcome loss': 0.5007451266947727, 'Total loss': 0.5007451266947727}
2022-11-28 04:00:31,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:31,210 INFO:     Epoch: 14
2022-11-28 04:00:31,871 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4758437553589994, 'Total loss': 0.4758437553589994} | train loss {'Reaction outcome loss': 0.4969140480645755, 'Total loss': 0.4969140480645755}
2022-11-28 04:00:31,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:31,871 INFO:     Epoch: 15
2022-11-28 04:00:32,528 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46040907739238307, 'Total loss': 0.46040907739238307} | train loss {'Reaction outcome loss': 0.4966182213065475, 'Total loss': 0.4966182213065475}
2022-11-28 04:00:32,528 INFO:     Found new best model at epoch 15
2022-11-28 04:00:32,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:32,529 INFO:     Epoch: 16
2022-11-28 04:00:33,187 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45765514502471144, 'Total loss': 0.45765514502471144} | train loss {'Reaction outcome loss': 0.48871181213753184, 'Total loss': 0.48871181213753184}
2022-11-28 04:00:33,187 INFO:     Found new best model at epoch 16
2022-11-28 04:00:33,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:33,188 INFO:     Epoch: 17
2022-11-28 04:00:33,849 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.463395970788869, 'Total loss': 0.463395970788869} | train loss {'Reaction outcome loss': 0.48253343756280476, 'Total loss': 0.48253343756280476}
2022-11-28 04:00:33,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:33,849 INFO:     Epoch: 18
2022-11-28 04:00:34,508 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47034461152824486, 'Total loss': 0.47034461152824486} | train loss {'Reaction outcome loss': 0.48531165145910704, 'Total loss': 0.48531165145910704}
2022-11-28 04:00:34,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:34,508 INFO:     Epoch: 19
2022-11-28 04:00:35,166 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4590487185526978, 'Total loss': 0.4590487185526978} | train loss {'Reaction outcome loss': 0.47609115310526084, 'Total loss': 0.47609115310526084}
2022-11-28 04:00:35,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:35,166 INFO:     Epoch: 20
2022-11-28 04:00:35,822 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4620269990780137, 'Total loss': 0.4620269990780137} | train loss {'Reaction outcome loss': 0.4825927185927808, 'Total loss': 0.4825927185927808}
2022-11-28 04:00:35,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:35,822 INFO:     Epoch: 21
2022-11-28 04:00:36,483 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4426553828472441, 'Total loss': 0.4426553828472441} | train loss {'Reaction outcome loss': 0.4865837111043544, 'Total loss': 0.4865837111043544}
2022-11-28 04:00:36,483 INFO:     Found new best model at epoch 21
2022-11-28 04:00:36,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:36,483 INFO:     Epoch: 22
2022-11-28 04:00:37,142 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4717088019983335, 'Total loss': 0.4717088019983335} | train loss {'Reaction outcome loss': 0.4873461095910323, 'Total loss': 0.4873461095910323}
2022-11-28 04:00:37,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:37,142 INFO:     Epoch: 23
2022-11-28 04:00:37,799 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47697149081663653, 'Total loss': 0.47697149081663653} | train loss {'Reaction outcome loss': 0.47708363295627026, 'Total loss': 0.47708363295627026}
2022-11-28 04:00:37,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:37,800 INFO:     Epoch: 24
2022-11-28 04:00:38,459 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5083660293709148, 'Total loss': 0.5083660293709148} | train loss {'Reaction outcome loss': 0.48149319566213167, 'Total loss': 0.48149319566213167}
2022-11-28 04:00:38,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:38,459 INFO:     Epoch: 25
2022-11-28 04:00:39,120 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5667310733009469, 'Total loss': 0.5667310733009469} | train loss {'Reaction outcome loss': 0.48543135978249446, 'Total loss': 0.48543135978249446}
2022-11-28 04:00:39,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:39,121 INFO:     Epoch: 26
2022-11-28 04:00:39,781 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43944530527700076, 'Total loss': 0.43944530527700076} | train loss {'Reaction outcome loss': 0.4766229464321846, 'Total loss': 0.4766229464321846}
2022-11-28 04:00:39,781 INFO:     Found new best model at epoch 26
2022-11-28 04:00:39,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:39,782 INFO:     Epoch: 27
2022-11-28 04:00:40,440 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4395816834135489, 'Total loss': 0.4395816834135489} | train loss {'Reaction outcome loss': 0.4744739661573881, 'Total loss': 0.4744739661573881}
2022-11-28 04:00:40,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:40,440 INFO:     Epoch: 28
2022-11-28 04:00:41,100 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46664174036546185, 'Total loss': 0.46664174036546185} | train loss {'Reaction outcome loss': 0.48219784268890675, 'Total loss': 0.48219784268890675}
2022-11-28 04:00:41,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:41,101 INFO:     Epoch: 29
2022-11-28 04:00:41,761 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4949421418661421, 'Total loss': 0.4949421418661421} | train loss {'Reaction outcome loss': 0.47473985686717246, 'Total loss': 0.47473985686717246}
2022-11-28 04:00:41,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:41,761 INFO:     Epoch: 30
2022-11-28 04:00:42,422 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4871643605557355, 'Total loss': 0.4871643605557355} | train loss {'Reaction outcome loss': 0.4806341775636441, 'Total loss': 0.4806341775636441}
2022-11-28 04:00:42,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:42,422 INFO:     Epoch: 31
2022-11-28 04:00:43,084 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4312697723507881, 'Total loss': 0.4312697723507881} | train loss {'Reaction outcome loss': 0.48310069522635657, 'Total loss': 0.48310069522635657}
2022-11-28 04:00:43,084 INFO:     Found new best model at epoch 31
2022-11-28 04:00:43,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:43,085 INFO:     Epoch: 32
2022-11-28 04:00:43,747 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4440560784529556, 'Total loss': 0.4440560784529556} | train loss {'Reaction outcome loss': 0.49002147306073535, 'Total loss': 0.49002147306073535}
2022-11-28 04:00:43,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:43,747 INFO:     Epoch: 33
2022-11-28 04:00:44,409 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46255301040681923, 'Total loss': 0.46255301040681923} | train loss {'Reaction outcome loss': 0.4851417133682652, 'Total loss': 0.4851417133682652}
2022-11-28 04:00:44,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:44,410 INFO:     Epoch: 34
2022-11-28 04:00:45,069 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4559214257381179, 'Total loss': 0.4559214257381179} | train loss {'Reaction outcome loss': 0.4735273808221567, 'Total loss': 0.4735273808221567}
2022-11-28 04:00:45,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:45,070 INFO:     Epoch: 35
2022-11-28 04:00:45,728 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5049566880545833, 'Total loss': 0.5049566880545833} | train loss {'Reaction outcome loss': 0.4716992815013839, 'Total loss': 0.4716992815013839}
2022-11-28 04:00:45,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:45,729 INFO:     Epoch: 36
2022-11-28 04:00:46,390 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4596481797370044, 'Total loss': 0.4596481797370044} | train loss {'Reaction outcome loss': 0.48470270464777465, 'Total loss': 0.48470270464777465}
2022-11-28 04:00:46,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:46,391 INFO:     Epoch: 37
2022-11-28 04:00:47,050 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4937611283226447, 'Total loss': 0.4937611283226447} | train loss {'Reaction outcome loss': 0.4864897200694451, 'Total loss': 0.4864897200694451}
2022-11-28 04:00:47,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:47,050 INFO:     Epoch: 38
2022-11-28 04:00:47,708 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4622677947309884, 'Total loss': 0.4622677947309884} | train loss {'Reaction outcome loss': 0.48293872527318144, 'Total loss': 0.48293872527318144}
2022-11-28 04:00:47,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:47,709 INFO:     Epoch: 39
2022-11-28 04:00:48,368 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5149929706345905, 'Total loss': 0.5149929706345905} | train loss {'Reaction outcome loss': 0.4763550323392698, 'Total loss': 0.4763550323392698}
2022-11-28 04:00:48,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:48,368 INFO:     Epoch: 40
2022-11-28 04:00:49,029 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4385934468697418, 'Total loss': 0.4385934468697418} | train loss {'Reaction outcome loss': 0.48232053089057386, 'Total loss': 0.48232053089057386}
2022-11-28 04:00:49,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:49,030 INFO:     Epoch: 41
2022-11-28 04:00:49,690 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4591995044188066, 'Total loss': 0.4591995044188066} | train loss {'Reaction outcome loss': 0.47469854131642625, 'Total loss': 0.47469854131642625}
2022-11-28 04:00:49,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:49,690 INFO:     Epoch: 42
2022-11-28 04:00:50,351 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45234571905298665, 'Total loss': 0.45234571905298665} | train loss {'Reaction outcome loss': 0.47330811776612935, 'Total loss': 0.47330811776612935}
2022-11-28 04:00:50,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:50,351 INFO:     Epoch: 43
2022-11-28 04:00:51,011 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45794984766028146, 'Total loss': 0.45794984766028146} | train loss {'Reaction outcome loss': 0.4837130366971618, 'Total loss': 0.4837130366971618}
2022-11-28 04:00:51,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:51,012 INFO:     Epoch: 44
2022-11-28 04:00:51,672 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5044311596588655, 'Total loss': 0.5044311596588655} | train loss {'Reaction outcome loss': 0.4739733215888985, 'Total loss': 0.4739733215888985}
2022-11-28 04:00:51,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:51,672 INFO:     Epoch: 45
2022-11-28 04:00:52,335 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4748692505738952, 'Total loss': 0.4748692505738952} | train loss {'Reaction outcome loss': 0.4852248257109028, 'Total loss': 0.4852248257109028}
2022-11-28 04:00:52,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:52,335 INFO:     Epoch: 46
2022-11-28 04:00:52,995 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5095886141061783, 'Total loss': 0.5095886141061783} | train loss {'Reaction outcome loss': 0.48609167403779047, 'Total loss': 0.48609167403779047}
2022-11-28 04:00:52,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:52,995 INFO:     Epoch: 47
2022-11-28 04:00:53,660 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48211239075118845, 'Total loss': 0.48211239075118845} | train loss {'Reaction outcome loss': 0.4796040915468994, 'Total loss': 0.4796040915468994}
2022-11-28 04:00:53,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:53,660 INFO:     Epoch: 48
2022-11-28 04:00:54,318 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4779954454438253, 'Total loss': 0.4779954454438253} | train loss {'Reaction outcome loss': 0.4756293895424378, 'Total loss': 0.4756293895424378}
2022-11-28 04:00:54,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:54,319 INFO:     Epoch: 49
2022-11-28 04:00:54,976 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45764607800678775, 'Total loss': 0.45764607800678775} | train loss {'Reaction outcome loss': 0.4663867997948216, 'Total loss': 0.4663867997948216}
2022-11-28 04:00:54,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:54,976 INFO:     Epoch: 50
2022-11-28 04:00:55,633 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4658791968090968, 'Total loss': 0.4658791968090968} | train loss {'Reaction outcome loss': 0.47990743475042374, 'Total loss': 0.47990743475042374}
2022-11-28 04:00:55,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:55,633 INFO:     Epoch: 51
2022-11-28 04:00:56,291 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5303449732336131, 'Total loss': 0.5303449732336131} | train loss {'Reaction outcome loss': 0.4974590773403886, 'Total loss': 0.4974590773403886}
2022-11-28 04:00:56,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:56,292 INFO:     Epoch: 52
2022-11-28 04:00:56,951 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45969726179133763, 'Total loss': 0.45969726179133763} | train loss {'Reaction outcome loss': 0.4745584524534492, 'Total loss': 0.4745584524534492}
2022-11-28 04:00:56,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:56,951 INFO:     Epoch: 53
2022-11-28 04:00:57,608 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47508861632509664, 'Total loss': 0.47508861632509664} | train loss {'Reaction outcome loss': 0.48416275220361316, 'Total loss': 0.48416275220361316}
2022-11-28 04:00:57,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:57,609 INFO:     Epoch: 54
2022-11-28 04:00:58,268 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4600575478239493, 'Total loss': 0.4600575478239493} | train loss {'Reaction outcome loss': 0.48144385749511875, 'Total loss': 0.48144385749511875}
2022-11-28 04:00:58,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:58,268 INFO:     Epoch: 55
2022-11-28 04:00:58,924 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5571477853439071, 'Total loss': 0.5571477853439071} | train loss {'Reaction outcome loss': 0.4767054293440421, 'Total loss': 0.4767054293440421}
2022-11-28 04:00:58,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:58,924 INFO:     Epoch: 56
2022-11-28 04:00:59,580 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48882801695303485, 'Total loss': 0.48882801695303485} | train loss {'Reaction outcome loss': 0.4888439118741495, 'Total loss': 0.4888439118741495}
2022-11-28 04:00:59,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:00:59,580 INFO:     Epoch: 57
2022-11-28 04:01:00,237 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.536047276109457, 'Total loss': 0.536047276109457} | train loss {'Reaction outcome loss': 0.47312576767162756, 'Total loss': 0.47312576767162756}
2022-11-28 04:01:00,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:00,238 INFO:     Epoch: 58
2022-11-28 04:01:00,895 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4622123424302448, 'Total loss': 0.4622123424302448} | train loss {'Reaction outcome loss': 0.4708985151790897, 'Total loss': 0.4708985151790897}
2022-11-28 04:01:00,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:00,895 INFO:     Epoch: 59
2022-11-28 04:01:01,551 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43232255564494565, 'Total loss': 0.43232255564494565} | train loss {'Reaction outcome loss': 0.47803992913802146, 'Total loss': 0.47803992913802146}
2022-11-28 04:01:01,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:01,551 INFO:     Epoch: 60
2022-11-28 04:01:02,210 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4641230990263549, 'Total loss': 0.4641230990263549} | train loss {'Reaction outcome loss': 0.47766242088817873, 'Total loss': 0.47766242088817873}
2022-11-28 04:01:02,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:02,211 INFO:     Epoch: 61
2022-11-28 04:01:02,866 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44330499321222305, 'Total loss': 0.44330499321222305} | train loss {'Reaction outcome loss': 0.47271554731586685, 'Total loss': 0.47271554731586685}
2022-11-28 04:01:02,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:02,866 INFO:     Epoch: 62
2022-11-28 04:01:03,522 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4812064529819922, 'Total loss': 0.4812064529819922} | train loss {'Reaction outcome loss': 0.4746548521901794, 'Total loss': 0.4746548521901794}
2022-11-28 04:01:03,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:03,522 INFO:     Epoch: 63
2022-11-28 04:01:04,181 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4781421792100776, 'Total loss': 0.4781421792100776} | train loss {'Reaction outcome loss': 0.4646550991274567, 'Total loss': 0.4646550991274567}
2022-11-28 04:01:04,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:04,181 INFO:     Epoch: 64
2022-11-28 04:01:04,834 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4723484522917054, 'Total loss': 0.4723484522917054} | train loss {'Reaction outcome loss': 0.47946452774740905, 'Total loss': 0.47946452774740905}
2022-11-28 04:01:04,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:04,834 INFO:     Epoch: 65
2022-11-28 04:01:05,489 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4606514054943215, 'Total loss': 0.4606514054943215} | train loss {'Reaction outcome loss': 0.46906090630331504, 'Total loss': 0.46906090630331504}
2022-11-28 04:01:05,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:05,489 INFO:     Epoch: 66
2022-11-28 04:01:06,146 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5310970097780228, 'Total loss': 0.5310970097780228} | train loss {'Reaction outcome loss': 0.46562538953565874, 'Total loss': 0.46562538953565874}
2022-11-28 04:01:06,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:06,146 INFO:     Epoch: 67
2022-11-28 04:01:06,801 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44979099387472327, 'Total loss': 0.44979099387472327} | train loss {'Reaction outcome loss': 0.4764715188337482, 'Total loss': 0.4764715188337482}
2022-11-28 04:01:06,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:06,801 INFO:     Epoch: 68
2022-11-28 04:01:07,457 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4815920557488095, 'Total loss': 0.4815920557488095} | train loss {'Reaction outcome loss': 0.460829466211832, 'Total loss': 0.460829466211832}
2022-11-28 04:01:07,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:07,457 INFO:     Epoch: 69
2022-11-28 04:01:08,114 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5107943510467355, 'Total loss': 0.5107943510467355} | train loss {'Reaction outcome loss': 0.4694027638568087, 'Total loss': 0.4694027638568087}
2022-11-28 04:01:08,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:08,114 INFO:     Epoch: 70
2022-11-28 04:01:08,768 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4537415766919201, 'Total loss': 0.4537415766919201} | train loss {'Reaction outcome loss': 0.46857017906088577, 'Total loss': 0.46857017906088577}
2022-11-28 04:01:08,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:08,769 INFO:     Epoch: 71
2022-11-28 04:01:09,426 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4632347815416076, 'Total loss': 0.4632347815416076} | train loss {'Reaction outcome loss': 0.46642161290413936, 'Total loss': 0.46642161290413936}
2022-11-28 04:01:09,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:09,426 INFO:     Epoch: 72
2022-11-28 04:01:10,080 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48619362847371533, 'Total loss': 0.48619362847371533} | train loss {'Reaction outcome loss': 0.4718808574594467, 'Total loss': 0.4718808574594467}
2022-11-28 04:01:10,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:10,080 INFO:     Epoch: 73
2022-11-28 04:01:10,733 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47192343256690283, 'Total loss': 0.47192343256690283} | train loss {'Reaction outcome loss': 0.464668555720615, 'Total loss': 0.464668555720615}
2022-11-28 04:01:10,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:10,734 INFO:     Epoch: 74
2022-11-28 04:01:11,387 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4817266938361255, 'Total loss': 0.4817266938361255} | train loss {'Reaction outcome loss': 0.47128789983538966, 'Total loss': 0.47128789983538966}
2022-11-28 04:01:11,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:11,387 INFO:     Epoch: 75
2022-11-28 04:01:12,042 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4435493458401073, 'Total loss': 0.4435493458401073} | train loss {'Reaction outcome loss': 0.4698453827606522, 'Total loss': 0.4698453827606522}
2022-11-28 04:01:12,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:12,042 INFO:     Epoch: 76
2022-11-28 04:01:12,701 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4968607798218727, 'Total loss': 0.4968607798218727} | train loss {'Reaction outcome loss': 0.46056743488017365, 'Total loss': 0.46056743488017365}
2022-11-28 04:01:12,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:12,702 INFO:     Epoch: 77
2022-11-28 04:01:13,358 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4772249866615642, 'Total loss': 0.4772249866615642} | train loss {'Reaction outcome loss': 0.47192156891741976, 'Total loss': 0.47192156891741976}
2022-11-28 04:01:13,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:13,358 INFO:     Epoch: 78
2022-11-28 04:01:14,010 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.484254581684416, 'Total loss': 0.484254581684416} | train loss {'Reaction outcome loss': 0.46302696157563555, 'Total loss': 0.46302696157563555}
2022-11-28 04:01:14,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:14,010 INFO:     Epoch: 79
2022-11-28 04:01:14,665 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5626857070760294, 'Total loss': 0.5626857070760294} | train loss {'Reaction outcome loss': 0.465913236563505, 'Total loss': 0.465913236563505}
2022-11-28 04:01:14,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:14,665 INFO:     Epoch: 80
2022-11-28 04:01:15,323 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45852142436937854, 'Total loss': 0.45852142436937854} | train loss {'Reaction outcome loss': 0.47452242530671207, 'Total loss': 0.47452242530671207}
2022-11-28 04:01:15,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:15,324 INFO:     Epoch: 81
2022-11-28 04:01:15,983 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4366816329685124, 'Total loss': 0.4366816329685124} | train loss {'Reaction outcome loss': 0.47269651740186125, 'Total loss': 0.47269651740186125}
2022-11-28 04:01:15,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:15,983 INFO:     Epoch: 82
2022-11-28 04:01:16,640 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48326490209861234, 'Total loss': 0.48326490209861234} | train loss {'Reaction outcome loss': 0.4669345858608663, 'Total loss': 0.4669345858608663}
2022-11-28 04:01:16,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:16,640 INFO:     Epoch: 83
2022-11-28 04:01:17,301 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48728502524847334, 'Total loss': 0.48728502524847334} | train loss {'Reaction outcome loss': 0.4619115290311184, 'Total loss': 0.4619115290311184}
2022-11-28 04:01:17,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:17,301 INFO:     Epoch: 84
2022-11-28 04:01:17,962 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43905190141363576, 'Total loss': 0.43905190141363576} | train loss {'Reaction outcome loss': 0.4703725802934604, 'Total loss': 0.4703725802934604}
2022-11-28 04:01:17,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:17,962 INFO:     Epoch: 85
2022-11-28 04:01:18,619 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47806054624644195, 'Total loss': 0.47806054624644195} | train loss {'Reaction outcome loss': 0.4630924944241761, 'Total loss': 0.4630924944241761}
2022-11-28 04:01:18,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:18,620 INFO:     Epoch: 86
2022-11-28 04:01:19,277 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48139617896892806, 'Total loss': 0.48139617896892806} | train loss {'Reaction outcome loss': 0.4715394398823441, 'Total loss': 0.4715394398823441}
2022-11-28 04:01:19,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:19,277 INFO:     Epoch: 87
2022-11-28 04:01:19,938 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4529435946182771, 'Total loss': 0.4529435946182771} | train loss {'Reaction outcome loss': 0.45880142379144906, 'Total loss': 0.45880142379144906}
2022-11-28 04:01:19,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:19,939 INFO:     Epoch: 88
2022-11-28 04:01:20,598 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4981167028573426, 'Total loss': 0.4981167028573426} | train loss {'Reaction outcome loss': 0.4678260399865718, 'Total loss': 0.4678260399865718}
2022-11-28 04:01:20,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:20,598 INFO:     Epoch: 89
2022-11-28 04:01:21,255 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46594390306960454, 'Total loss': 0.46594390306960454} | train loss {'Reaction outcome loss': 0.47693604055927835, 'Total loss': 0.47693604055927835}
2022-11-28 04:01:21,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:21,255 INFO:     Epoch: 90
2022-11-28 04:01:21,915 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44555902311747725, 'Total loss': 0.44555902311747725} | train loss {'Reaction outcome loss': 0.46355290167968766, 'Total loss': 0.46355290167968766}
2022-11-28 04:01:21,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:21,915 INFO:     Epoch: 91
2022-11-28 04:01:22,572 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4685863158242269, 'Total loss': 0.4685863158242269} | train loss {'Reaction outcome loss': 0.46556162791937467, 'Total loss': 0.46556162791937467}
2022-11-28 04:01:22,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:22,572 INFO:     Epoch: 92
2022-11-28 04:01:23,225 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4761527194218202, 'Total loss': 0.4761527194218202} | train loss {'Reaction outcome loss': 0.4678911316865557, 'Total loss': 0.4678911316865557}
2022-11-28 04:01:23,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:23,225 INFO:     Epoch: 93
2022-11-28 04:01:23,882 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4355663704601201, 'Total loss': 0.4355663704601201} | train loss {'Reaction outcome loss': 0.4569447502071558, 'Total loss': 0.4569447502071558}
2022-11-28 04:01:23,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:23,883 INFO:     Epoch: 94
2022-11-28 04:01:24,537 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4631447304378856, 'Total loss': 0.4631447304378856} | train loss {'Reaction outcome loss': 0.4754590412624452, 'Total loss': 0.4754590412624452}
2022-11-28 04:01:24,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:24,537 INFO:     Epoch: 95
2022-11-28 04:01:25,193 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48390246893871913, 'Total loss': 0.48390246893871913} | train loss {'Reaction outcome loss': 0.45771471220954707, 'Total loss': 0.45771471220954707}
2022-11-28 04:01:25,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:25,194 INFO:     Epoch: 96
2022-11-28 04:01:25,850 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48038372126492584, 'Total loss': 0.48038372126492584} | train loss {'Reaction outcome loss': 0.4673169861860603, 'Total loss': 0.4673169861860603}
2022-11-28 04:01:25,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:25,850 INFO:     Epoch: 97
2022-11-28 04:01:26,506 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4500594078139825, 'Total loss': 0.4500594078139825} | train loss {'Reaction outcome loss': 0.46127603751058627, 'Total loss': 0.46127603751058627}
2022-11-28 04:01:26,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:26,506 INFO:     Epoch: 98
2022-11-28 04:01:27,162 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48417354408990254, 'Total loss': 0.48417354408990254} | train loss {'Reaction outcome loss': 0.45678417170457997, 'Total loss': 0.45678417170457997}
2022-11-28 04:01:27,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:27,162 INFO:     Epoch: 99
2022-11-28 04:01:27,816 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43419153141704475, 'Total loss': 0.43419153141704475} | train loss {'Reaction outcome loss': 0.4594928903377008, 'Total loss': 0.4594928903377008}
2022-11-28 04:01:27,817 INFO:     Best model found after epoch 32 of 100.
2022-11-28 04:01:27,817 INFO:   Done with stage: TRAINING
2022-11-28 04:01:27,817 INFO:   Starting stage: EVALUATION
2022-11-28 04:01:27,935 INFO:   Done with stage: EVALUATION
2022-11-28 04:01:27,935 INFO:   Leaving out SEQ value Fold_2
2022-11-28 04:01:27,948 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:01:27,948 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:01:28,583 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:01:28,583 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:01:28,650 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:01:28,650 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:01:28,650 INFO:     No hyperparam tuning for this model
2022-11-28 04:01:28,650 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:01:28,650 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:01:28,651 INFO:     None feature selector for col prot
2022-11-28 04:01:28,651 INFO:     None feature selector for col prot
2022-11-28 04:01:28,651 INFO:     None feature selector for col prot
2022-11-28 04:01:28,652 INFO:     None feature selector for col chem
2022-11-28 04:01:28,652 INFO:     None feature selector for col chem
2022-11-28 04:01:28,652 INFO:     None feature selector for col chem
2022-11-28 04:01:28,652 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:01:28,652 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:01:28,653 INFO:     Number of params in model 169651
2022-11-28 04:01:28,656 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:01:28,656 INFO:   Starting stage: TRAINING
2022-11-28 04:01:28,706 INFO:     Val loss before train {'Reaction outcome loss': 1.0365484763275494, 'Total loss': 1.0365484763275494}
2022-11-28 04:01:28,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:28,707 INFO:     Epoch: 0
2022-11-28 04:01:29,358 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.640117733315988, 'Total loss': 0.640117733315988} | train loss {'Reaction outcome loss': 0.6989052458685272, 'Total loss': 0.6989052458685272}
2022-11-28 04:01:29,358 INFO:     Found new best model at epoch 0
2022-11-28 04:01:29,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:29,359 INFO:     Epoch: 1
2022-11-28 04:01:30,009 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6363512846556577, 'Total loss': 0.6363512846556577} | train loss {'Reaction outcome loss': 0.5871521005825121, 'Total loss': 0.5871521005825121}
2022-11-28 04:01:30,009 INFO:     Found new best model at epoch 1
2022-11-28 04:01:30,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:30,010 INFO:     Epoch: 2
2022-11-28 04:01:30,661 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.574763951653784, 'Total loss': 0.574763951653784} | train loss {'Reaction outcome loss': 0.5640198258112888, 'Total loss': 0.5640198258112888}
2022-11-28 04:01:30,661 INFO:     Found new best model at epoch 2
2022-11-28 04:01:30,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:30,662 INFO:     Epoch: 3
2022-11-28 04:01:31,313 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6105217005718838, 'Total loss': 0.6105217005718838} | train loss {'Reaction outcome loss': 0.5377646248559562, 'Total loss': 0.5377646248559562}
2022-11-28 04:01:31,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:31,314 INFO:     Epoch: 4
2022-11-28 04:01:31,966 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5330411852760748, 'Total loss': 0.5330411852760748} | train loss {'Reaction outcome loss': 0.529630786058854, 'Total loss': 0.529630786058854}
2022-11-28 04:01:31,966 INFO:     Found new best model at epoch 4
2022-11-28 04:01:31,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:31,967 INFO:     Epoch: 5
2022-11-28 04:01:32,619 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5556496530771255, 'Total loss': 0.5556496530771255} | train loss {'Reaction outcome loss': 0.519676239149911, 'Total loss': 0.519676239149911}
2022-11-28 04:01:32,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:32,619 INFO:     Epoch: 6
2022-11-28 04:01:33,269 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5644358938390558, 'Total loss': 0.5644358938390558} | train loss {'Reaction outcome loss': 0.5122687896295469, 'Total loss': 0.5122687896295469}
2022-11-28 04:01:33,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:33,270 INFO:     Epoch: 7
2022-11-28 04:01:33,921 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5724490389905192, 'Total loss': 0.5724490389905192} | train loss {'Reaction outcome loss': 0.5081724655263278, 'Total loss': 0.5081724655263278}
2022-11-28 04:01:33,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:33,921 INFO:     Epoch: 8
2022-11-28 04:01:34,570 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5621697509830649, 'Total loss': 0.5621697509830649} | train loss {'Reaction outcome loss': 0.4976381381251374, 'Total loss': 0.4976381381251374}
2022-11-28 04:01:34,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:34,571 INFO:     Epoch: 9
2022-11-28 04:01:35,219 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.54903513870456, 'Total loss': 0.54903513870456} | train loss {'Reaction outcome loss': 0.5004003826452761, 'Total loss': 0.5004003826452761}
2022-11-28 04:01:35,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:35,220 INFO:     Epoch: 10
2022-11-28 04:01:35,870 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5284733941609209, 'Total loss': 0.5284733941609209} | train loss {'Reaction outcome loss': 0.4991489417090708, 'Total loss': 0.4991489417090708}
2022-11-28 04:01:35,870 INFO:     Found new best model at epoch 10
2022-11-28 04:01:35,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:35,871 INFO:     Epoch: 11
2022-11-28 04:01:36,524 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5427048389207233, 'Total loss': 0.5427048389207233} | train loss {'Reaction outcome loss': 0.4849935032883469, 'Total loss': 0.4849935032883469}
2022-11-28 04:01:36,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:36,524 INFO:     Epoch: 12
2022-11-28 04:01:37,176 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.525983874770728, 'Total loss': 0.525983874770728} | train loss {'Reaction outcome loss': 0.4842953737292971, 'Total loss': 0.4842953737292971}
2022-11-28 04:01:37,177 INFO:     Found new best model at epoch 12
2022-11-28 04:01:37,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:37,177 INFO:     Epoch: 13
2022-11-28 04:01:37,827 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5232086107134819, 'Total loss': 0.5232086107134819} | train loss {'Reaction outcome loss': 0.4852987111831198, 'Total loss': 0.4852987111831198}
2022-11-28 04:01:37,827 INFO:     Found new best model at epoch 13
2022-11-28 04:01:37,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:37,828 INFO:     Epoch: 14
2022-11-28 04:01:38,477 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5084491429681127, 'Total loss': 0.5084491429681127} | train loss {'Reaction outcome loss': 0.4740026677749595, 'Total loss': 0.4740026677749595}
2022-11-28 04:01:38,477 INFO:     Found new best model at epoch 14
2022-11-28 04:01:38,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:38,478 INFO:     Epoch: 15
2022-11-28 04:01:39,124 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5003205199133266, 'Total loss': 0.5003205199133266} | train loss {'Reaction outcome loss': 0.47757631339588946, 'Total loss': 0.47757631339588946}
2022-11-28 04:01:39,125 INFO:     Found new best model at epoch 15
2022-11-28 04:01:39,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:39,125 INFO:     Epoch: 16
2022-11-28 04:01:39,776 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.510047856379639, 'Total loss': 0.510047856379639} | train loss {'Reaction outcome loss': 0.4787587721737064, 'Total loss': 0.4787587721737064}
2022-11-28 04:01:39,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:39,777 INFO:     Epoch: 17
2022-11-28 04:01:40,428 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.515383625598836, 'Total loss': 0.515383625598836} | train loss {'Reaction outcome loss': 0.4875934872700244, 'Total loss': 0.4875934872700244}
2022-11-28 04:01:40,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:40,428 INFO:     Epoch: 18
2022-11-28 04:01:41,078 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5209549123590643, 'Total loss': 0.5209549123590643} | train loss {'Reaction outcome loss': 0.47469194032707995, 'Total loss': 0.47469194032707995}
2022-11-28 04:01:41,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:41,078 INFO:     Epoch: 19
2022-11-28 04:01:41,732 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49690785800868814, 'Total loss': 0.49690785800868814} | train loss {'Reaction outcome loss': 0.48039683334681454, 'Total loss': 0.48039683334681454}
2022-11-28 04:01:41,733 INFO:     Found new best model at epoch 19
2022-11-28 04:01:41,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:41,733 INFO:     Epoch: 20
2022-11-28 04:01:42,385 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5229398140853102, 'Total loss': 0.5229398140853102} | train loss {'Reaction outcome loss': 0.4796789165054049, 'Total loss': 0.4796789165054049}
2022-11-28 04:01:42,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:42,385 INFO:     Epoch: 21
2022-11-28 04:01:43,036 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5753583135929975, 'Total loss': 0.5753583135929975} | train loss {'Reaction outcome loss': 0.47564753318319514, 'Total loss': 0.47564753318319514}
2022-11-28 04:01:43,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:43,036 INFO:     Epoch: 22
2022-11-28 04:01:43,689 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5502908764915033, 'Total loss': 0.5502908764915033} | train loss {'Reaction outcome loss': 0.4753632735232918, 'Total loss': 0.4753632735232918}
2022-11-28 04:01:43,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:43,689 INFO:     Epoch: 23
2022-11-28 04:01:44,340 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5151656439358537, 'Total loss': 0.5151656439358537} | train loss {'Reaction outcome loss': 0.47531106173992155, 'Total loss': 0.47531106173992155}
2022-11-28 04:01:44,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:44,340 INFO:     Epoch: 24
2022-11-28 04:01:44,987 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5220973079346798, 'Total loss': 0.5220973079346798} | train loss {'Reaction outcome loss': 0.471703790523568, 'Total loss': 0.471703790523568}
2022-11-28 04:01:44,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:44,987 INFO:     Epoch: 25
2022-11-28 04:01:45,637 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5015309371731498, 'Total loss': 0.5015309371731498} | train loss {'Reaction outcome loss': 0.47489182608468195, 'Total loss': 0.47489182608468195}
2022-11-28 04:01:45,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:45,638 INFO:     Epoch: 26
2022-11-28 04:01:46,287 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5135201496834104, 'Total loss': 0.5135201496834104} | train loss {'Reaction outcome loss': 0.4732853818304685, 'Total loss': 0.4732853818304685}
2022-11-28 04:01:46,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:46,288 INFO:     Epoch: 27
2022-11-28 04:01:46,937 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4968679022382606, 'Total loss': 0.4968679022382606} | train loss {'Reaction outcome loss': 0.46490459712792415, 'Total loss': 0.46490459712792415}
2022-11-28 04:01:46,938 INFO:     Found new best model at epoch 27
2022-11-28 04:01:46,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:46,938 INFO:     Epoch: 28
2022-11-28 04:01:47,587 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4992884695529938, 'Total loss': 0.4992884695529938} | train loss {'Reaction outcome loss': 0.46813164523669654, 'Total loss': 0.46813164523669654}
2022-11-28 04:01:47,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:47,587 INFO:     Epoch: 29
2022-11-28 04:01:48,237 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5196651013737376, 'Total loss': 0.5196651013737376} | train loss {'Reaction outcome loss': 0.4735601442504902, 'Total loss': 0.4735601442504902}
2022-11-28 04:01:48,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:48,237 INFO:     Epoch: 30
2022-11-28 04:01:48,888 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5344308726489544, 'Total loss': 0.5344308726489544} | train loss {'Reaction outcome loss': 0.47347028261544755, 'Total loss': 0.47347028261544755}
2022-11-28 04:01:48,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:48,888 INFO:     Epoch: 31
2022-11-28 04:01:49,538 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5262520448728041, 'Total loss': 0.5262520448728041} | train loss {'Reaction outcome loss': 0.4707875695763802, 'Total loss': 0.4707875695763802}
2022-11-28 04:01:49,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:49,538 INFO:     Epoch: 32
2022-11-28 04:01:50,189 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5192969099364497, 'Total loss': 0.5192969099364497} | train loss {'Reaction outcome loss': 0.47053250129125557, 'Total loss': 0.47053250129125557}
2022-11-28 04:01:50,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:50,189 INFO:     Epoch: 33
2022-11-28 04:01:50,839 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5065822506492789, 'Total loss': 0.5065822506492789} | train loss {'Reaction outcome loss': 0.4725183306908121, 'Total loss': 0.4725183306908121}
2022-11-28 04:01:50,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:50,840 INFO:     Epoch: 34
2022-11-28 04:01:51,489 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5150485499338671, 'Total loss': 0.5150485499338671} | train loss {'Reaction outcome loss': 0.4782821863889694, 'Total loss': 0.4782821863889694}
2022-11-28 04:01:51,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:51,490 INFO:     Epoch: 35
2022-11-28 04:01:52,141 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5335836891423572, 'Total loss': 0.5335836891423572} | train loss {'Reaction outcome loss': 0.4686235089083107, 'Total loss': 0.4686235089083107}
2022-11-28 04:01:52,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:52,141 INFO:     Epoch: 36
2022-11-28 04:01:52,788 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.522196232595227, 'Total loss': 0.522196232595227} | train loss {'Reaction outcome loss': 0.4776875532403284, 'Total loss': 0.4776875532403284}
2022-11-28 04:01:52,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:52,788 INFO:     Epoch: 37
2022-11-28 04:01:53,438 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5132933536713774, 'Total loss': 0.5132933536713774} | train loss {'Reaction outcome loss': 0.4707702727646244, 'Total loss': 0.4707702727646244}
2022-11-28 04:01:53,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:53,438 INFO:     Epoch: 38
2022-11-28 04:01:54,091 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4902459423650395, 'Total loss': 0.4902459423650395} | train loss {'Reaction outcome loss': 0.4718128187315805, 'Total loss': 0.4718128187315805}
2022-11-28 04:01:54,091 INFO:     Found new best model at epoch 38
2022-11-28 04:01:54,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:54,092 INFO:     Epoch: 39
2022-11-28 04:01:54,745 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5469505360180681, 'Total loss': 0.5469505360180681} | train loss {'Reaction outcome loss': 0.46863363008109893, 'Total loss': 0.46863363008109893}
2022-11-28 04:01:54,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:54,745 INFO:     Epoch: 40
2022-11-28 04:01:55,393 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5598497783595865, 'Total loss': 0.5598497783595865} | train loss {'Reaction outcome loss': 0.46813743874734765, 'Total loss': 0.46813743874734765}
2022-11-28 04:01:55,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:55,393 INFO:     Epoch: 41
2022-11-28 04:01:56,042 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5210931158878587, 'Total loss': 0.5210931158878587} | train loss {'Reaction outcome loss': 0.47240462601184846, 'Total loss': 0.47240462601184846}
2022-11-28 04:01:56,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:56,042 INFO:     Epoch: 42
2022-11-28 04:01:56,689 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5128790285776962, 'Total loss': 0.5128790285776962} | train loss {'Reaction outcome loss': 0.47301300697180687, 'Total loss': 0.47301300697180687}
2022-11-28 04:01:56,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:56,690 INFO:     Epoch: 43
2022-11-28 04:01:57,339 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5083219341256402, 'Total loss': 0.5083219341256402} | train loss {'Reaction outcome loss': 0.470259028673172, 'Total loss': 0.470259028673172}
2022-11-28 04:01:57,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:57,340 INFO:     Epoch: 44
2022-11-28 04:01:57,991 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5137119442224503, 'Total loss': 0.5137119442224503} | train loss {'Reaction outcome loss': 0.47221973556645064, 'Total loss': 0.47221973556645064}
2022-11-28 04:01:57,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:57,991 INFO:     Epoch: 45
2022-11-28 04:01:58,639 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5152461312033914, 'Total loss': 0.5152461312033914} | train loss {'Reaction outcome loss': 0.4660980508947859, 'Total loss': 0.4660980508947859}
2022-11-28 04:01:58,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:58,640 INFO:     Epoch: 46
2022-11-28 04:01:59,287 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5256299861622128, 'Total loss': 0.5256299861622128} | train loss {'Reaction outcome loss': 0.4644226345480705, 'Total loss': 0.4644226345480705}
2022-11-28 04:01:59,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:59,287 INFO:     Epoch: 47
2022-11-28 04:01:59,934 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.486990660936995, 'Total loss': 0.486990660936995} | train loss {'Reaction outcome loss': 0.47504085606458235, 'Total loss': 0.47504085606458235}
2022-11-28 04:01:59,934 INFO:     Found new best model at epoch 47
2022-11-28 04:01:59,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:01:59,935 INFO:     Epoch: 48
2022-11-28 04:02:00,585 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5048770941793919, 'Total loss': 0.5048770941793919} | train loss {'Reaction outcome loss': 0.4701193555885432, 'Total loss': 0.4701193555885432}
2022-11-28 04:02:00,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:00,585 INFO:     Epoch: 49
2022-11-28 04:02:01,235 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5480070446025241, 'Total loss': 0.5480070446025241} | train loss {'Reaction outcome loss': 0.46915959046811473, 'Total loss': 0.46915959046811473}
2022-11-28 04:02:01,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:01,235 INFO:     Epoch: 50
2022-11-28 04:02:01,886 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5041138055649671, 'Total loss': 0.5041138055649671} | train loss {'Reaction outcome loss': 0.4684966114406683, 'Total loss': 0.4684966114406683}
2022-11-28 04:02:01,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:01,886 INFO:     Epoch: 51
2022-11-28 04:02:02,539 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5099956654012203, 'Total loss': 0.5099956654012203} | train loss {'Reaction outcome loss': 0.47025586883632503, 'Total loss': 0.47025586883632503}
2022-11-28 04:02:02,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:02,539 INFO:     Epoch: 52
2022-11-28 04:02:03,189 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5185352584177797, 'Total loss': 0.5185352584177797} | train loss {'Reaction outcome loss': 0.46569288044559715, 'Total loss': 0.46569288044559715}
2022-11-28 04:02:03,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:03,189 INFO:     Epoch: 53
2022-11-28 04:02:03,838 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5081824267452414, 'Total loss': 0.5081824267452414} | train loss {'Reaction outcome loss': 0.46756059314523424, 'Total loss': 0.46756059314523424}
2022-11-28 04:02:03,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:03,838 INFO:     Epoch: 54
2022-11-28 04:02:04,484 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5579376941208135, 'Total loss': 0.5579376941208135} | train loss {'Reaction outcome loss': 0.4693023837342554, 'Total loss': 0.4693023837342554}
2022-11-28 04:02:04,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:04,484 INFO:     Epoch: 55
2022-11-28 04:02:05,136 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5359462567351081, 'Total loss': 0.5359462567351081} | train loss {'Reaction outcome loss': 0.47420802523895184, 'Total loss': 0.47420802523895184}
2022-11-28 04:02:05,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:05,136 INFO:     Epoch: 56
2022-11-28 04:02:05,786 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5250248243735934, 'Total loss': 0.5250248243735934} | train loss {'Reaction outcome loss': 0.4739108828257541, 'Total loss': 0.4739108828257541}
2022-11-28 04:02:05,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:05,786 INFO:     Epoch: 57
2022-11-28 04:02:06,437 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49209998548030853, 'Total loss': 0.49209998548030853} | train loss {'Reaction outcome loss': 0.4733676695702027, 'Total loss': 0.4733676695702027}
2022-11-28 04:02:06,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:06,438 INFO:     Epoch: 58
2022-11-28 04:02:07,093 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4861345800825141, 'Total loss': 0.4861345800825141} | train loss {'Reaction outcome loss': 0.46794474058005275, 'Total loss': 0.46794474058005275}
2022-11-28 04:02:07,093 INFO:     Found new best model at epoch 58
2022-11-28 04:02:07,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:07,094 INFO:     Epoch: 59
2022-11-28 04:02:07,745 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5232770124619658, 'Total loss': 0.5232770124619658} | train loss {'Reaction outcome loss': 0.47637981869736495, 'Total loss': 0.47637981869736495}
2022-11-28 04:02:07,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:07,745 INFO:     Epoch: 60
2022-11-28 04:02:08,397 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49189802089875395, 'Total loss': 0.49189802089875395} | train loss {'Reaction outcome loss': 0.4570053081731407, 'Total loss': 0.4570053081731407}
2022-11-28 04:02:08,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:08,397 INFO:     Epoch: 61
2022-11-28 04:02:09,050 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5380783832886002, 'Total loss': 0.5380783832886002} | train loss {'Reaction outcome loss': 0.468138828569529, 'Total loss': 0.468138828569529}
2022-11-28 04:02:09,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:09,050 INFO:     Epoch: 62
2022-11-28 04:02:09,705 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4943246607753364, 'Total loss': 0.4943246607753364} | train loss {'Reaction outcome loss': 0.46445547847115265, 'Total loss': 0.46445547847115265}
2022-11-28 04:02:09,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:09,706 INFO:     Epoch: 63
2022-11-28 04:02:10,358 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4840768414803527, 'Total loss': 0.4840768414803527} | train loss {'Reaction outcome loss': 0.4690490819969956, 'Total loss': 0.4690490819969956}
2022-11-28 04:02:10,359 INFO:     Found new best model at epoch 63
2022-11-28 04:02:10,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:10,360 INFO:     Epoch: 64
2022-11-28 04:02:11,012 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49719374965537677, 'Total loss': 0.49719374965537677} | train loss {'Reaction outcome loss': 0.4692874138452569, 'Total loss': 0.4692874138452569}
2022-11-28 04:02:11,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:11,012 INFO:     Epoch: 65
2022-11-28 04:02:11,667 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4856127446348017, 'Total loss': 0.4856127446348017} | train loss {'Reaction outcome loss': 0.46617454269102643, 'Total loss': 0.46617454269102643}
2022-11-28 04:02:11,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:11,667 INFO:     Epoch: 66
2022-11-28 04:02:12,319 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5128504843874411, 'Total loss': 0.5128504843874411} | train loss {'Reaction outcome loss': 0.4667391456815661, 'Total loss': 0.4667391456815661}
2022-11-28 04:02:12,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:12,320 INFO:     Epoch: 67
2022-11-28 04:02:12,972 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4955301894382997, 'Total loss': 0.4955301894382997} | train loss {'Reaction outcome loss': 0.4659233271771548, 'Total loss': 0.4659233271771548}
2022-11-28 04:02:12,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:12,972 INFO:     Epoch: 68
2022-11-28 04:02:13,624 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5021865936842832, 'Total loss': 0.5021865936842832} | train loss {'Reaction outcome loss': 0.4687829692144783, 'Total loss': 0.4687829692144783}
2022-11-28 04:02:13,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:13,624 INFO:     Epoch: 69
2022-11-28 04:02:14,275 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5065152580765161, 'Total loss': 0.5065152580765161} | train loss {'Reaction outcome loss': 0.46809867365019664, 'Total loss': 0.46809867365019664}
2022-11-28 04:02:14,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:14,276 INFO:     Epoch: 70
2022-11-28 04:02:14,927 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5306056802245703, 'Total loss': 0.5306056802245703} | train loss {'Reaction outcome loss': 0.46621850957067645, 'Total loss': 0.46621850957067645}
2022-11-28 04:02:14,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:14,928 INFO:     Epoch: 71
2022-11-28 04:02:15,578 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5043911686675115, 'Total loss': 0.5043911686675115} | train loss {'Reaction outcome loss': 0.4635243212081948, 'Total loss': 0.4635243212081948}
2022-11-28 04:02:15,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:15,578 INFO:     Epoch: 72
2022-11-28 04:02:16,227 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.50082376497713, 'Total loss': 0.50082376497713} | train loss {'Reaction outcome loss': 0.4628944893272556, 'Total loss': 0.4628944893272556}
2022-11-28 04:02:16,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:16,228 INFO:     Epoch: 73
2022-11-28 04:02:16,873 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48820543627847324, 'Total loss': 0.48820543627847324} | train loss {'Reaction outcome loss': 0.46972059163512014, 'Total loss': 0.46972059163512014}
2022-11-28 04:02:16,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:16,874 INFO:     Epoch: 74
2022-11-28 04:02:17,521 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5076761692762375, 'Total loss': 0.5076761692762375} | train loss {'Reaction outcome loss': 0.4681306567727303, 'Total loss': 0.4681306567727303}
2022-11-28 04:02:17,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:17,521 INFO:     Epoch: 75
2022-11-28 04:02:18,172 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5599387108602307, 'Total loss': 0.5599387108602307} | train loss {'Reaction outcome loss': 0.4703304317532753, 'Total loss': 0.4703304317532753}
2022-11-28 04:02:18,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:18,172 INFO:     Epoch: 76
2022-11-28 04:02:18,822 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5292518057606437, 'Total loss': 0.5292518057606437} | train loss {'Reaction outcome loss': 0.465051773798709, 'Total loss': 0.465051773798709}
2022-11-28 04:02:18,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:18,822 INFO:     Epoch: 77
2022-11-28 04:02:19,473 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5178326717154547, 'Total loss': 0.5178326717154547} | train loss {'Reaction outcome loss': 0.4659674095255988, 'Total loss': 0.4659674095255988}
2022-11-28 04:02:19,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:19,474 INFO:     Epoch: 78
2022-11-28 04:02:20,124 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5327023359184916, 'Total loss': 0.5327023359184916} | train loss {'Reaction outcome loss': 0.46826044445743364, 'Total loss': 0.46826044445743364}
2022-11-28 04:02:20,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:20,125 INFO:     Epoch: 79
2022-11-28 04:02:20,776 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49602625688368623, 'Total loss': 0.49602625688368623} | train loss {'Reaction outcome loss': 0.47204447257883697, 'Total loss': 0.47204447257883697}
2022-11-28 04:02:20,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:20,776 INFO:     Epoch: 80
2022-11-28 04:02:21,428 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5366203578358347, 'Total loss': 0.5366203578358347} | train loss {'Reaction outcome loss': 0.4679875402426233, 'Total loss': 0.4679875402426233}
2022-11-28 04:02:21,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:21,428 INFO:     Epoch: 81
2022-11-28 04:02:22,082 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5732662305235863, 'Total loss': 0.5732662305235863} | train loss {'Reaction outcome loss': 0.46298814513245407, 'Total loss': 0.46298814513245407}
2022-11-28 04:02:22,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:22,082 INFO:     Epoch: 82
2022-11-28 04:02:22,737 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49148988689888606, 'Total loss': 0.49148988689888606} | train loss {'Reaction outcome loss': 0.4694323241102452, 'Total loss': 0.4694323241102452}
2022-11-28 04:02:22,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:22,737 INFO:     Epoch: 83
2022-11-28 04:02:23,393 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4881064804609526, 'Total loss': 0.4881064804609526} | train loss {'Reaction outcome loss': 0.47218441139070355, 'Total loss': 0.47218441139070355}
2022-11-28 04:02:23,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:23,394 INFO:     Epoch: 84
2022-11-28 04:02:24,047 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5093658569861542, 'Total loss': 0.5093658569861542} | train loss {'Reaction outcome loss': 0.46330084110401115, 'Total loss': 0.46330084110401115}
2022-11-28 04:02:24,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:24,047 INFO:     Epoch: 85
2022-11-28 04:02:24,697 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49772622233087366, 'Total loss': 0.49772622233087366} | train loss {'Reaction outcome loss': 0.470138086469806, 'Total loss': 0.470138086469806}
2022-11-28 04:02:24,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:24,697 INFO:     Epoch: 86
2022-11-28 04:02:25,350 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48984597250819206, 'Total loss': 0.48984597250819206} | train loss {'Reaction outcome loss': 0.47216405941515555, 'Total loss': 0.47216405941515555}
2022-11-28 04:02:25,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:25,350 INFO:     Epoch: 87
2022-11-28 04:02:26,003 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5108717175369913, 'Total loss': 0.5108717175369913} | train loss {'Reaction outcome loss': 0.46384214418275016, 'Total loss': 0.46384214418275016}
2022-11-28 04:02:26,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:26,003 INFO:     Epoch: 88
2022-11-28 04:02:26,658 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49706224927848036, 'Total loss': 0.49706224927848036} | train loss {'Reaction outcome loss': 0.4644458036033475, 'Total loss': 0.4644458036033475}
2022-11-28 04:02:26,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:26,658 INFO:     Epoch: 89
2022-11-28 04:02:27,315 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.525270709937269, 'Total loss': 0.525270709937269} | train loss {'Reaction outcome loss': 0.46670652798243933, 'Total loss': 0.46670652798243933}
2022-11-28 04:02:27,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:27,315 INFO:     Epoch: 90
2022-11-28 04:02:27,969 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5191180841489271, 'Total loss': 0.5191180841489271} | train loss {'Reaction outcome loss': 0.4680302045783218, 'Total loss': 0.4680302045783218}
2022-11-28 04:02:27,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:27,969 INFO:     Epoch: 91
2022-11-28 04:02:28,624 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4922967600551518, 'Total loss': 0.4922967600551518} | train loss {'Reaction outcome loss': 0.46335214540666464, 'Total loss': 0.46335214540666464}
2022-11-28 04:02:28,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:28,624 INFO:     Epoch: 92
2022-11-28 04:02:29,272 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5017003820023753, 'Total loss': 0.5017003820023753} | train loss {'Reaction outcome loss': 0.4600244410183965, 'Total loss': 0.4600244410183965}
2022-11-28 04:02:29,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:29,273 INFO:     Epoch: 93
2022-11-28 04:02:29,926 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47400222634049977, 'Total loss': 0.47400222634049977} | train loss {'Reaction outcome loss': 0.4702338636529689, 'Total loss': 0.4702338636529689}
2022-11-28 04:02:29,926 INFO:     Found new best model at epoch 93
2022-11-28 04:02:29,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:29,927 INFO:     Epoch: 94
2022-11-28 04:02:30,581 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5074995871294629, 'Total loss': 0.5074995871294629} | train loss {'Reaction outcome loss': 0.4682909436980072, 'Total loss': 0.4682909436980072}
2022-11-28 04:02:30,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:30,582 INFO:     Epoch: 95
2022-11-28 04:02:31,234 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5291198336265304, 'Total loss': 0.5291198336265304} | train loss {'Reaction outcome loss': 0.4670184896916759, 'Total loss': 0.4670184896916759}
2022-11-28 04:02:31,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:31,235 INFO:     Epoch: 96
2022-11-28 04:02:31,885 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49734957042065536, 'Total loss': 0.49734957042065536} | train loss {'Reaction outcome loss': 0.4652458235925558, 'Total loss': 0.4652458235925558}
2022-11-28 04:02:31,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:31,886 INFO:     Epoch: 97
2022-11-28 04:02:32,542 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4857151186601682, 'Total loss': 0.4857151186601682} | train loss {'Reaction outcome loss': 0.46488291998298803, 'Total loss': 0.46488291998298803}
2022-11-28 04:02:32,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:32,542 INFO:     Epoch: 98
2022-11-28 04:02:33,196 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5260631018741564, 'Total loss': 0.5260631018741564} | train loss {'Reaction outcome loss': 0.46551232532579073, 'Total loss': 0.46551232532579073}
2022-11-28 04:02:33,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:33,197 INFO:     Epoch: 99
2022-11-28 04:02:33,851 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47782866656780243, 'Total loss': 0.47782866656780243} | train loss {'Reaction outcome loss': 0.4686756477064016, 'Total loss': 0.4686756477064016}
2022-11-28 04:02:33,851 INFO:     Best model found after epoch 94 of 100.
2022-11-28 04:02:33,851 INFO:   Done with stage: TRAINING
2022-11-28 04:02:33,851 INFO:   Starting stage: EVALUATION
2022-11-28 04:02:33,975 INFO:   Done with stage: EVALUATION
2022-11-28 04:02:33,975 INFO:   Leaving out SEQ value Fold_3
2022-11-28 04:02:33,988 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 04:02:33,988 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:02:34,621 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:02:34,621 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:02:34,689 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:02:34,689 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:02:34,689 INFO:     No hyperparam tuning for this model
2022-11-28 04:02:34,689 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:02:34,689 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:02:34,690 INFO:     None feature selector for col prot
2022-11-28 04:02:34,690 INFO:     None feature selector for col prot
2022-11-28 04:02:34,690 INFO:     None feature selector for col prot
2022-11-28 04:02:34,690 INFO:     None feature selector for col chem
2022-11-28 04:02:34,690 INFO:     None feature selector for col chem
2022-11-28 04:02:34,690 INFO:     None feature selector for col chem
2022-11-28 04:02:34,690 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:02:34,691 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:02:34,692 INFO:     Number of params in model 169651
2022-11-28 04:02:34,695 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:02:34,695 INFO:   Starting stage: TRAINING
2022-11-28 04:02:34,744 INFO:     Val loss before train {'Reaction outcome loss': 1.029854976853659, 'Total loss': 1.029854976853659}
2022-11-28 04:02:34,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:34,745 INFO:     Epoch: 0
2022-11-28 04:02:35,399 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6302157231541567, 'Total loss': 0.6302157231541567} | train loss {'Reaction outcome loss': 0.6799161593567152, 'Total loss': 0.6799161593567152}
2022-11-28 04:02:35,399 INFO:     Found new best model at epoch 0
2022-11-28 04:02:35,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:35,400 INFO:     Epoch: 1
2022-11-28 04:02:36,046 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5809383822041888, 'Total loss': 0.5809383822041888} | train loss {'Reaction outcome loss': 0.5676028866198708, 'Total loss': 0.5676028866198708}
2022-11-28 04:02:36,046 INFO:     Found new best model at epoch 1
2022-11-28 04:02:36,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:36,047 INFO:     Epoch: 2
2022-11-28 04:02:36,697 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5233101297256558, 'Total loss': 0.5233101297256558} | train loss {'Reaction outcome loss': 0.5423562727624276, 'Total loss': 0.5423562727624276}
2022-11-28 04:02:36,697 INFO:     Found new best model at epoch 2
2022-11-28 04:02:36,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:36,698 INFO:     Epoch: 3
2022-11-28 04:02:37,351 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5393570911052615, 'Total loss': 0.5393570911052615} | train loss {'Reaction outcome loss': 0.5182314737409842, 'Total loss': 0.5182314737409842}
2022-11-28 04:02:37,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:37,351 INFO:     Epoch: 4
2022-11-28 04:02:38,002 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5122679998708326, 'Total loss': 0.5122679998708326} | train loss {'Reaction outcome loss': 0.5058758723564812, 'Total loss': 0.5058758723564812}
2022-11-28 04:02:38,002 INFO:     Found new best model at epoch 4
2022-11-28 04:02:38,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:38,003 INFO:     Epoch: 5
2022-11-28 04:02:38,657 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5086479502361875, 'Total loss': 0.5086479502361875} | train loss {'Reaction outcome loss': 0.4981932916724291, 'Total loss': 0.4981932916724291}
2022-11-28 04:02:38,658 INFO:     Found new best model at epoch 5
2022-11-28 04:02:38,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:38,658 INFO:     Epoch: 6
2022-11-28 04:02:39,312 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5225088159705318, 'Total loss': 0.5225088159705318} | train loss {'Reaction outcome loss': 0.4916909265591473, 'Total loss': 0.4916909265591473}
2022-11-28 04:02:39,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:39,312 INFO:     Epoch: 7
2022-11-28 04:02:39,962 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.526945715726808, 'Total loss': 0.526945715726808} | train loss {'Reaction outcome loss': 0.48783531610960845, 'Total loss': 0.48783531610960845}
2022-11-28 04:02:39,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:39,962 INFO:     Epoch: 8
2022-11-28 04:02:40,612 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5001640208931857, 'Total loss': 0.5001640208931857} | train loss {'Reaction outcome loss': 0.48340776300088306, 'Total loss': 0.48340776300088306}
2022-11-28 04:02:40,612 INFO:     Found new best model at epoch 8
2022-11-28 04:02:40,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:40,613 INFO:     Epoch: 9
2022-11-28 04:02:41,267 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5087272342900897, 'Total loss': 0.5087272342900897} | train loss {'Reaction outcome loss': 0.4778498190714688, 'Total loss': 0.4778498190714688}
2022-11-28 04:02:41,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:41,267 INFO:     Epoch: 10
2022-11-28 04:02:41,916 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5132795184157616, 'Total loss': 0.5132795184157616} | train loss {'Reaction outcome loss': 0.47820867732411526, 'Total loss': 0.47820867732411526}
2022-11-28 04:02:41,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:41,917 INFO:     Epoch: 11
2022-11-28 04:02:42,571 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4713025259417157, 'Total loss': 0.4713025259417157} | train loss {'Reaction outcome loss': 0.4756058238935275, 'Total loss': 0.4756058238935275}
2022-11-28 04:02:42,571 INFO:     Found new best model at epoch 11
2022-11-28 04:02:42,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:42,572 INFO:     Epoch: 12
2022-11-28 04:02:43,222 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5373684798562249, 'Total loss': 0.5373684798562249} | train loss {'Reaction outcome loss': 0.4702458829298371, 'Total loss': 0.4702458829298371}
2022-11-28 04:02:43,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:43,223 INFO:     Epoch: 13
2022-11-28 04:02:43,870 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4826399933460147, 'Total loss': 0.4826399933460147} | train loss {'Reaction outcome loss': 0.47595386384207694, 'Total loss': 0.47595386384207694}
2022-11-28 04:02:43,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:43,870 INFO:     Epoch: 14
2022-11-28 04:02:44,519 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49552225130935046, 'Total loss': 0.49552225130935046} | train loss {'Reaction outcome loss': 0.4700787152911796, 'Total loss': 0.4700787152911796}
2022-11-28 04:02:44,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:44,519 INFO:     Epoch: 15
2022-11-28 04:02:45,172 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49409935328849525, 'Total loss': 0.49409935328849525} | train loss {'Reaction outcome loss': 0.46269349692786327, 'Total loss': 0.46269349692786327}
2022-11-28 04:02:45,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:45,172 INFO:     Epoch: 16
2022-11-28 04:02:45,824 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.522314788643704, 'Total loss': 0.522314788643704} | train loss {'Reaction outcome loss': 0.47255983997563844, 'Total loss': 0.47255983997563844}
2022-11-28 04:02:45,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:45,824 INFO:     Epoch: 17
2022-11-28 04:02:46,475 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4667828925127207, 'Total loss': 0.4667828925127207} | train loss {'Reaction outcome loss': 0.4724921981086496, 'Total loss': 0.4724921981086496}
2022-11-28 04:02:46,475 INFO:     Found new best model at epoch 17
2022-11-28 04:02:46,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:46,476 INFO:     Epoch: 18
2022-11-28 04:02:47,125 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4689295284969862, 'Total loss': 0.4689295284969862} | train loss {'Reaction outcome loss': 0.4720794508142061, 'Total loss': 0.4720794508142061}
2022-11-28 04:02:47,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:47,125 INFO:     Epoch: 19
2022-11-28 04:02:47,775 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5150476174299107, 'Total loss': 0.5150476174299107} | train loss {'Reaction outcome loss': 0.4693347252600017, 'Total loss': 0.4693347252600017}
2022-11-28 04:02:47,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:47,775 INFO:     Epoch: 20
2022-11-28 04:02:48,424 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.499716013323429, 'Total loss': 0.499716013323429} | train loss {'Reaction outcome loss': 0.46742536567273685, 'Total loss': 0.46742536567273685}
2022-11-28 04:02:48,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:48,425 INFO:     Epoch: 21
2022-11-28 04:02:49,076 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5153756796620613, 'Total loss': 0.5153756796620613} | train loss {'Reaction outcome loss': 0.47177728839585037, 'Total loss': 0.47177728839585037}
2022-11-28 04:02:49,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:49,076 INFO:     Epoch: 22
2022-11-28 04:02:49,726 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5020859404358753, 'Total loss': 0.5020859404358753} | train loss {'Reaction outcome loss': 0.46583076343551033, 'Total loss': 0.46583076343551033}
2022-11-28 04:02:49,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:49,726 INFO:     Epoch: 23
2022-11-28 04:02:50,372 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4784197027600089, 'Total loss': 0.4784197027600089} | train loss {'Reaction outcome loss': 0.4611244092954964, 'Total loss': 0.4611244092954964}
2022-11-28 04:02:50,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:50,373 INFO:     Epoch: 24
2022-11-28 04:02:51,022 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4979546932980072, 'Total loss': 0.4979546932980072} | train loss {'Reaction outcome loss': 0.465619973044415, 'Total loss': 0.465619973044415}
2022-11-28 04:02:51,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:51,022 INFO:     Epoch: 25
2022-11-28 04:02:51,670 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49654563533705337, 'Total loss': 0.49654563533705337} | train loss {'Reaction outcome loss': 0.4701328174379028, 'Total loss': 0.4701328174379028}
2022-11-28 04:02:51,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:51,670 INFO:     Epoch: 26
2022-11-28 04:02:52,322 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47835520776205287, 'Total loss': 0.47835520776205287} | train loss {'Reaction outcome loss': 0.46833340939683993, 'Total loss': 0.46833340939683993}
2022-11-28 04:02:52,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:52,322 INFO:     Epoch: 27
2022-11-28 04:02:52,976 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4974175913389339, 'Total loss': 0.4974175913389339} | train loss {'Reaction outcome loss': 0.4671068518254601, 'Total loss': 0.4671068518254601}
2022-11-28 04:02:52,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:52,976 INFO:     Epoch: 28
2022-11-28 04:02:53,629 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.530538976539013, 'Total loss': 0.530538976539013} | train loss {'Reaction outcome loss': 0.45807649598258443, 'Total loss': 0.45807649598258443}
2022-11-28 04:02:53,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:53,630 INFO:     Epoch: 29
2022-11-28 04:02:54,282 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47842688026816343, 'Total loss': 0.47842688026816343} | train loss {'Reaction outcome loss': 0.47072193924276556, 'Total loss': 0.47072193924276556}
2022-11-28 04:02:54,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:54,283 INFO:     Epoch: 30
2022-11-28 04:02:54,936 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.504343936956206, 'Total loss': 0.504343936956206} | train loss {'Reaction outcome loss': 0.46399252553333026, 'Total loss': 0.46399252553333026}
2022-11-28 04:02:54,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:54,936 INFO:     Epoch: 31
2022-11-28 04:02:55,587 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49649362993794816, 'Total loss': 0.49649362993794816} | train loss {'Reaction outcome loss': 0.4610873601842122, 'Total loss': 0.4610873601842122}
2022-11-28 04:02:55,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:55,587 INFO:     Epoch: 32
2022-11-28 04:02:56,238 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48668743011563326, 'Total loss': 0.48668743011563326} | train loss {'Reaction outcome loss': 0.4621283811990355, 'Total loss': 0.4621283811990355}
2022-11-28 04:02:56,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:56,238 INFO:     Epoch: 33
2022-11-28 04:02:56,889 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5038644622924716, 'Total loss': 0.5038644622924716} | train loss {'Reaction outcome loss': 0.46216923853413006, 'Total loss': 0.46216923853413006}
2022-11-28 04:02:56,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:56,889 INFO:     Epoch: 34
2022-11-28 04:02:57,540 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48504084417986315, 'Total loss': 0.48504084417986315} | train loss {'Reaction outcome loss': 0.4721399177415449, 'Total loss': 0.4721399177415449}
2022-11-28 04:02:57,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:57,541 INFO:     Epoch: 35
2022-11-28 04:02:58,200 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5008218780506489, 'Total loss': 0.5008218780506489} | train loss {'Reaction outcome loss': 0.46605329050636685, 'Total loss': 0.46605329050636685}
2022-11-28 04:02:58,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:58,200 INFO:     Epoch: 36
2022-11-28 04:02:58,858 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46755319036716636, 'Total loss': 0.46755319036716636} | train loss {'Reaction outcome loss': 0.46784061969059415, 'Total loss': 0.46784061969059415}
2022-11-28 04:02:58,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:58,858 INFO:     Epoch: 37
2022-11-28 04:02:59,509 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4874031869478004, 'Total loss': 0.4874031869478004} | train loss {'Reaction outcome loss': 0.4629825645538627, 'Total loss': 0.4629825645538627}
2022-11-28 04:02:59,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:02:59,509 INFO:     Epoch: 38
2022-11-28 04:03:00,160 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5017262239788853, 'Total loss': 0.5017262239788853} | train loss {'Reaction outcome loss': 0.46351703946463396, 'Total loss': 0.46351703946463396}
2022-11-28 04:03:00,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:00,161 INFO:     Epoch: 39
2022-11-28 04:03:00,811 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48342924131903536, 'Total loss': 0.48342924131903536} | train loss {'Reaction outcome loss': 0.4627198756168612, 'Total loss': 0.4627198756168612}
2022-11-28 04:03:00,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:00,812 INFO:     Epoch: 40
2022-11-28 04:03:01,460 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47570723225904066, 'Total loss': 0.47570723225904066} | train loss {'Reaction outcome loss': 0.45943641253426426, 'Total loss': 0.45943641253426426}
2022-11-28 04:03:01,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:01,460 INFO:     Epoch: 41
2022-11-28 04:03:02,107 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48361412522404695, 'Total loss': 0.48361412522404695} | train loss {'Reaction outcome loss': 0.46098120846464985, 'Total loss': 0.46098120846464985}
2022-11-28 04:03:02,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:02,108 INFO:     Epoch: 42
2022-11-28 04:03:02,756 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4874030687781267, 'Total loss': 0.4874030687781267} | train loss {'Reaction outcome loss': 0.4674505319018833, 'Total loss': 0.4674505319018833}
2022-11-28 04:03:02,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:02,756 INFO:     Epoch: 43
2022-11-28 04:03:03,406 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47874330018841943, 'Total loss': 0.47874330018841943} | train loss {'Reaction outcome loss': 0.4561431306551714, 'Total loss': 0.4561431306551714}
2022-11-28 04:03:03,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:03,407 INFO:     Epoch: 44
2022-11-28 04:03:04,062 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4812422623468, 'Total loss': 0.4812422623468} | train loss {'Reaction outcome loss': 0.45643256891702044, 'Total loss': 0.45643256891702044}
2022-11-28 04:03:04,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:04,062 INFO:     Epoch: 45
2022-11-28 04:03:04,717 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.460297561315603, 'Total loss': 0.460297561315603} | train loss {'Reaction outcome loss': 0.46713285783275227, 'Total loss': 0.46713285783275227}
2022-11-28 04:03:04,717 INFO:     Found new best model at epoch 45
2022-11-28 04:03:04,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:04,718 INFO:     Epoch: 46
2022-11-28 04:03:05,374 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46743981782780136, 'Total loss': 0.46743981782780136} | train loss {'Reaction outcome loss': 0.4599315360127414, 'Total loss': 0.4599315360127414}
2022-11-28 04:03:05,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:05,374 INFO:     Epoch: 47
2022-11-28 04:03:06,028 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4882377483123957, 'Total loss': 0.4882377483123957} | train loss {'Reaction outcome loss': 0.4610594720503346, 'Total loss': 0.4610594720503346}
2022-11-28 04:03:06,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:06,028 INFO:     Epoch: 48
2022-11-28 04:03:06,679 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4911698990089949, 'Total loss': 0.4911698990089949} | train loss {'Reaction outcome loss': 0.4613390307201714, 'Total loss': 0.4613390307201714}
2022-11-28 04:03:06,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:06,680 INFO:     Epoch: 49
2022-11-28 04:03:07,328 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5028746339470841, 'Total loss': 0.5028746339470841} | train loss {'Reaction outcome loss': 0.45808695739165683, 'Total loss': 0.45808695739165683}
2022-11-28 04:03:07,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:07,329 INFO:     Epoch: 50
2022-11-28 04:03:07,979 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4914199259392051, 'Total loss': 0.4914199259392051} | train loss {'Reaction outcome loss': 0.46025873384759075, 'Total loss': 0.46025873384759075}
2022-11-28 04:03:07,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:07,979 INFO:     Epoch: 51
2022-11-28 04:03:08,630 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5252294117628142, 'Total loss': 0.5252294117628142} | train loss {'Reaction outcome loss': 0.46368663397724513, 'Total loss': 0.46368663397724513}
2022-11-28 04:03:08,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:08,631 INFO:     Epoch: 52
2022-11-28 04:03:09,282 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48418797344662423, 'Total loss': 0.48418797344662423} | train loss {'Reaction outcome loss': 0.46180297617540983, 'Total loss': 0.46180297617540983}
2022-11-28 04:03:09,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:09,282 INFO:     Epoch: 53
2022-11-28 04:03:09,933 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4872386022362598, 'Total loss': 0.4872386022362598} | train loss {'Reaction outcome loss': 0.46627547524747304, 'Total loss': 0.46627547524747304}
2022-11-28 04:03:09,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:09,933 INFO:     Epoch: 54
2022-11-28 04:03:10,586 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4805808743072111, 'Total loss': 0.4805808743072111} | train loss {'Reaction outcome loss': 0.4533099213950947, 'Total loss': 0.4533099213950947}
2022-11-28 04:03:10,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:10,586 INFO:     Epoch: 55
2022-11-28 04:03:11,239 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5113268380248269, 'Total loss': 0.5113268380248269} | train loss {'Reaction outcome loss': 0.46227793731406086, 'Total loss': 0.46227793731406086}
2022-11-28 04:03:11,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:11,239 INFO:     Epoch: 56
2022-11-28 04:03:11,894 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4730663393125978, 'Total loss': 0.4730663393125978} | train loss {'Reaction outcome loss': 0.46522048408867883, 'Total loss': 0.46522048408867883}
2022-11-28 04:03:11,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:11,894 INFO:     Epoch: 57
2022-11-28 04:03:12,544 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49012059874312824, 'Total loss': 0.49012059874312824} | train loss {'Reaction outcome loss': 0.46002447269246227, 'Total loss': 0.46002447269246227}
2022-11-28 04:03:12,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:12,546 INFO:     Epoch: 58
2022-11-28 04:03:13,197 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4974478289138439, 'Total loss': 0.4974478289138439} | train loss {'Reaction outcome loss': 0.46607055918115087, 'Total loss': 0.46607055918115087}
2022-11-28 04:03:13,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:13,197 INFO:     Epoch: 59
2022-11-28 04:03:13,848 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46888703385064767, 'Total loss': 0.46888703385064767} | train loss {'Reaction outcome loss': 0.45988457326273446, 'Total loss': 0.45988457326273446}
2022-11-28 04:03:13,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:13,848 INFO:     Epoch: 60
2022-11-28 04:03:14,499 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47179880218450415, 'Total loss': 0.47179880218450415} | train loss {'Reaction outcome loss': 0.4619631950483947, 'Total loss': 0.4619631950483947}
2022-11-28 04:03:14,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:14,499 INFO:     Epoch: 61
2022-11-28 04:03:15,150 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47850909447947215, 'Total loss': 0.47850909447947215} | train loss {'Reaction outcome loss': 0.46333638688579937, 'Total loss': 0.46333638688579937}
2022-11-28 04:03:15,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:15,151 INFO:     Epoch: 62
2022-11-28 04:03:15,803 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49681350727413975, 'Total loss': 0.49681350727413975} | train loss {'Reaction outcome loss': 0.46084089864228595, 'Total loss': 0.46084089864228595}
2022-11-28 04:03:15,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:15,803 INFO:     Epoch: 63
2022-11-28 04:03:16,456 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5016537513150725, 'Total loss': 0.5016537513150725} | train loss {'Reaction outcome loss': 0.4612520964907818, 'Total loss': 0.4612520964907818}
2022-11-28 04:03:16,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:16,456 INFO:     Epoch: 64
2022-11-28 04:03:17,108 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4742695595635924, 'Total loss': 0.4742695595635924} | train loss {'Reaction outcome loss': 0.4638673972155227, 'Total loss': 0.4638673972155227}
2022-11-28 04:03:17,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:17,108 INFO:     Epoch: 65
2022-11-28 04:03:17,760 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48115436022364816, 'Total loss': 0.48115436022364816} | train loss {'Reaction outcome loss': 0.4608605400216384, 'Total loss': 0.4608605400216384}
2022-11-28 04:03:17,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:17,760 INFO:     Epoch: 66
2022-11-28 04:03:18,412 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5007286681685337, 'Total loss': 0.5007286681685337} | train loss {'Reaction outcome loss': 0.4590128274542875, 'Total loss': 0.4590128274542875}
2022-11-28 04:03:18,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:18,412 INFO:     Epoch: 67
2022-11-28 04:03:19,061 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4693954850352088, 'Total loss': 0.4693954850352088} | train loss {'Reaction outcome loss': 0.4598605697516535, 'Total loss': 0.4598605697516535}
2022-11-28 04:03:19,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:19,061 INFO:     Epoch: 68
2022-11-28 04:03:19,710 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4918961077928543, 'Total loss': 0.4918961077928543} | train loss {'Reaction outcome loss': 0.46055009222177207, 'Total loss': 0.46055009222177207}
2022-11-28 04:03:19,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:19,711 INFO:     Epoch: 69
2022-11-28 04:03:20,362 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4847507365914278, 'Total loss': 0.4847507365914278} | train loss {'Reaction outcome loss': 0.4598042373163778, 'Total loss': 0.4598042373163778}
2022-11-28 04:03:20,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:20,362 INFO:     Epoch: 70
2022-11-28 04:03:21,014 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4835955798625946, 'Total loss': 0.4835955798625946} | train loss {'Reaction outcome loss': 0.46326050730269464, 'Total loss': 0.46326050730269464}
2022-11-28 04:03:21,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:21,014 INFO:     Epoch: 71
2022-11-28 04:03:21,666 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47627362019793934, 'Total loss': 0.47627362019793934} | train loss {'Reaction outcome loss': 0.4578064861173024, 'Total loss': 0.4578064861173024}
2022-11-28 04:03:21,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:21,666 INFO:     Epoch: 72
2022-11-28 04:03:22,321 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5031800429488338, 'Total loss': 0.5031800429488338} | train loss {'Reaction outcome loss': 0.462144780232281, 'Total loss': 0.462144780232281}
2022-11-28 04:03:22,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:22,321 INFO:     Epoch: 73
2022-11-28 04:03:22,972 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5031600816305294, 'Total loss': 0.5031600816305294} | train loss {'Reaction outcome loss': 0.45960451271690306, 'Total loss': 0.45960451271690306}
2022-11-28 04:03:22,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:22,972 INFO:     Epoch: 74
2022-11-28 04:03:23,624 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49340371129124666, 'Total loss': 0.49340371129124666} | train loss {'Reaction outcome loss': 0.46118199489400036, 'Total loss': 0.46118199489400036}
2022-11-28 04:03:23,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:23,624 INFO:     Epoch: 75
2022-11-28 04:03:24,277 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48211517306261287, 'Total loss': 0.48211517306261287} | train loss {'Reaction outcome loss': 0.45999895457605844, 'Total loss': 0.45999895457605844}
2022-11-28 04:03:24,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:24,277 INFO:     Epoch: 76
2022-11-28 04:03:24,932 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4722478417463081, 'Total loss': 0.4722478417463081} | train loss {'Reaction outcome loss': 0.4592225034950209, 'Total loss': 0.4592225034950209}
2022-11-28 04:03:24,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:24,932 INFO:     Epoch: 77
2022-11-28 04:03:25,584 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4766496014456416, 'Total loss': 0.4766496014456416} | train loss {'Reaction outcome loss': 0.46588257596385285, 'Total loss': 0.46588257596385285}
2022-11-28 04:03:25,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:25,584 INFO:     Epoch: 78
2022-11-28 04:03:26,234 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4686001393684121, 'Total loss': 0.4686001393684121} | train loss {'Reaction outcome loss': 0.46946481169491516, 'Total loss': 0.46946481169491516}
2022-11-28 04:03:26,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:26,234 INFO:     Epoch: 79
2022-11-28 04:03:26,889 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4960300489220508, 'Total loss': 0.4960300489220508} | train loss {'Reaction outcome loss': 0.45278180921908284, 'Total loss': 0.45278180921908284}
2022-11-28 04:03:26,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:26,890 INFO:     Epoch: 80
2022-11-28 04:03:27,544 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5411297471024269, 'Total loss': 0.5411297471024269} | train loss {'Reaction outcome loss': 0.4654948082065485, 'Total loss': 0.4654948082065485}
2022-11-28 04:03:27,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:27,544 INFO:     Epoch: 81
2022-11-28 04:03:28,194 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4880250903756119, 'Total loss': 0.4880250903756119} | train loss {'Reaction outcome loss': 0.4582664413286037, 'Total loss': 0.4582664413286037}
2022-11-28 04:03:28,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:28,195 INFO:     Epoch: 82
2022-11-28 04:03:28,844 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.496695403789365, 'Total loss': 0.496695403789365} | train loss {'Reaction outcome loss': 0.46048469829266186, 'Total loss': 0.46048469829266186}
2022-11-28 04:03:28,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:28,844 INFO:     Epoch: 83
2022-11-28 04:03:29,498 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47148860817731814, 'Total loss': 0.47148860817731814} | train loss {'Reaction outcome loss': 0.4603426873561789, 'Total loss': 0.4603426873561789}
2022-11-28 04:03:29,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:29,498 INFO:     Epoch: 84
2022-11-28 04:03:30,151 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4723933495061342, 'Total loss': 0.4723933495061342} | train loss {'Reaction outcome loss': 0.4611397045435476, 'Total loss': 0.4611397045435476}
2022-11-28 04:03:30,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:30,151 INFO:     Epoch: 85
2022-11-28 04:03:30,803 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.475357822554056, 'Total loss': 0.475357822554056} | train loss {'Reaction outcome loss': 0.46421362343625944, 'Total loss': 0.46421362343625944}
2022-11-28 04:03:30,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:30,803 INFO:     Epoch: 86
2022-11-28 04:03:31,454 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47823757834212727, 'Total loss': 0.47823757834212727} | train loss {'Reaction outcome loss': 0.45526589673073564, 'Total loss': 0.45526589673073564}
2022-11-28 04:03:31,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:31,455 INFO:     Epoch: 87
2022-11-28 04:03:32,104 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4956302507672199, 'Total loss': 0.4956302507672199} | train loss {'Reaction outcome loss': 0.4608685977024133, 'Total loss': 0.4608685977024133}
2022-11-28 04:03:32,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:32,104 INFO:     Epoch: 88
2022-11-28 04:03:32,755 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46411883207254634, 'Total loss': 0.46411883207254634} | train loss {'Reaction outcome loss': 0.4629582258277252, 'Total loss': 0.4629582258277252}
2022-11-28 04:03:32,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:32,755 INFO:     Epoch: 89
2022-11-28 04:03:33,407 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4773835148229155, 'Total loss': 0.4773835148229155} | train loss {'Reaction outcome loss': 0.46149655052872957, 'Total loss': 0.46149655052872957}
2022-11-28 04:03:33,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:33,408 INFO:     Epoch: 90
2022-11-28 04:03:34,060 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4785698770090591, 'Total loss': 0.4785698770090591} | train loss {'Reaction outcome loss': 0.4656987686137684, 'Total loss': 0.4656987686137684}
2022-11-28 04:03:34,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:34,060 INFO:     Epoch: 91
2022-11-28 04:03:34,710 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48592075116412586, 'Total loss': 0.48592075116412586} | train loss {'Reaction outcome loss': 0.46075552094300265, 'Total loss': 0.46075552094300265}
2022-11-28 04:03:34,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:34,710 INFO:     Epoch: 92
2022-11-28 04:03:35,363 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48467657281908877, 'Total loss': 0.48467657281908877} | train loss {'Reaction outcome loss': 0.45827632879868885, 'Total loss': 0.45827632879868885}
2022-11-28 04:03:35,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:35,363 INFO:     Epoch: 93
2022-11-28 04:03:36,019 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4802015434170878, 'Total loss': 0.4802015434170878} | train loss {'Reaction outcome loss': 0.4676781680557083, 'Total loss': 0.4676781680557083}
2022-11-28 04:03:36,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:36,019 INFO:     Epoch: 94
2022-11-28 04:03:36,673 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46625922932181246, 'Total loss': 0.46625922932181246} | train loss {'Reaction outcome loss': 0.4603847526013851, 'Total loss': 0.4603847526013851}
2022-11-28 04:03:36,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:36,673 INFO:     Epoch: 95
2022-11-28 04:03:37,323 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4842437945826109, 'Total loss': 0.4842437945826109} | train loss {'Reaction outcome loss': 0.46287546398454027, 'Total loss': 0.46287546398454027}
2022-11-28 04:03:37,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:37,324 INFO:     Epoch: 96
2022-11-28 04:03:37,975 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45625575267991353, 'Total loss': 0.45625575267991353} | train loss {'Reaction outcome loss': 0.46235583246242806, 'Total loss': 0.46235583246242806}
2022-11-28 04:03:37,975 INFO:     Found new best model at epoch 96
2022-11-28 04:03:37,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:37,976 INFO:     Epoch: 97
2022-11-28 04:03:38,628 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4623199195362801, 'Total loss': 0.4623199195362801} | train loss {'Reaction outcome loss': 0.4643997365578276, 'Total loss': 0.4643997365578276}
2022-11-28 04:03:38,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:38,628 INFO:     Epoch: 98
2022-11-28 04:03:39,280 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4816126376390457, 'Total loss': 0.4816126376390457} | train loss {'Reaction outcome loss': 0.45396914681205985, 'Total loss': 0.45396914681205985}
2022-11-28 04:03:39,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:39,280 INFO:     Epoch: 99
2022-11-28 04:03:39,936 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4848806237758592, 'Total loss': 0.4848806237758592} | train loss {'Reaction outcome loss': 0.4628034717113268, 'Total loss': 0.4628034717113268}
2022-11-28 04:03:39,936 INFO:     Best model found after epoch 97 of 100.
2022-11-28 04:03:39,936 INFO:   Done with stage: TRAINING
2022-11-28 04:03:39,936 INFO:   Starting stage: EVALUATION
2022-11-28 04:03:40,065 INFO:   Done with stage: EVALUATION
2022-11-28 04:03:40,065 INFO:   Leaving out SEQ value Fold_4
2022-11-28 04:03:40,078 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:03:40,078 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:03:40,715 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:03:40,718 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:03:40,785 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:03:40,785 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:03:40,785 INFO:     No hyperparam tuning for this model
2022-11-28 04:03:40,785 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:03:40,785 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:03:40,786 INFO:     None feature selector for col prot
2022-11-28 04:03:40,786 INFO:     None feature selector for col prot
2022-11-28 04:03:40,786 INFO:     None feature selector for col prot
2022-11-28 04:03:40,787 INFO:     None feature selector for col chem
2022-11-28 04:03:40,787 INFO:     None feature selector for col chem
2022-11-28 04:03:40,787 INFO:     None feature selector for col chem
2022-11-28 04:03:40,787 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:03:40,787 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:03:40,789 INFO:     Number of params in model 169651
2022-11-28 04:03:40,792 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:03:40,792 INFO:   Starting stage: TRAINING
2022-11-28 04:03:40,842 INFO:     Val loss before train {'Reaction outcome loss': 1.0067505010149695, 'Total loss': 1.0067505010149695}
2022-11-28 04:03:40,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:40,843 INFO:     Epoch: 0
2022-11-28 04:03:41,498 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5654216720299288, 'Total loss': 0.5654216720299288} | train loss {'Reaction outcome loss': 0.6834734535338928, 'Total loss': 0.6834734535338928}
2022-11-28 04:03:41,498 INFO:     Found new best model at epoch 0
2022-11-28 04:03:41,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:41,499 INFO:     Epoch: 1
2022-11-28 04:03:42,151 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6047291193496097, 'Total loss': 0.6047291193496097} | train loss {'Reaction outcome loss': 0.5894559602348172, 'Total loss': 0.5894559602348172}
2022-11-28 04:03:42,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:42,151 INFO:     Epoch: 2
2022-11-28 04:03:42,803 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5362691032615575, 'Total loss': 0.5362691032615575} | train loss {'Reaction outcome loss': 0.5657010563174073, 'Total loss': 0.5657010563174073}
2022-11-28 04:03:42,803 INFO:     Found new best model at epoch 2
2022-11-28 04:03:42,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:42,804 INFO:     Epoch: 3
2022-11-28 04:03:43,457 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5034718096933581, 'Total loss': 0.5034718096933581} | train loss {'Reaction outcome loss': 0.5395973593604808, 'Total loss': 0.5395973593604808}
2022-11-28 04:03:43,457 INFO:     Found new best model at epoch 3
2022-11-28 04:03:43,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:43,458 INFO:     Epoch: 4
2022-11-28 04:03:44,110 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4988439144058661, 'Total loss': 0.4988439144058661} | train loss {'Reaction outcome loss': 0.5370642476544089, 'Total loss': 0.5370642476544089}
2022-11-28 04:03:44,111 INFO:     Found new best model at epoch 4
2022-11-28 04:03:44,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:44,112 INFO:     Epoch: 5
2022-11-28 04:03:44,766 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5064844858239997, 'Total loss': 0.5064844858239997} | train loss {'Reaction outcome loss': 0.5182700505366131, 'Total loss': 0.5182700505366131}
2022-11-28 04:03:44,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:44,767 INFO:     Epoch: 6
2022-11-28 04:03:45,418 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4895766028626399, 'Total loss': 0.4895766028626399} | train loss {'Reaction outcome loss': 0.5265124286315879, 'Total loss': 0.5265124286315879}
2022-11-28 04:03:45,418 INFO:     Found new best model at epoch 6
2022-11-28 04:03:45,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:45,419 INFO:     Epoch: 7
2022-11-28 04:03:46,071 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5318357626145537, 'Total loss': 0.5318357626145537} | train loss {'Reaction outcome loss': 0.5165848685162407, 'Total loss': 0.5165848685162407}
2022-11-28 04:03:46,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:46,071 INFO:     Epoch: 8
2022-11-28 04:03:46,726 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47449406575072894, 'Total loss': 0.47449406575072894} | train loss {'Reaction outcome loss': 0.5134726724454335, 'Total loss': 0.5134726724454335}
2022-11-28 04:03:46,726 INFO:     Found new best model at epoch 8
2022-11-28 04:03:46,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:46,727 INFO:     Epoch: 9
2022-11-28 04:03:47,380 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4825149808417667, 'Total loss': 0.4825149808417667} | train loss {'Reaction outcome loss': 0.5058025394167219, 'Total loss': 0.5058025394167219}
2022-11-28 04:03:47,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:47,380 INFO:     Epoch: 10
2022-11-28 04:03:48,031 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5230053998529911, 'Total loss': 0.5230053998529911} | train loss {'Reaction outcome loss': 0.5122335946073338, 'Total loss': 0.5122335946073338}
2022-11-28 04:03:48,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:48,031 INFO:     Epoch: 11
2022-11-28 04:03:48,684 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49931056424975395, 'Total loss': 0.49931056424975395} | train loss {'Reaction outcome loss': 0.49740319331081545, 'Total loss': 0.49740319331081545}
2022-11-28 04:03:48,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:48,684 INFO:     Epoch: 12
2022-11-28 04:03:49,339 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45904716806994245, 'Total loss': 0.45904716806994245} | train loss {'Reaction outcome loss': 0.49914349524342283, 'Total loss': 0.49914349524342283}
2022-11-28 04:03:49,339 INFO:     Found new best model at epoch 12
2022-11-28 04:03:49,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:49,340 INFO:     Epoch: 13
2022-11-28 04:03:49,994 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4697383371266452, 'Total loss': 0.4697383371266452} | train loss {'Reaction outcome loss': 0.49316448776089417, 'Total loss': 0.49316448776089417}
2022-11-28 04:03:49,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:49,995 INFO:     Epoch: 14
2022-11-28 04:03:50,651 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49955854971300473, 'Total loss': 0.49955854971300473} | train loss {'Reaction outcome loss': 0.49681590491411637, 'Total loss': 0.49681590491411637}
2022-11-28 04:03:50,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:50,652 INFO:     Epoch: 15
2022-11-28 04:03:51,308 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4843920570882884, 'Total loss': 0.4843920570882884} | train loss {'Reaction outcome loss': 0.49472033582171615, 'Total loss': 0.49472033582171615}
2022-11-28 04:03:51,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:51,308 INFO:     Epoch: 16
2022-11-28 04:03:51,959 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.475391377102245, 'Total loss': 0.475391377102245} | train loss {'Reaction outcome loss': 0.4911936936329822, 'Total loss': 0.4911936936329822}
2022-11-28 04:03:51,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:51,959 INFO:     Epoch: 17
2022-11-28 04:03:52,609 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45104384439235384, 'Total loss': 0.45104384439235384} | train loss {'Reaction outcome loss': 0.49177134316794724, 'Total loss': 0.49177134316794724}
2022-11-28 04:03:52,609 INFO:     Found new best model at epoch 17
2022-11-28 04:03:52,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:52,610 INFO:     Epoch: 18
2022-11-28 04:03:53,261 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46504173563285306, 'Total loss': 0.46504173563285306} | train loss {'Reaction outcome loss': 0.48618523174402667, 'Total loss': 0.48618523174402667}
2022-11-28 04:03:53,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:53,261 INFO:     Epoch: 19
2022-11-28 04:03:53,913 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5010618824850429, 'Total loss': 0.5010618824850429} | train loss {'Reaction outcome loss': 0.4819642038977876, 'Total loss': 0.4819642038977876}
2022-11-28 04:03:53,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:53,913 INFO:     Epoch: 20
2022-11-28 04:03:54,565 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4692661782557314, 'Total loss': 0.4692661782557314} | train loss {'Reaction outcome loss': 0.5004911053545621, 'Total loss': 0.5004911053545621}
2022-11-28 04:03:54,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:54,565 INFO:     Epoch: 21
2022-11-28 04:03:55,216 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5088476972146467, 'Total loss': 0.5088476972146467} | train loss {'Reaction outcome loss': 0.48146647056754754, 'Total loss': 0.48146647056754754}
2022-11-28 04:03:55,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:55,217 INFO:     Epoch: 22
2022-11-28 04:03:55,867 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4757184867154468, 'Total loss': 0.4757184867154468} | train loss {'Reaction outcome loss': 0.48280859410154575, 'Total loss': 0.48280859410154575}
2022-11-28 04:03:55,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:55,867 INFO:     Epoch: 23
2022-11-28 04:03:56,520 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4864176355979659, 'Total loss': 0.4864176355979659} | train loss {'Reaction outcome loss': 0.48336720959264406, 'Total loss': 0.48336720959264406}
2022-11-28 04:03:56,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:56,520 INFO:     Epoch: 24
2022-11-28 04:03:57,168 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47620524940165604, 'Total loss': 0.47620524940165604} | train loss {'Reaction outcome loss': 0.4777468177737022, 'Total loss': 0.4777468177737022}
2022-11-28 04:03:57,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:57,169 INFO:     Epoch: 25
2022-11-28 04:03:57,820 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4467690692029216, 'Total loss': 0.4467690692029216} | train loss {'Reaction outcome loss': 0.4869171158391602, 'Total loss': 0.4869171158391602}
2022-11-28 04:03:57,820 INFO:     Found new best model at epoch 25
2022-11-28 04:03:57,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:57,821 INFO:     Epoch: 26
2022-11-28 04:03:58,471 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4691928557374261, 'Total loss': 0.4691928557374261} | train loss {'Reaction outcome loss': 0.4776558438125922, 'Total loss': 0.4776558438125922}
2022-11-28 04:03:58,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:58,471 INFO:     Epoch: 27
2022-11-28 04:03:59,123 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4647375981916081, 'Total loss': 0.4647375981916081} | train loss {'Reaction outcome loss': 0.4872523849715992, 'Total loss': 0.4872523849715992}
2022-11-28 04:03:59,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:59,123 INFO:     Epoch: 28
2022-11-28 04:03:59,772 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45986908640373836, 'Total loss': 0.45986908640373836} | train loss {'Reaction outcome loss': 0.4797737573482552, 'Total loss': 0.4797737573482552}
2022-11-28 04:03:59,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:03:59,772 INFO:     Epoch: 29
2022-11-28 04:04:00,422 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4703564278104089, 'Total loss': 0.4703564278104089} | train loss {'Reaction outcome loss': 0.478335341750359, 'Total loss': 0.478335341750359}
2022-11-28 04:04:00,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:00,422 INFO:     Epoch: 30
2022-11-28 04:04:01,073 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4615406986664642, 'Total loss': 0.4615406986664642} | train loss {'Reaction outcome loss': 0.48772575946486724, 'Total loss': 0.48772575946486724}
2022-11-28 04:04:01,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:01,074 INFO:     Epoch: 31
2022-11-28 04:04:01,723 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4648094905371016, 'Total loss': 0.4648094905371016} | train loss {'Reaction outcome loss': 0.48137563655571064, 'Total loss': 0.48137563655571064}
2022-11-28 04:04:01,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:01,724 INFO:     Epoch: 32
2022-11-28 04:04:02,372 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45661546289920807, 'Total loss': 0.45661546289920807} | train loss {'Reaction outcome loss': 0.4800641039804536, 'Total loss': 0.4800641039804536}
2022-11-28 04:04:02,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:02,372 INFO:     Epoch: 33
2022-11-28 04:04:03,025 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5470045527273958, 'Total loss': 0.5470045527273958} | train loss {'Reaction outcome loss': 0.47910702733360994, 'Total loss': 0.47910702733360994}
2022-11-28 04:04:03,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:03,025 INFO:     Epoch: 34
2022-11-28 04:04:03,675 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4503680156035857, 'Total loss': 0.4503680156035857} | train loss {'Reaction outcome loss': 0.47542498056985893, 'Total loss': 0.47542498056985893}
2022-11-28 04:04:03,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:03,676 INFO:     Epoch: 35
2022-11-28 04:04:04,325 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46290397576310416, 'Total loss': 0.46290397576310416} | train loss {'Reaction outcome loss': 0.47989065647125245, 'Total loss': 0.47989065647125245}
2022-11-28 04:04:04,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:04,325 INFO:     Epoch: 36
2022-11-28 04:04:04,978 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44350880045782437, 'Total loss': 0.44350880045782437} | train loss {'Reaction outcome loss': 0.4755099544719774, 'Total loss': 0.4755099544719774}
2022-11-28 04:04:04,978 INFO:     Found new best model at epoch 36
2022-11-28 04:04:04,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:04,979 INFO:     Epoch: 37
2022-11-28 04:04:05,631 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45638660206036136, 'Total loss': 0.45638660206036136} | train loss {'Reaction outcome loss': 0.46912352847201483, 'Total loss': 0.46912352847201483}
2022-11-28 04:04:05,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:05,631 INFO:     Epoch: 38
2022-11-28 04:04:06,285 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4371161457489837, 'Total loss': 0.4371161457489837} | train loss {'Reaction outcome loss': 0.48457042517102494, 'Total loss': 0.48457042517102494}
2022-11-28 04:04:06,285 INFO:     Found new best model at epoch 38
2022-11-28 04:04:06,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:06,286 INFO:     Epoch: 39
2022-11-28 04:04:06,938 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4642605320127173, 'Total loss': 0.4642605320127173} | train loss {'Reaction outcome loss': 0.47342241102335403, 'Total loss': 0.47342241102335403}
2022-11-28 04:04:06,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:06,939 INFO:     Epoch: 40
2022-11-28 04:04:07,587 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5405253795060244, 'Total loss': 0.5405253795060244} | train loss {'Reaction outcome loss': 0.4747424406664712, 'Total loss': 0.4747424406664712}
2022-11-28 04:04:07,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:07,587 INFO:     Epoch: 41
2022-11-28 04:04:08,241 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4631229263137687, 'Total loss': 0.4631229263137687} | train loss {'Reaction outcome loss': 0.4695006950777404, 'Total loss': 0.4695006950777404}
2022-11-28 04:04:08,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:08,241 INFO:     Epoch: 42
2022-11-28 04:04:08,894 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4614362825046886, 'Total loss': 0.4614362825046886} | train loss {'Reaction outcome loss': 0.47707178224714436, 'Total loss': 0.47707178224714436}
2022-11-28 04:04:08,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:08,894 INFO:     Epoch: 43
2022-11-28 04:04:09,546 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4534820413047617, 'Total loss': 0.4534820413047617} | train loss {'Reaction outcome loss': 0.47536970930440087, 'Total loss': 0.47536970930440087}
2022-11-28 04:04:09,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:09,547 INFO:     Epoch: 44
2022-11-28 04:04:10,202 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.436804823577404, 'Total loss': 0.436804823577404} | train loss {'Reaction outcome loss': 0.47792447531709864, 'Total loss': 0.47792447531709864}
2022-11-28 04:04:10,202 INFO:     Found new best model at epoch 44
2022-11-28 04:04:10,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:10,203 INFO:     Epoch: 45
2022-11-28 04:04:10,857 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46586224843155255, 'Total loss': 0.46586224843155255} | train loss {'Reaction outcome loss': 0.4790003503463706, 'Total loss': 0.4790003503463706}
2022-11-28 04:04:10,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:10,857 INFO:     Epoch: 46
2022-11-28 04:04:11,509 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.453472277996215, 'Total loss': 0.453472277996215} | train loss {'Reaction outcome loss': 0.47061928522830104, 'Total loss': 0.47061928522830104}
2022-11-28 04:04:11,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:11,509 INFO:     Epoch: 47
2022-11-28 04:04:12,161 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46288177591155877, 'Total loss': 0.46288177591155877} | train loss {'Reaction outcome loss': 0.474323921757085, 'Total loss': 0.474323921757085}
2022-11-28 04:04:12,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:12,162 INFO:     Epoch: 48
2022-11-28 04:04:12,814 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4272420900789174, 'Total loss': 0.4272420900789174} | train loss {'Reaction outcome loss': 0.4829490761367642, 'Total loss': 0.4829490761367642}
2022-11-28 04:04:12,815 INFO:     Found new best model at epoch 48
2022-11-28 04:04:12,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:12,815 INFO:     Epoch: 49
2022-11-28 04:04:13,471 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42504036324945366, 'Total loss': 0.42504036324945366} | train loss {'Reaction outcome loss': 0.47759191558069114, 'Total loss': 0.47759191558069114}
2022-11-28 04:04:13,471 INFO:     Found new best model at epoch 49
2022-11-28 04:04:13,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:13,472 INFO:     Epoch: 50
2022-11-28 04:04:14,125 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5129077261821791, 'Total loss': 0.5129077261821791} | train loss {'Reaction outcome loss': 0.46883675802727137, 'Total loss': 0.46883675802727137}
2022-11-28 04:04:14,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:14,125 INFO:     Epoch: 51
2022-11-28 04:04:14,777 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43792011216282845, 'Total loss': 0.43792011216282845} | train loss {'Reaction outcome loss': 0.478719103153871, 'Total loss': 0.478719103153871}
2022-11-28 04:04:14,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:14,778 INFO:     Epoch: 52
2022-11-28 04:04:15,430 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44121511720798234, 'Total loss': 0.44121511720798234} | train loss {'Reaction outcome loss': 0.4701088947909219, 'Total loss': 0.4701088947909219}
2022-11-28 04:04:15,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:15,430 INFO:     Epoch: 53
2022-11-28 04:04:16,080 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47321594100106845, 'Total loss': 0.47321594100106845} | train loss {'Reaction outcome loss': 0.4738185990829857, 'Total loss': 0.4738185990829857}
2022-11-28 04:04:16,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:16,080 INFO:     Epoch: 54
2022-11-28 04:04:16,732 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45220877772027795, 'Total loss': 0.45220877772027795} | train loss {'Reaction outcome loss': 0.47243510788800763, 'Total loss': 0.47243510788800763}
2022-11-28 04:04:16,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:16,732 INFO:     Epoch: 55
2022-11-28 04:04:17,385 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4523257562382655, 'Total loss': 0.4523257562382655} | train loss {'Reaction outcome loss': 0.4745260631551548, 'Total loss': 0.4745260631551548}
2022-11-28 04:04:17,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:17,385 INFO:     Epoch: 56
2022-11-28 04:04:18,044 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5073671273209832, 'Total loss': 0.5073671273209832} | train loss {'Reaction outcome loss': 0.46902609467506406, 'Total loss': 0.46902609467506406}
2022-11-28 04:04:18,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:18,044 INFO:     Epoch: 57
2022-11-28 04:04:18,698 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4258964203975417, 'Total loss': 0.4258964203975417} | train loss {'Reaction outcome loss': 0.47012693115643095, 'Total loss': 0.47012693115643095}
2022-11-28 04:04:18,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:18,698 INFO:     Epoch: 58
2022-11-28 04:04:19,347 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46047505736351013, 'Total loss': 0.46047505736351013} | train loss {'Reaction outcome loss': 0.4807764328864156, 'Total loss': 0.4807764328864156}
2022-11-28 04:04:19,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:19,348 INFO:     Epoch: 59
2022-11-28 04:04:20,002 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4435893926684829, 'Total loss': 0.4435893926684829} | train loss {'Reaction outcome loss': 0.47633050978183744, 'Total loss': 0.47633050978183744}
2022-11-28 04:04:20,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:20,002 INFO:     Epoch: 60
2022-11-28 04:04:20,654 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4236427379602736, 'Total loss': 0.4236427379602736} | train loss {'Reaction outcome loss': 0.47027572667112155, 'Total loss': 0.47027572667112155}
2022-11-28 04:04:20,654 INFO:     Found new best model at epoch 60
2022-11-28 04:04:20,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:20,655 INFO:     Epoch: 61
2022-11-28 04:04:21,308 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5209699770943685, 'Total loss': 0.5209699770943685} | train loss {'Reaction outcome loss': 0.4718892559105036, 'Total loss': 0.4718892559105036}
2022-11-28 04:04:21,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:21,309 INFO:     Epoch: 62
2022-11-28 04:04:21,963 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45664072036743164, 'Total loss': 0.45664072036743164} | train loss {'Reaction outcome loss': 0.4799879803341262, 'Total loss': 0.4799879803341262}
2022-11-28 04:04:21,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:21,963 INFO:     Epoch: 63
2022-11-28 04:04:22,615 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47089797258377075, 'Total loss': 0.47089797258377075} | train loss {'Reaction outcome loss': 0.47402978648944777, 'Total loss': 0.47402978648944777}
2022-11-28 04:04:22,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:22,615 INFO:     Epoch: 64
2022-11-28 04:04:23,267 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44534952261231164, 'Total loss': 0.44534952261231164} | train loss {'Reaction outcome loss': 0.4772831764148206, 'Total loss': 0.4772831764148206}
2022-11-28 04:04:23,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:23,268 INFO:     Epoch: 65
2022-11-28 04:04:23,919 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47246604615991766, 'Total loss': 0.47246604615991766} | train loss {'Reaction outcome loss': 0.4667720206538025, 'Total loss': 0.4667720206538025}
2022-11-28 04:04:23,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:23,919 INFO:     Epoch: 66
2022-11-28 04:04:24,569 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4513692148029804, 'Total loss': 0.4513692148029804} | train loss {'Reaction outcome loss': 0.4783737070706426, 'Total loss': 0.4783737070706426}
2022-11-28 04:04:24,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:24,569 INFO:     Epoch: 67
2022-11-28 04:04:25,222 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46918006478385493, 'Total loss': 0.46918006478385493} | train loss {'Reaction outcome loss': 0.4768749452367121, 'Total loss': 0.4768749452367121}
2022-11-28 04:04:25,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:25,222 INFO:     Epoch: 68
2022-11-28 04:04:25,874 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47500416230071674, 'Total loss': 0.47500416230071674} | train loss {'Reaction outcome loss': 0.47600334910105685, 'Total loss': 0.47600334910105685}
2022-11-28 04:04:25,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:25,875 INFO:     Epoch: 69
2022-11-28 04:04:26,529 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48246424238790164, 'Total loss': 0.48246424238790164} | train loss {'Reaction outcome loss': 0.47225561281856226, 'Total loss': 0.47225561281856226}
2022-11-28 04:04:26,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:26,529 INFO:     Epoch: 70
2022-11-28 04:04:27,182 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4396934329786084, 'Total loss': 0.4396934329786084} | train loss {'Reaction outcome loss': 0.47323434559666383, 'Total loss': 0.47323434559666383}
2022-11-28 04:04:27,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:27,182 INFO:     Epoch: 71
2022-11-28 04:04:27,835 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46022658625786955, 'Total loss': 0.46022658625786955} | train loss {'Reaction outcome loss': 0.4779970316254363, 'Total loss': 0.4779970316254363}
2022-11-28 04:04:27,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:27,835 INFO:     Epoch: 72
2022-11-28 04:04:28,490 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4546544677154584, 'Total loss': 0.4546544677154584} | train loss {'Reaction outcome loss': 0.4720702735136966, 'Total loss': 0.4720702735136966}
2022-11-28 04:04:28,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:28,490 INFO:     Epoch: 73
2022-11-28 04:04:29,141 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45380792224949057, 'Total loss': 0.45380792224949057} | train loss {'Reaction outcome loss': 0.47732560871815194, 'Total loss': 0.47732560871815194}
2022-11-28 04:04:29,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:29,141 INFO:     Epoch: 74
2022-11-28 04:04:29,792 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5387231057340448, 'Total loss': 0.5387231057340448} | train loss {'Reaction outcome loss': 0.47325109602237236, 'Total loss': 0.47325109602237236}
2022-11-28 04:04:29,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:29,792 INFO:     Epoch: 75
2022-11-28 04:04:30,446 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44609178314832126, 'Total loss': 0.44609178314832126} | train loss {'Reaction outcome loss': 0.4710149460909318, 'Total loss': 0.4710149460909318}
2022-11-28 04:04:30,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:30,447 INFO:     Epoch: 76
2022-11-28 04:04:31,101 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.470891287042336, 'Total loss': 0.470891287042336} | train loss {'Reaction outcome loss': 0.47604581403489016, 'Total loss': 0.47604581403489016}
2022-11-28 04:04:31,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:31,101 INFO:     Epoch: 77
2022-11-28 04:04:31,755 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5048519356006925, 'Total loss': 0.5048519356006925} | train loss {'Reaction outcome loss': 0.47540072816975265, 'Total loss': 0.47540072816975265}
2022-11-28 04:04:31,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:31,755 INFO:     Epoch: 78
2022-11-28 04:04:32,407 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4550927189940756, 'Total loss': 0.4550927189940756} | train loss {'Reaction outcome loss': 0.47437394230949637, 'Total loss': 0.47437394230949637}
2022-11-28 04:04:32,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:32,407 INFO:     Epoch: 79
2022-11-28 04:04:33,062 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4846192290159789, 'Total loss': 0.4846192290159789} | train loss {'Reaction outcome loss': 0.47688323551294753, 'Total loss': 0.47688323551294753}
2022-11-28 04:04:33,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:33,063 INFO:     Epoch: 80
2022-11-28 04:04:33,720 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4815415960143913, 'Total loss': 0.4815415960143913} | train loss {'Reaction outcome loss': 0.47446027051429357, 'Total loss': 0.47446027051429357}
2022-11-28 04:04:33,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:33,721 INFO:     Epoch: 81
2022-11-28 04:04:34,374 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43912586908448825, 'Total loss': 0.43912586908448825} | train loss {'Reaction outcome loss': 0.46652728708422914, 'Total loss': 0.46652728708422914}
2022-11-28 04:04:34,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:34,374 INFO:     Epoch: 82
2022-11-28 04:04:35,026 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44486823000691156, 'Total loss': 0.44486823000691156} | train loss {'Reaction outcome loss': 0.4696756101384455, 'Total loss': 0.4696756101384455}
2022-11-28 04:04:35,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:35,026 INFO:     Epoch: 83
2022-11-28 04:04:35,676 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48650219426913693, 'Total loss': 0.48650219426913693} | train loss {'Reaction outcome loss': 0.47597954705053447, 'Total loss': 0.47597954705053447}
2022-11-28 04:04:35,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:35,676 INFO:     Epoch: 84
2022-11-28 04:04:36,327 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4512988559224389, 'Total loss': 0.4512988559224389} | train loss {'Reaction outcome loss': 0.47760081771685153, 'Total loss': 0.47760081771685153}
2022-11-28 04:04:36,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:36,327 INFO:     Epoch: 85
2022-11-28 04:04:36,980 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45961481806906784, 'Total loss': 0.45961481806906784} | train loss {'Reaction outcome loss': 0.4734018613489307, 'Total loss': 0.4734018613489307}
2022-11-28 04:04:36,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:36,981 INFO:     Epoch: 86
2022-11-28 04:04:37,634 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47443660111589864, 'Total loss': 0.47443660111589864} | train loss {'Reaction outcome loss': 0.4705655572365741, 'Total loss': 0.4705655572365741}
2022-11-28 04:04:37,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:37,635 INFO:     Epoch: 87
2022-11-28 04:04:38,290 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4363673258234154, 'Total loss': 0.4363673258234154} | train loss {'Reaction outcome loss': 0.47639824206731757, 'Total loss': 0.47639824206731757}
2022-11-28 04:04:38,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:38,290 INFO:     Epoch: 88
2022-11-28 04:04:38,944 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4546769701621749, 'Total loss': 0.4546769701621749} | train loss {'Reaction outcome loss': 0.4744846957374592, 'Total loss': 0.4744846957374592}
2022-11-28 04:04:38,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:38,944 INFO:     Epoch: 89
2022-11-28 04:04:39,594 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4732052924280817, 'Total loss': 0.4732052924280817} | train loss {'Reaction outcome loss': 0.4734091573527881, 'Total loss': 0.4734091573527881}
2022-11-28 04:04:39,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:39,594 INFO:     Epoch: 90
2022-11-28 04:04:40,247 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4416970414194194, 'Total loss': 0.4416970414194194} | train loss {'Reaction outcome loss': 0.4729423066487118, 'Total loss': 0.4729423066487118}
2022-11-28 04:04:40,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:40,248 INFO:     Epoch: 91
2022-11-28 04:04:40,902 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4471237151460214, 'Total loss': 0.4471237151460214} | train loss {'Reaction outcome loss': 0.4748866418186499, 'Total loss': 0.4748866418186499}
2022-11-28 04:04:40,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:40,902 INFO:     Epoch: 92
2022-11-28 04:04:41,559 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5190347345037893, 'Total loss': 0.5190347345037893} | train loss {'Reaction outcome loss': 0.4752968218861794, 'Total loss': 0.4752968218861794}
2022-11-28 04:04:41,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:41,559 INFO:     Epoch: 93
2022-11-28 04:04:42,215 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45660881901329214, 'Total loss': 0.45660881901329214} | train loss {'Reaction outcome loss': 0.47381297605378286, 'Total loss': 0.47381297605378286}
2022-11-28 04:04:42,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:42,215 INFO:     Epoch: 94
2022-11-28 04:04:42,869 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4640868285840208, 'Total loss': 0.4640868285840208} | train loss {'Reaction outcome loss': 0.46717476309562217, 'Total loss': 0.46717476309562217}
2022-11-28 04:04:42,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:42,869 INFO:     Epoch: 95
2022-11-28 04:04:43,526 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4506897916170684, 'Total loss': 0.4506897916170684} | train loss {'Reaction outcome loss': 0.4767826512151835, 'Total loss': 0.4767826512151835}
2022-11-28 04:04:43,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:43,526 INFO:     Epoch: 96
2022-11-28 04:04:44,184 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4679709527302872, 'Total loss': 0.4679709527302872} | train loss {'Reaction outcome loss': 0.47534502343255647, 'Total loss': 0.47534502343255647}
2022-11-28 04:04:44,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:44,184 INFO:     Epoch: 97
2022-11-28 04:04:44,840 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5098099613731558, 'Total loss': 0.5098099613731558} | train loss {'Reaction outcome loss': 0.4723833113300557, 'Total loss': 0.4723833113300557}
2022-11-28 04:04:44,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:44,840 INFO:     Epoch: 98
2022-11-28 04:04:45,493 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43962317129427736, 'Total loss': 0.43962317129427736} | train loss {'Reaction outcome loss': 0.47494643902292055, 'Total loss': 0.47494643902292055}
2022-11-28 04:04:45,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:45,494 INFO:     Epoch: 99
2022-11-28 04:04:46,152 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46837572753429413, 'Total loss': 0.46837572753429413} | train loss {'Reaction outcome loss': 0.4747351828886538, 'Total loss': 0.4747351828886538}
2022-11-28 04:04:46,152 INFO:     Best model found after epoch 61 of 100.
2022-11-28 04:04:46,152 INFO:   Done with stage: TRAINING
2022-11-28 04:04:46,152 INFO:   Starting stage: EVALUATION
2022-11-28 04:04:46,277 INFO:   Done with stage: EVALUATION
2022-11-28 04:04:46,278 INFO:   Leaving out SEQ value Fold_5
2022-11-28 04:04:46,290 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:04:46,290 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:04:46,934 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:04:46,935 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:04:47,003 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:04:47,003 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:04:47,003 INFO:     No hyperparam tuning for this model
2022-11-28 04:04:47,003 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:04:47,003 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:04:47,004 INFO:     None feature selector for col prot
2022-11-28 04:04:47,004 INFO:     None feature selector for col prot
2022-11-28 04:04:47,004 INFO:     None feature selector for col prot
2022-11-28 04:04:47,004 INFO:     None feature selector for col chem
2022-11-28 04:04:47,005 INFO:     None feature selector for col chem
2022-11-28 04:04:47,005 INFO:     None feature selector for col chem
2022-11-28 04:04:47,005 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:04:47,005 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:04:47,006 INFO:     Number of params in model 169651
2022-11-28 04:04:47,009 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:04:47,009 INFO:   Starting stage: TRAINING
2022-11-28 04:04:47,060 INFO:     Val loss before train {'Reaction outcome loss': 1.0599865886298092, 'Total loss': 1.0599865886298092}
2022-11-28 04:04:47,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:47,060 INFO:     Epoch: 0
2022-11-28 04:04:47,725 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6102147197181528, 'Total loss': 0.6102147197181528} | train loss {'Reaction outcome loss': 0.6812995927717521, 'Total loss': 0.6812995927717521}
2022-11-28 04:04:47,725 INFO:     Found new best model at epoch 0
2022-11-28 04:04:47,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:47,726 INFO:     Epoch: 1
2022-11-28 04:04:48,386 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5537967221303419, 'Total loss': 0.5537967221303419} | train loss {'Reaction outcome loss': 0.57519561709904, 'Total loss': 0.57519561709904}
2022-11-28 04:04:48,386 INFO:     Found new best model at epoch 1
2022-11-28 04:04:48,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:48,387 INFO:     Epoch: 2
2022-11-28 04:04:49,048 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5443955825811083, 'Total loss': 0.5443955825811083} | train loss {'Reaction outcome loss': 0.5582077122530956, 'Total loss': 0.5582077122530956}
2022-11-28 04:04:49,048 INFO:     Found new best model at epoch 2
2022-11-28 04:04:49,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:49,049 INFO:     Epoch: 3
2022-11-28 04:04:49,708 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5301309878175909, 'Total loss': 0.5301309878175909} | train loss {'Reaction outcome loss': 0.5260914212417024, 'Total loss': 0.5260914212417024}
2022-11-28 04:04:49,709 INFO:     Found new best model at epoch 3
2022-11-28 04:04:49,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:49,709 INFO:     Epoch: 4
2022-11-28 04:04:50,368 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5085384608669714, 'Total loss': 0.5085384608669714} | train loss {'Reaction outcome loss': 0.5145703217519922, 'Total loss': 0.5145703217519922}
2022-11-28 04:04:50,368 INFO:     Found new best model at epoch 4
2022-11-28 04:04:50,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:50,369 INFO:     Epoch: 5
2022-11-28 04:04:51,025 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5248427221720869, 'Total loss': 0.5248427221720869} | train loss {'Reaction outcome loss': 0.5027042785395495, 'Total loss': 0.5027042785395495}
2022-11-28 04:04:51,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:51,026 INFO:     Epoch: 6
2022-11-28 04:04:51,686 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4942181750454686, 'Total loss': 0.4942181750454686} | train loss {'Reaction outcome loss': 0.5154044529807712, 'Total loss': 0.5154044529807712}
2022-11-28 04:04:51,687 INFO:     Found new best model at epoch 6
2022-11-28 04:04:51,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:51,688 INFO:     Epoch: 7
2022-11-28 04:04:52,346 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5216343269090761, 'Total loss': 0.5216343269090761} | train loss {'Reaction outcome loss': 0.5093281020519704, 'Total loss': 0.5093281020519704}
2022-11-28 04:04:52,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:52,346 INFO:     Epoch: 8
2022-11-28 04:04:53,004 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48452735412865877, 'Total loss': 0.48452735412865877} | train loss {'Reaction outcome loss': 0.4939953825975719, 'Total loss': 0.4939953825975719}
2022-11-28 04:04:53,004 INFO:     Found new best model at epoch 8
2022-11-28 04:04:53,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:53,005 INFO:     Epoch: 9
2022-11-28 04:04:53,666 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5278418186036024, 'Total loss': 0.5278418186036024} | train loss {'Reaction outcome loss': 0.486618630267559, 'Total loss': 0.486618630267559}
2022-11-28 04:04:53,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:53,666 INFO:     Epoch: 10
2022-11-28 04:04:54,325 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5206908282231201, 'Total loss': 0.5206908282231201} | train loss {'Reaction outcome loss': 0.48328323420966685, 'Total loss': 0.48328323420966685}
2022-11-28 04:04:54,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:54,325 INFO:     Epoch: 11
2022-11-28 04:04:54,981 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5146517394618555, 'Total loss': 0.5146517394618555} | train loss {'Reaction outcome loss': 0.49535532705938284, 'Total loss': 0.49535532705938284}
2022-11-28 04:04:54,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:54,982 INFO:     Epoch: 12
2022-11-28 04:04:55,641 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4809669850563461, 'Total loss': 0.4809669850563461} | train loss {'Reaction outcome loss': 0.4790118564719613, 'Total loss': 0.4790118564719613}
2022-11-28 04:04:55,641 INFO:     Found new best model at epoch 12
2022-11-28 04:04:55,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:55,642 INFO:     Epoch: 13
2022-11-28 04:04:56,301 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5167743997140364, 'Total loss': 0.5167743997140364} | train loss {'Reaction outcome loss': 0.47981599558461535, 'Total loss': 0.47981599558461535}
2022-11-28 04:04:56,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:56,301 INFO:     Epoch: 14
2022-11-28 04:04:56,958 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5124455957927487, 'Total loss': 0.5124455957927487} | train loss {'Reaction outcome loss': 0.4831759764356652, 'Total loss': 0.4831759764356652}
2022-11-28 04:04:56,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:56,958 INFO:     Epoch: 15
2022-11-28 04:04:57,618 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5297416326674548, 'Total loss': 0.5297416326674548} | train loss {'Reaction outcome loss': 0.4823833921780953, 'Total loss': 0.4823833921780953}
2022-11-28 04:04:57,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:57,618 INFO:     Epoch: 16
2022-11-28 04:04:58,275 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5006331872533668, 'Total loss': 0.5006331872533668} | train loss {'Reaction outcome loss': 0.47003094239635507, 'Total loss': 0.47003094239635507}
2022-11-28 04:04:58,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:58,276 INFO:     Epoch: 17
2022-11-28 04:04:58,934 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5096521377563477, 'Total loss': 0.5096521377563477} | train loss {'Reaction outcome loss': 0.4755136960069178, 'Total loss': 0.4755136960069178}
2022-11-28 04:04:58,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:58,934 INFO:     Epoch: 18
2022-11-28 04:04:59,588 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4821889183738015, 'Total loss': 0.4821889183738015} | train loss {'Reaction outcome loss': 0.4739259210714942, 'Total loss': 0.4739259210714942}
2022-11-28 04:04:59,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:04:59,588 INFO:     Epoch: 19
2022-11-28 04:05:00,246 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.547299384732138, 'Total loss': 0.547299384732138} | train loss {'Reaction outcome loss': 0.46924697085913375, 'Total loss': 0.46924697085913375}
2022-11-28 04:05:00,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:00,246 INFO:     Epoch: 20
2022-11-28 04:05:00,904 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45218881558288226, 'Total loss': 0.45218881558288226} | train loss {'Reaction outcome loss': 0.4827687838661526, 'Total loss': 0.4827687838661526}
2022-11-28 04:05:00,904 INFO:     Found new best model at epoch 20
2022-11-28 04:05:00,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:00,905 INFO:     Epoch: 21
2022-11-28 04:05:01,563 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4847157621248202, 'Total loss': 0.4847157621248202} | train loss {'Reaction outcome loss': 0.4677733183397274, 'Total loss': 0.4677733183397274}
2022-11-28 04:05:01,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:01,563 INFO:     Epoch: 22
2022-11-28 04:05:02,219 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45718486640941014, 'Total loss': 0.45718486640941014} | train loss {'Reaction outcome loss': 0.47043309623171925, 'Total loss': 0.47043309623171925}
2022-11-28 04:05:02,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:02,220 INFO:     Epoch: 23
2022-11-28 04:05:02,875 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4900057745928114, 'Total loss': 0.4900057745928114} | train loss {'Reaction outcome loss': 0.46711587730930887, 'Total loss': 0.46711587730930887}
2022-11-28 04:05:02,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:02,875 INFO:     Epoch: 24
2022-11-28 04:05:03,534 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.575897644189271, 'Total loss': 0.575897644189271} | train loss {'Reaction outcome loss': 0.47924815866387327, 'Total loss': 0.47924815866387327}
2022-11-28 04:05:03,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:03,534 INFO:     Epoch: 25
2022-11-28 04:05:04,195 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.551455176689408, 'Total loss': 0.551455176689408} | train loss {'Reaction outcome loss': 0.4676345644088892, 'Total loss': 0.4676345644088892}
2022-11-28 04:05:04,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:04,196 INFO:     Epoch: 26
2022-11-28 04:05:04,860 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4758356572552161, 'Total loss': 0.4758356572552161} | train loss {'Reaction outcome loss': 0.4717717048248299, 'Total loss': 0.4717717048248299}
2022-11-28 04:05:04,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:04,860 INFO:     Epoch: 27
2022-11-28 04:05:05,522 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4758873636072332, 'Total loss': 0.4758873636072332} | train loss {'Reaction outcome loss': 0.46490853285861883, 'Total loss': 0.46490853285861883}
2022-11-28 04:05:05,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:05,523 INFO:     Epoch: 28
2022-11-28 04:05:06,183 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5018502348525957, 'Total loss': 0.5018502348525957} | train loss {'Reaction outcome loss': 0.46854285346834285, 'Total loss': 0.46854285346834285}
2022-11-28 04:05:06,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:06,183 INFO:     Epoch: 29
2022-11-28 04:05:06,843 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4671215347268365, 'Total loss': 0.4671215347268365} | train loss {'Reaction outcome loss': 0.4686622621438764, 'Total loss': 0.4686622621438764}
2022-11-28 04:05:06,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:06,843 INFO:     Epoch: 30
2022-11-28 04:05:07,506 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4599366438659755, 'Total loss': 0.4599366438659755} | train loss {'Reaction outcome loss': 0.4717915076234563, 'Total loss': 0.4717915076234563}
2022-11-28 04:05:07,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:07,506 INFO:     Epoch: 31
2022-11-28 04:05:08,167 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4995348724451932, 'Total loss': 0.4995348724451932} | train loss {'Reaction outcome loss': 0.4613564419842925, 'Total loss': 0.4613564419842925}
2022-11-28 04:05:08,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:08,167 INFO:     Epoch: 32
2022-11-28 04:05:08,829 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46765177696943283, 'Total loss': 0.46765177696943283} | train loss {'Reaction outcome loss': 0.45541713129623457, 'Total loss': 0.45541713129623457}
2022-11-28 04:05:08,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:08,830 INFO:     Epoch: 33
2022-11-28 04:05:09,489 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46769351308996027, 'Total loss': 0.46769351308996027} | train loss {'Reaction outcome loss': 0.4656122623516722, 'Total loss': 0.4656122623516722}
2022-11-28 04:05:09,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:09,490 INFO:     Epoch: 34
2022-11-28 04:05:10,150 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5520689643242143, 'Total loss': 0.5520689643242143} | train loss {'Reaction outcome loss': 0.4804777725022814, 'Total loss': 0.4804777725022814}
2022-11-28 04:05:10,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:10,151 INFO:     Epoch: 35
2022-11-28 04:05:10,817 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4572055089202794, 'Total loss': 0.4572055089202794} | train loss {'Reaction outcome loss': 0.47923825629930267, 'Total loss': 0.47923825629930267}
2022-11-28 04:05:10,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:10,817 INFO:     Epoch: 36
2022-11-28 04:05:11,482 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5258149389516223, 'Total loss': 0.5258149389516223} | train loss {'Reaction outcome loss': 0.4681810232761659, 'Total loss': 0.4681810232761659}
2022-11-28 04:05:11,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:11,483 INFO:     Epoch: 37
2022-11-28 04:05:12,145 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.500922522761605, 'Total loss': 0.500922522761605} | train loss {'Reaction outcome loss': 0.4653846161809527, 'Total loss': 0.4653846161809527}
2022-11-28 04:05:12,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:12,145 INFO:     Epoch: 38
2022-11-28 04:05:12,806 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4944332919337533, 'Total loss': 0.4944332919337533} | train loss {'Reaction outcome loss': 0.46747487679270927, 'Total loss': 0.46747487679270927}
2022-11-28 04:05:12,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:12,806 INFO:     Epoch: 39
2022-11-28 04:05:13,466 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47468808090144937, 'Total loss': 0.47468808090144937} | train loss {'Reaction outcome loss': 0.4547353437705803, 'Total loss': 0.4547353437705803}
2022-11-28 04:05:13,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:13,466 INFO:     Epoch: 40
2022-11-28 04:05:14,127 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4762409156696363, 'Total loss': 0.4762409156696363} | train loss {'Reaction outcome loss': 0.4596533552943333, 'Total loss': 0.4596533552943333}
2022-11-28 04:05:14,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:14,127 INFO:     Epoch: 41
2022-11-28 04:05:14,787 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.497962259772149, 'Total loss': 0.497962259772149} | train loss {'Reaction outcome loss': 0.4637750244816305, 'Total loss': 0.4637750244816305}
2022-11-28 04:05:14,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:14,787 INFO:     Epoch: 42
2022-11-28 04:05:15,447 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4748299599371173, 'Total loss': 0.4748299599371173} | train loss {'Reaction outcome loss': 0.4673179790437946, 'Total loss': 0.4673179790437946}
2022-11-28 04:05:15,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:15,448 INFO:     Epoch: 43
2022-11-28 04:05:16,109 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5035723596811295, 'Total loss': 0.5035723596811295} | train loss {'Reaction outcome loss': 0.46112903035604036, 'Total loss': 0.46112903035604036}
2022-11-28 04:05:16,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:16,110 INFO:     Epoch: 44
2022-11-28 04:05:16,773 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5033311959017407, 'Total loss': 0.5033311959017407} | train loss {'Reaction outcome loss': 0.47016383384765403, 'Total loss': 0.47016383384765403}
2022-11-28 04:05:16,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:16,773 INFO:     Epoch: 45
2022-11-28 04:05:17,434 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4773284244266423, 'Total loss': 0.4773284244266423} | train loss {'Reaction outcome loss': 0.4686141624322787, 'Total loss': 0.4686141624322787}
2022-11-28 04:05:17,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:17,435 INFO:     Epoch: 46
2022-11-28 04:05:18,096 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4603974988514727, 'Total loss': 0.4603974988514727} | train loss {'Reaction outcome loss': 0.46724216793833473, 'Total loss': 0.46724216793833473}
2022-11-28 04:05:18,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:18,096 INFO:     Epoch: 47
2022-11-28 04:05:18,757 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4709070534868674, 'Total loss': 0.4709070534868674} | train loss {'Reaction outcome loss': 0.46070537670903844, 'Total loss': 0.46070537670903844}
2022-11-28 04:05:18,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:18,757 INFO:     Epoch: 48
2022-11-28 04:05:19,418 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49420795115557586, 'Total loss': 0.49420795115557586} | train loss {'Reaction outcome loss': 0.4706707327741647, 'Total loss': 0.4706707327741647}
2022-11-28 04:05:19,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:19,419 INFO:     Epoch: 49
2022-11-28 04:05:20,080 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46542246876792476, 'Total loss': 0.46542246876792476} | train loss {'Reaction outcome loss': 0.45958206742277996, 'Total loss': 0.45958206742277996}
2022-11-28 04:05:20,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:20,080 INFO:     Epoch: 50
2022-11-28 04:05:20,742 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5376315966925838, 'Total loss': 0.5376315966925838} | train loss {'Reaction outcome loss': 0.46312169772987577, 'Total loss': 0.46312169772987577}
2022-11-28 04:05:20,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:20,742 INFO:     Epoch: 51
2022-11-28 04:05:21,404 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4994617727669803, 'Total loss': 0.4994617727669803} | train loss {'Reaction outcome loss': 0.4602717964755379, 'Total loss': 0.4602717964755379}
2022-11-28 04:05:21,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:21,404 INFO:     Epoch: 52
2022-11-28 04:05:22,069 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47533007033846597, 'Total loss': 0.47533007033846597} | train loss {'Reaction outcome loss': 0.47097460447475015, 'Total loss': 0.47097460447475015}
2022-11-28 04:05:22,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:22,069 INFO:     Epoch: 53
2022-11-28 04:05:22,733 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4853021035140211, 'Total loss': 0.4853021035140211} | train loss {'Reaction outcome loss': 0.46086817171409544, 'Total loss': 0.46086817171409544}
2022-11-28 04:05:22,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:22,734 INFO:     Epoch: 54
2022-11-28 04:05:23,396 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5171177207746289, 'Total loss': 0.5171177207746289} | train loss {'Reaction outcome loss': 0.46833782572193666, 'Total loss': 0.46833782572193666}
2022-11-28 04:05:23,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:23,396 INFO:     Epoch: 55
2022-11-28 04:05:24,058 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48369480635632167, 'Total loss': 0.48369480635632167} | train loss {'Reaction outcome loss': 0.4597798106882736, 'Total loss': 0.4597798106882736}
2022-11-28 04:05:24,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:24,058 INFO:     Epoch: 56
2022-11-28 04:05:24,721 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4504506875845519, 'Total loss': 0.4504506875845519} | train loss {'Reaction outcome loss': 0.45149358523668354, 'Total loss': 0.45149358523668354}
2022-11-28 04:05:24,722 INFO:     Found new best model at epoch 56
2022-11-28 04:05:24,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:24,722 INFO:     Epoch: 57
2022-11-28 04:05:25,386 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47305790842934087, 'Total loss': 0.47305790842934087} | train loss {'Reaction outcome loss': 0.456896284813823, 'Total loss': 0.456896284813823}
2022-11-28 04:05:25,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:25,386 INFO:     Epoch: 58
2022-11-28 04:05:26,048 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48907162655483594, 'Total loss': 0.48907162655483594} | train loss {'Reaction outcome loss': 0.4630712086828765, 'Total loss': 0.4630712086828765}
2022-11-28 04:05:26,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:26,048 INFO:     Epoch: 59
2022-11-28 04:05:26,709 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46857608143578877, 'Total loss': 0.46857608143578877} | train loss {'Reaction outcome loss': 0.4574370633642027, 'Total loss': 0.4574370633642027}
2022-11-28 04:05:26,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:26,709 INFO:     Epoch: 60
2022-11-28 04:05:27,369 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46065420047803357, 'Total loss': 0.46065420047803357} | train loss {'Reaction outcome loss': 0.46400977405700605, 'Total loss': 0.46400977405700605}
2022-11-28 04:05:27,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:27,369 INFO:     Epoch: 61
2022-11-28 04:05:28,030 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4762501167980107, 'Total loss': 0.4762501167980107} | train loss {'Reaction outcome loss': 0.45624070949400003, 'Total loss': 0.45624070949400003}
2022-11-28 04:05:28,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:28,030 INFO:     Epoch: 62
2022-11-28 04:05:28,692 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47757481241768057, 'Total loss': 0.47757481241768057} | train loss {'Reaction outcome loss': 0.47648319490404745, 'Total loss': 0.47648319490404745}
2022-11-28 04:05:28,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:28,692 INFO:     Epoch: 63
2022-11-28 04:05:29,353 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7440270524133336, 'Total loss': 0.7440270524133336} | train loss {'Reaction outcome loss': 0.4557280695510779, 'Total loss': 0.4557280695510779}
2022-11-28 04:05:29,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:29,353 INFO:     Epoch: 64
2022-11-28 04:05:30,018 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45937308635223995, 'Total loss': 0.45937308635223995} | train loss {'Reaction outcome loss': 0.46739113256938547, 'Total loss': 0.46739113256938547}
2022-11-28 04:05:30,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:30,018 INFO:     Epoch: 65
2022-11-28 04:05:30,678 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49427014318379486, 'Total loss': 0.49427014318379486} | train loss {'Reaction outcome loss': 0.4672266639738913, 'Total loss': 0.4672266639738913}
2022-11-28 04:05:30,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:30,678 INFO:     Epoch: 66
2022-11-28 04:05:31,341 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4908232106403871, 'Total loss': 0.4908232106403871} | train loss {'Reaction outcome loss': 0.46219403387013414, 'Total loss': 0.46219403387013414}
2022-11-28 04:05:31,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:31,341 INFO:     Epoch: 67
2022-11-28 04:05:32,006 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45004031468521466, 'Total loss': 0.45004031468521466} | train loss {'Reaction outcome loss': 0.4598108434725387, 'Total loss': 0.4598108434725387}
2022-11-28 04:05:32,006 INFO:     Found new best model at epoch 67
2022-11-28 04:05:32,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:32,007 INFO:     Epoch: 68
2022-11-28 04:05:32,666 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.522338658909906, 'Total loss': 0.522338658909906} | train loss {'Reaction outcome loss': 0.46325526636863046, 'Total loss': 0.46325526636863046}
2022-11-28 04:05:32,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:32,666 INFO:     Epoch: 69
2022-11-28 04:05:33,327 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.476698408072645, 'Total loss': 0.476698408072645} | train loss {'Reaction outcome loss': 0.4688713897457007, 'Total loss': 0.4688713897457007}
2022-11-28 04:05:33,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:33,327 INFO:     Epoch: 70
2022-11-28 04:05:33,992 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4693421944975853, 'Total loss': 0.4693421944975853} | train loss {'Reaction outcome loss': 0.4710826600490794, 'Total loss': 0.4710826600490794}
2022-11-28 04:05:33,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:33,992 INFO:     Epoch: 71
2022-11-28 04:05:34,657 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.479735808277672, 'Total loss': 0.479735808277672} | train loss {'Reaction outcome loss': 0.45502484770046797, 'Total loss': 0.45502484770046797}
2022-11-28 04:05:34,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:34,658 INFO:     Epoch: 72
2022-11-28 04:05:35,319 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5063469210131601, 'Total loss': 0.5063469210131601} | train loss {'Reaction outcome loss': 0.45623735263038745, 'Total loss': 0.45623735263038745}
2022-11-28 04:05:35,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:35,320 INFO:     Epoch: 73
2022-11-28 04:05:35,977 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4798832566223361, 'Total loss': 0.4798832566223361} | train loss {'Reaction outcome loss': 0.46637342758627554, 'Total loss': 0.46637342758627554}
2022-11-28 04:05:35,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:35,977 INFO:     Epoch: 74
2022-11-28 04:05:36,639 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49217159825969825, 'Total loss': 0.49217159825969825} | train loss {'Reaction outcome loss': 0.47703903566608546, 'Total loss': 0.47703903566608546}
2022-11-28 04:05:36,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:36,639 INFO:     Epoch: 75
2022-11-28 04:05:37,302 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44611063904382964, 'Total loss': 0.44611063904382964} | train loss {'Reaction outcome loss': 0.46774585623490184, 'Total loss': 0.46774585623490184}
2022-11-28 04:05:37,302 INFO:     Found new best model at epoch 75
2022-11-28 04:05:37,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:37,303 INFO:     Epoch: 76
2022-11-28 04:05:37,964 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5059634738347747, 'Total loss': 0.5059634738347747} | train loss {'Reaction outcome loss': 0.4603098118112155, 'Total loss': 0.4603098118112155}
2022-11-28 04:05:37,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:37,965 INFO:     Epoch: 77
2022-11-28 04:05:38,627 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4860525256530805, 'Total loss': 0.4860525256530805} | train loss {'Reaction outcome loss': 0.46758849838906935, 'Total loss': 0.46758849838906935}
2022-11-28 04:05:38,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:38,627 INFO:     Epoch: 78
2022-11-28 04:05:39,284 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.480454414405606, 'Total loss': 0.480454414405606} | train loss {'Reaction outcome loss': 0.45761998932853887, 'Total loss': 0.45761998932853887}
2022-11-28 04:05:39,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:39,285 INFO:     Epoch: 79
2022-11-28 04:05:39,947 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4655026373538104, 'Total loss': 0.4655026373538104} | train loss {'Reaction outcome loss': 0.4671099559377562, 'Total loss': 0.4671099559377562}
2022-11-28 04:05:39,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:39,947 INFO:     Epoch: 80
2022-11-28 04:05:40,610 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5132349699058316, 'Total loss': 0.5132349699058316} | train loss {'Reaction outcome loss': 0.4606598185805174, 'Total loss': 0.4606598185805174}
2022-11-28 04:05:40,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:40,611 INFO:     Epoch: 81
2022-11-28 04:05:41,275 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.469049409031868, 'Total loss': 0.469049409031868} | train loss {'Reaction outcome loss': 0.4605937303922437, 'Total loss': 0.4605937303922437}
2022-11-28 04:05:41,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:41,275 INFO:     Epoch: 82
2022-11-28 04:05:41,937 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46642822670665657, 'Total loss': 0.46642822670665657} | train loss {'Reaction outcome loss': 0.4627682879597311, 'Total loss': 0.4627682879597311}
2022-11-28 04:05:41,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:41,938 INFO:     Epoch: 83
2022-11-28 04:05:42,600 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.479192566126585, 'Total loss': 0.479192566126585} | train loss {'Reaction outcome loss': 0.4619319884008483, 'Total loss': 0.4619319884008483}
2022-11-28 04:05:42,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:42,600 INFO:     Epoch: 84
2022-11-28 04:05:43,262 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4675729430534623, 'Total loss': 0.4675729430534623} | train loss {'Reaction outcome loss': 0.4625443739869334, 'Total loss': 0.4625443739869334}
2022-11-28 04:05:43,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:43,262 INFO:     Epoch: 85
2022-11-28 04:05:43,929 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48010857471010904, 'Total loss': 0.48010857471010904} | train loss {'Reaction outcome loss': 0.45811403841383547, 'Total loss': 0.45811403841383547}
2022-11-28 04:05:43,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:43,929 INFO:     Epoch: 86
2022-11-28 04:05:44,593 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.488778044892983, 'Total loss': 0.488778044892983} | train loss {'Reaction outcome loss': 0.46194572003109585, 'Total loss': 0.46194572003109585}
2022-11-28 04:05:44,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:44,593 INFO:     Epoch: 87
2022-11-28 04:05:45,251 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4742609973658215, 'Total loss': 0.4742609973658215} | train loss {'Reaction outcome loss': 0.47277932840320264, 'Total loss': 0.47277932840320264}
2022-11-28 04:05:45,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:45,252 INFO:     Epoch: 88
2022-11-28 04:05:45,911 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47631388394670054, 'Total loss': 0.47631388394670054} | train loss {'Reaction outcome loss': 0.46154699034174446, 'Total loss': 0.46154699034174446}
2022-11-28 04:05:45,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:45,911 INFO:     Epoch: 89
2022-11-28 04:05:46,575 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4750840094956485, 'Total loss': 0.4750840094956485} | train loss {'Reaction outcome loss': 0.46434099570685916, 'Total loss': 0.46434099570685916}
2022-11-28 04:05:46,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:46,575 INFO:     Epoch: 90
2022-11-28 04:05:47,236 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5527959499846805, 'Total loss': 0.5527959499846805} | train loss {'Reaction outcome loss': 0.4572400295360368, 'Total loss': 0.4572400295360368}
2022-11-28 04:05:47,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:47,237 INFO:     Epoch: 91
2022-11-28 04:05:47,890 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4604909951713952, 'Total loss': 0.4604909951713952} | train loss {'Reaction outcome loss': 0.47932332138783534, 'Total loss': 0.47932332138783534}
2022-11-28 04:05:47,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:47,890 INFO:     Epoch: 92
2022-11-28 04:05:48,540 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.522119558670304, 'Total loss': 0.522119558670304} | train loss {'Reaction outcome loss': 0.4683502130361221, 'Total loss': 0.4683502130361221}
2022-11-28 04:05:48,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:48,541 INFO:     Epoch: 93
2022-11-28 04:05:49,194 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48200446570461447, 'Total loss': 0.48200446570461447} | train loss {'Reaction outcome loss': 0.4656763631201949, 'Total loss': 0.4656763631201949}
2022-11-28 04:05:49,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:49,194 INFO:     Epoch: 94
2022-11-28 04:05:49,849 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44958911023356696, 'Total loss': 0.44958911023356696} | train loss {'Reaction outcome loss': 0.47674181411864786, 'Total loss': 0.47674181411864786}
2022-11-28 04:05:49,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:49,849 INFO:     Epoch: 95
2022-11-28 04:05:50,504 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49494795365767047, 'Total loss': 0.49494795365767047} | train loss {'Reaction outcome loss': 0.46542280978760736, 'Total loss': 0.46542280978760736}
2022-11-28 04:05:50,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:50,504 INFO:     Epoch: 96
2022-11-28 04:05:51,157 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47861968725919724, 'Total loss': 0.47861968725919724} | train loss {'Reaction outcome loss': 0.46678695529096037, 'Total loss': 0.46678695529096037}
2022-11-28 04:05:51,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:51,157 INFO:     Epoch: 97
2022-11-28 04:05:51,811 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46881886978041043, 'Total loss': 0.46881886978041043} | train loss {'Reaction outcome loss': 0.46185391778522267, 'Total loss': 0.46185391778522267}
2022-11-28 04:05:51,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:51,811 INFO:     Epoch: 98
2022-11-28 04:05:52,464 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4931807294487953, 'Total loss': 0.4931807294487953} | train loss {'Reaction outcome loss': 0.4626015819579001, 'Total loss': 0.4626015819579001}
2022-11-28 04:05:52,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:52,464 INFO:     Epoch: 99
2022-11-28 04:05:53,121 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47470335391434754, 'Total loss': 0.47470335391434754} | train loss {'Reaction outcome loss': 0.46508170670343313, 'Total loss': 0.46508170670343313}
2022-11-28 04:05:53,121 INFO:     Best model found after epoch 76 of 100.
2022-11-28 04:05:53,121 INFO:   Done with stage: TRAINING
2022-11-28 04:05:53,121 INFO:   Starting stage: EVALUATION
2022-11-28 04:05:53,239 INFO:   Done with stage: EVALUATION
2022-11-28 04:05:53,240 INFO:   Leaving out SEQ value Fold_6
2022-11-28 04:05:53,253 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:05:53,253 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:05:53,895 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:05:53,895 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:05:53,963 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:05:53,963 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:05:53,963 INFO:     No hyperparam tuning for this model
2022-11-28 04:05:53,964 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:05:53,964 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:05:53,964 INFO:     None feature selector for col prot
2022-11-28 04:05:53,964 INFO:     None feature selector for col prot
2022-11-28 04:05:53,964 INFO:     None feature selector for col prot
2022-11-28 04:05:53,965 INFO:     None feature selector for col chem
2022-11-28 04:05:53,965 INFO:     None feature selector for col chem
2022-11-28 04:05:53,965 INFO:     None feature selector for col chem
2022-11-28 04:05:53,965 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:05:53,965 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:05:53,967 INFO:     Number of params in model 169651
2022-11-28 04:05:53,970 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:05:53,970 INFO:   Starting stage: TRAINING
2022-11-28 04:05:54,021 INFO:     Val loss before train {'Reaction outcome loss': 0.9828066568483006, 'Total loss': 0.9828066568483006}
2022-11-28 04:05:54,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:54,021 INFO:     Epoch: 0
2022-11-28 04:05:54,684 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5927068503065542, 'Total loss': 0.5927068503065542} | train loss {'Reaction outcome loss': 0.6938368512257453, 'Total loss': 0.6938368512257453}
2022-11-28 04:05:54,684 INFO:     Found new best model at epoch 0
2022-11-28 04:05:54,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:54,685 INFO:     Epoch: 1
2022-11-28 04:05:55,340 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5613157681443475, 'Total loss': 0.5613157681443475} | train loss {'Reaction outcome loss': 0.5859182407899249, 'Total loss': 0.5859182407899249}
2022-11-28 04:05:55,340 INFO:     Found new best model at epoch 1
2022-11-28 04:05:55,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:55,341 INFO:     Epoch: 2
2022-11-28 04:05:55,999 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5306383503431623, 'Total loss': 0.5306383503431623} | train loss {'Reaction outcome loss': 0.5551456796425965, 'Total loss': 0.5551456796425965}
2022-11-28 04:05:55,999 INFO:     Found new best model at epoch 2
2022-11-28 04:05:56,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:56,000 INFO:     Epoch: 3
2022-11-28 04:05:56,662 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5011704428629442, 'Total loss': 0.5011704428629442} | train loss {'Reaction outcome loss': 0.535572919874422, 'Total loss': 0.535572919874422}
2022-11-28 04:05:56,662 INFO:     Found new best model at epoch 3
2022-11-28 04:05:56,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:56,663 INFO:     Epoch: 4
2022-11-28 04:05:57,323 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47336897118525073, 'Total loss': 0.47336897118525073} | train loss {'Reaction outcome loss': 0.5201338525981672, 'Total loss': 0.5201338525981672}
2022-11-28 04:05:57,323 INFO:     Found new best model at epoch 4
2022-11-28 04:05:57,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:57,324 INFO:     Epoch: 5
2022-11-28 04:05:57,984 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5071507472206246, 'Total loss': 0.5071507472206246} | train loss {'Reaction outcome loss': 0.520891223102808, 'Total loss': 0.520891223102808}
2022-11-28 04:05:57,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:57,984 INFO:     Epoch: 6
2022-11-28 04:05:58,643 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5578207874839957, 'Total loss': 0.5578207874839957} | train loss {'Reaction outcome loss': 0.5123476531476744, 'Total loss': 0.5123476531476744}
2022-11-28 04:05:58,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:58,644 INFO:     Epoch: 7
2022-11-28 04:05:59,308 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4800255467945879, 'Total loss': 0.4800255467945879} | train loss {'Reaction outcome loss': 0.4982829985599364, 'Total loss': 0.4982829985599364}
2022-11-28 04:05:59,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:59,308 INFO:     Epoch: 8
2022-11-28 04:05:59,971 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4732959886843508, 'Total loss': 0.4732959886843508} | train loss {'Reaction outcome loss': 0.5018092952067813, 'Total loss': 0.5018092952067813}
2022-11-28 04:05:59,971 INFO:     Found new best model at epoch 8
2022-11-28 04:05:59,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:05:59,972 INFO:     Epoch: 9
2022-11-28 04:06:00,634 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4807659482414072, 'Total loss': 0.4807659482414072} | train loss {'Reaction outcome loss': 0.49201360801535265, 'Total loss': 0.49201360801535265}
2022-11-28 04:06:00,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:00,634 INFO:     Epoch: 10
2022-11-28 04:06:01,295 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46427485025064513, 'Total loss': 0.46427485025064513} | train loss {'Reaction outcome loss': 0.4861789235785123, 'Total loss': 0.4861789235785123}
2022-11-28 04:06:01,295 INFO:     Found new best model at epoch 10
2022-11-28 04:06:01,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:01,295 INFO:     Epoch: 11
2022-11-28 04:06:01,956 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5210424532944505, 'Total loss': 0.5210424532944505} | train loss {'Reaction outcome loss': 0.48466888965377886, 'Total loss': 0.48466888965377886}
2022-11-28 04:06:01,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:01,956 INFO:     Epoch: 12
2022-11-28 04:06:02,619 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47948294336145575, 'Total loss': 0.47948294336145575} | train loss {'Reaction outcome loss': 0.48418324879340585, 'Total loss': 0.48418324879340585}
2022-11-28 04:06:02,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:02,619 INFO:     Epoch: 13
2022-11-28 04:06:03,277 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47146362879059533, 'Total loss': 0.47146362879059533} | train loss {'Reaction outcome loss': 0.4741855910828998, 'Total loss': 0.4741855910828998}
2022-11-28 04:06:03,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:03,277 INFO:     Epoch: 14
2022-11-28 04:06:03,939 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4532040405002507, 'Total loss': 0.4532040405002507} | train loss {'Reaction outcome loss': 0.47534935915422055, 'Total loss': 0.47534935915422055}
2022-11-28 04:06:03,939 INFO:     Found new best model at epoch 14
2022-11-28 04:06:03,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:03,940 INFO:     Epoch: 15
2022-11-28 04:06:04,597 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4971152117306536, 'Total loss': 0.4971152117306536} | train loss {'Reaction outcome loss': 0.4806327454505428, 'Total loss': 0.4806327454505428}
2022-11-28 04:06:04,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:04,598 INFO:     Epoch: 16
2022-11-28 04:06:05,258 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48317212001843884, 'Total loss': 0.48317212001843884} | train loss {'Reaction outcome loss': 0.4724911889061332, 'Total loss': 0.4724911889061332}
2022-11-28 04:06:05,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:05,259 INFO:     Epoch: 17
2022-11-28 04:06:05,918 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5009368346496061, 'Total loss': 0.5009368346496061} | train loss {'Reaction outcome loss': 0.4695331999851811, 'Total loss': 0.4695331999851811}
2022-11-28 04:06:05,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:05,918 INFO:     Epoch: 18
2022-11-28 04:06:06,580 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5203831446441737, 'Total loss': 0.5203831446441737} | train loss {'Reaction outcome loss': 0.48024397794037094, 'Total loss': 0.48024397794037094}
2022-11-28 04:06:06,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:06,580 INFO:     Epoch: 19
2022-11-28 04:06:07,241 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4679797664284706, 'Total loss': 0.4679797664284706} | train loss {'Reaction outcome loss': 0.47577958926558495, 'Total loss': 0.47577958926558495}
2022-11-28 04:06:07,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:07,241 INFO:     Epoch: 20
2022-11-28 04:06:07,898 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4767732129178264, 'Total loss': 0.4767732129178264} | train loss {'Reaction outcome loss': 0.4729422217895908, 'Total loss': 0.4729422217895908}
2022-11-28 04:06:07,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:07,899 INFO:     Epoch: 21
2022-11-28 04:06:08,558 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4561353105713021, 'Total loss': 0.4561353105713021} | train loss {'Reaction outcome loss': 0.47219039055128254, 'Total loss': 0.47219039055128254}
2022-11-28 04:06:08,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:08,558 INFO:     Epoch: 22
2022-11-28 04:06:09,218 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.449038337577473, 'Total loss': 0.449038337577473} | train loss {'Reaction outcome loss': 0.4652066326309596, 'Total loss': 0.4652066326309596}
2022-11-28 04:06:09,218 INFO:     Found new best model at epoch 22
2022-11-28 04:06:09,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:09,219 INFO:     Epoch: 23
2022-11-28 04:06:09,881 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45226590978828346, 'Total loss': 0.45226590978828346} | train loss {'Reaction outcome loss': 0.4623665076289927, 'Total loss': 0.4623665076289927}
2022-11-28 04:06:09,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:09,881 INFO:     Epoch: 24
2022-11-28 04:06:10,541 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45748531953854993, 'Total loss': 0.45748531953854993} | train loss {'Reaction outcome loss': 0.4724968382788281, 'Total loss': 0.4724968382788281}
2022-11-28 04:06:10,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:10,541 INFO:     Epoch: 25
2022-11-28 04:06:11,204 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45170696316794917, 'Total loss': 0.45170696316794917} | train loss {'Reaction outcome loss': 0.4658372796951763, 'Total loss': 0.4658372796951763}
2022-11-28 04:06:11,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:11,204 INFO:     Epoch: 26
2022-11-28 04:06:11,869 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4844146618111567, 'Total loss': 0.4844146618111567} | train loss {'Reaction outcome loss': 0.46661223423096443, 'Total loss': 0.46661223423096443}
2022-11-28 04:06:11,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:11,869 INFO:     Epoch: 27
2022-11-28 04:06:12,529 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4465270574119958, 'Total loss': 0.4465270574119958} | train loss {'Reaction outcome loss': 0.470176512195218, 'Total loss': 0.470176512195218}
2022-11-28 04:06:12,529 INFO:     Found new best model at epoch 27
2022-11-28 04:06:12,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:12,530 INFO:     Epoch: 28
2022-11-28 04:06:13,192 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4639727192168886, 'Total loss': 0.4639727192168886} | train loss {'Reaction outcome loss': 0.4681281776678178, 'Total loss': 0.4681281776678178}
2022-11-28 04:06:13,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:13,192 INFO:     Epoch: 29
2022-11-28 04:06:13,856 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44795512103221635, 'Total loss': 0.44795512103221635} | train loss {'Reaction outcome loss': 0.4669425970303916, 'Total loss': 0.4669425970303916}
2022-11-28 04:06:13,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:13,856 INFO:     Epoch: 30
2022-11-28 04:06:14,522 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4729590869762681, 'Total loss': 0.4729590869762681} | train loss {'Reaction outcome loss': 0.46516814148954805, 'Total loss': 0.46516814148954805}
2022-11-28 04:06:14,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:14,522 INFO:     Epoch: 31
2022-11-28 04:06:15,184 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43456184017387306, 'Total loss': 0.43456184017387306} | train loss {'Reaction outcome loss': 0.4583128284542791, 'Total loss': 0.4583128284542791}
2022-11-28 04:06:15,184 INFO:     Found new best model at epoch 31
2022-11-28 04:06:15,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:15,185 INFO:     Epoch: 32
2022-11-28 04:06:15,844 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4941803772341121, 'Total loss': 0.4941803772341121} | train loss {'Reaction outcome loss': 0.4655477936349569, 'Total loss': 0.4655477936349569}
2022-11-28 04:06:15,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:15,844 INFO:     Epoch: 33
2022-11-28 04:06:16,504 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4637122523378242, 'Total loss': 0.4637122523378242} | train loss {'Reaction outcome loss': 0.461515276482509, 'Total loss': 0.461515276482509}
2022-11-28 04:06:16,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:16,504 INFO:     Epoch: 34
2022-11-28 04:06:17,165 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44921208681030705, 'Total loss': 0.44921208681030705} | train loss {'Reaction outcome loss': 0.4599914744256004, 'Total loss': 0.4599914744256004}
2022-11-28 04:06:17,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:17,165 INFO:     Epoch: 35
2022-11-28 04:06:17,827 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5186773768880151, 'Total loss': 0.5186773768880151} | train loss {'Reaction outcome loss': 0.46204948521429495, 'Total loss': 0.46204948521429495}
2022-11-28 04:06:17,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:17,827 INFO:     Epoch: 36
2022-11-28 04:06:18,492 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45689729668877344, 'Total loss': 0.45689729668877344} | train loss {'Reaction outcome loss': 0.4678803778463794, 'Total loss': 0.4678803778463794}
2022-11-28 04:06:18,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:18,493 INFO:     Epoch: 37
2022-11-28 04:06:19,153 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.468070598827167, 'Total loss': 0.468070598827167} | train loss {'Reaction outcome loss': 0.46504870045088953, 'Total loss': 0.46504870045088953}
2022-11-28 04:06:19,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:19,154 INFO:     Epoch: 38
2022-11-28 04:06:19,818 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45004257119514723, 'Total loss': 0.45004257119514723} | train loss {'Reaction outcome loss': 0.4622420550834748, 'Total loss': 0.4622420550834748}
2022-11-28 04:06:19,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:19,818 INFO:     Epoch: 39
2022-11-28 04:06:20,482 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4516006823290478, 'Total loss': 0.4516006823290478} | train loss {'Reaction outcome loss': 0.4613337840344156, 'Total loss': 0.4613337840344156}
2022-11-28 04:06:20,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:20,483 INFO:     Epoch: 40
2022-11-28 04:06:21,144 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4651409387588501, 'Total loss': 0.4651409387588501} | train loss {'Reaction outcome loss': 0.4563068507179137, 'Total loss': 0.4563068507179137}
2022-11-28 04:06:21,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:21,144 INFO:     Epoch: 41
2022-11-28 04:06:21,808 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45051981576464395, 'Total loss': 0.45051981576464395} | train loss {'Reaction outcome loss': 0.46975637984371954, 'Total loss': 0.46975637984371954}
2022-11-28 04:06:21,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:21,809 INFO:     Epoch: 42
2022-11-28 04:06:22,471 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4760923179035837, 'Total loss': 0.4760923179035837} | train loss {'Reaction outcome loss': 0.4574011048121798, 'Total loss': 0.4574011048121798}
2022-11-28 04:06:22,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:22,471 INFO:     Epoch: 43
2022-11-28 04:06:23,133 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4642630439590324, 'Total loss': 0.4642630439590324} | train loss {'Reaction outcome loss': 0.4575905261501189, 'Total loss': 0.4575905261501189}
2022-11-28 04:06:23,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:23,133 INFO:     Epoch: 44
2022-11-28 04:06:23,794 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44577444006096234, 'Total loss': 0.44577444006096234} | train loss {'Reaction outcome loss': 0.4640359888754545, 'Total loss': 0.4640359888754545}
2022-11-28 04:06:23,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:23,795 INFO:     Epoch: 45
2022-11-28 04:06:24,458 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47259291396899655, 'Total loss': 0.47259291396899655} | train loss {'Reaction outcome loss': 0.459954829946641, 'Total loss': 0.459954829946641}
2022-11-28 04:06:24,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:24,458 INFO:     Epoch: 46
2022-11-28 04:06:25,124 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45761588334359904, 'Total loss': 0.45761588334359904} | train loss {'Reaction outcome loss': 0.45964973612177756, 'Total loss': 0.45964973612177756}
2022-11-28 04:06:25,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:25,125 INFO:     Epoch: 47
2022-11-28 04:06:25,787 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4698758419941772, 'Total loss': 0.4698758419941772} | train loss {'Reaction outcome loss': 0.464864841512134, 'Total loss': 0.464864841512134}
2022-11-28 04:06:25,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:25,787 INFO:     Epoch: 48
2022-11-28 04:06:26,448 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4562269127504392, 'Total loss': 0.4562269127504392} | train loss {'Reaction outcome loss': 0.4596918982663943, 'Total loss': 0.4596918982663943}
2022-11-28 04:06:26,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:26,448 INFO:     Epoch: 49
2022-11-28 04:06:27,108 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4563406167382544, 'Total loss': 0.4563406167382544} | train loss {'Reaction outcome loss': 0.4547218474889955, 'Total loss': 0.4547218474889955}
2022-11-28 04:06:27,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:27,108 INFO:     Epoch: 50
2022-11-28 04:06:27,766 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4516889588399367, 'Total loss': 0.4516889588399367} | train loss {'Reaction outcome loss': 0.4538373425602913, 'Total loss': 0.4538373425602913}
2022-11-28 04:06:27,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:27,766 INFO:     Epoch: 51
2022-11-28 04:06:28,424 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4545672305605628, 'Total loss': 0.4545672305605628} | train loss {'Reaction outcome loss': 0.4608949490732724, 'Total loss': 0.4608949490732724}
2022-11-28 04:06:28,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:28,424 INFO:     Epoch: 52
2022-11-28 04:06:29,083 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45088598199866037, 'Total loss': 0.45088598199866037} | train loss {'Reaction outcome loss': 0.4608656011762158, 'Total loss': 0.4608656011762158}
2022-11-28 04:06:29,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:29,084 INFO:     Epoch: 53
2022-11-28 04:06:29,744 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4597019153562459, 'Total loss': 0.4597019153562459} | train loss {'Reaction outcome loss': 0.4676312550061172, 'Total loss': 0.4676312550061172}
2022-11-28 04:06:29,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:29,744 INFO:     Epoch: 54
2022-11-28 04:06:30,404 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4563734619454904, 'Total loss': 0.4563734619454904} | train loss {'Reaction outcome loss': 0.4640321406505762, 'Total loss': 0.4640321406505762}
2022-11-28 04:06:30,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:30,405 INFO:     Epoch: 55
2022-11-28 04:06:31,067 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46943853118202905, 'Total loss': 0.46943853118202905} | train loss {'Reaction outcome loss': 0.46152602736988374, 'Total loss': 0.46152602736988374}
2022-11-28 04:06:31,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:31,067 INFO:     Epoch: 56
2022-11-28 04:06:31,728 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4379332455044443, 'Total loss': 0.4379332455044443} | train loss {'Reaction outcome loss': 0.45838176885679843, 'Total loss': 0.45838176885679843}
2022-11-28 04:06:31,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:31,728 INFO:     Epoch: 57
2022-11-28 04:06:32,389 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48634212938222016, 'Total loss': 0.48634212938222016} | train loss {'Reaction outcome loss': 0.4585019156276699, 'Total loss': 0.4585019156276699}
2022-11-28 04:06:32,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:32,390 INFO:     Epoch: 58
2022-11-28 04:06:33,053 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47539748962629924, 'Total loss': 0.47539748962629924} | train loss {'Reaction outcome loss': 0.4549743629270984, 'Total loss': 0.4549743629270984}
2022-11-28 04:06:33,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:33,053 INFO:     Epoch: 59
2022-11-28 04:06:33,714 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4885524721308188, 'Total loss': 0.4885524721308188} | train loss {'Reaction outcome loss': 0.45944963575851533, 'Total loss': 0.45944963575851533}
2022-11-28 04:06:33,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:33,714 INFO:     Epoch: 60
2022-11-28 04:06:34,375 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4668785506351428, 'Total loss': 0.4668785506351428} | train loss {'Reaction outcome loss': 0.4648714847261867, 'Total loss': 0.4648714847261867}
2022-11-28 04:06:34,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:34,375 INFO:     Epoch: 61
2022-11-28 04:06:35,037 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46138413656841626, 'Total loss': 0.46138413656841626} | train loss {'Reaction outcome loss': 0.45743191368397207, 'Total loss': 0.45743191368397207}
2022-11-28 04:06:35,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:35,037 INFO:     Epoch: 62
2022-11-28 04:06:35,700 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4458650496195663, 'Total loss': 0.4458650496195663} | train loss {'Reaction outcome loss': 0.45455317355452046, 'Total loss': 0.45455317355452046}
2022-11-28 04:06:35,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:35,700 INFO:     Epoch: 63
2022-11-28 04:06:36,367 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47391614419492806, 'Total loss': 0.47391614419492806} | train loss {'Reaction outcome loss': 0.46313778899850383, 'Total loss': 0.46313778899850383}
2022-11-28 04:06:36,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:36,367 INFO:     Epoch: 64
2022-11-28 04:06:37,033 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44833249056881125, 'Total loss': 0.44833249056881125} | train loss {'Reaction outcome loss': 0.45834564009020407, 'Total loss': 0.45834564009020407}
2022-11-28 04:06:37,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:37,033 INFO:     Epoch: 65
2022-11-28 04:06:37,697 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43839104541323404, 'Total loss': 0.43839104541323404} | train loss {'Reaction outcome loss': 0.45865410416116636, 'Total loss': 0.45865410416116636}
2022-11-28 04:06:37,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:37,698 INFO:     Epoch: 66
2022-11-28 04:06:38,360 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5344211838462136, 'Total loss': 0.5344211838462136} | train loss {'Reaction outcome loss': 0.45630351183635576, 'Total loss': 0.45630351183635576}
2022-11-28 04:06:38,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:38,361 INFO:     Epoch: 67
2022-11-28 04:06:39,020 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46042792769995605, 'Total loss': 0.46042792769995605} | train loss {'Reaction outcome loss': 0.46086333872329804, 'Total loss': 0.46086333872329804}
2022-11-28 04:06:39,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:39,021 INFO:     Epoch: 68
2022-11-28 04:06:39,682 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4576228599656712, 'Total loss': 0.4576228599656712} | train loss {'Reaction outcome loss': 0.4562859763841956, 'Total loss': 0.4562859763841956}
2022-11-28 04:06:39,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:39,682 INFO:     Epoch: 69
2022-11-28 04:06:40,350 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47341368973932485, 'Total loss': 0.47341368973932485} | train loss {'Reaction outcome loss': 0.45761031248877126, 'Total loss': 0.45761031248877126}
2022-11-28 04:06:40,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:40,350 INFO:     Epoch: 70
2022-11-28 04:06:41,017 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4591746878894893, 'Total loss': 0.4591746878894893} | train loss {'Reaction outcome loss': 0.45600462374427625, 'Total loss': 0.45600462374427625}
2022-11-28 04:06:41,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:41,017 INFO:     Epoch: 71
2022-11-28 04:06:41,681 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46012907509099354, 'Total loss': 0.46012907509099354} | train loss {'Reaction outcome loss': 0.4584952600660824, 'Total loss': 0.4584952600660824}
2022-11-28 04:06:41,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:41,681 INFO:     Epoch: 72
2022-11-28 04:06:42,346 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4536385434595021, 'Total loss': 0.4536385434595021} | train loss {'Reaction outcome loss': 0.45834938520866053, 'Total loss': 0.45834938520866053}
2022-11-28 04:06:42,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:42,347 INFO:     Epoch: 73
2022-11-28 04:06:43,009 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4387438622387973, 'Total loss': 0.4387438622387973} | train loss {'Reaction outcome loss': 0.4526808050971839, 'Total loss': 0.4526808050971839}
2022-11-28 04:06:43,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:43,010 INFO:     Epoch: 74
2022-11-28 04:06:43,670 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4681501645933498, 'Total loss': 0.4681501645933498} | train loss {'Reaction outcome loss': 0.4581210715395789, 'Total loss': 0.4581210715395789}
2022-11-28 04:06:43,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:43,670 INFO:     Epoch: 75
2022-11-28 04:06:44,333 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45095380632714793, 'Total loss': 0.45095380632714793} | train loss {'Reaction outcome loss': 0.4580375539259084, 'Total loss': 0.4580375539259084}
2022-11-28 04:06:44,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:44,333 INFO:     Epoch: 76
2022-11-28 04:06:44,994 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4661986760117791, 'Total loss': 0.4661986760117791} | train loss {'Reaction outcome loss': 0.4571652140828871, 'Total loss': 0.4571652140828871}
2022-11-28 04:06:44,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:44,994 INFO:     Epoch: 77
2022-11-28 04:06:45,658 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46614439717747946, 'Total loss': 0.46614439717747946} | train loss {'Reaction outcome loss': 0.4602386553080813, 'Total loss': 0.4602386553080813}
2022-11-28 04:06:45,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:45,658 INFO:     Epoch: 78
2022-11-28 04:06:46,325 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47355359115383844, 'Total loss': 0.47355359115383844} | train loss {'Reaction outcome loss': 0.4598110877578297, 'Total loss': 0.4598110877578297}
2022-11-28 04:06:46,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:46,325 INFO:     Epoch: 79
2022-11-28 04:06:46,992 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45581383766098454, 'Total loss': 0.45581383766098454} | train loss {'Reaction outcome loss': 0.46157592961624744, 'Total loss': 0.46157592961624744}
2022-11-28 04:06:46,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:46,992 INFO:     Epoch: 80
2022-11-28 04:06:47,661 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4435886175117709, 'Total loss': 0.4435886175117709} | train loss {'Reaction outcome loss': 0.4665508653157421, 'Total loss': 0.4665508653157421}
2022-11-28 04:06:47,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:47,661 INFO:     Epoch: 81
2022-11-28 04:06:48,327 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4610234553163702, 'Total loss': 0.4610234553163702} | train loss {'Reaction outcome loss': 0.4560701354226518, 'Total loss': 0.4560701354226518}
2022-11-28 04:06:48,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:48,327 INFO:     Epoch: 82
2022-11-28 04:06:48,993 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45397821661423554, 'Total loss': 0.45397821661423554} | train loss {'Reaction outcome loss': 0.4589958923958963, 'Total loss': 0.4589958923958963}
2022-11-28 04:06:48,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:48,993 INFO:     Epoch: 83
2022-11-28 04:06:49,660 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4286792759190906, 'Total loss': 0.4286792759190906} | train loss {'Reaction outcome loss': 0.4639528761167199, 'Total loss': 0.4639528761167199}
2022-11-28 04:06:49,661 INFO:     Found new best model at epoch 83
2022-11-28 04:06:49,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:49,662 INFO:     Epoch: 84
2022-11-28 04:06:50,328 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45089274509386584, 'Total loss': 0.45089274509386584} | train loss {'Reaction outcome loss': 0.45891972474994197, 'Total loss': 0.45891972474994197}
2022-11-28 04:06:50,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:50,328 INFO:     Epoch: 85
2022-11-28 04:06:50,991 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4493285204199227, 'Total loss': 0.4493285204199227} | train loss {'Reaction outcome loss': 0.45601848795288996, 'Total loss': 0.45601848795288996}
2022-11-28 04:06:50,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:50,991 INFO:     Epoch: 86
2022-11-28 04:06:51,659 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44960345463319257, 'Total loss': 0.44960345463319257} | train loss {'Reaction outcome loss': 0.4629488263519541, 'Total loss': 0.4629488263519541}
2022-11-28 04:06:51,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:51,659 INFO:     Epoch: 87
2022-11-28 04:06:52,326 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45030741867693985, 'Total loss': 0.45030741867693985} | train loss {'Reaction outcome loss': 0.45739254601780444, 'Total loss': 0.45739254601780444}
2022-11-28 04:06:52,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:52,326 INFO:     Epoch: 88
2022-11-28 04:06:52,991 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46434139155528764, 'Total loss': 0.46434139155528764} | train loss {'Reaction outcome loss': 0.4607973042274675, 'Total loss': 0.4607973042274675}
2022-11-28 04:06:52,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:52,992 INFO:     Epoch: 89
2022-11-28 04:06:53,653 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4571686112745242, 'Total loss': 0.4571686112745242} | train loss {'Reaction outcome loss': 0.45905258903099644, 'Total loss': 0.45905258903099644}
2022-11-28 04:06:53,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:53,654 INFO:     Epoch: 90
2022-11-28 04:06:54,316 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45227828418666666, 'Total loss': 0.45227828418666666} | train loss {'Reaction outcome loss': 0.47066251687224836, 'Total loss': 0.47066251687224836}
2022-11-28 04:06:54,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:54,316 INFO:     Epoch: 91
2022-11-28 04:06:54,976 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4729569053108042, 'Total loss': 0.4729569053108042} | train loss {'Reaction outcome loss': 0.4587053612114922, 'Total loss': 0.4587053612114922}
2022-11-28 04:06:54,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:54,976 INFO:     Epoch: 92
2022-11-28 04:06:55,638 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5028863085264509, 'Total loss': 0.5028863085264509} | train loss {'Reaction outcome loss': 0.454572067806317, 'Total loss': 0.454572067806317}
2022-11-28 04:06:55,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:55,638 INFO:     Epoch: 93
2022-11-28 04:06:56,303 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46755744076587935, 'Total loss': 0.46755744076587935} | train loss {'Reaction outcome loss': 0.46722481381748954, 'Total loss': 0.46722481381748954}
2022-11-28 04:06:56,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:56,304 INFO:     Epoch: 94
2022-11-28 04:06:56,963 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4390847479755228, 'Total loss': 0.4390847479755228} | train loss {'Reaction outcome loss': 0.4620993018390671, 'Total loss': 0.4620993018390671}
2022-11-28 04:06:56,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:56,964 INFO:     Epoch: 95
2022-11-28 04:06:57,625 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4190892187709158, 'Total loss': 0.4190892187709158} | train loss {'Reaction outcome loss': 0.4609819182134684, 'Total loss': 0.4609819182134684}
2022-11-28 04:06:57,626 INFO:     Found new best model at epoch 95
2022-11-28 04:06:57,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:57,626 INFO:     Epoch: 96
2022-11-28 04:06:58,287 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4494363648647612, 'Total loss': 0.4494363648647612} | train loss {'Reaction outcome loss': 0.4593117604212415, 'Total loss': 0.4593117604212415}
2022-11-28 04:06:58,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:58,288 INFO:     Epoch: 97
2022-11-28 04:06:58,950 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4622646350074898, 'Total loss': 0.4622646350074898} | train loss {'Reaction outcome loss': 0.45710982178007403, 'Total loss': 0.45710982178007403}
2022-11-28 04:06:58,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:58,951 INFO:     Epoch: 98
2022-11-28 04:06:59,610 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45865468409928406, 'Total loss': 0.45865468409928406} | train loss {'Reaction outcome loss': 0.45844447378429676, 'Total loss': 0.45844447378429676}
2022-11-28 04:06:59,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:06:59,610 INFO:     Epoch: 99
2022-11-28 04:07:00,272 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4467665884982456, 'Total loss': 0.4467665884982456} | train loss {'Reaction outcome loss': 0.45841545335227446, 'Total loss': 0.45841545335227446}
2022-11-28 04:07:00,272 INFO:     Best model found after epoch 96 of 100.
2022-11-28 04:07:00,272 INFO:   Done with stage: TRAINING
2022-11-28 04:07:00,272 INFO:   Starting stage: EVALUATION
2022-11-28 04:07:00,385 INFO:   Done with stage: EVALUATION
2022-11-28 04:07:00,386 INFO:   Leaving out SEQ value Fold_7
2022-11-28 04:07:00,398 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:07:00,399 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:07:01,044 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:07:01,044 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:07:01,112 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:07:01,113 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:07:01,113 INFO:     No hyperparam tuning for this model
2022-11-28 04:07:01,113 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:07:01,113 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:07:01,114 INFO:     None feature selector for col prot
2022-11-28 04:07:01,114 INFO:     None feature selector for col prot
2022-11-28 04:07:01,114 INFO:     None feature selector for col prot
2022-11-28 04:07:01,114 INFO:     None feature selector for col chem
2022-11-28 04:07:01,114 INFO:     None feature selector for col chem
2022-11-28 04:07:01,114 INFO:     None feature selector for col chem
2022-11-28 04:07:01,115 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:07:01,115 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:07:01,116 INFO:     Number of params in model 169651
2022-11-28 04:07:01,119 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:07:01,119 INFO:   Starting stage: TRAINING
2022-11-28 04:07:01,171 INFO:     Val loss before train {'Reaction outcome loss': 0.9985407739877701, 'Total loss': 0.9985407739877701}
2022-11-28 04:07:01,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:01,171 INFO:     Epoch: 0
2022-11-28 04:07:01,829 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5999259508468888, 'Total loss': 0.5999259508468888} | train loss {'Reaction outcome loss': 0.6717810038357012, 'Total loss': 0.6717810038357012}
2022-11-28 04:07:01,829 INFO:     Found new best model at epoch 0
2022-11-28 04:07:01,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:01,830 INFO:     Epoch: 1
2022-11-28 04:07:02,490 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.589887451719154, 'Total loss': 0.589887451719154} | train loss {'Reaction outcome loss': 0.5665238634232552, 'Total loss': 0.5665238634232552}
2022-11-28 04:07:02,490 INFO:     Found new best model at epoch 1
2022-11-28 04:07:02,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:02,491 INFO:     Epoch: 2
2022-11-28 04:07:03,151 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5257082994688641, 'Total loss': 0.5257082994688641} | train loss {'Reaction outcome loss': 0.5456737383839584, 'Total loss': 0.5456737383839584}
2022-11-28 04:07:03,151 INFO:     Found new best model at epoch 2
2022-11-28 04:07:03,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:03,152 INFO:     Epoch: 3
2022-11-28 04:07:03,811 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5268876931884072, 'Total loss': 0.5268876931884072} | train loss {'Reaction outcome loss': 0.5303719726301008, 'Total loss': 0.5303719726301008}
2022-11-28 04:07:03,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:03,811 INFO:     Epoch: 4
2022-11-28 04:07:04,472 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5236012844199484, 'Total loss': 0.5236012844199484} | train loss {'Reaction outcome loss': 0.5051092156359265, 'Total loss': 0.5051092156359265}
2022-11-28 04:07:04,472 INFO:     Found new best model at epoch 4
2022-11-28 04:07:04,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:04,473 INFO:     Epoch: 5
2022-11-28 04:07:05,131 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4958050708201798, 'Total loss': 0.4958050708201798} | train loss {'Reaction outcome loss': 0.5024333689361811, 'Total loss': 0.5024333689361811}
2022-11-28 04:07:05,131 INFO:     Found new best model at epoch 5
2022-11-28 04:07:05,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:05,132 INFO:     Epoch: 6
2022-11-28 04:07:05,793 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4944174127145247, 'Total loss': 0.4944174127145247} | train loss {'Reaction outcome loss': 0.5007307298120952, 'Total loss': 0.5007307298120952}
2022-11-28 04:07:05,793 INFO:     Found new best model at epoch 6
2022-11-28 04:07:05,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:05,794 INFO:     Epoch: 7
2022-11-28 04:07:06,456 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5410049727017229, 'Total loss': 0.5410049727017229} | train loss {'Reaction outcome loss': 0.49236574558721435, 'Total loss': 0.49236574558721435}
2022-11-28 04:07:06,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:06,456 INFO:     Epoch: 8
2022-11-28 04:07:07,115 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5217829847877676, 'Total loss': 0.5217829847877676} | train loss {'Reaction outcome loss': 0.49070313350567896, 'Total loss': 0.49070313350567896}
2022-11-28 04:07:07,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:07,116 INFO:     Epoch: 9
2022-11-28 04:07:07,777 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5039080726829442, 'Total loss': 0.5039080726829442} | train loss {'Reaction outcome loss': 0.4721871821750556, 'Total loss': 0.4721871821750556}
2022-11-28 04:07:07,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:07,777 INFO:     Epoch: 10
2022-11-28 04:07:08,434 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5223836004734039, 'Total loss': 0.5223836004734039} | train loss {'Reaction outcome loss': 0.48034647275363246, 'Total loss': 0.48034647275363246}
2022-11-28 04:07:08,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:08,435 INFO:     Epoch: 11
2022-11-28 04:07:09,097 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5773451971736822, 'Total loss': 0.5773451971736822} | train loss {'Reaction outcome loss': 0.47433137406985604, 'Total loss': 0.47433137406985604}
2022-11-28 04:07:09,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:09,097 INFO:     Epoch: 12
2022-11-28 04:07:09,758 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5818695050071586, 'Total loss': 0.5818695050071586} | train loss {'Reaction outcome loss': 0.48055850115093973, 'Total loss': 0.48055850115093973}
2022-11-28 04:07:09,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:09,758 INFO:     Epoch: 13
2022-11-28 04:07:10,419 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5036618248982863, 'Total loss': 0.5036618248982863} | train loss {'Reaction outcome loss': 0.47648447085051765, 'Total loss': 0.47648447085051765}
2022-11-28 04:07:10,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:10,419 INFO:     Epoch: 14
2022-11-28 04:07:11,078 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5011509338563139, 'Total loss': 0.5011509338563139} | train loss {'Reaction outcome loss': 0.4707301296894589, 'Total loss': 0.4707301296894589}
2022-11-28 04:07:11,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:11,078 INFO:     Epoch: 15
2022-11-28 04:07:11,738 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4954429150305011, 'Total loss': 0.4954429150305011} | train loss {'Reaction outcome loss': 0.47203394842724644, 'Total loss': 0.47203394842724644}
2022-11-28 04:07:11,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:11,738 INFO:     Epoch: 16
2022-11-28 04:07:12,398 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5108989622782577, 'Total loss': 0.5108989622782577} | train loss {'Reaction outcome loss': 0.4585784303565179, 'Total loss': 0.4585784303565179}
2022-11-28 04:07:12,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:12,398 INFO:     Epoch: 17
2022-11-28 04:07:13,062 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5260312977162275, 'Total loss': 0.5260312977162275} | train loss {'Reaction outcome loss': 0.4702022513374686, 'Total loss': 0.4702022513374686}
2022-11-28 04:07:13,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:13,062 INFO:     Epoch: 18
2022-11-28 04:07:13,722 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4849600416015495, 'Total loss': 0.4849600416015495} | train loss {'Reaction outcome loss': 0.4655422908404181, 'Total loss': 0.4655422908404181}
2022-11-28 04:07:13,722 INFO:     Found new best model at epoch 18
2022-11-28 04:07:13,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:13,723 INFO:     Epoch: 19
2022-11-28 04:07:14,381 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48075455461036076, 'Total loss': 0.48075455461036076} | train loss {'Reaction outcome loss': 0.46087006131006825, 'Total loss': 0.46087006131006825}
2022-11-28 04:07:14,381 INFO:     Found new best model at epoch 19
2022-11-28 04:07:14,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:14,382 INFO:     Epoch: 20
2022-11-28 04:07:15,042 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47894868830388243, 'Total loss': 0.47894868830388243} | train loss {'Reaction outcome loss': 0.4564374175163046, 'Total loss': 0.4564374175163046}
2022-11-28 04:07:15,042 INFO:     Found new best model at epoch 20
2022-11-28 04:07:15,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:15,043 INFO:     Epoch: 21
2022-11-28 04:07:15,705 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4964353157715364, 'Total loss': 0.4964353157715364} | train loss {'Reaction outcome loss': 0.4566319804458368, 'Total loss': 0.4566319804458368}
2022-11-28 04:07:15,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:15,705 INFO:     Epoch: 22
2022-11-28 04:07:16,365 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5032266852530566, 'Total loss': 0.5032266852530566} | train loss {'Reaction outcome loss': 0.4640031154117277, 'Total loss': 0.4640031154117277}
2022-11-28 04:07:16,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:16,366 INFO:     Epoch: 23
2022-11-28 04:07:17,026 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4776767028326338, 'Total loss': 0.4776767028326338} | train loss {'Reaction outcome loss': 0.45827735023152444, 'Total loss': 0.45827735023152444}
2022-11-28 04:07:17,026 INFO:     Found new best model at epoch 23
2022-11-28 04:07:17,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:17,027 INFO:     Epoch: 24
2022-11-28 04:07:17,688 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.510464411567558, 'Total loss': 0.510464411567558} | train loss {'Reaction outcome loss': 0.4601251746437723, 'Total loss': 0.4601251746437723}
2022-11-28 04:07:17,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:17,688 INFO:     Epoch: 25
2022-11-28 04:07:18,346 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4813275835053487, 'Total loss': 0.4813275835053487} | train loss {'Reaction outcome loss': 0.4615100082010031, 'Total loss': 0.4615100082010031}
2022-11-28 04:07:18,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:18,346 INFO:     Epoch: 26
2022-11-28 04:07:19,007 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49435933272946964, 'Total loss': 0.49435933272946964} | train loss {'Reaction outcome loss': 0.46720744834672057, 'Total loss': 0.46720744834672057}
2022-11-28 04:07:19,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:19,008 INFO:     Epoch: 27
2022-11-28 04:07:19,668 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46503315662795847, 'Total loss': 0.46503315662795847} | train loss {'Reaction outcome loss': 0.4575400264753449, 'Total loss': 0.4575400264753449}
2022-11-28 04:07:19,668 INFO:     Found new best model at epoch 27
2022-11-28 04:07:19,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:19,669 INFO:     Epoch: 28
2022-11-28 04:07:20,330 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5006865032694556, 'Total loss': 0.5006865032694556} | train loss {'Reaction outcome loss': 0.45607958319446734, 'Total loss': 0.45607958319446734}
2022-11-28 04:07:20,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:20,331 INFO:     Epoch: 29
2022-11-28 04:07:20,991 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5323675660924478, 'Total loss': 0.5323675660924478} | train loss {'Reaction outcome loss': 0.46065137907862663, 'Total loss': 0.46065137907862663}
2022-11-28 04:07:20,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:20,992 INFO:     Epoch: 30
2022-11-28 04:07:21,654 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48075887154449115, 'Total loss': 0.48075887154449115} | train loss {'Reaction outcome loss': 0.455544859230999, 'Total loss': 0.455544859230999}
2022-11-28 04:07:21,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:21,655 INFO:     Epoch: 31
2022-11-28 04:07:22,316 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5307788571173494, 'Total loss': 0.5307788571173494} | train loss {'Reaction outcome loss': 0.4514558979820821, 'Total loss': 0.4514558979820821}
2022-11-28 04:07:22,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:22,317 INFO:     Epoch: 32
2022-11-28 04:07:22,979 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4992629618129947, 'Total loss': 0.4992629618129947} | train loss {'Reaction outcome loss': 0.4569596527144313, 'Total loss': 0.4569596527144313}
2022-11-28 04:07:22,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:22,979 INFO:     Epoch: 33
2022-11-28 04:07:23,641 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5114089446988973, 'Total loss': 0.5114089446988973} | train loss {'Reaction outcome loss': 0.4619577822966441, 'Total loss': 0.4619577822966441}
2022-11-28 04:07:23,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:23,642 INFO:     Epoch: 34
2022-11-28 04:07:24,305 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49743302911520004, 'Total loss': 0.49743302911520004} | train loss {'Reaction outcome loss': 0.4564646657916807, 'Total loss': 0.4564646657916807}
2022-11-28 04:07:24,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:24,305 INFO:     Epoch: 35
2022-11-28 04:07:24,964 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5291826725006104, 'Total loss': 0.5291826725006104} | train loss {'Reaction outcome loss': 0.46155953815867823, 'Total loss': 0.46155953815867823}
2022-11-28 04:07:24,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:24,964 INFO:     Epoch: 36
2022-11-28 04:07:25,624 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4705535601824522, 'Total loss': 0.4705535601824522} | train loss {'Reaction outcome loss': 0.45230314466020755, 'Total loss': 0.45230314466020755}
2022-11-28 04:07:25,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:25,624 INFO:     Epoch: 37
2022-11-28 04:07:26,285 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4895664253695445, 'Total loss': 0.4895664253695445} | train loss {'Reaction outcome loss': 0.46314020472909173, 'Total loss': 0.46314020472909173}
2022-11-28 04:07:26,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:26,285 INFO:     Epoch: 38
2022-11-28 04:07:26,945 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5151747559959238, 'Total loss': 0.5151747559959238} | train loss {'Reaction outcome loss': 0.4571044472677092, 'Total loss': 0.4571044472677092}
2022-11-28 04:07:26,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:26,945 INFO:     Epoch: 39
2022-11-28 04:07:27,608 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4943226789208976, 'Total loss': 0.4943226789208976} | train loss {'Reaction outcome loss': 0.4528856032918538, 'Total loss': 0.4528856032918538}
2022-11-28 04:07:27,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:27,609 INFO:     Epoch: 40
2022-11-28 04:07:28,272 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5163847150450404, 'Total loss': 0.5163847150450404} | train loss {'Reaction outcome loss': 0.4590548559302284, 'Total loss': 0.4590548559302284}
2022-11-28 04:07:28,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:28,272 INFO:     Epoch: 41
2022-11-28 04:07:28,934 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.508972489359704, 'Total loss': 0.508972489359704} | train loss {'Reaction outcome loss': 0.4571938467242064, 'Total loss': 0.4571938467242064}
2022-11-28 04:07:28,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:28,934 INFO:     Epoch: 42
2022-11-28 04:07:29,593 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4973828254098242, 'Total loss': 0.4973828254098242} | train loss {'Reaction outcome loss': 0.4541057732196585, 'Total loss': 0.4541057732196585}
2022-11-28 04:07:29,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:29,594 INFO:     Epoch: 43
2022-11-28 04:07:30,254 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5153981589458205, 'Total loss': 0.5153981589458205} | train loss {'Reaction outcome loss': 0.4632264257318551, 'Total loss': 0.4632264257318551}
2022-11-28 04:07:30,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:30,254 INFO:     Epoch: 44
2022-11-28 04:07:30,915 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48597687211903656, 'Total loss': 0.48597687211903656} | train loss {'Reaction outcome loss': 0.4543616626892359, 'Total loss': 0.4543616626892359}
2022-11-28 04:07:30,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:30,915 INFO:     Epoch: 45
2022-11-28 04:07:31,581 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48323694040829485, 'Total loss': 0.48323694040829485} | train loss {'Reaction outcome loss': 0.46093803511992576, 'Total loss': 0.46093803511992576}
2022-11-28 04:07:31,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:31,581 INFO:     Epoch: 46
2022-11-28 04:07:32,241 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5098989243534479, 'Total loss': 0.5098989243534479} | train loss {'Reaction outcome loss': 0.4586828649344464, 'Total loss': 0.4586828649344464}
2022-11-28 04:07:32,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:32,241 INFO:     Epoch: 47
2022-11-28 04:07:32,904 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4850852523337711, 'Total loss': 0.4850852523337711} | train loss {'Reaction outcome loss': 0.45499239747803055, 'Total loss': 0.45499239747803055}
2022-11-28 04:07:32,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:32,904 INFO:     Epoch: 48
2022-11-28 04:07:33,566 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5320778072557666, 'Total loss': 0.5320778072557666} | train loss {'Reaction outcome loss': 0.45445500554576995, 'Total loss': 0.45445500554576995}
2022-11-28 04:07:33,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:33,566 INFO:     Epoch: 49
2022-11-28 04:07:34,228 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.501029832796617, 'Total loss': 0.501029832796617} | train loss {'Reaction outcome loss': 0.4652427508225364, 'Total loss': 0.4652427508225364}
2022-11-28 04:07:34,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:34,229 INFO:     Epoch: 50
2022-11-28 04:07:34,890 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47131097757003526, 'Total loss': 0.47131097757003526} | train loss {'Reaction outcome loss': 0.4517536812251614, 'Total loss': 0.4517536812251614}
2022-11-28 04:07:34,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:34,890 INFO:     Epoch: 51
2022-11-28 04:07:35,548 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5080561888488856, 'Total loss': 0.5080561888488856} | train loss {'Reaction outcome loss': 0.4567236930973107, 'Total loss': 0.4567236930973107}
2022-11-28 04:07:35,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:35,548 INFO:     Epoch: 52
2022-11-28 04:07:36,206 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47435557198795403, 'Total loss': 0.47435557198795403} | train loss {'Reaction outcome loss': 0.4595407981185182, 'Total loss': 0.4595407981185182}
2022-11-28 04:07:36,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:36,206 INFO:     Epoch: 53
2022-11-28 04:07:36,864 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4653069857846607, 'Total loss': 0.4653069857846607} | train loss {'Reaction outcome loss': 0.45474015458697276, 'Total loss': 0.45474015458697276}
2022-11-28 04:07:36,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:36,864 INFO:     Epoch: 54
2022-11-28 04:07:37,521 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49237935922362586, 'Total loss': 0.49237935922362586} | train loss {'Reaction outcome loss': 0.4533224529436519, 'Total loss': 0.4533224529436519}
2022-11-28 04:07:37,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:37,522 INFO:     Epoch: 55
2022-11-28 04:07:38,178 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48864637823267415, 'Total loss': 0.48864637823267415} | train loss {'Reaction outcome loss': 0.46190503510015624, 'Total loss': 0.46190503510015624}
2022-11-28 04:07:38,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:38,178 INFO:     Epoch: 56
2022-11-28 04:07:38,838 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5071957151998173, 'Total loss': 0.5071957151998173} | train loss {'Reaction outcome loss': 0.45519136264920235, 'Total loss': 0.45519136264920235}
2022-11-28 04:07:38,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:38,838 INFO:     Epoch: 57
2022-11-28 04:07:39,497 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48907822743058205, 'Total loss': 0.48907822743058205} | train loss {'Reaction outcome loss': 0.4580716651173369, 'Total loss': 0.4580716651173369}
2022-11-28 04:07:39,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:39,497 INFO:     Epoch: 58
2022-11-28 04:07:40,152 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4881108030676842, 'Total loss': 0.4881108030676842} | train loss {'Reaction outcome loss': 0.4538556644993444, 'Total loss': 0.4538556644993444}
2022-11-28 04:07:40,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:40,153 INFO:     Epoch: 59
2022-11-28 04:07:40,807 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5006745894524184, 'Total loss': 0.5006745894524184} | train loss {'Reaction outcome loss': 0.45128082243665574, 'Total loss': 0.45128082243665574}
2022-11-28 04:07:40,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:40,807 INFO:     Epoch: 60
2022-11-28 04:07:41,465 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4772653406993909, 'Total loss': 0.4772653406993909} | train loss {'Reaction outcome loss': 0.45944817223015333, 'Total loss': 0.45944817223015333}
2022-11-28 04:07:41,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:41,465 INFO:     Epoch: 61
2022-11-28 04:07:42,122 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5431478582322598, 'Total loss': 0.5431478582322598} | train loss {'Reaction outcome loss': 0.46152385207073343, 'Total loss': 0.46152385207073343}
2022-11-28 04:07:42,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:42,122 INFO:     Epoch: 62
2022-11-28 04:07:42,781 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5100560076534748, 'Total loss': 0.5100560076534748} | train loss {'Reaction outcome loss': 0.456552037668805, 'Total loss': 0.456552037668805}
2022-11-28 04:07:42,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:42,782 INFO:     Epoch: 63
2022-11-28 04:07:43,438 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5061737048355016, 'Total loss': 0.5061737048355016} | train loss {'Reaction outcome loss': 0.45743200465315775, 'Total loss': 0.45743200465315775}
2022-11-28 04:07:43,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:43,439 INFO:     Epoch: 64
2022-11-28 04:07:44,094 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5223583704368635, 'Total loss': 0.5223583704368635} | train loss {'Reaction outcome loss': 0.46005341044116405, 'Total loss': 0.46005341044116405}
2022-11-28 04:07:44,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:44,094 INFO:     Epoch: 65
2022-11-28 04:07:44,753 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5182729224589738, 'Total loss': 0.5182729224589738} | train loss {'Reaction outcome loss': 0.46599531371987635, 'Total loss': 0.46599531371987635}
2022-11-28 04:07:44,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:44,753 INFO:     Epoch: 66
2022-11-28 04:07:45,415 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5058878301219507, 'Total loss': 0.5058878301219507} | train loss {'Reaction outcome loss': 0.4559494185471727, 'Total loss': 0.4559494185471727}
2022-11-28 04:07:45,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:45,416 INFO:     Epoch: 67
2022-11-28 04:07:46,072 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4871485737914389, 'Total loss': 0.4871485737914389} | train loss {'Reaction outcome loss': 0.4593588223740939, 'Total loss': 0.4593588223740939}
2022-11-28 04:07:46,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:46,072 INFO:     Epoch: 68
2022-11-28 04:07:46,727 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4936163174835118, 'Total loss': 0.4936163174835118} | train loss {'Reaction outcome loss': 0.4621779823735837, 'Total loss': 0.4621779823735837}
2022-11-28 04:07:46,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:46,727 INFO:     Epoch: 69
2022-11-28 04:07:47,387 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5088987834751606, 'Total loss': 0.5088987834751606} | train loss {'Reaction outcome loss': 0.4615816151903522, 'Total loss': 0.4615816151903522}
2022-11-28 04:07:47,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:47,387 INFO:     Epoch: 70
2022-11-28 04:07:48,044 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5107631039890376, 'Total loss': 0.5107631039890376} | train loss {'Reaction outcome loss': 0.4556715126720167, 'Total loss': 0.4556715126720167}
2022-11-28 04:07:48,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:48,044 INFO:     Epoch: 71
2022-11-28 04:07:48,700 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4925973794677041, 'Total loss': 0.4925973794677041} | train loss {'Reaction outcome loss': 0.46095223054139606, 'Total loss': 0.46095223054139606}
2022-11-28 04:07:48,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:48,701 INFO:     Epoch: 72
2022-11-28 04:07:49,359 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5181632299314846, 'Total loss': 0.5181632299314846} | train loss {'Reaction outcome loss': 0.46290875875180765, 'Total loss': 0.46290875875180765}
2022-11-28 04:07:49,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:49,359 INFO:     Epoch: 73
2022-11-28 04:07:50,013 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4840986007316546, 'Total loss': 0.4840986007316546} | train loss {'Reaction outcome loss': 0.46359010972082615, 'Total loss': 0.46359010972082615}
2022-11-28 04:07:50,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:50,013 INFO:     Epoch: 74
2022-11-28 04:07:50,670 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5375554101033644, 'Total loss': 0.5375554101033644} | train loss {'Reaction outcome loss': 0.4624509521790089, 'Total loss': 0.4624509521790089}
2022-11-28 04:07:50,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:50,670 INFO:     Epoch: 75
2022-11-28 04:07:51,328 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48636204309084197, 'Total loss': 0.48636204309084197} | train loss {'Reaction outcome loss': 0.46177482947466836, 'Total loss': 0.46177482947466836}
2022-11-28 04:07:51,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:51,328 INFO:     Epoch: 76
2022-11-28 04:07:51,990 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5385823425921527, 'Total loss': 0.5385823425921527} | train loss {'Reaction outcome loss': 0.45782427904346296, 'Total loss': 0.45782427904346296}
2022-11-28 04:07:51,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:51,990 INFO:     Epoch: 77
2022-11-28 04:07:52,648 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4897496612234549, 'Total loss': 0.4897496612234549} | train loss {'Reaction outcome loss': 0.462584764846871, 'Total loss': 0.462584764846871}
2022-11-28 04:07:52,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:52,649 INFO:     Epoch: 78
2022-11-28 04:07:53,307 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5364417149261995, 'Total loss': 0.5364417149261995} | train loss {'Reaction outcome loss': 0.45781468383727536, 'Total loss': 0.45781468383727536}
2022-11-28 04:07:53,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:53,307 INFO:     Epoch: 79
2022-11-28 04:07:53,965 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5309085229581053, 'Total loss': 0.5309085229581053} | train loss {'Reaction outcome loss': 0.4668497360281406, 'Total loss': 0.4668497360281406}
2022-11-28 04:07:53,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:53,966 INFO:     Epoch: 80
2022-11-28 04:07:54,624 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4914555793458765, 'Total loss': 0.4914555793458765} | train loss {'Reaction outcome loss': 0.46610388820690496, 'Total loss': 0.46610388820690496}
2022-11-28 04:07:54,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:54,624 INFO:     Epoch: 81
2022-11-28 04:07:55,283 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.497795527970249, 'Total loss': 0.497795527970249} | train loss {'Reaction outcome loss': 0.4612325630000522, 'Total loss': 0.4612325630000522}
2022-11-28 04:07:55,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:55,283 INFO:     Epoch: 82
2022-11-28 04:07:55,942 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4917754104191607, 'Total loss': 0.4917754104191607} | train loss {'Reaction outcome loss': 0.4573104824239929, 'Total loss': 0.4573104824239929}
2022-11-28 04:07:55,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:55,943 INFO:     Epoch: 83
2022-11-28 04:07:56,598 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48802797530185094, 'Total loss': 0.48802797530185094} | train loss {'Reaction outcome loss': 0.44631996180020994, 'Total loss': 0.44631996180020994}
2022-11-28 04:07:56,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:56,598 INFO:     Epoch: 84
2022-11-28 04:07:57,260 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5388097322799943, 'Total loss': 0.5388097322799943} | train loss {'Reaction outcome loss': 0.4719798903792135, 'Total loss': 0.4719798903792135}
2022-11-28 04:07:57,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:57,260 INFO:     Epoch: 85
2022-11-28 04:07:57,921 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4880632378838279, 'Total loss': 0.4880632378838279} | train loss {'Reaction outcome loss': 0.45378903630039386, 'Total loss': 0.45378903630039386}
2022-11-28 04:07:57,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:57,921 INFO:     Epoch: 86
2022-11-28 04:07:58,583 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4909226596355438, 'Total loss': 0.4909226596355438} | train loss {'Reaction outcome loss': 0.46679102611397544, 'Total loss': 0.46679102611397544}
2022-11-28 04:07:58,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:58,583 INFO:     Epoch: 87
2022-11-28 04:07:59,241 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4844421385364099, 'Total loss': 0.4844421385364099} | train loss {'Reaction outcome loss': 0.46002081204806605, 'Total loss': 0.46002081204806605}
2022-11-28 04:07:59,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:59,242 INFO:     Epoch: 88
2022-11-28 04:07:59,899 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4779679924249649, 'Total loss': 0.4779679924249649} | train loss {'Reaction outcome loss': 0.4598799915683846, 'Total loss': 0.4598799915683846}
2022-11-28 04:07:59,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:07:59,899 INFO:     Epoch: 89
2022-11-28 04:08:00,555 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5419447096911344, 'Total loss': 0.5419447096911344} | train loss {'Reaction outcome loss': 0.460477699014929, 'Total loss': 0.460477699014929}
2022-11-28 04:08:00,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:00,555 INFO:     Epoch: 90
2022-11-28 04:08:01,212 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5032308562235399, 'Total loss': 0.5032308562235399} | train loss {'Reaction outcome loss': 0.466952963281543, 'Total loss': 0.466952963281543}
2022-11-28 04:08:01,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:01,212 INFO:     Epoch: 91
2022-11-28 04:08:01,871 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49088115854696796, 'Total loss': 0.49088115854696796} | train loss {'Reaction outcome loss': 0.4593279377046612, 'Total loss': 0.4593279377046612}
2022-11-28 04:08:01,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:01,871 INFO:     Epoch: 92
2022-11-28 04:08:02,531 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4932467856190421, 'Total loss': 0.4932467856190421} | train loss {'Reaction outcome loss': 0.4598201692344681, 'Total loss': 0.4598201692344681}
2022-11-28 04:08:02,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:02,531 INFO:     Epoch: 93
2022-11-28 04:08:03,190 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5075784396718849, 'Total loss': 0.5075784396718849} | train loss {'Reaction outcome loss': 0.45982019311838573, 'Total loss': 0.45982019311838573}
2022-11-28 04:08:03,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:03,190 INFO:     Epoch: 94
2022-11-28 04:08:03,846 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4841714535247196, 'Total loss': 0.4841714535247196} | train loss {'Reaction outcome loss': 0.46077900461011356, 'Total loss': 0.46077900461011356}
2022-11-28 04:08:03,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:03,847 INFO:     Epoch: 95
2022-11-28 04:08:04,507 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5227079537104476, 'Total loss': 0.5227079537104476} | train loss {'Reaction outcome loss': 0.46379005608539425, 'Total loss': 0.46379005608539425}
2022-11-28 04:08:04,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:04,507 INFO:     Epoch: 96
2022-11-28 04:08:05,162 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5034650499847803, 'Total loss': 0.5034650499847803} | train loss {'Reaction outcome loss': 0.4618738032276592, 'Total loss': 0.4618738032276592}
2022-11-28 04:08:05,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:05,162 INFO:     Epoch: 97
2022-11-28 04:08:05,817 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5446749234741385, 'Total loss': 0.5446749234741385} | train loss {'Reaction outcome loss': 0.46162097393384866, 'Total loss': 0.46162097393384866}
2022-11-28 04:08:05,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:05,818 INFO:     Epoch: 98
2022-11-28 04:08:06,477 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.516721076247367, 'Total loss': 0.516721076247367} | train loss {'Reaction outcome loss': 0.4520122721310585, 'Total loss': 0.4520122721310585}
2022-11-28 04:08:06,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:06,477 INFO:     Epoch: 99
2022-11-28 04:08:07,138 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5312769778750159, 'Total loss': 0.5312769778750159} | train loss {'Reaction outcome loss': 0.46137749559936986, 'Total loss': 0.46137749559936986}
2022-11-28 04:08:07,138 INFO:     Best model found after epoch 28 of 100.
2022-11-28 04:08:07,138 INFO:   Done with stage: TRAINING
2022-11-28 04:08:07,138 INFO:   Starting stage: EVALUATION
2022-11-28 04:08:07,252 INFO:   Done with stage: EVALUATION
2022-11-28 04:08:07,252 INFO:   Leaving out SEQ value Fold_8
2022-11-28 04:08:07,265 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:08:07,265 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:08:07,919 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:08:07,919 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:08:07,987 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:08:07,987 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:08:07,987 INFO:     No hyperparam tuning for this model
2022-11-28 04:08:07,987 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:08:07,987 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:08:07,988 INFO:     None feature selector for col prot
2022-11-28 04:08:07,988 INFO:     None feature selector for col prot
2022-11-28 04:08:07,988 INFO:     None feature selector for col prot
2022-11-28 04:08:07,989 INFO:     None feature selector for col chem
2022-11-28 04:08:07,989 INFO:     None feature selector for col chem
2022-11-28 04:08:07,989 INFO:     None feature selector for col chem
2022-11-28 04:08:07,989 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:08:07,989 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:08:07,991 INFO:     Number of params in model 169651
2022-11-28 04:08:07,994 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:08:07,994 INFO:   Starting stage: TRAINING
2022-11-28 04:08:08,045 INFO:     Val loss before train {'Reaction outcome loss': 1.0210263674909419, 'Total loss': 1.0210263674909419}
2022-11-28 04:08:08,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:08,045 INFO:     Epoch: 0
2022-11-28 04:08:08,702 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6404754986817186, 'Total loss': 0.6404754986817186} | train loss {'Reaction outcome loss': 0.6806964820575135, 'Total loss': 0.6806964820575135}
2022-11-28 04:08:08,702 INFO:     Found new best model at epoch 0
2022-11-28 04:08:08,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:08,703 INFO:     Epoch: 1
2022-11-28 04:08:09,359 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6326049410484054, 'Total loss': 0.6326049410484054} | train loss {'Reaction outcome loss': 0.5755519762424081, 'Total loss': 0.5755519762424081}
2022-11-28 04:08:09,360 INFO:     Found new best model at epoch 1
2022-11-28 04:08:09,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:09,360 INFO:     Epoch: 2
2022-11-28 04:08:10,020 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5328139791434462, 'Total loss': 0.5328139791434462} | train loss {'Reaction outcome loss': 0.5582133022397153, 'Total loss': 0.5582133022397153}
2022-11-28 04:08:10,021 INFO:     Found new best model at epoch 2
2022-11-28 04:08:10,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:10,021 INFO:     Epoch: 3
2022-11-28 04:08:10,676 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5556662993674929, 'Total loss': 0.5556662993674929} | train loss {'Reaction outcome loss': 0.522720957152274, 'Total loss': 0.522720957152274}
2022-11-28 04:08:10,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:10,676 INFO:     Epoch: 4
2022-11-28 04:08:11,334 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6091345440257679, 'Total loss': 0.6091345440257679} | train loss {'Reaction outcome loss': 0.5166539228276202, 'Total loss': 0.5166539228276202}
2022-11-28 04:08:11,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:11,335 INFO:     Epoch: 5
2022-11-28 04:08:11,995 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5309312438422983, 'Total loss': 0.5309312438422983} | train loss {'Reaction outcome loss': 0.49989487291106327, 'Total loss': 0.49989487291106327}
2022-11-28 04:08:11,995 INFO:     Found new best model at epoch 5
2022-11-28 04:08:11,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:11,996 INFO:     Epoch: 6
2022-11-28 04:08:12,658 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5823996046727354, 'Total loss': 0.5823996046727354} | train loss {'Reaction outcome loss': 0.4956523885249126, 'Total loss': 0.4956523885249126}
2022-11-28 04:08:12,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:12,658 INFO:     Epoch: 7
2022-11-28 04:08:13,315 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5069968751208349, 'Total loss': 0.5069968751208349} | train loss {'Reaction outcome loss': 0.4879714317529308, 'Total loss': 0.4879714317529308}
2022-11-28 04:08:13,316 INFO:     Found new best model at epoch 7
2022-11-28 04:08:13,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:13,316 INFO:     Epoch: 8
2022-11-28 04:08:13,972 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5763317813927477, 'Total loss': 0.5763317813927477} | train loss {'Reaction outcome loss': 0.48513376338761827, 'Total loss': 0.48513376338761827}
2022-11-28 04:08:13,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:13,973 INFO:     Epoch: 9
2022-11-28 04:08:14,631 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5181173390962861, 'Total loss': 0.5181173390962861} | train loss {'Reaction outcome loss': 0.48412687277142336, 'Total loss': 0.48412687277142336}
2022-11-28 04:08:14,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:14,631 INFO:     Epoch: 10
2022-11-28 04:08:15,287 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5284569236365232, 'Total loss': 0.5284569236365232} | train loss {'Reaction outcome loss': 0.4800222497358013, 'Total loss': 0.4800222497358013}
2022-11-28 04:08:15,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:15,287 INFO:     Epoch: 11
2022-11-28 04:08:15,942 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5008405656977133, 'Total loss': 0.5008405656977133} | train loss {'Reaction outcome loss': 0.47730430954622355, 'Total loss': 0.47730430954622355}
2022-11-28 04:08:15,942 INFO:     Found new best model at epoch 11
2022-11-28 04:08:15,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:15,943 INFO:     Epoch: 12
2022-11-28 04:08:16,601 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49548198553648864, 'Total loss': 0.49548198553648864} | train loss {'Reaction outcome loss': 0.47488298203781065, 'Total loss': 0.47488298203781065}
2022-11-28 04:08:16,601 INFO:     Found new best model at epoch 12
2022-11-28 04:08:16,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:16,601 INFO:     Epoch: 13
2022-11-28 04:08:17,258 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5299768529155038, 'Total loss': 0.5299768529155038} | train loss {'Reaction outcome loss': 0.46668446492328336, 'Total loss': 0.46668446492328336}
2022-11-28 04:08:17,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:17,259 INFO:     Epoch: 14
2022-11-28 04:08:17,917 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5653430541807954, 'Total loss': 0.5653430541807954} | train loss {'Reaction outcome loss': 0.4861502438059703, 'Total loss': 0.4861502438059703}
2022-11-28 04:08:17,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:17,917 INFO:     Epoch: 15
2022-11-28 04:08:18,576 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.535051488402215, 'Total loss': 0.535051488402215} | train loss {'Reaction outcome loss': 0.4910652207338858, 'Total loss': 0.4910652207338858}
2022-11-28 04:08:18,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:18,576 INFO:     Epoch: 16
2022-11-28 04:08:19,234 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4969627670943737, 'Total loss': 0.4969627670943737} | train loss {'Reaction outcome loss': 0.4807866001539385, 'Total loss': 0.4807866001539385}
2022-11-28 04:08:19,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:19,235 INFO:     Epoch: 17
2022-11-28 04:08:19,891 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5399130962111733, 'Total loss': 0.5399130962111733} | train loss {'Reaction outcome loss': 0.46443944052238817, 'Total loss': 0.46443944052238817}
2022-11-28 04:08:19,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:19,891 INFO:     Epoch: 18
2022-11-28 04:08:20,546 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.50088896331462, 'Total loss': 0.50088896331462} | train loss {'Reaction outcome loss': 0.4707573817039912, 'Total loss': 0.4707573817039912}
2022-11-28 04:08:20,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:20,546 INFO:     Epoch: 19
2022-11-28 04:08:21,199 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5728240473703905, 'Total loss': 0.5728240473703905} | train loss {'Reaction outcome loss': 0.4685966547442834, 'Total loss': 0.4685966547442834}
2022-11-28 04:08:21,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:21,200 INFO:     Epoch: 20
2022-11-28 04:08:21,856 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4999804198741913, 'Total loss': 0.4999804198741913} | train loss {'Reaction outcome loss': 0.466047430086715, 'Total loss': 0.466047430086715}
2022-11-28 04:08:21,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:21,857 INFO:     Epoch: 21
2022-11-28 04:08:22,519 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.539508546617898, 'Total loss': 0.539508546617898} | train loss {'Reaction outcome loss': 0.46111393060821754, 'Total loss': 0.46111393060821754}
2022-11-28 04:08:22,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:22,520 INFO:     Epoch: 22
2022-11-28 04:08:23,179 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5232423726807941, 'Total loss': 0.5232423726807941} | train loss {'Reaction outcome loss': 0.4711077283871801, 'Total loss': 0.4711077283871801}
2022-11-28 04:08:23,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:23,180 INFO:     Epoch: 23
2022-11-28 04:08:23,837 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5809782289645888, 'Total loss': 0.5809782289645888} | train loss {'Reaction outcome loss': 0.4630017900718791, 'Total loss': 0.4630017900718791}
2022-11-28 04:08:23,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:23,837 INFO:     Epoch: 24
2022-11-28 04:08:24,495 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.492068122733723, 'Total loss': 0.492068122733723} | train loss {'Reaction outcome loss': 0.4641965771246436, 'Total loss': 0.4641965771246436}
2022-11-28 04:08:24,495 INFO:     Found new best model at epoch 24
2022-11-28 04:08:24,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:24,496 INFO:     Epoch: 25
2022-11-28 04:08:25,152 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5171356895430521, 'Total loss': 0.5171356895430521} | train loss {'Reaction outcome loss': 0.47326196144949567, 'Total loss': 0.47326196144949567}
2022-11-28 04:08:25,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:25,153 INFO:     Epoch: 26
2022-11-28 04:08:25,807 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5364434942603111, 'Total loss': 0.5364434942603111} | train loss {'Reaction outcome loss': 0.47811548538536197, 'Total loss': 0.47811548538536197}
2022-11-28 04:08:25,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:25,807 INFO:     Epoch: 27
2022-11-28 04:08:26,467 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49311265925114806, 'Total loss': 0.49311265925114806} | train loss {'Reaction outcome loss': 0.469042723960722, 'Total loss': 0.469042723960722}
2022-11-28 04:08:26,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:26,467 INFO:     Epoch: 28
2022-11-28 04:08:27,122 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5022507404739206, 'Total loss': 0.5022507404739206} | train loss {'Reaction outcome loss': 0.47443001865134066, 'Total loss': 0.47443001865134066}
2022-11-28 04:08:27,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:27,122 INFO:     Epoch: 29
2022-11-28 04:08:27,780 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48869765482165595, 'Total loss': 0.48869765482165595} | train loss {'Reaction outcome loss': 0.4668647175473783, 'Total loss': 0.4668647175473783}
2022-11-28 04:08:27,780 INFO:     Found new best model at epoch 29
2022-11-28 04:08:27,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:27,781 INFO:     Epoch: 30
2022-11-28 04:08:28,441 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5438155372711745, 'Total loss': 0.5438155372711745} | train loss {'Reaction outcome loss': 0.4679459736716409, 'Total loss': 0.4679459736716409}
2022-11-28 04:08:28,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:28,442 INFO:     Epoch: 31
2022-11-28 04:08:29,105 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4879154664548961, 'Total loss': 0.4879154664548961} | train loss {'Reaction outcome loss': 0.47853702554094646, 'Total loss': 0.47853702554094646}
2022-11-28 04:08:29,105 INFO:     Found new best model at epoch 31
2022-11-28 04:08:29,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:29,106 INFO:     Epoch: 32
2022-11-28 04:08:29,768 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4791186468845064, 'Total loss': 0.4791186468845064} | train loss {'Reaction outcome loss': 0.4682460992563109, 'Total loss': 0.4682460992563109}
2022-11-28 04:08:29,769 INFO:     Found new best model at epoch 32
2022-11-28 04:08:29,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:29,769 INFO:     Epoch: 33
2022-11-28 04:08:30,432 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5138062218373473, 'Total loss': 0.5138062218373473} | train loss {'Reaction outcome loss': 0.4663979151259791, 'Total loss': 0.4663979151259791}
2022-11-28 04:08:30,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:30,432 INFO:     Epoch: 34
2022-11-28 04:08:31,096 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5005306188355793, 'Total loss': 0.5005306188355793} | train loss {'Reaction outcome loss': 0.4660818056478674, 'Total loss': 0.4660818056478674}
2022-11-28 04:08:31,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:31,096 INFO:     Epoch: 35
2022-11-28 04:08:31,762 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5139732726595618, 'Total loss': 0.5139732726595618} | train loss {'Reaction outcome loss': 0.4675689926333273, 'Total loss': 0.4675689926333273}
2022-11-28 04:08:31,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:31,762 INFO:     Epoch: 36
2022-11-28 04:08:32,423 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49481869116425514, 'Total loss': 0.49481869116425514} | train loss {'Reaction outcome loss': 0.46410469747024025, 'Total loss': 0.46410469747024025}
2022-11-28 04:08:32,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:32,423 INFO:     Epoch: 37
2022-11-28 04:08:33,080 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5135776160115545, 'Total loss': 0.5135776160115545} | train loss {'Reaction outcome loss': 0.46656229167513036, 'Total loss': 0.46656229167513036}
2022-11-28 04:08:33,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:33,080 INFO:     Epoch: 38
2022-11-28 04:08:33,737 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5039501125839624, 'Total loss': 0.5039501125839624} | train loss {'Reaction outcome loss': 0.46843619469688974, 'Total loss': 0.46843619469688974}
2022-11-28 04:08:33,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:33,737 INFO:     Epoch: 39
2022-11-28 04:08:34,394 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4789028418335048, 'Total loss': 0.4789028418335048} | train loss {'Reaction outcome loss': 0.46592343239649103, 'Total loss': 0.46592343239649103}
2022-11-28 04:08:34,394 INFO:     Found new best model at epoch 39
2022-11-28 04:08:34,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:34,395 INFO:     Epoch: 40
2022-11-28 04:08:35,052 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5253934321755712, 'Total loss': 0.5253934321755712} | train loss {'Reaction outcome loss': 0.46840314066361805, 'Total loss': 0.46840314066361805}
2022-11-28 04:08:35,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:35,052 INFO:     Epoch: 41
2022-11-28 04:08:35,712 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49128930643200874, 'Total loss': 0.49128930643200874} | train loss {'Reaction outcome loss': 0.48319650715903234, 'Total loss': 0.48319650715903234}
2022-11-28 04:08:35,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:35,713 INFO:     Epoch: 42
2022-11-28 04:08:36,374 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4945162595673041, 'Total loss': 0.4945162595673041} | train loss {'Reaction outcome loss': 0.4721830440798269, 'Total loss': 0.4721830440798269}
2022-11-28 04:08:36,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:36,375 INFO:     Epoch: 43
2022-11-28 04:08:37,032 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5179526937956159, 'Total loss': 0.5179526937956159} | train loss {'Reaction outcome loss': 0.4595445305832967, 'Total loss': 0.4595445305832967}
2022-11-28 04:08:37,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:37,032 INFO:     Epoch: 44
2022-11-28 04:08:37,691 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47815110500563274, 'Total loss': 0.47815110500563274} | train loss {'Reaction outcome loss': 0.4648678421008925, 'Total loss': 0.4648678421008925}
2022-11-28 04:08:37,691 INFO:     Found new best model at epoch 44
2022-11-28 04:08:37,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:37,692 INFO:     Epoch: 45
2022-11-28 04:08:38,351 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49173424155874684, 'Total loss': 0.49173424155874684} | train loss {'Reaction outcome loss': 0.4663686939337958, 'Total loss': 0.4663686939337958}
2022-11-28 04:08:38,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:38,351 INFO:     Epoch: 46
2022-11-28 04:08:39,009 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5203255729919131, 'Total loss': 0.5203255729919131} | train loss {'Reaction outcome loss': 0.46645085872546865, 'Total loss': 0.46645085872546865}
2022-11-28 04:08:39,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:39,010 INFO:     Epoch: 47
2022-11-28 04:08:39,668 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5047299990599806, 'Total loss': 0.5047299990599806} | train loss {'Reaction outcome loss': 0.4741646440526252, 'Total loss': 0.4741646440526252}
2022-11-28 04:08:39,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:39,668 INFO:     Epoch: 48
2022-11-28 04:08:40,324 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5321617197584022, 'Total loss': 0.5321617197584022} | train loss {'Reaction outcome loss': 0.46488235553025237, 'Total loss': 0.46488235553025237}
2022-11-28 04:08:40,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:40,324 INFO:     Epoch: 49
2022-11-28 04:08:40,979 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5385124297304587, 'Total loss': 0.5385124297304587} | train loss {'Reaction outcome loss': 0.4683220843795823, 'Total loss': 0.4683220843795823}
2022-11-28 04:08:40,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:40,979 INFO:     Epoch: 50
2022-11-28 04:08:41,635 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5257780189541253, 'Total loss': 0.5257780189541253} | train loss {'Reaction outcome loss': 0.46856400170759394, 'Total loss': 0.46856400170759394}
2022-11-28 04:08:41,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:41,635 INFO:     Epoch: 51
2022-11-28 04:08:42,293 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5161886235529726, 'Total loss': 0.5161886235529726} | train loss {'Reaction outcome loss': 0.4641203885136346, 'Total loss': 0.4641203885136346}
2022-11-28 04:08:42,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:42,294 INFO:     Epoch: 52
2022-11-28 04:08:42,951 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5088517699729312, 'Total loss': 0.5088517699729312} | train loss {'Reaction outcome loss': 0.4608641775430516, 'Total loss': 0.4608641775430516}
2022-11-28 04:08:42,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:42,951 INFO:     Epoch: 53
2022-11-28 04:08:43,605 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5015216686508872, 'Total loss': 0.5015216686508872} | train loss {'Reaction outcome loss': 0.4654204141092204, 'Total loss': 0.4654204141092204}
2022-11-28 04:08:43,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:43,605 INFO:     Epoch: 54
2022-11-28 04:08:44,260 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4953702440993352, 'Total loss': 0.4953702440993352} | train loss {'Reaction outcome loss': 0.4746319235939729, 'Total loss': 0.4746319235939729}
2022-11-28 04:08:44,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:44,260 INFO:     Epoch: 55
2022-11-28 04:08:44,915 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5002803026952527, 'Total loss': 0.5002803026952527} | train loss {'Reaction outcome loss': 0.46360169526053824, 'Total loss': 0.46360169526053824}
2022-11-28 04:08:44,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:44,915 INFO:     Epoch: 56
2022-11-28 04:08:45,573 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4996820772913369, 'Total loss': 0.4996820772913369} | train loss {'Reaction outcome loss': 0.4701568942200317, 'Total loss': 0.4701568942200317}
2022-11-28 04:08:45,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:45,573 INFO:     Epoch: 57
2022-11-28 04:08:46,235 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49715512923218985, 'Total loss': 0.49715512923218985} | train loss {'Reaction outcome loss': 0.46549242309592515, 'Total loss': 0.46549242309592515}
2022-11-28 04:08:46,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:46,235 INFO:     Epoch: 58
2022-11-28 04:08:46,892 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4819572198797356, 'Total loss': 0.4819572198797356} | train loss {'Reaction outcome loss': 0.46952985812295306, 'Total loss': 0.46952985812295306}
2022-11-28 04:08:46,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:46,892 INFO:     Epoch: 59
2022-11-28 04:08:47,545 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5245650061829523, 'Total loss': 0.5245650061829523} | train loss {'Reaction outcome loss': 0.4743909597517508, 'Total loss': 0.4743909597517508}
2022-11-28 04:08:47,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:47,546 INFO:     Epoch: 60
2022-11-28 04:08:48,201 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4781782776117325, 'Total loss': 0.4781782776117325} | train loss {'Reaction outcome loss': 0.4626262953584101, 'Total loss': 0.4626262953584101}
2022-11-28 04:08:48,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:48,201 INFO:     Epoch: 61
2022-11-28 04:08:48,859 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5215997540137984, 'Total loss': 0.5215997540137984} | train loss {'Reaction outcome loss': 0.45816871098540574, 'Total loss': 0.45816871098540574}
2022-11-28 04:08:48,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:48,860 INFO:     Epoch: 62
2022-11-28 04:08:49,513 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5181917223063383, 'Total loss': 0.5181917223063383} | train loss {'Reaction outcome loss': 0.46437264951737783, 'Total loss': 0.46437264951737783}
2022-11-28 04:08:49,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:49,513 INFO:     Epoch: 63
2022-11-28 04:08:50,170 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.518750073896213, 'Total loss': 0.518750073896213} | train loss {'Reaction outcome loss': 0.46841269336369357, 'Total loss': 0.46841269336369357}
2022-11-28 04:08:50,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:50,170 INFO:     Epoch: 64
2022-11-28 04:08:50,827 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49257525327530777, 'Total loss': 0.49257525327530777} | train loss {'Reaction outcome loss': 0.45947961153289085, 'Total loss': 0.45947961153289085}
2022-11-28 04:08:50,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:50,827 INFO:     Epoch: 65
2022-11-28 04:08:51,480 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4983910085125403, 'Total loss': 0.4983910085125403} | train loss {'Reaction outcome loss': 0.4623929496839462, 'Total loss': 0.4623929496839462}
2022-11-28 04:08:51,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:51,481 INFO:     Epoch: 66
2022-11-28 04:08:52,137 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4850970513441346, 'Total loss': 0.4850970513441346} | train loss {'Reaction outcome loss': 0.4687561379511829, 'Total loss': 0.4687561379511829}
2022-11-28 04:08:52,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:52,137 INFO:     Epoch: 67
2022-11-28 04:08:52,793 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5057686706158248, 'Total loss': 0.5057686706158248} | train loss {'Reaction outcome loss': 0.46660519768351966, 'Total loss': 0.46660519768351966}
2022-11-28 04:08:52,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:52,794 INFO:     Epoch: 68
2022-11-28 04:08:53,449 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5137727341868661, 'Total loss': 0.5137727341868661} | train loss {'Reaction outcome loss': 0.4632729530817101, 'Total loss': 0.4632729530817101}
2022-11-28 04:08:53,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:53,449 INFO:     Epoch: 69
2022-11-28 04:08:54,110 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5206313688646663, 'Total loss': 0.5206313688646663} | train loss {'Reaction outcome loss': 0.4645662717973655, 'Total loss': 0.4645662717973655}
2022-11-28 04:08:54,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:54,110 INFO:     Epoch: 70
2022-11-28 04:08:54,768 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49902278794483707, 'Total loss': 0.49902278794483707} | train loss {'Reaction outcome loss': 0.46080545634634584, 'Total loss': 0.46080545634634584}
2022-11-28 04:08:54,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:54,770 INFO:     Epoch: 71
2022-11-28 04:08:55,424 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4946118833666498, 'Total loss': 0.4946118833666498} | train loss {'Reaction outcome loss': 0.45674639463665995, 'Total loss': 0.45674639463665995}
2022-11-28 04:08:55,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:55,425 INFO:     Epoch: 72
2022-11-28 04:08:56,079 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5282341895455663, 'Total loss': 0.5282341895455663} | train loss {'Reaction outcome loss': 0.46291899185454255, 'Total loss': 0.46291899185454255}
2022-11-28 04:08:56,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:56,080 INFO:     Epoch: 73
2022-11-28 04:08:56,740 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5152902074835517, 'Total loss': 0.5152902074835517} | train loss {'Reaction outcome loss': 0.46193673157016274, 'Total loss': 0.46193673157016274}
2022-11-28 04:08:56,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:56,740 INFO:     Epoch: 74
2022-11-28 04:08:57,403 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5411073538390073, 'Total loss': 0.5411073538390073} | train loss {'Reaction outcome loss': 0.46633235685647983, 'Total loss': 0.46633235685647983}
2022-11-28 04:08:57,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:57,403 INFO:     Epoch: 75
2022-11-28 04:08:58,064 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5043832212686539, 'Total loss': 0.5043832212686539} | train loss {'Reaction outcome loss': 0.4649434808513474, 'Total loss': 0.4649434808513474}
2022-11-28 04:08:58,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:58,064 INFO:     Epoch: 76
2022-11-28 04:08:58,724 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4988778792321682, 'Total loss': 0.4988778792321682} | train loss {'Reaction outcome loss': 0.46369416746292036, 'Total loss': 0.46369416746292036}
2022-11-28 04:08:58,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:58,724 INFO:     Epoch: 77
2022-11-28 04:08:59,379 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49857594005086203, 'Total loss': 0.49857594005086203} | train loss {'Reaction outcome loss': 0.46516273523914636, 'Total loss': 0.46516273523914636}
2022-11-28 04:08:59,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:08:59,379 INFO:     Epoch: 78
2022-11-28 04:09:00,036 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4693843695250424, 'Total loss': 0.4693843695250424} | train loss {'Reaction outcome loss': 0.45706648509459274, 'Total loss': 0.45706648509459274}
2022-11-28 04:09:00,036 INFO:     Found new best model at epoch 78
2022-11-28 04:09:00,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:00,037 INFO:     Epoch: 79
2022-11-28 04:09:00,697 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48708710650151427, 'Total loss': 0.48708710650151427} | train loss {'Reaction outcome loss': 0.46275728784109416, 'Total loss': 0.46275728784109416}
2022-11-28 04:09:00,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:00,697 INFO:     Epoch: 80
2022-11-28 04:09:01,359 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5288037183609876, 'Total loss': 0.5288037183609876} | train loss {'Reaction outcome loss': 0.46930438557617093, 'Total loss': 0.46930438557617093}
2022-11-28 04:09:01,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:01,360 INFO:     Epoch: 81
2022-11-28 04:09:02,022 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49618887630375946, 'Total loss': 0.49618887630375946} | train loss {'Reaction outcome loss': 0.4695477671468789, 'Total loss': 0.4695477671468789}
2022-11-28 04:09:02,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:02,022 INFO:     Epoch: 82
2022-11-28 04:09:02,679 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4948642761869864, 'Total loss': 0.4948642761869864} | train loss {'Reaction outcome loss': 0.47351213776872225, 'Total loss': 0.47351213776872225}
2022-11-28 04:09:02,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:02,679 INFO:     Epoch: 83
2022-11-28 04:09:03,336 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48300093480131845, 'Total loss': 0.48300093480131845} | train loss {'Reaction outcome loss': 0.47102810167952586, 'Total loss': 0.47102810167952586}
2022-11-28 04:09:03,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:03,336 INFO:     Epoch: 84
2022-11-28 04:09:03,999 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47418471493504266, 'Total loss': 0.47418471493504266} | train loss {'Reaction outcome loss': 0.4643134179144253, 'Total loss': 0.4643134179144253}
2022-11-28 04:09:03,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:03,999 INFO:     Epoch: 85
2022-11-28 04:09:04,661 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49190373955802486, 'Total loss': 0.49190373955802486} | train loss {'Reaction outcome loss': 0.45490225793620354, 'Total loss': 0.45490225793620354}
2022-11-28 04:09:04,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:04,661 INFO:     Epoch: 86
2022-11-28 04:09:05,318 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5318217213180932, 'Total loss': 0.5318217213180932} | train loss {'Reaction outcome loss': 0.4600935179574287, 'Total loss': 0.4600935179574287}
2022-11-28 04:09:05,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:05,319 INFO:     Epoch: 87
2022-11-28 04:09:05,979 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.545284475792538, 'Total loss': 0.545284475792538} | train loss {'Reaction outcome loss': 0.4706327065161848, 'Total loss': 0.4706327065161848}
2022-11-28 04:09:05,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:05,979 INFO:     Epoch: 88
2022-11-28 04:09:06,639 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5030063563449816, 'Total loss': 0.5030063563449816} | train loss {'Reaction outcome loss': 0.46532040701703986, 'Total loss': 0.46532040701703986}
2022-11-28 04:09:06,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:06,639 INFO:     Epoch: 89
2022-11-28 04:09:07,298 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5367787724191492, 'Total loss': 0.5367787724191492} | train loss {'Reaction outcome loss': 0.46209583714084046, 'Total loss': 0.46209583714084046}
2022-11-28 04:09:07,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:07,298 INFO:     Epoch: 90
2022-11-28 04:09:07,954 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.508601152761416, 'Total loss': 0.508601152761416} | train loss {'Reaction outcome loss': 0.4575357604074303, 'Total loss': 0.4575357604074303}
2022-11-28 04:09:07,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:07,954 INFO:     Epoch: 91
2022-11-28 04:09:08,613 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5117030445147644, 'Total loss': 0.5117030445147644} | train loss {'Reaction outcome loss': 0.46397534895288617, 'Total loss': 0.46397534895288617}
2022-11-28 04:09:08,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:08,613 INFO:     Epoch: 92
2022-11-28 04:09:09,266 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5041060698303309, 'Total loss': 0.5041060698303309} | train loss {'Reaction outcome loss': 0.4584626690578847, 'Total loss': 0.4584626690578847}
2022-11-28 04:09:09,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:09,266 INFO:     Epoch: 93
2022-11-28 04:09:09,921 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5311117741194639, 'Total loss': 0.5311117741194639} | train loss {'Reaction outcome loss': 0.4707408654696764, 'Total loss': 0.4707408654696764}
2022-11-28 04:09:09,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:09,921 INFO:     Epoch: 94
2022-11-28 04:09:10,579 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4836982935667038, 'Total loss': 0.4836982935667038} | train loss {'Reaction outcome loss': 0.4633505009058184, 'Total loss': 0.4633505009058184}
2022-11-28 04:09:10,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:10,579 INFO:     Epoch: 95
2022-11-28 04:09:11,235 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5224490666931326, 'Total loss': 0.5224490666931326} | train loss {'Reaction outcome loss': 0.46838059894710415, 'Total loss': 0.46838059894710415}
2022-11-28 04:09:11,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:11,235 INFO:     Epoch: 96
2022-11-28 04:09:11,893 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4778691645372998, 'Total loss': 0.4778691645372998} | train loss {'Reaction outcome loss': 0.4698357153156026, 'Total loss': 0.4698357153156026}
2022-11-28 04:09:11,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:11,893 INFO:     Epoch: 97
2022-11-28 04:09:12,557 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49483452466401184, 'Total loss': 0.49483452466401184} | train loss {'Reaction outcome loss': 0.463276548484559, 'Total loss': 0.463276548484559}
2022-11-28 04:09:12,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:12,557 INFO:     Epoch: 98
2022-11-28 04:09:13,216 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5047568787227977, 'Total loss': 0.5047568787227977} | train loss {'Reaction outcome loss': 0.46213970915508656, 'Total loss': 0.46213970915508656}
2022-11-28 04:09:13,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:13,217 INFO:     Epoch: 99
2022-11-28 04:09:13,874 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4804766841910102, 'Total loss': 0.4804766841910102} | train loss {'Reaction outcome loss': 0.4660557729271259, 'Total loss': 0.4660557729271259}
2022-11-28 04:09:13,875 INFO:     Best model found after epoch 79 of 100.
2022-11-28 04:09:13,875 INFO:   Done with stage: TRAINING
2022-11-28 04:09:13,875 INFO:   Starting stage: EVALUATION
2022-11-28 04:09:13,994 INFO:   Done with stage: EVALUATION
2022-11-28 04:09:13,994 INFO:   Leaving out SEQ value Fold_9
2022-11-28 04:09:14,007 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:09:14,007 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:09:14,645 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:09:14,645 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:09:14,714 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:09:14,714 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:09:14,714 INFO:     No hyperparam tuning for this model
2022-11-28 04:09:14,714 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:09:14,714 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:09:14,715 INFO:     None feature selector for col prot
2022-11-28 04:09:14,715 INFO:     None feature selector for col prot
2022-11-28 04:09:14,715 INFO:     None feature selector for col prot
2022-11-28 04:09:14,716 INFO:     None feature selector for col chem
2022-11-28 04:09:14,716 INFO:     None feature selector for col chem
2022-11-28 04:09:14,716 INFO:     None feature selector for col chem
2022-11-28 04:09:14,716 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:09:14,716 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:09:14,718 INFO:     Number of params in model 169651
2022-11-28 04:09:14,721 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:09:14,721 INFO:   Starting stage: TRAINING
2022-11-28 04:09:14,773 INFO:     Val loss before train {'Reaction outcome loss': 1.003227792002938, 'Total loss': 1.003227792002938}
2022-11-28 04:09:14,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:14,773 INFO:     Epoch: 0
2022-11-28 04:09:15,440 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6313623372804035, 'Total loss': 0.6313623372804035} | train loss {'Reaction outcome loss': 0.7004209863803079, 'Total loss': 0.7004209863803079}
2022-11-28 04:09:15,440 INFO:     Found new best model at epoch 0
2022-11-28 04:09:15,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:15,440 INFO:     Epoch: 1
2022-11-28 04:09:16,104 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5796038880944252, 'Total loss': 0.5796038880944252} | train loss {'Reaction outcome loss': 0.5976454908809354, 'Total loss': 0.5976454908809354}
2022-11-28 04:09:16,104 INFO:     Found new best model at epoch 1
2022-11-28 04:09:16,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:16,105 INFO:     Epoch: 2
2022-11-28 04:09:16,769 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.565823616629297, 'Total loss': 0.565823616629297} | train loss {'Reaction outcome loss': 0.5597183471245151, 'Total loss': 0.5597183471245151}
2022-11-28 04:09:16,769 INFO:     Found new best model at epoch 2
2022-11-28 04:09:16,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:16,770 INFO:     Epoch: 3
2022-11-28 04:09:17,434 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5010680684989149, 'Total loss': 0.5010680684989149} | train loss {'Reaction outcome loss': 0.5392874595859358, 'Total loss': 0.5392874595859358}
2022-11-28 04:09:17,434 INFO:     Found new best model at epoch 3
2022-11-28 04:09:17,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:17,435 INFO:     Epoch: 4
2022-11-28 04:09:18,095 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5527015436779369, 'Total loss': 0.5527015436779369} | train loss {'Reaction outcome loss': 0.5232228544210235, 'Total loss': 0.5232228544210235}
2022-11-28 04:09:18,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:18,095 INFO:     Epoch: 5
2022-11-28 04:09:18,756 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5170965804295107, 'Total loss': 0.5170965804295107} | train loss {'Reaction outcome loss': 0.5176017692372683, 'Total loss': 0.5176017692372683}
2022-11-28 04:09:18,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:18,756 INFO:     Epoch: 6
2022-11-28 04:09:19,421 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5135581926866011, 'Total loss': 0.5135581926866011} | train loss {'Reaction outcome loss': 0.5086988246729297, 'Total loss': 0.5086988246729297}
2022-11-28 04:09:19,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:19,421 INFO:     Epoch: 7
2022-11-28 04:09:20,081 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5019662234593522, 'Total loss': 0.5019662234593522} | train loss {'Reaction outcome loss': 0.5069137089435132, 'Total loss': 0.5069137089435132}
2022-11-28 04:09:20,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:20,081 INFO:     Epoch: 8
2022-11-28 04:09:20,740 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5097867213189602, 'Total loss': 0.5097867213189602} | train loss {'Reaction outcome loss': 0.5023338479861137, 'Total loss': 0.5023338479861137}
2022-11-28 04:09:20,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:20,740 INFO:     Epoch: 9
2022-11-28 04:09:21,398 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49256041713736276, 'Total loss': 0.49256041713736276} | train loss {'Reaction outcome loss': 0.5013344663706037, 'Total loss': 0.5013344663706037}
2022-11-28 04:09:21,398 INFO:     Found new best model at epoch 9
2022-11-28 04:09:21,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:21,399 INFO:     Epoch: 10
2022-11-28 04:09:22,057 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48262314566157083, 'Total loss': 0.48262314566157083} | train loss {'Reaction outcome loss': 0.4982672550024525, 'Total loss': 0.4982672550024525}
2022-11-28 04:09:22,057 INFO:     Found new best model at epoch 10
2022-11-28 04:09:22,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:22,058 INFO:     Epoch: 11
2022-11-28 04:09:22,720 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.515584471212192, 'Total loss': 0.515584471212192} | train loss {'Reaction outcome loss': 0.48833370232774365, 'Total loss': 0.48833370232774365}
2022-11-28 04:09:22,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:22,720 INFO:     Epoch: 12
2022-11-28 04:09:23,381 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48471849310127174, 'Total loss': 0.48471849310127174} | train loss {'Reaction outcome loss': 0.4844095800672808, 'Total loss': 0.4844095800672808}
2022-11-28 04:09:23,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:23,381 INFO:     Epoch: 13
2022-11-28 04:09:24,041 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4868785034526478, 'Total loss': 0.4868785034526478} | train loss {'Reaction outcome loss': 0.4877919036774866, 'Total loss': 0.4877919036774866}
2022-11-28 04:09:24,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:24,041 INFO:     Epoch: 14
2022-11-28 04:09:24,705 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4942600862546401, 'Total loss': 0.4942600862546401} | train loss {'Reaction outcome loss': 0.49211973414546056, 'Total loss': 0.49211973414546056}
2022-11-28 04:09:24,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:24,705 INFO:     Epoch: 15
2022-11-28 04:09:25,369 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49376940490169957, 'Total loss': 0.49376940490169957} | train loss {'Reaction outcome loss': 0.48060877537054403, 'Total loss': 0.48060877537054403}
2022-11-28 04:09:25,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:25,370 INFO:     Epoch: 16
2022-11-28 04:09:26,029 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48057489706711337, 'Total loss': 0.48057489706711337} | train loss {'Reaction outcome loss': 0.47781046954614503, 'Total loss': 0.47781046954614503}
2022-11-28 04:09:26,030 INFO:     Found new best model at epoch 16
2022-11-28 04:09:26,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:26,030 INFO:     Epoch: 17
2022-11-28 04:09:26,692 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4995436705648899, 'Total loss': 0.4995436705648899} | train loss {'Reaction outcome loss': 0.48218223752994693, 'Total loss': 0.48218223752994693}
2022-11-28 04:09:26,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:26,693 INFO:     Epoch: 18
2022-11-28 04:09:27,355 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48145446757023985, 'Total loss': 0.48145446757023985} | train loss {'Reaction outcome loss': 0.4790507819383375, 'Total loss': 0.4790507819383375}
2022-11-28 04:09:27,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:27,355 INFO:     Epoch: 19
2022-11-28 04:09:28,018 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4754087369550358, 'Total loss': 0.4754087369550358} | train loss {'Reaction outcome loss': 0.4755414446755763, 'Total loss': 0.4755414446755763}
2022-11-28 04:09:28,018 INFO:     Found new best model at epoch 19
2022-11-28 04:09:28,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:28,019 INFO:     Epoch: 20
2022-11-28 04:09:28,683 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4780759540471164, 'Total loss': 0.4780759540471164} | train loss {'Reaction outcome loss': 0.46622898579845506, 'Total loss': 0.46622898579845506}
2022-11-28 04:09:28,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:28,684 INFO:     Epoch: 21
2022-11-28 04:09:29,343 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5088497393510558, 'Total loss': 0.5088497393510558} | train loss {'Reaction outcome loss': 0.47378789182872544, 'Total loss': 0.47378789182872544}
2022-11-28 04:09:29,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:29,343 INFO:     Epoch: 22
2022-11-28 04:09:30,003 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4839843518354676, 'Total loss': 0.4839843518354676} | train loss {'Reaction outcome loss': 0.47353445023538604, 'Total loss': 0.47353445023538604}
2022-11-28 04:09:30,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:30,003 INFO:     Epoch: 23
2022-11-28 04:09:30,665 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5540859160775488, 'Total loss': 0.5540859160775488} | train loss {'Reaction outcome loss': 0.48540144948469055, 'Total loss': 0.48540144948469055}
2022-11-28 04:09:30,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:30,665 INFO:     Epoch: 24
2022-11-28 04:09:31,329 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4615351530638608, 'Total loss': 0.4615351530638608} | train loss {'Reaction outcome loss': 0.46673407383082854, 'Total loss': 0.46673407383082854}
2022-11-28 04:09:31,329 INFO:     Found new best model at epoch 24
2022-11-28 04:09:31,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:31,330 INFO:     Epoch: 25
2022-11-28 04:09:31,988 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48278692263093864, 'Total loss': 0.48278692263093864} | train loss {'Reaction outcome loss': 0.4703949736731668, 'Total loss': 0.4703949736731668}
2022-11-28 04:09:31,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:31,989 INFO:     Epoch: 26
2022-11-28 04:09:32,649 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47239672900600865, 'Total loss': 0.47239672900600865} | train loss {'Reaction outcome loss': 0.4723478103236806, 'Total loss': 0.4723478103236806}
2022-11-28 04:09:32,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:32,649 INFO:     Epoch: 27
2022-11-28 04:09:33,310 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.534247643568299, 'Total loss': 0.534247643568299} | train loss {'Reaction outcome loss': 0.47295237512838456, 'Total loss': 0.47295237512838456}
2022-11-28 04:09:33,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:33,310 INFO:     Epoch: 28
2022-11-28 04:09:33,972 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45933000641790306, 'Total loss': 0.45933000641790306} | train loss {'Reaction outcome loss': 0.47262895197397276, 'Total loss': 0.47262895197397276}
2022-11-28 04:09:33,972 INFO:     Found new best model at epoch 28
2022-11-28 04:09:33,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:33,973 INFO:     Epoch: 29
2022-11-28 04:09:34,633 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4820514599030668, 'Total loss': 0.4820514599030668} | train loss {'Reaction outcome loss': 0.47149315554528465, 'Total loss': 0.47149315554528465}
2022-11-28 04:09:34,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:34,634 INFO:     Epoch: 30
2022-11-28 04:09:35,301 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4842252399433743, 'Total loss': 0.4842252399433743} | train loss {'Reaction outcome loss': 0.4705383921823194, 'Total loss': 0.4705383921823194}
2022-11-28 04:09:35,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:35,301 INFO:     Epoch: 31
2022-11-28 04:09:35,965 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48151886090636253, 'Total loss': 0.48151886090636253} | train loss {'Reaction outcome loss': 0.4658508702151237, 'Total loss': 0.4658508702151237}
2022-11-28 04:09:35,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:35,965 INFO:     Epoch: 32
2022-11-28 04:09:36,632 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4735380092805082, 'Total loss': 0.4735380092805082} | train loss {'Reaction outcome loss': 0.470454168295668, 'Total loss': 0.470454168295668}
2022-11-28 04:09:36,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:36,632 INFO:     Epoch: 33
2022-11-28 04:09:37,296 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5643768364732916, 'Total loss': 0.5643768364732916} | train loss {'Reaction outcome loss': 0.4647357132766516, 'Total loss': 0.4647357132766516}
2022-11-28 04:09:37,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:37,296 INFO:     Epoch: 34
2022-11-28 04:09:37,957 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4762684472582557, 'Total loss': 0.4762684472582557} | train loss {'Reaction outcome loss': 0.46843365315468083, 'Total loss': 0.46843365315468083}
2022-11-28 04:09:37,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:37,958 INFO:     Epoch: 35
2022-11-28 04:09:38,621 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5041421275924552, 'Total loss': 0.5041421275924552} | train loss {'Reaction outcome loss': 0.4605407297250725, 'Total loss': 0.4605407297250725}
2022-11-28 04:09:38,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:38,621 INFO:     Epoch: 36
2022-11-28 04:09:39,283 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47530842843380844, 'Total loss': 0.47530842843380844} | train loss {'Reaction outcome loss': 0.46470502060988256, 'Total loss': 0.46470502060988256}
2022-11-28 04:09:39,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:39,284 INFO:     Epoch: 37
2022-11-28 04:09:39,952 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4612388522787528, 'Total loss': 0.4612388522787528} | train loss {'Reaction outcome loss': 0.4714551958585939, 'Total loss': 0.4714551958585939}
2022-11-28 04:09:39,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:39,952 INFO:     Epoch: 38
2022-11-28 04:09:40,619 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49686703458428383, 'Total loss': 0.49686703458428383} | train loss {'Reaction outcome loss': 0.4695679337507294, 'Total loss': 0.4695679337507294}
2022-11-28 04:09:40,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:40,619 INFO:     Epoch: 39
2022-11-28 04:09:41,283 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.477195237509229, 'Total loss': 0.477195237509229} | train loss {'Reaction outcome loss': 0.4735683820420696, 'Total loss': 0.4735683820420696}
2022-11-28 04:09:41,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:41,284 INFO:     Epoch: 40
2022-11-28 04:09:41,948 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47163843939250166, 'Total loss': 0.47163843939250166} | train loss {'Reaction outcome loss': 0.4683188425316926, 'Total loss': 0.4683188425316926}
2022-11-28 04:09:41,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:41,948 INFO:     Epoch: 41
2022-11-28 04:09:42,610 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4837497997690331, 'Total loss': 0.4837497997690331} | train loss {'Reaction outcome loss': 0.4751633063799912, 'Total loss': 0.4751633063799912}
2022-11-28 04:09:42,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:42,611 INFO:     Epoch: 42
2022-11-28 04:09:43,272 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4848992492664944, 'Total loss': 0.4848992492664944} | train loss {'Reaction outcome loss': 0.4687251104342361, 'Total loss': 0.4687251104342361}
2022-11-28 04:09:43,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:43,272 INFO:     Epoch: 43
2022-11-28 04:09:43,939 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.52789841118184, 'Total loss': 0.52789841118184} | train loss {'Reaction outcome loss': 0.4716852873924278, 'Total loss': 0.4716852873924278}
2022-11-28 04:09:43,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:43,939 INFO:     Epoch: 44
2022-11-28 04:09:44,605 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4921442500569604, 'Total loss': 0.4921442500569604} | train loss {'Reaction outcome loss': 0.46986807504248235, 'Total loss': 0.46986807504248235}
2022-11-28 04:09:44,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:44,606 INFO:     Epoch: 45
2022-11-28 04:09:45,271 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44633583656766196, 'Total loss': 0.44633583656766196} | train loss {'Reaction outcome loss': 0.47012635104117856, 'Total loss': 0.47012635104117856}
2022-11-28 04:09:45,272 INFO:     Found new best model at epoch 45
2022-11-28 04:09:45,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:45,272 INFO:     Epoch: 46
2022-11-28 04:09:45,934 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4801403365351937, 'Total loss': 0.4801403365351937} | train loss {'Reaction outcome loss': 0.47339298534056834, 'Total loss': 0.47339298534056834}
2022-11-28 04:09:45,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:45,934 INFO:     Epoch: 47
2022-11-28 04:09:46,595 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46932213042270055, 'Total loss': 0.46932213042270055} | train loss {'Reaction outcome loss': 0.466757764468991, 'Total loss': 0.466757764468991}
2022-11-28 04:09:46,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:46,595 INFO:     Epoch: 48
2022-11-28 04:09:47,258 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4599552991038019, 'Total loss': 0.4599552991038019} | train loss {'Reaction outcome loss': 0.47339776026145103, 'Total loss': 0.47339776026145103}
2022-11-28 04:09:47,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:47,258 INFO:     Epoch: 49
2022-11-28 04:09:47,916 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4629333141175183, 'Total loss': 0.4629333141175183} | train loss {'Reaction outcome loss': 0.4707268088334991, 'Total loss': 0.4707268088334991}
2022-11-28 04:09:47,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:47,917 INFO:     Epoch: 50
2022-11-28 04:09:48,578 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47638236663558264, 'Total loss': 0.47638236663558264} | train loss {'Reaction outcome loss': 0.47074116928683174, 'Total loss': 0.47074116928683174}
2022-11-28 04:09:48,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:48,578 INFO:     Epoch: 51
2022-11-28 04:09:49,238 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47751029987226834, 'Total loss': 0.47751029987226834} | train loss {'Reaction outcome loss': 0.4647222268545339, 'Total loss': 0.4647222268545339}
2022-11-28 04:09:49,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:49,239 INFO:     Epoch: 52
2022-11-28 04:09:49,902 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4665520374070514, 'Total loss': 0.4665520374070514} | train loss {'Reaction outcome loss': 0.4687481375050641, 'Total loss': 0.4687481375050641}
2022-11-28 04:09:49,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:49,902 INFO:     Epoch: 53
2022-11-28 04:09:50,564 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4537904384461316, 'Total loss': 0.4537904384461316} | train loss {'Reaction outcome loss': 0.4712265829044965, 'Total loss': 0.4712265829044965}
2022-11-28 04:09:50,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:50,565 INFO:     Epoch: 54
2022-11-28 04:09:51,228 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45878782360391185, 'Total loss': 0.45878782360391185} | train loss {'Reaction outcome loss': 0.4732175594976833, 'Total loss': 0.4732175594976833}
2022-11-28 04:09:51,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:51,228 INFO:     Epoch: 55
2022-11-28 04:09:51,888 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49769740450111305, 'Total loss': 0.49769740450111305} | train loss {'Reaction outcome loss': 0.47385506950799494, 'Total loss': 0.47385506950799494}
2022-11-28 04:09:51,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:51,888 INFO:     Epoch: 56
2022-11-28 04:09:52,549 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4564550901678475, 'Total loss': 0.4564550901678475} | train loss {'Reaction outcome loss': 0.4764116635365832, 'Total loss': 0.4764116635365832}
2022-11-28 04:09:52,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:52,549 INFO:     Epoch: 57
2022-11-28 04:09:53,210 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5025679960169576, 'Total loss': 0.5025679960169576} | train loss {'Reaction outcome loss': 0.47176103131665337, 'Total loss': 0.47176103131665337}
2022-11-28 04:09:53,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:53,210 INFO:     Epoch: 58
2022-11-28 04:09:53,871 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4618723490698771, 'Total loss': 0.4618723490698771} | train loss {'Reaction outcome loss': 0.47610413331177925, 'Total loss': 0.47610413331177925}
2022-11-28 04:09:53,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:53,872 INFO:     Epoch: 59
2022-11-28 04:09:54,534 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4508376477116888, 'Total loss': 0.4508376477116888} | train loss {'Reaction outcome loss': 0.4698518146910975, 'Total loss': 0.4698518146910975}
2022-11-28 04:09:54,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:54,534 INFO:     Epoch: 60
2022-11-28 04:09:55,198 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4707289416004311, 'Total loss': 0.4707289416004311} | train loss {'Reaction outcome loss': 0.4722101430018102, 'Total loss': 0.4722101430018102}
2022-11-28 04:09:55,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:55,198 INFO:     Epoch: 61
2022-11-28 04:09:55,861 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4951669404452497, 'Total loss': 0.4951669404452497} | train loss {'Reaction outcome loss': 0.4710528318800272, 'Total loss': 0.4710528318800272}
2022-11-28 04:09:55,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:55,861 INFO:     Epoch: 62
2022-11-28 04:09:56,524 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46351766789501364, 'Total loss': 0.46351766789501364} | train loss {'Reaction outcome loss': 0.46924550945480026, 'Total loss': 0.46924550945480026}
2022-11-28 04:09:56,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:56,525 INFO:     Epoch: 63
2022-11-28 04:09:57,188 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4889098724181002, 'Total loss': 0.4889098724181002} | train loss {'Reaction outcome loss': 0.47559571314242577, 'Total loss': 0.47559571314242577}
2022-11-28 04:09:57,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:57,188 INFO:     Epoch: 64
2022-11-28 04:09:57,853 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4933248697356744, 'Total loss': 0.4933248697356744} | train loss {'Reaction outcome loss': 0.47425276173218606, 'Total loss': 0.47425276173218606}
2022-11-28 04:09:57,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:57,853 INFO:     Epoch: 65
2022-11-28 04:09:58,517 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5080245347185568, 'Total loss': 0.5080245347185568} | train loss {'Reaction outcome loss': 0.46441269726041823, 'Total loss': 0.46441269726041823}
2022-11-28 04:09:58,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:58,518 INFO:     Epoch: 66
2022-11-28 04:09:59,182 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4590027386491949, 'Total loss': 0.4590027386491949} | train loss {'Reaction outcome loss': 0.47213055334624743, 'Total loss': 0.47213055334624743}
2022-11-28 04:09:59,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:59,182 INFO:     Epoch: 67
2022-11-28 04:09:59,845 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4720659757202322, 'Total loss': 0.4720659757202322} | train loss {'Reaction outcome loss': 0.4761382100442725, 'Total loss': 0.4761382100442725}
2022-11-28 04:09:59,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:09:59,845 INFO:     Epoch: 68
2022-11-28 04:10:00,508 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48960016058249906, 'Total loss': 0.48960016058249906} | train loss {'Reaction outcome loss': 0.4789899384542819, 'Total loss': 0.4789899384542819}
2022-11-28 04:10:00,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:00,508 INFO:     Epoch: 69
2022-11-28 04:10:01,169 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.55886750634421, 'Total loss': 0.55886750634421} | train loss {'Reaction outcome loss': 0.4716843118770949, 'Total loss': 0.4716843118770949}
2022-11-28 04:10:01,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:01,170 INFO:     Epoch: 70
2022-11-28 04:10:01,832 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4581723382527178, 'Total loss': 0.4581723382527178} | train loss {'Reaction outcome loss': 0.4768301670950267, 'Total loss': 0.4768301670950267}
2022-11-28 04:10:01,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:01,832 INFO:     Epoch: 71
2022-11-28 04:10:02,494 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4808394255285913, 'Total loss': 0.4808394255285913} | train loss {'Reaction outcome loss': 0.47063180062198834, 'Total loss': 0.47063180062198834}
2022-11-28 04:10:02,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:02,495 INFO:     Epoch: 72
2022-11-28 04:10:03,154 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4715522466735406, 'Total loss': 0.4715522466735406} | train loss {'Reaction outcome loss': 0.47544602076372794, 'Total loss': 0.47544602076372794}
2022-11-28 04:10:03,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:03,155 INFO:     Epoch: 73
2022-11-28 04:10:03,818 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.482313987206329, 'Total loss': 0.482313987206329} | train loss {'Reaction outcome loss': 0.4732443838109893, 'Total loss': 0.4732443838109893}
2022-11-28 04:10:03,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:03,818 INFO:     Epoch: 74
2022-11-28 04:10:04,479 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4556048752909357, 'Total loss': 0.4556048752909357} | train loss {'Reaction outcome loss': 0.4706770422898473, 'Total loss': 0.4706770422898473}
2022-11-28 04:10:04,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:04,479 INFO:     Epoch: 75
2022-11-28 04:10:05,139 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45743917572227394, 'Total loss': 0.45743917572227394} | train loss {'Reaction outcome loss': 0.4765745698804817, 'Total loss': 0.4765745698804817}
2022-11-28 04:10:05,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:05,140 INFO:     Epoch: 76
2022-11-28 04:10:05,800 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49229517579078674, 'Total loss': 0.49229517579078674} | train loss {'Reaction outcome loss': 0.4712767989765252, 'Total loss': 0.4712767989765252}
2022-11-28 04:10:05,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:05,801 INFO:     Epoch: 77
2022-11-28 04:10:06,465 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4751251604069363, 'Total loss': 0.4751251604069363} | train loss {'Reaction outcome loss': 0.4744262006734648, 'Total loss': 0.4744262006734648}
2022-11-28 04:10:06,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:06,465 INFO:     Epoch: 78
2022-11-28 04:10:07,128 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4602477459067648, 'Total loss': 0.4602477459067648} | train loss {'Reaction outcome loss': 0.4729966825895732, 'Total loss': 0.4729966825895732}
2022-11-28 04:10:07,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:07,129 INFO:     Epoch: 79
2022-11-28 04:10:07,791 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46539547565308487, 'Total loss': 0.46539547565308487} | train loss {'Reaction outcome loss': 0.47086306210727463, 'Total loss': 0.47086306210727463}
2022-11-28 04:10:07,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:07,792 INFO:     Epoch: 80
2022-11-28 04:10:08,451 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4639991322024302, 'Total loss': 0.4639991322024302} | train loss {'Reaction outcome loss': 0.47106263504153295, 'Total loss': 0.47106263504153295}
2022-11-28 04:10:08,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:08,451 INFO:     Epoch: 81
2022-11-28 04:10:09,117 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4777314039793881, 'Total loss': 0.4777314039793881} | train loss {'Reaction outcome loss': 0.4658864734754447, 'Total loss': 0.4658864734754447}
2022-11-28 04:10:09,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:09,117 INFO:     Epoch: 82
2022-11-28 04:10:09,780 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47780194641514256, 'Total loss': 0.47780194641514256} | train loss {'Reaction outcome loss': 0.4734037523308108, 'Total loss': 0.4734037523308108}
2022-11-28 04:10:09,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:09,780 INFO:     Epoch: 83
2022-11-28 04:10:10,442 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4753819135102359, 'Total loss': 0.4753819135102359} | train loss {'Reaction outcome loss': 0.4746949339826261, 'Total loss': 0.4746949339826261}
2022-11-28 04:10:10,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:10,442 INFO:     Epoch: 84
2022-11-28 04:10:11,102 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4543559077111157, 'Total loss': 0.4543559077111157} | train loss {'Reaction outcome loss': 0.4818196348365276, 'Total loss': 0.4818196348365276}
2022-11-28 04:10:11,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:11,102 INFO:     Epoch: 85
2022-11-28 04:10:11,765 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.474983004683798, 'Total loss': 0.474983004683798} | train loss {'Reaction outcome loss': 0.47401910137024617, 'Total loss': 0.47401910137024617}
2022-11-28 04:10:11,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:11,765 INFO:     Epoch: 86
2022-11-28 04:10:12,429 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.530309717763554, 'Total loss': 0.530309717763554} | train loss {'Reaction outcome loss': 0.47387209768977856, 'Total loss': 0.47387209768977856}
2022-11-28 04:10:12,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:12,429 INFO:     Epoch: 87
2022-11-28 04:10:13,088 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4694273146716031, 'Total loss': 0.4694273146716031} | train loss {'Reaction outcome loss': 0.4771269924578167, 'Total loss': 0.4771269924578167}
2022-11-28 04:10:13,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:13,088 INFO:     Epoch: 88
2022-11-28 04:10:13,750 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49446148764003406, 'Total loss': 0.49446148764003406} | train loss {'Reaction outcome loss': 0.47113124885025526, 'Total loss': 0.47113124885025526}
2022-11-28 04:10:13,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:13,750 INFO:     Epoch: 89
2022-11-28 04:10:14,414 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46298473328351974, 'Total loss': 0.46298473328351974} | train loss {'Reaction outcome loss': 0.4742178980020746, 'Total loss': 0.4742178980020746}
2022-11-28 04:10:14,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:14,414 INFO:     Epoch: 90
2022-11-28 04:10:15,079 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4893435957756909, 'Total loss': 0.4893435957756909} | train loss {'Reaction outcome loss': 0.469412881580572, 'Total loss': 0.469412881580572}
2022-11-28 04:10:15,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:15,079 INFO:     Epoch: 91
2022-11-28 04:10:15,746 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4642976911907846, 'Total loss': 0.4642976911907846} | train loss {'Reaction outcome loss': 0.4743343376885018, 'Total loss': 0.4743343376885018}
2022-11-28 04:10:15,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:15,747 INFO:     Epoch: 92
2022-11-28 04:10:16,411 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45167882029305806, 'Total loss': 0.45167882029305806} | train loss {'Reaction outcome loss': 0.47026317440454035, 'Total loss': 0.47026317440454035}
2022-11-28 04:10:16,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:16,411 INFO:     Epoch: 93
2022-11-28 04:10:17,078 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4641099517995661, 'Total loss': 0.4641099517995661} | train loss {'Reaction outcome loss': 0.47260138146098585, 'Total loss': 0.47260138146098585}
2022-11-28 04:10:17,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:17,078 INFO:     Epoch: 94
2022-11-28 04:10:17,742 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5149949497797273, 'Total loss': 0.5149949497797273} | train loss {'Reaction outcome loss': 0.47224463573506764, 'Total loss': 0.47224463573506764}
2022-11-28 04:10:17,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:17,742 INFO:     Epoch: 95
2022-11-28 04:10:18,407 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46892852607098495, 'Total loss': 0.46892852607098495} | train loss {'Reaction outcome loss': 0.47577914998175636, 'Total loss': 0.47577914998175636}
2022-11-28 04:10:18,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:18,407 INFO:     Epoch: 96
2022-11-28 04:10:19,068 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5039534758437764, 'Total loss': 0.5039534758437764} | train loss {'Reaction outcome loss': 0.47509122537749426, 'Total loss': 0.47509122537749426}
2022-11-28 04:10:19,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:19,068 INFO:     Epoch: 97
2022-11-28 04:10:19,732 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48282216489315033, 'Total loss': 0.48282216489315033} | train loss {'Reaction outcome loss': 0.4751540926555472, 'Total loss': 0.4751540926555472}
2022-11-28 04:10:19,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:19,733 INFO:     Epoch: 98
2022-11-28 04:10:20,396 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47322439537806943, 'Total loss': 0.47322439537806943} | train loss {'Reaction outcome loss': 0.4692043545505693, 'Total loss': 0.4692043545505693}
2022-11-28 04:10:20,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:20,396 INFO:     Epoch: 99
2022-11-28 04:10:21,058 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5084133717146787, 'Total loss': 0.5084133717146787} | train loss {'Reaction outcome loss': 0.46869577431390363, 'Total loss': 0.46869577431390363}
2022-11-28 04:10:21,058 INFO:     Best model found after epoch 46 of 100.
2022-11-28 04:10:21,058 INFO:   Done with stage: TRAINING
2022-11-28 04:10:21,058 INFO:   Starting stage: EVALUATION
2022-11-28 04:10:21,172 INFO:   Done with stage: EVALUATION
2022-11-28 04:10:21,180 INFO:   Leaving out SEQ value Fold_0
2022-11-28 04:10:21,193 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:10:21,193 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:10:21,837 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:10:21,837 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:10:21,904 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:10:21,904 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:10:21,904 INFO:     No hyperparam tuning for this model
2022-11-28 04:10:21,904 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:10:21,904 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:10:21,905 INFO:     None feature selector for col prot
2022-11-28 04:10:21,905 INFO:     None feature selector for col prot
2022-11-28 04:10:21,905 INFO:     None feature selector for col prot
2022-11-28 04:10:21,906 INFO:     None feature selector for col chem
2022-11-28 04:10:21,906 INFO:     None feature selector for col chem
2022-11-28 04:10:21,906 INFO:     None feature selector for col chem
2022-11-28 04:10:21,906 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:10:21,906 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:10:21,907 INFO:     Number of params in model 169651
2022-11-28 04:10:21,911 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:10:21,911 INFO:   Starting stage: TRAINING
2022-11-28 04:10:21,962 INFO:     Val loss before train {'Reaction outcome loss': 0.9995252632281997, 'Total loss': 0.9995252632281997}
2022-11-28 04:10:21,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:21,962 INFO:     Epoch: 0
2022-11-28 04:10:22,618 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5732494497841055, 'Total loss': 0.5732494497841055} | train loss {'Reaction outcome loss': 0.6969488141488056, 'Total loss': 0.6969488141488056}
2022-11-28 04:10:22,619 INFO:     Found new best model at epoch 0
2022-11-28 04:10:22,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:22,619 INFO:     Epoch: 1
2022-11-28 04:10:23,271 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5189566910266876, 'Total loss': 0.5189566910266876} | train loss {'Reaction outcome loss': 0.5675815275737217, 'Total loss': 0.5675815275737217}
2022-11-28 04:10:23,271 INFO:     Found new best model at epoch 1
2022-11-28 04:10:23,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:23,271 INFO:     Epoch: 2
2022-11-28 04:10:23,923 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5525285046208989, 'Total loss': 0.5525285046208989} | train loss {'Reaction outcome loss': 0.5440520308455642, 'Total loss': 0.5440520308455642}
2022-11-28 04:10:23,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:23,923 INFO:     Epoch: 3
2022-11-28 04:10:24,576 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5217420973561027, 'Total loss': 0.5217420973561027} | train loss {'Reaction outcome loss': 0.5249134304572125, 'Total loss': 0.5249134304572125}
2022-11-28 04:10:24,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:24,576 INFO:     Epoch: 4
2022-11-28 04:10:25,227 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5202698804099452, 'Total loss': 0.5202698804099452} | train loss {'Reaction outcome loss': 0.5127423158105539, 'Total loss': 0.5127423158105539}
2022-11-28 04:10:25,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:25,227 INFO:     Epoch: 5
2022-11-28 04:10:25,882 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47648509964346886, 'Total loss': 0.47648509964346886} | train loss {'Reaction outcome loss': 0.5000912782489036, 'Total loss': 0.5000912782489036}
2022-11-28 04:10:25,882 INFO:     Found new best model at epoch 5
2022-11-28 04:10:25,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:25,883 INFO:     Epoch: 6
2022-11-28 04:10:26,535 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4854329733008688, 'Total loss': 0.4854329733008688} | train loss {'Reaction outcome loss': 0.49743118614566567, 'Total loss': 0.49743118614566567}
2022-11-28 04:10:26,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:26,535 INFO:     Epoch: 7
2022-11-28 04:10:27,188 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4786760048432784, 'Total loss': 0.4786760048432784} | train loss {'Reaction outcome loss': 0.48545721805825526, 'Total loss': 0.48545721805825526}
2022-11-28 04:10:27,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:27,189 INFO:     Epoch: 8
2022-11-28 04:10:27,842 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48559172316031024, 'Total loss': 0.48559172316031024} | train loss {'Reaction outcome loss': 0.48188480479376655, 'Total loss': 0.48188480479376655}
2022-11-28 04:10:27,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:27,843 INFO:     Epoch: 9
2022-11-28 04:10:28,495 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47249063510786404, 'Total loss': 0.47249063510786404} | train loss {'Reaction outcome loss': 0.47974056279172705, 'Total loss': 0.47974056279172705}
2022-11-28 04:10:28,495 INFO:     Found new best model at epoch 9
2022-11-28 04:10:28,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:28,496 INFO:     Epoch: 10
2022-11-28 04:10:29,150 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4463523165746169, 'Total loss': 0.4463523165746169} | train loss {'Reaction outcome loss': 0.4771564746389584, 'Total loss': 0.4771564746389584}
2022-11-28 04:10:29,150 INFO:     Found new best model at epoch 10
2022-11-28 04:10:29,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:29,151 INFO:     Epoch: 11
2022-11-28 04:10:29,805 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5417423901910131, 'Total loss': 0.5417423901910131} | train loss {'Reaction outcome loss': 0.4801920468101696, 'Total loss': 0.4801920468101696}
2022-11-28 04:10:29,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:29,805 INFO:     Epoch: 12
2022-11-28 04:10:30,459 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49708187309178437, 'Total loss': 0.49708187309178437} | train loss {'Reaction outcome loss': 0.4727767772820531, 'Total loss': 0.4727767772820531}
2022-11-28 04:10:30,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:30,460 INFO:     Epoch: 13
2022-11-28 04:10:31,118 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47616424377668987, 'Total loss': 0.47616424377668987} | train loss {'Reaction outcome loss': 0.4731348155104384, 'Total loss': 0.4731348155104384}
2022-11-28 04:10:31,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:31,118 INFO:     Epoch: 14
2022-11-28 04:10:31,776 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4771064482629299, 'Total loss': 0.4771064482629299} | train loss {'Reaction outcome loss': 0.46951102422816415, 'Total loss': 0.46951102422816415}
2022-11-28 04:10:31,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:31,776 INFO:     Epoch: 15
2022-11-28 04:10:32,430 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4727129909125241, 'Total loss': 0.4727129909125241} | train loss {'Reaction outcome loss': 0.4713463646112656, 'Total loss': 0.4713463646112656}
2022-11-28 04:10:32,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:32,430 INFO:     Epoch: 16
2022-11-28 04:10:33,083 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.495958229357546, 'Total loss': 0.495958229357546} | train loss {'Reaction outcome loss': 0.468785087186463, 'Total loss': 0.468785087186463}
2022-11-28 04:10:33,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:33,083 INFO:     Epoch: 17
2022-11-28 04:10:33,738 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4846438579261303, 'Total loss': 0.4846438579261303} | train loss {'Reaction outcome loss': 0.47060291292716044, 'Total loss': 0.47060291292716044}
2022-11-28 04:10:33,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:33,738 INFO:     Epoch: 18
2022-11-28 04:10:34,390 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4869918308474801, 'Total loss': 0.4869918308474801} | train loss {'Reaction outcome loss': 0.46517887960891335, 'Total loss': 0.46517887960891335}
2022-11-28 04:10:34,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:34,391 INFO:     Epoch: 19
2022-11-28 04:10:35,049 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5139932364902713, 'Total loss': 0.5139932364902713} | train loss {'Reaction outcome loss': 0.4742096232516425, 'Total loss': 0.4742096232516425}
2022-11-28 04:10:35,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:35,049 INFO:     Epoch: 20
2022-11-28 04:10:35,706 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4593197137794711, 'Total loss': 0.4593197137794711} | train loss {'Reaction outcome loss': 0.4665471660543461, 'Total loss': 0.4665471660543461}
2022-11-28 04:10:35,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:35,706 INFO:     Epoch: 21
2022-11-28 04:10:36,361 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49485268714753067, 'Total loss': 0.49485268714753067} | train loss {'Reaction outcome loss': 0.4705618615661349, 'Total loss': 0.4705618615661349}
2022-11-28 04:10:36,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:36,361 INFO:     Epoch: 22
2022-11-28 04:10:37,014 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4882237274538387, 'Total loss': 0.4882237274538387} | train loss {'Reaction outcome loss': 0.46306951903567023, 'Total loss': 0.46306951903567023}
2022-11-28 04:10:37,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:37,015 INFO:     Epoch: 23
2022-11-28 04:10:37,667 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4941054345531897, 'Total loss': 0.4941054345531897} | train loss {'Reaction outcome loss': 0.46818069700075654, 'Total loss': 0.46818069700075654}
2022-11-28 04:10:37,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:37,668 INFO:     Epoch: 24
2022-11-28 04:10:38,323 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4936071688478643, 'Total loss': 0.4936071688478643} | train loss {'Reaction outcome loss': 0.46416436613214257, 'Total loss': 0.46416436613214257}
2022-11-28 04:10:38,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:38,323 INFO:     Epoch: 25
2022-11-28 04:10:38,976 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46331078017299826, 'Total loss': 0.46331078017299826} | train loss {'Reaction outcome loss': 0.46205957769131173, 'Total loss': 0.46205957769131173}
2022-11-28 04:10:38,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:38,976 INFO:     Epoch: 26
2022-11-28 04:10:39,629 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4877747351473028, 'Total loss': 0.4877747351473028} | train loss {'Reaction outcome loss': 0.4622124948671886, 'Total loss': 0.4622124948671886}
2022-11-28 04:10:39,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:39,629 INFO:     Epoch: 27
2022-11-28 04:10:40,285 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45575002106753265, 'Total loss': 0.45575002106753265} | train loss {'Reaction outcome loss': 0.4599550808570823, 'Total loss': 0.4599550808570823}
2022-11-28 04:10:40,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:40,285 INFO:     Epoch: 28
2022-11-28 04:10:40,941 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47255881198427896, 'Total loss': 0.47255881198427896} | train loss {'Reaction outcome loss': 0.45700945221647926, 'Total loss': 0.45700945221647926}
2022-11-28 04:10:40,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:40,941 INFO:     Epoch: 29
2022-11-28 04:10:41,603 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47721029682592914, 'Total loss': 0.47721029682592914} | train loss {'Reaction outcome loss': 0.4569878125069093, 'Total loss': 0.4569878125069093}
2022-11-28 04:10:41,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:41,603 INFO:     Epoch: 30
2022-11-28 04:10:42,273 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5070110291919925, 'Total loss': 0.5070110291919925} | train loss {'Reaction outcome loss': 0.4610699997568617, 'Total loss': 0.4610699997568617}
2022-11-28 04:10:42,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:42,273 INFO:     Epoch: 31
2022-11-28 04:10:42,943 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44880303452638065, 'Total loss': 0.44880303452638065} | train loss {'Reaction outcome loss': 0.46207335962324725, 'Total loss': 0.46207335962324725}
2022-11-28 04:10:42,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:42,943 INFO:     Epoch: 32
2022-11-28 04:10:43,614 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5325633405961774, 'Total loss': 0.5325633405961774} | train loss {'Reaction outcome loss': 0.46358023656874286, 'Total loss': 0.46358023656874286}
2022-11-28 04:10:43,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:43,614 INFO:     Epoch: 33
2022-11-28 04:10:44,284 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4726907346736301, 'Total loss': 0.4726907346736301} | train loss {'Reaction outcome loss': 0.46573814153671267, 'Total loss': 0.46573814153671267}
2022-11-28 04:10:44,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:44,284 INFO:     Epoch: 34
2022-11-28 04:10:44,953 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46952206810767, 'Total loss': 0.46952206810767} | train loss {'Reaction outcome loss': 0.45970787162683446, 'Total loss': 0.45970787162683446}
2022-11-28 04:10:44,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:44,953 INFO:     Epoch: 35
2022-11-28 04:10:45,625 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4525159438225356, 'Total loss': 0.4525159438225356} | train loss {'Reaction outcome loss': 0.46729470284617675, 'Total loss': 0.46729470284617675}
2022-11-28 04:10:45,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:45,625 INFO:     Epoch: 36
2022-11-28 04:10:46,299 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4598002227192575, 'Total loss': 0.4598002227192575} | train loss {'Reaction outcome loss': 0.4620610003872794, 'Total loss': 0.4620610003872794}
2022-11-28 04:10:46,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:46,299 INFO:     Epoch: 37
2022-11-28 04:10:46,973 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4683504636314782, 'Total loss': 0.4683504636314782} | train loss {'Reaction outcome loss': 0.4615563662076483, 'Total loss': 0.4615563662076483}
2022-11-28 04:10:46,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:46,974 INFO:     Epoch: 38
2022-11-28 04:10:47,643 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5208312926644628, 'Total loss': 0.5208312926644628} | train loss {'Reaction outcome loss': 0.4579772235179434, 'Total loss': 0.4579772235179434}
2022-11-28 04:10:47,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:47,644 INFO:     Epoch: 39
2022-11-28 04:10:48,313 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4783139553937045, 'Total loss': 0.4783139553937045} | train loss {'Reaction outcome loss': 0.4725833444571009, 'Total loss': 0.4725833444571009}
2022-11-28 04:10:48,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:48,313 INFO:     Epoch: 40
2022-11-28 04:10:48,985 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4713302671232007, 'Total loss': 0.4713302671232007} | train loss {'Reaction outcome loss': 0.4619582813613269, 'Total loss': 0.4619582813613269}
2022-11-28 04:10:48,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:48,985 INFO:     Epoch: 41
2022-11-28 04:10:49,656 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5102975883267142, 'Total loss': 0.5102975883267142} | train loss {'Reaction outcome loss': 0.45408869525607753, 'Total loss': 0.45408869525607753}
2022-11-28 04:10:49,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:49,656 INFO:     Epoch: 42
2022-11-28 04:10:50,324 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5020851922983472, 'Total loss': 0.5020851922983472} | train loss {'Reaction outcome loss': 0.4612018315767755, 'Total loss': 0.4612018315767755}
2022-11-28 04:10:50,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:50,324 INFO:     Epoch: 43
2022-11-28 04:10:50,996 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44779116406359454, 'Total loss': 0.44779116406359454} | train loss {'Reaction outcome loss': 0.46275959638308506, 'Total loss': 0.46275959638308506}
2022-11-28 04:10:50,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:50,997 INFO:     Epoch: 44
2022-11-28 04:10:51,671 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4712639745663513, 'Total loss': 0.4712639745663513} | train loss {'Reaction outcome loss': 0.4596308069569724, 'Total loss': 0.4596308069569724}
2022-11-28 04:10:51,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:51,672 INFO:     Epoch: 45
2022-11-28 04:10:52,344 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46041927791454573, 'Total loss': 0.46041927791454573} | train loss {'Reaction outcome loss': 0.46259679107033475, 'Total loss': 0.46259679107033475}
2022-11-28 04:10:52,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:52,344 INFO:     Epoch: 46
2022-11-28 04:10:53,014 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.470684003084898, 'Total loss': 0.470684003084898} | train loss {'Reaction outcome loss': 0.4569362723401615, 'Total loss': 0.4569362723401615}
2022-11-28 04:10:53,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:53,014 INFO:     Epoch: 47
2022-11-28 04:10:53,687 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4953360232439908, 'Total loss': 0.4953360232439908} | train loss {'Reaction outcome loss': 0.46265363729729947, 'Total loss': 0.46265363729729947}
2022-11-28 04:10:53,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:53,687 INFO:     Epoch: 48
2022-11-28 04:10:54,363 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45366140827536583, 'Total loss': 0.45366140827536583} | train loss {'Reaction outcome loss': 0.46382173108203073, 'Total loss': 0.46382173108203073}
2022-11-28 04:10:54,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:54,363 INFO:     Epoch: 49
2022-11-28 04:10:55,039 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45635065165433014, 'Total loss': 0.45635065165433014} | train loss {'Reaction outcome loss': 0.46779091595386973, 'Total loss': 0.46779091595386973}
2022-11-28 04:10:55,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:55,040 INFO:     Epoch: 50
2022-11-28 04:10:55,711 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.464712799272754, 'Total loss': 0.464712799272754} | train loss {'Reaction outcome loss': 0.4619301314256629, 'Total loss': 0.4619301314256629}
2022-11-28 04:10:55,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:55,712 INFO:     Epoch: 51
2022-11-28 04:10:56,386 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4895700253546238, 'Total loss': 0.4895700253546238} | train loss {'Reaction outcome loss': 0.46448455909077, 'Total loss': 0.46448455909077}
2022-11-28 04:10:56,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:56,386 INFO:     Epoch: 52
2022-11-28 04:10:57,055 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4677397215908224, 'Total loss': 0.4677397215908224} | train loss {'Reaction outcome loss': 0.460857326157239, 'Total loss': 0.460857326157239}
2022-11-28 04:10:57,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:57,056 INFO:     Epoch: 53
2022-11-28 04:10:57,726 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5069026699797674, 'Total loss': 0.5069026699797674} | train loss {'Reaction outcome loss': 0.45332478661926423, 'Total loss': 0.45332478661926423}
2022-11-28 04:10:57,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:57,727 INFO:     Epoch: 54
2022-11-28 04:10:58,383 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46614945138042624, 'Total loss': 0.46614945138042624} | train loss {'Reaction outcome loss': 0.4658283675203518, 'Total loss': 0.4658283675203518}
2022-11-28 04:10:58,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:58,383 INFO:     Epoch: 55
2022-11-28 04:10:59,043 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47922680526971817, 'Total loss': 0.47922680526971817} | train loss {'Reaction outcome loss': 0.46458204765709077, 'Total loss': 0.46458204765709077}
2022-11-28 04:10:59,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:59,044 INFO:     Epoch: 56
2022-11-28 04:10:59,702 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4670783213593743, 'Total loss': 0.4670783213593743} | train loss {'Reaction outcome loss': 0.4617673626359628, 'Total loss': 0.4617673626359628}
2022-11-28 04:10:59,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:10:59,702 INFO:     Epoch: 57
2022-11-28 04:11:00,358 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45079748501831834, 'Total loss': 0.45079748501831834} | train loss {'Reaction outcome loss': 0.46103944778442385, 'Total loss': 0.46103944778442385}
2022-11-28 04:11:00,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:00,359 INFO:     Epoch: 58
2022-11-28 04:11:01,019 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47311403399164026, 'Total loss': 0.47311403399164026} | train loss {'Reaction outcome loss': 0.455475456191569, 'Total loss': 0.455475456191569}
2022-11-28 04:11:01,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:01,019 INFO:     Epoch: 59
2022-11-28 04:11:01,675 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4889086799865419, 'Total loss': 0.4889086799865419} | train loss {'Reaction outcome loss': 0.45758083663424665, 'Total loss': 0.45758083663424665}
2022-11-28 04:11:01,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:01,675 INFO:     Epoch: 60
2022-11-28 04:11:02,330 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4458233500746163, 'Total loss': 0.4458233500746163} | train loss {'Reaction outcome loss': 0.46528051249226743, 'Total loss': 0.46528051249226743}
2022-11-28 04:11:02,330 INFO:     Found new best model at epoch 60
2022-11-28 04:11:02,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:02,331 INFO:     Epoch: 61
2022-11-28 04:11:02,984 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47091463580727577, 'Total loss': 0.47091463580727577} | train loss {'Reaction outcome loss': 0.45594910316321313, 'Total loss': 0.45594910316321313}
2022-11-28 04:11:02,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:02,985 INFO:     Epoch: 62
2022-11-28 04:11:03,640 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4457135032015768, 'Total loss': 0.4457135032015768} | train loss {'Reaction outcome loss': 0.458318461508167, 'Total loss': 0.458318461508167}
2022-11-28 04:11:03,640 INFO:     Found new best model at epoch 62
2022-11-28 04:11:03,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:03,641 INFO:     Epoch: 63
2022-11-28 04:11:04,295 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4816369990056211, 'Total loss': 0.4816369990056211} | train loss {'Reaction outcome loss': 0.45867719540790636, 'Total loss': 0.45867719540790636}
2022-11-28 04:11:04,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:04,296 INFO:     Epoch: 64
2022-11-28 04:11:04,949 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45760149271650746, 'Total loss': 0.45760149271650746} | train loss {'Reaction outcome loss': 0.4602000568594251, 'Total loss': 0.4602000568594251}
2022-11-28 04:11:04,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:04,949 INFO:     Epoch: 65
2022-11-28 04:11:05,606 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4750554849478332, 'Total loss': 0.4750554849478332} | train loss {'Reaction outcome loss': 0.45937527545860835, 'Total loss': 0.45937527545860835}
2022-11-28 04:11:05,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:05,607 INFO:     Epoch: 66
2022-11-28 04:11:06,261 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46196945214813406, 'Total loss': 0.46196945214813406} | train loss {'Reaction outcome loss': 0.4526923091435919, 'Total loss': 0.4526923091435919}
2022-11-28 04:11:06,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:06,261 INFO:     Epoch: 67
2022-11-28 04:11:06,916 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49019658362323587, 'Total loss': 0.49019658362323587} | train loss {'Reaction outcome loss': 0.4623934500375573, 'Total loss': 0.4623934500375573}
2022-11-28 04:11:06,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:06,916 INFO:     Epoch: 68
2022-11-28 04:11:07,576 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43743155287070706, 'Total loss': 0.43743155287070706} | train loss {'Reaction outcome loss': 0.45952664863090126, 'Total loss': 0.45952664863090126}
2022-11-28 04:11:07,576 INFO:     Found new best model at epoch 68
2022-11-28 04:11:07,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:07,577 INFO:     Epoch: 69
2022-11-28 04:11:08,232 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4682079147208821, 'Total loss': 0.4682079147208821} | train loss {'Reaction outcome loss': 0.4596260807952102, 'Total loss': 0.4596260807952102}
2022-11-28 04:11:08,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:08,233 INFO:     Epoch: 70
2022-11-28 04:11:08,889 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4591738368299874, 'Total loss': 0.4591738368299874} | train loss {'Reaction outcome loss': 0.46044555203038817, 'Total loss': 0.46044555203038817}
2022-11-28 04:11:08,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:08,889 INFO:     Epoch: 71
2022-11-28 04:11:09,545 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.461449879814278, 'Total loss': 0.461449879814278} | train loss {'Reaction outcome loss': 0.45784360742082403, 'Total loss': 0.45784360742082403}
2022-11-28 04:11:09,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:09,545 INFO:     Epoch: 72
2022-11-28 04:11:10,203 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5072610867633061, 'Total loss': 0.5072610867633061} | train loss {'Reaction outcome loss': 0.45894410220944154, 'Total loss': 0.45894410220944154}
2022-11-28 04:11:10,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:10,203 INFO:     Epoch: 73
2022-11-28 04:11:10,857 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45699211345477536, 'Total loss': 0.45699211345477536} | train loss {'Reaction outcome loss': 0.4584086533711881, 'Total loss': 0.4584086533711881}
2022-11-28 04:11:10,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:10,858 INFO:     Epoch: 74
2022-11-28 04:11:11,512 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45324766026301816, 'Total loss': 0.45324766026301816} | train loss {'Reaction outcome loss': 0.4669528968784274, 'Total loss': 0.4669528968784274}
2022-11-28 04:11:11,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:11,512 INFO:     Epoch: 75
2022-11-28 04:11:12,167 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4646926495161923, 'Total loss': 0.4646926495161923} | train loss {'Reaction outcome loss': 0.45802206494370284, 'Total loss': 0.45802206494370284}
2022-11-28 04:11:12,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:12,167 INFO:     Epoch: 76
2022-11-28 04:11:12,822 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44294068623672833, 'Total loss': 0.44294068623672833} | train loss {'Reaction outcome loss': 0.46517385743102246, 'Total loss': 0.46517385743102246}
2022-11-28 04:11:12,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:12,822 INFO:     Epoch: 77
2022-11-28 04:11:13,478 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.465839781883088, 'Total loss': 0.465839781883088} | train loss {'Reaction outcome loss': 0.4606651334738245, 'Total loss': 0.4606651334738245}
2022-11-28 04:11:13,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:13,479 INFO:     Epoch: 78
2022-11-28 04:11:14,134 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4674356525594538, 'Total loss': 0.4674356525594538} | train loss {'Reaction outcome loss': 0.4600646147314383, 'Total loss': 0.4600646147314383}
2022-11-28 04:11:14,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:14,134 INFO:     Epoch: 79
2022-11-28 04:11:14,787 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4505970234220678, 'Total loss': 0.4505970234220678} | train loss {'Reaction outcome loss': 0.45654925229598065, 'Total loss': 0.45654925229598065}
2022-11-28 04:11:14,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:14,787 INFO:     Epoch: 80
2022-11-28 04:11:15,441 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45404332131147385, 'Total loss': 0.45404332131147385} | train loss {'Reaction outcome loss': 0.4590727166861904, 'Total loss': 0.4590727166861904}
2022-11-28 04:11:15,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:15,441 INFO:     Epoch: 81
2022-11-28 04:11:16,096 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4726587120782245, 'Total loss': 0.4726587120782245} | train loss {'Reaction outcome loss': 0.4653204503108044, 'Total loss': 0.4653204503108044}
2022-11-28 04:11:16,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:16,096 INFO:     Epoch: 82
2022-11-28 04:11:16,753 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4878571087663824, 'Total loss': 0.4878571087663824} | train loss {'Reaction outcome loss': 0.45673424999932855, 'Total loss': 0.45673424999932855}
2022-11-28 04:11:16,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:16,753 INFO:     Epoch: 83
2022-11-28 04:11:17,406 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47082292051477864, 'Total loss': 0.47082292051477864} | train loss {'Reaction outcome loss': 0.4587202943101221, 'Total loss': 0.4587202943101221}
2022-11-28 04:11:17,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:17,406 INFO:     Epoch: 84
2022-11-28 04:11:18,059 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5126435048878193, 'Total loss': 0.5126435048878193} | train loss {'Reaction outcome loss': 0.46169500071175246, 'Total loss': 0.46169500071175246}
2022-11-28 04:11:18,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:18,059 INFO:     Epoch: 85
2022-11-28 04:11:18,716 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4545245583761822, 'Total loss': 0.4545245583761822} | train loss {'Reaction outcome loss': 0.4615730510682476, 'Total loss': 0.4615730510682476}
2022-11-28 04:11:18,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:18,716 INFO:     Epoch: 86
2022-11-28 04:11:19,377 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4510898993096568, 'Total loss': 0.4510898993096568} | train loss {'Reaction outcome loss': 0.45412854950646964, 'Total loss': 0.45412854950646964}
2022-11-28 04:11:19,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:19,378 INFO:     Epoch: 87
2022-11-28 04:11:20,036 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5180431214923208, 'Total loss': 0.5180431214923208} | train loss {'Reaction outcome loss': 0.4651559856473183, 'Total loss': 0.4651559856473183}
2022-11-28 04:11:20,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:20,036 INFO:     Epoch: 88
2022-11-28 04:11:20,700 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49588724090294406, 'Total loss': 0.49588724090294406} | train loss {'Reaction outcome loss': 0.4531163406007144, 'Total loss': 0.4531163406007144}
2022-11-28 04:11:20,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:20,700 INFO:     Epoch: 89
2022-11-28 04:11:21,360 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4368607059798457, 'Total loss': 0.4368607059798457} | train loss {'Reaction outcome loss': 0.46642934345469184, 'Total loss': 0.46642934345469184}
2022-11-28 04:11:21,360 INFO:     Found new best model at epoch 89
2022-11-28 04:11:21,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:21,361 INFO:     Epoch: 90
2022-11-28 04:11:22,020 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49625778807835147, 'Total loss': 0.49625778807835147} | train loss {'Reaction outcome loss': 0.4583585492202214, 'Total loss': 0.4583585492202214}
2022-11-28 04:11:22,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:22,020 INFO:     Epoch: 91
2022-11-28 04:11:22,675 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4706164412200451, 'Total loss': 0.4706164412200451} | train loss {'Reaction outcome loss': 0.46063533242867916, 'Total loss': 0.46063533242867916}
2022-11-28 04:11:22,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:22,676 INFO:     Epoch: 92
2022-11-28 04:11:23,328 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4663012959063053, 'Total loss': 0.4663012959063053} | train loss {'Reaction outcome loss': 0.45750824298177445, 'Total loss': 0.45750824298177445}
2022-11-28 04:11:23,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:23,329 INFO:     Epoch: 93
2022-11-28 04:11:23,983 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44995069452984765, 'Total loss': 0.44995069452984765} | train loss {'Reaction outcome loss': 0.45893224331797383, 'Total loss': 0.45893224331797383}
2022-11-28 04:11:23,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:23,983 INFO:     Epoch: 94
2022-11-28 04:11:24,638 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4513316530395638, 'Total loss': 0.4513316530395638} | train loss {'Reaction outcome loss': 0.4645456610285506, 'Total loss': 0.4645456610285506}
2022-11-28 04:11:24,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:24,638 INFO:     Epoch: 95
2022-11-28 04:11:25,297 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46876505931670015, 'Total loss': 0.46876505931670015} | train loss {'Reaction outcome loss': 0.4603514960833958, 'Total loss': 0.4603514960833958}
2022-11-28 04:11:25,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:25,297 INFO:     Epoch: 96
2022-11-28 04:11:25,954 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4597480371594429, 'Total loss': 0.4597480371594429} | train loss {'Reaction outcome loss': 0.4593742318299352, 'Total loss': 0.4593742318299352}
2022-11-28 04:11:25,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:25,954 INFO:     Epoch: 97
2022-11-28 04:11:26,607 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49882254614071414, 'Total loss': 0.49882254614071414} | train loss {'Reaction outcome loss': 0.46246108230279415, 'Total loss': 0.46246108230279415}
2022-11-28 04:11:26,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:26,607 INFO:     Epoch: 98
2022-11-28 04:11:27,257 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4652103182267059, 'Total loss': 0.4652103182267059} | train loss {'Reaction outcome loss': 0.4590750415106209, 'Total loss': 0.4590750415106209}
2022-11-28 04:11:27,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:27,257 INFO:     Epoch: 99
2022-11-28 04:11:27,912 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47048521956259554, 'Total loss': 0.47048521956259554} | train loss {'Reaction outcome loss': 0.45833457525895566, 'Total loss': 0.45833457525895566}
2022-11-28 04:11:27,912 INFO:     Best model found after epoch 90 of 100.
2022-11-28 04:11:27,912 INFO:   Done with stage: TRAINING
2022-11-28 04:11:27,912 INFO:   Starting stage: EVALUATION
2022-11-28 04:11:28,036 INFO:   Done with stage: EVALUATION
2022-11-28 04:11:28,036 INFO:   Leaving out SEQ value Fold_1
2022-11-28 04:11:28,049 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 04:11:28,050 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:11:28,684 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:11:28,684 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:11:28,750 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:11:28,751 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:11:28,751 INFO:     No hyperparam tuning for this model
2022-11-28 04:11:28,751 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:11:28,751 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:11:28,751 INFO:     None feature selector for col prot
2022-11-28 04:11:28,752 INFO:     None feature selector for col prot
2022-11-28 04:11:28,752 INFO:     None feature selector for col prot
2022-11-28 04:11:28,752 INFO:     None feature selector for col chem
2022-11-28 04:11:28,752 INFO:     None feature selector for col chem
2022-11-28 04:11:28,752 INFO:     None feature selector for col chem
2022-11-28 04:11:28,752 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:11:28,752 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:11:28,754 INFO:     Number of params in model 169651
2022-11-28 04:11:28,757 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:11:28,757 INFO:   Starting stage: TRAINING
2022-11-28 04:11:28,807 INFO:     Val loss before train {'Reaction outcome loss': 1.0096207108608513, 'Total loss': 1.0096207108608513}
2022-11-28 04:11:28,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:28,807 INFO:     Epoch: 0
2022-11-28 04:11:29,454 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5920291646968486, 'Total loss': 0.5920291646968486} | train loss {'Reaction outcome loss': 0.6860190562505291, 'Total loss': 0.6860190562505291}
2022-11-28 04:11:29,454 INFO:     Found new best model at epoch 0
2022-11-28 04:11:29,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:29,455 INFO:     Epoch: 1
2022-11-28 04:11:30,103 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6189154833555222, 'Total loss': 0.6189154833555222} | train loss {'Reaction outcome loss': 0.5785737520873301, 'Total loss': 0.5785737520873301}
2022-11-28 04:11:30,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:30,103 INFO:     Epoch: 2
2022-11-28 04:11:30,752 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5268486350081688, 'Total loss': 0.5268486350081688} | train loss {'Reaction outcome loss': 0.545402931455722, 'Total loss': 0.545402931455722}
2022-11-28 04:11:30,753 INFO:     Found new best model at epoch 2
2022-11-28 04:11:30,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:30,754 INFO:     Epoch: 3
2022-11-28 04:11:31,403 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5915130685235179, 'Total loss': 0.5915130685235179} | train loss {'Reaction outcome loss': 0.5252247414716478, 'Total loss': 0.5252247414716478}
2022-11-28 04:11:31,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:31,403 INFO:     Epoch: 4
2022-11-28 04:11:32,055 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.543448910463688, 'Total loss': 0.543448910463688} | train loss {'Reaction outcome loss': 0.5167035962696429, 'Total loss': 0.5167035962696429}
2022-11-28 04:11:32,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:32,055 INFO:     Epoch: 5
2022-11-28 04:11:32,705 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5327717249476632, 'Total loss': 0.5327717249476632} | train loss {'Reaction outcome loss': 0.502283504409064, 'Total loss': 0.502283504409064}
2022-11-28 04:11:32,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:32,705 INFO:     Epoch: 6
2022-11-28 04:11:33,355 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.505472258772961, 'Total loss': 0.505472258772961} | train loss {'Reaction outcome loss': 0.4954787308787122, 'Total loss': 0.4954787308787122}
2022-11-28 04:11:33,355 INFO:     Found new best model at epoch 6
2022-11-28 04:11:33,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:33,356 INFO:     Epoch: 7
2022-11-28 04:11:34,003 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5204139362240947, 'Total loss': 0.5204139362240947} | train loss {'Reaction outcome loss': 0.4939002032878468, 'Total loss': 0.4939002032878468}
2022-11-28 04:11:34,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:34,003 INFO:     Epoch: 8
2022-11-28 04:11:34,652 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5095982142659121, 'Total loss': 0.5095982142659121} | train loss {'Reaction outcome loss': 0.48823386936643975, 'Total loss': 0.48823386936643975}
2022-11-28 04:11:34,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:34,652 INFO:     Epoch: 9
2022-11-28 04:11:35,303 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5270339610964753, 'Total loss': 0.5270339610964753} | train loss {'Reaction outcome loss': 0.4839480071646686, 'Total loss': 0.4839480071646686}
2022-11-28 04:11:35,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:35,303 INFO:     Epoch: 10
2022-11-28 04:11:35,952 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5230042130448097, 'Total loss': 0.5230042130448097} | train loss {'Reaction outcome loss': 0.4761472305152642, 'Total loss': 0.4761472305152642}
2022-11-28 04:11:35,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:35,952 INFO:     Epoch: 11
2022-11-28 04:11:36,599 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5188654307709184, 'Total loss': 0.5188654307709184} | train loss {'Reaction outcome loss': 0.49505423990542013, 'Total loss': 0.49505423990542013}
2022-11-28 04:11:36,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:36,599 INFO:     Epoch: 12
2022-11-28 04:11:37,250 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4969716363174971, 'Total loss': 0.4969716363174971} | train loss {'Reaction outcome loss': 0.4807715874027323, 'Total loss': 0.4807715874027323}
2022-11-28 04:11:37,251 INFO:     Found new best model at epoch 12
2022-11-28 04:11:37,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:37,251 INFO:     Epoch: 13
2022-11-28 04:11:37,907 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.548455476067787, 'Total loss': 0.548455476067787} | train loss {'Reaction outcome loss': 0.4651818255828732, 'Total loss': 0.4651818255828732}
2022-11-28 04:11:37,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:37,908 INFO:     Epoch: 14
2022-11-28 04:11:38,559 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49364321557588353, 'Total loss': 0.49364321557588353} | train loss {'Reaction outcome loss': 0.478508506169535, 'Total loss': 0.478508506169535}
2022-11-28 04:11:38,560 INFO:     Found new best model at epoch 14
2022-11-28 04:11:38,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:38,560 INFO:     Epoch: 15
2022-11-28 04:11:39,210 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4817620259384776, 'Total loss': 0.4817620259384776} | train loss {'Reaction outcome loss': 0.47777509278475994, 'Total loss': 0.47777509278475994}
2022-11-28 04:11:39,211 INFO:     Found new best model at epoch 15
2022-11-28 04:11:39,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:39,211 INFO:     Epoch: 16
2022-11-28 04:11:39,862 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5175248578537343, 'Total loss': 0.5175248578537343} | train loss {'Reaction outcome loss': 0.47523382486997806, 'Total loss': 0.47523382486997806}
2022-11-28 04:11:39,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:39,862 INFO:     Epoch: 17
2022-11-28 04:11:40,510 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4598300256008326, 'Total loss': 0.4598300256008326} | train loss {'Reaction outcome loss': 0.4655344644446432, 'Total loss': 0.4655344644446432}
2022-11-28 04:11:40,510 INFO:     Found new best model at epoch 17
2022-11-28 04:11:40,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:40,511 INFO:     Epoch: 18
2022-11-28 04:11:41,157 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5054681089728378, 'Total loss': 0.5054681089728378} | train loss {'Reaction outcome loss': 0.468206937237041, 'Total loss': 0.468206937237041}
2022-11-28 04:11:41,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:41,157 INFO:     Epoch: 19
2022-11-28 04:11:41,800 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48949536819790684, 'Total loss': 0.48949536819790684} | train loss {'Reaction outcome loss': 0.4633108321040746, 'Total loss': 0.4633108321040746}
2022-11-28 04:11:41,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:41,800 INFO:     Epoch: 20
2022-11-28 04:11:42,447 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47185514174228493, 'Total loss': 0.47185514174228493} | train loss {'Reaction outcome loss': 0.46612151568073307, 'Total loss': 0.46612151568073307}
2022-11-28 04:11:42,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:42,447 INFO:     Epoch: 21
2022-11-28 04:11:43,093 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48812314937281054, 'Total loss': 0.48812314937281054} | train loss {'Reaction outcome loss': 0.4637759827046728, 'Total loss': 0.4637759827046728}
2022-11-28 04:11:43,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:43,093 INFO:     Epoch: 22
2022-11-28 04:11:43,740 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5159945446391438, 'Total loss': 0.5159945446391438} | train loss {'Reaction outcome loss': 0.4629707061704785, 'Total loss': 0.4629707061704785}
2022-11-28 04:11:43,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:43,740 INFO:     Epoch: 23
2022-11-28 04:11:44,384 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5531405747629875, 'Total loss': 0.5531405747629875} | train loss {'Reaction outcome loss': 0.4638982166846593, 'Total loss': 0.4638982166846593}
2022-11-28 04:11:44,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:44,384 INFO:     Epoch: 24
2022-11-28 04:11:45,033 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4841848715793255, 'Total loss': 0.4841848715793255} | train loss {'Reaction outcome loss': 0.4673983898673038, 'Total loss': 0.4673983898673038}
2022-11-28 04:11:45,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:45,033 INFO:     Epoch: 25
2022-11-28 04:11:45,681 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5306428885737131, 'Total loss': 0.5306428885737131} | train loss {'Reaction outcome loss': 0.45152897433734235, 'Total loss': 0.45152897433734235}
2022-11-28 04:11:45,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:45,681 INFO:     Epoch: 26
2022-11-28 04:11:46,329 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49350000398103583, 'Total loss': 0.49350000398103583} | train loss {'Reaction outcome loss': 0.4540769891054542, 'Total loss': 0.4540769891054542}
2022-11-28 04:11:46,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:46,329 INFO:     Epoch: 27
2022-11-28 04:11:46,976 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5097200350705967, 'Total loss': 0.5097200350705967} | train loss {'Reaction outcome loss': 0.46378267467512513, 'Total loss': 0.46378267467512513}
2022-11-28 04:11:46,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:46,976 INFO:     Epoch: 28
2022-11-28 04:11:47,625 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47889715086582096, 'Total loss': 0.47889715086582096} | train loss {'Reaction outcome loss': 0.46173454814977605, 'Total loss': 0.46173454814977605}
2022-11-28 04:11:47,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:47,625 INFO:     Epoch: 29
2022-11-28 04:11:48,274 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.540842603112376, 'Total loss': 0.540842603112376} | train loss {'Reaction outcome loss': 0.4551219782588904, 'Total loss': 0.4551219782588904}
2022-11-28 04:11:48,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:48,275 INFO:     Epoch: 30
2022-11-28 04:11:48,918 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4815939557413722, 'Total loss': 0.4815939557413722} | train loss {'Reaction outcome loss': 0.4500045059517087, 'Total loss': 0.4500045059517087}
2022-11-28 04:11:48,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:48,918 INFO:     Epoch: 31
2022-11-28 04:11:49,564 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4692626259354658, 'Total loss': 0.4692626259354658} | train loss {'Reaction outcome loss': 0.46004919217201906, 'Total loss': 0.46004919217201906}
2022-11-28 04:11:49,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:49,565 INFO:     Epoch: 32
2022-11-28 04:11:50,215 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5055019657972247, 'Total loss': 0.5055019657972247} | train loss {'Reaction outcome loss': 0.45497295119389586, 'Total loss': 0.45497295119389586}
2022-11-28 04:11:50,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:50,215 INFO:     Epoch: 33
2022-11-28 04:11:50,863 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4965531683938448, 'Total loss': 0.4965531683938448} | train loss {'Reaction outcome loss': 0.4656950749855473, 'Total loss': 0.4656950749855473}
2022-11-28 04:11:50,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:50,863 INFO:     Epoch: 34
2022-11-28 04:11:51,507 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4849887032841527, 'Total loss': 0.4849887032841527} | train loss {'Reaction outcome loss': 0.45931925370124144, 'Total loss': 0.45931925370124144}
2022-11-28 04:11:51,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:51,507 INFO:     Epoch: 35
2022-11-28 04:11:52,153 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5355209167613539, 'Total loss': 0.5355209167613539} | train loss {'Reaction outcome loss': 0.4616380555271612, 'Total loss': 0.4616380555271612}
2022-11-28 04:11:52,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:52,153 INFO:     Epoch: 36
2022-11-28 04:11:52,798 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5091829175172851, 'Total loss': 0.5091829175172851} | train loss {'Reaction outcome loss': 0.46483618579038377, 'Total loss': 0.46483618579038377}
2022-11-28 04:11:52,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:52,798 INFO:     Epoch: 37
2022-11-28 04:11:53,444 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4861142143260601, 'Total loss': 0.4861142143260601} | train loss {'Reaction outcome loss': 0.45436472086994734, 'Total loss': 0.45436472086994734}
2022-11-28 04:11:53,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:53,444 INFO:     Epoch: 38
2022-11-28 04:11:54,093 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45569435697655347, 'Total loss': 0.45569435697655347} | train loss {'Reaction outcome loss': 0.45515262911962384, 'Total loss': 0.45515262911962384}
2022-11-28 04:11:54,093 INFO:     Found new best model at epoch 38
2022-11-28 04:11:54,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:54,094 INFO:     Epoch: 39
2022-11-28 04:11:54,740 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46181836654973585, 'Total loss': 0.46181836654973585} | train loss {'Reaction outcome loss': 0.4510682237491686, 'Total loss': 0.4510682237491686}
2022-11-28 04:11:54,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:54,740 INFO:     Epoch: 40
2022-11-28 04:11:55,386 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5124778037154397, 'Total loss': 0.5124778037154397} | train loss {'Reaction outcome loss': 0.45649751950315975, 'Total loss': 0.45649751950315975}
2022-11-28 04:11:55,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:55,386 INFO:     Epoch: 41
2022-11-28 04:11:56,032 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47844610241956487, 'Total loss': 0.47844610241956487} | train loss {'Reaction outcome loss': 0.4561648819856192, 'Total loss': 0.4561648819856192}
2022-11-28 04:11:56,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:56,032 INFO:     Epoch: 42
2022-11-28 04:11:56,681 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4895522421182588, 'Total loss': 0.4895522421182588} | train loss {'Reaction outcome loss': 0.4586647807202712, 'Total loss': 0.4586647807202712}
2022-11-28 04:11:56,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:56,681 INFO:     Epoch: 43
2022-11-28 04:11:57,330 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47658723211565684, 'Total loss': 0.47658723211565684} | train loss {'Reaction outcome loss': 0.44799667069450816, 'Total loss': 0.44799667069450816}
2022-11-28 04:11:57,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:57,330 INFO:     Epoch: 44
2022-11-28 04:11:57,977 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49224987972614376, 'Total loss': 0.49224987972614376} | train loss {'Reaction outcome loss': 0.4566181324146412, 'Total loss': 0.4566181324146412}
2022-11-28 04:11:57,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:57,977 INFO:     Epoch: 45
2022-11-28 04:11:58,626 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4682368275731109, 'Total loss': 0.4682368275731109} | train loss {'Reaction outcome loss': 0.4510531740056144, 'Total loss': 0.4510531740056144}
2022-11-28 04:11:58,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:58,627 INFO:     Epoch: 46
2022-11-28 04:11:59,273 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46635504656059795, 'Total loss': 0.46635504656059795} | train loss {'Reaction outcome loss': 0.4486113256265106, 'Total loss': 0.4486113256265106}
2022-11-28 04:11:59,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:59,274 INFO:     Epoch: 47
2022-11-28 04:11:59,925 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.480588577514471, 'Total loss': 0.480588577514471} | train loss {'Reaction outcome loss': 0.4517363488306234, 'Total loss': 0.4517363488306234}
2022-11-28 04:11:59,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:11:59,925 INFO:     Epoch: 48
2022-11-28 04:12:00,574 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4696609977372857, 'Total loss': 0.4696609977372857} | train loss {'Reaction outcome loss': 0.4510056245228881, 'Total loss': 0.4510056245228881}
2022-11-28 04:12:00,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:00,575 INFO:     Epoch: 49
2022-11-28 04:12:01,220 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4826452191485915, 'Total loss': 0.4826452191485915} | train loss {'Reaction outcome loss': 0.44546559848535205, 'Total loss': 0.44546559848535205}
2022-11-28 04:12:01,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:01,221 INFO:     Epoch: 50
2022-11-28 04:12:01,869 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49714730368104093, 'Total loss': 0.49714730368104093} | train loss {'Reaction outcome loss': 0.4490211179840221, 'Total loss': 0.4490211179840221}
2022-11-28 04:12:01,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:01,869 INFO:     Epoch: 51
2022-11-28 04:12:02,519 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4967220286990321, 'Total loss': 0.4967220286990321} | train loss {'Reaction outcome loss': 0.4493576315204793, 'Total loss': 0.4493576315204793}
2022-11-28 04:12:02,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:02,519 INFO:     Epoch: 52
2022-11-28 04:12:03,167 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5246538904517196, 'Total loss': 0.5246538904517196} | train loss {'Reaction outcome loss': 0.45877757460001567, 'Total loss': 0.45877757460001567}
2022-11-28 04:12:03,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:03,168 INFO:     Epoch: 53
2022-11-28 04:12:03,809 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4920077608075253, 'Total loss': 0.4920077608075253} | train loss {'Reaction outcome loss': 0.4463609445978094, 'Total loss': 0.4463609445978094}
2022-11-28 04:12:03,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:03,810 INFO:     Epoch: 54
2022-11-28 04:12:04,456 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45956891983054404, 'Total loss': 0.45956891983054404} | train loss {'Reaction outcome loss': 0.45384537517533874, 'Total loss': 0.45384537517533874}
2022-11-28 04:12:04,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:04,456 INFO:     Epoch: 55
2022-11-28 04:12:05,105 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5273413623488227, 'Total loss': 0.5273413623488227} | train loss {'Reaction outcome loss': 0.45374700690738456, 'Total loss': 0.45374700690738456}
2022-11-28 04:12:05,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:05,105 INFO:     Epoch: 56
2022-11-28 04:12:05,750 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46618786211623703, 'Total loss': 0.46618786211623703} | train loss {'Reaction outcome loss': 0.45531597101884613, 'Total loss': 0.45531597101884613}
2022-11-28 04:12:05,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:05,750 INFO:     Epoch: 57
2022-11-28 04:12:06,398 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45035743158917096, 'Total loss': 0.45035743158917096} | train loss {'Reaction outcome loss': 0.44775840719786203, 'Total loss': 0.44775840719786203}
2022-11-28 04:12:06,398 INFO:     Found new best model at epoch 57
2022-11-28 04:12:06,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:06,399 INFO:     Epoch: 58
2022-11-28 04:12:07,049 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5148175996403361, 'Total loss': 0.5148175996403361} | train loss {'Reaction outcome loss': 0.45051702869281846, 'Total loss': 0.45051702869281846}
2022-11-28 04:12:07,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:07,049 INFO:     Epoch: 59
2022-11-28 04:12:07,698 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45905936318774554, 'Total loss': 0.45905936318774554} | train loss {'Reaction outcome loss': 0.45089971936411327, 'Total loss': 0.45089971936411327}
2022-11-28 04:12:07,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:07,699 INFO:     Epoch: 60
2022-11-28 04:12:08,345 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44286397446033565, 'Total loss': 0.44286397446033565} | train loss {'Reaction outcome loss': 0.4482509737274774, 'Total loss': 0.4482509737274774}
2022-11-28 04:12:08,345 INFO:     Found new best model at epoch 60
2022-11-28 04:12:08,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:08,346 INFO:     Epoch: 61
2022-11-28 04:12:08,993 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45029379462086877, 'Total loss': 0.45029379462086877} | train loss {'Reaction outcome loss': 0.44517423270783796, 'Total loss': 0.44517423270783796}
2022-11-28 04:12:08,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:08,993 INFO:     Epoch: 62
2022-11-28 04:12:09,642 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4618472675251406, 'Total loss': 0.4618472675251406} | train loss {'Reaction outcome loss': 0.44327353109670764, 'Total loss': 0.44327353109670764}
2022-11-28 04:12:09,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:09,643 INFO:     Epoch: 63
2022-11-28 04:12:10,290 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.512144403748734, 'Total loss': 0.512144403748734} | train loss {'Reaction outcome loss': 0.44811715311351624, 'Total loss': 0.44811715311351624}
2022-11-28 04:12:10,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:10,291 INFO:     Epoch: 64
2022-11-28 04:12:10,938 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45971348847067633, 'Total loss': 0.45971348847067633} | train loss {'Reaction outcome loss': 0.44488278144794235, 'Total loss': 0.44488278144794235}
2022-11-28 04:12:10,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:10,939 INFO:     Epoch: 65
2022-11-28 04:12:11,590 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4870416327964428, 'Total loss': 0.4870416327964428} | train loss {'Reaction outcome loss': 0.4439085076865836, 'Total loss': 0.4439085076865836}
2022-11-28 04:12:11,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:11,591 INFO:     Epoch: 66
2022-11-28 04:12:12,240 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4763065683980321, 'Total loss': 0.4763065683980321} | train loss {'Reaction outcome loss': 0.44364283534357085, 'Total loss': 0.44364283534357085}
2022-11-28 04:12:12,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:12,240 INFO:     Epoch: 67
2022-11-28 04:12:12,889 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5042227527429891, 'Total loss': 0.5042227527429891} | train loss {'Reaction outcome loss': 0.4509907260598469, 'Total loss': 0.4509907260598469}
2022-11-28 04:12:12,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:12,889 INFO:     Epoch: 68
2022-11-28 04:12:13,541 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4560582935810089, 'Total loss': 0.4560582935810089} | train loss {'Reaction outcome loss': 0.4468379554802498, 'Total loss': 0.4468379554802498}
2022-11-28 04:12:13,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:13,541 INFO:     Epoch: 69
2022-11-28 04:12:14,188 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4879540953525277, 'Total loss': 0.4879540953525277} | train loss {'Reaction outcome loss': 0.44240173823181, 'Total loss': 0.44240173823181}
2022-11-28 04:12:14,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:14,189 INFO:     Epoch: 70
2022-11-28 04:12:14,836 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4678276208944099, 'Total loss': 0.4678276208944099} | train loss {'Reaction outcome loss': 0.438839628694602, 'Total loss': 0.438839628694602}
2022-11-28 04:12:14,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:14,836 INFO:     Epoch: 71
2022-11-28 04:12:15,480 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4591960563909176, 'Total loss': 0.4591960563909176} | train loss {'Reaction outcome loss': 0.45524776405022466, 'Total loss': 0.45524776405022466}
2022-11-28 04:12:15,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:15,480 INFO:     Epoch: 72
2022-11-28 04:12:16,130 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4803131333617277, 'Total loss': 0.4803131333617277} | train loss {'Reaction outcome loss': 0.4471408460488535, 'Total loss': 0.4471408460488535}
2022-11-28 04:12:16,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:16,130 INFO:     Epoch: 73
2022-11-28 04:12:16,785 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4667336673930634, 'Total loss': 0.4667336673930634} | train loss {'Reaction outcome loss': 0.44638971941461286, 'Total loss': 0.44638971941461286}
2022-11-28 04:12:16,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:16,785 INFO:     Epoch: 74
2022-11-28 04:12:17,433 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4903017285951348, 'Total loss': 0.4903017285951348} | train loss {'Reaction outcome loss': 0.45126515154730634, 'Total loss': 0.45126515154730634}
2022-11-28 04:12:17,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:17,433 INFO:     Epoch: 75
2022-11-28 04:12:18,082 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4753235204275264, 'Total loss': 0.4753235204275264} | train loss {'Reaction outcome loss': 0.4475405998681308, 'Total loss': 0.4475405998681308}
2022-11-28 04:12:18,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:18,082 INFO:     Epoch: 76
2022-11-28 04:12:18,730 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47053453949994817, 'Total loss': 0.47053453949994817} | train loss {'Reaction outcome loss': 0.4440614462450699, 'Total loss': 0.4440614462450699}
2022-11-28 04:12:18,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:18,731 INFO:     Epoch: 77
2022-11-28 04:12:19,378 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4634029549914737, 'Total loss': 0.4634029549914737} | train loss {'Reaction outcome loss': 0.4537762379879324, 'Total loss': 0.4537762379879324}
2022-11-28 04:12:19,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:19,379 INFO:     Epoch: 78
2022-11-28 04:12:20,025 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4656969960345778, 'Total loss': 0.4656969960345778} | train loss {'Reaction outcome loss': 0.4399913264890757, 'Total loss': 0.4399913264890757}
2022-11-28 04:12:20,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:20,025 INFO:     Epoch: 79
2022-11-28 04:12:20,672 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47301883614340495, 'Total loss': 0.47301883614340495} | train loss {'Reaction outcome loss': 0.4435485559113232, 'Total loss': 0.4435485559113232}
2022-11-28 04:12:20,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:20,672 INFO:     Epoch: 80
2022-11-28 04:12:21,316 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47693754420724027, 'Total loss': 0.47693754420724027} | train loss {'Reaction outcome loss': 0.4475157188535227, 'Total loss': 0.4475157188535227}
2022-11-28 04:12:21,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:21,317 INFO:     Epoch: 81
2022-11-28 04:12:21,963 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45218095443276474, 'Total loss': 0.45218095443276474} | train loss {'Reaction outcome loss': 0.4530185137265994, 'Total loss': 0.4530185137265994}
2022-11-28 04:12:21,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:21,963 INFO:     Epoch: 82
2022-11-28 04:12:22,607 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5156165104965831, 'Total loss': 0.5156165104965831} | train loss {'Reaction outcome loss': 0.4467216812902027, 'Total loss': 0.4467216812902027}
2022-11-28 04:12:22,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:22,608 INFO:     Epoch: 83
2022-11-28 04:12:23,256 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4795957384414451, 'Total loss': 0.4795957384414451} | train loss {'Reaction outcome loss': 0.4416595606033694, 'Total loss': 0.4416595606033694}
2022-11-28 04:12:23,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:23,256 INFO:     Epoch: 84
2022-11-28 04:12:23,904 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5013886128747186, 'Total loss': 0.5013886128747186} | train loss {'Reaction outcome loss': 0.44621166470364776, 'Total loss': 0.44621166470364776}
2022-11-28 04:12:23,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:23,904 INFO:     Epoch: 85
2022-11-28 04:12:24,552 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4690684908351233, 'Total loss': 0.4690684908351233} | train loss {'Reaction outcome loss': 0.43628493215076225, 'Total loss': 0.43628493215076225}
2022-11-28 04:12:24,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:24,552 INFO:     Epoch: 86
2022-11-28 04:12:25,197 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5280905767928722, 'Total loss': 0.5280905767928722} | train loss {'Reaction outcome loss': 0.4382638381832421, 'Total loss': 0.4382638381832421}
2022-11-28 04:12:25,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:25,197 INFO:     Epoch: 87
2022-11-28 04:12:25,842 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4680457531019699, 'Total loss': 0.4680457531019699} | train loss {'Reaction outcome loss': 0.4538638971040769, 'Total loss': 0.4538638971040769}
2022-11-28 04:12:25,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:25,842 INFO:     Epoch: 88
2022-11-28 04:12:26,487 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4832466709059338, 'Total loss': 0.4832466709059338} | train loss {'Reaction outcome loss': 0.4438417207434344, 'Total loss': 0.4438417207434344}
2022-11-28 04:12:26,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:26,487 INFO:     Epoch: 89
2022-11-28 04:12:27,131 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5326110360234283, 'Total loss': 0.5326110360234283} | train loss {'Reaction outcome loss': 0.4463976914132083, 'Total loss': 0.4463976914132083}
2022-11-28 04:12:27,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:27,132 INFO:     Epoch: 90
2022-11-28 04:12:27,775 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5083105824021406, 'Total loss': 0.5083105824021406} | train loss {'Reaction outcome loss': 0.450914939980448, 'Total loss': 0.450914939980448}
2022-11-28 04:12:27,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:27,776 INFO:     Epoch: 91
2022-11-28 04:12:28,423 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4760596558105114, 'Total loss': 0.4760596558105114} | train loss {'Reaction outcome loss': 0.44758805227868353, 'Total loss': 0.44758805227868353}
2022-11-28 04:12:28,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:28,423 INFO:     Epoch: 92
2022-11-28 04:12:29,070 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49608670902806656, 'Total loss': 0.49608670902806656} | train loss {'Reaction outcome loss': 0.44868706399766506, 'Total loss': 0.44868706399766506}
2022-11-28 04:12:29,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:29,071 INFO:     Epoch: 93
2022-11-28 04:12:29,719 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4604991934327192, 'Total loss': 0.4604991934327192} | train loss {'Reaction outcome loss': 0.446889250213472, 'Total loss': 0.446889250213472}
2022-11-28 04:12:29,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:29,719 INFO:     Epoch: 94
2022-11-28 04:12:30,371 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47580123224923776, 'Total loss': 0.47580123224923776} | train loss {'Reaction outcome loss': 0.4439703961336073, 'Total loss': 0.4439703961336073}
2022-11-28 04:12:30,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:30,371 INFO:     Epoch: 95
2022-11-28 04:12:31,020 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4561682471702265, 'Total loss': 0.4561682471702265} | train loss {'Reaction outcome loss': 0.4558047480543945, 'Total loss': 0.4558047480543945}
2022-11-28 04:12:31,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:31,020 INFO:     Epoch: 96
2022-11-28 04:12:31,666 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5047663131425547, 'Total loss': 0.5047663131425547} | train loss {'Reaction outcome loss': 0.44820292527047695, 'Total loss': 0.44820292527047695}
2022-11-28 04:12:31,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:31,666 INFO:     Epoch: 97
2022-11-28 04:12:32,313 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4672190696001053, 'Total loss': 0.4672190696001053} | train loss {'Reaction outcome loss': 0.44856084705380256, 'Total loss': 0.44856084705380256}
2022-11-28 04:12:32,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:32,313 INFO:     Epoch: 98
2022-11-28 04:12:32,962 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49521211898604106, 'Total loss': 0.49521211898604106} | train loss {'Reaction outcome loss': 0.45056196084483663, 'Total loss': 0.45056196084483663}
2022-11-28 04:12:32,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:32,963 INFO:     Epoch: 99
2022-11-28 04:12:33,611 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4637080462172974, 'Total loss': 0.4637080462172974} | train loss {'Reaction outcome loss': 0.44170287239208145, 'Total loss': 0.44170287239208145}
2022-11-28 04:12:33,611 INFO:     Best model found after epoch 61 of 100.
2022-11-28 04:12:33,612 INFO:   Done with stage: TRAINING
2022-11-28 04:12:33,612 INFO:   Starting stage: EVALUATION
2022-11-28 04:12:33,747 INFO:   Done with stage: EVALUATION
2022-11-28 04:12:33,747 INFO:   Leaving out SEQ value Fold_2
2022-11-28 04:12:33,760 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:12:33,760 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:12:34,396 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:12:34,396 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:12:34,464 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:12:34,464 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:12:34,464 INFO:     No hyperparam tuning for this model
2022-11-28 04:12:34,464 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:12:34,464 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:12:34,465 INFO:     None feature selector for col prot
2022-11-28 04:12:34,465 INFO:     None feature selector for col prot
2022-11-28 04:12:34,465 INFO:     None feature selector for col prot
2022-11-28 04:12:34,466 INFO:     None feature selector for col chem
2022-11-28 04:12:34,466 INFO:     None feature selector for col chem
2022-11-28 04:12:34,466 INFO:     None feature selector for col chem
2022-11-28 04:12:34,466 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:12:34,466 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:12:34,467 INFO:     Number of params in model 169651
2022-11-28 04:12:34,470 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:12:34,470 INFO:   Starting stage: TRAINING
2022-11-28 04:12:34,521 INFO:     Val loss before train {'Reaction outcome loss': 0.9821829118511893, 'Total loss': 0.9821829118511893}
2022-11-28 04:12:34,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:34,522 INFO:     Epoch: 0
2022-11-28 04:12:35,180 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6379354934800755, 'Total loss': 0.6379354934800755} | train loss {'Reaction outcome loss': 0.6933557535578244, 'Total loss': 0.6933557535578244}
2022-11-28 04:12:35,180 INFO:     Found new best model at epoch 0
2022-11-28 04:12:35,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:35,181 INFO:     Epoch: 1
2022-11-28 04:12:35,836 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5426050438122316, 'Total loss': 0.5426050438122316} | train loss {'Reaction outcome loss': 0.5865733877487993, 'Total loss': 0.5865733877487993}
2022-11-28 04:12:35,836 INFO:     Found new best model at epoch 1
2022-11-28 04:12:35,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:35,837 INFO:     Epoch: 2
2022-11-28 04:12:36,496 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5183852382681586, 'Total loss': 0.5183852382681586} | train loss {'Reaction outcome loss': 0.5481131114065647, 'Total loss': 0.5481131114065647}
2022-11-28 04:12:36,496 INFO:     Found new best model at epoch 2
2022-11-28 04:12:36,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:36,497 INFO:     Epoch: 3
2022-11-28 04:12:37,156 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5329529903829098, 'Total loss': 0.5329529903829098} | train loss {'Reaction outcome loss': 0.5256061479147629, 'Total loss': 0.5256061479147629}
2022-11-28 04:12:37,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:37,156 INFO:     Epoch: 4
2022-11-28 04:12:37,817 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5282117304476824, 'Total loss': 0.5282117304476824} | train loss {'Reaction outcome loss': 0.5169154592273146, 'Total loss': 0.5169154592273146}
2022-11-28 04:12:37,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:37,817 INFO:     Epoch: 5
2022-11-28 04:12:38,476 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5414576994424517, 'Total loss': 0.5414576994424517} | train loss {'Reaction outcome loss': 0.505337648365179, 'Total loss': 0.505337648365179}
2022-11-28 04:12:38,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:38,476 INFO:     Epoch: 6
2022-11-28 04:12:39,138 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4979218014261939, 'Total loss': 0.4979218014261939} | train loss {'Reaction outcome loss': 0.5157281357327453, 'Total loss': 0.5157281357327453}
2022-11-28 04:12:39,139 INFO:     Found new best model at epoch 6
2022-11-28 04:12:39,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:39,140 INFO:     Epoch: 7
2022-11-28 04:12:39,798 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5045866099270907, 'Total loss': 0.5045866099270907} | train loss {'Reaction outcome loss': 0.4953468372283677, 'Total loss': 0.4953468372283677}
2022-11-28 04:12:39,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:39,798 INFO:     Epoch: 8
2022-11-28 04:12:40,457 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.506143272261728, 'Total loss': 0.506143272261728} | train loss {'Reaction outcome loss': 0.4917117963254693, 'Total loss': 0.4917117963254693}
2022-11-28 04:12:40,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:40,457 INFO:     Epoch: 9
2022-11-28 04:12:41,119 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4855264858766036, 'Total loss': 0.4855264858766036} | train loss {'Reaction outcome loss': 0.497921941734036, 'Total loss': 0.497921941734036}
2022-11-28 04:12:41,119 INFO:     Found new best model at epoch 9
2022-11-28 04:12:41,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:41,120 INFO:     Epoch: 10
2022-11-28 04:12:41,776 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4725082133981315, 'Total loss': 0.4725082133981315} | train loss {'Reaction outcome loss': 0.48777189380244207, 'Total loss': 0.48777189380244207}
2022-11-28 04:12:41,777 INFO:     Found new best model at epoch 10
2022-11-28 04:12:41,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:41,777 INFO:     Epoch: 11
2022-11-28 04:12:42,435 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4850217747417363, 'Total loss': 0.4850217747417363} | train loss {'Reaction outcome loss': 0.4789316554413354, 'Total loss': 0.4789316554413354}
2022-11-28 04:12:42,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:42,436 INFO:     Epoch: 12
2022-11-28 04:12:43,097 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5077713037079031, 'Total loss': 0.5077713037079031} | train loss {'Reaction outcome loss': 0.47777205443213344, 'Total loss': 0.47777205443213344}
2022-11-28 04:12:43,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:43,097 INFO:     Epoch: 13
2022-11-28 04:12:43,753 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47532192820852454, 'Total loss': 0.47532192820852454} | train loss {'Reaction outcome loss': 0.4727787093413986, 'Total loss': 0.4727787093413986}
2022-11-28 04:12:43,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:43,753 INFO:     Epoch: 14
2022-11-28 04:12:44,409 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4519496565176682, 'Total loss': 0.4519496565176682} | train loss {'Reaction outcome loss': 0.4842636341508101, 'Total loss': 0.4842636341508101}
2022-11-28 04:12:44,409 INFO:     Found new best model at epoch 14
2022-11-28 04:12:44,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:44,410 INFO:     Epoch: 15
2022-11-28 04:12:45,067 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5001256953586232, 'Total loss': 0.5001256953586232} | train loss {'Reaction outcome loss': 0.4755247515656416, 'Total loss': 0.4755247515656416}
2022-11-28 04:12:45,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:45,067 INFO:     Epoch: 16
2022-11-28 04:12:45,725 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5082509365271438, 'Total loss': 0.5082509365271438} | train loss {'Reaction outcome loss': 0.4764834683735361, 'Total loss': 0.4764834683735361}
2022-11-28 04:12:45,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:45,726 INFO:     Epoch: 17
2022-11-28 04:12:46,382 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4707007919522849, 'Total loss': 0.4707007919522849} | train loss {'Reaction outcome loss': 0.4872604643827991, 'Total loss': 0.4872604643827991}
2022-11-28 04:12:46,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:46,383 INFO:     Epoch: 18
2022-11-28 04:12:47,041 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45912302895025775, 'Total loss': 0.45912302895025775} | train loss {'Reaction outcome loss': 0.47237363913914693, 'Total loss': 0.47237363913914693}
2022-11-28 04:12:47,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:47,042 INFO:     Epoch: 19
2022-11-28 04:12:47,700 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4910646737976508, 'Total loss': 0.4910646737976508} | train loss {'Reaction outcome loss': 0.469448167664802, 'Total loss': 0.469448167664802}
2022-11-28 04:12:47,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:47,701 INFO:     Epoch: 20
2022-11-28 04:12:48,359 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48874637281352823, 'Total loss': 0.48874637281352823} | train loss {'Reaction outcome loss': 0.47379100485610576, 'Total loss': 0.47379100485610576}
2022-11-28 04:12:48,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:48,359 INFO:     Epoch: 21
2022-11-28 04:12:49,015 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5009148913350973, 'Total loss': 0.5009148913350973} | train loss {'Reaction outcome loss': 0.4783939095402536, 'Total loss': 0.4783939095402536}
2022-11-28 04:12:49,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:49,016 INFO:     Epoch: 22
2022-11-28 04:12:49,670 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4797362041744319, 'Total loss': 0.4797362041744319} | train loss {'Reaction outcome loss': 0.462736865286885, 'Total loss': 0.462736865286885}
2022-11-28 04:12:49,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:49,670 INFO:     Epoch: 23
2022-11-28 04:12:50,325 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5428369834341786, 'Total loss': 0.5428369834341786} | train loss {'Reaction outcome loss': 0.46200717285818416, 'Total loss': 0.46200717285818416}
2022-11-28 04:12:50,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:50,325 INFO:     Epoch: 24
2022-11-28 04:12:50,981 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4880447099831971, 'Total loss': 0.4880447099831971} | train loss {'Reaction outcome loss': 0.4684971825932322, 'Total loss': 0.4684971825932322}
2022-11-28 04:12:50,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:50,981 INFO:     Epoch: 25
2022-11-28 04:12:51,637 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4760661267421462, 'Total loss': 0.4760661267421462} | train loss {'Reaction outcome loss': 0.45760856160087143, 'Total loss': 0.45760856160087143}
2022-11-28 04:12:51,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:51,638 INFO:     Epoch: 26
2022-11-28 04:12:52,294 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.51143298975446, 'Total loss': 0.51143298975446} | train loss {'Reaction outcome loss': 0.45844180869911366, 'Total loss': 0.45844180869911366}
2022-11-28 04:12:52,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:52,295 INFO:     Epoch: 27
2022-11-28 04:12:52,954 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46031181277199223, 'Total loss': 0.46031181277199223} | train loss {'Reaction outcome loss': 0.4705896628530402, 'Total loss': 0.4705896628530402}
2022-11-28 04:12:52,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:52,954 INFO:     Epoch: 28
2022-11-28 04:12:53,612 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49781466952779074, 'Total loss': 0.49781466952779074} | train loss {'Reaction outcome loss': 0.46574539133170356, 'Total loss': 0.46574539133170356}
2022-11-28 04:12:53,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:53,612 INFO:     Epoch: 29
2022-11-28 04:12:54,271 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4592407542196187, 'Total loss': 0.4592407542196187} | train loss {'Reaction outcome loss': 0.46547216086493814, 'Total loss': 0.46547216086493814}
2022-11-28 04:12:54,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:54,271 INFO:     Epoch: 30
2022-11-28 04:12:54,925 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4991077655418353, 'Total loss': 0.4991077655418353} | train loss {'Reaction outcome loss': 0.4617917122044092, 'Total loss': 0.4617917122044092}
2022-11-28 04:12:54,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:54,925 INFO:     Epoch: 31
2022-11-28 04:12:55,579 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48216772824525833, 'Total loss': 0.48216772824525833} | train loss {'Reaction outcome loss': 0.4647194614053255, 'Total loss': 0.4647194614053255}
2022-11-28 04:12:55,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:55,579 INFO:     Epoch: 32
2022-11-28 04:12:56,232 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47401579875837674, 'Total loss': 0.47401579875837674} | train loss {'Reaction outcome loss': 0.4602439023162189, 'Total loss': 0.4602439023162189}
2022-11-28 04:12:56,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:56,232 INFO:     Epoch: 33
2022-11-28 04:12:56,885 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4478394521231001, 'Total loss': 0.4478394521231001} | train loss {'Reaction outcome loss': 0.4721395649950997, 'Total loss': 0.4721395649950997}
2022-11-28 04:12:56,885 INFO:     Found new best model at epoch 33
2022-11-28 04:12:56,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:56,886 INFO:     Epoch: 34
2022-11-28 04:12:57,548 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4637277173725041, 'Total loss': 0.4637277173725041} | train loss {'Reaction outcome loss': 0.46214449178683853, 'Total loss': 0.46214449178683853}
2022-11-28 04:12:57,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:57,548 INFO:     Epoch: 35
2022-11-28 04:12:58,201 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48795775357972493, 'Total loss': 0.48795775357972493} | train loss {'Reaction outcome loss': 0.46326201164770703, 'Total loss': 0.46326201164770703}
2022-11-28 04:12:58,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:58,202 INFO:     Epoch: 36
2022-11-28 04:12:58,857 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4740117016163739, 'Total loss': 0.4740117016163739} | train loss {'Reaction outcome loss': 0.4696602250038371, 'Total loss': 0.4696602250038371}
2022-11-28 04:12:58,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:58,857 INFO:     Epoch: 37
2022-11-28 04:12:59,511 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47740311615846376, 'Total loss': 0.47740311615846376} | train loss {'Reaction outcome loss': 0.4649263998636833, 'Total loss': 0.4649263998636833}
2022-11-28 04:12:59,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:12:59,511 INFO:     Epoch: 38
2022-11-28 04:13:00,165 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45510875569148496, 'Total loss': 0.45510875569148496} | train loss {'Reaction outcome loss': 0.46325352165550143, 'Total loss': 0.46325352165550143}
2022-11-28 04:13:00,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:00,165 INFO:     Epoch: 39
2022-11-28 04:13:00,818 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5243186015974391, 'Total loss': 0.5243186015974391} | train loss {'Reaction outcome loss': 0.4610200680581182, 'Total loss': 0.4610200680581182}
2022-11-28 04:13:00,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:00,818 INFO:     Epoch: 40
2022-11-28 04:13:01,479 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4477026818150824, 'Total loss': 0.4477026818150824} | train loss {'Reaction outcome loss': 0.46614289205325277, 'Total loss': 0.46614289205325277}
2022-11-28 04:13:01,479 INFO:     Found new best model at epoch 40
2022-11-28 04:13:01,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:01,480 INFO:     Epoch: 41
2022-11-28 04:13:02,139 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4629302329637788, 'Total loss': 0.4629302329637788} | train loss {'Reaction outcome loss': 0.4597575677792553, 'Total loss': 0.4597575677792553}
2022-11-28 04:13:02,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:02,139 INFO:     Epoch: 42
2022-11-28 04:13:02,795 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4962738345969807, 'Total loss': 0.4962738345969807} | train loss {'Reaction outcome loss': 0.4592418300689232, 'Total loss': 0.4592418300689232}
2022-11-28 04:13:02,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:02,795 INFO:     Epoch: 43
2022-11-28 04:13:03,451 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4607620117339221, 'Total loss': 0.4607620117339221} | train loss {'Reaction outcome loss': 0.46050145624861544, 'Total loss': 0.46050145624861544}
2022-11-28 04:13:03,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:03,451 INFO:     Epoch: 44
2022-11-28 04:13:04,106 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4496743841604753, 'Total loss': 0.4496743841604753} | train loss {'Reaction outcome loss': 0.46050466765151904, 'Total loss': 0.46050466765151904}
2022-11-28 04:13:04,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:04,107 INFO:     Epoch: 45
2022-11-28 04:13:04,764 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46612950651483104, 'Total loss': 0.46612950651483104} | train loss {'Reaction outcome loss': 0.4595154551298995, 'Total loss': 0.4595154551298995}
2022-11-28 04:13:04,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:04,764 INFO:     Epoch: 46
2022-11-28 04:13:05,417 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.485920287668705, 'Total loss': 0.485920287668705} | train loss {'Reaction outcome loss': 0.46375550366259416, 'Total loss': 0.46375550366259416}
2022-11-28 04:13:05,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:05,417 INFO:     Epoch: 47
2022-11-28 04:13:06,073 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4574283090504733, 'Total loss': 0.4574283090504733} | train loss {'Reaction outcome loss': 0.4505890787613054, 'Total loss': 0.4505890787613054}
2022-11-28 04:13:06,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:06,074 INFO:     Epoch: 48
2022-11-28 04:13:06,726 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4733302495019002, 'Total loss': 0.4733302495019002} | train loss {'Reaction outcome loss': 0.46749271229211137, 'Total loss': 0.46749271229211137}
2022-11-28 04:13:06,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:06,727 INFO:     Epoch: 49
2022-11-28 04:13:07,381 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46031532470475545, 'Total loss': 0.46031532470475545} | train loss {'Reaction outcome loss': 0.4570764953247931, 'Total loss': 0.4570764953247931}
2022-11-28 04:13:07,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:07,382 INFO:     Epoch: 50
2022-11-28 04:13:08,037 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45606052401390945, 'Total loss': 0.45606052401390945} | train loss {'Reaction outcome loss': 0.453260659730356, 'Total loss': 0.453260659730356}
2022-11-28 04:13:08,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:08,037 INFO:     Epoch: 51
2022-11-28 04:13:08,693 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44565012509172613, 'Total loss': 0.44565012509172613} | train loss {'Reaction outcome loss': 0.4654558595224672, 'Total loss': 0.4654558595224672}
2022-11-28 04:13:08,693 INFO:     Found new best model at epoch 51
2022-11-28 04:13:08,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:08,694 INFO:     Epoch: 52
2022-11-28 04:13:09,353 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4675921506502412, 'Total loss': 0.4675921506502412} | train loss {'Reaction outcome loss': 0.45475829801397766, 'Total loss': 0.45475829801397766}
2022-11-28 04:13:09,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:09,354 INFO:     Epoch: 53
2022-11-28 04:13:10,009 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4940431087531827, 'Total loss': 0.4940431087531827} | train loss {'Reaction outcome loss': 0.4546301844510955, 'Total loss': 0.4546301844510955}
2022-11-28 04:13:10,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:10,009 INFO:     Epoch: 54
2022-11-28 04:13:10,665 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4509643577039242, 'Total loss': 0.4509643577039242} | train loss {'Reaction outcome loss': 0.46380020121512144, 'Total loss': 0.46380020121512144}
2022-11-28 04:13:10,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:10,666 INFO:     Epoch: 55
2022-11-28 04:13:11,321 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49168816886164923, 'Total loss': 0.49168816886164923} | train loss {'Reaction outcome loss': 0.47548772442920006, 'Total loss': 0.47548772442920006}
2022-11-28 04:13:11,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:11,322 INFO:     Epoch: 56
2022-11-28 04:13:11,976 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4434054639529098, 'Total loss': 0.4434054639529098} | train loss {'Reaction outcome loss': 0.4619164839085297, 'Total loss': 0.4619164839085297}
2022-11-28 04:13:11,976 INFO:     Found new best model at epoch 56
2022-11-28 04:13:11,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:11,977 INFO:     Epoch: 57
2022-11-28 04:13:12,630 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43889403410933236, 'Total loss': 0.43889403410933236} | train loss {'Reaction outcome loss': 0.45805831141920705, 'Total loss': 0.45805831141920705}
2022-11-28 04:13:12,630 INFO:     Found new best model at epoch 57
2022-11-28 04:13:12,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:12,631 INFO:     Epoch: 58
2022-11-28 04:13:13,283 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4569642584432255, 'Total loss': 0.4569642584432255} | train loss {'Reaction outcome loss': 0.4637396240885924, 'Total loss': 0.4637396240885924}
2022-11-28 04:13:13,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:13,283 INFO:     Epoch: 59
2022-11-28 04:13:13,937 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5110376660119403, 'Total loss': 0.5110376660119403} | train loss {'Reaction outcome loss': 0.4608182358717629, 'Total loss': 0.4608182358717629}
2022-11-28 04:13:13,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:13,937 INFO:     Epoch: 60
2022-11-28 04:13:14,593 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46752793003212323, 'Total loss': 0.46752793003212323} | train loss {'Reaction outcome loss': 0.4653293352257385, 'Total loss': 0.4653293352257385}
2022-11-28 04:13:14,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:14,593 INFO:     Epoch: 61
2022-11-28 04:13:15,248 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5009064244275744, 'Total loss': 0.5009064244275744} | train loss {'Reaction outcome loss': 0.4663006732700325, 'Total loss': 0.4663006732700325}
2022-11-28 04:13:15,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:15,248 INFO:     Epoch: 62
2022-11-28 04:13:15,907 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4713110798461871, 'Total loss': 0.4713110798461871} | train loss {'Reaction outcome loss': 0.46473017992519655, 'Total loss': 0.46473017992519655}
2022-11-28 04:13:15,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:15,907 INFO:     Epoch: 63
2022-11-28 04:13:16,568 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43093969774517144, 'Total loss': 0.43093969774517144} | train loss {'Reaction outcome loss': 0.4630353271693504, 'Total loss': 0.4630353271693504}
2022-11-28 04:13:16,568 INFO:     Found new best model at epoch 63
2022-11-28 04:13:16,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:16,569 INFO:     Epoch: 64
2022-11-28 04:13:17,229 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4409276494248347, 'Total loss': 0.4409276494248347} | train loss {'Reaction outcome loss': 0.46104920329714594, 'Total loss': 0.46104920329714594}
2022-11-28 04:13:17,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:17,229 INFO:     Epoch: 65
2022-11-28 04:13:17,893 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4529066543010148, 'Total loss': 0.4529066543010148} | train loss {'Reaction outcome loss': 0.4607907839209927, 'Total loss': 0.4607907839209927}
2022-11-28 04:13:17,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:17,893 INFO:     Epoch: 66
2022-11-28 04:13:18,549 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4927365000952374, 'Total loss': 0.4927365000952374} | train loss {'Reaction outcome loss': 0.4615810429639662, 'Total loss': 0.4615810429639662}
2022-11-28 04:13:18,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:18,549 INFO:     Epoch: 67
2022-11-28 04:13:19,210 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5056149647994475, 'Total loss': 0.5056149647994475} | train loss {'Reaction outcome loss': 0.4582634944061519, 'Total loss': 0.4582634944061519}
2022-11-28 04:13:19,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:19,210 INFO:     Epoch: 68
2022-11-28 04:13:19,870 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45315716754306445, 'Total loss': 0.45315716754306445} | train loss {'Reaction outcome loss': 0.47267977422789526, 'Total loss': 0.47267977422789526}
2022-11-28 04:13:19,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:19,871 INFO:     Epoch: 69
2022-11-28 04:13:20,534 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.457948120480234, 'Total loss': 0.457948120480234} | train loss {'Reaction outcome loss': 0.4591928899650149, 'Total loss': 0.4591928899650149}
2022-11-28 04:13:20,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:20,535 INFO:     Epoch: 70
2022-11-28 04:13:21,193 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44696244394237344, 'Total loss': 0.44696244394237344} | train loss {'Reaction outcome loss': 0.4686784311405078, 'Total loss': 0.4686784311405078}
2022-11-28 04:13:21,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:21,194 INFO:     Epoch: 71
2022-11-28 04:13:21,851 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4660408862612464, 'Total loss': 0.4660408862612464} | train loss {'Reaction outcome loss': 0.45772346383646917, 'Total loss': 0.45772346383646917}
2022-11-28 04:13:21,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:21,852 INFO:     Epoch: 72
2022-11-28 04:13:22,513 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4483137195083228, 'Total loss': 0.4483137195083228} | train loss {'Reaction outcome loss': 0.4589570130783356, 'Total loss': 0.4589570130783356}
2022-11-28 04:13:22,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:22,513 INFO:     Epoch: 73
2022-11-28 04:13:23,172 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4972315938635306, 'Total loss': 0.4972315938635306} | train loss {'Reaction outcome loss': 0.46294836440549686, 'Total loss': 0.46294836440549686}
2022-11-28 04:13:23,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:23,173 INFO:     Epoch: 74
2022-11-28 04:13:23,837 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5189601890742779, 'Total loss': 0.5189601890742779} | train loss {'Reaction outcome loss': 0.4572206495503182, 'Total loss': 0.4572206495503182}
2022-11-28 04:13:23,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:23,837 INFO:     Epoch: 75
2022-11-28 04:13:24,496 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43964296918023715, 'Total loss': 0.43964296918023715} | train loss {'Reaction outcome loss': 0.46194929237051413, 'Total loss': 0.46194929237051413}
2022-11-28 04:13:24,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:24,496 INFO:     Epoch: 76
2022-11-28 04:13:25,153 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4788064848292958, 'Total loss': 0.4788064848292958} | train loss {'Reaction outcome loss': 0.4511581527800695, 'Total loss': 0.4511581527800695}
2022-11-28 04:13:25,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:25,154 INFO:     Epoch: 77
2022-11-28 04:13:25,815 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46954761005260726, 'Total loss': 0.46954761005260726} | train loss {'Reaction outcome loss': 0.4539659435027524, 'Total loss': 0.4539659435027524}
2022-11-28 04:13:25,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:25,815 INFO:     Epoch: 78
2022-11-28 04:13:26,478 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46327529136430134, 'Total loss': 0.46327529136430134} | train loss {'Reaction outcome loss': 0.46030855432213075, 'Total loss': 0.46030855432213075}
2022-11-28 04:13:26,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:26,478 INFO:     Epoch: 79
2022-11-28 04:13:27,133 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4523095745931972, 'Total loss': 0.4523095745931972} | train loss {'Reaction outcome loss': 0.4622221855740798, 'Total loss': 0.4622221855740798}
2022-11-28 04:13:27,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:27,134 INFO:     Epoch: 80
2022-11-28 04:13:27,789 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4725292230194265, 'Total loss': 0.4725292230194265} | train loss {'Reaction outcome loss': 0.4730975883692382, 'Total loss': 0.4730975883692382}
2022-11-28 04:13:27,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:27,789 INFO:     Epoch: 81
2022-11-28 04:13:28,449 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4762366552921859, 'Total loss': 0.4762366552921859} | train loss {'Reaction outcome loss': 0.4696217362094022, 'Total loss': 0.4696217362094022}
2022-11-28 04:13:28,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:28,449 INFO:     Epoch: 82
2022-11-28 04:13:29,110 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4629221429879015, 'Total loss': 0.4629221429879015} | train loss {'Reaction outcome loss': 0.47908086314616416, 'Total loss': 0.47908086314616416}
2022-11-28 04:13:29,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:29,110 INFO:     Epoch: 83
2022-11-28 04:13:29,771 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4603258127515966, 'Total loss': 0.4603258127515966} | train loss {'Reaction outcome loss': 0.45664658683242826, 'Total loss': 0.45664658683242826}
2022-11-28 04:13:29,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:29,771 INFO:     Epoch: 84
2022-11-28 04:13:30,437 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5647711960429495, 'Total loss': 0.5647711960429495} | train loss {'Reaction outcome loss': 0.4560235706176835, 'Total loss': 0.4560235706176835}
2022-11-28 04:13:30,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:30,437 INFO:     Epoch: 85
2022-11-28 04:13:31,098 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44545056247575715, 'Total loss': 0.44545056247575715} | train loss {'Reaction outcome loss': 0.4561043279443449, 'Total loss': 0.4561043279443449}
2022-11-28 04:13:31,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:31,099 INFO:     Epoch: 86
2022-11-28 04:13:31,757 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46375688825818623, 'Total loss': 0.46375688825818623} | train loss {'Reaction outcome loss': 0.4536473985746322, 'Total loss': 0.4536473985746322}
2022-11-28 04:13:31,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:31,757 INFO:     Epoch: 87
2022-11-28 04:13:32,417 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5027631304480813, 'Total loss': 0.5027631304480813} | train loss {'Reaction outcome loss': 0.4567576761429126, 'Total loss': 0.4567576761429126}
2022-11-28 04:13:32,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:32,417 INFO:     Epoch: 88
2022-11-28 04:13:33,078 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48555604605512187, 'Total loss': 0.48555604605512187} | train loss {'Reaction outcome loss': 0.4643639858947833, 'Total loss': 0.4643639858947833}
2022-11-28 04:13:33,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:33,078 INFO:     Epoch: 89
2022-11-28 04:13:33,735 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5069225654006004, 'Total loss': 0.5069225654006004} | train loss {'Reaction outcome loss': 0.4620851083443715, 'Total loss': 0.4620851083443715}
2022-11-28 04:13:33,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:33,735 INFO:     Epoch: 90
2022-11-28 04:13:34,396 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49246782809495926, 'Total loss': 0.49246782809495926} | train loss {'Reaction outcome loss': 0.456967034561914, 'Total loss': 0.456967034561914}
2022-11-28 04:13:34,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:34,396 INFO:     Epoch: 91
2022-11-28 04:13:35,059 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4764608706940304, 'Total loss': 0.4764608706940304} | train loss {'Reaction outcome loss': 0.46876779337402297, 'Total loss': 0.46876779337402297}
2022-11-28 04:13:35,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:35,060 INFO:     Epoch: 92
2022-11-28 04:13:35,721 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47990703684362496, 'Total loss': 0.47990703684362496} | train loss {'Reaction outcome loss': 0.456991347374945, 'Total loss': 0.456991347374945}
2022-11-28 04:13:35,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:35,721 INFO:     Epoch: 93
2022-11-28 04:13:36,382 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4528803728859533, 'Total loss': 0.4528803728859533} | train loss {'Reaction outcome loss': 0.45528213690348, 'Total loss': 0.45528213690348}
2022-11-28 04:13:36,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:36,382 INFO:     Epoch: 94
2022-11-28 04:13:37,045 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.474031024697152, 'Total loss': 0.474031024697152} | train loss {'Reaction outcome loss': 0.4600954055182847, 'Total loss': 0.4600954055182847}
2022-11-28 04:13:37,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:37,045 INFO:     Epoch: 95
2022-11-28 04:13:37,709 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4624613181433894, 'Total loss': 0.4624613181433894} | train loss {'Reaction outcome loss': 0.46603397403651403, 'Total loss': 0.46603397403651403}
2022-11-28 04:13:37,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:37,709 INFO:     Epoch: 96
2022-11-28 04:13:38,367 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44571382145990024, 'Total loss': 0.44571382145990024} | train loss {'Reaction outcome loss': 0.47636713684811766, 'Total loss': 0.47636713684811766}
2022-11-28 04:13:38,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:38,367 INFO:     Epoch: 97
2022-11-28 04:13:39,024 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5359882952814753, 'Total loss': 0.5359882952814753} | train loss {'Reaction outcome loss': 0.45344187871285296, 'Total loss': 0.45344187871285296}
2022-11-28 04:13:39,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:39,024 INFO:     Epoch: 98
2022-11-28 04:13:39,682 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46547392958944495, 'Total loss': 0.46547392958944495} | train loss {'Reaction outcome loss': 0.46306981671194314, 'Total loss': 0.46306981671194314}
2022-11-28 04:13:39,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:39,683 INFO:     Epoch: 99
2022-11-28 04:13:40,342 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44822795485908334, 'Total loss': 0.44822795485908334} | train loss {'Reaction outcome loss': 0.4488745395297765, 'Total loss': 0.4488745395297765}
2022-11-28 04:13:40,343 INFO:     Best model found after epoch 64 of 100.
2022-11-28 04:13:40,343 INFO:   Done with stage: TRAINING
2022-11-28 04:13:40,343 INFO:   Starting stage: EVALUATION
2022-11-28 04:13:40,462 INFO:   Done with stage: EVALUATION
2022-11-28 04:13:40,462 INFO:   Leaving out SEQ value Fold_3
2022-11-28 04:13:40,475 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 04:13:40,475 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:13:41,132 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:13:41,132 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:13:41,199 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:13:41,199 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:13:41,199 INFO:     No hyperparam tuning for this model
2022-11-28 04:13:41,199 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:13:41,199 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:13:41,200 INFO:     None feature selector for col prot
2022-11-28 04:13:41,200 INFO:     None feature selector for col prot
2022-11-28 04:13:41,200 INFO:     None feature selector for col prot
2022-11-28 04:13:41,201 INFO:     None feature selector for col chem
2022-11-28 04:13:41,201 INFO:     None feature selector for col chem
2022-11-28 04:13:41,201 INFO:     None feature selector for col chem
2022-11-28 04:13:41,201 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:13:41,201 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:13:41,203 INFO:     Number of params in model 169651
2022-11-28 04:13:41,206 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:13:41,206 INFO:   Starting stage: TRAINING
2022-11-28 04:13:41,256 INFO:     Val loss before train {'Reaction outcome loss': 1.0032476117444593, 'Total loss': 1.0032476117444593}
2022-11-28 04:13:41,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:41,256 INFO:     Epoch: 0
2022-11-28 04:13:41,910 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5545046329498291, 'Total loss': 0.5545046329498291} | train loss {'Reaction outcome loss': 0.6801062581724808, 'Total loss': 0.6801062581724808}
2022-11-28 04:13:41,910 INFO:     Found new best model at epoch 0
2022-11-28 04:13:41,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:41,911 INFO:     Epoch: 1
2022-11-28 04:13:42,563 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5703455015670421, 'Total loss': 0.5703455015670421} | train loss {'Reaction outcome loss': 0.5850935203374409, 'Total loss': 0.5850935203374409}
2022-11-28 04:13:42,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:42,564 INFO:     Epoch: 2
2022-11-28 04:13:43,216 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5533240118692088, 'Total loss': 0.5533240118692088} | train loss {'Reaction outcome loss': 0.5599275242354049, 'Total loss': 0.5599275242354049}
2022-11-28 04:13:43,216 INFO:     Found new best model at epoch 2
2022-11-28 04:13:43,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:43,217 INFO:     Epoch: 3
2022-11-28 04:13:43,870 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4937439647524856, 'Total loss': 0.4937439647524856} | train loss {'Reaction outcome loss': 0.5349309112815583, 'Total loss': 0.5349309112815583}
2022-11-28 04:13:43,871 INFO:     Found new best model at epoch 3
2022-11-28 04:13:43,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:43,871 INFO:     Epoch: 4
2022-11-28 04:13:44,522 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.519247769616371, 'Total loss': 0.519247769616371} | train loss {'Reaction outcome loss': 0.5195536224446335, 'Total loss': 0.5195536224446335}
2022-11-28 04:13:44,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:44,522 INFO:     Epoch: 5
2022-11-28 04:13:45,172 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4853696746881618, 'Total loss': 0.4853696746881618} | train loss {'Reaction outcome loss': 0.5171858864973803, 'Total loss': 0.5171858864973803}
2022-11-28 04:13:45,172 INFO:     Found new best model at epoch 5
2022-11-28 04:13:45,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:45,173 INFO:     Epoch: 6
2022-11-28 04:13:45,823 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49841242162294164, 'Total loss': 0.49841242162294164} | train loss {'Reaction outcome loss': 0.5110248047553125, 'Total loss': 0.5110248047553125}
2022-11-28 04:13:45,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:45,823 INFO:     Epoch: 7
2022-11-28 04:13:46,478 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47882927988850793, 'Total loss': 0.47882927988850793} | train loss {'Reaction outcome loss': 0.49438278144988856, 'Total loss': 0.49438278144988856}
2022-11-28 04:13:46,478 INFO:     Found new best model at epoch 7
2022-11-28 04:13:46,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:46,479 INFO:     Epoch: 8
2022-11-28 04:13:47,132 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5206689456867617, 'Total loss': 0.5206689456867617} | train loss {'Reaction outcome loss': 0.49260806658717454, 'Total loss': 0.49260806658717454}
2022-11-28 04:13:47,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:47,132 INFO:     Epoch: 9
2022-11-28 04:13:47,785 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48361240188742793, 'Total loss': 0.48361240188742793} | train loss {'Reaction outcome loss': 0.48176857523742267, 'Total loss': 0.48176857523742267}
2022-11-28 04:13:47,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:47,786 INFO:     Epoch: 10
2022-11-28 04:13:48,438 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48014986619006755, 'Total loss': 0.48014986619006755} | train loss {'Reaction outcome loss': 0.48835647124491754, 'Total loss': 0.48835647124491754}
2022-11-28 04:13:48,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:48,438 INFO:     Epoch: 11
2022-11-28 04:13:49,091 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49634130680283833, 'Total loss': 0.49634130680283833} | train loss {'Reaction outcome loss': 0.4852558632121711, 'Total loss': 0.4852558632121711}
2022-11-28 04:13:49,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:49,092 INFO:     Epoch: 12
2022-11-28 04:13:49,746 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.489548854703127, 'Total loss': 0.489548854703127} | train loss {'Reaction outcome loss': 0.4713586965178857, 'Total loss': 0.4713586965178857}
2022-11-28 04:13:49,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:49,746 INFO:     Epoch: 13
2022-11-28 04:13:50,400 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4552585063285606, 'Total loss': 0.4552585063285606} | train loss {'Reaction outcome loss': 0.4813341574102152, 'Total loss': 0.4813341574102152}
2022-11-28 04:13:50,400 INFO:     Found new best model at epoch 13
2022-11-28 04:13:50,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:50,401 INFO:     Epoch: 14
2022-11-28 04:13:51,053 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5005412143330241, 'Total loss': 0.5005412143330241} | train loss {'Reaction outcome loss': 0.4732658507027587, 'Total loss': 0.4732658507027587}
2022-11-28 04:13:51,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:51,053 INFO:     Epoch: 15
2022-11-28 04:13:51,706 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5026703258586485, 'Total loss': 0.5026703258586485} | train loss {'Reaction outcome loss': 0.47847433357698016, 'Total loss': 0.47847433357698016}
2022-11-28 04:13:51,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:51,706 INFO:     Epoch: 16
2022-11-28 04:13:52,359 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4883951915557994, 'Total loss': 0.4883951915557994} | train loss {'Reaction outcome loss': 0.47040042904068213, 'Total loss': 0.47040042904068213}
2022-11-28 04:13:52,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:52,359 INFO:     Epoch: 17
2022-11-28 04:13:53,010 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4763757175830908, 'Total loss': 0.4763757175830908} | train loss {'Reaction outcome loss': 0.47184610534764704, 'Total loss': 0.47184610534764704}
2022-11-28 04:13:53,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:53,011 INFO:     Epoch: 18
2022-11-28 04:13:53,662 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5109104119067969, 'Total loss': 0.5109104119067969} | train loss {'Reaction outcome loss': 0.4673720726468524, 'Total loss': 0.4673720726468524}
2022-11-28 04:13:53,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:53,662 INFO:     Epoch: 19
2022-11-28 04:13:54,316 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46112226920072424, 'Total loss': 0.46112226920072424} | train loss {'Reaction outcome loss': 0.4654014075755096, 'Total loss': 0.4654014075755096}
2022-11-28 04:13:54,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:54,316 INFO:     Epoch: 20
2022-11-28 04:13:54,972 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46280383128066394, 'Total loss': 0.46280383128066394} | train loss {'Reaction outcome loss': 0.4664298809270878, 'Total loss': 0.4664298809270878}
2022-11-28 04:13:54,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:54,972 INFO:     Epoch: 21
2022-11-28 04:13:55,625 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45596299129863116, 'Total loss': 0.45596299129863116} | train loss {'Reaction outcome loss': 0.4730724872502147, 'Total loss': 0.4730724872502147}
2022-11-28 04:13:55,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:55,625 INFO:     Epoch: 22
2022-11-28 04:13:56,278 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45776190314182014, 'Total loss': 0.45776190314182014} | train loss {'Reaction outcome loss': 0.4612023930569164, 'Total loss': 0.4612023930569164}
2022-11-28 04:13:56,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:56,278 INFO:     Epoch: 23
2022-11-28 04:13:56,930 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4842005424028219, 'Total loss': 0.4842005424028219} | train loss {'Reaction outcome loss': 0.4588163848050305, 'Total loss': 0.4588163848050305}
2022-11-28 04:13:56,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:56,930 INFO:     Epoch: 24
2022-11-28 04:13:57,587 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5421467430369799, 'Total loss': 0.5421467430369799} | train loss {'Reaction outcome loss': 0.47106639454599286, 'Total loss': 0.47106639454599286}
2022-11-28 04:13:57,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:57,587 INFO:     Epoch: 25
2022-11-28 04:13:58,243 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4914733542259349, 'Total loss': 0.4914733542259349} | train loss {'Reaction outcome loss': 0.4704922788211557, 'Total loss': 0.4704922788211557}
2022-11-28 04:13:58,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:58,243 INFO:     Epoch: 26
2022-11-28 04:13:58,900 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4750117472437925, 'Total loss': 0.4750117472437925} | train loss {'Reaction outcome loss': 0.45738440898598215, 'Total loss': 0.45738440898598215}
2022-11-28 04:13:58,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:58,900 INFO:     Epoch: 27
2022-11-28 04:13:59,556 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4828875137622966, 'Total loss': 0.4828875137622966} | train loss {'Reaction outcome loss': 0.45454016395035335, 'Total loss': 0.45454016395035335}
2022-11-28 04:13:59,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:13:59,556 INFO:     Epoch: 28
2022-11-28 04:14:00,212 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4622642384019009, 'Total loss': 0.4622642384019009} | train loss {'Reaction outcome loss': 0.45570689861158853, 'Total loss': 0.45570689861158853}
2022-11-28 04:14:00,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:00,212 INFO:     Epoch: 29
2022-11-28 04:14:00,868 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47514599700306737, 'Total loss': 0.47514599700306737} | train loss {'Reaction outcome loss': 0.4589477553352958, 'Total loss': 0.4589477553352958}
2022-11-28 04:14:00,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:00,868 INFO:     Epoch: 30
2022-11-28 04:14:01,524 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4426144697638445, 'Total loss': 0.4426144697638445} | train loss {'Reaction outcome loss': 0.45250315219163895, 'Total loss': 0.45250315219163895}
2022-11-28 04:14:01,524 INFO:     Found new best model at epoch 30
2022-11-28 04:14:01,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:01,525 INFO:     Epoch: 31
2022-11-28 04:14:02,177 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4668720402689867, 'Total loss': 0.4668720402689867} | train loss {'Reaction outcome loss': 0.461754782522311, 'Total loss': 0.461754782522311}
2022-11-28 04:14:02,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:02,177 INFO:     Epoch: 32
2022-11-28 04:14:02,829 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4504432040591573, 'Total loss': 0.4504432040591573} | train loss {'Reaction outcome loss': 0.4562930728873757, 'Total loss': 0.4562930728873757}
2022-11-28 04:14:02,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:02,830 INFO:     Epoch: 33
2022-11-28 04:14:03,486 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4668688327074051, 'Total loss': 0.4668688327074051} | train loss {'Reaction outcome loss': 0.4553125164792186, 'Total loss': 0.4553125164792186}
2022-11-28 04:14:03,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:03,486 INFO:     Epoch: 34
2022-11-28 04:14:04,139 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44038528793079906, 'Total loss': 0.44038528793079906} | train loss {'Reaction outcome loss': 0.4501566077719946, 'Total loss': 0.4501566077719946}
2022-11-28 04:14:04,139 INFO:     Found new best model at epoch 34
2022-11-28 04:14:04,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:04,140 INFO:     Epoch: 35
2022-11-28 04:14:04,795 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4555945514246475, 'Total loss': 0.4555945514246475} | train loss {'Reaction outcome loss': 0.45561714849022567, 'Total loss': 0.45561714849022567}
2022-11-28 04:14:04,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:04,795 INFO:     Epoch: 36
2022-11-28 04:14:05,448 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43732317762319434, 'Total loss': 0.43732317762319434} | train loss {'Reaction outcome loss': 0.4486902361644096, 'Total loss': 0.4486902361644096}
2022-11-28 04:14:05,448 INFO:     Found new best model at epoch 36
2022-11-28 04:14:05,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:05,449 INFO:     Epoch: 37
2022-11-28 04:14:06,104 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45537390819815704, 'Total loss': 0.45537390819815704} | train loss {'Reaction outcome loss': 0.454643739020971, 'Total loss': 0.454643739020971}
2022-11-28 04:14:06,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:06,105 INFO:     Epoch: 38
2022-11-28 04:14:06,756 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47758110907188683, 'Total loss': 0.47758110907188683} | train loss {'Reaction outcome loss': 0.449758736325092, 'Total loss': 0.449758736325092}
2022-11-28 04:14:06,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:06,756 INFO:     Epoch: 39
2022-11-28 04:14:07,408 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48071068456006605, 'Total loss': 0.48071068456006605} | train loss {'Reaction outcome loss': 0.450388708808383, 'Total loss': 0.450388708808383}
2022-11-28 04:14:07,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:07,408 INFO:     Epoch: 40
2022-11-28 04:14:08,057 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4305225032013516, 'Total loss': 0.4305225032013516} | train loss {'Reaction outcome loss': 0.4545999090568941, 'Total loss': 0.4545999090568941}
2022-11-28 04:14:08,057 INFO:     Found new best model at epoch 40
2022-11-28 04:14:08,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:08,058 INFO:     Epoch: 41
2022-11-28 04:14:08,711 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47146199366381003, 'Total loss': 0.47146199366381003} | train loss {'Reaction outcome loss': 0.44792528462703113, 'Total loss': 0.44792528462703113}
2022-11-28 04:14:08,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:08,712 INFO:     Epoch: 42
2022-11-28 04:14:09,364 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46843320408532785, 'Total loss': 0.46843320408532785} | train loss {'Reaction outcome loss': 0.4549408415179761, 'Total loss': 0.4549408415179761}
2022-11-28 04:14:09,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:09,365 INFO:     Epoch: 43
2022-11-28 04:14:10,015 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44127533290275306, 'Total loss': 0.44127533290275306} | train loss {'Reaction outcome loss': 0.4474249891326076, 'Total loss': 0.4474249891326076}
2022-11-28 04:14:10,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:10,016 INFO:     Epoch: 44
2022-11-28 04:14:10,667 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4478308956983478, 'Total loss': 0.4478308956983478} | train loss {'Reaction outcome loss': 0.45229153054170923, 'Total loss': 0.45229153054170923}
2022-11-28 04:14:10,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:10,667 INFO:     Epoch: 45
2022-11-28 04:14:11,320 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4735575401505759, 'Total loss': 0.4735575401505759} | train loss {'Reaction outcome loss': 0.45583301770393964, 'Total loss': 0.45583301770393964}
2022-11-28 04:14:11,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:11,321 INFO:     Epoch: 46
2022-11-28 04:14:11,974 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4641053714724474, 'Total loss': 0.4641053714724474} | train loss {'Reaction outcome loss': 0.44896904223400064, 'Total loss': 0.44896904223400064}
2022-11-28 04:14:11,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:11,975 INFO:     Epoch: 47
2022-11-28 04:14:12,627 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46784344696721364, 'Total loss': 0.46784344696721364} | train loss {'Reaction outcome loss': 0.45708429611852913, 'Total loss': 0.45708429611852913}
2022-11-28 04:14:12,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:12,628 INFO:     Epoch: 48
2022-11-28 04:14:13,280 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.453852677068045, 'Total loss': 0.453852677068045} | train loss {'Reaction outcome loss': 0.44877407620431947, 'Total loss': 0.44877407620431947}
2022-11-28 04:14:13,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:13,280 INFO:     Epoch: 49
2022-11-28 04:14:13,936 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4668795331272968, 'Total loss': 0.4668795331272968} | train loss {'Reaction outcome loss': 0.45317945672107524, 'Total loss': 0.45317945672107524}
2022-11-28 04:14:13,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:13,936 INFO:     Epoch: 50
2022-11-28 04:14:14,590 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45278006722760755, 'Total loss': 0.45278006722760755} | train loss {'Reaction outcome loss': 0.44820902710322474, 'Total loss': 0.44820902710322474}
2022-11-28 04:14:14,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:14,590 INFO:     Epoch: 51
2022-11-28 04:14:15,243 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4623564831739248, 'Total loss': 0.4623564831739248} | train loss {'Reaction outcome loss': 0.45440035282832675, 'Total loss': 0.45440035282832675}
2022-11-28 04:14:15,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:15,243 INFO:     Epoch: 52
2022-11-28 04:14:15,899 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4841022397889647, 'Total loss': 0.4841022397889647} | train loss {'Reaction outcome loss': 0.4575395537082289, 'Total loss': 0.4575395537082289}
2022-11-28 04:14:15,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:15,900 INFO:     Epoch: 53
2022-11-28 04:14:16,556 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4808311982210292, 'Total loss': 0.4808311982210292} | train loss {'Reaction outcome loss': 0.44765633265258836, 'Total loss': 0.44765633265258836}
2022-11-28 04:14:16,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:16,556 INFO:     Epoch: 54
2022-11-28 04:14:17,210 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45025951051434804, 'Total loss': 0.45025951051434804} | train loss {'Reaction outcome loss': 0.4491334412185872, 'Total loss': 0.4491334412185872}
2022-11-28 04:14:17,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:17,210 INFO:     Epoch: 55
2022-11-28 04:14:17,863 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4520302820344304, 'Total loss': 0.4520302820344304} | train loss {'Reaction outcome loss': 0.44570007792017496, 'Total loss': 0.44570007792017496}
2022-11-28 04:14:17,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:17,863 INFO:     Epoch: 56
2022-11-28 04:14:18,517 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4655505838089211, 'Total loss': 0.4655505838089211} | train loss {'Reaction outcome loss': 0.45139337361591764, 'Total loss': 0.45139337361591764}
2022-11-28 04:14:18,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:18,518 INFO:     Epoch: 57
2022-11-28 04:14:19,173 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45479968606039534, 'Total loss': 0.45479968606039534} | train loss {'Reaction outcome loss': 0.45239471613627963, 'Total loss': 0.45239471613627963}
2022-11-28 04:14:19,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:19,173 INFO:     Epoch: 58
2022-11-28 04:14:19,829 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45808357346889583, 'Total loss': 0.45808357346889583} | train loss {'Reaction outcome loss': 0.4530374119516279, 'Total loss': 0.4530374119516279}
2022-11-28 04:14:19,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:19,829 INFO:     Epoch: 59
2022-11-28 04:14:20,480 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44430799920891606, 'Total loss': 0.44430799920891606} | train loss {'Reaction outcome loss': 0.4441221820526436, 'Total loss': 0.4441221820526436}
2022-11-28 04:14:20,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:20,481 INFO:     Epoch: 60
2022-11-28 04:14:21,137 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4376022150350172, 'Total loss': 0.4376022150350172} | train loss {'Reaction outcome loss': 0.45408183165261, 'Total loss': 0.45408183165261}
2022-11-28 04:14:21,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:21,137 INFO:     Epoch: 61
2022-11-28 04:14:21,792 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4412403266097224, 'Total loss': 0.4412403266097224} | train loss {'Reaction outcome loss': 0.4492289921665778, 'Total loss': 0.4492289921665778}
2022-11-28 04:14:21,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:21,792 INFO:     Epoch: 62
2022-11-28 04:14:22,446 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.442334565658902, 'Total loss': 0.442334565658902} | train loss {'Reaction outcome loss': 0.44420653282374634, 'Total loss': 0.44420653282374634}
2022-11-28 04:14:22,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:22,446 INFO:     Epoch: 63
2022-11-28 04:14:23,100 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.444211964690408, 'Total loss': 0.444211964690408} | train loss {'Reaction outcome loss': 0.45323412001255103, 'Total loss': 0.45323412001255103}
2022-11-28 04:14:23,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:23,100 INFO:     Epoch: 64
2022-11-28 04:14:23,751 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4610346153725025, 'Total loss': 0.4610346153725025} | train loss {'Reaction outcome loss': 0.4500381039669279, 'Total loss': 0.4500381039669279}
2022-11-28 04:14:23,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:23,752 INFO:     Epoch: 65
2022-11-28 04:14:24,405 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45420700311660767, 'Total loss': 0.45420700311660767} | train loss {'Reaction outcome loss': 0.4544939693124568, 'Total loss': 0.4544939693124568}
2022-11-28 04:14:24,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:24,405 INFO:     Epoch: 66
2022-11-28 04:14:25,059 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4506327028191367, 'Total loss': 0.4506327028191367} | train loss {'Reaction outcome loss': 0.44625553769654913, 'Total loss': 0.44625553769654913}
2022-11-28 04:14:25,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:25,060 INFO:     Epoch: 67
2022-11-28 04:14:25,715 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45840705688609634, 'Total loss': 0.45840705688609634} | train loss {'Reaction outcome loss': 0.4525857176326337, 'Total loss': 0.4525857176326337}
2022-11-28 04:14:25,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:25,715 INFO:     Epoch: 68
2022-11-28 04:14:26,372 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4575667104055715, 'Total loss': 0.4575667104055715} | train loss {'Reaction outcome loss': 0.45073401445492367, 'Total loss': 0.45073401445492367}
2022-11-28 04:14:26,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:26,372 INFO:     Epoch: 69
2022-11-28 04:14:27,028 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.461694392700528, 'Total loss': 0.461694392700528} | train loss {'Reaction outcome loss': 0.4511445998901226, 'Total loss': 0.4511445998901226}
2022-11-28 04:14:27,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:27,028 INFO:     Epoch: 70
2022-11-28 04:14:27,685 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4409733113161353, 'Total loss': 0.4409733113161353} | train loss {'Reaction outcome loss': 0.45042709832186584, 'Total loss': 0.45042709832186584}
2022-11-28 04:14:27,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:27,685 INFO:     Epoch: 71
2022-11-28 04:14:28,341 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4875163134447364, 'Total loss': 0.4875163134447364} | train loss {'Reaction outcome loss': 0.4479646682433906, 'Total loss': 0.4479646682433906}
2022-11-28 04:14:28,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:28,341 INFO:     Epoch: 72
2022-11-28 04:14:28,997 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44729259021060414, 'Total loss': 0.44729259021060414} | train loss {'Reaction outcome loss': 0.44821575030562333, 'Total loss': 0.44821575030562333}
2022-11-28 04:14:28,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:28,997 INFO:     Epoch: 73
2022-11-28 04:14:29,656 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4442492117022359, 'Total loss': 0.4442492117022359} | train loss {'Reaction outcome loss': 0.4471135962693418, 'Total loss': 0.4471135962693418}
2022-11-28 04:14:29,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:29,657 INFO:     Epoch: 74
2022-11-28 04:14:30,316 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.500850475111673, 'Total loss': 0.500850475111673} | train loss {'Reaction outcome loss': 0.45759821744238743, 'Total loss': 0.45759821744238743}
2022-11-28 04:14:30,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:30,316 INFO:     Epoch: 75
2022-11-28 04:14:30,976 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4359393455954485, 'Total loss': 0.4359393455954485} | train loss {'Reaction outcome loss': 0.4423249908035896, 'Total loss': 0.4423249908035896}
2022-11-28 04:14:30,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:30,976 INFO:     Epoch: 76
2022-11-28 04:14:31,636 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4492836644829706, 'Total loss': 0.4492836644829706} | train loss {'Reaction outcome loss': 0.44845941461256295, 'Total loss': 0.44845941461256295}
2022-11-28 04:14:31,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:31,636 INFO:     Epoch: 77
2022-11-28 04:14:32,295 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4375851712254591, 'Total loss': 0.4375851712254591} | train loss {'Reaction outcome loss': 0.4443541352377563, 'Total loss': 0.4443541352377563}
2022-11-28 04:14:32,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:32,295 INFO:     Epoch: 78
2022-11-28 04:14:32,953 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47140006617058156, 'Total loss': 0.47140006617058156} | train loss {'Reaction outcome loss': 0.4606753829561296, 'Total loss': 0.4606753829561296}
2022-11-28 04:14:32,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:32,954 INFO:     Epoch: 79
2022-11-28 04:14:33,614 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43019217599269954, 'Total loss': 0.43019217599269954} | train loss {'Reaction outcome loss': 0.4440779080767123, 'Total loss': 0.4440779080767123}
2022-11-28 04:14:33,615 INFO:     Found new best model at epoch 79
2022-11-28 04:14:33,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:33,615 INFO:     Epoch: 80
2022-11-28 04:14:34,273 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46914583652518516, 'Total loss': 0.46914583652518516} | train loss {'Reaction outcome loss': 0.45730388533995775, 'Total loss': 0.45730388533995775}
2022-11-28 04:14:34,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:34,273 INFO:     Epoch: 81
2022-11-28 04:14:34,930 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4539195399644763, 'Total loss': 0.4539195399644763} | train loss {'Reaction outcome loss': 0.448929348074999, 'Total loss': 0.448929348074999}
2022-11-28 04:14:34,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:34,930 INFO:     Epoch: 82
2022-11-28 04:14:35,586 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4291739966287169, 'Total loss': 0.4291739966287169} | train loss {'Reaction outcome loss': 0.4470964464374253, 'Total loss': 0.4470964464374253}
2022-11-28 04:14:35,587 INFO:     Found new best model at epoch 82
2022-11-28 04:14:35,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:35,587 INFO:     Epoch: 83
2022-11-28 04:14:36,244 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4297254147917725, 'Total loss': 0.4297254147917725} | train loss {'Reaction outcome loss': 0.4539584595038266, 'Total loss': 0.4539584595038266}
2022-11-28 04:14:36,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:36,245 INFO:     Epoch: 84
2022-11-28 04:14:36,900 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46237042199733647, 'Total loss': 0.46237042199733647} | train loss {'Reaction outcome loss': 0.4466307007203825, 'Total loss': 0.4466307007203825}
2022-11-28 04:14:36,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:36,901 INFO:     Epoch: 85
2022-11-28 04:14:37,556 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47157635591750924, 'Total loss': 0.47157635591750924} | train loss {'Reaction outcome loss': 0.45095662308520956, 'Total loss': 0.45095662308520956}
2022-11-28 04:14:37,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:37,556 INFO:     Epoch: 86
2022-11-28 04:14:38,211 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46764121776403383, 'Total loss': 0.46764121776403383} | train loss {'Reaction outcome loss': 0.4488458611437532, 'Total loss': 0.4488458611437532}
2022-11-28 04:14:38,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:38,212 INFO:     Epoch: 87
2022-11-28 04:14:38,871 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4429645801699439, 'Total loss': 0.4429645801699439} | train loss {'Reaction outcome loss': 0.4551010046948175, 'Total loss': 0.4551010046948175}
2022-11-28 04:14:38,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:38,871 INFO:     Epoch: 88
2022-11-28 04:14:39,528 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4606140363355016, 'Total loss': 0.4606140363355016} | train loss {'Reaction outcome loss': 0.446796786650771, 'Total loss': 0.446796786650771}
2022-11-28 04:14:39,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:39,529 INFO:     Epoch: 89
2022-11-28 04:14:40,189 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47081555148889853, 'Total loss': 0.47081555148889853} | train loss {'Reaction outcome loss': 0.446527402603724, 'Total loss': 0.446527402603724}
2022-11-28 04:14:40,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:40,190 INFO:     Epoch: 90
2022-11-28 04:14:40,847 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4340197152869646, 'Total loss': 0.4340197152869646} | train loss {'Reaction outcome loss': 0.45148012133651094, 'Total loss': 0.45148012133651094}
2022-11-28 04:14:40,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:40,847 INFO:     Epoch: 91
2022-11-28 04:14:41,506 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47818660528160806, 'Total loss': 0.47818660528160806} | train loss {'Reaction outcome loss': 0.4499468858369061, 'Total loss': 0.4499468858369061}
2022-11-28 04:14:41,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:41,507 INFO:     Epoch: 92
2022-11-28 04:14:42,160 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4738194096920102, 'Total loss': 0.4738194096920102} | train loss {'Reaction outcome loss': 0.4544647428222367, 'Total loss': 0.4544647428222367}
2022-11-28 04:14:42,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:42,160 INFO:     Epoch: 93
2022-11-28 04:14:42,813 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4413652288359265, 'Total loss': 0.4413652288359265} | train loss {'Reaction outcome loss': 0.4502396755164764, 'Total loss': 0.4502396755164764}
2022-11-28 04:14:42,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:42,813 INFO:     Epoch: 94
2022-11-28 04:14:43,466 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4471702371225801, 'Total loss': 0.4471702371225801} | train loss {'Reaction outcome loss': 0.46037316074991813, 'Total loss': 0.46037316074991813}
2022-11-28 04:14:43,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:43,466 INFO:     Epoch: 95
2022-11-28 04:14:44,120 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4173870259939238, 'Total loss': 0.4173870259939238} | train loss {'Reaction outcome loss': 0.4505987230566193, 'Total loss': 0.4505987230566193}
2022-11-28 04:14:44,120 INFO:     Found new best model at epoch 95
2022-11-28 04:14:44,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:44,121 INFO:     Epoch: 96
2022-11-28 04:14:44,773 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4524158079956853, 'Total loss': 0.4524158079956853} | train loss {'Reaction outcome loss': 0.45164212202805964, 'Total loss': 0.45164212202805964}
2022-11-28 04:14:44,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:44,774 INFO:     Epoch: 97
2022-11-28 04:14:45,429 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4593108029559601, 'Total loss': 0.4593108029559601} | train loss {'Reaction outcome loss': 0.4578706270358602, 'Total loss': 0.4578706270358602}
2022-11-28 04:14:45,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:45,429 INFO:     Epoch: 98
2022-11-28 04:14:46,079 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4739867670591487, 'Total loss': 0.4739867670591487} | train loss {'Reaction outcome loss': 0.45657078146201663, 'Total loss': 0.45657078146201663}
2022-11-28 04:14:46,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:46,079 INFO:     Epoch: 99
2022-11-28 04:14:46,730 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46103559469067773, 'Total loss': 0.46103559469067773} | train loss {'Reaction outcome loss': 0.44948794747718046, 'Total loss': 0.44948794747718046}
2022-11-28 04:14:46,730 INFO:     Best model found after epoch 96 of 100.
2022-11-28 04:14:46,730 INFO:   Done with stage: TRAINING
2022-11-28 04:14:46,730 INFO:   Starting stage: EVALUATION
2022-11-28 04:14:46,860 INFO:   Done with stage: EVALUATION
2022-11-28 04:14:46,860 INFO:   Leaving out SEQ value Fold_4
2022-11-28 04:14:46,873 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:14:46,873 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:14:47,514 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:14:47,514 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:14:47,582 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:14:47,582 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:14:47,582 INFO:     No hyperparam tuning for this model
2022-11-28 04:14:47,582 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:14:47,582 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:14:47,583 INFO:     None feature selector for col prot
2022-11-28 04:14:47,583 INFO:     None feature selector for col prot
2022-11-28 04:14:47,583 INFO:     None feature selector for col prot
2022-11-28 04:14:47,584 INFO:     None feature selector for col chem
2022-11-28 04:14:47,584 INFO:     None feature selector for col chem
2022-11-28 04:14:47,584 INFO:     None feature selector for col chem
2022-11-28 04:14:47,584 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:14:47,584 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:14:47,585 INFO:     Number of params in model 169651
2022-11-28 04:14:47,588 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:14:47,588 INFO:   Starting stage: TRAINING
2022-11-28 04:14:47,640 INFO:     Val loss before train {'Reaction outcome loss': 0.982340625741265, 'Total loss': 0.982340625741265}
2022-11-28 04:14:47,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:47,640 INFO:     Epoch: 0
2022-11-28 04:14:48,308 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5985841304063797, 'Total loss': 0.5985841304063797} | train loss {'Reaction outcome loss': 0.6990451091720212, 'Total loss': 0.6990451091720212}
2022-11-28 04:14:48,308 INFO:     Found new best model at epoch 0
2022-11-28 04:14:48,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:48,309 INFO:     Epoch: 1
2022-11-28 04:14:48,976 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5507300130345605, 'Total loss': 0.5507300130345605} | train loss {'Reaction outcome loss': 0.5935722047523144, 'Total loss': 0.5935722047523144}
2022-11-28 04:14:48,977 INFO:     Found new best model at epoch 1
2022-11-28 04:14:48,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:48,977 INFO:     Epoch: 2
2022-11-28 04:14:49,640 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5290061323480173, 'Total loss': 0.5290061323480173} | train loss {'Reaction outcome loss': 0.5619296445961921, 'Total loss': 0.5619296445961921}
2022-11-28 04:14:49,640 INFO:     Found new best model at epoch 2
2022-11-28 04:14:49,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:49,641 INFO:     Epoch: 3
2022-11-28 04:14:50,304 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5419522889635779, 'Total loss': 0.5419522889635779} | train loss {'Reaction outcome loss': 0.5421638515507502, 'Total loss': 0.5421638515507502}
2022-11-28 04:14:50,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:50,304 INFO:     Epoch: 4
2022-11-28 04:14:50,965 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49089259349487047, 'Total loss': 0.49089259349487047} | train loss {'Reaction outcome loss': 0.5300200840518359, 'Total loss': 0.5300200840518359}
2022-11-28 04:14:50,965 INFO:     Found new best model at epoch 4
2022-11-28 04:14:50,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:50,966 INFO:     Epoch: 5
2022-11-28 04:14:51,628 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5296119607307694, 'Total loss': 0.5296119607307694} | train loss {'Reaction outcome loss': 0.5257435434407765, 'Total loss': 0.5257435434407765}
2022-11-28 04:14:51,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:51,629 INFO:     Epoch: 6
2022-11-28 04:14:52,290 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4874464469877156, 'Total loss': 0.4874464469877156} | train loss {'Reaction outcome loss': 0.5155012893580622, 'Total loss': 0.5155012893580622}
2022-11-28 04:14:52,290 INFO:     Found new best model at epoch 6
2022-11-28 04:14:52,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:52,291 INFO:     Epoch: 7
2022-11-28 04:14:52,950 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4935665432025086, 'Total loss': 0.4935665432025086} | train loss {'Reaction outcome loss': 0.5091925748293439, 'Total loss': 0.5091925748293439}
2022-11-28 04:14:52,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:52,950 INFO:     Epoch: 8
2022-11-28 04:14:53,609 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5031538592143492, 'Total loss': 0.5031538592143492} | train loss {'Reaction outcome loss': 0.5068916495769255, 'Total loss': 0.5068916495769255}
2022-11-28 04:14:53,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:53,609 INFO:     Epoch: 9
2022-11-28 04:14:54,270 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4696206210011786, 'Total loss': 0.4696206210011786} | train loss {'Reaction outcome loss': 0.495905903318236, 'Total loss': 0.495905903318236}
2022-11-28 04:14:54,270 INFO:     Found new best model at epoch 9
2022-11-28 04:14:54,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:54,271 INFO:     Epoch: 10
2022-11-28 04:14:54,938 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49638699807903985, 'Total loss': 0.49638699807903985} | train loss {'Reaction outcome loss': 0.49279706859059874, 'Total loss': 0.49279706859059874}
2022-11-28 04:14:54,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:54,938 INFO:     Epoch: 11
2022-11-28 04:14:55,600 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5963428921320222, 'Total loss': 0.5963428921320222} | train loss {'Reaction outcome loss': 0.49195921174701185, 'Total loss': 0.49195921174701185}
2022-11-28 04:14:55,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:55,601 INFO:     Epoch: 12
2022-11-28 04:14:56,265 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4828041751276363, 'Total loss': 0.4828041751276363} | train loss {'Reaction outcome loss': 0.4891279779614941, 'Total loss': 0.4891279779614941}
2022-11-28 04:14:56,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:56,265 INFO:     Epoch: 13
2022-11-28 04:14:56,928 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4988331916657361, 'Total loss': 0.4988331916657361} | train loss {'Reaction outcome loss': 0.4921620221988809, 'Total loss': 0.4921620221988809}
2022-11-28 04:14:56,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:56,928 INFO:     Epoch: 14
2022-11-28 04:14:57,593 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48432816395705397, 'Total loss': 0.48432816395705397} | train loss {'Reaction outcome loss': 0.48815255786382383, 'Total loss': 0.48815255786382383}
2022-11-28 04:14:57,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:57,594 INFO:     Epoch: 15
2022-11-28 04:14:58,263 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4700012616813183, 'Total loss': 0.4700012616813183} | train loss {'Reaction outcome loss': 0.4854889718755599, 'Total loss': 0.4854889718755599}
2022-11-28 04:14:58,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:58,263 INFO:     Epoch: 16
2022-11-28 04:14:58,930 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4641998474570838, 'Total loss': 0.4641998474570838} | train loss {'Reaction outcome loss': 0.4877747142867696, 'Total loss': 0.4877747142867696}
2022-11-28 04:14:58,930 INFO:     Found new best model at epoch 16
2022-11-28 04:14:58,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:58,931 INFO:     Epoch: 17
2022-11-28 04:14:59,594 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5120030519637194, 'Total loss': 0.5120030519637194} | train loss {'Reaction outcome loss': 0.48749273907273044, 'Total loss': 0.48749273907273044}
2022-11-28 04:14:59,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:14:59,594 INFO:     Epoch: 18
2022-11-28 04:15:00,254 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4846108335662972, 'Total loss': 0.4846108335662972} | train loss {'Reaction outcome loss': 0.4872611210110687, 'Total loss': 0.4872611210110687}
2022-11-28 04:15:00,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:00,255 INFO:     Epoch: 19
2022-11-28 04:15:00,917 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4751168770546263, 'Total loss': 0.4751168770546263} | train loss {'Reaction outcome loss': 0.49722654690905926, 'Total loss': 0.49722654690905926}
2022-11-28 04:15:00,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:00,917 INFO:     Epoch: 20
2022-11-28 04:15:01,580 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4675602418455211, 'Total loss': 0.4675602418455211} | train loss {'Reaction outcome loss': 0.4889315341809584, 'Total loss': 0.4889315341809584}
2022-11-28 04:15:01,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:01,580 INFO:     Epoch: 21
2022-11-28 04:15:02,242 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.482797155326063, 'Total loss': 0.482797155326063} | train loss {'Reaction outcome loss': 0.47938005764397884, 'Total loss': 0.47938005764397884}
2022-11-28 04:15:02,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:02,243 INFO:     Epoch: 22
2022-11-28 04:15:02,906 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5100495439361442, 'Total loss': 0.5100495439361442} | train loss {'Reaction outcome loss': 0.47666265575155137, 'Total loss': 0.47666265575155137}
2022-11-28 04:15:02,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:02,906 INFO:     Epoch: 23
2022-11-28 04:15:03,566 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.488157680766149, 'Total loss': 0.488157680766149} | train loss {'Reaction outcome loss': 0.4895136819611634, 'Total loss': 0.4895136819611634}
2022-11-28 04:15:03,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:03,567 INFO:     Epoch: 24
2022-11-28 04:15:04,231 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4808293960311196, 'Total loss': 0.4808293960311196} | train loss {'Reaction outcome loss': 0.4807630821822151, 'Total loss': 0.4807630821822151}
2022-11-28 04:15:04,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:04,231 INFO:     Epoch: 25
2022-11-28 04:15:04,893 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46978000788526103, 'Total loss': 0.46978000788526103} | train loss {'Reaction outcome loss': 0.47999004773314924, 'Total loss': 0.47999004773314924}
2022-11-28 04:15:04,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:04,893 INFO:     Epoch: 26
2022-11-28 04:15:05,555 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4698495404286818, 'Total loss': 0.4698495404286818} | train loss {'Reaction outcome loss': 0.4857020468240784, 'Total loss': 0.4857020468240784}
2022-11-28 04:15:05,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:05,555 INFO:     Epoch: 27
2022-11-28 04:15:06,216 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46432122215628624, 'Total loss': 0.46432122215628624} | train loss {'Reaction outcome loss': 0.48350813768563733, 'Total loss': 0.48350813768563733}
2022-11-28 04:15:06,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:06,216 INFO:     Epoch: 28
2022-11-28 04:15:06,875 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44634150341153145, 'Total loss': 0.44634150341153145} | train loss {'Reaction outcome loss': 0.4806416239589453, 'Total loss': 0.4806416239589453}
2022-11-28 04:15:06,875 INFO:     Found new best model at epoch 28
2022-11-28 04:15:06,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:06,876 INFO:     Epoch: 29
2022-11-28 04:15:07,538 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5070111460306428, 'Total loss': 0.5070111460306428} | train loss {'Reaction outcome loss': 0.4827281896085028, 'Total loss': 0.4827281896085028}
2022-11-28 04:15:07,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:07,539 INFO:     Epoch: 30
2022-11-28 04:15:08,201 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4977566000412811, 'Total loss': 0.4977566000412811} | train loss {'Reaction outcome loss': 0.47832855480092185, 'Total loss': 0.47832855480092185}
2022-11-28 04:15:08,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:08,201 INFO:     Epoch: 31
2022-11-28 04:15:08,862 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4763616252351891, 'Total loss': 0.4763616252351891} | train loss {'Reaction outcome loss': 0.47852861959367027, 'Total loss': 0.47852861959367027}
2022-11-28 04:15:08,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:08,863 INFO:     Epoch: 32
2022-11-28 04:15:09,523 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46849083494056354, 'Total loss': 0.46849083494056354} | train loss {'Reaction outcome loss': 0.4856293645477103, 'Total loss': 0.4856293645477103}
2022-11-28 04:15:09,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:09,523 INFO:     Epoch: 33
2022-11-28 04:15:10,188 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4929891072890975, 'Total loss': 0.4929891072890975} | train loss {'Reaction outcome loss': 0.471134762489988, 'Total loss': 0.471134762489988}
2022-11-28 04:15:10,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:10,189 INFO:     Epoch: 34
2022-11-28 04:15:10,854 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.474071396345442, 'Total loss': 0.474071396345442} | train loss {'Reaction outcome loss': 0.4837913463613199, 'Total loss': 0.4837913463613199}
2022-11-28 04:15:10,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:10,854 INFO:     Epoch: 35
2022-11-28 04:15:11,517 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48341094533150847, 'Total loss': 0.48341094533150847} | train loss {'Reaction outcome loss': 0.4714012059473222, 'Total loss': 0.4714012059473222}
2022-11-28 04:15:11,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:11,517 INFO:     Epoch: 36
2022-11-28 04:15:12,180 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49341655895113945, 'Total loss': 0.49341655895113945} | train loss {'Reaction outcome loss': 0.4743798815254723, 'Total loss': 0.4743798815254723}
2022-11-28 04:15:12,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:12,180 INFO:     Epoch: 37
2022-11-28 04:15:12,845 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44831323555924674, 'Total loss': 0.44831323555924674} | train loss {'Reaction outcome loss': 0.48315677912004534, 'Total loss': 0.48315677912004534}
2022-11-28 04:15:12,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:12,845 INFO:     Epoch: 38
2022-11-28 04:15:13,507 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4488520043140108, 'Total loss': 0.4488520043140108} | train loss {'Reaction outcome loss': 0.4750689789051971, 'Total loss': 0.4750689789051971}
2022-11-28 04:15:13,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:13,507 INFO:     Epoch: 39
2022-11-28 04:15:14,168 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47666228460994636, 'Total loss': 0.47666228460994636} | train loss {'Reaction outcome loss': 0.4688222202802858, 'Total loss': 0.4688222202802858}
2022-11-28 04:15:14,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:14,169 INFO:     Epoch: 40
2022-11-28 04:15:14,830 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44983676279133017, 'Total loss': 0.44983676279133017} | train loss {'Reaction outcome loss': 0.4735468651258176, 'Total loss': 0.4735468651258176}
2022-11-28 04:15:14,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:14,830 INFO:     Epoch: 41
2022-11-28 04:15:15,494 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46236679432067, 'Total loss': 0.46236679432067} | train loss {'Reaction outcome loss': 0.47700666257691, 'Total loss': 0.47700666257691}
2022-11-28 04:15:15,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:15,494 INFO:     Epoch: 42
2022-11-28 04:15:16,158 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46250122582370584, 'Total loss': 0.46250122582370584} | train loss {'Reaction outcome loss': 0.466564470481488, 'Total loss': 0.466564470481488}
2022-11-28 04:15:16,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:16,158 INFO:     Epoch: 43
2022-11-28 04:15:16,820 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48886316405101254, 'Total loss': 0.48886316405101254} | train loss {'Reaction outcome loss': 0.472272356912013, 'Total loss': 0.472272356912013}
2022-11-28 04:15:16,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:16,820 INFO:     Epoch: 44
2022-11-28 04:15:17,483 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4871050210838968, 'Total loss': 0.4871050210838968} | train loss {'Reaction outcome loss': 0.4750376984837555, 'Total loss': 0.4750376984837555}
2022-11-28 04:15:17,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:17,483 INFO:     Epoch: 45
2022-11-28 04:15:18,144 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.460928927091035, 'Total loss': 0.460928927091035} | train loss {'Reaction outcome loss': 0.4686802479047929, 'Total loss': 0.4686802479047929}
2022-11-28 04:15:18,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:18,144 INFO:     Epoch: 46
2022-11-28 04:15:18,807 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4857317761264064, 'Total loss': 0.4857317761264064} | train loss {'Reaction outcome loss': 0.4702305139733418, 'Total loss': 0.4702305139733418}
2022-11-28 04:15:18,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:18,807 INFO:     Epoch: 47
2022-11-28 04:15:19,472 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5107922164553945, 'Total loss': 0.5107922164553945} | train loss {'Reaction outcome loss': 0.47080172658447295, 'Total loss': 0.47080172658447295}
2022-11-28 04:15:19,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:19,473 INFO:     Epoch: 48
2022-11-28 04:15:20,136 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46039029786532576, 'Total loss': 0.46039029786532576} | train loss {'Reaction outcome loss': 0.47400527750892985, 'Total loss': 0.47400527750892985}
2022-11-28 04:15:20,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:20,136 INFO:     Epoch: 49
2022-11-28 04:15:20,795 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46037778935649176, 'Total loss': 0.46037778935649176} | train loss {'Reaction outcome loss': 0.4662298742201059, 'Total loss': 0.4662298742201059}
2022-11-28 04:15:20,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:20,795 INFO:     Epoch: 50
2022-11-28 04:15:21,458 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4757563465020873, 'Total loss': 0.4757563465020873} | train loss {'Reaction outcome loss': 0.4732264434137652, 'Total loss': 0.4732264434137652}
2022-11-28 04:15:21,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:21,458 INFO:     Epoch: 51
2022-11-28 04:15:22,118 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4604826071722941, 'Total loss': 0.4604826071722941} | train loss {'Reaction outcome loss': 0.46251688428944154, 'Total loss': 0.46251688428944154}
2022-11-28 04:15:22,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:22,118 INFO:     Epoch: 52
2022-11-28 04:15:22,778 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4796184274283322, 'Total loss': 0.4796184274283322} | train loss {'Reaction outcome loss': 0.47761196390755717, 'Total loss': 0.47761196390755717}
2022-11-28 04:15:22,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:22,779 INFO:     Epoch: 53
2022-11-28 04:15:23,443 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46916402503848076, 'Total loss': 0.46916402503848076} | train loss {'Reaction outcome loss': 0.4672020981989561, 'Total loss': 0.4672020981989561}
2022-11-28 04:15:23,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:23,443 INFO:     Epoch: 54
2022-11-28 04:15:24,102 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5156029713424769, 'Total loss': 0.5156029713424769} | train loss {'Reaction outcome loss': 0.46530772799686076, 'Total loss': 0.46530772799686076}
2022-11-28 04:15:24,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:24,102 INFO:     Epoch: 55
2022-11-28 04:15:24,760 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4704873568632386, 'Total loss': 0.4704873568632386} | train loss {'Reaction outcome loss': 0.47491492877804464, 'Total loss': 0.47491492877804464}
2022-11-28 04:15:24,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:24,761 INFO:     Epoch: 56
2022-11-28 04:15:25,421 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47588689997792244, 'Total loss': 0.47588689997792244} | train loss {'Reaction outcome loss': 0.4795405377423571, 'Total loss': 0.4795405377423571}
2022-11-28 04:15:25,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:25,421 INFO:     Epoch: 57
2022-11-28 04:15:26,083 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49765164303508674, 'Total loss': 0.49765164303508674} | train loss {'Reaction outcome loss': 0.4714495405074089, 'Total loss': 0.4714495405074089}
2022-11-28 04:15:26,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:26,084 INFO:     Epoch: 58
2022-11-28 04:15:26,745 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46147898076610133, 'Total loss': 0.46147898076610133} | train loss {'Reaction outcome loss': 0.47241075282856343, 'Total loss': 0.47241075282856343}
2022-11-28 04:15:26,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:26,746 INFO:     Epoch: 59
2022-11-28 04:15:27,407 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46404382146217604, 'Total loss': 0.46404382146217604} | train loss {'Reaction outcome loss': 0.4677803162485361, 'Total loss': 0.4677803162485361}
2022-11-28 04:15:27,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:27,408 INFO:     Epoch: 60
2022-11-28 04:15:28,067 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4527763192626563, 'Total loss': 0.4527763192626563} | train loss {'Reaction outcome loss': 0.4695342610019349, 'Total loss': 0.4695342610019349}
2022-11-28 04:15:28,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:28,067 INFO:     Epoch: 61
2022-11-28 04:15:28,727 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49363928186622535, 'Total loss': 0.49363928186622535} | train loss {'Reaction outcome loss': 0.4728533287322329, 'Total loss': 0.4728533287322329}
2022-11-28 04:15:28,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:28,727 INFO:     Epoch: 62
2022-11-28 04:15:29,386 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4678293544460427, 'Total loss': 0.4678293544460427} | train loss {'Reaction outcome loss': 0.47374234672996307, 'Total loss': 0.47374234672996307}
2022-11-28 04:15:29,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:29,387 INFO:     Epoch: 63
2022-11-28 04:15:30,049 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4870096214792945, 'Total loss': 0.4870096214792945} | train loss {'Reaction outcome loss': 0.46825310912343765, 'Total loss': 0.46825310912343765}
2022-11-28 04:15:30,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:30,050 INFO:     Epoch: 64
2022-11-28 04:15:30,709 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48658382960341195, 'Total loss': 0.48658382960341195} | train loss {'Reaction outcome loss': 0.461529805565313, 'Total loss': 0.461529805565313}
2022-11-28 04:15:30,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:30,709 INFO:     Epoch: 65
2022-11-28 04:15:31,369 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5045237161896445, 'Total loss': 0.5045237161896445} | train loss {'Reaction outcome loss': 0.47171919092896486, 'Total loss': 0.47171919092896486}
2022-11-28 04:15:31,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:31,369 INFO:     Epoch: 66
2022-11-28 04:15:32,028 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4439384998245673, 'Total loss': 0.4439384998245673} | train loss {'Reaction outcome loss': 0.4738168140512801, 'Total loss': 0.4738168140512801}
2022-11-28 04:15:32,029 INFO:     Found new best model at epoch 66
2022-11-28 04:15:32,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:32,029 INFO:     Epoch: 67
2022-11-28 04:15:32,689 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4650989462706176, 'Total loss': 0.4650989462706176} | train loss {'Reaction outcome loss': 0.4753494132310152, 'Total loss': 0.4753494132310152}
2022-11-28 04:15:32,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:32,689 INFO:     Epoch: 68
2022-11-28 04:15:33,348 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4493727734820409, 'Total loss': 0.4493727734820409} | train loss {'Reaction outcome loss': 0.4659960939578952, 'Total loss': 0.4659960939578952}
2022-11-28 04:15:33,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:33,349 INFO:     Epoch: 69
2022-11-28 04:15:34,008 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45949741114269604, 'Total loss': 0.45949741114269604} | train loss {'Reaction outcome loss': 0.4703592432422503, 'Total loss': 0.4703592432422503}
2022-11-28 04:15:34,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:34,008 INFO:     Epoch: 70
2022-11-28 04:15:34,664 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46126497265967453, 'Total loss': 0.46126497265967453} | train loss {'Reaction outcome loss': 0.47110617172814184, 'Total loss': 0.47110617172814184}
2022-11-28 04:15:34,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:34,664 INFO:     Epoch: 71
2022-11-28 04:15:35,324 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4603735577653755, 'Total loss': 0.4603735577653755} | train loss {'Reaction outcome loss': 0.47448626358903223, 'Total loss': 0.47448626358903223}
2022-11-28 04:15:35,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:35,324 INFO:     Epoch: 72
2022-11-28 04:15:35,984 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5034184943545948, 'Total loss': 0.5034184943545948} | train loss {'Reaction outcome loss': 0.46534179493544564, 'Total loss': 0.46534179493544564}
2022-11-28 04:15:35,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:35,984 INFO:     Epoch: 73
2022-11-28 04:15:36,644 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44495087692683394, 'Total loss': 0.44495087692683394} | train loss {'Reaction outcome loss': 0.46684774546132934, 'Total loss': 0.46684774546132934}
2022-11-28 04:15:36,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:36,644 INFO:     Epoch: 74
2022-11-28 04:15:37,309 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4795739643953063, 'Total loss': 0.4795739643953063} | train loss {'Reaction outcome loss': 0.4676876015240146, 'Total loss': 0.4676876015240146}
2022-11-28 04:15:37,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:37,309 INFO:     Epoch: 75
2022-11-28 04:15:37,970 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4847032143311067, 'Total loss': 0.4847032143311067} | train loss {'Reaction outcome loss': 0.46566795245293646, 'Total loss': 0.46566795245293646}
2022-11-28 04:15:37,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:37,971 INFO:     Epoch: 76
2022-11-28 04:15:38,634 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4463151943954555, 'Total loss': 0.4463151943954555} | train loss {'Reaction outcome loss': 0.472950255858802, 'Total loss': 0.472950255858802}
2022-11-28 04:15:38,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:38,634 INFO:     Epoch: 77
2022-11-28 04:15:39,295 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4463514827869155, 'Total loss': 0.4463514827869155} | train loss {'Reaction outcome loss': 0.46500789446215474, 'Total loss': 0.46500789446215474}
2022-11-28 04:15:39,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:39,295 INFO:     Epoch: 78
2022-11-28 04:15:39,958 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4513202052224766, 'Total loss': 0.4513202052224766} | train loss {'Reaction outcome loss': 0.471325377663297, 'Total loss': 0.471325377663297}
2022-11-28 04:15:39,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:39,958 INFO:     Epoch: 79
2022-11-28 04:15:40,619 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4560312127525156, 'Total loss': 0.4560312127525156} | train loss {'Reaction outcome loss': 0.46789303082492084, 'Total loss': 0.46789303082492084}
2022-11-28 04:15:40,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:40,619 INFO:     Epoch: 80
2022-11-28 04:15:41,282 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4550547670911659, 'Total loss': 0.4550547670911659} | train loss {'Reaction outcome loss': 0.462674317520953, 'Total loss': 0.462674317520953}
2022-11-28 04:15:41,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:41,282 INFO:     Epoch: 81
2022-11-28 04:15:41,943 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48451501774516975, 'Total loss': 0.48451501774516975} | train loss {'Reaction outcome loss': 0.46511495086334403, 'Total loss': 0.46511495086334403}
2022-11-28 04:15:41,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:41,943 INFO:     Epoch: 82
2022-11-28 04:15:42,599 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4963519176976247, 'Total loss': 0.4963519176976247} | train loss {'Reaction outcome loss': 0.46219507706982477, 'Total loss': 0.46219507706982477}
2022-11-28 04:15:42,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:42,600 INFO:     Epoch: 83
2022-11-28 04:15:43,257 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4530511661009355, 'Total loss': 0.4530511661009355} | train loss {'Reaction outcome loss': 0.46641674487581175, 'Total loss': 0.46641674487581175}
2022-11-28 04:15:43,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:43,258 INFO:     Epoch: 84
2022-11-28 04:15:43,921 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4593376073647629, 'Total loss': 0.4593376073647629} | train loss {'Reaction outcome loss': 0.4629509168406648, 'Total loss': 0.4629509168406648}
2022-11-28 04:15:43,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:43,921 INFO:     Epoch: 85
2022-11-28 04:15:44,585 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5252479761838913, 'Total loss': 0.5252479761838913} | train loss {'Reaction outcome loss': 0.4620894595019279, 'Total loss': 0.4620894595019279}
2022-11-28 04:15:44,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:44,586 INFO:     Epoch: 86
2022-11-28 04:15:45,243 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4606776941906322, 'Total loss': 0.4606776941906322} | train loss {'Reaction outcome loss': 0.4624841289835111, 'Total loss': 0.4624841289835111}
2022-11-28 04:15:45,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:45,244 INFO:     Epoch: 87
2022-11-28 04:15:45,907 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4795810194178061, 'Total loss': 0.4795810194178061} | train loss {'Reaction outcome loss': 0.464965098687718, 'Total loss': 0.464965098687718}
2022-11-28 04:15:45,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:45,907 INFO:     Epoch: 88
2022-11-28 04:15:46,571 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47892410545186564, 'Total loss': 0.47892410545186564} | train loss {'Reaction outcome loss': 0.47809697952001323, 'Total loss': 0.47809697952001323}
2022-11-28 04:15:46,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:46,571 INFO:     Epoch: 89
2022-11-28 04:15:47,230 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.490071662786332, 'Total loss': 0.490071662786332} | train loss {'Reaction outcome loss': 0.46071344992566493, 'Total loss': 0.46071344992566493}
2022-11-28 04:15:47,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:47,230 INFO:     Epoch: 90
2022-11-28 04:15:47,889 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4430597102777524, 'Total loss': 0.4430597102777524} | train loss {'Reaction outcome loss': 0.4652446527334471, 'Total loss': 0.4652446527334471}
2022-11-28 04:15:47,890 INFO:     Found new best model at epoch 90
2022-11-28 04:15:47,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:47,890 INFO:     Epoch: 91
2022-11-28 04:15:48,550 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4473067030987956, 'Total loss': 0.4473067030987956} | train loss {'Reaction outcome loss': 0.4690481727762568, 'Total loss': 0.4690481727762568}
2022-11-28 04:15:48,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:48,550 INFO:     Epoch: 92
2022-11-28 04:15:49,212 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5161896483464674, 'Total loss': 0.5161896483464674} | train loss {'Reaction outcome loss': 0.46758628630590054, 'Total loss': 0.46758628630590054}
2022-11-28 04:15:49,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:49,212 INFO:     Epoch: 93
2022-11-28 04:15:49,871 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46241278743202036, 'Total loss': 0.46241278743202036} | train loss {'Reaction outcome loss': 0.4680668080766355, 'Total loss': 0.4680668080766355}
2022-11-28 04:15:49,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:49,872 INFO:     Epoch: 94
2022-11-28 04:15:50,532 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48485451530326495, 'Total loss': 0.48485451530326495} | train loss {'Reaction outcome loss': 0.46455024525282845, 'Total loss': 0.46455024525282845}
2022-11-28 04:15:50,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:50,532 INFO:     Epoch: 95
2022-11-28 04:15:51,193 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4552038569342006, 'Total loss': 0.4552038569342006} | train loss {'Reaction outcome loss': 0.4788491248243278, 'Total loss': 0.4788491248243278}
2022-11-28 04:15:51,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:51,193 INFO:     Epoch: 96
2022-11-28 04:15:51,852 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4614371376281435, 'Total loss': 0.4614371376281435} | train loss {'Reaction outcome loss': 0.47343076975835907, 'Total loss': 0.47343076975835907}
2022-11-28 04:15:51,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:51,852 INFO:     Epoch: 97
2022-11-28 04:15:52,508 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4794449338858778, 'Total loss': 0.4794449338858778} | train loss {'Reaction outcome loss': 0.47076192462155897, 'Total loss': 0.47076192462155897}
2022-11-28 04:15:52,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:52,508 INFO:     Epoch: 98
2022-11-28 04:15:53,169 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5035727701403878, 'Total loss': 0.5035727701403878} | train loss {'Reaction outcome loss': 0.47684994021490695, 'Total loss': 0.47684994021490695}
2022-11-28 04:15:53,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:53,169 INFO:     Epoch: 99
2022-11-28 04:15:53,828 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49059303172610025, 'Total loss': 0.49059303172610025} | train loss {'Reaction outcome loss': 0.4760015843315951, 'Total loss': 0.4760015843315951}
2022-11-28 04:15:53,828 INFO:     Best model found after epoch 91 of 100.
2022-11-28 04:15:53,828 INFO:   Done with stage: TRAINING
2022-11-28 04:15:53,828 INFO:   Starting stage: EVALUATION
2022-11-28 04:15:53,942 INFO:   Done with stage: EVALUATION
2022-11-28 04:15:53,942 INFO:   Leaving out SEQ value Fold_5
2022-11-28 04:15:53,955 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:15:53,955 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:15:54,611 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:15:54,611 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:15:54,679 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:15:54,679 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:15:54,679 INFO:     No hyperparam tuning for this model
2022-11-28 04:15:54,679 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:15:54,679 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:15:54,680 INFO:     None feature selector for col prot
2022-11-28 04:15:54,680 INFO:     None feature selector for col prot
2022-11-28 04:15:54,680 INFO:     None feature selector for col prot
2022-11-28 04:15:54,681 INFO:     None feature selector for col chem
2022-11-28 04:15:54,681 INFO:     None feature selector for col chem
2022-11-28 04:15:54,681 INFO:     None feature selector for col chem
2022-11-28 04:15:54,681 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:15:54,681 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:15:54,683 INFO:     Number of params in model 169651
2022-11-28 04:15:54,686 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:15:54,686 INFO:   Starting stage: TRAINING
2022-11-28 04:15:54,737 INFO:     Val loss before train {'Reaction outcome loss': 1.0577453767711467, 'Total loss': 1.0577453767711467}
2022-11-28 04:15:54,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:54,738 INFO:     Epoch: 0
2022-11-28 04:15:55,394 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6052182181314989, 'Total loss': 0.6052182181314989} | train loss {'Reaction outcome loss': 0.6751770801721555, 'Total loss': 0.6751770801721555}
2022-11-28 04:15:55,394 INFO:     Found new best model at epoch 0
2022-11-28 04:15:55,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:55,395 INFO:     Epoch: 1
2022-11-28 04:15:56,045 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6355217566544359, 'Total loss': 0.6355217566544359} | train loss {'Reaction outcome loss': 0.5723394603743727, 'Total loss': 0.5723394603743727}
2022-11-28 04:15:56,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:56,046 INFO:     Epoch: 2
2022-11-28 04:15:56,700 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5540770580145445, 'Total loss': 0.5540770580145445} | train loss {'Reaction outcome loss': 0.5429850815972577, 'Total loss': 0.5429850815972577}
2022-11-28 04:15:56,700 INFO:     Found new best model at epoch 2
2022-11-28 04:15:56,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:56,701 INFO:     Epoch: 3
2022-11-28 04:15:57,355 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.515734041956338, 'Total loss': 0.515734041956338} | train loss {'Reaction outcome loss': 0.52778173174694, 'Total loss': 0.52778173174694}
2022-11-28 04:15:57,355 INFO:     Found new best model at epoch 3
2022-11-28 04:15:57,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:57,356 INFO:     Epoch: 4
2022-11-28 04:15:58,012 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5394855493848975, 'Total loss': 0.5394855493848975} | train loss {'Reaction outcome loss': 0.509252332754222, 'Total loss': 0.509252332754222}
2022-11-28 04:15:58,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:58,012 INFO:     Epoch: 5
2022-11-28 04:15:58,668 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.507388299331069, 'Total loss': 0.507388299331069} | train loss {'Reaction outcome loss': 0.5042693447849529, 'Total loss': 0.5042693447849529}
2022-11-28 04:15:58,668 INFO:     Found new best model at epoch 5
2022-11-28 04:15:58,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:58,669 INFO:     Epoch: 6
2022-11-28 04:15:59,326 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5228533500974829, 'Total loss': 0.5228533500974829} | train loss {'Reaction outcome loss': 0.49281557282877836, 'Total loss': 0.49281557282877836}
2022-11-28 04:15:59,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:59,326 INFO:     Epoch: 7
2022-11-28 04:15:59,983 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5476937917145815, 'Total loss': 0.5476937917145815} | train loss {'Reaction outcome loss': 0.4811119906197072, 'Total loss': 0.4811119906197072}
2022-11-28 04:15:59,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:15:59,983 INFO:     Epoch: 8
2022-11-28 04:16:00,638 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.519921502945098, 'Total loss': 0.519921502945098} | train loss {'Reaction outcome loss': 0.49248533614492607, 'Total loss': 0.49248533614492607}
2022-11-28 04:16:00,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:00,638 INFO:     Epoch: 9
2022-11-28 04:16:01,294 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5163658813319423, 'Total loss': 0.5163658813319423} | train loss {'Reaction outcome loss': 0.4984005433224473, 'Total loss': 0.4984005433224473}
2022-11-28 04:16:01,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:01,294 INFO:     Epoch: 10
2022-11-28 04:16:01,951 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5186377154155211, 'Total loss': 0.5186377154155211} | train loss {'Reaction outcome loss': 0.4834683329802052, 'Total loss': 0.4834683329802052}
2022-11-28 04:16:01,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:01,952 INFO:     Epoch: 11
2022-11-28 04:16:02,608 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.513387824662707, 'Total loss': 0.513387824662707} | train loss {'Reaction outcome loss': 0.4731727652100899, 'Total loss': 0.4731727652100899}
2022-11-28 04:16:02,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:02,608 INFO:     Epoch: 12
2022-11-28 04:16:03,268 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.505043129352006, 'Total loss': 0.505043129352006} | train loss {'Reaction outcome loss': 0.4712605093028924, 'Total loss': 0.4712605093028924}
2022-11-28 04:16:03,268 INFO:     Found new best model at epoch 12
2022-11-28 04:16:03,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:03,269 INFO:     Epoch: 13
2022-11-28 04:16:03,927 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5285195146094669, 'Total loss': 0.5285195146094669} | train loss {'Reaction outcome loss': 0.45966462827163185, 'Total loss': 0.45966462827163185}
2022-11-28 04:16:03,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:03,927 INFO:     Epoch: 14
2022-11-28 04:16:04,587 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.533544674854387, 'Total loss': 0.533544674854387} | train loss {'Reaction outcome loss': 0.47744058512965676, 'Total loss': 0.47744058512965676}
2022-11-28 04:16:04,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:04,587 INFO:     Epoch: 15
2022-11-28 04:16:05,250 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5780004919929937, 'Total loss': 0.5780004919929937} | train loss {'Reaction outcome loss': 0.46810828463027354, 'Total loss': 0.46810828463027354}
2022-11-28 04:16:05,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:05,250 INFO:     Epoch: 16
2022-11-28 04:16:05,912 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5156002515418963, 'Total loss': 0.5156002515418963} | train loss {'Reaction outcome loss': 0.46918338887121996, 'Total loss': 0.46918338887121996}
2022-11-28 04:16:05,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:05,912 INFO:     Epoch: 17
2022-11-28 04:16:06,570 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4849477264691483, 'Total loss': 0.4849477264691483} | train loss {'Reaction outcome loss': 0.4686731425555129, 'Total loss': 0.4686731425555129}
2022-11-28 04:16:06,571 INFO:     Found new best model at epoch 17
2022-11-28 04:16:06,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:06,571 INFO:     Epoch: 18
2022-11-28 04:16:07,230 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5211590887470678, 'Total loss': 0.5211590887470678} | train loss {'Reaction outcome loss': 0.4674418743262407, 'Total loss': 0.4674418743262407}
2022-11-28 04:16:07,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:07,230 INFO:     Epoch: 19
2022-11-28 04:16:07,888 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5117445112290707, 'Total loss': 0.5117445112290707} | train loss {'Reaction outcome loss': 0.4672179989184928, 'Total loss': 0.4672179989184928}
2022-11-28 04:16:07,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:07,889 INFO:     Epoch: 20
2022-11-28 04:16:08,547 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5001221800392325, 'Total loss': 0.5001221800392325} | train loss {'Reaction outcome loss': 0.465042716337119, 'Total loss': 0.465042716337119}
2022-11-28 04:16:08,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:08,548 INFO:     Epoch: 21
2022-11-28 04:16:09,208 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.522624248130755, 'Total loss': 0.522624248130755} | train loss {'Reaction outcome loss': 0.46699343531237925, 'Total loss': 0.46699343531237925}
2022-11-28 04:16:09,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:09,209 INFO:     Epoch: 22
2022-11-28 04:16:09,868 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5597704262896017, 'Total loss': 0.5597704262896017} | train loss {'Reaction outcome loss': 0.45601217243594194, 'Total loss': 0.45601217243594194}
2022-11-28 04:16:09,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:09,868 INFO:     Epoch: 23
2022-11-28 04:16:10,529 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.6174333888021383, 'Total loss': 0.6174333888021383} | train loss {'Reaction outcome loss': 0.4705170747722209, 'Total loss': 0.4705170747722209}
2022-11-28 04:16:10,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:10,529 INFO:     Epoch: 24
2022-11-28 04:16:11,189 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5665634779090231, 'Total loss': 0.5665634779090231} | train loss {'Reaction outcome loss': 0.47476665559507575, 'Total loss': 0.47476665559507575}
2022-11-28 04:16:11,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:11,189 INFO:     Epoch: 25
2022-11-28 04:16:11,846 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.506998149170117, 'Total loss': 0.506998149170117} | train loss {'Reaction outcome loss': 0.4559437183866858, 'Total loss': 0.4559437183866858}
2022-11-28 04:16:11,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:11,846 INFO:     Epoch: 26
2022-11-28 04:16:12,505 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4937575256282633, 'Total loss': 0.4937575256282633} | train loss {'Reaction outcome loss': 0.45738726444089944, 'Total loss': 0.45738726444089944}
2022-11-28 04:16:12,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:12,506 INFO:     Epoch: 27
2022-11-28 04:16:13,166 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48928968100385234, 'Total loss': 0.48928968100385234} | train loss {'Reaction outcome loss': 0.4544165587799269, 'Total loss': 0.4544165587799269}
2022-11-28 04:16:13,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:13,166 INFO:     Epoch: 28
2022-11-28 04:16:13,830 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5394515205513347, 'Total loss': 0.5394515205513347} | train loss {'Reaction outcome loss': 0.4585780188863577, 'Total loss': 0.4585780188863577}
2022-11-28 04:16:13,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:13,830 INFO:     Epoch: 29
2022-11-28 04:16:14,490 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5118090500208464, 'Total loss': 0.5118090500208464} | train loss {'Reaction outcome loss': 0.46166464647180155, 'Total loss': 0.46166464647180155}
2022-11-28 04:16:14,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:14,491 INFO:     Epoch: 30
2022-11-28 04:16:15,149 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.496815061704679, 'Total loss': 0.496815061704679} | train loss {'Reaction outcome loss': 0.45668692784836357, 'Total loss': 0.45668692784836357}
2022-11-28 04:16:15,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:15,149 INFO:     Epoch: 31
2022-11-28 04:16:15,809 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5098285112868656, 'Total loss': 0.5098285112868656} | train loss {'Reaction outcome loss': 0.4582607574791078, 'Total loss': 0.4582607574791078}
2022-11-28 04:16:15,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:15,810 INFO:     Epoch: 32
2022-11-28 04:16:16,472 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.531039722263813, 'Total loss': 0.531039722263813} | train loss {'Reaction outcome loss': 0.46419363594161506, 'Total loss': 0.46419363594161506}
2022-11-28 04:16:16,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:16,472 INFO:     Epoch: 33
2022-11-28 04:16:17,133 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5131888125430454, 'Total loss': 0.5131888125430454} | train loss {'Reaction outcome loss': 0.45749521300739604, 'Total loss': 0.45749521300739604}
2022-11-28 04:16:17,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:17,134 INFO:     Epoch: 34
2022-11-28 04:16:17,794 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5145343189889734, 'Total loss': 0.5145343189889734} | train loss {'Reaction outcome loss': 0.4642175986122355, 'Total loss': 0.4642175986122355}
2022-11-28 04:16:17,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:17,794 INFO:     Epoch: 35
2022-11-28 04:16:18,455 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5281264490701936, 'Total loss': 0.5281264490701936} | train loss {'Reaction outcome loss': 0.45678455216681907, 'Total loss': 0.45678455216681907}
2022-11-28 04:16:18,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:18,455 INFO:     Epoch: 36
2022-11-28 04:16:19,112 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5352462540295991, 'Total loss': 0.5352462540295991} | train loss {'Reaction outcome loss': 0.47829095035912056, 'Total loss': 0.47829095035912056}
2022-11-28 04:16:19,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:19,112 INFO:     Epoch: 37
2022-11-28 04:16:19,773 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48944510925899853, 'Total loss': 0.48944510925899853} | train loss {'Reaction outcome loss': 0.46476849109153096, 'Total loss': 0.46476849109153096}
2022-11-28 04:16:19,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:19,773 INFO:     Epoch: 38
2022-11-28 04:16:20,435 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5257474749603055, 'Total loss': 0.5257474749603055} | train loss {'Reaction outcome loss': 0.45335511205650053, 'Total loss': 0.45335511205650053}
2022-11-28 04:16:20,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:20,435 INFO:     Epoch: 39
2022-11-28 04:16:21,097 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5300662341442975, 'Total loss': 0.5300662341442975} | train loss {'Reaction outcome loss': 0.4614854924652258, 'Total loss': 0.4614854924652258}
2022-11-28 04:16:21,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:21,097 INFO:     Epoch: 40
2022-11-28 04:16:21,756 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5358438837257299, 'Total loss': 0.5358438837257299} | train loss {'Reaction outcome loss': 0.4899881786783697, 'Total loss': 0.4899881786783697}
2022-11-28 04:16:21,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:21,756 INFO:     Epoch: 41
2022-11-28 04:16:22,416 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.491752607578581, 'Total loss': 0.491752607578581} | train loss {'Reaction outcome loss': 0.46843179535527946, 'Total loss': 0.46843179535527946}
2022-11-28 04:16:22,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:22,416 INFO:     Epoch: 42
2022-11-28 04:16:23,077 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5230848741802302, 'Total loss': 0.5230848741802302} | train loss {'Reaction outcome loss': 0.46575801810513623, 'Total loss': 0.46575801810513623}
2022-11-28 04:16:23,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:23,077 INFO:     Epoch: 43
2022-11-28 04:16:23,733 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5647740546952594, 'Total loss': 0.5647740546952594} | train loss {'Reaction outcome loss': 0.49292820689045946, 'Total loss': 0.49292820689045946}
2022-11-28 04:16:23,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:23,734 INFO:     Epoch: 44
2022-11-28 04:16:24,391 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4811954159628261, 'Total loss': 0.4811954159628261} | train loss {'Reaction outcome loss': 0.46062539976376754, 'Total loss': 0.46062539976376754}
2022-11-28 04:16:24,391 INFO:     Found new best model at epoch 44
2022-11-28 04:16:24,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:24,392 INFO:     Epoch: 45
2022-11-28 04:16:25,049 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5109708109362558, 'Total loss': 0.5109708109362558} | train loss {'Reaction outcome loss': 0.4515175093040775, 'Total loss': 0.4515175093040775}
2022-11-28 04:16:25,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:25,049 INFO:     Epoch: 46
2022-11-28 04:16:25,711 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5412429097023878, 'Total loss': 0.5412429097023878} | train loss {'Reaction outcome loss': 0.46026015278660815, 'Total loss': 0.46026015278660815}
2022-11-28 04:16:25,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:25,711 INFO:     Epoch: 47
2022-11-28 04:16:26,369 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5852107852697372, 'Total loss': 0.5852107852697372} | train loss {'Reaction outcome loss': 0.4659200421711694, 'Total loss': 0.4659200421711694}
2022-11-28 04:16:26,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:26,369 INFO:     Epoch: 48
2022-11-28 04:16:27,028 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5246951905163851, 'Total loss': 0.5246951905163851} | train loss {'Reaction outcome loss': 0.4649353493080448, 'Total loss': 0.4649353493080448}
2022-11-28 04:16:27,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:27,029 INFO:     Epoch: 49
2022-11-28 04:16:27,684 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5121839405460791, 'Total loss': 0.5121839405460791} | train loss {'Reaction outcome loss': 0.45310503549059394, 'Total loss': 0.45310503549059394}
2022-11-28 04:16:27,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:27,684 INFO:     Epoch: 50
2022-11-28 04:16:28,337 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5012368139895526, 'Total loss': 0.5012368139895526} | train loss {'Reaction outcome loss': 0.4516839174485882, 'Total loss': 0.4516839174485882}
2022-11-28 04:16:28,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:28,338 INFO:     Epoch: 51
2022-11-28 04:16:28,996 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5119708752767607, 'Total loss': 0.5119708752767607} | train loss {'Reaction outcome loss': 0.45615400692169, 'Total loss': 0.45615400692169}
2022-11-28 04:16:28,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:28,997 INFO:     Epoch: 52
2022-11-28 04:16:29,654 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5068294927477837, 'Total loss': 0.5068294927477837} | train loss {'Reaction outcome loss': 0.45208217773722253, 'Total loss': 0.45208217773722253}
2022-11-28 04:16:29,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:29,654 INFO:     Epoch: 53
2022-11-28 04:16:30,312 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5478266497904604, 'Total loss': 0.5478266497904604} | train loss {'Reaction outcome loss': 0.45244355415284393, 'Total loss': 0.45244355415284393}
2022-11-28 04:16:30,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:30,312 INFO:     Epoch: 54
2022-11-28 04:16:30,970 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5427005798979239, 'Total loss': 0.5427005798979239} | train loss {'Reaction outcome loss': 0.4589149161027028, 'Total loss': 0.4589149161027028}
2022-11-28 04:16:30,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:30,970 INFO:     Epoch: 55
2022-11-28 04:16:31,631 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.520757257938385, 'Total loss': 0.520757257938385} | train loss {'Reaction outcome loss': 0.4596860919162812, 'Total loss': 0.4596860919162812}
2022-11-28 04:16:31,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:31,631 INFO:     Epoch: 56
2022-11-28 04:16:32,295 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5231004770506512, 'Total loss': 0.5231004770506512} | train loss {'Reaction outcome loss': 0.4522315014591101, 'Total loss': 0.4522315014591101}
2022-11-28 04:16:32,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:32,295 INFO:     Epoch: 57
2022-11-28 04:16:32,958 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.527940917421471, 'Total loss': 0.527940917421471} | train loss {'Reaction outcome loss': 0.45679998789962967, 'Total loss': 0.45679998789962967}
2022-11-28 04:16:32,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:32,959 INFO:     Epoch: 58
2022-11-28 04:16:33,621 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4900271994146434, 'Total loss': 0.4900271994146434} | train loss {'Reaction outcome loss': 0.45308211789681363, 'Total loss': 0.45308211789681363}
2022-11-28 04:16:33,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:33,621 INFO:     Epoch: 59
2022-11-28 04:16:34,283 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5231113843619823, 'Total loss': 0.5231113843619823} | train loss {'Reaction outcome loss': 0.4532265596106829, 'Total loss': 0.4532265596106829}
2022-11-28 04:16:34,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:34,283 INFO:     Epoch: 60
2022-11-28 04:16:34,945 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5165047828446735, 'Total loss': 0.5165047828446735} | train loss {'Reaction outcome loss': 0.4551987665345297, 'Total loss': 0.4551987665345297}
2022-11-28 04:16:34,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:34,946 INFO:     Epoch: 61
2022-11-28 04:16:35,610 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5006758387793194, 'Total loss': 0.5006758387793194} | train loss {'Reaction outcome loss': 0.447742985146731, 'Total loss': 0.447742985146731}
2022-11-28 04:16:35,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:35,610 INFO:     Epoch: 62
2022-11-28 04:16:36,271 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4939198156988079, 'Total loss': 0.4939198156988079} | train loss {'Reaction outcome loss': 0.45966076410492424, 'Total loss': 0.45966076410492424}
2022-11-28 04:16:36,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:36,271 INFO:     Epoch: 63
2022-11-28 04:16:36,934 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5624544153159315, 'Total loss': 0.5624544153159315} | train loss {'Reaction outcome loss': 0.47158594489821537, 'Total loss': 0.47158594489821537}
2022-11-28 04:16:36,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:36,934 INFO:     Epoch: 64
2022-11-28 04:16:37,598 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49016856436025014, 'Total loss': 0.49016856436025014} | train loss {'Reaction outcome loss': 0.46229848689456216, 'Total loss': 0.46229848689456216}
2022-11-28 04:16:37,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:37,599 INFO:     Epoch: 65
2022-11-28 04:16:38,261 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5231645578010515, 'Total loss': 0.5231645578010515} | train loss {'Reaction outcome loss': 0.44505653204584894, 'Total loss': 0.44505653204584894}
2022-11-28 04:16:38,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:38,261 INFO:     Epoch: 66
2022-11-28 04:16:38,924 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5163296969099478, 'Total loss': 0.5163296969099478} | train loss {'Reaction outcome loss': 0.4620469830296783, 'Total loss': 0.4620469830296783}
2022-11-28 04:16:38,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:38,924 INFO:     Epoch: 67
2022-11-28 04:16:39,587 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5270105657929723, 'Total loss': 0.5270105657929723} | train loss {'Reaction outcome loss': 0.4558166202142654, 'Total loss': 0.4558166202142654}
2022-11-28 04:16:39,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:39,587 INFO:     Epoch: 68
2022-11-28 04:16:40,254 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5177838849750432, 'Total loss': 0.5177838849750432} | train loss {'Reaction outcome loss': 0.46293398207015835, 'Total loss': 0.46293398207015835}
2022-11-28 04:16:40,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:40,254 INFO:     Epoch: 69
2022-11-28 04:16:40,919 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4960875633088025, 'Total loss': 0.4960875633088025} | train loss {'Reaction outcome loss': 0.45896891712659765, 'Total loss': 0.45896891712659765}
2022-11-28 04:16:40,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:40,920 INFO:     Epoch: 70
2022-11-28 04:16:41,584 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.511110957711935, 'Total loss': 0.511110957711935} | train loss {'Reaction outcome loss': 0.45379340621503256, 'Total loss': 0.45379340621503256}
2022-11-28 04:16:41,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:41,584 INFO:     Epoch: 71
2022-11-28 04:16:42,243 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4926145720210942, 'Total loss': 0.4926145720210942} | train loss {'Reaction outcome loss': 0.46016286537503664, 'Total loss': 0.46016286537503664}
2022-11-28 04:16:42,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:42,244 INFO:     Epoch: 72
2022-11-28 04:16:42,905 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5210473415526476, 'Total loss': 0.5210473415526476} | train loss {'Reaction outcome loss': 0.4590353227639005, 'Total loss': 0.4590353227639005}
2022-11-28 04:16:42,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:42,905 INFO:     Epoch: 73
2022-11-28 04:16:43,565 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.522420197725296, 'Total loss': 0.522420197725296} | train loss {'Reaction outcome loss': 0.4719430097804861, 'Total loss': 0.4719430097804861}
2022-11-28 04:16:43,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:43,565 INFO:     Epoch: 74
2022-11-28 04:16:44,230 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49032119153575465, 'Total loss': 0.49032119153575465} | train loss {'Reaction outcome loss': 0.45907082245779424, 'Total loss': 0.45907082245779424}
2022-11-28 04:16:44,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:44,230 INFO:     Epoch: 75
2022-11-28 04:16:44,890 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5014845149760897, 'Total loss': 0.5014845149760897} | train loss {'Reaction outcome loss': 0.44823555992199826, 'Total loss': 0.44823555992199826}
2022-11-28 04:16:44,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:44,890 INFO:     Epoch: 76
2022-11-28 04:16:45,554 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5167849111286077, 'Total loss': 0.5167849111286077} | train loss {'Reaction outcome loss': 0.461970043870119, 'Total loss': 0.461970043870119}
2022-11-28 04:16:45,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:45,554 INFO:     Epoch: 77
2022-11-28 04:16:46,226 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49649145013906737, 'Total loss': 0.49649145013906737} | train loss {'Reaction outcome loss': 0.45260778015200426, 'Total loss': 0.45260778015200426}
2022-11-28 04:16:46,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:46,226 INFO:     Epoch: 78
2022-11-28 04:16:46,889 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5041636573997411, 'Total loss': 0.5041636573997411} | train loss {'Reaction outcome loss': 0.4643944667478805, 'Total loss': 0.4643944667478805}
2022-11-28 04:16:46,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:46,889 INFO:     Epoch: 79
2022-11-28 04:16:47,555 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4762427163395015, 'Total loss': 0.4762427163395015} | train loss {'Reaction outcome loss': 0.4549519073365158, 'Total loss': 0.4549519073365158}
2022-11-28 04:16:47,556 INFO:     Found new best model at epoch 79
2022-11-28 04:16:47,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:47,557 INFO:     Epoch: 80
2022-11-28 04:16:48,221 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48749197951771994, 'Total loss': 0.48749197951771994} | train loss {'Reaction outcome loss': 0.45169386045765963, 'Total loss': 0.45169386045765963}
2022-11-28 04:16:48,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:48,221 INFO:     Epoch: 81
2022-11-28 04:16:48,885 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.480229392986406, 'Total loss': 0.480229392986406} | train loss {'Reaction outcome loss': 0.4506091327036011, 'Total loss': 0.4506091327036011}
2022-11-28 04:16:48,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:48,885 INFO:     Epoch: 82
2022-11-28 04:16:49,547 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5446653643792326, 'Total loss': 0.5446653643792326} | train loss {'Reaction outcome loss': 0.45102598086783763, 'Total loss': 0.45102598086783763}
2022-11-28 04:16:49,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:49,547 INFO:     Epoch: 83
2022-11-28 04:16:50,210 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5042758042162115, 'Total loss': 0.5042758042162115} | train loss {'Reaction outcome loss': 0.4501240140879112, 'Total loss': 0.4501240140879112}
2022-11-28 04:16:50,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:50,210 INFO:     Epoch: 84
2022-11-28 04:16:50,874 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5313903980634429, 'Total loss': 0.5313903980634429} | train loss {'Reaction outcome loss': 0.4577680962529742, 'Total loss': 0.4577680962529742}
2022-11-28 04:16:50,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:50,874 INFO:     Epoch: 85
2022-11-28 04:16:51,534 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5128352479501204, 'Total loss': 0.5128352479501204} | train loss {'Reaction outcome loss': 0.4621804212992973, 'Total loss': 0.4621804212992973}
2022-11-28 04:16:51,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:51,534 INFO:     Epoch: 86
2022-11-28 04:16:52,198 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5198143344711174, 'Total loss': 0.5198143344711174} | train loss {'Reaction outcome loss': 0.44904149404155685, 'Total loss': 0.44904149404155685}
2022-11-28 04:16:52,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:52,198 INFO:     Epoch: 87
2022-11-28 04:16:52,859 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4962876615199176, 'Total loss': 0.4962876615199176} | train loss {'Reaction outcome loss': 0.4539388131335197, 'Total loss': 0.4539388131335197}
2022-11-28 04:16:52,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:52,859 INFO:     Epoch: 88
2022-11-28 04:16:53,518 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5010991397906434, 'Total loss': 0.5010991397906434} | train loss {'Reaction outcome loss': 0.4420354355594166, 'Total loss': 0.4420354355594166}
2022-11-28 04:16:53,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:53,519 INFO:     Epoch: 89
2022-11-28 04:16:54,181 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4862385263497179, 'Total loss': 0.4862385263497179} | train loss {'Reaction outcome loss': 0.4582306633473408, 'Total loss': 0.4582306633473408}
2022-11-28 04:16:54,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:54,181 INFO:     Epoch: 90
2022-11-28 04:16:54,842 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4993288056416945, 'Total loss': 0.4993288056416945} | train loss {'Reaction outcome loss': 0.47099858443987996, 'Total loss': 0.47099858443987996}
2022-11-28 04:16:54,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:54,842 INFO:     Epoch: 91
2022-11-28 04:16:55,504 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5038640851324255, 'Total loss': 0.5038640851324255} | train loss {'Reaction outcome loss': 0.4655381890981428, 'Total loss': 0.4655381890981428}
2022-11-28 04:16:55,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:55,504 INFO:     Epoch: 92
2022-11-28 04:16:56,165 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.515666748481718, 'Total loss': 0.515666748481718} | train loss {'Reaction outcome loss': 0.4484888045230375, 'Total loss': 0.4484888045230375}
2022-11-28 04:16:56,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:56,166 INFO:     Epoch: 93
2022-11-28 04:16:56,824 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48529986292123795, 'Total loss': 0.48529986292123795} | train loss {'Reaction outcome loss': 0.45903191374622376, 'Total loss': 0.45903191374622376}
2022-11-28 04:16:56,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:56,825 INFO:     Epoch: 94
2022-11-28 04:16:57,486 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4883184114640409, 'Total loss': 0.4883184114640409} | train loss {'Reaction outcome loss': 0.4501905034066212, 'Total loss': 0.4501905034066212}
2022-11-28 04:16:57,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:57,487 INFO:     Epoch: 95
2022-11-28 04:16:58,144 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4959788014265624, 'Total loss': 0.4959788014265624} | train loss {'Reaction outcome loss': 0.4645035763078856, 'Total loss': 0.4645035763078856}
2022-11-28 04:16:58,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:58,144 INFO:     Epoch: 96
2022-11-28 04:16:58,803 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4668098268183795, 'Total loss': 0.4668098268183795} | train loss {'Reaction outcome loss': 0.4610861023427986, 'Total loss': 0.4610861023427986}
2022-11-28 04:16:58,803 INFO:     Found new best model at epoch 96
2022-11-28 04:16:58,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:58,804 INFO:     Epoch: 97
2022-11-28 04:16:59,469 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5349593270908702, 'Total loss': 0.5349593270908702} | train loss {'Reaction outcome loss': 0.4512924515238778, 'Total loss': 0.4512924515238778}
2022-11-28 04:16:59,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:16:59,469 INFO:     Epoch: 98
2022-11-28 04:17:00,129 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5376663797281005, 'Total loss': 0.5376663797281005} | train loss {'Reaction outcome loss': 0.4525757995754601, 'Total loss': 0.4525757995754601}
2022-11-28 04:17:00,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:00,129 INFO:     Epoch: 99
2022-11-28 04:17:00,788 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5928742350502447, 'Total loss': 0.5928742350502447} | train loss {'Reaction outcome loss': 0.45939889643718357, 'Total loss': 0.45939889643718357}
2022-11-28 04:17:00,788 INFO:     Best model found after epoch 97 of 100.
2022-11-28 04:17:00,789 INFO:   Done with stage: TRAINING
2022-11-28 04:17:00,789 INFO:   Starting stage: EVALUATION
2022-11-28 04:17:00,908 INFO:   Done with stage: EVALUATION
2022-11-28 04:17:00,908 INFO:   Leaving out SEQ value Fold_6
2022-11-28 04:17:00,921 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:17:00,921 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:17:01,565 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:17:01,565 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:17:01,633 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:17:01,634 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:17:01,634 INFO:     No hyperparam tuning for this model
2022-11-28 04:17:01,634 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:17:01,634 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:17:01,634 INFO:     None feature selector for col prot
2022-11-28 04:17:01,635 INFO:     None feature selector for col prot
2022-11-28 04:17:01,635 INFO:     None feature selector for col prot
2022-11-28 04:17:01,635 INFO:     None feature selector for col chem
2022-11-28 04:17:01,635 INFO:     None feature selector for col chem
2022-11-28 04:17:01,635 INFO:     None feature selector for col chem
2022-11-28 04:17:01,635 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:17:01,635 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:17:01,637 INFO:     Number of params in model 169651
2022-11-28 04:17:01,640 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:17:01,640 INFO:   Starting stage: TRAINING
2022-11-28 04:17:01,691 INFO:     Val loss before train {'Reaction outcome loss': 0.9795664034106515, 'Total loss': 0.9795664034106515}
2022-11-28 04:17:01,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:01,692 INFO:     Epoch: 0
2022-11-28 04:17:02,357 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5782166197896004, 'Total loss': 0.5782166197896004} | train loss {'Reaction outcome loss': 0.7147262249021761, 'Total loss': 0.7147262249021761}
2022-11-28 04:17:02,357 INFO:     Found new best model at epoch 0
2022-11-28 04:17:02,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:02,358 INFO:     Epoch: 1
2022-11-28 04:17:03,023 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5522451881657947, 'Total loss': 0.5522451881657947} | train loss {'Reaction outcome loss': 0.5898727464579767, 'Total loss': 0.5898727464579767}
2022-11-28 04:17:03,023 INFO:     Found new best model at epoch 1
2022-11-28 04:17:03,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:03,024 INFO:     Epoch: 2
2022-11-28 04:17:03,689 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5689749189398505, 'Total loss': 0.5689749189398505} | train loss {'Reaction outcome loss': 0.5657424139640024, 'Total loss': 0.5657424139640024}
2022-11-28 04:17:03,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:03,689 INFO:     Epoch: 3
2022-11-28 04:17:04,354 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4947719055820595, 'Total loss': 0.4947719055820595} | train loss {'Reaction outcome loss': 0.5454281131106038, 'Total loss': 0.5454281131106038}
2022-11-28 04:17:04,354 INFO:     Found new best model at epoch 3
2022-11-28 04:17:04,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:04,355 INFO:     Epoch: 4
2022-11-28 04:17:05,017 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5852134227752686, 'Total loss': 0.5852134227752686} | train loss {'Reaction outcome loss': 0.5307295921468927, 'Total loss': 0.5307295921468927}
2022-11-28 04:17:05,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:05,017 INFO:     Epoch: 5
2022-11-28 04:17:05,682 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5048448297787796, 'Total loss': 0.5048448297787796} | train loss {'Reaction outcome loss': 0.5273596911180404, 'Total loss': 0.5273596911180404}
2022-11-28 04:17:05,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:05,682 INFO:     Epoch: 6
2022-11-28 04:17:06,347 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5231217860498212, 'Total loss': 0.5231217860498212} | train loss {'Reaction outcome loss': 0.507687289297821, 'Total loss': 0.507687289297821}
2022-11-28 04:17:06,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:06,347 INFO:     Epoch: 7
2022-11-28 04:17:07,009 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49011584201996977, 'Total loss': 0.49011584201996977} | train loss {'Reaction outcome loss': 0.5071605657858234, 'Total loss': 0.5071605657858234}
2022-11-28 04:17:07,009 INFO:     Found new best model at epoch 7
2022-11-28 04:17:07,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:07,010 INFO:     Epoch: 8
2022-11-28 04:17:07,679 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4683579887178811, 'Total loss': 0.4683579887178811} | train loss {'Reaction outcome loss': 0.5096608268157128, 'Total loss': 0.5096608268157128}
2022-11-28 04:17:07,679 INFO:     Found new best model at epoch 8
2022-11-28 04:17:07,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:07,680 INFO:     Epoch: 9
2022-11-28 04:17:08,345 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4830146875571121, 'Total loss': 0.4830146875571121} | train loss {'Reaction outcome loss': 0.4953808325432962, 'Total loss': 0.4953808325432962}
2022-11-28 04:17:08,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:08,345 INFO:     Epoch: 10
2022-11-28 04:17:09,013 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49985289539803157, 'Total loss': 0.49985289539803157} | train loss {'Reaction outcome loss': 0.4939997897994134, 'Total loss': 0.4939997897994134}
2022-11-28 04:17:09,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:09,013 INFO:     Epoch: 11
2022-11-28 04:17:09,687 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4796944555233825, 'Total loss': 0.4796944555233825} | train loss {'Reaction outcome loss': 0.49540667196795823, 'Total loss': 0.49540667196795823}
2022-11-28 04:17:09,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:09,688 INFO:     Epoch: 12
2022-11-28 04:17:10,354 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45733459530906245, 'Total loss': 0.45733459530906245} | train loss {'Reaction outcome loss': 0.4915763616802231, 'Total loss': 0.4915763616802231}
2022-11-28 04:17:10,355 INFO:     Found new best model at epoch 12
2022-11-28 04:17:10,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:10,355 INFO:     Epoch: 13
2022-11-28 04:17:11,021 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5000255033373833, 'Total loss': 0.5000255033373833} | train loss {'Reaction outcome loss': 0.4906983866446441, 'Total loss': 0.4906983866446441}
2022-11-28 04:17:11,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:11,021 INFO:     Epoch: 14
2022-11-28 04:17:11,683 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46477056497877295, 'Total loss': 0.46477056497877295} | train loss {'Reaction outcome loss': 0.4934577636060215, 'Total loss': 0.4934577636060215}
2022-11-28 04:17:11,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:11,684 INFO:     Epoch: 15
2022-11-28 04:17:12,353 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4575438668782061, 'Total loss': 0.4575438668782061} | train loss {'Reaction outcome loss': 0.4856225025028952, 'Total loss': 0.4856225025028952}
2022-11-28 04:17:12,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:12,354 INFO:     Epoch: 16
2022-11-28 04:17:13,019 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4513322941281579, 'Total loss': 0.4513322941281579} | train loss {'Reaction outcome loss': 0.4838739380000099, 'Total loss': 0.4838739380000099}
2022-11-28 04:17:13,019 INFO:     Found new best model at epoch 16
2022-11-28 04:17:13,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:13,020 INFO:     Epoch: 17
2022-11-28 04:17:13,688 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4695897722108798, 'Total loss': 0.4695897722108798} | train loss {'Reaction outcome loss': 0.48558443874841734, 'Total loss': 0.48558443874841734}
2022-11-28 04:17:13,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:13,688 INFO:     Epoch: 18
2022-11-28 04:17:14,358 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4487096050923521, 'Total loss': 0.4487096050923521} | train loss {'Reaction outcome loss': 0.4795951100607072, 'Total loss': 0.4795951100607072}
2022-11-28 04:17:14,359 INFO:     Found new best model at epoch 18
2022-11-28 04:17:14,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:14,359 INFO:     Epoch: 19
2022-11-28 04:17:15,023 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.457890871912241, 'Total loss': 0.457890871912241} | train loss {'Reaction outcome loss': 0.47766933878583295, 'Total loss': 0.47766933878583295}
2022-11-28 04:17:15,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:15,024 INFO:     Epoch: 20
2022-11-28 04:17:15,689 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47823433713479474, 'Total loss': 0.47823433713479474} | train loss {'Reaction outcome loss': 0.4797147303939827, 'Total loss': 0.4797147303939827}
2022-11-28 04:17:15,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:15,690 INFO:     Epoch: 21
2022-11-28 04:17:16,356 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48682780360633676, 'Total loss': 0.48682780360633676} | train loss {'Reaction outcome loss': 0.47340958244017056, 'Total loss': 0.47340958244017056}
2022-11-28 04:17:16,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:16,357 INFO:     Epoch: 22
2022-11-28 04:17:17,020 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4823385873301463, 'Total loss': 0.4823385873301463} | train loss {'Reaction outcome loss': 0.486898040519126, 'Total loss': 0.486898040519126}
2022-11-28 04:17:17,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:17,020 INFO:     Epoch: 23
2022-11-28 04:17:17,685 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45954138243740256, 'Total loss': 0.45954138243740256} | train loss {'Reaction outcome loss': 0.47748891841019353, 'Total loss': 0.47748891841019353}
2022-11-28 04:17:17,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:17,686 INFO:     Epoch: 24
2022-11-28 04:17:18,350 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4529555629600178, 'Total loss': 0.4529555629600178} | train loss {'Reaction outcome loss': 0.4750317047320066, 'Total loss': 0.4750317047320066}
2022-11-28 04:17:18,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:18,351 INFO:     Epoch: 25
2022-11-28 04:17:19,018 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49239912967790256, 'Total loss': 0.49239912967790256} | train loss {'Reaction outcome loss': 0.48021714749836153, 'Total loss': 0.48021714749836153}
2022-11-28 04:17:19,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:19,018 INFO:     Epoch: 26
2022-11-28 04:17:19,684 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4489667581563646, 'Total loss': 0.4489667581563646} | train loss {'Reaction outcome loss': 0.4765693357274417, 'Total loss': 0.4765693357274417}
2022-11-28 04:17:19,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:19,684 INFO:     Epoch: 27
2022-11-28 04:17:20,349 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4472354399886998, 'Total loss': 0.4472354399886998} | train loss {'Reaction outcome loss': 0.4730091454881814, 'Total loss': 0.4730091454881814}
2022-11-28 04:17:20,349 INFO:     Found new best model at epoch 27
2022-11-28 04:17:20,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:20,350 INFO:     Epoch: 28
2022-11-28 04:17:21,014 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45962798595428467, 'Total loss': 0.45962798595428467} | train loss {'Reaction outcome loss': 0.4681940758300404, 'Total loss': 0.4681940758300404}
2022-11-28 04:17:21,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:21,015 INFO:     Epoch: 29
2022-11-28 04:17:21,679 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.437115760689432, 'Total loss': 0.437115760689432} | train loss {'Reaction outcome loss': 0.4666451962604638, 'Total loss': 0.4666451962604638}
2022-11-28 04:17:21,679 INFO:     Found new best model at epoch 29
2022-11-28 04:17:21,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:21,679 INFO:     Epoch: 30
2022-11-28 04:17:22,340 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4744673635471951, 'Total loss': 0.4744673635471951} | train loss {'Reaction outcome loss': 0.4737820342904137, 'Total loss': 0.4737820342904137}
2022-11-28 04:17:22,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:22,340 INFO:     Epoch: 31
2022-11-28 04:17:23,004 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4409299801019105, 'Total loss': 0.4409299801019105} | train loss {'Reaction outcome loss': 0.4740271382634678, 'Total loss': 0.4740271382634678}
2022-11-28 04:17:23,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:23,004 INFO:     Epoch: 32
2022-11-28 04:17:23,670 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4479674720628695, 'Total loss': 0.4479674720628695} | train loss {'Reaction outcome loss': 0.4772054589683971, 'Total loss': 0.4772054589683971}
2022-11-28 04:17:23,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:23,671 INFO:     Epoch: 33
2022-11-28 04:17:24,336 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46596030450680037, 'Total loss': 0.46596030450680037} | train loss {'Reaction outcome loss': 0.46811566051215897, 'Total loss': 0.46811566051215897}
2022-11-28 04:17:24,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:24,336 INFO:     Epoch: 34
2022-11-28 04:17:25,002 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4563418010419065, 'Total loss': 0.4563418010419065} | train loss {'Reaction outcome loss': 0.46907163249148476, 'Total loss': 0.46907163249148476}
2022-11-28 04:17:25,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:25,002 INFO:     Epoch: 35
2022-11-28 04:17:25,666 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4869457290253856, 'Total loss': 0.4869457290253856} | train loss {'Reaction outcome loss': 0.4794882479754667, 'Total loss': 0.4794882479754667}
2022-11-28 04:17:25,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:25,666 INFO:     Epoch: 36
2022-11-28 04:17:26,327 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44969903982498427, 'Total loss': 0.44969903982498427} | train loss {'Reaction outcome loss': 0.47227604771333354, 'Total loss': 0.47227604771333354}
2022-11-28 04:17:26,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:26,327 INFO:     Epoch: 37
2022-11-28 04:17:26,992 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46116277744824236, 'Total loss': 0.46116277744824236} | train loss {'Reaction outcome loss': 0.4693681479942414, 'Total loss': 0.4693681479942414}
2022-11-28 04:17:26,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:26,993 INFO:     Epoch: 38
2022-11-28 04:17:27,661 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4624965231526982, 'Total loss': 0.4624965231526982} | train loss {'Reaction outcome loss': 0.47187940277639895, 'Total loss': 0.47187940277639895}
2022-11-28 04:17:27,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:27,661 INFO:     Epoch: 39
2022-11-28 04:17:28,326 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4995555640621619, 'Total loss': 0.4995555640621619} | train loss {'Reaction outcome loss': 0.46797774888334737, 'Total loss': 0.46797774888334737}
2022-11-28 04:17:28,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:28,326 INFO:     Epoch: 40
2022-11-28 04:17:28,991 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43986246091398323, 'Total loss': 0.43986246091398323} | train loss {'Reaction outcome loss': 0.47895932924603263, 'Total loss': 0.47895932924603263}
2022-11-28 04:17:28,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:28,991 INFO:     Epoch: 41
2022-11-28 04:17:29,655 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5332559489391067, 'Total loss': 0.5332559489391067} | train loss {'Reaction outcome loss': 0.47034365972203596, 'Total loss': 0.47034365972203596}
2022-11-28 04:17:29,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:29,655 INFO:     Epoch: 42
2022-11-28 04:17:30,320 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4810240881686861, 'Total loss': 0.4810240881686861} | train loss {'Reaction outcome loss': 0.4749074363179745, 'Total loss': 0.4749074363179745}
2022-11-28 04:17:30,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:30,321 INFO:     Epoch: 43
2022-11-28 04:17:30,989 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5050241750749674, 'Total loss': 0.5050241750749674} | train loss {'Reaction outcome loss': 0.4731896187088663, 'Total loss': 0.4731896187088663}
2022-11-28 04:17:30,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:30,989 INFO:     Epoch: 44
2022-11-28 04:17:31,657 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4668919190087102, 'Total loss': 0.4668919190087102} | train loss {'Reaction outcome loss': 0.47357015395837443, 'Total loss': 0.47357015395837443}
2022-11-28 04:17:31,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:31,657 INFO:     Epoch: 45
2022-11-28 04:17:32,320 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4502333998680115, 'Total loss': 0.4502333998680115} | train loss {'Reaction outcome loss': 0.47039270527180166, 'Total loss': 0.47039270527180166}
2022-11-28 04:17:32,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:32,320 INFO:     Epoch: 46
2022-11-28 04:17:32,983 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4658230394124985, 'Total loss': 0.4658230394124985} | train loss {'Reaction outcome loss': 0.4766961357766582, 'Total loss': 0.4766961357766582}
2022-11-28 04:17:32,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:32,984 INFO:     Epoch: 47
2022-11-28 04:17:33,648 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44334828785874625, 'Total loss': 0.44334828785874625} | train loss {'Reaction outcome loss': 0.46752708663623177, 'Total loss': 0.46752708663623177}
2022-11-28 04:17:33,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:33,649 INFO:     Epoch: 48
2022-11-28 04:17:34,313 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49605184387076984, 'Total loss': 0.49605184387076984} | train loss {'Reaction outcome loss': 0.47127950876470537, 'Total loss': 0.47127950876470537}
2022-11-28 04:17:34,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:34,313 INFO:     Epoch: 49
2022-11-28 04:17:34,980 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45869438214735553, 'Total loss': 0.45869438214735553} | train loss {'Reaction outcome loss': 0.4786345467211739, 'Total loss': 0.4786345467211739}
2022-11-28 04:17:34,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:34,980 INFO:     Epoch: 50
2022-11-28 04:17:35,646 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4581504768945954, 'Total loss': 0.4581504768945954} | train loss {'Reaction outcome loss': 0.4705697447962819, 'Total loss': 0.4705697447962819}
2022-11-28 04:17:35,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:35,646 INFO:     Epoch: 51
2022-11-28 04:17:36,312 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46485141529278323, 'Total loss': 0.46485141529278323} | train loss {'Reaction outcome loss': 0.47453140034790964, 'Total loss': 0.47453140034790964}
2022-11-28 04:17:36,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:36,312 INFO:     Epoch: 52
2022-11-28 04:17:36,977 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46471466598185623, 'Total loss': 0.46471466598185623} | train loss {'Reaction outcome loss': 0.47136095706974307, 'Total loss': 0.47136095706974307}
2022-11-28 04:17:36,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:36,977 INFO:     Epoch: 53
2022-11-28 04:17:37,644 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43822176348079334, 'Total loss': 0.43822176348079334} | train loss {'Reaction outcome loss': 0.46802298772719597, 'Total loss': 0.46802298772719597}
2022-11-28 04:17:37,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:37,645 INFO:     Epoch: 54
2022-11-28 04:17:38,309 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4658246152102947, 'Total loss': 0.4658246152102947} | train loss {'Reaction outcome loss': 0.4735883517310985, 'Total loss': 0.4735883517310985}
2022-11-28 04:17:38,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:38,310 INFO:     Epoch: 55
2022-11-28 04:17:38,975 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44224198535084724, 'Total loss': 0.44224198535084724} | train loss {'Reaction outcome loss': 0.464397706181532, 'Total loss': 0.464397706181532}
2022-11-28 04:17:38,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:38,976 INFO:     Epoch: 56
2022-11-28 04:17:39,642 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45140538771044125, 'Total loss': 0.45140538771044125} | train loss {'Reaction outcome loss': 0.4723780671314847, 'Total loss': 0.4723780671314847}
2022-11-28 04:17:39,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:39,642 INFO:     Epoch: 57
2022-11-28 04:17:40,310 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44712368568236177, 'Total loss': 0.44712368568236177} | train loss {'Reaction outcome loss': 0.4722006892064406, 'Total loss': 0.4722006892064406}
2022-11-28 04:17:40,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:40,310 INFO:     Epoch: 58
2022-11-28 04:17:40,972 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44291825287721376, 'Total loss': 0.44291825287721376} | train loss {'Reaction outcome loss': 0.475029174719126, 'Total loss': 0.475029174719126}
2022-11-28 04:17:40,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:40,973 INFO:     Epoch: 59
2022-11-28 04:17:41,635 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47103166072206065, 'Total loss': 0.47103166072206065} | train loss {'Reaction outcome loss': 0.4673396302687545, 'Total loss': 0.4673396302687545}
2022-11-28 04:17:41,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:41,635 INFO:     Epoch: 60
2022-11-28 04:17:42,297 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4486730383201079, 'Total loss': 0.4486730383201079} | train loss {'Reaction outcome loss': 0.4770702060552374, 'Total loss': 0.4770702060552374}
2022-11-28 04:17:42,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:42,297 INFO:     Epoch: 61
2022-11-28 04:17:42,959 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4907504970377142, 'Total loss': 0.4907504970377142} | train loss {'Reaction outcome loss': 0.4716261971982256, 'Total loss': 0.4716261971982256}
2022-11-28 04:17:42,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:42,961 INFO:     Epoch: 62
2022-11-28 04:17:43,630 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4557797448201613, 'Total loss': 0.4557797448201613} | train loss {'Reaction outcome loss': 0.4666744129011227, 'Total loss': 0.4666744129011227}
2022-11-28 04:17:43,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:43,630 INFO:     Epoch: 63
2022-11-28 04:17:44,294 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4620882496237755, 'Total loss': 0.4620882496237755} | train loss {'Reaction outcome loss': 0.4682692964711497, 'Total loss': 0.4682692964711497}
2022-11-28 04:17:44,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:44,295 INFO:     Epoch: 64
2022-11-28 04:17:44,958 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43940615552392875, 'Total loss': 0.43940615552392875} | train loss {'Reaction outcome loss': 0.46945624329870744, 'Total loss': 0.46945624329870744}
2022-11-28 04:17:44,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:44,959 INFO:     Epoch: 65
2022-11-28 04:17:45,626 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4326659525659951, 'Total loss': 0.4326659525659951} | train loss {'Reaction outcome loss': 0.4655076737004903, 'Total loss': 0.4655076737004903}
2022-11-28 04:17:45,626 INFO:     Found new best model at epoch 65
2022-11-28 04:17:45,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:45,627 INFO:     Epoch: 66
2022-11-28 04:17:46,301 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4588917747817256, 'Total loss': 0.4588917747817256} | train loss {'Reaction outcome loss': 0.46615169665986494, 'Total loss': 0.46615169665986494}
2022-11-28 04:17:46,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:46,301 INFO:     Epoch: 67
2022-11-28 04:17:46,965 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.500742525539615, 'Total loss': 0.500742525539615} | train loss {'Reaction outcome loss': 0.4703694568165848, 'Total loss': 0.4703694568165848}
2022-11-28 04:17:46,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:46,965 INFO:     Epoch: 68
2022-11-28 04:17:47,635 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42436791804026475, 'Total loss': 0.42436791804026475} | train loss {'Reaction outcome loss': 0.4719509537662229, 'Total loss': 0.4719509537662229}
2022-11-28 04:17:47,635 INFO:     Found new best model at epoch 68
2022-11-28 04:17:47,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:47,636 INFO:     Epoch: 69
2022-11-28 04:17:48,300 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4713357531211593, 'Total loss': 0.4713357531211593} | train loss {'Reaction outcome loss': 0.4701948671812011, 'Total loss': 0.4701948671812011}
2022-11-28 04:17:48,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:48,301 INFO:     Epoch: 70
2022-11-28 04:17:48,967 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4489032781936906, 'Total loss': 0.4489032781936906} | train loss {'Reaction outcome loss': 0.47073976010564833, 'Total loss': 0.47073976010564833}
2022-11-28 04:17:48,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:48,968 INFO:     Epoch: 71
2022-11-28 04:17:49,631 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4563172161579132, 'Total loss': 0.4563172161579132} | train loss {'Reaction outcome loss': 0.47295579368308666, 'Total loss': 0.47295579368308666}
2022-11-28 04:17:49,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:49,631 INFO:     Epoch: 72
2022-11-28 04:17:50,295 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4498757245865735, 'Total loss': 0.4498757245865735} | train loss {'Reaction outcome loss': 0.4818517754395162, 'Total loss': 0.4818517754395162}
2022-11-28 04:17:50,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:50,295 INFO:     Epoch: 73
2022-11-28 04:17:50,967 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45091433044184337, 'Total loss': 0.45091433044184337} | train loss {'Reaction outcome loss': 0.4643604843727043, 'Total loss': 0.4643604843727043}
2022-11-28 04:17:50,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:50,968 INFO:     Epoch: 74
2022-11-28 04:17:51,635 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45290045135400514, 'Total loss': 0.45290045135400514} | train loss {'Reaction outcome loss': 0.47333477677837493, 'Total loss': 0.47333477677837493}
2022-11-28 04:17:51,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:51,635 INFO:     Epoch: 75
2022-11-28 04:17:52,297 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49183878200975334, 'Total loss': 0.49183878200975334} | train loss {'Reaction outcome loss': 0.4669133145362139, 'Total loss': 0.4669133145362139}
2022-11-28 04:17:52,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:52,297 INFO:     Epoch: 76
2022-11-28 04:17:52,964 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44967385279861366, 'Total loss': 0.44967385279861366} | train loss {'Reaction outcome loss': 0.47870950647179156, 'Total loss': 0.47870950647179156}
2022-11-28 04:17:52,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:52,964 INFO:     Epoch: 77
2022-11-28 04:17:53,630 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4866830926727165, 'Total loss': 0.4866830926727165} | train loss {'Reaction outcome loss': 0.4714635903195989, 'Total loss': 0.4714635903195989}
2022-11-28 04:17:53,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:53,630 INFO:     Epoch: 78
2022-11-28 04:17:54,295 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44917850264094095, 'Total loss': 0.44917850264094095} | train loss {'Reaction outcome loss': 0.4780352246917544, 'Total loss': 0.4780352246917544}
2022-11-28 04:17:54,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:54,296 INFO:     Epoch: 79
2022-11-28 04:17:54,965 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44184793362563307, 'Total loss': 0.44184793362563307} | train loss {'Reaction outcome loss': 0.47472034959543136, 'Total loss': 0.47472034959543136}
2022-11-28 04:17:54,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:54,965 INFO:     Epoch: 80
2022-11-28 04:17:55,633 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4355016140775247, 'Total loss': 0.4355016140775247} | train loss {'Reaction outcome loss': 0.4725496012477144, 'Total loss': 0.4725496012477144}
2022-11-28 04:17:55,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:55,633 INFO:     Epoch: 81
2022-11-28 04:17:56,296 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45556225356730545, 'Total loss': 0.45556225356730545} | train loss {'Reaction outcome loss': 0.46565439711294826, 'Total loss': 0.46565439711294826}
2022-11-28 04:17:56,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:56,296 INFO:     Epoch: 82
2022-11-28 04:17:56,961 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4768733217973601, 'Total loss': 0.4768733217973601} | train loss {'Reaction outcome loss': 0.46972959933261715, 'Total loss': 0.46972959933261715}
2022-11-28 04:17:56,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:56,961 INFO:     Epoch: 83
2022-11-28 04:17:57,625 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4453527524390004, 'Total loss': 0.4453527524390004} | train loss {'Reaction outcome loss': 0.4713410392043091, 'Total loss': 0.4713410392043091}
2022-11-28 04:17:57,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:57,625 INFO:     Epoch: 84
2022-11-28 04:17:58,292 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44025593013925984, 'Total loss': 0.44025593013925984} | train loss {'Reaction outcome loss': 0.47777429565546975, 'Total loss': 0.47777429565546975}
2022-11-28 04:17:58,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:58,292 INFO:     Epoch: 85
2022-11-28 04:17:58,957 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4938479597595605, 'Total loss': 0.4938479597595605} | train loss {'Reaction outcome loss': 0.47620860445162944, 'Total loss': 0.47620860445162944}
2022-11-28 04:17:58,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:58,957 INFO:     Epoch: 86
2022-11-28 04:17:59,629 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46743845600973477, 'Total loss': 0.46743845600973477} | train loss {'Reaction outcome loss': 0.47692769098906745, 'Total loss': 0.47692769098906745}
2022-11-28 04:17:59,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:17:59,629 INFO:     Epoch: 87
2022-11-28 04:18:00,294 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46454055641185155, 'Total loss': 0.46454055641185155} | train loss {'Reaction outcome loss': 0.472736478092209, 'Total loss': 0.472736478092209}
2022-11-28 04:18:00,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:00,295 INFO:     Epoch: 88
2022-11-28 04:18:00,960 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4614844173192978, 'Total loss': 0.4614844173192978} | train loss {'Reaction outcome loss': 0.47534437982305405, 'Total loss': 0.47534437982305405}
2022-11-28 04:18:00,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:00,961 INFO:     Epoch: 89
2022-11-28 04:18:01,624 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45327614146200096, 'Total loss': 0.45327614146200096} | train loss {'Reaction outcome loss': 0.47306599077438155, 'Total loss': 0.47306599077438155}
2022-11-28 04:18:01,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:01,625 INFO:     Epoch: 90
2022-11-28 04:18:02,291 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4873556460846554, 'Total loss': 0.4873556460846554} | train loss {'Reaction outcome loss': 0.4676873301786761, 'Total loss': 0.4676873301786761}
2022-11-28 04:18:02,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:02,291 INFO:     Epoch: 91
2022-11-28 04:18:02,960 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4649577977305109, 'Total loss': 0.4649577977305109} | train loss {'Reaction outcome loss': 0.4684524467034686, 'Total loss': 0.4684524467034686}
2022-11-28 04:18:02,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:02,960 INFO:     Epoch: 92
2022-11-28 04:18:03,628 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43794701112942264, 'Total loss': 0.43794701112942264} | train loss {'Reaction outcome loss': 0.4735222300214152, 'Total loss': 0.4735222300214152}
2022-11-28 04:18:03,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:03,629 INFO:     Epoch: 93
2022-11-28 04:18:04,293 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4440704384310679, 'Total loss': 0.4440704384310679} | train loss {'Reaction outcome loss': 0.47467188993769305, 'Total loss': 0.47467188993769305}
2022-11-28 04:18:04,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:04,293 INFO:     Epoch: 94
2022-11-28 04:18:04,954 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45248854566704144, 'Total loss': 0.45248854566704144} | train loss {'Reaction outcome loss': 0.46938209488026555, 'Total loss': 0.46938209488026555}
2022-11-28 04:18:04,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:04,955 INFO:     Epoch: 95
2022-11-28 04:18:05,617 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44897451387210324, 'Total loss': 0.44897451387210324} | train loss {'Reaction outcome loss': 0.4680341630573234, 'Total loss': 0.4680341630573234}
2022-11-28 04:18:05,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:05,617 INFO:     Epoch: 96
2022-11-28 04:18:06,275 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4313459535214034, 'Total loss': 0.4313459535214034} | train loss {'Reaction outcome loss': 0.46982846415090945, 'Total loss': 0.46982846415090945}
2022-11-28 04:18:06,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:06,275 INFO:     Epoch: 97
2022-11-28 04:18:06,936 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4457897401668809, 'Total loss': 0.4457897401668809} | train loss {'Reaction outcome loss': 0.467819650747603, 'Total loss': 0.467819650747603}
2022-11-28 04:18:06,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:06,936 INFO:     Epoch: 98
2022-11-28 04:18:07,598 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.439448011869734, 'Total loss': 0.439448011869734} | train loss {'Reaction outcome loss': 0.46866265486084646, 'Total loss': 0.46866265486084646}
2022-11-28 04:18:07,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:07,598 INFO:     Epoch: 99
2022-11-28 04:18:08,259 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4379284686662934, 'Total loss': 0.4379284686662934} | train loss {'Reaction outcome loss': 0.4707178127381109, 'Total loss': 0.4707178127381109}
2022-11-28 04:18:08,260 INFO:     Best model found after epoch 69 of 100.
2022-11-28 04:18:08,260 INFO:   Done with stage: TRAINING
2022-11-28 04:18:08,260 INFO:   Starting stage: EVALUATION
2022-11-28 04:18:08,373 INFO:   Done with stage: EVALUATION
2022-11-28 04:18:08,373 INFO:   Leaving out SEQ value Fold_7
2022-11-28 04:18:08,385 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:18:08,385 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:18:09,028 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:18:09,028 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:18:09,096 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:18:09,096 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:18:09,096 INFO:     No hyperparam tuning for this model
2022-11-28 04:18:09,096 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:18:09,096 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:18:09,097 INFO:     None feature selector for col prot
2022-11-28 04:18:09,097 INFO:     None feature selector for col prot
2022-11-28 04:18:09,097 INFO:     None feature selector for col prot
2022-11-28 04:18:09,098 INFO:     None feature selector for col chem
2022-11-28 04:18:09,098 INFO:     None feature selector for col chem
2022-11-28 04:18:09,098 INFO:     None feature selector for col chem
2022-11-28 04:18:09,098 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:18:09,098 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:18:09,099 INFO:     Number of params in model 169651
2022-11-28 04:18:09,103 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:18:09,103 INFO:   Starting stage: TRAINING
2022-11-28 04:18:09,154 INFO:     Val loss before train {'Reaction outcome loss': 1.0296362333677032, 'Total loss': 1.0296362333677032}
2022-11-28 04:18:09,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:09,154 INFO:     Epoch: 0
2022-11-28 04:18:09,810 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5993560958992351, 'Total loss': 0.5993560958992351} | train loss {'Reaction outcome loss': 0.6774554106653953, 'Total loss': 0.6774554106653953}
2022-11-28 04:18:09,811 INFO:     Found new best model at epoch 0
2022-11-28 04:18:09,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:09,811 INFO:     Epoch: 1
2022-11-28 04:18:10,469 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5331440215761011, 'Total loss': 0.5331440215761011} | train loss {'Reaction outcome loss': 0.5713086193313404, 'Total loss': 0.5713086193313404}
2022-11-28 04:18:10,469 INFO:     Found new best model at epoch 1
2022-11-28 04:18:10,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:10,470 INFO:     Epoch: 2
2022-11-28 04:18:11,128 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5701381956989114, 'Total loss': 0.5701381956989114} | train loss {'Reaction outcome loss': 0.5579180924259887, 'Total loss': 0.5579180924259887}
2022-11-28 04:18:11,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:11,129 INFO:     Epoch: 3
2022-11-28 04:18:11,782 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5461154319345951, 'Total loss': 0.5461154319345951} | train loss {'Reaction outcome loss': 0.5353767450366701, 'Total loss': 0.5353767450366701}
2022-11-28 04:18:11,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:11,782 INFO:     Epoch: 4
2022-11-28 04:18:12,436 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5191590958698229, 'Total loss': 0.5191590958698229} | train loss {'Reaction outcome loss': 0.525511813832789, 'Total loss': 0.525511813832789}
2022-11-28 04:18:12,437 INFO:     Found new best model at epoch 4
2022-11-28 04:18:12,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:12,437 INFO:     Epoch: 5
2022-11-28 04:18:13,092 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5394558466293595, 'Total loss': 0.5394558466293595} | train loss {'Reaction outcome loss': 0.49896853189079127, 'Total loss': 0.49896853189079127}
2022-11-28 04:18:13,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:13,092 INFO:     Epoch: 6
2022-11-28 04:18:13,752 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5006515803662214, 'Total loss': 0.5006515803662214} | train loss {'Reaction outcome loss': 0.497129742892421, 'Total loss': 0.497129742892421}
2022-11-28 04:18:13,753 INFO:     Found new best model at epoch 6
2022-11-28 04:18:13,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:13,754 INFO:     Epoch: 7
2022-11-28 04:18:14,410 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49896352975205943, 'Total loss': 0.49896352975205943} | train loss {'Reaction outcome loss': 0.4893621946475944, 'Total loss': 0.4893621946475944}
2022-11-28 04:18:14,410 INFO:     Found new best model at epoch 7
2022-11-28 04:18:14,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:14,410 INFO:     Epoch: 8
2022-11-28 04:18:15,065 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5154919858005914, 'Total loss': 0.5154919858005914} | train loss {'Reaction outcome loss': 0.48934190303695446, 'Total loss': 0.48934190303695446}
2022-11-28 04:18:15,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:15,065 INFO:     Epoch: 9
2022-11-28 04:18:15,718 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5100381001830101, 'Total loss': 0.5100381001830101} | train loss {'Reaction outcome loss': 0.4774197653848298, 'Total loss': 0.4774197653848298}
2022-11-28 04:18:15,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:15,718 INFO:     Epoch: 10
2022-11-28 04:18:16,373 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4743080042641271, 'Total loss': 0.4743080042641271} | train loss {'Reaction outcome loss': 0.4792329572293223, 'Total loss': 0.4792329572293223}
2022-11-28 04:18:16,373 INFO:     Found new best model at epoch 10
2022-11-28 04:18:16,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:16,374 INFO:     Epoch: 11
2022-11-28 04:18:17,030 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5383552312850952, 'Total loss': 0.5383552312850952} | train loss {'Reaction outcome loss': 0.47884617666808926, 'Total loss': 0.47884617666808926}
2022-11-28 04:18:17,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:17,030 INFO:     Epoch: 12
2022-11-28 04:18:17,684 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5050126127898693, 'Total loss': 0.5050126127898693} | train loss {'Reaction outcome loss': 0.48026677205854534, 'Total loss': 0.48026677205854534}
2022-11-28 04:18:17,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:17,684 INFO:     Epoch: 13
2022-11-28 04:18:18,340 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4938279996541413, 'Total loss': 0.4938279996541413} | train loss {'Reaction outcome loss': 0.4801685174813076, 'Total loss': 0.4801685174813076}
2022-11-28 04:18:18,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:18,340 INFO:     Epoch: 14
2022-11-28 04:18:18,998 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4843576221980832, 'Total loss': 0.4843576221980832} | train loss {'Reaction outcome loss': 0.4762682725580371, 'Total loss': 0.4762682725580371}
2022-11-28 04:18:18,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:18,999 INFO:     Epoch: 15
2022-11-28 04:18:19,655 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5030235665088351, 'Total loss': 0.5030235665088351} | train loss {'Reaction outcome loss': 0.4704787433755641, 'Total loss': 0.4704787433755641}
2022-11-28 04:18:19,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:19,655 INFO:     Epoch: 16
2022-11-28 04:18:20,309 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4938979545523497, 'Total loss': 0.4938979545523497} | train loss {'Reaction outcome loss': 0.47614176048308005, 'Total loss': 0.47614176048308005}
2022-11-28 04:18:20,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:20,310 INFO:     Epoch: 17
2022-11-28 04:18:20,963 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4683158038692041, 'Total loss': 0.4683158038692041} | train loss {'Reaction outcome loss': 0.46501054119090646, 'Total loss': 0.46501054119090646}
2022-11-28 04:18:20,963 INFO:     Found new best model at epoch 17
2022-11-28 04:18:20,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:20,964 INFO:     Epoch: 18
2022-11-28 04:18:21,619 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5216856998476115, 'Total loss': 0.5216856998476115} | train loss {'Reaction outcome loss': 0.46847762611447546, 'Total loss': 0.46847762611447546}
2022-11-28 04:18:21,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:21,619 INFO:     Epoch: 19
2022-11-28 04:18:22,274 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49652614783157, 'Total loss': 0.49652614783157} | train loss {'Reaction outcome loss': 0.47851377330264266, 'Total loss': 0.47851377330264266}
2022-11-28 04:18:22,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:22,274 INFO:     Epoch: 20
2022-11-28 04:18:22,928 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5066201321103356, 'Total loss': 0.5066201321103356} | train loss {'Reaction outcome loss': 0.46431337561534375, 'Total loss': 0.46431337561534375}
2022-11-28 04:18:22,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:22,929 INFO:     Epoch: 21
2022-11-28 04:18:23,585 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5236799805001779, 'Total loss': 0.5236799805001779} | train loss {'Reaction outcome loss': 0.47183426752382396, 'Total loss': 0.47183426752382396}
2022-11-28 04:18:23,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:23,585 INFO:     Epoch: 22
2022-11-28 04:18:24,239 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48976526341655036, 'Total loss': 0.48976526341655036} | train loss {'Reaction outcome loss': 0.4680486488707212, 'Total loss': 0.4680486488707212}
2022-11-28 04:18:24,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:24,239 INFO:     Epoch: 23
2022-11-28 04:18:24,892 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48094065724448726, 'Total loss': 0.48094065724448726} | train loss {'Reaction outcome loss': 0.47302553197559044, 'Total loss': 0.47302553197559044}
2022-11-28 04:18:24,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:24,892 INFO:     Epoch: 24
2022-11-28 04:18:25,552 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5210712386125868, 'Total loss': 0.5210712386125868} | train loss {'Reaction outcome loss': 0.4674219554784347, 'Total loss': 0.4674219554784347}
2022-11-28 04:18:25,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:25,553 INFO:     Epoch: 25
2022-11-28 04:18:26,211 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48564839126034215, 'Total loss': 0.48564839126034215} | train loss {'Reaction outcome loss': 0.46359085233844055, 'Total loss': 0.46359085233844055}
2022-11-28 04:18:26,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:26,211 INFO:     Epoch: 26
2022-11-28 04:18:26,870 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4875265092334964, 'Total loss': 0.4875265092334964} | train loss {'Reaction outcome loss': 0.4590762694879454, 'Total loss': 0.4590762694879454}
2022-11-28 04:18:26,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:26,870 INFO:     Epoch: 27
2022-11-28 04:18:27,525 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4777628654106097, 'Total loss': 0.4777628654106097} | train loss {'Reaction outcome loss': 0.4676496553785947, 'Total loss': 0.4676496553785947}
2022-11-28 04:18:27,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:27,526 INFO:     Epoch: 28
2022-11-28 04:18:28,186 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49099942499941046, 'Total loss': 0.49099942499941046} | train loss {'Reaction outcome loss': 0.46685868626346394, 'Total loss': 0.46685868626346394}
2022-11-28 04:18:28,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:28,186 INFO:     Epoch: 29
2022-11-28 04:18:28,846 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4967525686052712, 'Total loss': 0.4967525686052712} | train loss {'Reaction outcome loss': 0.4606701959152611, 'Total loss': 0.4606701959152611}
2022-11-28 04:18:28,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:28,847 INFO:     Epoch: 30
2022-11-28 04:18:29,503 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5066247006708925, 'Total loss': 0.5066247006708925} | train loss {'Reaction outcome loss': 0.46437047196894277, 'Total loss': 0.46437047196894277}
2022-11-28 04:18:29,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:29,503 INFO:     Epoch: 31
2022-11-28 04:18:30,156 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48970994454893196, 'Total loss': 0.48970994454893196} | train loss {'Reaction outcome loss': 0.4647444884387814, 'Total loss': 0.4647444884387814}
2022-11-28 04:18:30,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:30,157 INFO:     Epoch: 32
2022-11-28 04:18:30,812 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4781901291148229, 'Total loss': 0.4781901291148229} | train loss {'Reaction outcome loss': 0.46732398919305024, 'Total loss': 0.46732398919305024}
2022-11-28 04:18:30,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:30,812 INFO:     Epoch: 33
2022-11-28 04:18:31,465 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5185658085075292, 'Total loss': 0.5185658085075292} | train loss {'Reaction outcome loss': 0.4645012212651117, 'Total loss': 0.4645012212651117}
2022-11-28 04:18:31,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:31,466 INFO:     Epoch: 34
2022-11-28 04:18:32,119 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4868123233318329, 'Total loss': 0.4868123233318329} | train loss {'Reaction outcome loss': 0.46125111585977124, 'Total loss': 0.46125111585977124}
2022-11-28 04:18:32,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:32,119 INFO:     Epoch: 35
2022-11-28 04:18:32,773 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5028740932995622, 'Total loss': 0.5028740932995622} | train loss {'Reaction outcome loss': 0.46612697128130465, 'Total loss': 0.46612697128130465}
2022-11-28 04:18:32,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:32,774 INFO:     Epoch: 36
2022-11-28 04:18:33,425 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48790422759272833, 'Total loss': 0.48790422759272833} | train loss {'Reaction outcome loss': 0.4700903109749969, 'Total loss': 0.4700903109749969}
2022-11-28 04:18:33,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:33,425 INFO:     Epoch: 37
2022-11-28 04:18:34,080 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5087699036706578, 'Total loss': 0.5087699036706578} | train loss {'Reaction outcome loss': 0.4684505491232385, 'Total loss': 0.4684505491232385}
2022-11-28 04:18:34,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:34,080 INFO:     Epoch: 38
2022-11-28 04:18:34,733 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48017771474339743, 'Total loss': 0.48017771474339743} | train loss {'Reaction outcome loss': 0.4624365084025325, 'Total loss': 0.4624365084025325}
2022-11-28 04:18:34,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:34,734 INFO:     Epoch: 39
2022-11-28 04:18:35,387 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4904336841268973, 'Total loss': 0.4904336841268973} | train loss {'Reaction outcome loss': 0.46064461420993413, 'Total loss': 0.46064461420993413}
2022-11-28 04:18:35,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:35,387 INFO:     Epoch: 40
2022-11-28 04:18:36,039 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48049538290466776, 'Total loss': 0.48049538290466776} | train loss {'Reaction outcome loss': 0.46777628051991366, 'Total loss': 0.46777628051991366}
2022-11-28 04:18:36,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:36,039 INFO:     Epoch: 41
2022-11-28 04:18:36,694 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5046850022944537, 'Total loss': 0.5046850022944537} | train loss {'Reaction outcome loss': 0.4622303101177118, 'Total loss': 0.4622303101177118}
2022-11-28 04:18:36,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:36,694 INFO:     Epoch: 42
2022-11-28 04:18:37,351 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4880118424242193, 'Total loss': 0.4880118424242193} | train loss {'Reaction outcome loss': 0.46150458978146924, 'Total loss': 0.46150458978146924}
2022-11-28 04:18:37,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:37,351 INFO:     Epoch: 43
2022-11-28 04:18:38,007 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5047553940252825, 'Total loss': 0.5047553940252825} | train loss {'Reaction outcome loss': 0.46588706009242, 'Total loss': 0.46588706009242}
2022-11-28 04:18:38,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:38,007 INFO:     Epoch: 44
2022-11-28 04:18:38,661 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4610942473465746, 'Total loss': 0.4610942473465746} | train loss {'Reaction outcome loss': 0.4633289027578977, 'Total loss': 0.4633289027578977}
2022-11-28 04:18:38,661 INFO:     Found new best model at epoch 44
2022-11-28 04:18:38,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:38,662 INFO:     Epoch: 45
2022-11-28 04:18:39,315 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4946090690791607, 'Total loss': 0.4946090690791607} | train loss {'Reaction outcome loss': 0.462627830614849, 'Total loss': 0.462627830614849}
2022-11-28 04:18:39,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:39,315 INFO:     Epoch: 46
2022-11-28 04:18:39,969 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4724564664065838, 'Total loss': 0.4724564664065838} | train loss {'Reaction outcome loss': 0.4656578955601673, 'Total loss': 0.4656578955601673}
2022-11-28 04:18:39,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:39,970 INFO:     Epoch: 47
2022-11-28 04:18:40,624 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5608422370119528, 'Total loss': 0.5608422370119528} | train loss {'Reaction outcome loss': 0.4631520871605192, 'Total loss': 0.4631520871605192}
2022-11-28 04:18:40,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:40,624 INFO:     Epoch: 48
2022-11-28 04:18:41,280 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.511813779107549, 'Total loss': 0.511813779107549} | train loss {'Reaction outcome loss': 0.46323790608011944, 'Total loss': 0.46323790608011944}
2022-11-28 04:18:41,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:41,280 INFO:     Epoch: 49
2022-11-28 04:18:41,939 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47218922965905885, 'Total loss': 0.47218922965905885} | train loss {'Reaction outcome loss': 0.46140917363215467, 'Total loss': 0.46140917363215467}
2022-11-28 04:18:41,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:41,939 INFO:     Epoch: 50
2022-11-28 04:18:42,597 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.492256797850132, 'Total loss': 0.492256797850132} | train loss {'Reaction outcome loss': 0.45409677417910826, 'Total loss': 0.45409677417910826}
2022-11-28 04:18:42,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:42,597 INFO:     Epoch: 51
2022-11-28 04:18:43,256 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49106667800383136, 'Total loss': 0.49106667800383136} | train loss {'Reaction outcome loss': 0.4637518213719738, 'Total loss': 0.4637518213719738}
2022-11-28 04:18:43,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:43,257 INFO:     Epoch: 52
2022-11-28 04:18:43,913 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4946926175193353, 'Total loss': 0.4946926175193353} | train loss {'Reaction outcome loss': 0.4593708661137795, 'Total loss': 0.4593708661137795}
2022-11-28 04:18:43,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:43,913 INFO:     Epoch: 53
2022-11-28 04:18:44,572 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4661898370832205, 'Total loss': 0.4661898370832205} | train loss {'Reaction outcome loss': 0.4556075625273646, 'Total loss': 0.4556075625273646}
2022-11-28 04:18:44,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:44,574 INFO:     Epoch: 54
2022-11-28 04:18:45,228 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49111108922145585, 'Total loss': 0.49111108922145585} | train loss {'Reaction outcome loss': 0.4602585116515354, 'Total loss': 0.4602585116515354}
2022-11-28 04:18:45,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:45,228 INFO:     Epoch: 55
2022-11-28 04:18:45,889 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4932900524952195, 'Total loss': 0.4932900524952195} | train loss {'Reaction outcome loss': 0.46970583820829587, 'Total loss': 0.46970583820829587}
2022-11-28 04:18:45,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:45,889 INFO:     Epoch: 56
2022-11-28 04:18:46,560 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47539693024009466, 'Total loss': 0.47539693024009466} | train loss {'Reaction outcome loss': 0.4608049390875563, 'Total loss': 0.4608049390875563}
2022-11-28 04:18:46,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:46,561 INFO:     Epoch: 57
2022-11-28 04:18:47,221 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4709082944741981, 'Total loss': 0.4709082944741981} | train loss {'Reaction outcome loss': 0.46100421791173973, 'Total loss': 0.46100421791173973}
2022-11-28 04:18:47,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:47,222 INFO:     Epoch: 58
2022-11-28 04:18:47,879 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47552885894070973, 'Total loss': 0.47552885894070973} | train loss {'Reaction outcome loss': 0.46444020508503425, 'Total loss': 0.46444020508503425}
2022-11-28 04:18:47,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:47,879 INFO:     Epoch: 59
2022-11-28 04:18:48,540 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4907890029928901, 'Total loss': 0.4907890029928901} | train loss {'Reaction outcome loss': 0.4611747229585842, 'Total loss': 0.4611747229585842}
2022-11-28 04:18:48,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:48,540 INFO:     Epoch: 60
2022-11-28 04:18:49,195 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49584339423613116, 'Total loss': 0.49584339423613116} | train loss {'Reaction outcome loss': 0.45694076412794543, 'Total loss': 0.45694076412794543}
2022-11-28 04:18:49,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:49,195 INFO:     Epoch: 61
2022-11-28 04:18:49,850 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5473876060409979, 'Total loss': 0.5473876060409979} | train loss {'Reaction outcome loss': 0.467086223801788, 'Total loss': 0.467086223801788}
2022-11-28 04:18:49,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:49,850 INFO:     Epoch: 62
2022-11-28 04:18:50,505 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5173741917718541, 'Total loss': 0.5173741917718541} | train loss {'Reaction outcome loss': 0.46619098539255105, 'Total loss': 0.46619098539255105}
2022-11-28 04:18:50,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:50,505 INFO:     Epoch: 63
2022-11-28 04:18:51,158 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47081687809391454, 'Total loss': 0.47081687809391454} | train loss {'Reaction outcome loss': 0.46047481204174, 'Total loss': 0.46047481204174}
2022-11-28 04:18:51,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:51,159 INFO:     Epoch: 64
2022-11-28 04:18:51,810 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49309962954033504, 'Total loss': 0.49309962954033504} | train loss {'Reaction outcome loss': 0.4644629402428257, 'Total loss': 0.4644629402428257}
2022-11-28 04:18:51,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:51,811 INFO:     Epoch: 65
2022-11-28 04:18:52,467 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47913211541758344, 'Total loss': 0.47913211541758344} | train loss {'Reaction outcome loss': 0.4633317335223665, 'Total loss': 0.4633317335223665}
2022-11-28 04:18:52,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:52,467 INFO:     Epoch: 66
2022-11-28 04:18:53,120 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4780089675702832, 'Total loss': 0.4780089675702832} | train loss {'Reaction outcome loss': 0.46298737702321036, 'Total loss': 0.46298737702321036}
2022-11-28 04:18:53,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:53,120 INFO:     Epoch: 67
2022-11-28 04:18:53,778 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4826475581662221, 'Total loss': 0.4826475581662221} | train loss {'Reaction outcome loss': 0.46424623168244655, 'Total loss': 0.46424623168244655}
2022-11-28 04:18:53,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:53,778 INFO:     Epoch: 68
2022-11-28 04:18:54,432 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49605046957731247, 'Total loss': 0.49605046957731247} | train loss {'Reaction outcome loss': 0.4640737551207445, 'Total loss': 0.4640737551207445}
2022-11-28 04:18:54,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:54,432 INFO:     Epoch: 69
2022-11-28 04:18:55,084 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4738826100629839, 'Total loss': 0.4738826100629839} | train loss {'Reaction outcome loss': 0.46458553027133553, 'Total loss': 0.46458553027133553}
2022-11-28 04:18:55,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:55,084 INFO:     Epoch: 70
2022-11-28 04:18:55,738 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5050866150043227, 'Total loss': 0.5050866150043227} | train loss {'Reaction outcome loss': 0.4650153418584746, 'Total loss': 0.4650153418584746}
2022-11-28 04:18:55,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:55,739 INFO:     Epoch: 71
2022-11-28 04:18:56,394 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5023007785732095, 'Total loss': 0.5023007785732095} | train loss {'Reaction outcome loss': 0.46584084033966067, 'Total loss': 0.46584084033966067}
2022-11-28 04:18:56,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:56,394 INFO:     Epoch: 72
2022-11-28 04:18:57,046 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5177630443464626, 'Total loss': 0.5177630443464626} | train loss {'Reaction outcome loss': 0.45631256790793673, 'Total loss': 0.45631256790793673}
2022-11-28 04:18:57,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:57,046 INFO:     Epoch: 73
2022-11-28 04:18:57,696 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5106374347074465, 'Total loss': 0.5106374347074465} | train loss {'Reaction outcome loss': 0.469001860886204, 'Total loss': 0.469001860886204}
2022-11-28 04:18:57,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:57,696 INFO:     Epoch: 74
2022-11-28 04:18:58,347 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5220341469076547, 'Total loss': 0.5220341469076547} | train loss {'Reaction outcome loss': 0.4558462085164323, 'Total loss': 0.4558462085164323}
2022-11-28 04:18:58,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:58,348 INFO:     Epoch: 75
2022-11-28 04:18:59,000 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5159010846506465, 'Total loss': 0.5159010846506465} | train loss {'Reaction outcome loss': 0.46788096902321796, 'Total loss': 0.46788096902321796}
2022-11-28 04:18:59,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:59,000 INFO:     Epoch: 76
2022-11-28 04:18:59,654 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5022605481472883, 'Total loss': 0.5022605481472883} | train loss {'Reaction outcome loss': 0.4722987573365776, 'Total loss': 0.4722987573365776}
2022-11-28 04:18:59,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:18:59,654 INFO:     Epoch: 77
2022-11-28 04:19:00,303 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48062365950847213, 'Total loss': 0.48062365950847213} | train loss {'Reaction outcome loss': 0.45653528887398387, 'Total loss': 0.45653528887398387}
2022-11-28 04:19:00,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:00,303 INFO:     Epoch: 78
2022-11-28 04:19:00,958 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47645813768560236, 'Total loss': 0.47645813768560236} | train loss {'Reaction outcome loss': 0.46147595011458103, 'Total loss': 0.46147595011458103}
2022-11-28 04:19:00,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:00,958 INFO:     Epoch: 79
2022-11-28 04:19:01,612 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48722721670161595, 'Total loss': 0.48722721670161595} | train loss {'Reaction outcome loss': 0.4638918989775132, 'Total loss': 0.4638918989775132}
2022-11-28 04:19:01,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:01,613 INFO:     Epoch: 80
2022-11-28 04:19:02,266 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48115384714169934, 'Total loss': 0.48115384714169934} | train loss {'Reaction outcome loss': 0.4589391965647133, 'Total loss': 0.4589391965647133}
2022-11-28 04:19:02,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:02,266 INFO:     Epoch: 81
2022-11-28 04:19:02,916 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5037360022013838, 'Total loss': 0.5037360022013838} | train loss {'Reaction outcome loss': 0.46615479406045407, 'Total loss': 0.46615479406045407}
2022-11-28 04:19:02,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:02,916 INFO:     Epoch: 82
2022-11-28 04:19:03,568 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4820390377532352, 'Total loss': 0.4820390377532352} | train loss {'Reaction outcome loss': 0.4680409810980972, 'Total loss': 0.4680409810980972}
2022-11-28 04:19:03,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:03,569 INFO:     Epoch: 83
2022-11-28 04:19:04,220 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4805105375972661, 'Total loss': 0.4805105375972661} | train loss {'Reaction outcome loss': 0.46362552217074804, 'Total loss': 0.46362552217074804}
2022-11-28 04:19:04,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:04,220 INFO:     Epoch: 84
2022-11-28 04:19:04,873 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48299346322363074, 'Total loss': 0.48299346322363074} | train loss {'Reaction outcome loss': 0.4579706016851931, 'Total loss': 0.4579706016851931}
2022-11-28 04:19:04,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:04,873 INFO:     Epoch: 85
2022-11-28 04:19:05,527 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4801604575054212, 'Total loss': 0.4801604575054212} | train loss {'Reaction outcome loss': 0.4613727607289139, 'Total loss': 0.4613727607289139}
2022-11-28 04:19:05,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:05,528 INFO:     Epoch: 86
2022-11-28 04:19:06,183 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4755347858775746, 'Total loss': 0.4755347858775746} | train loss {'Reaction outcome loss': 0.4599981208845061, 'Total loss': 0.4599981208845061}
2022-11-28 04:19:06,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:06,183 INFO:     Epoch: 87
2022-11-28 04:19:06,835 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48311580141836946, 'Total loss': 0.48311580141836946} | train loss {'Reaction outcome loss': 0.45904090118651486, 'Total loss': 0.45904090118651486}
2022-11-28 04:19:06,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:06,835 INFO:     Epoch: 88
2022-11-28 04:19:07,489 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4929026246748187, 'Total loss': 0.4929026246748187} | train loss {'Reaction outcome loss': 0.4607666280196637, 'Total loss': 0.4607666280196637}
2022-11-28 04:19:07,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:07,489 INFO:     Epoch: 89
2022-11-28 04:19:08,141 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.470550193705342, 'Total loss': 0.470550193705342} | train loss {'Reaction outcome loss': 0.4607227013427384, 'Total loss': 0.4607227013427384}
2022-11-28 04:19:08,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:08,141 INFO:     Epoch: 90
2022-11-28 04:19:08,792 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.623337228528478, 'Total loss': 0.623337228528478} | train loss {'Reaction outcome loss': 0.45901722737721035, 'Total loss': 0.45901722737721035}
2022-11-28 04:19:08,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:08,793 INFO:     Epoch: 91
2022-11-28 04:19:09,444 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.516120407730341, 'Total loss': 0.516120407730341} | train loss {'Reaction outcome loss': 0.4621631758553641, 'Total loss': 0.4621631758553641}
2022-11-28 04:19:09,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:09,444 INFO:     Epoch: 92
2022-11-28 04:19:10,095 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5016553512012417, 'Total loss': 0.5016553512012417} | train loss {'Reaction outcome loss': 0.46452672299073666, 'Total loss': 0.46452672299073666}
2022-11-28 04:19:10,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:10,096 INFO:     Epoch: 93
2022-11-28 04:19:10,748 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49422673000530765, 'Total loss': 0.49422673000530765} | train loss {'Reaction outcome loss': 0.46707367215837753, 'Total loss': 0.46707367215837753}
2022-11-28 04:19:10,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:10,748 INFO:     Epoch: 94
2022-11-28 04:19:11,402 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47288741933351214, 'Total loss': 0.47288741933351214} | train loss {'Reaction outcome loss': 0.45679376180074655, 'Total loss': 0.45679376180074655}
2022-11-28 04:19:11,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:11,403 INFO:     Epoch: 95
2022-11-28 04:19:12,055 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49486039782112295, 'Total loss': 0.49486039782112295} | train loss {'Reaction outcome loss': 0.4616861513074563, 'Total loss': 0.4616861513074563}
2022-11-28 04:19:12,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:12,055 INFO:     Epoch: 96
2022-11-28 04:19:12,707 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47322842461819, 'Total loss': 0.47322842461819} | train loss {'Reaction outcome loss': 0.45794050614444576, 'Total loss': 0.45794050614444576}
2022-11-28 04:19:12,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:12,708 INFO:     Epoch: 97
2022-11-28 04:19:13,360 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4801135930148038, 'Total loss': 0.4801135930148038} | train loss {'Reaction outcome loss': 0.46412288066075774, 'Total loss': 0.46412288066075774}
2022-11-28 04:19:13,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:13,360 INFO:     Epoch: 98
2022-11-28 04:19:14,008 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4711995195936073, 'Total loss': 0.4711995195936073} | train loss {'Reaction outcome loss': 0.4657440607036863, 'Total loss': 0.4657440607036863}
2022-11-28 04:19:14,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:14,008 INFO:     Epoch: 99
2022-11-28 04:19:14,656 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49771389297463675, 'Total loss': 0.49771389297463675} | train loss {'Reaction outcome loss': 0.4605866309331388, 'Total loss': 0.4605866309331388}
2022-11-28 04:19:14,656 INFO:     Best model found after epoch 45 of 100.
2022-11-28 04:19:14,657 INFO:   Done with stage: TRAINING
2022-11-28 04:19:14,657 INFO:   Starting stage: EVALUATION
2022-11-28 04:19:14,781 INFO:   Done with stage: EVALUATION
2022-11-28 04:19:14,781 INFO:   Leaving out SEQ value Fold_8
2022-11-28 04:19:14,794 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:19:14,794 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:19:15,437 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:19:15,437 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:19:15,505 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:19:15,505 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:19:15,505 INFO:     No hyperparam tuning for this model
2022-11-28 04:19:15,505 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:19:15,505 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:19:15,506 INFO:     None feature selector for col prot
2022-11-28 04:19:15,506 INFO:     None feature selector for col prot
2022-11-28 04:19:15,506 INFO:     None feature selector for col prot
2022-11-28 04:19:15,507 INFO:     None feature selector for col chem
2022-11-28 04:19:15,507 INFO:     None feature selector for col chem
2022-11-28 04:19:15,507 INFO:     None feature selector for col chem
2022-11-28 04:19:15,507 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:19:15,507 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:19:15,509 INFO:     Number of params in model 169651
2022-11-28 04:19:15,512 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:19:15,512 INFO:   Starting stage: TRAINING
2022-11-28 04:19:15,563 INFO:     Val loss before train {'Reaction outcome loss': 0.9898400184783068, 'Total loss': 0.9898400184783068}
2022-11-28 04:19:15,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:15,564 INFO:     Epoch: 0
2022-11-28 04:19:16,221 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5980674062262882, 'Total loss': 0.5980674062262882} | train loss {'Reaction outcome loss': 0.69482539882583, 'Total loss': 0.69482539882583}
2022-11-28 04:19:16,222 INFO:     Found new best model at epoch 0
2022-11-28 04:19:16,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:16,222 INFO:     Epoch: 1
2022-11-28 04:19:16,881 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5147081261331384, 'Total loss': 0.5147081261331384} | train loss {'Reaction outcome loss': 0.5878891792869375, 'Total loss': 0.5878891792869375}
2022-11-28 04:19:16,881 INFO:     Found new best model at epoch 1
2022-11-28 04:19:16,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:16,882 INFO:     Epoch: 2
2022-11-28 04:19:17,546 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5084179152141918, 'Total loss': 0.5084179152141918} | train loss {'Reaction outcome loss': 0.5454004735595757, 'Total loss': 0.5454004735595757}
2022-11-28 04:19:17,546 INFO:     Found new best model at epoch 2
2022-11-28 04:19:17,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:17,547 INFO:     Epoch: 3
2022-11-28 04:19:18,212 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5195626203309406, 'Total loss': 0.5195626203309406} | train loss {'Reaction outcome loss': 0.5309319425854953, 'Total loss': 0.5309319425854953}
2022-11-28 04:19:18,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:18,213 INFO:     Epoch: 4
2022-11-28 04:19:18,882 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4874625703827901, 'Total loss': 0.4874625703827901} | train loss {'Reaction outcome loss': 0.5166092531815651, 'Total loss': 0.5166092531815651}
2022-11-28 04:19:18,882 INFO:     Found new best model at epoch 4
2022-11-28 04:19:18,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:18,883 INFO:     Epoch: 5
2022-11-28 04:19:19,552 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5124828075482086, 'Total loss': 0.5124828075482086} | train loss {'Reaction outcome loss': 0.5161926339290315, 'Total loss': 0.5161926339290315}
2022-11-28 04:19:19,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:19,553 INFO:     Epoch: 6
2022-11-28 04:19:20,217 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4783607416532256, 'Total loss': 0.4783607416532256} | train loss {'Reaction outcome loss': 0.49765589112235653, 'Total loss': 0.49765589112235653}
2022-11-28 04:19:20,217 INFO:     Found new best model at epoch 6
2022-11-28 04:19:20,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:20,218 INFO:     Epoch: 7
2022-11-28 04:19:20,884 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5334738560698249, 'Total loss': 0.5334738560698249} | train loss {'Reaction outcome loss': 0.49639443878925615, 'Total loss': 0.49639443878925615}
2022-11-28 04:19:20,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:20,885 INFO:     Epoch: 8
2022-11-28 04:19:21,554 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45182902907783334, 'Total loss': 0.45182902907783334} | train loss {'Reaction outcome loss': 0.4991681927274312, 'Total loss': 0.4991681927274312}
2022-11-28 04:19:21,554 INFO:     Found new best model at epoch 8
2022-11-28 04:19:21,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:21,555 INFO:     Epoch: 9
2022-11-28 04:19:22,224 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4679381349547343, 'Total loss': 0.4679381349547343} | train loss {'Reaction outcome loss': 0.4827803146815108, 'Total loss': 0.4827803146815108}
2022-11-28 04:19:22,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:22,225 INFO:     Epoch: 10
2022-11-28 04:19:22,893 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4637968072837049, 'Total loss': 0.4637968072837049} | train loss {'Reaction outcome loss': 0.48179532383238116, 'Total loss': 0.48179532383238116}
2022-11-28 04:19:22,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:22,894 INFO:     Epoch: 11
2022-11-28 04:19:23,561 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4870096573775465, 'Total loss': 0.4870096573775465} | train loss {'Reaction outcome loss': 0.4867276515090658, 'Total loss': 0.4867276515090658}
2022-11-28 04:19:23,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:23,562 INFO:     Epoch: 12
2022-11-28 04:19:24,226 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4630603150210597, 'Total loss': 0.4630603150210597} | train loss {'Reaction outcome loss': 0.4758797832314045, 'Total loss': 0.4758797832314045}
2022-11-28 04:19:24,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:24,226 INFO:     Epoch: 13
2022-11-28 04:19:24,892 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45495504987510765, 'Total loss': 0.45495504987510765} | train loss {'Reaction outcome loss': 0.4878397242075974, 'Total loss': 0.4878397242075974}
2022-11-28 04:19:24,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:24,892 INFO:     Epoch: 14
2022-11-28 04:19:25,560 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4396728477017446, 'Total loss': 0.4396728477017446} | train loss {'Reaction outcome loss': 0.4781333680955633, 'Total loss': 0.4781333680955633}
2022-11-28 04:19:25,560 INFO:     Found new best model at epoch 14
2022-11-28 04:19:25,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:25,561 INFO:     Epoch: 15
2022-11-28 04:19:26,226 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43764736638827756, 'Total loss': 0.43764736638827756} | train loss {'Reaction outcome loss': 0.4771116067685427, 'Total loss': 0.4771116067685427}
2022-11-28 04:19:26,226 INFO:     Found new best model at epoch 15
2022-11-28 04:19:26,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:26,227 INFO:     Epoch: 16
2022-11-28 04:19:26,896 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5110143538225781, 'Total loss': 0.5110143538225781} | train loss {'Reaction outcome loss': 0.4762993958748637, 'Total loss': 0.4762993958748637}
2022-11-28 04:19:26,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:26,896 INFO:     Epoch: 17
2022-11-28 04:19:27,565 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45355837724425574, 'Total loss': 0.45355837724425574} | train loss {'Reaction outcome loss': 0.4839349528474192, 'Total loss': 0.4839349528474192}
2022-11-28 04:19:27,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:27,565 INFO:     Epoch: 18
2022-11-28 04:19:28,235 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4461246297102083, 'Total loss': 0.4461246297102083} | train loss {'Reaction outcome loss': 0.4746876490572768, 'Total loss': 0.4746876490572768}
2022-11-28 04:19:28,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:28,235 INFO:     Epoch: 19
2022-11-28 04:19:28,903 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45481893386353145, 'Total loss': 0.45481893386353145} | train loss {'Reaction outcome loss': 0.487094916102867, 'Total loss': 0.487094916102867}
2022-11-28 04:19:28,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:28,903 INFO:     Epoch: 20
2022-11-28 04:19:29,569 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47086072814735497, 'Total loss': 0.47086072814735497} | train loss {'Reaction outcome loss': 0.4795338037393747, 'Total loss': 0.4795338037393747}
2022-11-28 04:19:29,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:29,569 INFO:     Epoch: 21
2022-11-28 04:19:30,236 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4743764325976372, 'Total loss': 0.4743764325976372} | train loss {'Reaction outcome loss': 0.4719169406040061, 'Total loss': 0.4719169406040061}
2022-11-28 04:19:30,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:30,237 INFO:     Epoch: 22
2022-11-28 04:19:30,903 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4538840465247631, 'Total loss': 0.4538840465247631} | train loss {'Reaction outcome loss': 0.4792335149982283, 'Total loss': 0.4792335149982283}
2022-11-28 04:19:30,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:30,903 INFO:     Epoch: 23
2022-11-28 04:19:31,572 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45679867470806296, 'Total loss': 0.45679867470806296} | train loss {'Reaction outcome loss': 0.48044423614778825, 'Total loss': 0.48044423614778825}
2022-11-28 04:19:31,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:31,572 INFO:     Epoch: 24
2022-11-28 04:19:32,238 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48090719092975964, 'Total loss': 0.48090719092975964} | train loss {'Reaction outcome loss': 0.47602164733313745, 'Total loss': 0.47602164733313745}
2022-11-28 04:19:32,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:32,238 INFO:     Epoch: 25
2022-11-28 04:19:32,910 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.476819651032036, 'Total loss': 0.476819651032036} | train loss {'Reaction outcome loss': 0.4763933184646791, 'Total loss': 0.4763933184646791}
2022-11-28 04:19:32,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:32,910 INFO:     Epoch: 26
2022-11-28 04:19:33,579 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48633494634519925, 'Total loss': 0.48633494634519925} | train loss {'Reaction outcome loss': 0.4778768045887832, 'Total loss': 0.4778768045887832}
2022-11-28 04:19:33,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:33,580 INFO:     Epoch: 27
2022-11-28 04:19:34,246 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4633890872990543, 'Total loss': 0.4633890872990543} | train loss {'Reaction outcome loss': 0.4783929577998577, 'Total loss': 0.4783929577998577}
2022-11-28 04:19:34,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:34,247 INFO:     Epoch: 28
2022-11-28 04:19:34,915 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4770866981284185, 'Total loss': 0.4770866981284185} | train loss {'Reaction outcome loss': 0.4737277149913772, 'Total loss': 0.4737277149913772}
2022-11-28 04:19:34,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:34,915 INFO:     Epoch: 29
2022-11-28 04:19:35,578 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45446968180212105, 'Total loss': 0.45446968180212105} | train loss {'Reaction outcome loss': 0.4840402670444981, 'Total loss': 0.4840402670444981}
2022-11-28 04:19:35,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:35,579 INFO:     Epoch: 30
2022-11-28 04:19:36,246 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4832997488027269, 'Total loss': 0.4832997488027269} | train loss {'Reaction outcome loss': 0.4793614929602031, 'Total loss': 0.4793614929602031}
2022-11-28 04:19:36,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:36,247 INFO:     Epoch: 31
2022-11-28 04:19:36,913 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47811092842708935, 'Total loss': 0.47811092842708935} | train loss {'Reaction outcome loss': 0.4702103057155205, 'Total loss': 0.4702103057155205}
2022-11-28 04:19:36,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:36,913 INFO:     Epoch: 32
2022-11-28 04:19:37,581 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4845442392609336, 'Total loss': 0.4845442392609336} | train loss {'Reaction outcome loss': 0.47878890400452, 'Total loss': 0.47878890400452}
2022-11-28 04:19:37,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:37,581 INFO:     Epoch: 33
2022-11-28 04:19:38,248 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5364359796724536, 'Total loss': 0.5364359796724536} | train loss {'Reaction outcome loss': 0.4733687837518031, 'Total loss': 0.4733687837518031}
2022-11-28 04:19:38,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:38,249 INFO:     Epoch: 34
2022-11-28 04:19:38,915 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4522250416603955, 'Total loss': 0.4522250416603955} | train loss {'Reaction outcome loss': 0.47518242799466653, 'Total loss': 0.47518242799466653}
2022-11-28 04:19:38,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:38,915 INFO:     Epoch: 35
2022-11-28 04:19:39,580 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4649835276332768, 'Total loss': 0.4649835276332768} | train loss {'Reaction outcome loss': 0.4749903507050007, 'Total loss': 0.4749903507050007}
2022-11-28 04:19:39,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:39,581 INFO:     Epoch: 36
2022-11-28 04:19:40,249 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47060421684926207, 'Total loss': 0.47060421684926207} | train loss {'Reaction outcome loss': 0.47735872263869933, 'Total loss': 0.47735872263869933}
2022-11-28 04:19:40,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:40,250 INFO:     Epoch: 37
2022-11-28 04:19:40,917 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5165331136773933, 'Total loss': 0.5165331136773933} | train loss {'Reaction outcome loss': 0.47417337152986755, 'Total loss': 0.47417337152986755}
2022-11-28 04:19:40,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:40,917 INFO:     Epoch: 38
2022-11-28 04:19:41,587 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47134847058491275, 'Total loss': 0.47134847058491275} | train loss {'Reaction outcome loss': 0.47399616403685463, 'Total loss': 0.47399616403685463}
2022-11-28 04:19:41,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:41,587 INFO:     Epoch: 39
2022-11-28 04:19:42,253 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4785170741379261, 'Total loss': 0.4785170741379261} | train loss {'Reaction outcome loss': 0.4717520017837805, 'Total loss': 0.4717520017837805}
2022-11-28 04:19:42,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:42,253 INFO:     Epoch: 40
2022-11-28 04:19:42,920 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4579275318167426, 'Total loss': 0.4579275318167426} | train loss {'Reaction outcome loss': 0.4739662977836786, 'Total loss': 0.4739662977836786}
2022-11-28 04:19:42,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:42,920 INFO:     Epoch: 41
2022-11-28 04:19:43,585 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4784240499138832, 'Total loss': 0.4784240499138832} | train loss {'Reaction outcome loss': 0.46889717708672246, 'Total loss': 0.46889717708672246}
2022-11-28 04:19:43,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:43,585 INFO:     Epoch: 42
2022-11-28 04:19:44,253 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.468260545283556, 'Total loss': 0.468260545283556} | train loss {'Reaction outcome loss': 0.4736349481127916, 'Total loss': 0.4736349481127916}
2022-11-28 04:19:44,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:44,253 INFO:     Epoch: 43
2022-11-28 04:19:44,922 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45364397865804756, 'Total loss': 0.45364397865804756} | train loss {'Reaction outcome loss': 0.4784991159554451, 'Total loss': 0.4784991159554451}
2022-11-28 04:19:44,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:44,923 INFO:     Epoch: 44
2022-11-28 04:19:45,593 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47889203239570965, 'Total loss': 0.47889203239570965} | train loss {'Reaction outcome loss': 0.4778170337479922, 'Total loss': 0.4778170337479922}
2022-11-28 04:19:45,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:45,593 INFO:     Epoch: 45
2022-11-28 04:19:46,262 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4777174432846633, 'Total loss': 0.4777174432846633} | train loss {'Reaction outcome loss': 0.4694368386821401, 'Total loss': 0.4694368386821401}
2022-11-28 04:19:46,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:46,262 INFO:     Epoch: 46
2022-11-28 04:19:46,923 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4878616136583415, 'Total loss': 0.4878616136583415} | train loss {'Reaction outcome loss': 0.47458965439469586, 'Total loss': 0.47458965439469586}
2022-11-28 04:19:46,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:46,924 INFO:     Epoch: 47
2022-11-28 04:19:47,588 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45995647832751274, 'Total loss': 0.45995647832751274} | train loss {'Reaction outcome loss': 0.4738667269027041, 'Total loss': 0.4738667269027041}
2022-11-28 04:19:47,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:47,588 INFO:     Epoch: 48
2022-11-28 04:19:48,253 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5028755603866144, 'Total loss': 0.5028755603866144} | train loss {'Reaction outcome loss': 0.46676208379287876, 'Total loss': 0.46676208379287876}
2022-11-28 04:19:48,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:48,253 INFO:     Epoch: 49
2022-11-28 04:19:48,917 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4906967929141088, 'Total loss': 0.4906967929141088} | train loss {'Reaction outcome loss': 0.47729944044183337, 'Total loss': 0.47729944044183337}
2022-11-28 04:19:48,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:48,918 INFO:     Epoch: 50
2022-11-28 04:19:49,578 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4597118131139062, 'Total loss': 0.4597118131139062} | train loss {'Reaction outcome loss': 0.47833422060695385, 'Total loss': 0.47833422060695385}
2022-11-28 04:19:49,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:49,578 INFO:     Epoch: 51
2022-11-28 04:19:50,239 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48266840048811654, 'Total loss': 0.48266840048811654} | train loss {'Reaction outcome loss': 0.46971255210378476, 'Total loss': 0.46971255210378476}
2022-11-28 04:19:50,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:50,239 INFO:     Epoch: 52
2022-11-28 04:19:50,902 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45872341468930244, 'Total loss': 0.45872341468930244} | train loss {'Reaction outcome loss': 0.47287491540754995, 'Total loss': 0.47287491540754995}
2022-11-28 04:19:50,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:50,902 INFO:     Epoch: 53
2022-11-28 04:19:51,566 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45587479492480104, 'Total loss': 0.45587479492480104} | train loss {'Reaction outcome loss': 0.4728902141533552, 'Total loss': 0.4728902141533552}
2022-11-28 04:19:51,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:51,566 INFO:     Epoch: 54
2022-11-28 04:19:52,227 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4861403050070459, 'Total loss': 0.4861403050070459} | train loss {'Reaction outcome loss': 0.46825542661451525, 'Total loss': 0.46825542661451525}
2022-11-28 04:19:52,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:52,227 INFO:     Epoch: 55
2022-11-28 04:19:52,891 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4876743331551552, 'Total loss': 0.4876743331551552} | train loss {'Reaction outcome loss': 0.469462514374285, 'Total loss': 0.469462514374285}
2022-11-28 04:19:52,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:52,891 INFO:     Epoch: 56
2022-11-28 04:19:53,556 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4671706675805829, 'Total loss': 0.4671706675805829} | train loss {'Reaction outcome loss': 0.4683192368716963, 'Total loss': 0.4683192368716963}
2022-11-28 04:19:53,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:53,556 INFO:     Epoch: 57
2022-11-28 04:19:54,218 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47061567211692984, 'Total loss': 0.47061567211692984} | train loss {'Reaction outcome loss': 0.47147440537810326, 'Total loss': 0.47147440537810326}
2022-11-28 04:19:54,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:54,218 INFO:     Epoch: 58
2022-11-28 04:19:54,879 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4805027971213514, 'Total loss': 0.4805027971213514} | train loss {'Reaction outcome loss': 0.4668435882476549, 'Total loss': 0.4668435882476549}
2022-11-28 04:19:54,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:54,879 INFO:     Epoch: 59
2022-11-28 04:19:55,542 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4646677767688578, 'Total loss': 0.4646677767688578} | train loss {'Reaction outcome loss': 0.4727109738535458, 'Total loss': 0.4727109738535458}
2022-11-28 04:19:55,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:55,542 INFO:     Epoch: 60
2022-11-28 04:19:56,202 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4940260018814694, 'Total loss': 0.4940260018814694} | train loss {'Reaction outcome loss': 0.47242939616403273, 'Total loss': 0.47242939616403273}
2022-11-28 04:19:56,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:56,202 INFO:     Epoch: 61
2022-11-28 04:19:56,866 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47644416107372806, 'Total loss': 0.47644416107372806} | train loss {'Reaction outcome loss': 0.4737376617568155, 'Total loss': 0.4737376617568155}
2022-11-28 04:19:56,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:56,866 INFO:     Epoch: 62
2022-11-28 04:19:57,529 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4652096246453849, 'Total loss': 0.4652096246453849} | train loss {'Reaction outcome loss': 0.468352529490667, 'Total loss': 0.468352529490667}
2022-11-28 04:19:57,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:57,529 INFO:     Epoch: 63
2022-11-28 04:19:58,190 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47231623056260025, 'Total loss': 0.47231623056260025} | train loss {'Reaction outcome loss': 0.47466560621415416, 'Total loss': 0.47466560621415416}
2022-11-28 04:19:58,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:58,190 INFO:     Epoch: 64
2022-11-28 04:19:58,849 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46974419158968056, 'Total loss': 0.46974419158968056} | train loss {'Reaction outcome loss': 0.46713204621787996, 'Total loss': 0.46713204621787996}
2022-11-28 04:19:58,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:58,849 INFO:     Epoch: 65
2022-11-28 04:19:59,513 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46103567155924713, 'Total loss': 0.46103567155924713} | train loss {'Reaction outcome loss': 0.4738813675940037, 'Total loss': 0.4738813675940037}
2022-11-28 04:19:59,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:19:59,513 INFO:     Epoch: 66
2022-11-28 04:20:00,176 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45440237020904367, 'Total loss': 0.45440237020904367} | train loss {'Reaction outcome loss': 0.4737522429035556, 'Total loss': 0.4737522429035556}
2022-11-28 04:20:00,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:00,176 INFO:     Epoch: 67
2022-11-28 04:20:00,839 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4727679772133177, 'Total loss': 0.4727679772133177} | train loss {'Reaction outcome loss': 0.4707393503237155, 'Total loss': 0.4707393503237155}
2022-11-28 04:20:00,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:00,839 INFO:     Epoch: 68
2022-11-28 04:20:01,501 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46096320247108286, 'Total loss': 0.46096320247108286} | train loss {'Reaction outcome loss': 0.46356257141357465, 'Total loss': 0.46356257141357465}
2022-11-28 04:20:01,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:01,501 INFO:     Epoch: 69
2022-11-28 04:20:02,165 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.466144168918783, 'Total loss': 0.466144168918783} | train loss {'Reaction outcome loss': 0.46233322771806873, 'Total loss': 0.46233322771806873}
2022-11-28 04:20:02,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:02,165 INFO:     Epoch: 70
2022-11-28 04:20:02,828 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45448343049396167, 'Total loss': 0.45448343049396167} | train loss {'Reaction outcome loss': 0.4631505529246023, 'Total loss': 0.4631505529246023}
2022-11-28 04:20:02,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:02,828 INFO:     Epoch: 71
2022-11-28 04:20:03,494 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48255485499447043, 'Total loss': 0.48255485499447043} | train loss {'Reaction outcome loss': 0.4689905052223513, 'Total loss': 0.4689905052223513}
2022-11-28 04:20:03,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:03,494 INFO:     Epoch: 72
2022-11-28 04:20:04,161 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49534694173119287, 'Total loss': 0.49534694173119287} | train loss {'Reaction outcome loss': 0.47234252789208003, 'Total loss': 0.47234252789208003}
2022-11-28 04:20:04,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:04,161 INFO:     Epoch: 73
2022-11-28 04:20:04,829 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47000231729312375, 'Total loss': 0.47000231729312375} | train loss {'Reaction outcome loss': 0.47031453555269587, 'Total loss': 0.47031453555269587}
2022-11-28 04:20:04,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:04,829 INFO:     Epoch: 74
2022-11-28 04:20:05,496 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48146640306169336, 'Total loss': 0.48146640306169336} | train loss {'Reaction outcome loss': 0.4643660564456255, 'Total loss': 0.4643660564456255}
2022-11-28 04:20:05,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:05,496 INFO:     Epoch: 75
2022-11-28 04:20:06,162 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4654224802824584, 'Total loss': 0.4654224802824584} | train loss {'Reaction outcome loss': 0.47370287703890956, 'Total loss': 0.47370287703890956}
2022-11-28 04:20:06,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:06,163 INFO:     Epoch: 76
2022-11-28 04:20:06,825 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46351430768316443, 'Total loss': 0.46351430768316443} | train loss {'Reaction outcome loss': 0.46538787617558436, 'Total loss': 0.46538787617558436}
2022-11-28 04:20:06,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:06,825 INFO:     Epoch: 77
2022-11-28 04:20:07,491 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47848017886281013, 'Total loss': 0.47848017886281013} | train loss {'Reaction outcome loss': 0.4736902010176451, 'Total loss': 0.4736902010176451}
2022-11-28 04:20:07,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:07,491 INFO:     Epoch: 78
2022-11-28 04:20:08,158 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48103241520849144, 'Total loss': 0.48103241520849144} | train loss {'Reaction outcome loss': 0.47379888504022555, 'Total loss': 0.47379888504022555}
2022-11-28 04:20:08,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:08,158 INFO:     Epoch: 79
2022-11-28 04:20:08,826 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46806227280334994, 'Total loss': 0.46806227280334994} | train loss {'Reaction outcome loss': 0.47497511144366955, 'Total loss': 0.47497511144366955}
2022-11-28 04:20:08,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:08,826 INFO:     Epoch: 80
2022-11-28 04:20:09,493 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4580939330837943, 'Total loss': 0.4580939330837943} | train loss {'Reaction outcome loss': 0.4706116383594851, 'Total loss': 0.4706116383594851}
2022-11-28 04:20:09,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:09,493 INFO:     Epoch: 81
2022-11-28 04:20:10,163 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4676182442768054, 'Total loss': 0.4676182442768054} | train loss {'Reaction outcome loss': 0.4720204248423538, 'Total loss': 0.4720204248423538}
2022-11-28 04:20:10,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:10,163 INFO:     Epoch: 82
2022-11-28 04:20:10,830 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46782316910949623, 'Total loss': 0.46782316910949623} | train loss {'Reaction outcome loss': 0.47140974154876125, 'Total loss': 0.47140974154876125}
2022-11-28 04:20:10,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:10,830 INFO:     Epoch: 83
2022-11-28 04:20:11,500 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4479775626889684, 'Total loss': 0.4479775626889684} | train loss {'Reaction outcome loss': 0.46742727595471567, 'Total loss': 0.46742727595471567}
2022-11-28 04:20:11,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:11,500 INFO:     Epoch: 84
2022-11-28 04:20:12,167 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47502831742167473, 'Total loss': 0.47502831742167473} | train loss {'Reaction outcome loss': 0.4658310644689106, 'Total loss': 0.4658310644689106}
2022-11-28 04:20:12,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:12,167 INFO:     Epoch: 85
2022-11-28 04:20:12,837 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46709228273142467, 'Total loss': 0.46709228273142467} | train loss {'Reaction outcome loss': 0.4707216432378177, 'Total loss': 0.4707216432378177}
2022-11-28 04:20:12,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:12,838 INFO:     Epoch: 86
2022-11-28 04:20:13,507 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48303631760857324, 'Total loss': 0.48303631760857324} | train loss {'Reaction outcome loss': 0.470942668676857, 'Total loss': 0.470942668676857}
2022-11-28 04:20:13,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:13,507 INFO:     Epoch: 87
2022-11-28 04:20:14,169 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4867841394787485, 'Total loss': 0.4867841394787485} | train loss {'Reaction outcome loss': 0.47030004294168565, 'Total loss': 0.47030004294168565}
2022-11-28 04:20:14,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:14,170 INFO:     Epoch: 88
2022-11-28 04:20:14,836 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4697719128294425, 'Total loss': 0.4697719128294425} | train loss {'Reaction outcome loss': 0.4641360220529379, 'Total loss': 0.4641360220529379}
2022-11-28 04:20:14,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:14,836 INFO:     Epoch: 89
2022-11-28 04:20:15,506 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48590743338519876, 'Total loss': 0.48590743338519876} | train loss {'Reaction outcome loss': 0.46971271175049967, 'Total loss': 0.46971271175049967}
2022-11-28 04:20:15,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:15,507 INFO:     Epoch: 90
2022-11-28 04:20:16,175 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4585387591611255, 'Total loss': 0.4585387591611255} | train loss {'Reaction outcome loss': 0.46528897182114665, 'Total loss': 0.46528897182114665}
2022-11-28 04:20:16,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:16,175 INFO:     Epoch: 91
2022-11-28 04:20:16,844 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4548757489431988, 'Total loss': 0.4548757489431988} | train loss {'Reaction outcome loss': 0.47103001757134355, 'Total loss': 0.47103001757134355}
2022-11-28 04:20:16,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:16,844 INFO:     Epoch: 92
2022-11-28 04:20:17,513 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4771326942877336, 'Total loss': 0.4771326942877336} | train loss {'Reaction outcome loss': 0.46559178078126523, 'Total loss': 0.46559178078126523}
2022-11-28 04:20:17,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:17,514 INFO:     Epoch: 93
2022-11-28 04:20:18,183 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45946448194709694, 'Total loss': 0.45946448194709694} | train loss {'Reaction outcome loss': 0.46796519219154314, 'Total loss': 0.46796519219154314}
2022-11-28 04:20:18,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:18,183 INFO:     Epoch: 94
2022-11-28 04:20:18,852 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4727412401275201, 'Total loss': 0.4727412401275201} | train loss {'Reaction outcome loss': 0.46573319898978355, 'Total loss': 0.46573319898978355}
2022-11-28 04:20:18,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:18,852 INFO:     Epoch: 95
2022-11-28 04:20:19,519 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4535535729744218, 'Total loss': 0.4535535729744218} | train loss {'Reaction outcome loss': 0.464685840231757, 'Total loss': 0.464685840231757}
2022-11-28 04:20:19,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:19,519 INFO:     Epoch: 96
2022-11-28 04:20:20,188 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4668881507082419, 'Total loss': 0.4668881507082419} | train loss {'Reaction outcome loss': 0.4764419360867431, 'Total loss': 0.4764419360867431}
2022-11-28 04:20:20,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:20,188 INFO:     Epoch: 97
2022-11-28 04:20:20,855 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4679598821835084, 'Total loss': 0.4679598821835084} | train loss {'Reaction outcome loss': 0.46374099731685653, 'Total loss': 0.46374099731685653}
2022-11-28 04:20:20,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:20,855 INFO:     Epoch: 98
2022-11-28 04:20:21,524 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4781574403697794, 'Total loss': 0.4781574403697794} | train loss {'Reaction outcome loss': 0.47374485364003527, 'Total loss': 0.47374485364003527}
2022-11-28 04:20:21,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:21,524 INFO:     Epoch: 99
2022-11-28 04:20:22,192 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4531954032453624, 'Total loss': 0.4531954032453624} | train loss {'Reaction outcome loss': 0.464594139026538, 'Total loss': 0.464594139026538}
2022-11-28 04:20:22,192 INFO:     Best model found after epoch 16 of 100.
2022-11-28 04:20:22,192 INFO:   Done with stage: TRAINING
2022-11-28 04:20:22,192 INFO:   Starting stage: EVALUATION
2022-11-28 04:20:22,307 INFO:   Done with stage: EVALUATION
2022-11-28 04:20:22,307 INFO:   Leaving out SEQ value Fold_9
2022-11-28 04:20:22,319 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:20:22,320 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:20:22,969 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:20:22,969 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:20:23,037 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:20:23,037 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:20:23,037 INFO:     No hyperparam tuning for this model
2022-11-28 04:20:23,037 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:20:23,037 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:20:23,038 INFO:     None feature selector for col prot
2022-11-28 04:20:23,038 INFO:     None feature selector for col prot
2022-11-28 04:20:23,038 INFO:     None feature selector for col prot
2022-11-28 04:20:23,039 INFO:     None feature selector for col chem
2022-11-28 04:20:23,039 INFO:     None feature selector for col chem
2022-11-28 04:20:23,039 INFO:     None feature selector for col chem
2022-11-28 04:20:23,039 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:20:23,039 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:20:23,041 INFO:     Number of params in model 169651
2022-11-28 04:20:23,044 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:20:23,044 INFO:   Starting stage: TRAINING
2022-11-28 04:20:23,095 INFO:     Val loss before train {'Reaction outcome loss': 1.0257189070636576, 'Total loss': 1.0257189070636576}
2022-11-28 04:20:23,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:23,095 INFO:     Epoch: 0
2022-11-28 04:20:23,758 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.612917307425629, 'Total loss': 0.612917307425629} | train loss {'Reaction outcome loss': 0.6941237847814675, 'Total loss': 0.6941237847814675}
2022-11-28 04:20:23,759 INFO:     Found new best model at epoch 0
2022-11-28 04:20:23,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:23,760 INFO:     Epoch: 1
2022-11-28 04:20:24,425 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5390892990610816, 'Total loss': 0.5390892990610816} | train loss {'Reaction outcome loss': 0.5900987401182353, 'Total loss': 0.5900987401182353}
2022-11-28 04:20:24,425 INFO:     Found new best model at epoch 1
2022-11-28 04:20:24,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:24,425 INFO:     Epoch: 2
2022-11-28 04:20:25,096 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.566922552883625, 'Total loss': 0.566922552883625} | train loss {'Reaction outcome loss': 0.5514046277074136, 'Total loss': 0.5514046277074136}
2022-11-28 04:20:25,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:25,096 INFO:     Epoch: 3
2022-11-28 04:20:25,764 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5354657335714861, 'Total loss': 0.5354657335714861} | train loss {'Reaction outcome loss': 0.5385766105371931, 'Total loss': 0.5385766105371931}
2022-11-28 04:20:25,765 INFO:     Found new best model at epoch 3
2022-11-28 04:20:25,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:25,765 INFO:     Epoch: 4
2022-11-28 04:20:26,429 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5185136038132689, 'Total loss': 0.5185136038132689} | train loss {'Reaction outcome loss': 0.5345988460262174, 'Total loss': 0.5345988460262174}
2022-11-28 04:20:26,430 INFO:     Found new best model at epoch 4
2022-11-28 04:20:26,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:26,430 INFO:     Epoch: 5
2022-11-28 04:20:27,094 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5383972945538434, 'Total loss': 0.5383972945538434} | train loss {'Reaction outcome loss': 0.5300860157621051, 'Total loss': 0.5300860157621051}
2022-11-28 04:20:27,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:27,094 INFO:     Epoch: 6
2022-11-28 04:20:27,760 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5193261795423247, 'Total loss': 0.5193261795423247} | train loss {'Reaction outcome loss': 0.5110692408403404, 'Total loss': 0.5110692408403404}
2022-11-28 04:20:27,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:27,761 INFO:     Epoch: 7
2022-11-28 04:20:28,424 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4984250942414457, 'Total loss': 0.4984250942414457} | train loss {'Reaction outcome loss': 0.5099786504922126, 'Total loss': 0.5099786504922126}
2022-11-28 04:20:28,424 INFO:     Found new best model at epoch 7
2022-11-28 04:20:28,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:28,425 INFO:     Epoch: 8
2022-11-28 04:20:29,087 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5330306840213862, 'Total loss': 0.5330306840213862} | train loss {'Reaction outcome loss': 0.5040312981919238, 'Total loss': 0.5040312981919238}
2022-11-28 04:20:29,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:29,087 INFO:     Epoch: 9
2022-11-28 04:20:29,752 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5098962390964682, 'Total loss': 0.5098962390964682} | train loss {'Reaction outcome loss': 0.4961394968438848, 'Total loss': 0.4961394968438848}
2022-11-28 04:20:29,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:29,753 INFO:     Epoch: 10
2022-11-28 04:20:30,414 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5249386328187856, 'Total loss': 0.5249386328187856} | train loss {'Reaction outcome loss': 0.48983923596167855, 'Total loss': 0.48983923596167855}
2022-11-28 04:20:30,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:30,414 INFO:     Epoch: 11
2022-11-28 04:20:31,076 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5248632864518599, 'Total loss': 0.5248632864518599} | train loss {'Reaction outcome loss': 0.5172751980875185, 'Total loss': 0.5172751980875185}
2022-11-28 04:20:31,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:31,077 INFO:     Epoch: 12
2022-11-28 04:20:31,738 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48941081830046396, 'Total loss': 0.48941081830046396} | train loss {'Reaction outcome loss': 0.48858501722938136, 'Total loss': 0.48858501722938136}
2022-11-28 04:20:31,738 INFO:     Found new best model at epoch 12
2022-11-28 04:20:31,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:31,739 INFO:     Epoch: 13
2022-11-28 04:20:32,404 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5041648508472876, 'Total loss': 0.5041648508472876} | train loss {'Reaction outcome loss': 0.4871781361609818, 'Total loss': 0.4871781361609818}
2022-11-28 04:20:32,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:32,405 INFO:     Epoch: 14
2022-11-28 04:20:33,066 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5068157227201895, 'Total loss': 0.5068157227201895} | train loss {'Reaction outcome loss': 0.48844761247576973, 'Total loss': 0.48844761247576973}
2022-11-28 04:20:33,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:33,066 INFO:     Epoch: 15
2022-11-28 04:20:33,726 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5475505766543475, 'Total loss': 0.5475505766543475} | train loss {'Reaction outcome loss': 0.512764664947504, 'Total loss': 0.512764664947504}
2022-11-28 04:20:33,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:33,726 INFO:     Epoch: 16
2022-11-28 04:20:34,391 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5238758393309333, 'Total loss': 0.5238758393309333} | train loss {'Reaction outcome loss': 0.48244944088130826, 'Total loss': 0.48244944088130826}
2022-11-28 04:20:34,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:34,392 INFO:     Epoch: 17
2022-11-28 04:20:35,056 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5026917775923555, 'Total loss': 0.5026917775923555} | train loss {'Reaction outcome loss': 0.4857302600072946, 'Total loss': 0.4857302600072946}
2022-11-28 04:20:35,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:35,056 INFO:     Epoch: 18
2022-11-28 04:20:35,720 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49741237881508743, 'Total loss': 0.49741237881508743} | train loss {'Reaction outcome loss': 0.4924534291390948, 'Total loss': 0.4924534291390948}
2022-11-28 04:20:35,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:35,720 INFO:     Epoch: 19
2022-11-28 04:20:36,382 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47084374962882564, 'Total loss': 0.47084374962882564} | train loss {'Reaction outcome loss': 0.48048074633968985, 'Total loss': 0.48048074633968985}
2022-11-28 04:20:36,383 INFO:     Found new best model at epoch 19
2022-11-28 04:20:36,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:36,383 INFO:     Epoch: 20
2022-11-28 04:20:37,047 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5062336058101871, 'Total loss': 0.5062336058101871} | train loss {'Reaction outcome loss': 0.4787510159210517, 'Total loss': 0.4787510159210517}
2022-11-28 04:20:37,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:37,048 INFO:     Epoch: 21
2022-11-28 04:20:37,715 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48899645324457774, 'Total loss': 0.48899645324457774} | train loss {'Reaction outcome loss': 0.4777239637698239, 'Total loss': 0.4777239637698239}
2022-11-28 04:20:37,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:37,715 INFO:     Epoch: 22
2022-11-28 04:20:38,381 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48876033892685716, 'Total loss': 0.48876033892685716} | train loss {'Reaction outcome loss': 0.48177573594607803, 'Total loss': 0.48177573594607803}
2022-11-28 04:20:38,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:38,382 INFO:     Epoch: 23
2022-11-28 04:20:39,043 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48138055950403214, 'Total loss': 0.48138055950403214} | train loss {'Reaction outcome loss': 0.4743109190693268, 'Total loss': 0.4743109190693268}
2022-11-28 04:20:39,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:39,043 INFO:     Epoch: 24
2022-11-28 04:20:39,703 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5089675723151728, 'Total loss': 0.5089675723151728} | train loss {'Reaction outcome loss': 0.46338605542897215, 'Total loss': 0.46338605542897215}
2022-11-28 04:20:39,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:39,704 INFO:     Epoch: 25
2022-11-28 04:20:40,365 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5184237103570591, 'Total loss': 0.5184237103570591} | train loss {'Reaction outcome loss': 0.47015149363878406, 'Total loss': 0.47015149363878406}
2022-11-28 04:20:40,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:40,365 INFO:     Epoch: 26
2022-11-28 04:20:41,027 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4790457087484273, 'Total loss': 0.4790457087484273} | train loss {'Reaction outcome loss': 0.46630415350560717, 'Total loss': 0.46630415350560717}
2022-11-28 04:20:41,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:41,027 INFO:     Epoch: 27
2022-11-28 04:20:41,689 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47917384654283524, 'Total loss': 0.47917384654283524} | train loss {'Reaction outcome loss': 0.48092517817792624, 'Total loss': 0.48092517817792624}
2022-11-28 04:20:41,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:41,689 INFO:     Epoch: 28
2022-11-28 04:20:42,347 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.484934939918193, 'Total loss': 0.484934939918193} | train loss {'Reaction outcome loss': 0.47716705511637064, 'Total loss': 0.47716705511637064}
2022-11-28 04:20:42,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:42,347 INFO:     Epoch: 29
2022-11-28 04:20:43,009 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4824930862946944, 'Total loss': 0.4824930862946944} | train loss {'Reaction outcome loss': 0.46642002971609114, 'Total loss': 0.46642002971609114}
2022-11-28 04:20:43,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:43,009 INFO:     Epoch: 30
2022-11-28 04:20:43,672 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4935010939159177, 'Total loss': 0.4935010939159177} | train loss {'Reaction outcome loss': 0.4708903208073334, 'Total loss': 0.4708903208073334}
2022-11-28 04:20:43,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:43,672 INFO:     Epoch: 31
2022-11-28 04:20:44,334 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4821398529139432, 'Total loss': 0.4821398529139432} | train loss {'Reaction outcome loss': 0.4734868870007425, 'Total loss': 0.4734868870007425}
2022-11-28 04:20:44,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:44,334 INFO:     Epoch: 32
2022-11-28 04:20:44,993 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5092922781001438, 'Total loss': 0.5092922781001438} | train loss {'Reaction outcome loss': 0.4722765014480483, 'Total loss': 0.4722765014480483}
2022-11-28 04:20:44,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:44,993 INFO:     Epoch: 33
2022-11-28 04:20:45,654 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4920914318751205, 'Total loss': 0.4920914318751205} | train loss {'Reaction outcome loss': 0.47030088374851203, 'Total loss': 0.47030088374851203}
2022-11-28 04:20:45,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:45,654 INFO:     Epoch: 34
2022-11-28 04:20:46,317 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46647741086781025, 'Total loss': 0.46647741086781025} | train loss {'Reaction outcome loss': 0.47525320577280605, 'Total loss': 0.47525320577280605}
2022-11-28 04:20:46,317 INFO:     Found new best model at epoch 34
2022-11-28 04:20:46,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:46,318 INFO:     Epoch: 35
2022-11-28 04:20:46,980 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5011285479095849, 'Total loss': 0.5011285479095849} | train loss {'Reaction outcome loss': 0.46475166444353727, 'Total loss': 0.46475166444353727}
2022-11-28 04:20:46,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:46,980 INFO:     Epoch: 36
2022-11-28 04:20:47,646 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5382133546200666, 'Total loss': 0.5382133546200666} | train loss {'Reaction outcome loss': 0.4711112282295459, 'Total loss': 0.4711112282295459}
2022-11-28 04:20:47,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:47,646 INFO:     Epoch: 37
2022-11-28 04:20:48,309 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4791495657779954, 'Total loss': 0.4791495657779954} | train loss {'Reaction outcome loss': 0.46849121358471846, 'Total loss': 0.46849121358471846}
2022-11-28 04:20:48,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:48,309 INFO:     Epoch: 38
2022-11-28 04:20:48,972 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5152976153926416, 'Total loss': 0.5152976153926416} | train loss {'Reaction outcome loss': 0.4660975593425002, 'Total loss': 0.4660975593425002}
2022-11-28 04:20:48,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:48,974 INFO:     Epoch: 39
2022-11-28 04:20:49,636 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5008390898054297, 'Total loss': 0.5008390898054297} | train loss {'Reaction outcome loss': 0.4678340864175486, 'Total loss': 0.4678340864175486}
2022-11-28 04:20:49,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:49,637 INFO:     Epoch: 40
2022-11-28 04:20:50,301 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49132713269103656, 'Total loss': 0.49132713269103656} | train loss {'Reaction outcome loss': 0.47182223725656747, 'Total loss': 0.47182223725656747}
2022-11-28 04:20:50,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:50,301 INFO:     Epoch: 41
2022-11-28 04:20:50,962 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5087445263158191, 'Total loss': 0.5087445263158191} | train loss {'Reaction outcome loss': 0.4734896444357358, 'Total loss': 0.4734896444357358}
2022-11-28 04:20:50,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:50,962 INFO:     Epoch: 42
2022-11-28 04:20:51,627 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4698568301444704, 'Total loss': 0.4698568301444704} | train loss {'Reaction outcome loss': 0.4719552825457654, 'Total loss': 0.4719552825457654}
2022-11-28 04:20:51,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:51,627 INFO:     Epoch: 43
2022-11-28 04:20:52,288 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5001677952029489, 'Total loss': 0.5001677952029489} | train loss {'Reaction outcome loss': 0.47182531419553253, 'Total loss': 0.47182531419553253}
2022-11-28 04:20:52,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:52,288 INFO:     Epoch: 44
2022-11-28 04:20:52,952 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5245617885481227, 'Total loss': 0.5245617885481227} | train loss {'Reaction outcome loss': 0.4651011114238727, 'Total loss': 0.4651011114238727}
2022-11-28 04:20:52,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:52,952 INFO:     Epoch: 45
2022-11-28 04:20:53,617 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4873723780566996, 'Total loss': 0.4873723780566996} | train loss {'Reaction outcome loss': 0.4989457169645711, 'Total loss': 0.4989457169645711}
2022-11-28 04:20:53,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:53,617 INFO:     Epoch: 46
2022-11-28 04:20:54,280 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48126531460068445, 'Total loss': 0.48126531460068445} | train loss {'Reaction outcome loss': 0.46712245004862424, 'Total loss': 0.46712245004862424}
2022-11-28 04:20:54,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:54,280 INFO:     Epoch: 47
2022-11-28 04:20:54,948 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47627526115287433, 'Total loss': 0.47627526115287433} | train loss {'Reaction outcome loss': 0.4656254614774997, 'Total loss': 0.4656254614774997}
2022-11-28 04:20:54,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:54,949 INFO:     Epoch: 48
2022-11-28 04:20:55,612 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4606084891340949, 'Total loss': 0.4606084891340949} | train loss {'Reaction outcome loss': 0.468893344676205, 'Total loss': 0.468893344676205}
2022-11-28 04:20:55,612 INFO:     Found new best model at epoch 48
2022-11-28 04:20:55,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:55,613 INFO:     Epoch: 49
2022-11-28 04:20:56,271 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.514820474115285, 'Total loss': 0.514820474115285} | train loss {'Reaction outcome loss': 0.4649096714702212, 'Total loss': 0.4649096714702212}
2022-11-28 04:20:56,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:56,271 INFO:     Epoch: 50
2022-11-28 04:20:56,927 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4784111915664239, 'Total loss': 0.4784111915664239} | train loss {'Reaction outcome loss': 0.4737702634351456, 'Total loss': 0.4737702634351456}
2022-11-28 04:20:56,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:56,928 INFO:     Epoch: 51
2022-11-28 04:20:57,586 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5015357350083914, 'Total loss': 0.5015357350083914} | train loss {'Reaction outcome loss': 0.46631523037728995, 'Total loss': 0.46631523037728995}
2022-11-28 04:20:57,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:57,586 INFO:     Epoch: 52
2022-11-28 04:20:58,245 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5185364119031213, 'Total loss': 0.5185364119031213} | train loss {'Reaction outcome loss': 0.47064214649229397, 'Total loss': 0.47064214649229397}
2022-11-28 04:20:58,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:58,245 INFO:     Epoch: 53
2022-11-28 04:20:58,903 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5039134285497394, 'Total loss': 0.5039134285497394} | train loss {'Reaction outcome loss': 0.47639527657495334, 'Total loss': 0.47639527657495334}
2022-11-28 04:20:58,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:58,903 INFO:     Epoch: 54
2022-11-28 04:20:59,560 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49143354391509836, 'Total loss': 0.49143354391509836} | train loss {'Reaction outcome loss': 0.47327821431040523, 'Total loss': 0.47327821431040523}
2022-11-28 04:20:59,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:20:59,560 INFO:     Epoch: 55
2022-11-28 04:21:00,214 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5044982778755102, 'Total loss': 0.5044982778755102} | train loss {'Reaction outcome loss': 0.46890568129929455, 'Total loss': 0.46890568129929455}
2022-11-28 04:21:00,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:00,214 INFO:     Epoch: 56
2022-11-28 04:21:00,871 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4559099345721982, 'Total loss': 0.4559099345721982} | train loss {'Reaction outcome loss': 0.479537595681816, 'Total loss': 0.479537595681816}
2022-11-28 04:21:00,871 INFO:     Found new best model at epoch 56
2022-11-28 04:21:00,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:00,872 INFO:     Epoch: 57
2022-11-28 04:21:01,526 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4781068197705529, 'Total loss': 0.4781068197705529} | train loss {'Reaction outcome loss': 0.46477460565595974, 'Total loss': 0.46477460565595974}
2022-11-28 04:21:01,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:01,526 INFO:     Epoch: 58
2022-11-28 04:21:02,184 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4609162011607127, 'Total loss': 0.4609162011607127} | train loss {'Reaction outcome loss': 0.4730806226129474, 'Total loss': 0.4730806226129474}
2022-11-28 04:21:02,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:02,184 INFO:     Epoch: 59
2022-11-28 04:21:02,848 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4735651986504143, 'Total loss': 0.4735651986504143} | train loss {'Reaction outcome loss': 0.47086948979842036, 'Total loss': 0.47086948979842036}
2022-11-28 04:21:02,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:02,848 INFO:     Epoch: 60
2022-11-28 04:21:03,505 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49236852811141446, 'Total loss': 0.49236852811141446} | train loss {'Reaction outcome loss': 0.4655197983087316, 'Total loss': 0.4655197983087316}
2022-11-28 04:21:03,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:03,505 INFO:     Epoch: 61
2022-11-28 04:21:04,162 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48210873725739395, 'Total loss': 0.48210873725739395} | train loss {'Reaction outcome loss': 0.46415614928043475, 'Total loss': 0.46415614928043475}
2022-11-28 04:21:04,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:04,162 INFO:     Epoch: 62
2022-11-28 04:21:04,816 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4949907779016278, 'Total loss': 0.4949907779016278} | train loss {'Reaction outcome loss': 0.46297989839966963, 'Total loss': 0.46297989839966963}
2022-11-28 04:21:04,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:04,816 INFO:     Epoch: 63
2022-11-28 04:21:05,469 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5035261173139919, 'Total loss': 0.5035261173139919} | train loss {'Reaction outcome loss': 0.469114421289942, 'Total loss': 0.469114421289942}
2022-11-28 04:21:05,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:05,469 INFO:     Epoch: 64
2022-11-28 04:21:06,128 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5159120756116781, 'Total loss': 0.5159120756116781} | train loss {'Reaction outcome loss': 0.46977166855624813, 'Total loss': 0.46977166855624813}
2022-11-28 04:21:06,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:06,129 INFO:     Epoch: 65
2022-11-28 04:21:06,787 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4710629314861514, 'Total loss': 0.4710629314861514} | train loss {'Reaction outcome loss': 0.4650371534059857, 'Total loss': 0.4650371534059857}
2022-11-28 04:21:06,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:06,787 INFO:     Epoch: 66
2022-11-28 04:21:07,446 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46966247057372873, 'Total loss': 0.46966247057372873} | train loss {'Reaction outcome loss': 0.4635768818408854, 'Total loss': 0.4635768818408854}
2022-11-28 04:21:07,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:07,446 INFO:     Epoch: 67
2022-11-28 04:21:08,107 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46302896263924515, 'Total loss': 0.46302896263924515} | train loss {'Reaction outcome loss': 0.46896862395499883, 'Total loss': 0.46896862395499883}
2022-11-28 04:21:08,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:08,108 INFO:     Epoch: 68
2022-11-28 04:21:08,769 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5124936110594056, 'Total loss': 0.5124936110594056} | train loss {'Reaction outcome loss': 0.46027377597716174, 'Total loss': 0.46027377597716174}
2022-11-28 04:21:08,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:08,770 INFO:     Epoch: 69
2022-11-28 04:21:09,426 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4817527095702561, 'Total loss': 0.4817527095702561} | train loss {'Reaction outcome loss': 0.46444388614733695, 'Total loss': 0.46444388614733695}
2022-11-28 04:21:09,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:09,427 INFO:     Epoch: 70
2022-11-28 04:21:10,085 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.6667788834734396, 'Total loss': 0.6667788834734396} | train loss {'Reaction outcome loss': 0.4663590692918793, 'Total loss': 0.4663590692918793}
2022-11-28 04:21:10,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:10,086 INFO:     Epoch: 71
2022-11-28 04:21:10,744 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48261934146285057, 'Total loss': 0.48261934146285057} | train loss {'Reaction outcome loss': 0.49022381112492275, 'Total loss': 0.49022381112492275}
2022-11-28 04:21:10,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:10,744 INFO:     Epoch: 72
2022-11-28 04:21:11,399 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4738303910602223, 'Total loss': 0.4738303910602223} | train loss {'Reaction outcome loss': 0.46072568360203314, 'Total loss': 0.46072568360203314}
2022-11-28 04:21:11,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:11,399 INFO:     Epoch: 73
2022-11-28 04:21:12,057 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4970206990838051, 'Total loss': 0.4970206990838051} | train loss {'Reaction outcome loss': 0.46662480924052263, 'Total loss': 0.46662480924052263}
2022-11-28 04:21:12,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:12,057 INFO:     Epoch: 74
2022-11-28 04:21:12,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5154418081722476, 'Total loss': 0.5154418081722476} | train loss {'Reaction outcome loss': 0.4690275644913678, 'Total loss': 0.4690275644913678}
2022-11-28 04:21:12,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:12,717 INFO:     Epoch: 75
2022-11-28 04:21:13,374 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48610146750103345, 'Total loss': 0.48610146750103345} | train loss {'Reaction outcome loss': 0.4732747497828866, 'Total loss': 0.4732747497828866}
2022-11-28 04:21:13,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:13,374 INFO:     Epoch: 76
2022-11-28 04:21:14,031 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5631178163669326, 'Total loss': 0.5631178163669326} | train loss {'Reaction outcome loss': 0.472970919208488, 'Total loss': 0.472970919208488}
2022-11-28 04:21:14,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:14,031 INFO:     Epoch: 77
2022-11-28 04:21:14,688 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4727674140171571, 'Total loss': 0.4727674140171571} | train loss {'Reaction outcome loss': 0.47091636677019993, 'Total loss': 0.47091636677019993}
2022-11-28 04:21:14,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:14,689 INFO:     Epoch: 78
2022-11-28 04:21:15,348 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48889888653701, 'Total loss': 0.48889888653701} | train loss {'Reaction outcome loss': 0.4736266257429895, 'Total loss': 0.4736266257429895}
2022-11-28 04:21:15,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:15,348 INFO:     Epoch: 79
2022-11-28 04:21:16,008 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47680763324553316, 'Total loss': 0.47680763324553316} | train loss {'Reaction outcome loss': 0.46792004073438376, 'Total loss': 0.46792004073438376}
2022-11-28 04:21:16,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:16,009 INFO:     Epoch: 80
2022-11-28 04:21:16,667 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.524191827936606, 'Total loss': 0.524191827936606} | train loss {'Reaction outcome loss': 0.46685856671227133, 'Total loss': 0.46685856671227133}
2022-11-28 04:21:16,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:16,668 INFO:     Epoch: 81
2022-11-28 04:21:17,325 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45372690429741686, 'Total loss': 0.45372690429741686} | train loss {'Reaction outcome loss': 0.4656540822644948, 'Total loss': 0.4656540822644948}
2022-11-28 04:21:17,325 INFO:     Found new best model at epoch 81
2022-11-28 04:21:17,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:17,326 INFO:     Epoch: 82
2022-11-28 04:21:17,984 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4740511893548749, 'Total loss': 0.4740511893548749} | train loss {'Reaction outcome loss': 0.46369695862536486, 'Total loss': 0.46369695862536486}
2022-11-28 04:21:17,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:17,984 INFO:     Epoch: 83
2022-11-28 04:21:18,645 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4702738625082103, 'Total loss': 0.4702738625082103} | train loss {'Reaction outcome loss': 0.4668267179838559, 'Total loss': 0.4668267179838559}
2022-11-28 04:21:18,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:18,645 INFO:     Epoch: 84
2022-11-28 04:21:19,306 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5307680801911787, 'Total loss': 0.5307680801911787} | train loss {'Reaction outcome loss': 0.4752275992018974, 'Total loss': 0.4752275992018974}
2022-11-28 04:21:19,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:19,306 INFO:     Epoch: 85
2022-11-28 04:21:19,966 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4858113622123545, 'Total loss': 0.4858113622123545} | train loss {'Reaction outcome loss': 0.47582791027752497, 'Total loss': 0.47582791027752497}
2022-11-28 04:21:19,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:19,967 INFO:     Epoch: 86
2022-11-28 04:21:20,627 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5067906914786859, 'Total loss': 0.5067906914786859} | train loss {'Reaction outcome loss': 0.4810019872087216, 'Total loss': 0.4810019872087216}
2022-11-28 04:21:20,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:20,627 INFO:     Epoch: 87
2022-11-28 04:21:21,287 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4972350959750739, 'Total loss': 0.4972350959750739} | train loss {'Reaction outcome loss': 0.48300891076987573, 'Total loss': 0.48300891076987573}
2022-11-28 04:21:21,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:21,287 INFO:     Epoch: 88
2022-11-28 04:21:21,945 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49143652990460396, 'Total loss': 0.49143652990460396} | train loss {'Reaction outcome loss': 0.46793860917098384, 'Total loss': 0.46793860917098384}
2022-11-28 04:21:21,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:21,946 INFO:     Epoch: 89
2022-11-28 04:21:22,609 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4834901338273829, 'Total loss': 0.4834901338273829} | train loss {'Reaction outcome loss': 0.4753914118295739, 'Total loss': 0.4753914118295739}
2022-11-28 04:21:22,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:22,609 INFO:     Epoch: 90
2022-11-28 04:21:23,269 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49481241608207877, 'Total loss': 0.49481241608207877} | train loss {'Reaction outcome loss': 0.4785312916706448, 'Total loss': 0.4785312916706448}
2022-11-28 04:21:23,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:23,269 INFO:     Epoch: 91
2022-11-28 04:21:23,926 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4754598597911271, 'Total loss': 0.4754598597911271} | train loss {'Reaction outcome loss': 0.46765688339225675, 'Total loss': 0.46765688339225675}
2022-11-28 04:21:23,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:23,926 INFO:     Epoch: 92
2022-11-28 04:21:24,585 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49264186417514627, 'Total loss': 0.49264186417514627} | train loss {'Reaction outcome loss': 0.46557714859483695, 'Total loss': 0.46557714859483695}
2022-11-28 04:21:24,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:24,585 INFO:     Epoch: 93
2022-11-28 04:21:25,242 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48149716955694283, 'Total loss': 0.48149716955694283} | train loss {'Reaction outcome loss': 0.4682288967103128, 'Total loss': 0.4682288967103128}
2022-11-28 04:21:25,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:25,242 INFO:     Epoch: 94
2022-11-28 04:21:25,898 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5326691689816389, 'Total loss': 0.5326691689816389} | train loss {'Reaction outcome loss': 0.46584168522946745, 'Total loss': 0.46584168522946745}
2022-11-28 04:21:25,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:25,898 INFO:     Epoch: 95
2022-11-28 04:21:26,556 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4916259131648324, 'Total loss': 0.4916259131648324} | train loss {'Reaction outcome loss': 0.47367542408979857, 'Total loss': 0.47367542408979857}
2022-11-28 04:21:26,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:26,556 INFO:     Epoch: 96
2022-11-28 04:21:27,212 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.502085093408823, 'Total loss': 0.502085093408823} | train loss {'Reaction outcome loss': 0.4691712396692575, 'Total loss': 0.4691712396692575}
2022-11-28 04:21:27,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:27,212 INFO:     Epoch: 97
2022-11-28 04:21:27,866 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4955732070586898, 'Total loss': 0.4955732070586898} | train loss {'Reaction outcome loss': 0.4669236992957138, 'Total loss': 0.4669236992957138}
2022-11-28 04:21:27,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:27,867 INFO:     Epoch: 98
2022-11-28 04:21:28,526 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48305236107923766, 'Total loss': 0.48305236107923766} | train loss {'Reaction outcome loss': 0.47097742486639543, 'Total loss': 0.47097742486639543}
2022-11-28 04:21:28,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:28,526 INFO:     Epoch: 99
2022-11-28 04:21:29,185 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4775144390084527, 'Total loss': 0.4775144390084527} | train loss {'Reaction outcome loss': 0.4648103784422884, 'Total loss': 0.4648103784422884}
2022-11-28 04:21:29,185 INFO:     Best model found after epoch 82 of 100.
2022-11-28 04:21:29,185 INFO:   Done with stage: TRAINING
2022-11-28 04:21:29,185 INFO:   Starting stage: EVALUATION
2022-11-28 04:21:29,306 INFO:   Done with stage: EVALUATION
2022-11-28 04:21:29,314 INFO:   Leaving out SEQ value Fold_0
2022-11-28 04:21:29,327 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:21:29,327 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:21:29,962 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:21:29,962 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:21:30,029 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:21:30,029 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:21:30,029 INFO:     No hyperparam tuning for this model
2022-11-28 04:21:30,029 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:21:30,029 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:21:30,030 INFO:     None feature selector for col prot
2022-11-28 04:21:30,030 INFO:     None feature selector for col prot
2022-11-28 04:21:30,030 INFO:     None feature selector for col prot
2022-11-28 04:21:30,031 INFO:     None feature selector for col chem
2022-11-28 04:21:30,031 INFO:     None feature selector for col chem
2022-11-28 04:21:30,031 INFO:     None feature selector for col chem
2022-11-28 04:21:30,031 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:21:30,031 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:21:30,032 INFO:     Number of params in model 169651
2022-11-28 04:21:30,036 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:21:30,036 INFO:   Starting stage: TRAINING
2022-11-28 04:21:30,086 INFO:     Val loss before train {'Reaction outcome loss': 1.0937114263122731, 'Total loss': 1.0937114263122731}
2022-11-28 04:21:30,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:30,086 INFO:     Epoch: 0
2022-11-28 04:21:30,743 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6103287163105878, 'Total loss': 0.6103287163105878} | train loss {'Reaction outcome loss': 0.6862269506162527, 'Total loss': 0.6862269506162527}
2022-11-28 04:21:30,743 INFO:     Found new best model at epoch 0
2022-11-28 04:21:30,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:30,744 INFO:     Epoch: 1
2022-11-28 04:21:31,399 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5874299122528597, 'Total loss': 0.5874299122528597} | train loss {'Reaction outcome loss': 0.5851316293891595, 'Total loss': 0.5851316293891595}
2022-11-28 04:21:31,399 INFO:     Found new best model at epoch 1
2022-11-28 04:21:31,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:31,400 INFO:     Epoch: 2
2022-11-28 04:21:32,052 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6057908047329296, 'Total loss': 0.6057908047329296} | train loss {'Reaction outcome loss': 0.5514940433356227, 'Total loss': 0.5514940433356227}
2022-11-28 04:21:32,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:32,053 INFO:     Epoch: 3
2022-11-28 04:21:32,706 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5945185019888661, 'Total loss': 0.5945185019888661} | train loss {'Reaction outcome loss': 0.5327883134082873, 'Total loss': 0.5327883134082873}
2022-11-28 04:21:32,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:32,706 INFO:     Epoch: 4
2022-11-28 04:21:33,360 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5707626749168743, 'Total loss': 0.5707626749168743} | train loss {'Reaction outcome loss': 0.5171763595269651, 'Total loss': 0.5171763595269651}
2022-11-28 04:21:33,360 INFO:     Found new best model at epoch 4
2022-11-28 04:21:33,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:33,361 INFO:     Epoch: 5
2022-11-28 04:21:34,013 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5977721451358362, 'Total loss': 0.5977721451358362} | train loss {'Reaction outcome loss': 0.5165595857464538, 'Total loss': 0.5165595857464538}
2022-11-28 04:21:34,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:34,013 INFO:     Epoch: 6
2022-11-28 04:21:34,665 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5223198560151187, 'Total loss': 0.5223198560151187} | train loss {'Reaction outcome loss': 0.5169799617662721, 'Total loss': 0.5169799617662721}
2022-11-28 04:21:34,665 INFO:     Found new best model at epoch 6
2022-11-28 04:21:34,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:34,666 INFO:     Epoch: 7
2022-11-28 04:21:35,318 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5990464619614861, 'Total loss': 0.5990464619614861} | train loss {'Reaction outcome loss': 0.4967320445848971, 'Total loss': 0.4967320445848971}
2022-11-28 04:21:35,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:35,318 INFO:     Epoch: 8
2022-11-28 04:21:35,972 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5379473289305513, 'Total loss': 0.5379473289305513} | train loss {'Reaction outcome loss': 0.4937717514378684, 'Total loss': 0.4937717514378684}
2022-11-28 04:21:35,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:35,973 INFO:     Epoch: 9
2022-11-28 04:21:36,626 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5688365481116555, 'Total loss': 0.5688365481116555} | train loss {'Reaction outcome loss': 0.48377985169692916, 'Total loss': 0.48377985169692916}
2022-11-28 04:21:36,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:36,627 INFO:     Epoch: 10
2022-11-28 04:21:37,284 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5149396569891409, 'Total loss': 0.5149396569891409} | train loss {'Reaction outcome loss': 0.4800334831281584, 'Total loss': 0.4800334831281584}
2022-11-28 04:21:37,284 INFO:     Found new best model at epoch 10
2022-11-28 04:21:37,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:37,285 INFO:     Epoch: 11
2022-11-28 04:21:37,941 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5720740837807005, 'Total loss': 0.5720740837807005} | train loss {'Reaction outcome loss': 0.476807515718499, 'Total loss': 0.476807515718499}
2022-11-28 04:21:37,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:37,942 INFO:     Epoch: 12
2022-11-28 04:21:38,599 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5638511787084016, 'Total loss': 0.5638511787084016} | train loss {'Reaction outcome loss': 0.480954320394263, 'Total loss': 0.480954320394263}
2022-11-28 04:21:38,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:38,600 INFO:     Epoch: 13
2022-11-28 04:21:39,254 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5099805173548785, 'Total loss': 0.5099805173548785} | train loss {'Reaction outcome loss': 0.4827755441775127, 'Total loss': 0.4827755441775127}
2022-11-28 04:21:39,254 INFO:     Found new best model at epoch 13
2022-11-28 04:21:39,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:39,255 INFO:     Epoch: 14
2022-11-28 04:21:39,908 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5638292289593003, 'Total loss': 0.5638292289593003} | train loss {'Reaction outcome loss': 0.47226713765032435, 'Total loss': 0.47226713765032435}
2022-11-28 04:21:39,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:39,909 INFO:     Epoch: 15
2022-11-28 04:21:40,563 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5717522881247781, 'Total loss': 0.5717522881247781} | train loss {'Reaction outcome loss': 0.473980860077605, 'Total loss': 0.473980860077605}
2022-11-28 04:21:40,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:40,563 INFO:     Epoch: 16
2022-11-28 04:21:41,216 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5436235239559953, 'Total loss': 0.5436235239559953} | train loss {'Reaction outcome loss': 0.4695212607481042, 'Total loss': 0.4695212607481042}
2022-11-28 04:21:41,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:41,216 INFO:     Epoch: 17
2022-11-28 04:21:41,869 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5341390452601693, 'Total loss': 0.5341390452601693} | train loss {'Reaction outcome loss': 0.4815552802110205, 'Total loss': 0.4815552802110205}
2022-11-28 04:21:41,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:41,869 INFO:     Epoch: 18
2022-11-28 04:21:42,522 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5345866117965091, 'Total loss': 0.5345866117965091} | train loss {'Reaction outcome loss': 0.4736034209630927, 'Total loss': 0.4736034209630927}
2022-11-28 04:21:42,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:42,522 INFO:     Epoch: 19
2022-11-28 04:21:43,176 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.552390651946718, 'Total loss': 0.552390651946718} | train loss {'Reaction outcome loss': 0.4734954389686487, 'Total loss': 0.4734954389686487}
2022-11-28 04:21:43,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:43,176 INFO:     Epoch: 20
2022-11-28 04:21:43,827 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5427215184000406, 'Total loss': 0.5427215184000406} | train loss {'Reaction outcome loss': 0.4741142883896828, 'Total loss': 0.4741142883896828}
2022-11-28 04:21:43,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:43,827 INFO:     Epoch: 21
2022-11-28 04:21:44,477 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5178727927533063, 'Total loss': 0.5178727927533063} | train loss {'Reaction outcome loss': 0.46934228417824725, 'Total loss': 0.46934228417824725}
2022-11-28 04:21:44,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:44,478 INFO:     Epoch: 22
2022-11-28 04:21:45,127 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5332906849851663, 'Total loss': 0.5332906849851663} | train loss {'Reaction outcome loss': 0.46596809856745663, 'Total loss': 0.46596809856745663}
2022-11-28 04:21:45,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:45,127 INFO:     Epoch: 23
2022-11-28 04:21:45,783 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5446093990044161, 'Total loss': 0.5446093990044161} | train loss {'Reaction outcome loss': 0.4590816961259258, 'Total loss': 0.4590816961259258}
2022-11-28 04:21:45,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:45,783 INFO:     Epoch: 24
2022-11-28 04:21:46,441 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4997523186559027, 'Total loss': 0.4997523186559027} | train loss {'Reaction outcome loss': 0.4601564444449483, 'Total loss': 0.4601564444449483}
2022-11-28 04:21:46,441 INFO:     Found new best model at epoch 24
2022-11-28 04:21:46,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:46,442 INFO:     Epoch: 25
2022-11-28 04:21:47,095 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5606912973929535, 'Total loss': 0.5606912973929535} | train loss {'Reaction outcome loss': 0.4615979161189527, 'Total loss': 0.4615979161189527}
2022-11-28 04:21:47,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:47,095 INFO:     Epoch: 26
2022-11-28 04:21:47,749 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5772498324513435, 'Total loss': 0.5772498324513435} | train loss {'Reaction outcome loss': 0.4651129375915138, 'Total loss': 0.4651129375915138}
2022-11-28 04:21:47,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:47,749 INFO:     Epoch: 27
2022-11-28 04:21:48,403 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5019935416904363, 'Total loss': 0.5019935416904363} | train loss {'Reaction outcome loss': 0.4675811426980155, 'Total loss': 0.4675811426980155}
2022-11-28 04:21:48,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:48,403 INFO:     Epoch: 28
2022-11-28 04:21:49,055 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5825607289390807, 'Total loss': 0.5825607289390807} | train loss {'Reaction outcome loss': 0.4576081491854726, 'Total loss': 0.4576081491854726}
2022-11-28 04:21:49,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:49,055 INFO:     Epoch: 29
2022-11-28 04:21:49,708 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5330777029422197, 'Total loss': 0.5330777029422197} | train loss {'Reaction outcome loss': 0.46680638899608534, 'Total loss': 0.46680638899608534}
2022-11-28 04:21:49,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:49,709 INFO:     Epoch: 30
2022-11-28 04:21:50,362 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5124405693601478, 'Total loss': 0.5124405693601478} | train loss {'Reaction outcome loss': 0.46381732182843344, 'Total loss': 0.46381732182843344}
2022-11-28 04:21:50,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:50,362 INFO:     Epoch: 31
2022-11-28 04:21:51,016 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5867462347854268, 'Total loss': 0.5867462347854268} | train loss {'Reaction outcome loss': 0.45272081637260864, 'Total loss': 0.45272081637260864}
2022-11-28 04:21:51,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:51,017 INFO:     Epoch: 32
2022-11-28 04:21:51,679 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5086201832375743, 'Total loss': 0.5086201832375743} | train loss {'Reaction outcome loss': 0.46241223124825226, 'Total loss': 0.46241223124825226}
2022-11-28 04:21:51,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:51,679 INFO:     Epoch: 33
2022-11-28 04:21:52,350 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5366283824498003, 'Total loss': 0.5366283824498003} | train loss {'Reaction outcome loss': 0.4589345175392774, 'Total loss': 0.4589345175392774}
2022-11-28 04:21:52,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:52,350 INFO:     Epoch: 34
2022-11-28 04:21:53,021 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5055326545103029, 'Total loss': 0.5055326545103029} | train loss {'Reaction outcome loss': 0.453674029786976, 'Total loss': 0.453674029786976}
2022-11-28 04:21:53,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:53,021 INFO:     Epoch: 35
2022-11-28 04:21:53,688 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5295409431511705, 'Total loss': 0.5295409431511705} | train loss {'Reaction outcome loss': 0.46167780319038704, 'Total loss': 0.46167780319038704}
2022-11-28 04:21:53,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:53,689 INFO:     Epoch: 36
2022-11-28 04:21:54,356 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5349759676239707, 'Total loss': 0.5349759676239707} | train loss {'Reaction outcome loss': 0.4580145542414821, 'Total loss': 0.4580145542414821}
2022-11-28 04:21:54,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:54,357 INFO:     Epoch: 37
2022-11-28 04:21:55,028 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48947249014269223, 'Total loss': 0.48947249014269223} | train loss {'Reaction outcome loss': 0.4578775209735851, 'Total loss': 0.4578775209735851}
2022-11-28 04:21:55,028 INFO:     Found new best model at epoch 37
2022-11-28 04:21:55,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:55,029 INFO:     Epoch: 38
2022-11-28 04:21:55,701 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5283514396710829, 'Total loss': 0.5283514396710829} | train loss {'Reaction outcome loss': 0.45994524785450525, 'Total loss': 0.45994524785450525}
2022-11-28 04:21:55,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:55,701 INFO:     Epoch: 39
2022-11-28 04:21:56,366 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5049393072047017, 'Total loss': 0.5049393072047017} | train loss {'Reaction outcome loss': 0.45756177719758484, 'Total loss': 0.45756177719758484}
2022-11-28 04:21:56,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:56,366 INFO:     Epoch: 40
2022-11-28 04:21:57,015 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5154400623657487, 'Total loss': 0.5154400623657487} | train loss {'Reaction outcome loss': 0.45549679587081987, 'Total loss': 0.45549679587081987}
2022-11-28 04:21:57,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:57,016 INFO:     Epoch: 41
2022-11-28 04:21:57,664 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5362977690317414, 'Total loss': 0.5362977690317414} | train loss {'Reaction outcome loss': 0.45817448740102806, 'Total loss': 0.45817448740102806}
2022-11-28 04:21:57,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:57,664 INFO:     Epoch: 42
2022-11-28 04:21:58,312 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5477822351862084, 'Total loss': 0.5477822351862084} | train loss {'Reaction outcome loss': 0.45261029467290764, 'Total loss': 0.45261029467290764}
2022-11-28 04:21:58,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:58,312 INFO:     Epoch: 43
2022-11-28 04:21:58,962 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49679026198150084, 'Total loss': 0.49679026198150084} | train loss {'Reaction outcome loss': 0.45135120189919764, 'Total loss': 0.45135120189919764}
2022-11-28 04:21:58,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:58,963 INFO:     Epoch: 44
2022-11-28 04:21:59,613 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4844473898410797, 'Total loss': 0.4844473898410797} | train loss {'Reaction outcome loss': 0.4631366330141924, 'Total loss': 0.4631366330141924}
2022-11-28 04:21:59,613 INFO:     Found new best model at epoch 44
2022-11-28 04:21:59,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:21:59,614 INFO:     Epoch: 45
2022-11-28 04:22:00,262 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5687926005233418, 'Total loss': 0.5687926005233418} | train loss {'Reaction outcome loss': 0.45280266391987706, 'Total loss': 0.45280266391987706}
2022-11-28 04:22:00,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:00,262 INFO:     Epoch: 46
2022-11-28 04:22:00,912 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5013787563551556, 'Total loss': 0.5013787563551556} | train loss {'Reaction outcome loss': 0.4541341488154567, 'Total loss': 0.4541341488154567}
2022-11-28 04:22:00,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:00,912 INFO:     Epoch: 47
2022-11-28 04:22:01,564 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.520471169528636, 'Total loss': 0.520471169528636} | train loss {'Reaction outcome loss': 0.4577176032625899, 'Total loss': 0.4577176032625899}
2022-11-28 04:22:01,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:01,565 INFO:     Epoch: 48
2022-11-28 04:22:02,214 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5138642032715407, 'Total loss': 0.5138642032715407} | train loss {'Reaction outcome loss': 0.4563406360392668, 'Total loss': 0.4563406360392668}
2022-11-28 04:22:02,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:02,214 INFO:     Epoch: 49
2022-11-28 04:22:02,867 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5667389434846964, 'Total loss': 0.5667389434846964} | train loss {'Reaction outcome loss': 0.45664956563589526, 'Total loss': 0.45664956563589526}
2022-11-28 04:22:02,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:02,867 INFO:     Epoch: 50
2022-11-28 04:22:03,519 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5344846939498727, 'Total loss': 0.5344846939498727} | train loss {'Reaction outcome loss': 0.44829964266747846, 'Total loss': 0.44829964266747846}
2022-11-28 04:22:03,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:03,519 INFO:     Epoch: 51
2022-11-28 04:22:04,170 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5308155197311532, 'Total loss': 0.5308155197311532} | train loss {'Reaction outcome loss': 0.45575027569216126, 'Total loss': 0.45575027569216126}
2022-11-28 04:22:04,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:04,170 INFO:     Epoch: 52
2022-11-28 04:22:04,821 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5115864901718769, 'Total loss': 0.5115864901718769} | train loss {'Reaction outcome loss': 0.454561002765383, 'Total loss': 0.454561002765383}
2022-11-28 04:22:04,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:04,821 INFO:     Epoch: 53
2022-11-28 04:22:05,475 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49874117225408554, 'Total loss': 0.49874117225408554} | train loss {'Reaction outcome loss': 0.454481326682227, 'Total loss': 0.454481326682227}
2022-11-28 04:22:05,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:05,475 INFO:     Epoch: 54
2022-11-28 04:22:06,127 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5244026556611061, 'Total loss': 0.5244026556611061} | train loss {'Reaction outcome loss': 0.4508245958965652, 'Total loss': 0.4508245958965652}
2022-11-28 04:22:06,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:06,127 INFO:     Epoch: 55
2022-11-28 04:22:06,777 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5352453934875402, 'Total loss': 0.5352453934875402} | train loss {'Reaction outcome loss': 0.45381047251273177, 'Total loss': 0.45381047251273177}
2022-11-28 04:22:06,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:06,777 INFO:     Epoch: 56
2022-11-28 04:22:07,429 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49165595458312467, 'Total loss': 0.49165595458312467} | train loss {'Reaction outcome loss': 0.45677493457891505, 'Total loss': 0.45677493457891505}
2022-11-28 04:22:07,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:07,429 INFO:     Epoch: 57
2022-11-28 04:22:08,079 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5215901624072682, 'Total loss': 0.5215901624072682} | train loss {'Reaction outcome loss': 0.4482053625340364, 'Total loss': 0.4482053625340364}
2022-11-28 04:22:08,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:08,080 INFO:     Epoch: 58
2022-11-28 04:22:08,727 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4831139054149389, 'Total loss': 0.4831139054149389} | train loss {'Reaction outcome loss': 0.4544616756998763, 'Total loss': 0.4544616756998763}
2022-11-28 04:22:08,727 INFO:     Found new best model at epoch 58
2022-11-28 04:22:08,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:08,728 INFO:     Epoch: 59
2022-11-28 04:22:09,376 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5008159296756441, 'Total loss': 0.5008159296756441} | train loss {'Reaction outcome loss': 0.4471223460168255, 'Total loss': 0.4471223460168255}
2022-11-28 04:22:09,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:09,377 INFO:     Epoch: 60
2022-11-28 04:22:10,027 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5260440988296812, 'Total loss': 0.5260440988296812} | train loss {'Reaction outcome loss': 0.455221691484354, 'Total loss': 0.455221691484354}
2022-11-28 04:22:10,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:10,027 INFO:     Epoch: 61
2022-11-28 04:22:10,672 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5518484528769146, 'Total loss': 0.5518484528769146} | train loss {'Reaction outcome loss': 0.4515416034630367, 'Total loss': 0.4515416034630367}
2022-11-28 04:22:10,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:10,672 INFO:     Epoch: 62
2022-11-28 04:22:11,325 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.501324251294136, 'Total loss': 0.501324251294136} | train loss {'Reaction outcome loss': 0.44630125514706787, 'Total loss': 0.44630125514706787}
2022-11-28 04:22:11,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:11,325 INFO:     Epoch: 63
2022-11-28 04:22:11,978 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5093172090974721, 'Total loss': 0.5093172090974721} | train loss {'Reaction outcome loss': 0.45449166340487346, 'Total loss': 0.45449166340487346}
2022-11-28 04:22:11,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:11,978 INFO:     Epoch: 64
2022-11-28 04:22:12,624 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5108171816576611, 'Total loss': 0.5108171816576611} | train loss {'Reaction outcome loss': 0.45168246061218026, 'Total loss': 0.45168246061218026}
2022-11-28 04:22:12,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:12,624 INFO:     Epoch: 65
2022-11-28 04:22:13,275 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5331754250959917, 'Total loss': 0.5331754250959917} | train loss {'Reaction outcome loss': 0.4495086350611278, 'Total loss': 0.4495086350611278}
2022-11-28 04:22:13,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:13,275 INFO:     Epoch: 66
2022-11-28 04:22:13,925 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5097891146486456, 'Total loss': 0.5097891146486456} | train loss {'Reaction outcome loss': 0.45864751950210453, 'Total loss': 0.45864751950210453}
2022-11-28 04:22:13,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:13,925 INFO:     Epoch: 67
2022-11-28 04:22:14,576 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5635063854808157, 'Total loss': 0.5635063854808157} | train loss {'Reaction outcome loss': 0.45245266617560875, 'Total loss': 0.45245266617560875}
2022-11-28 04:22:14,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:14,576 INFO:     Epoch: 68
2022-11-28 04:22:15,227 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5213517482307825, 'Total loss': 0.5213517482307825} | train loss {'Reaction outcome loss': 0.4496757774328699, 'Total loss': 0.4496757774328699}
2022-11-28 04:22:15,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:15,227 INFO:     Epoch: 69
2022-11-28 04:22:15,875 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4962481031702323, 'Total loss': 0.4962481031702323} | train loss {'Reaction outcome loss': 0.4581739925304238, 'Total loss': 0.4581739925304238}
2022-11-28 04:22:15,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:15,875 INFO:     Epoch: 70
2022-11-28 04:22:16,523 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5030361996455626, 'Total loss': 0.5030361996455626} | train loss {'Reaction outcome loss': 0.4502014081697075, 'Total loss': 0.4502014081697075}
2022-11-28 04:22:16,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:16,523 INFO:     Epoch: 71
2022-11-28 04:22:17,174 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5343699509447272, 'Total loss': 0.5343699509447272} | train loss {'Reaction outcome loss': 0.4481140622070858, 'Total loss': 0.4481140622070858}
2022-11-28 04:22:17,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:17,174 INFO:     Epoch: 72
2022-11-28 04:22:17,825 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49389140612699767, 'Total loss': 0.49389140612699767} | train loss {'Reaction outcome loss': 0.4498310419977928, 'Total loss': 0.4498310419977928}
2022-11-28 04:22:17,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:17,826 INFO:     Epoch: 73
2022-11-28 04:22:18,475 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5077211565592072, 'Total loss': 0.5077211565592072} | train loss {'Reaction outcome loss': 0.44782070560114723, 'Total loss': 0.44782070560114723}
2022-11-28 04:22:18,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:18,475 INFO:     Epoch: 74
2022-11-28 04:22:19,124 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5047653012654998, 'Total loss': 0.5047653012654998} | train loss {'Reaction outcome loss': 0.4596352954908293, 'Total loss': 0.4596352954908293}
2022-11-28 04:22:19,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:19,125 INFO:     Epoch: 75
2022-11-28 04:22:19,776 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5144820714538748, 'Total loss': 0.5144820714538748} | train loss {'Reaction outcome loss': 0.45107241765576966, 'Total loss': 0.45107241765576966}
2022-11-28 04:22:19,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:19,776 INFO:     Epoch: 76
2022-11-28 04:22:20,427 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4912997897375714, 'Total loss': 0.4912997897375714} | train loss {'Reaction outcome loss': 0.45581025669769365, 'Total loss': 0.45581025669769365}
2022-11-28 04:22:20,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:20,427 INFO:     Epoch: 77
2022-11-28 04:22:21,077 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5140951716087081, 'Total loss': 0.5140951716087081} | train loss {'Reaction outcome loss': 0.45002373779306604, 'Total loss': 0.45002373779306604}
2022-11-28 04:22:21,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:21,078 INFO:     Epoch: 78
2022-11-28 04:22:21,728 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5601680712266401, 'Total loss': 0.5601680712266401} | train loss {'Reaction outcome loss': 0.4480981416544136, 'Total loss': 0.4480981416544136}
2022-11-28 04:22:21,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:21,729 INFO:     Epoch: 79
2022-11-28 04:22:22,381 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5086429579691454, 'Total loss': 0.5086429579691454} | train loss {'Reaction outcome loss': 0.450316651256717, 'Total loss': 0.450316651256717}
2022-11-28 04:22:22,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:22,381 INFO:     Epoch: 80
2022-11-28 04:22:23,035 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49893472174351866, 'Total loss': 0.49893472174351866} | train loss {'Reaction outcome loss': 0.45253823417790084, 'Total loss': 0.45253823417790084}
2022-11-28 04:22:23,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:23,035 INFO:     Epoch: 81
2022-11-28 04:22:23,686 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5129698538644747, 'Total loss': 0.5129698538644747} | train loss {'Reaction outcome loss': 0.45465346282842206, 'Total loss': 0.45465346282842206}
2022-11-28 04:22:23,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:23,687 INFO:     Epoch: 82
2022-11-28 04:22:24,336 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5412565412169154, 'Total loss': 0.5412565412169154} | train loss {'Reaction outcome loss': 0.4536143720149994, 'Total loss': 0.4536143720149994}
2022-11-28 04:22:24,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:24,337 INFO:     Epoch: 83
2022-11-28 04:22:24,986 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5198978893458843, 'Total loss': 0.5198978893458843} | train loss {'Reaction outcome loss': 0.452014087475076, 'Total loss': 0.452014087475076}
2022-11-28 04:22:24,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:24,986 INFO:     Epoch: 84
2022-11-28 04:22:25,634 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4909153553572568, 'Total loss': 0.4909153553572568} | train loss {'Reaction outcome loss': 0.4536897371618115, 'Total loss': 0.4536897371618115}
2022-11-28 04:22:25,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:25,634 INFO:     Epoch: 85
2022-11-28 04:22:26,279 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49990574710748414, 'Total loss': 0.49990574710748414} | train loss {'Reaction outcome loss': 0.4486866879219912, 'Total loss': 0.4486866879219912}
2022-11-28 04:22:26,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:26,280 INFO:     Epoch: 86
2022-11-28 04:22:26,928 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5212346945296634, 'Total loss': 0.5212346945296634} | train loss {'Reaction outcome loss': 0.4522297577894464, 'Total loss': 0.4522297577894464}
2022-11-28 04:22:26,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:26,928 INFO:     Epoch: 87
2022-11-28 04:22:27,575 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5153839130970564, 'Total loss': 0.5153839130970564} | train loss {'Reaction outcome loss': 0.4527621318491138, 'Total loss': 0.4527621318491138}
2022-11-28 04:22:27,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:27,575 INFO:     Epoch: 88
2022-11-28 04:22:28,221 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5392546145753427, 'Total loss': 0.5392546145753427} | train loss {'Reaction outcome loss': 0.454448172814992, 'Total loss': 0.454448172814992}
2022-11-28 04:22:28,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:28,221 INFO:     Epoch: 89
2022-11-28 04:22:28,872 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5123582069169391, 'Total loss': 0.5123582069169391} | train loss {'Reaction outcome loss': 0.4527522288414897, 'Total loss': 0.4527522288414897}
2022-11-28 04:22:28,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:28,872 INFO:     Epoch: 90
2022-11-28 04:22:29,525 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4960541677745906, 'Total loss': 0.4960541677745906} | train loss {'Reaction outcome loss': 0.45549547076225283, 'Total loss': 0.45549547076225283}
2022-11-28 04:22:29,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:29,525 INFO:     Epoch: 91
2022-11-28 04:22:30,180 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5158009115945209, 'Total loss': 0.5158009115945209} | train loss {'Reaction outcome loss': 0.4473367132094442, 'Total loss': 0.4473367132094442}
2022-11-28 04:22:30,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:30,181 INFO:     Epoch: 92
2022-11-28 04:22:30,831 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4979944222352721, 'Total loss': 0.4979944222352721} | train loss {'Reaction outcome loss': 0.45765354371800715, 'Total loss': 0.45765354371800715}
2022-11-28 04:22:30,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:30,832 INFO:     Epoch: 93
2022-11-28 04:22:31,484 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5074016201225194, 'Total loss': 0.5074016201225194} | train loss {'Reaction outcome loss': 0.44593049476341323, 'Total loss': 0.44593049476341323}
2022-11-28 04:22:31,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:31,484 INFO:     Epoch: 94
2022-11-28 04:22:32,138 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5187786172398112, 'Total loss': 0.5187786172398112} | train loss {'Reaction outcome loss': 0.4521051970063424, 'Total loss': 0.4521051970063424}
2022-11-28 04:22:32,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:32,138 INFO:     Epoch: 95
2022-11-28 04:22:32,788 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49442302706566726, 'Total loss': 0.49442302706566726} | train loss {'Reaction outcome loss': 0.46079812402627907, 'Total loss': 0.46079812402627907}
2022-11-28 04:22:32,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:32,788 INFO:     Epoch: 96
2022-11-28 04:22:33,444 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5187968423759396, 'Total loss': 0.5187968423759396} | train loss {'Reaction outcome loss': 0.4614728756705109, 'Total loss': 0.4614728756705109}
2022-11-28 04:22:33,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:33,444 INFO:     Epoch: 97
2022-11-28 04:22:34,096 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5258691564879634, 'Total loss': 0.5258691564879634} | train loss {'Reaction outcome loss': 0.4488911087415656, 'Total loss': 0.4488911087415656}
2022-11-28 04:22:34,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:34,096 INFO:     Epoch: 98
2022-11-28 04:22:34,744 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.554300828074867, 'Total loss': 0.554300828074867} | train loss {'Reaction outcome loss': 0.45960053540005974, 'Total loss': 0.45960053540005974}
2022-11-28 04:22:34,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:34,744 INFO:     Epoch: 99
2022-11-28 04:22:35,397 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5448034337975762, 'Total loss': 0.5448034337975762} | train loss {'Reaction outcome loss': 0.4547784198911823, 'Total loss': 0.4547784198911823}
2022-11-28 04:22:35,397 INFO:     Best model found after epoch 59 of 100.
2022-11-28 04:22:35,397 INFO:   Done with stage: TRAINING
2022-11-28 04:22:35,397 INFO:   Starting stage: EVALUATION
2022-11-28 04:22:35,521 INFO:   Done with stage: EVALUATION
2022-11-28 04:22:35,521 INFO:   Leaving out SEQ value Fold_1
2022-11-28 04:22:35,534 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:22:35,534 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:22:36,176 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:22:36,176 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:22:36,243 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:22:36,244 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:22:36,244 INFO:     No hyperparam tuning for this model
2022-11-28 04:22:36,244 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:22:36,244 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:22:36,244 INFO:     None feature selector for col prot
2022-11-28 04:22:36,245 INFO:     None feature selector for col prot
2022-11-28 04:22:36,245 INFO:     None feature selector for col prot
2022-11-28 04:22:36,245 INFO:     None feature selector for col chem
2022-11-28 04:22:36,245 INFO:     None feature selector for col chem
2022-11-28 04:22:36,245 INFO:     None feature selector for col chem
2022-11-28 04:22:36,245 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:22:36,245 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:22:36,247 INFO:     Number of params in model 169651
2022-11-28 04:22:36,250 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:22:36,250 INFO:   Starting stage: TRAINING
2022-11-28 04:22:36,300 INFO:     Val loss before train {'Reaction outcome loss': 0.9790676764466546, 'Total loss': 0.9790676764466546}
2022-11-28 04:22:36,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:36,300 INFO:     Epoch: 0
2022-11-28 04:22:36,955 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6269773556427523, 'Total loss': 0.6269773556427523} | train loss {'Reaction outcome loss': 0.6955851306720656, 'Total loss': 0.6955851306720656}
2022-11-28 04:22:36,955 INFO:     Found new best model at epoch 0
2022-11-28 04:22:36,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:36,956 INFO:     Epoch: 1
2022-11-28 04:22:37,610 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5518832684240558, 'Total loss': 0.5518832684240558} | train loss {'Reaction outcome loss': 0.5912116722184785, 'Total loss': 0.5912116722184785}
2022-11-28 04:22:37,610 INFO:     Found new best model at epoch 1
2022-11-28 04:22:37,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:37,611 INFO:     Epoch: 2
2022-11-28 04:22:38,266 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5734714228998531, 'Total loss': 0.5734714228998531} | train loss {'Reaction outcome loss': 0.5509332322344488, 'Total loss': 0.5509332322344488}
2022-11-28 04:22:38,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:38,266 INFO:     Epoch: 3
2022-11-28 04:22:38,916 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5305477749894966, 'Total loss': 0.5305477749894966} | train loss {'Reaction outcome loss': 0.5347691996973388, 'Total loss': 0.5347691996973388}
2022-11-28 04:22:38,917 INFO:     Found new best model at epoch 3
2022-11-28 04:22:38,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:38,917 INFO:     Epoch: 4
2022-11-28 04:22:39,565 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5229863717474721, 'Total loss': 0.5229863717474721} | train loss {'Reaction outcome loss': 0.5264301722755238, 'Total loss': 0.5264301722755238}
2022-11-28 04:22:39,565 INFO:     Found new best model at epoch 4
2022-11-28 04:22:39,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:39,566 INFO:     Epoch: 5
2022-11-28 04:22:40,217 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5209246081384745, 'Total loss': 0.5209246081384745} | train loss {'Reaction outcome loss': 0.513042668177157, 'Total loss': 0.513042668177157}
2022-11-28 04:22:40,217 INFO:     Found new best model at epoch 5
2022-11-28 04:22:40,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:40,218 INFO:     Epoch: 6
2022-11-28 04:22:40,869 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5057269111275673, 'Total loss': 0.5057269111275673} | train loss {'Reaction outcome loss': 0.5158199533516047, 'Total loss': 0.5158199533516047}
2022-11-28 04:22:40,869 INFO:     Found new best model at epoch 6
2022-11-28 04:22:40,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:40,870 INFO:     Epoch: 7
2022-11-28 04:22:41,522 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.6032536483623765, 'Total loss': 0.6032536483623765} | train loss {'Reaction outcome loss': 0.501139492222241, 'Total loss': 0.501139492222241}
2022-11-28 04:22:41,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:41,522 INFO:     Epoch: 8
2022-11-28 04:22:42,171 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4759609733115543, 'Total loss': 0.4759609733115543} | train loss {'Reaction outcome loss': 0.5034507652934717, 'Total loss': 0.5034507652934717}
2022-11-28 04:22:42,171 INFO:     Found new best model at epoch 8
2022-11-28 04:22:42,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:42,172 INFO:     Epoch: 9
2022-11-28 04:22:42,823 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5460195111280138, 'Total loss': 0.5460195111280138} | train loss {'Reaction outcome loss': 0.4918705692096632, 'Total loss': 0.4918705692096632}
2022-11-28 04:22:42,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:42,823 INFO:     Epoch: 10
2022-11-28 04:22:43,471 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5176733942194418, 'Total loss': 0.5176733942194418} | train loss {'Reaction outcome loss': 0.4887936360982, 'Total loss': 0.4887936360982}
2022-11-28 04:22:43,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:43,472 INFO:     Epoch: 11
2022-11-28 04:22:44,125 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5111694935370575, 'Total loss': 0.5111694935370575} | train loss {'Reaction outcome loss': 0.48630566019184734, 'Total loss': 0.48630566019184734}
2022-11-28 04:22:44,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:44,125 INFO:     Epoch: 12
2022-11-28 04:22:44,781 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5387071205133741, 'Total loss': 0.5387071205133741} | train loss {'Reaction outcome loss': 0.4909025468388382, 'Total loss': 0.4909025468388382}
2022-11-28 04:22:44,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:44,782 INFO:     Epoch: 13
2022-11-28 04:22:45,433 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5294874703342264, 'Total loss': 0.5294874703342264} | train loss {'Reaction outcome loss': 0.4879754108433821, 'Total loss': 0.4879754108433821}
2022-11-28 04:22:45,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:45,434 INFO:     Epoch: 14
2022-11-28 04:22:46,089 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4885701256042177, 'Total loss': 0.4885701256042177} | train loss {'Reaction outcome loss': 0.4880074484007699, 'Total loss': 0.4880074484007699}
2022-11-28 04:22:46,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:46,089 INFO:     Epoch: 15
2022-11-28 04:22:46,739 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5146158574657007, 'Total loss': 0.5146158574657007} | train loss {'Reaction outcome loss': 0.4817541686247806, 'Total loss': 0.4817541686247806}
2022-11-28 04:22:46,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:46,739 INFO:     Epoch: 16
2022-11-28 04:22:47,395 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4739252118901773, 'Total loss': 0.4739252118901773} | train loss {'Reaction outcome loss': 0.4865020657680473, 'Total loss': 0.4865020657680473}
2022-11-28 04:22:47,396 INFO:     Found new best model at epoch 16
2022-11-28 04:22:47,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:47,396 INFO:     Epoch: 17
2022-11-28 04:22:48,048 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5406486635858362, 'Total loss': 0.5406486635858362} | train loss {'Reaction outcome loss': 0.46851277241901473, 'Total loss': 0.46851277241901473}
2022-11-28 04:22:48,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:48,048 INFO:     Epoch: 18
2022-11-28 04:22:48,698 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5259809822521426, 'Total loss': 0.5259809822521426} | train loss {'Reaction outcome loss': 0.48060515109373597, 'Total loss': 0.48060515109373597}
2022-11-28 04:22:48,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:48,699 INFO:     Epoch: 19
2022-11-28 04:22:49,346 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48853668638251047, 'Total loss': 0.48853668638251047} | train loss {'Reaction outcome loss': 0.4711584084496206, 'Total loss': 0.4711584084496206}
2022-11-28 04:22:49,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:49,346 INFO:     Epoch: 20
2022-11-28 04:22:49,994 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4972884126684882, 'Total loss': 0.4972884126684882} | train loss {'Reaction outcome loss': 0.47598990743257563, 'Total loss': 0.47598990743257563}
2022-11-28 04:22:49,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:49,994 INFO:     Epoch: 21
2022-11-28 04:22:50,646 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.502931223674254, 'Total loss': 0.502931223674254} | train loss {'Reaction outcome loss': 0.47184679477798697, 'Total loss': 0.47184679477798697}
2022-11-28 04:22:50,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:50,646 INFO:     Epoch: 22
2022-11-28 04:22:51,298 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4603602558967065, 'Total loss': 0.4603602558967065} | train loss {'Reaction outcome loss': 0.47257771291294876, 'Total loss': 0.47257771291294876}
2022-11-28 04:22:51,299 INFO:     Found new best model at epoch 22
2022-11-28 04:22:51,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:51,299 INFO:     Epoch: 23
2022-11-28 04:22:51,952 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48162645169279794, 'Total loss': 0.48162645169279794} | train loss {'Reaction outcome loss': 0.4686571723040269, 'Total loss': 0.4686571723040269}
2022-11-28 04:22:51,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:51,952 INFO:     Epoch: 24
2022-11-28 04:22:52,605 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47353807294910605, 'Total loss': 0.47353807294910605} | train loss {'Reaction outcome loss': 0.4748881487822046, 'Total loss': 0.4748881487822046}
2022-11-28 04:22:52,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:52,606 INFO:     Epoch: 25
2022-11-28 04:22:53,253 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49839419566772203, 'Total loss': 0.49839419566772203} | train loss {'Reaction outcome loss': 0.4662406628837391, 'Total loss': 0.4662406628837391}
2022-11-28 04:22:53,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:53,254 INFO:     Epoch: 26
2022-11-28 04:22:53,901 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46647055802697485, 'Total loss': 0.46647055802697485} | train loss {'Reaction outcome loss': 0.46685682009069285, 'Total loss': 0.46685682009069285}
2022-11-28 04:22:53,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:53,901 INFO:     Epoch: 27
2022-11-28 04:22:54,552 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.480743966658007, 'Total loss': 0.480743966658007} | train loss {'Reaction outcome loss': 0.469109051993915, 'Total loss': 0.469109051993915}
2022-11-28 04:22:54,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:54,552 INFO:     Epoch: 28
2022-11-28 04:22:55,204 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4687424403699962, 'Total loss': 0.4687424403699962} | train loss {'Reaction outcome loss': 0.46862609453347265, 'Total loss': 0.46862609453347265}
2022-11-28 04:22:55,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:55,204 INFO:     Epoch: 29
2022-11-28 04:22:55,854 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48239757256074384, 'Total loss': 0.48239757256074384} | train loss {'Reaction outcome loss': 0.46744263822935067, 'Total loss': 0.46744263822935067}
2022-11-28 04:22:55,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:55,854 INFO:     Epoch: 30
2022-11-28 04:22:56,502 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4911694763736291, 'Total loss': 0.4911694763736291} | train loss {'Reaction outcome loss': 0.4646737291496627, 'Total loss': 0.4646737291496627}
2022-11-28 04:22:56,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:56,503 INFO:     Epoch: 31
2022-11-28 04:22:57,154 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48421642336655746, 'Total loss': 0.48421642336655746} | train loss {'Reaction outcome loss': 0.46721146228362104, 'Total loss': 0.46721146228362104}
2022-11-28 04:22:57,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:57,154 INFO:     Epoch: 32
2022-11-28 04:22:57,804 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48040724207054486, 'Total loss': 0.48040724207054486} | train loss {'Reaction outcome loss': 0.46953855564399644, 'Total loss': 0.46953855564399644}
2022-11-28 04:22:57,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:57,804 INFO:     Epoch: 33
2022-11-28 04:22:58,454 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5038812861523845, 'Total loss': 0.5038812861523845} | train loss {'Reaction outcome loss': 0.46458397991195016, 'Total loss': 0.46458397991195016}
2022-11-28 04:22:58,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:58,454 INFO:     Epoch: 34
2022-11-28 04:22:59,106 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46939732879400253, 'Total loss': 0.46939732879400253} | train loss {'Reaction outcome loss': 0.46649972537950596, 'Total loss': 0.46649972537950596}
2022-11-28 04:22:59,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:59,107 INFO:     Epoch: 35
2022-11-28 04:22:59,755 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.471471155570312, 'Total loss': 0.471471155570312} | train loss {'Reaction outcome loss': 0.4657278916665486, 'Total loss': 0.4657278916665486}
2022-11-28 04:22:59,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:22:59,756 INFO:     Epoch: 36
2022-11-28 04:23:00,404 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4733602394434539, 'Total loss': 0.4733602394434539} | train loss {'Reaction outcome loss': 0.46497588902711867, 'Total loss': 0.46497588902711867}
2022-11-28 04:23:00,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:00,405 INFO:     Epoch: 37
2022-11-28 04:23:01,052 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4823632382533767, 'Total loss': 0.4823632382533767} | train loss {'Reaction outcome loss': 0.4632695069118422, 'Total loss': 0.4632695069118422}
2022-11-28 04:23:01,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:01,052 INFO:     Epoch: 38
2022-11-28 04:23:01,705 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4668351300060749, 'Total loss': 0.4668351300060749} | train loss {'Reaction outcome loss': 0.46384833953818494, 'Total loss': 0.46384833953818494}
2022-11-28 04:23:01,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:01,705 INFO:     Epoch: 39
2022-11-28 04:23:02,355 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46183809638023376, 'Total loss': 0.46183809638023376} | train loss {'Reaction outcome loss': 0.4604771410932346, 'Total loss': 0.4604771410932346}
2022-11-28 04:23:02,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:02,355 INFO:     Epoch: 40
2022-11-28 04:23:03,004 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4573872536420822, 'Total loss': 0.4573872536420822} | train loss {'Reaction outcome loss': 0.4585695163631926, 'Total loss': 0.4585695163631926}
2022-11-28 04:23:03,005 INFO:     Found new best model at epoch 40
2022-11-28 04:23:03,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:03,005 INFO:     Epoch: 41
2022-11-28 04:23:03,658 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4779504703527147, 'Total loss': 0.4779504703527147} | train loss {'Reaction outcome loss': 0.46145170379658135, 'Total loss': 0.46145170379658135}
2022-11-28 04:23:03,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:03,658 INFO:     Epoch: 42
2022-11-28 04:23:04,312 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5779150622812185, 'Total loss': 0.5779150622812185} | train loss {'Reaction outcome loss': 0.4665987353543846, 'Total loss': 0.4665987353543846}
2022-11-28 04:23:04,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:04,312 INFO:     Epoch: 43
2022-11-28 04:23:04,966 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4592930769378489, 'Total loss': 0.4592930769378489} | train loss {'Reaction outcome loss': 0.46368205860561257, 'Total loss': 0.46368205860561257}
2022-11-28 04:23:04,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:04,966 INFO:     Epoch: 44
2022-11-28 04:23:05,621 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4888329025019299, 'Total loss': 0.4888329025019299} | train loss {'Reaction outcome loss': 0.46126412737126254, 'Total loss': 0.46126412737126254}
2022-11-28 04:23:05,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:05,621 INFO:     Epoch: 45
2022-11-28 04:23:06,277 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47400921515443106, 'Total loss': 0.47400921515443106} | train loss {'Reaction outcome loss': 0.463747356010943, 'Total loss': 0.463747356010943}
2022-11-28 04:23:06,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:06,277 INFO:     Epoch: 46
2022-11-28 04:23:06,934 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4925802858038382, 'Total loss': 0.4925802858038382} | train loss {'Reaction outcome loss': 0.46189653283479265, 'Total loss': 0.46189653283479265}
2022-11-28 04:23:06,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:06,934 INFO:     Epoch: 47
2022-11-28 04:23:07,588 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47247965701601724, 'Total loss': 0.47247965701601724} | train loss {'Reaction outcome loss': 0.4653441193760658, 'Total loss': 0.4653441193760658}
2022-11-28 04:23:07,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:07,588 INFO:     Epoch: 48
2022-11-28 04:23:08,243 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44820304384285753, 'Total loss': 0.44820304384285753} | train loss {'Reaction outcome loss': 0.462690138391086, 'Total loss': 0.462690138391086}
2022-11-28 04:23:08,243 INFO:     Found new best model at epoch 48
2022-11-28 04:23:08,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:08,244 INFO:     Epoch: 49
2022-11-28 04:23:08,897 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47472246770154347, 'Total loss': 0.47472246770154347} | train loss {'Reaction outcome loss': 0.45437432296422064, 'Total loss': 0.45437432296422064}
2022-11-28 04:23:08,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:08,897 INFO:     Epoch: 50
2022-11-28 04:23:09,553 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47859845107251947, 'Total loss': 0.47859845107251947} | train loss {'Reaction outcome loss': 0.4607587471300242, 'Total loss': 0.4607587471300242}
2022-11-28 04:23:09,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:09,553 INFO:     Epoch: 51
2022-11-28 04:23:10,211 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45287917452779686, 'Total loss': 0.45287917452779686} | train loss {'Reaction outcome loss': 0.460485427598564, 'Total loss': 0.460485427598564}
2022-11-28 04:23:10,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:10,211 INFO:     Epoch: 52
2022-11-28 04:23:10,867 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47825571623715485, 'Total loss': 0.47825571623715485} | train loss {'Reaction outcome loss': 0.46182929618018015, 'Total loss': 0.46182929618018015}
2022-11-28 04:23:10,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:10,867 INFO:     Epoch: 53
2022-11-28 04:23:11,523 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48236339014362206, 'Total loss': 0.48236339014362206} | train loss {'Reaction outcome loss': 0.46370322898942595, 'Total loss': 0.46370322898942595}
2022-11-28 04:23:11,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:11,524 INFO:     Epoch: 54
2022-11-28 04:23:12,183 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47057057138193736, 'Total loss': 0.47057057138193736} | train loss {'Reaction outcome loss': 0.45389016355787004, 'Total loss': 0.45389016355787004}
2022-11-28 04:23:12,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:12,183 INFO:     Epoch: 55
2022-11-28 04:23:12,840 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4538912210105495, 'Total loss': 0.4538912210105495} | train loss {'Reaction outcome loss': 0.4664221053220788, 'Total loss': 0.4664221053220788}
2022-11-28 04:23:12,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:12,840 INFO:     Epoch: 56
2022-11-28 04:23:13,499 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4692717871882699, 'Total loss': 0.4692717871882699} | train loss {'Reaction outcome loss': 0.4593659793844028, 'Total loss': 0.4593659793844028}
2022-11-28 04:23:13,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:13,499 INFO:     Epoch: 57
2022-11-28 04:23:14,158 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48227018930695276, 'Total loss': 0.48227018930695276} | train loss {'Reaction outcome loss': 0.45828241453487045, 'Total loss': 0.45828241453487045}
2022-11-28 04:23:14,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:14,159 INFO:     Epoch: 58
2022-11-28 04:23:14,817 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4794078201732852, 'Total loss': 0.4794078201732852} | train loss {'Reaction outcome loss': 0.46401863545179367, 'Total loss': 0.46401863545179367}
2022-11-28 04:23:14,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:14,817 INFO:     Epoch: 59
2022-11-28 04:23:15,472 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4790730432353236, 'Total loss': 0.4790730432353236} | train loss {'Reaction outcome loss': 0.46173612201700404, 'Total loss': 0.46173612201700404}
2022-11-28 04:23:15,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:15,472 INFO:     Epoch: 60
2022-11-28 04:23:16,129 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46363466707142914, 'Total loss': 0.46363466707142914} | train loss {'Reaction outcome loss': 0.4621137314913224, 'Total loss': 0.4621137314913224}
2022-11-28 04:23:16,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:16,129 INFO:     Epoch: 61
2022-11-28 04:23:16,785 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4971051730892875, 'Total loss': 0.4971051730892875} | train loss {'Reaction outcome loss': 0.45873494476688154, 'Total loss': 0.45873494476688154}
2022-11-28 04:23:16,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:16,785 INFO:     Epoch: 62
2022-11-28 04:23:17,443 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4993672326884486, 'Total loss': 0.4993672326884486} | train loss {'Reaction outcome loss': 0.46201997095224806, 'Total loss': 0.46201997095224806}
2022-11-28 04:23:17,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:17,443 INFO:     Epoch: 63
2022-11-28 04:23:18,099 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4830160364508629, 'Total loss': 0.4830160364508629} | train loss {'Reaction outcome loss': 0.46134319843686356, 'Total loss': 0.46134319843686356}
2022-11-28 04:23:18,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:18,099 INFO:     Epoch: 64
2022-11-28 04:23:18,755 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4896095933561975, 'Total loss': 0.4896095933561975} | train loss {'Reaction outcome loss': 0.4569939460681409, 'Total loss': 0.4569939460681409}
2022-11-28 04:23:18,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:18,755 INFO:     Epoch: 65
2022-11-28 04:23:19,415 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47102280909364874, 'Total loss': 0.47102280909364874} | train loss {'Reaction outcome loss': 0.4581141108761028, 'Total loss': 0.4581141108761028}
2022-11-28 04:23:19,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:19,415 INFO:     Epoch: 66
2022-11-28 04:23:20,075 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4745584468949925, 'Total loss': 0.4745584468949925} | train loss {'Reaction outcome loss': 0.4641036362064128, 'Total loss': 0.4641036362064128}
2022-11-28 04:23:20,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:20,075 INFO:     Epoch: 67
2022-11-28 04:23:20,738 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4647393101318316, 'Total loss': 0.4647393101318316} | train loss {'Reaction outcome loss': 0.46378776650039516, 'Total loss': 0.46378776650039516}
2022-11-28 04:23:20,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:20,738 INFO:     Epoch: 68
2022-11-28 04:23:21,396 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48313961313529447, 'Total loss': 0.48313961313529447} | train loss {'Reaction outcome loss': 0.4534160342751717, 'Total loss': 0.4534160342751717}
2022-11-28 04:23:21,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:21,396 INFO:     Epoch: 69
2022-11-28 04:23:22,054 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4738224646584554, 'Total loss': 0.4738224646584554} | train loss {'Reaction outcome loss': 0.4538327471942318, 'Total loss': 0.4538327471942318}
2022-11-28 04:23:22,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:22,054 INFO:     Epoch: 70
2022-11-28 04:23:22,711 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49014860730279575, 'Total loss': 0.49014860730279575} | train loss {'Reaction outcome loss': 0.4588696186031614, 'Total loss': 0.4588696186031614}
2022-11-28 04:23:22,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:22,711 INFO:     Epoch: 71
2022-11-28 04:23:23,367 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4683994505215775, 'Total loss': 0.4683994505215775} | train loss {'Reaction outcome loss': 0.46125677185399194, 'Total loss': 0.46125677185399194}
2022-11-28 04:23:23,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:23,368 INFO:     Epoch: 72
2022-11-28 04:23:24,026 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.504172953015024, 'Total loss': 0.504172953015024} | train loss {'Reaction outcome loss': 0.4540653200173865, 'Total loss': 0.4540653200173865}
2022-11-28 04:23:24,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:24,027 INFO:     Epoch: 73
2022-11-28 04:23:24,685 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4590226054530252, 'Total loss': 0.4590226054530252} | train loss {'Reaction outcome loss': 0.46906776562029, 'Total loss': 0.46906776562029}
2022-11-28 04:23:24,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:24,685 INFO:     Epoch: 74
2022-11-28 04:23:25,346 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48544340885498305, 'Total loss': 0.48544340885498305} | train loss {'Reaction outcome loss': 0.4599397888597177, 'Total loss': 0.4599397888597177}
2022-11-28 04:23:25,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:25,346 INFO:     Epoch: 75
2022-11-28 04:23:26,002 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4786968393759294, 'Total loss': 0.4786968393759294} | train loss {'Reaction outcome loss': 0.45847837566112987, 'Total loss': 0.45847837566112987}
2022-11-28 04:23:26,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:26,002 INFO:     Epoch: 76
2022-11-28 04:23:26,659 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.477558258920908, 'Total loss': 0.477558258920908} | train loss {'Reaction outcome loss': 0.4588227824441024, 'Total loss': 0.4588227824441024}
2022-11-28 04:23:26,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:26,660 INFO:     Epoch: 77
2022-11-28 04:23:27,318 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47572672163898294, 'Total loss': 0.47572672163898294} | train loss {'Reaction outcome loss': 0.46333855925774087, 'Total loss': 0.46333855925774087}
2022-11-28 04:23:27,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:27,318 INFO:     Epoch: 78
2022-11-28 04:23:27,977 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4808705967258323, 'Total loss': 0.4808705967258323} | train loss {'Reaction outcome loss': 0.45031957589850136, 'Total loss': 0.45031957589850136}
2022-11-28 04:23:27,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:27,978 INFO:     Epoch: 79
2022-11-28 04:23:28,635 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4809825931760398, 'Total loss': 0.4809825931760398} | train loss {'Reaction outcome loss': 0.46293023575325404, 'Total loss': 0.46293023575325404}
2022-11-28 04:23:28,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:28,635 INFO:     Epoch: 80
2022-11-28 04:23:29,289 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45898038978603756, 'Total loss': 0.45898038978603756} | train loss {'Reaction outcome loss': 0.4565647077499604, 'Total loss': 0.4565647077499604}
2022-11-28 04:23:29,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:29,289 INFO:     Epoch: 81
2022-11-28 04:23:29,947 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4739518041976474, 'Total loss': 0.4739518041976474} | train loss {'Reaction outcome loss': 0.4573726840773407, 'Total loss': 0.4573726840773407}
2022-11-28 04:23:29,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:29,948 INFO:     Epoch: 82
2022-11-28 04:23:30,607 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4909503642808307, 'Total loss': 0.4909503642808307} | train loss {'Reaction outcome loss': 0.45939869205562434, 'Total loss': 0.45939869205562434}
2022-11-28 04:23:30,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:30,607 INFO:     Epoch: 83
2022-11-28 04:23:31,273 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4797251414168965, 'Total loss': 0.4797251414168965} | train loss {'Reaction outcome loss': 0.45618512545313156, 'Total loss': 0.45618512545313156}
2022-11-28 04:23:31,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:31,273 INFO:     Epoch: 84
2022-11-28 04:23:31,932 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47143562273545697, 'Total loss': 0.47143562273545697} | train loss {'Reaction outcome loss': 0.461568827835881, 'Total loss': 0.461568827835881}
2022-11-28 04:23:31,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:31,932 INFO:     Epoch: 85
2022-11-28 04:23:32,590 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45466373793103476, 'Total loss': 0.45466373793103476} | train loss {'Reaction outcome loss': 0.46292083281643537, 'Total loss': 0.46292083281643537}
2022-11-28 04:23:32,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:32,590 INFO:     Epoch: 86
2022-11-28 04:23:33,248 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4800583307038654, 'Total loss': 0.4800583307038654} | train loss {'Reaction outcome loss': 0.46494055402522183, 'Total loss': 0.46494055402522183}
2022-11-28 04:23:33,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:33,248 INFO:     Epoch: 87
2022-11-28 04:23:33,910 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.464727963574908, 'Total loss': 0.464727963574908} | train loss {'Reaction outcome loss': 0.4598293256394717, 'Total loss': 0.4598293256394717}
2022-11-28 04:23:33,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:33,910 INFO:     Epoch: 88
2022-11-28 04:23:34,569 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43822228112681344, 'Total loss': 0.43822228112681344} | train loss {'Reaction outcome loss': 0.46184046241093657, 'Total loss': 0.46184046241093657}
2022-11-28 04:23:34,569 INFO:     Found new best model at epoch 88
2022-11-28 04:23:34,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:34,570 INFO:     Epoch: 89
2022-11-28 04:23:35,227 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46356367421421135, 'Total loss': 0.46356367421421135} | train loss {'Reaction outcome loss': 0.4702158497000227, 'Total loss': 0.4702158497000227}
2022-11-28 04:23:35,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:35,227 INFO:     Epoch: 90
2022-11-28 04:23:35,891 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4610019929029725, 'Total loss': 0.4610019929029725} | train loss {'Reaction outcome loss': 0.4538401119563044, 'Total loss': 0.4538401119563044}
2022-11-28 04:23:35,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:35,891 INFO:     Epoch: 91
2022-11-28 04:23:36,552 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46526873348788783, 'Total loss': 0.46526873348788783} | train loss {'Reaction outcome loss': 0.46170520314148494, 'Total loss': 0.46170520314148494}
2022-11-28 04:23:36,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:36,552 INFO:     Epoch: 92
2022-11-28 04:23:37,218 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46973895823413675, 'Total loss': 0.46973895823413675} | train loss {'Reaction outcome loss': 0.44834453162490107, 'Total loss': 0.44834453162490107}
2022-11-28 04:23:37,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:37,218 INFO:     Epoch: 93
2022-11-28 04:23:37,879 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45041203972968186, 'Total loss': 0.45041203972968186} | train loss {'Reaction outcome loss': 0.4634012904702401, 'Total loss': 0.4634012904702401}
2022-11-28 04:23:37,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:37,880 INFO:     Epoch: 94
2022-11-28 04:23:38,541 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4417787996882742, 'Total loss': 0.4417787996882742} | train loss {'Reaction outcome loss': 0.45688883577074324, 'Total loss': 0.45688883577074324}
2022-11-28 04:23:38,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:38,541 INFO:     Epoch: 95
2022-11-28 04:23:39,204 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4591877306388183, 'Total loss': 0.4591877306388183} | train loss {'Reaction outcome loss': 0.45584853686848464, 'Total loss': 0.45584853686848464}
2022-11-28 04:23:39,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:39,205 INFO:     Epoch: 96
2022-11-28 04:23:39,868 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4603237746791406, 'Total loss': 0.4603237746791406} | train loss {'Reaction outcome loss': 0.4570031729279732, 'Total loss': 0.4570031729279732}
2022-11-28 04:23:39,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:39,868 INFO:     Epoch: 97
2022-11-28 04:23:40,530 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44145867143842304, 'Total loss': 0.44145867143842304} | train loss {'Reaction outcome loss': 0.45689194293654695, 'Total loss': 0.45689194293654695}
2022-11-28 04:23:40,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:40,530 INFO:     Epoch: 98
2022-11-28 04:23:41,189 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45820410922169685, 'Total loss': 0.45820410922169685} | train loss {'Reaction outcome loss': 0.45932005291082423, 'Total loss': 0.45932005291082423}
2022-11-28 04:23:41,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:41,189 INFO:     Epoch: 99
2022-11-28 04:23:41,849 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46064240316098387, 'Total loss': 0.46064240316098387} | train loss {'Reaction outcome loss': 0.45943677668668786, 'Total loss': 0.45943677668668786}
2022-11-28 04:23:41,849 INFO:     Best model found after epoch 89 of 100.
2022-11-28 04:23:41,849 INFO:   Done with stage: TRAINING
2022-11-28 04:23:41,849 INFO:   Starting stage: EVALUATION
2022-11-28 04:23:41,973 INFO:   Done with stage: EVALUATION
2022-11-28 04:23:41,974 INFO:   Leaving out SEQ value Fold_2
2022-11-28 04:23:41,987 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:23:41,987 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:23:42,631 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:23:42,631 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:23:42,699 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:23:42,699 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:23:42,699 INFO:     No hyperparam tuning for this model
2022-11-28 04:23:42,699 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:23:42,699 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:23:42,700 INFO:     None feature selector for col prot
2022-11-28 04:23:42,700 INFO:     None feature selector for col prot
2022-11-28 04:23:42,700 INFO:     None feature selector for col prot
2022-11-28 04:23:42,700 INFO:     None feature selector for col chem
2022-11-28 04:23:42,700 INFO:     None feature selector for col chem
2022-11-28 04:23:42,700 INFO:     None feature selector for col chem
2022-11-28 04:23:42,700 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:23:42,701 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:23:42,702 INFO:     Number of params in model 169651
2022-11-28 04:23:42,705 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:23:42,705 INFO:   Starting stage: TRAINING
2022-11-28 04:23:42,757 INFO:     Val loss before train {'Reaction outcome loss': 0.9930794049393047, 'Total loss': 0.9930794049393047}
2022-11-28 04:23:42,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:42,757 INFO:     Epoch: 0
2022-11-28 04:23:43,423 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6271850087425925, 'Total loss': 0.6271850087425925} | train loss {'Reaction outcome loss': 0.6976362977191987, 'Total loss': 0.6976362977191987}
2022-11-28 04:23:43,423 INFO:     Found new best model at epoch 0
2022-11-28 04:23:43,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:43,424 INFO:     Epoch: 1
2022-11-28 04:23:44,085 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5459207943217321, 'Total loss': 0.5459207943217321} | train loss {'Reaction outcome loss': 0.5954144784072151, 'Total loss': 0.5954144784072151}
2022-11-28 04:23:44,085 INFO:     Found new best model at epoch 1
2022-11-28 04:23:44,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:44,086 INFO:     Epoch: 2
2022-11-28 04:23:44,747 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.521069335327907, 'Total loss': 0.521069335327907} | train loss {'Reaction outcome loss': 0.5537290288972468, 'Total loss': 0.5537290288972468}
2022-11-28 04:23:44,747 INFO:     Found new best model at epoch 2
2022-11-28 04:23:44,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:44,748 INFO:     Epoch: 3
2022-11-28 04:23:45,411 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5190512118014422, 'Total loss': 0.5190512118014422} | train loss {'Reaction outcome loss': 0.5397832343573512, 'Total loss': 0.5397832343573512}
2022-11-28 04:23:45,411 INFO:     Found new best model at epoch 3
2022-11-28 04:23:45,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:45,412 INFO:     Epoch: 4
2022-11-28 04:23:46,075 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5921180431138385, 'Total loss': 0.5921180431138385} | train loss {'Reaction outcome loss': 0.5323979006062153, 'Total loss': 0.5323979006062153}
2022-11-28 04:23:46,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:46,075 INFO:     Epoch: 5
2022-11-28 04:23:46,734 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4873395077884197, 'Total loss': 0.4873395077884197} | train loss {'Reaction outcome loss': 0.530261458896915, 'Total loss': 0.530261458896915}
2022-11-28 04:23:46,734 INFO:     Found new best model at epoch 5
2022-11-28 04:23:46,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:46,735 INFO:     Epoch: 6
2022-11-28 04:23:47,398 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5352822941812602, 'Total loss': 0.5352822941812602} | train loss {'Reaction outcome loss': 0.5263341710363564, 'Total loss': 0.5263341710363564}
2022-11-28 04:23:47,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:47,398 INFO:     Epoch: 7
2022-11-28 04:23:48,055 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4772450818934224, 'Total loss': 0.4772450818934224} | train loss {'Reaction outcome loss': 0.5089430025955926, 'Total loss': 0.5089430025955926}
2022-11-28 04:23:48,056 INFO:     Found new best model at epoch 7
2022-11-28 04:23:48,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:48,056 INFO:     Epoch: 8
2022-11-28 04:23:48,719 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4964181845161048, 'Total loss': 0.4964181845161048} | train loss {'Reaction outcome loss': 0.5029473956297283, 'Total loss': 0.5029473956297283}
2022-11-28 04:23:48,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:48,719 INFO:     Epoch: 9
2022-11-28 04:23:49,380 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5197182677008889, 'Total loss': 0.5197182677008889} | train loss {'Reaction outcome loss': 0.5148065590303437, 'Total loss': 0.5148065590303437}
2022-11-28 04:23:49,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:49,380 INFO:     Epoch: 10
2022-11-28 04:23:50,040 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48121743954040785, 'Total loss': 0.48121743954040785} | train loss {'Reaction outcome loss': 0.49434634881011147, 'Total loss': 0.49434634881011147}
2022-11-28 04:23:50,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:50,041 INFO:     Epoch: 11
2022-11-28 04:23:50,700 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5441189753738317, 'Total loss': 0.5441189753738317} | train loss {'Reaction outcome loss': 0.5061531968806919, 'Total loss': 0.5061531968806919}
2022-11-28 04:23:50,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:50,700 INFO:     Epoch: 12
2022-11-28 04:23:51,359 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48956257782199164, 'Total loss': 0.48956257782199164} | train loss {'Reaction outcome loss': 0.4915804528567171, 'Total loss': 0.4915804528567171}
2022-11-28 04:23:51,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:51,359 INFO:     Epoch: 13
2022-11-28 04:23:52,021 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5398086499084126, 'Total loss': 0.5398086499084126} | train loss {'Reaction outcome loss': 0.4964486169308303, 'Total loss': 0.4964486169308303}
2022-11-28 04:23:52,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:52,021 INFO:     Epoch: 14
2022-11-28 04:23:52,688 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49259288947690616, 'Total loss': 0.49259288947690616} | train loss {'Reaction outcome loss': 0.5090560814750339, 'Total loss': 0.5090560814750339}
2022-11-28 04:23:52,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:52,688 INFO:     Epoch: 15
2022-11-28 04:23:53,351 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48210847682573577, 'Total loss': 0.48210847682573577} | train loss {'Reaction outcome loss': 0.4831157106876011, 'Total loss': 0.4831157106876011}
2022-11-28 04:23:53,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:53,351 INFO:     Epoch: 16
2022-11-28 04:23:54,008 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4400827217508446, 'Total loss': 0.4400827217508446} | train loss {'Reaction outcome loss': 0.48718310590939, 'Total loss': 0.48718310590939}
2022-11-28 04:23:54,008 INFO:     Found new best model at epoch 16
2022-11-28 04:23:54,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:54,009 INFO:     Epoch: 17
2022-11-28 04:23:54,669 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5007982721382921, 'Total loss': 0.5007982721382921} | train loss {'Reaction outcome loss': 0.49270855521157325, 'Total loss': 0.49270855521157325}
2022-11-28 04:23:54,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:54,670 INFO:     Epoch: 18
2022-11-28 04:23:55,333 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48154143718155945, 'Total loss': 0.48154143718155945} | train loss {'Reaction outcome loss': 0.4856559713842415, 'Total loss': 0.4856559713842415}
2022-11-28 04:23:55,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:55,333 INFO:     Epoch: 19
2022-11-28 04:23:55,991 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5082992721687664, 'Total loss': 0.5082992721687664} | train loss {'Reaction outcome loss': 0.4862444208942444, 'Total loss': 0.4862444208942444}
2022-11-28 04:23:55,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:55,991 INFO:     Epoch: 20
2022-11-28 04:23:56,649 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4724724025211551, 'Total loss': 0.4724724025211551} | train loss {'Reaction outcome loss': 0.5015529110605418, 'Total loss': 0.5015529110605418}
2022-11-28 04:23:56,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:56,650 INFO:     Epoch: 21
2022-11-28 04:23:57,315 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5542588816447691, 'Total loss': 0.5542588816447691} | train loss {'Reaction outcome loss': 0.48667334333846446, 'Total loss': 0.48667334333846446}
2022-11-28 04:23:57,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:57,315 INFO:     Epoch: 22
2022-11-28 04:23:57,981 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45635640214789996, 'Total loss': 0.45635640214789996} | train loss {'Reaction outcome loss': 0.5102929159214622, 'Total loss': 0.5102929159214622}
2022-11-28 04:23:57,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:57,982 INFO:     Epoch: 23
2022-11-28 04:23:58,643 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4665657715363936, 'Total loss': 0.4665657715363936} | train loss {'Reaction outcome loss': 0.48401480907977745, 'Total loss': 0.48401480907977745}
2022-11-28 04:23:58,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:58,643 INFO:     Epoch: 24
2022-11-28 04:23:59,306 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5290347700091925, 'Total loss': 0.5290347700091925} | train loss {'Reaction outcome loss': 0.4748039542422121, 'Total loss': 0.4748039542422121}
2022-11-28 04:23:59,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:59,307 INFO:     Epoch: 25
2022-11-28 04:23:59,965 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4769703227687966, 'Total loss': 0.4769703227687966} | train loss {'Reaction outcome loss': 0.47817373266707547, 'Total loss': 0.47817373266707547}
2022-11-28 04:23:59,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:23:59,965 INFO:     Epoch: 26
2022-11-28 04:24:00,627 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5082276663319631, 'Total loss': 0.5082276663319631} | train loss {'Reaction outcome loss': 0.4809051425109508, 'Total loss': 0.4809051425109508}
2022-11-28 04:24:00,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:00,627 INFO:     Epoch: 27
2022-11-28 04:24:01,288 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4939800202846527, 'Total loss': 0.4939800202846527} | train loss {'Reaction outcome loss': 0.4754972708852668, 'Total loss': 0.4754972708852668}
2022-11-28 04:24:01,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:01,289 INFO:     Epoch: 28
2022-11-28 04:24:01,948 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4771879112178629, 'Total loss': 0.4771879112178629} | train loss {'Reaction outcome loss': 0.48136336642962235, 'Total loss': 0.48136336642962235}
2022-11-28 04:24:01,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:01,949 INFO:     Epoch: 29
2022-11-28 04:24:02,608 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4563968422060663, 'Total loss': 0.4563968422060663} | train loss {'Reaction outcome loss': 0.48106170895128597, 'Total loss': 0.48106170895128597}
2022-11-28 04:24:02,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:02,609 INFO:     Epoch: 30
2022-11-28 04:24:03,270 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5230374353175814, 'Total loss': 0.5230374353175814} | train loss {'Reaction outcome loss': 0.4769210620304411, 'Total loss': 0.4769210620304411}
2022-11-28 04:24:03,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:03,270 INFO:     Epoch: 31
2022-11-28 04:24:03,933 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.487648989666592, 'Total loss': 0.487648989666592} | train loss {'Reaction outcome loss': 0.4800539415495598, 'Total loss': 0.4800539415495598}
2022-11-28 04:24:03,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:03,934 INFO:     Epoch: 32
2022-11-28 04:24:04,596 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.484749971465631, 'Total loss': 0.484749971465631} | train loss {'Reaction outcome loss': 0.47255338948627235, 'Total loss': 0.47255338948627235}
2022-11-28 04:24:04,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:04,597 INFO:     Epoch: 33
2022-11-28 04:24:05,262 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5132342387329448, 'Total loss': 0.5132342387329448} | train loss {'Reaction outcome loss': 0.48395497566051326, 'Total loss': 0.48395497566051326}
2022-11-28 04:24:05,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:05,262 INFO:     Epoch: 34
2022-11-28 04:24:05,922 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4634621332992207, 'Total loss': 0.4634621332992207} | train loss {'Reaction outcome loss': 0.48701949260736765, 'Total loss': 0.48701949260736765}
2022-11-28 04:24:05,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:05,922 INFO:     Epoch: 35
2022-11-28 04:24:06,582 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45726020668040623, 'Total loss': 0.45726020668040623} | train loss {'Reaction outcome loss': 0.4763722206778854, 'Total loss': 0.4763722206778854}
2022-11-28 04:24:06,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:06,583 INFO:     Epoch: 36
2022-11-28 04:24:07,242 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4972547919235446, 'Total loss': 0.4972547919235446} | train loss {'Reaction outcome loss': 0.47956959499038665, 'Total loss': 0.47956959499038665}
2022-11-28 04:24:07,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:07,242 INFO:     Epoch: 37
2022-11-28 04:24:07,903 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45702920481562614, 'Total loss': 0.45702920481562614} | train loss {'Reaction outcome loss': 0.4773142126045729, 'Total loss': 0.4773142126045729}
2022-11-28 04:24:07,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:07,904 INFO:     Epoch: 38
2022-11-28 04:24:08,564 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4796910452741114, 'Total loss': 0.4796910452741114} | train loss {'Reaction outcome loss': 0.4740513159708697, 'Total loss': 0.4740513159708697}
2022-11-28 04:24:08,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:08,564 INFO:     Epoch: 39
2022-11-28 04:24:09,225 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4953218193894083, 'Total loss': 0.4953218193894083} | train loss {'Reaction outcome loss': 0.4731096809028614, 'Total loss': 0.4731096809028614}
2022-11-28 04:24:09,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:09,226 INFO:     Epoch: 40
2022-11-28 04:24:09,889 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5106222358616915, 'Total loss': 0.5106222358616915} | train loss {'Reaction outcome loss': 0.48155633477788223, 'Total loss': 0.48155633477788223}
2022-11-28 04:24:09,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:09,890 INFO:     Epoch: 41
2022-11-28 04:24:10,557 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4733015911822969, 'Total loss': 0.4733015911822969} | train loss {'Reaction outcome loss': 0.48480172063175003, 'Total loss': 0.48480172063175003}
2022-11-28 04:24:10,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:10,558 INFO:     Epoch: 42
2022-11-28 04:24:11,221 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4819819036532532, 'Total loss': 0.4819819036532532} | train loss {'Reaction outcome loss': 0.47901749279093647, 'Total loss': 0.47901749279093647}
2022-11-28 04:24:11,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:11,221 INFO:     Epoch: 43
2022-11-28 04:24:11,883 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46590921553698456, 'Total loss': 0.46590921553698456} | train loss {'Reaction outcome loss': 0.4800843131928309, 'Total loss': 0.4800843131928309}
2022-11-28 04:24:11,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:11,883 INFO:     Epoch: 44
2022-11-28 04:24:12,546 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45783302221785893, 'Total loss': 0.45783302221785893} | train loss {'Reaction outcome loss': 0.4744431095325995, 'Total loss': 0.4744431095325995}
2022-11-28 04:24:12,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:12,546 INFO:     Epoch: 45
2022-11-28 04:24:13,211 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4779548269103874, 'Total loss': 0.4779548269103874} | train loss {'Reaction outcome loss': 0.47734517251190384, 'Total loss': 0.47734517251190384}
2022-11-28 04:24:13,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:13,211 INFO:     Epoch: 46
2022-11-28 04:24:13,875 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46687834506685083, 'Total loss': 0.46687834506685083} | train loss {'Reaction outcome loss': 0.47140388637177855, 'Total loss': 0.47140388637177855}
2022-11-28 04:24:13,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:13,876 INFO:     Epoch: 47
2022-11-28 04:24:14,542 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4810273830186237, 'Total loss': 0.4810273830186237} | train loss {'Reaction outcome loss': 0.47401003105196393, 'Total loss': 0.47401003105196393}
2022-11-28 04:24:14,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:14,543 INFO:     Epoch: 48
2022-11-28 04:24:15,211 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4706472883170301, 'Total loss': 0.4706472883170301} | train loss {'Reaction outcome loss': 0.47712714517647437, 'Total loss': 0.47712714517647437}
2022-11-28 04:24:15,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:15,211 INFO:     Epoch: 49
2022-11-28 04:24:15,872 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49773662706667726, 'Total loss': 0.49773662706667726} | train loss {'Reaction outcome loss': 0.46764120453735813, 'Total loss': 0.46764120453735813}
2022-11-28 04:24:15,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:15,873 INFO:     Epoch: 50
2022-11-28 04:24:16,536 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46798457781022246, 'Total loss': 0.46798457781022246} | train loss {'Reaction outcome loss': 0.472892745531839, 'Total loss': 0.472892745531839}
2022-11-28 04:24:16,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:16,536 INFO:     Epoch: 51
2022-11-28 04:24:17,199 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4517560757019303, 'Total loss': 0.4517560757019303} | train loss {'Reaction outcome loss': 0.47555955363671304, 'Total loss': 0.47555955363671304}
2022-11-28 04:24:17,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:17,199 INFO:     Epoch: 52
2022-11-28 04:24:17,866 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46046514876864175, 'Total loss': 0.46046514876864175} | train loss {'Reaction outcome loss': 0.4869221474236322, 'Total loss': 0.4869221474236322}
2022-11-28 04:24:17,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:17,867 INFO:     Epoch: 53
2022-11-28 04:24:18,533 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48716103014620865, 'Total loss': 0.48716103014620865} | train loss {'Reaction outcome loss': 0.4810112962114666, 'Total loss': 0.4810112962114666}
2022-11-28 04:24:18,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:18,533 INFO:     Epoch: 54
2022-11-28 04:24:19,195 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48152676631103863, 'Total loss': 0.48152676631103863} | train loss {'Reaction outcome loss': 0.48290411904755876, 'Total loss': 0.48290411904755876}
2022-11-28 04:24:19,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:19,195 INFO:     Epoch: 55
2022-11-28 04:24:19,859 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47915457968007436, 'Total loss': 0.47915457968007436} | train loss {'Reaction outcome loss': 0.47345453991105985, 'Total loss': 0.47345453991105985}
2022-11-28 04:24:19,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:19,859 INFO:     Epoch: 56
2022-11-28 04:24:20,523 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48231698843565857, 'Total loss': 0.48231698843565857} | train loss {'Reaction outcome loss': 0.4716222027414723, 'Total loss': 0.4716222027414723}
2022-11-28 04:24:20,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:20,523 INFO:     Epoch: 57
2022-11-28 04:24:21,188 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4834939173676751, 'Total loss': 0.4834939173676751} | train loss {'Reaction outcome loss': 0.47757051366302167, 'Total loss': 0.47757051366302167}
2022-11-28 04:24:21,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:21,188 INFO:     Epoch: 58
2022-11-28 04:24:21,850 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5285270610316233, 'Total loss': 0.5285270610316233} | train loss {'Reaction outcome loss': 0.4829946083699161, 'Total loss': 0.4829946083699161}
2022-11-28 04:24:21,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:21,851 INFO:     Epoch: 59
2022-11-28 04:24:22,513 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48597846857526084, 'Total loss': 0.48597846857526084} | train loss {'Reaction outcome loss': 0.4792397951976837, 'Total loss': 0.4792397951976837}
2022-11-28 04:24:22,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:22,513 INFO:     Epoch: 60
2022-11-28 04:24:23,175 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47496776011857117, 'Total loss': 0.47496776011857117} | train loss {'Reaction outcome loss': 0.48401775232210814, 'Total loss': 0.48401775232210814}
2022-11-28 04:24:23,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:23,175 INFO:     Epoch: 61
2022-11-28 04:24:23,837 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47978374192660506, 'Total loss': 0.47978374192660506} | train loss {'Reaction outcome loss': 0.47780516378672017, 'Total loss': 0.47780516378672017}
2022-11-28 04:24:23,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:23,837 INFO:     Epoch: 62
2022-11-28 04:24:24,499 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48582529107278044, 'Total loss': 0.48582529107278044} | train loss {'Reaction outcome loss': 0.47804137798938673, 'Total loss': 0.47804137798938673}
2022-11-28 04:24:24,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:24,500 INFO:     Epoch: 63
2022-11-28 04:24:25,171 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47187198156660254, 'Total loss': 0.47187198156660254} | train loss {'Reaction outcome loss': 0.4758957002294506, 'Total loss': 0.4758957002294506}
2022-11-28 04:24:25,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:25,171 INFO:     Epoch: 64
2022-11-28 04:24:25,838 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4977966977114027, 'Total loss': 0.4977966977114027} | train loss {'Reaction outcome loss': 0.4784073282470587, 'Total loss': 0.4784073282470587}
2022-11-28 04:24:25,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:25,839 INFO:     Epoch: 65
2022-11-28 04:24:26,501 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4814924733205275, 'Total loss': 0.4814924733205275} | train loss {'Reaction outcome loss': 0.49000973559101585, 'Total loss': 0.49000973559101585}
2022-11-28 04:24:26,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:26,501 INFO:     Epoch: 66
2022-11-28 04:24:27,161 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5081673701378432, 'Total loss': 0.5081673701378432} | train loss {'Reaction outcome loss': 0.48891722890529554, 'Total loss': 0.48891722890529554}
2022-11-28 04:24:27,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:27,161 INFO:     Epoch: 67
2022-11-28 04:24:27,823 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46989781815897336, 'Total loss': 0.46989781815897336} | train loss {'Reaction outcome loss': 0.47522627999478206, 'Total loss': 0.47522627999478206}
2022-11-28 04:24:27,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:27,823 INFO:     Epoch: 68
2022-11-28 04:24:28,482 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47121563282879914, 'Total loss': 0.47121563282879914} | train loss {'Reaction outcome loss': 0.4723785855026863, 'Total loss': 0.4723785855026863}
2022-11-28 04:24:28,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:28,482 INFO:     Epoch: 69
2022-11-28 04:24:29,143 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4536974694241177, 'Total loss': 0.4536974694241177} | train loss {'Reaction outcome loss': 0.4740934545996218, 'Total loss': 0.4740934545996218}
2022-11-28 04:24:29,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:29,143 INFO:     Epoch: 70
2022-11-28 04:24:29,802 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5284187299284068, 'Total loss': 0.5284187299284068} | train loss {'Reaction outcome loss': 0.4811571529399046, 'Total loss': 0.4811571529399046}
2022-11-28 04:24:29,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:29,803 INFO:     Epoch: 71
2022-11-28 04:24:30,467 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4818120537833734, 'Total loss': 0.4818120537833734} | train loss {'Reaction outcome loss': 0.48490900810249904, 'Total loss': 0.48490900810249904}
2022-11-28 04:24:30,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:30,468 INFO:     Epoch: 72
2022-11-28 04:24:31,126 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49529259177771484, 'Total loss': 0.49529259177771484} | train loss {'Reaction outcome loss': 0.4720990779066858, 'Total loss': 0.4720990779066858}
2022-11-28 04:24:31,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:31,126 INFO:     Epoch: 73
2022-11-28 04:24:31,785 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5150537971745838, 'Total loss': 0.5150537971745838} | train loss {'Reaction outcome loss': 0.4840916646757589, 'Total loss': 0.4840916646757589}
2022-11-28 04:24:31,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:31,785 INFO:     Epoch: 74
2022-11-28 04:24:32,446 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4852014404128898, 'Total loss': 0.4852014404128898} | train loss {'Reaction outcome loss': 0.48351900925037833, 'Total loss': 0.48351900925037833}
2022-11-28 04:24:32,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:32,447 INFO:     Epoch: 75
2022-11-28 04:24:33,101 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4563053412870927, 'Total loss': 0.4563053412870927} | train loss {'Reaction outcome loss': 0.46496215474750346, 'Total loss': 0.46496215474750346}
2022-11-28 04:24:33,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:33,101 INFO:     Epoch: 76
2022-11-28 04:24:33,763 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4644299691373652, 'Total loss': 0.4644299691373652} | train loss {'Reaction outcome loss': 0.47447427974538764, 'Total loss': 0.47447427974538764}
2022-11-28 04:24:33,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:33,763 INFO:     Epoch: 77
2022-11-28 04:24:34,422 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.490163019773635, 'Total loss': 0.490163019773635} | train loss {'Reaction outcome loss': 0.48488458870393547, 'Total loss': 0.48488458870393547}
2022-11-28 04:24:34,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:34,423 INFO:     Epoch: 78
2022-11-28 04:24:35,085 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45095106756145303, 'Total loss': 0.45095106756145303} | train loss {'Reaction outcome loss': 0.4719588751734992, 'Total loss': 0.4719588751734992}
2022-11-28 04:24:35,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:35,085 INFO:     Epoch: 79
2022-11-28 04:24:35,744 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44762973792173644, 'Total loss': 0.44762973792173644} | train loss {'Reaction outcome loss': 0.4751675615185185, 'Total loss': 0.4751675615185185}
2022-11-28 04:24:35,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:35,744 INFO:     Epoch: 80
2022-11-28 04:24:36,402 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5082279480993748, 'Total loss': 0.5082279480993748} | train loss {'Reaction outcome loss': 0.4785178063610787, 'Total loss': 0.4785178063610787}
2022-11-28 04:24:36,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:36,403 INFO:     Epoch: 81
2022-11-28 04:24:37,061 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46368528699333017, 'Total loss': 0.46368528699333017} | train loss {'Reaction outcome loss': 0.4781833878050932, 'Total loss': 0.4781833878050932}
2022-11-28 04:24:37,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:37,062 INFO:     Epoch: 82
2022-11-28 04:24:37,723 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4501724351536144, 'Total loss': 0.4501724351536144} | train loss {'Reaction outcome loss': 0.47440681663843304, 'Total loss': 0.47440681663843304}
2022-11-28 04:24:37,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:37,723 INFO:     Epoch: 83
2022-11-28 04:24:38,382 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4675428295000033, 'Total loss': 0.4675428295000033} | train loss {'Reaction outcome loss': 0.47961624942508785, 'Total loss': 0.47961624942508785}
2022-11-28 04:24:38,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:38,382 INFO:     Epoch: 84
2022-11-28 04:24:39,041 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4867779002948241, 'Total loss': 0.4867779002948241} | train loss {'Reaction outcome loss': 0.47178158646653057, 'Total loss': 0.47178158646653057}
2022-11-28 04:24:39,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:39,041 INFO:     Epoch: 85
2022-11-28 04:24:39,701 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49903480166738684, 'Total loss': 0.49903480166738684} | train loss {'Reaction outcome loss': 0.48810582010731524, 'Total loss': 0.48810582010731524}
2022-11-28 04:24:39,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:39,701 INFO:     Epoch: 86
2022-11-28 04:24:40,364 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5368006503717466, 'Total loss': 0.5368006503717466} | train loss {'Reaction outcome loss': 0.4791813784162043, 'Total loss': 0.4791813784162043}
2022-11-28 04:24:40,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:40,365 INFO:     Epoch: 87
2022-11-28 04:24:41,024 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4897424111312086, 'Total loss': 0.4897424111312086} | train loss {'Reaction outcome loss': 0.47187975018854567, 'Total loss': 0.47187975018854567}
2022-11-28 04:24:41,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:41,025 INFO:     Epoch: 88
2022-11-28 04:24:41,686 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46127023751085455, 'Total loss': 0.46127023751085455} | train loss {'Reaction outcome loss': 0.47553028419674165, 'Total loss': 0.47553028419674165}
2022-11-28 04:24:41,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:41,687 INFO:     Epoch: 89
2022-11-28 04:24:42,349 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4633166739209132, 'Total loss': 0.4633166739209132} | train loss {'Reaction outcome loss': 0.47539501712631116, 'Total loss': 0.47539501712631116}
2022-11-28 04:24:42,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:42,350 INFO:     Epoch: 90
2022-11-28 04:24:43,008 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47946702113205736, 'Total loss': 0.47946702113205736} | train loss {'Reaction outcome loss': 0.48741144527066577, 'Total loss': 0.48741144527066577}
2022-11-28 04:24:43,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:43,009 INFO:     Epoch: 91
2022-11-28 04:24:43,667 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4771204326640476, 'Total loss': 0.4771204326640476} | train loss {'Reaction outcome loss': 0.4934332228382589, 'Total loss': 0.4934332228382589}
2022-11-28 04:24:43,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:43,667 INFO:     Epoch: 92
2022-11-28 04:24:44,327 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5083367909220132, 'Total loss': 0.5083367909220132} | train loss {'Reaction outcome loss': 0.47949725933569043, 'Total loss': 0.47949725933569043}
2022-11-28 04:24:44,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:44,327 INFO:     Epoch: 93
2022-11-28 04:24:44,989 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4541155377572233, 'Total loss': 0.4541155377572233} | train loss {'Reaction outcome loss': 0.4721690386171766, 'Total loss': 0.4721690386171766}
2022-11-28 04:24:44,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:44,990 INFO:     Epoch: 94
2022-11-28 04:24:45,653 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4584923315454613, 'Total loss': 0.4584923315454613} | train loss {'Reaction outcome loss': 0.47920643408530156, 'Total loss': 0.47920643408530156}
2022-11-28 04:24:45,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:45,653 INFO:     Epoch: 95
2022-11-28 04:24:46,322 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47768905995921657, 'Total loss': 0.47768905995921657} | train loss {'Reaction outcome loss': 0.476086936076643, 'Total loss': 0.476086936076643}
2022-11-28 04:24:46,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:46,322 INFO:     Epoch: 96
2022-11-28 04:24:46,982 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4572893123735081, 'Total loss': 0.4572893123735081} | train loss {'Reaction outcome loss': 0.4718283391915835, 'Total loss': 0.4718283391915835}
2022-11-28 04:24:46,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:46,982 INFO:     Epoch: 97
2022-11-28 04:24:47,643 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49585282328453933, 'Total loss': 0.49585282328453933} | train loss {'Reaction outcome loss': 0.4715684801340103, 'Total loss': 0.4715684801340103}
2022-11-28 04:24:47,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:47,644 INFO:     Epoch: 98
2022-11-28 04:24:48,305 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4582927900959145, 'Total loss': 0.4582927900959145} | train loss {'Reaction outcome loss': 0.47364301858884605, 'Total loss': 0.47364301858884605}
2022-11-28 04:24:48,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:48,305 INFO:     Epoch: 99
2022-11-28 04:24:48,965 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5024380931122736, 'Total loss': 0.5024380931122736} | train loss {'Reaction outcome loss': 0.4834130391900839, 'Total loss': 0.4834130391900839}
2022-11-28 04:24:48,965 INFO:     Best model found after epoch 17 of 100.
2022-11-28 04:24:48,965 INFO:   Done with stage: TRAINING
2022-11-28 04:24:48,966 INFO:   Starting stage: EVALUATION
2022-11-28 04:24:49,085 INFO:   Done with stage: EVALUATION
2022-11-28 04:24:49,085 INFO:   Leaving out SEQ value Fold_3
2022-11-28 04:24:49,098 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:24:49,098 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:24:49,741 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:24:49,741 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:24:49,808 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:24:49,808 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:24:49,808 INFO:     No hyperparam tuning for this model
2022-11-28 04:24:49,808 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:24:49,808 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:24:49,809 INFO:     None feature selector for col prot
2022-11-28 04:24:49,809 INFO:     None feature selector for col prot
2022-11-28 04:24:49,809 INFO:     None feature selector for col prot
2022-11-28 04:24:49,810 INFO:     None feature selector for col chem
2022-11-28 04:24:49,810 INFO:     None feature selector for col chem
2022-11-28 04:24:49,810 INFO:     None feature selector for col chem
2022-11-28 04:24:49,810 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:24:49,810 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:24:49,811 INFO:     Number of params in model 169651
2022-11-28 04:24:49,814 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:24:49,814 INFO:   Starting stage: TRAINING
2022-11-28 04:24:49,865 INFO:     Val loss before train {'Reaction outcome loss': 0.9833861155943437, 'Total loss': 0.9833861155943437}
2022-11-28 04:24:49,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:49,866 INFO:     Epoch: 0
2022-11-28 04:24:50,522 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5675294690511443, 'Total loss': 0.5675294690511443} | train loss {'Reaction outcome loss': 0.6816015408963573, 'Total loss': 0.6816015408963573}
2022-11-28 04:24:50,522 INFO:     Found new best model at epoch 0
2022-11-28 04:24:50,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:50,523 INFO:     Epoch: 1
2022-11-28 04:24:51,183 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5447679446502165, 'Total loss': 0.5447679446502165} | train loss {'Reaction outcome loss': 0.5827505084933067, 'Total loss': 0.5827505084933067}
2022-11-28 04:24:51,183 INFO:     Found new best model at epoch 1
2022-11-28 04:24:51,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:51,183 INFO:     Epoch: 2
2022-11-28 04:24:51,839 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5382258885286071, 'Total loss': 0.5382258885286071} | train loss {'Reaction outcome loss': 0.5565645481250724, 'Total loss': 0.5565645481250724}
2022-11-28 04:24:51,840 INFO:     Found new best model at epoch 2
2022-11-28 04:24:51,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:51,840 INFO:     Epoch: 3
2022-11-28 04:24:52,495 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6010169732299718, 'Total loss': 0.6010169732299718} | train loss {'Reaction outcome loss': 0.5313264949589359, 'Total loss': 0.5313264949589359}
2022-11-28 04:24:52,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:52,495 INFO:     Epoch: 4
2022-11-28 04:24:53,148 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5068914287469604, 'Total loss': 0.5068914287469604} | train loss {'Reaction outcome loss': 0.5244378447532654, 'Total loss': 0.5244378447532654}
2022-11-28 04:24:53,149 INFO:     Found new best model at epoch 4
2022-11-28 04:24:53,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:53,149 INFO:     Epoch: 5
2022-11-28 04:24:53,808 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5318145877258345, 'Total loss': 0.5318145877258345} | train loss {'Reaction outcome loss': 0.5096201807260513, 'Total loss': 0.5096201807260513}
2022-11-28 04:24:53,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:53,808 INFO:     Epoch: 6
2022-11-28 04:24:54,468 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5136045380072161, 'Total loss': 0.5136045380072161} | train loss {'Reaction outcome loss': 0.4946413671483799, 'Total loss': 0.4946413671483799}
2022-11-28 04:24:54,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:54,468 INFO:     Epoch: 7
2022-11-28 04:24:55,129 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5068880306048826, 'Total loss': 0.5068880306048826} | train loss {'Reaction outcome loss': 0.4998054472159366, 'Total loss': 0.4998054472159366}
2022-11-28 04:24:55,129 INFO:     Found new best model at epoch 7
2022-11-28 04:24:55,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:55,130 INFO:     Epoch: 8
2022-11-28 04:24:55,785 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48958164758302947, 'Total loss': 0.48958164758302947} | train loss {'Reaction outcome loss': 0.4858343766051896, 'Total loss': 0.4858343766051896}
2022-11-28 04:24:55,785 INFO:     Found new best model at epoch 8
2022-11-28 04:24:55,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:55,786 INFO:     Epoch: 9
2022-11-28 04:24:56,443 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5339467681267045, 'Total loss': 0.5339467681267045} | train loss {'Reaction outcome loss': 0.48457766223926935, 'Total loss': 0.48457766223926935}
2022-11-28 04:24:56,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:56,443 INFO:     Epoch: 10
2022-11-28 04:24:57,100 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4736520725895058, 'Total loss': 0.4736520725895058} | train loss {'Reaction outcome loss': 0.47917047927574236, 'Total loss': 0.47917047927574236}
2022-11-28 04:24:57,101 INFO:     Found new best model at epoch 10
2022-11-28 04:24:57,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:57,102 INFO:     Epoch: 11
2022-11-28 04:24:57,757 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5021276490932162, 'Total loss': 0.5021276490932162} | train loss {'Reaction outcome loss': 0.4743152453583114, 'Total loss': 0.4743152453583114}
2022-11-28 04:24:57,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:57,757 INFO:     Epoch: 12
2022-11-28 04:24:58,411 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4910543046214364, 'Total loss': 0.4910543046214364} | train loss {'Reaction outcome loss': 0.4710005598408835, 'Total loss': 0.4710005598408835}
2022-11-28 04:24:58,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:58,412 INFO:     Epoch: 13
2022-11-28 04:24:59,067 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4545849092643369, 'Total loss': 0.4545849092643369} | train loss {'Reaction outcome loss': 0.4654900889007413, 'Total loss': 0.4654900889007413}
2022-11-28 04:24:59,067 INFO:     Found new best model at epoch 13
2022-11-28 04:24:59,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:59,068 INFO:     Epoch: 14
2022-11-28 04:24:59,725 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4616570281372829, 'Total loss': 0.4616570281372829} | train loss {'Reaction outcome loss': 0.46330882389934697, 'Total loss': 0.46330882389934697}
2022-11-28 04:24:59,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:24:59,725 INFO:     Epoch: 15
2022-11-28 04:25:00,382 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45918485115874896, 'Total loss': 0.45918485115874896} | train loss {'Reaction outcome loss': 0.45802438091866826, 'Total loss': 0.45802438091866826}
2022-11-28 04:25:00,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:00,382 INFO:     Epoch: 16
2022-11-28 04:25:01,039 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4560216401110996, 'Total loss': 0.4560216401110996} | train loss {'Reaction outcome loss': 0.462947284749576, 'Total loss': 0.462947284749576}
2022-11-28 04:25:01,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:01,039 INFO:     Epoch: 17
2022-11-28 04:25:01,697 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4722439650107514, 'Total loss': 0.4722439650107514} | train loss {'Reaction outcome loss': 0.4705092473297703, 'Total loss': 0.4705092473297703}
2022-11-28 04:25:01,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:01,697 INFO:     Epoch: 18
2022-11-28 04:25:02,351 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5163975781337782, 'Total loss': 0.5163975781337782} | train loss {'Reaction outcome loss': 0.4672388269280901, 'Total loss': 0.4672388269280901}
2022-11-28 04:25:02,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:02,352 INFO:     Epoch: 19
2022-11-28 04:25:03,009 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46713528443466534, 'Total loss': 0.46713528443466534} | train loss {'Reaction outcome loss': 0.4618688141204873, 'Total loss': 0.4618688141204873}
2022-11-28 04:25:03,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:03,009 INFO:     Epoch: 20
2022-11-28 04:25:03,665 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4659908054904504, 'Total loss': 0.4659908054904504} | train loss {'Reaction outcome loss': 0.45868681352965684, 'Total loss': 0.45868681352965684}
2022-11-28 04:25:03,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:03,666 INFO:     Epoch: 21
2022-11-28 04:25:04,322 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4731990606947379, 'Total loss': 0.4731990606947379} | train loss {'Reaction outcome loss': 0.4700646629138869, 'Total loss': 0.4700646629138869}
2022-11-28 04:25:04,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:04,322 INFO:     Epoch: 22
2022-11-28 04:25:04,978 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47070023011077533, 'Total loss': 0.47070023011077533} | train loss {'Reaction outcome loss': 0.46640527449092084, 'Total loss': 0.46640527449092084}
2022-11-28 04:25:04,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:04,978 INFO:     Epoch: 23
2022-11-28 04:25:05,635 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.469315436414697, 'Total loss': 0.469315436414697} | train loss {'Reaction outcome loss': 0.4600008880605503, 'Total loss': 0.4600008880605503}
2022-11-28 04:25:05,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:05,635 INFO:     Epoch: 24
2022-11-28 04:25:06,291 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5052529898556796, 'Total loss': 0.5052529898556796} | train loss {'Reaction outcome loss': 0.4608124362570899, 'Total loss': 0.4608124362570899}
2022-11-28 04:25:06,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:06,292 INFO:     Epoch: 25
2022-11-28 04:25:06,949 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46763380853967235, 'Total loss': 0.46763380853967235} | train loss {'Reaction outcome loss': 0.45756387552436517, 'Total loss': 0.45756387552436517}
2022-11-28 04:25:06,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:06,949 INFO:     Epoch: 26
2022-11-28 04:25:07,602 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4838189457289197, 'Total loss': 0.4838189457289197} | train loss {'Reaction outcome loss': 0.4635067380204493, 'Total loss': 0.4635067380204493}
2022-11-28 04:25:07,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:07,602 INFO:     Epoch: 27
2022-11-28 04:25:08,257 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4659269353882833, 'Total loss': 0.4659269353882833} | train loss {'Reaction outcome loss': 0.45968139834549965, 'Total loss': 0.45968139834549965}
2022-11-28 04:25:08,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:08,257 INFO:     Epoch: 28
2022-11-28 04:25:08,911 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.471832083707506, 'Total loss': 0.471832083707506} | train loss {'Reaction outcome loss': 0.45783560805174767, 'Total loss': 0.45783560805174767}
2022-11-28 04:25:08,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:08,912 INFO:     Epoch: 29
2022-11-28 04:25:09,570 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5295251523229209, 'Total loss': 0.5295251523229209} | train loss {'Reaction outcome loss': 0.4659643490703739, 'Total loss': 0.4659643490703739}
2022-11-28 04:25:09,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:09,570 INFO:     Epoch: 30
2022-11-28 04:25:10,227 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45885309543121944, 'Total loss': 0.45885309543121944} | train loss {'Reaction outcome loss': 0.45797499029003846, 'Total loss': 0.45797499029003846}
2022-11-28 04:25:10,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:10,228 INFO:     Epoch: 31
2022-11-28 04:25:10,886 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4787917103279721, 'Total loss': 0.4787917103279721} | train loss {'Reaction outcome loss': 0.45227023764532437, 'Total loss': 0.45227023764532437}
2022-11-28 04:25:10,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:10,887 INFO:     Epoch: 32
2022-11-28 04:25:11,549 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4574620601805774, 'Total loss': 0.4574620601805774} | train loss {'Reaction outcome loss': 0.4561815401729272, 'Total loss': 0.4561815401729272}
2022-11-28 04:25:11,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:11,549 INFO:     Epoch: 33
2022-11-28 04:25:12,207 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4762035438113592, 'Total loss': 0.4762035438113592} | train loss {'Reaction outcome loss': 0.4541297812851108, 'Total loss': 0.4541297812851108}
2022-11-28 04:25:12,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:12,207 INFO:     Epoch: 34
2022-11-28 04:25:12,864 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5144887871362946, 'Total loss': 0.5144887871362946} | train loss {'Reaction outcome loss': 0.46021930219567553, 'Total loss': 0.46021930219567553}
2022-11-28 04:25:12,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:12,864 INFO:     Epoch: 35
2022-11-28 04:25:13,520 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4670714156871492, 'Total loss': 0.4670714156871492} | train loss {'Reaction outcome loss': 0.4493527064822158, 'Total loss': 0.4493527064822158}
2022-11-28 04:25:13,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:13,520 INFO:     Epoch: 36
2022-11-28 04:25:14,177 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45224580439654266, 'Total loss': 0.45224580439654266} | train loss {'Reaction outcome loss': 0.4592825025015948, 'Total loss': 0.4592825025015948}
2022-11-28 04:25:14,177 INFO:     Found new best model at epoch 36
2022-11-28 04:25:14,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:14,178 INFO:     Epoch: 37
2022-11-28 04:25:14,839 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4593715342608365, 'Total loss': 0.4593715342608365} | train loss {'Reaction outcome loss': 0.45607217008970224, 'Total loss': 0.45607217008970224}
2022-11-28 04:25:14,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:14,839 INFO:     Epoch: 38
2022-11-28 04:25:15,495 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47354875606569374, 'Total loss': 0.47354875606569374} | train loss {'Reaction outcome loss': 0.4548460178229274, 'Total loss': 0.4548460178229274}
2022-11-28 04:25:15,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:15,496 INFO:     Epoch: 39
2022-11-28 04:25:16,152 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46537470106374135, 'Total loss': 0.46537470106374135} | train loss {'Reaction outcome loss': 0.4566791018052977, 'Total loss': 0.4566791018052977}
2022-11-28 04:25:16,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:16,153 INFO:     Epoch: 40
2022-11-28 04:25:16,810 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.467233172533187, 'Total loss': 0.467233172533187} | train loss {'Reaction outcome loss': 0.4633151738619318, 'Total loss': 0.4633151738619318}
2022-11-28 04:25:16,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:16,810 INFO:     Epoch: 41
2022-11-28 04:25:17,468 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4549626345661553, 'Total loss': 0.4549626345661553} | train loss {'Reaction outcome loss': 0.4554167244507342, 'Total loss': 0.4554167244507342}
2022-11-28 04:25:17,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:17,468 INFO:     Epoch: 42
2022-11-28 04:25:18,127 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45242703943090007, 'Total loss': 0.45242703943090007} | train loss {'Reaction outcome loss': 0.45990303128349536, 'Total loss': 0.45990303128349536}
2022-11-28 04:25:18,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:18,127 INFO:     Epoch: 43
2022-11-28 04:25:18,782 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4837147295475006, 'Total loss': 0.4837147295475006} | train loss {'Reaction outcome loss': 0.4583409895094074, 'Total loss': 0.4583409895094074}
2022-11-28 04:25:18,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:18,782 INFO:     Epoch: 44
2022-11-28 04:25:19,435 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4635084569454193, 'Total loss': 0.4635084569454193} | train loss {'Reaction outcome loss': 0.457798225356608, 'Total loss': 0.457798225356608}
2022-11-28 04:25:19,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:19,435 INFO:     Epoch: 45
2022-11-28 04:25:20,092 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4783012074503032, 'Total loss': 0.4783012074503032} | train loss {'Reaction outcome loss': 0.4509071974730005, 'Total loss': 0.4509071974730005}
2022-11-28 04:25:20,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:20,092 INFO:     Epoch: 46
2022-11-28 04:25:20,745 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46979576112194493, 'Total loss': 0.46979576112194493} | train loss {'Reaction outcome loss': 0.4530823134037913, 'Total loss': 0.4530823134037913}
2022-11-28 04:25:20,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:20,745 INFO:     Epoch: 47
2022-11-28 04:25:21,401 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46775242923335597, 'Total loss': 0.46775242923335597} | train loss {'Reaction outcome loss': 0.4552026065028444, 'Total loss': 0.4552026065028444}
2022-11-28 04:25:21,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:21,401 INFO:     Epoch: 48
2022-11-28 04:25:22,057 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4925655214623971, 'Total loss': 0.4925655214623971} | train loss {'Reaction outcome loss': 0.4540843177206662, 'Total loss': 0.4540843177206662}
2022-11-28 04:25:22,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:22,058 INFO:     Epoch: 49
2022-11-28 04:25:22,715 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4773924553936178, 'Total loss': 0.4773924553936178} | train loss {'Reaction outcome loss': 0.4586245165187485, 'Total loss': 0.4586245165187485}
2022-11-28 04:25:22,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:22,716 INFO:     Epoch: 50
2022-11-28 04:25:23,372 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.478569278662855, 'Total loss': 0.478569278662855} | train loss {'Reaction outcome loss': 0.45371744441134587, 'Total loss': 0.45371744441134587}
2022-11-28 04:25:23,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:23,372 INFO:     Epoch: 51
2022-11-28 04:25:24,028 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4954052303325046, 'Total loss': 0.4954052303325046} | train loss {'Reaction outcome loss': 0.45231674179738884, 'Total loss': 0.45231674179738884}
2022-11-28 04:25:24,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:24,028 INFO:     Epoch: 52
2022-11-28 04:25:24,679 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49961389668963174, 'Total loss': 0.49961389668963174} | train loss {'Reaction outcome loss': 0.4606312453746796, 'Total loss': 0.4606312453746796}
2022-11-28 04:25:24,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:24,679 INFO:     Epoch: 53
2022-11-28 04:25:25,337 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4394030323760076, 'Total loss': 0.4394030323760076} | train loss {'Reaction outcome loss': 0.45979738928833785, 'Total loss': 0.45979738928833785}
2022-11-28 04:25:25,337 INFO:     Found new best model at epoch 53
2022-11-28 04:25:25,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:25,338 INFO:     Epoch: 54
2022-11-28 04:25:25,996 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49840983816168527, 'Total loss': 0.49840983816168527} | train loss {'Reaction outcome loss': 0.4569531248236189, 'Total loss': 0.4569531248236189}
2022-11-28 04:25:25,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:25,997 INFO:     Epoch: 55
2022-11-28 04:25:26,656 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4390130662782626, 'Total loss': 0.4390130662782626} | train loss {'Reaction outcome loss': 0.44846093009929267, 'Total loss': 0.44846093009929267}
2022-11-28 04:25:26,656 INFO:     Found new best model at epoch 55
2022-11-28 04:25:26,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:26,657 INFO:     Epoch: 56
2022-11-28 04:25:27,315 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45127956061200664, 'Total loss': 0.45127956061200664} | train loss {'Reaction outcome loss': 0.4545506189672314, 'Total loss': 0.4545506189672314}
2022-11-28 04:25:27,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:27,315 INFO:     Epoch: 57
2022-11-28 04:25:27,971 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47860175134106114, 'Total loss': 0.47860175134106114} | train loss {'Reaction outcome loss': 0.4568221436471355, 'Total loss': 0.4568221436471355}
2022-11-28 04:25:27,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:27,973 INFO:     Epoch: 58
2022-11-28 04:25:28,629 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.471950569444082, 'Total loss': 0.471950569444082} | train loss {'Reaction outcome loss': 0.4549320777155915, 'Total loss': 0.4549320777155915}
2022-11-28 04:25:28,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:28,629 INFO:     Epoch: 59
2022-11-28 04:25:29,286 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4706070026890798, 'Total loss': 0.4706070026890798} | train loss {'Reaction outcome loss': 0.453615491487542, 'Total loss': 0.453615491487542}
2022-11-28 04:25:29,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:29,286 INFO:     Epoch: 60
2022-11-28 04:25:29,942 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4614274874329567, 'Total loss': 0.4614274874329567} | train loss {'Reaction outcome loss': 0.45721288755231976, 'Total loss': 0.45721288755231976}
2022-11-28 04:25:29,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:29,943 INFO:     Epoch: 61
2022-11-28 04:25:30,599 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4416826113381169, 'Total loss': 0.4416826113381169} | train loss {'Reaction outcome loss': 0.45751023292541504, 'Total loss': 0.45751023292541504}
2022-11-28 04:25:30,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:30,599 INFO:     Epoch: 62
2022-11-28 04:25:31,256 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4687587792762894, 'Total loss': 0.4687587792762894} | train loss {'Reaction outcome loss': 0.45234556018697974, 'Total loss': 0.45234556018697974}
2022-11-28 04:25:31,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:31,256 INFO:     Epoch: 63
2022-11-28 04:25:31,920 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4662450220097195, 'Total loss': 0.4662450220097195} | train loss {'Reaction outcome loss': 0.45510552482945577, 'Total loss': 0.45510552482945577}
2022-11-28 04:25:31,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:31,920 INFO:     Epoch: 64
2022-11-28 04:25:32,578 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4644148634238677, 'Total loss': 0.4644148634238677} | train loss {'Reaction outcome loss': 0.45659046054494623, 'Total loss': 0.45659046054494623}
2022-11-28 04:25:32,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:32,579 INFO:     Epoch: 65
2022-11-28 04:25:33,235 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4740824672308835, 'Total loss': 0.4740824672308835} | train loss {'Reaction outcome loss': 0.46077363910723707, 'Total loss': 0.46077363910723707}
2022-11-28 04:25:33,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:33,235 INFO:     Epoch: 66
2022-11-28 04:25:33,889 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46765640581196005, 'Total loss': 0.46765640581196005} | train loss {'Reaction outcome loss': 0.45224722745467205, 'Total loss': 0.45224722745467205}
2022-11-28 04:25:33,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:33,890 INFO:     Epoch: 67
2022-11-28 04:25:34,544 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4806287666698071, 'Total loss': 0.4806287666698071} | train loss {'Reaction outcome loss': 0.45647226468640933, 'Total loss': 0.45647226468640933}
2022-11-28 04:25:34,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:34,545 INFO:     Epoch: 68
2022-11-28 04:25:35,199 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5135162445631895, 'Total loss': 0.5135162445631895} | train loss {'Reaction outcome loss': 0.4559120133519173, 'Total loss': 0.4559120133519173}
2022-11-28 04:25:35,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:35,199 INFO:     Epoch: 69
2022-11-28 04:25:35,858 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45229911093007436, 'Total loss': 0.45229911093007436} | train loss {'Reaction outcome loss': 0.45422078392335347, 'Total loss': 0.45422078392335347}
2022-11-28 04:25:35,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:35,858 INFO:     Epoch: 70
2022-11-28 04:25:36,516 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4813897094943307, 'Total loss': 0.4813897094943307} | train loss {'Reaction outcome loss': 0.4492678679677905, 'Total loss': 0.4492678679677905}
2022-11-28 04:25:36,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:36,516 INFO:     Epoch: 71
2022-11-28 04:25:37,171 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.499943425709551, 'Total loss': 0.499943425709551} | train loss {'Reaction outcome loss': 0.4580048598197042, 'Total loss': 0.4580048598197042}
2022-11-28 04:25:37,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:37,171 INFO:     Epoch: 72
2022-11-28 04:25:37,828 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4699588543312116, 'Total loss': 0.4699588543312116} | train loss {'Reaction outcome loss': 0.45614895954424023, 'Total loss': 0.45614895954424023}
2022-11-28 04:25:37,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:37,828 INFO:     Epoch: 73
2022-11-28 04:25:38,483 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48837476901032706, 'Total loss': 0.48837476901032706} | train loss {'Reaction outcome loss': 0.4651929059807135, 'Total loss': 0.4651929059807135}
2022-11-28 04:25:38,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:38,483 INFO:     Epoch: 74
2022-11-28 04:25:39,133 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4521773962134665, 'Total loss': 0.4521773962134665} | train loss {'Reaction outcome loss': 0.458682168624839, 'Total loss': 0.458682168624839}
2022-11-28 04:25:39,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:39,133 INFO:     Epoch: 75
2022-11-28 04:25:39,785 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4521627625958486, 'Total loss': 0.4521627625958486} | train loss {'Reaction outcome loss': 0.4571857738251589, 'Total loss': 0.4571857738251589}
2022-11-28 04:25:39,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:39,786 INFO:     Epoch: 76
2022-11-28 04:25:40,438 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45114486427469686, 'Total loss': 0.45114486427469686} | train loss {'Reaction outcome loss': 0.45287958450463356, 'Total loss': 0.45287958450463356}
2022-11-28 04:25:40,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:40,438 INFO:     Epoch: 77
2022-11-28 04:25:41,096 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48375842584805057, 'Total loss': 0.48375842584805057} | train loss {'Reaction outcome loss': 0.45029191919127287, 'Total loss': 0.45029191919127287}
2022-11-28 04:25:41,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:41,096 INFO:     Epoch: 78
2022-11-28 04:25:41,754 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47001311352307146, 'Total loss': 0.47001311352307146} | train loss {'Reaction outcome loss': 0.453217949094821, 'Total loss': 0.453217949094821}
2022-11-28 04:25:41,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:41,754 INFO:     Epoch: 79
2022-11-28 04:25:42,410 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46494393423199654, 'Total loss': 0.46494393423199654} | train loss {'Reaction outcome loss': 0.44985015264579226, 'Total loss': 0.44985015264579226}
2022-11-28 04:25:42,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:42,410 INFO:     Epoch: 80
2022-11-28 04:25:43,069 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47907709228721534, 'Total loss': 0.47907709228721534} | train loss {'Reaction outcome loss': 0.4556009318755597, 'Total loss': 0.4556009318755597}
2022-11-28 04:25:43,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:43,069 INFO:     Epoch: 81
2022-11-28 04:25:43,726 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4547613755884496, 'Total loss': 0.4547613755884496} | train loss {'Reaction outcome loss': 0.4507229246047078, 'Total loss': 0.4507229246047078}
2022-11-28 04:25:43,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:43,726 INFO:     Epoch: 82
2022-11-28 04:25:44,381 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45521902360699396, 'Total loss': 0.45521902360699396} | train loss {'Reaction outcome loss': 0.4570490693559452, 'Total loss': 0.4570490693559452}
2022-11-28 04:25:44,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:44,381 INFO:     Epoch: 83
2022-11-28 04:25:45,039 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4720853509550745, 'Total loss': 0.4720853509550745} | train loss {'Reaction outcome loss': 0.4585052638637776, 'Total loss': 0.4585052638637776}
2022-11-28 04:25:45,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:45,039 INFO:     Epoch: 84
2022-11-28 04:25:45,700 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4947091466323896, 'Total loss': 0.4947091466323896} | train loss {'Reaction outcome loss': 0.4607776054314205, 'Total loss': 0.4607776054314205}
2022-11-28 04:25:45,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:45,701 INFO:     Epoch: 85
2022-11-28 04:25:46,361 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4560999535024166, 'Total loss': 0.4560999535024166} | train loss {'Reaction outcome loss': 0.45247724025833364, 'Total loss': 0.45247724025833364}
2022-11-28 04:25:46,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:46,361 INFO:     Epoch: 86
2022-11-28 04:25:47,016 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4470771136270328, 'Total loss': 0.4470771136270328} | train loss {'Reaction outcome loss': 0.4633934771223944, 'Total loss': 0.4633934771223944}
2022-11-28 04:25:47,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:47,017 INFO:     Epoch: 87
2022-11-28 04:25:47,676 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4840467687357556, 'Total loss': 0.4840467687357556} | train loss {'Reaction outcome loss': 0.4558962998341541, 'Total loss': 0.4558962998341541}
2022-11-28 04:25:47,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:47,677 INFO:     Epoch: 88
2022-11-28 04:25:48,337 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46484899757937953, 'Total loss': 0.46484899757937953} | train loss {'Reaction outcome loss': 0.46106306831447447, 'Total loss': 0.46106306831447447}
2022-11-28 04:25:48,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:48,337 INFO:     Epoch: 89
2022-11-28 04:25:48,995 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47875130303542723, 'Total loss': 0.47875130303542723} | train loss {'Reaction outcome loss': 0.45322491179923624, 'Total loss': 0.45322491179923624}
2022-11-28 04:25:48,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:48,995 INFO:     Epoch: 90
2022-11-28 04:25:49,650 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46032048270783643, 'Total loss': 0.46032048270783643} | train loss {'Reaction outcome loss': 0.4576128428079644, 'Total loss': 0.4576128428079644}
2022-11-28 04:25:49,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:49,651 INFO:     Epoch: 91
2022-11-28 04:25:50,306 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4847299056974324, 'Total loss': 0.4847299056974324} | train loss {'Reaction outcome loss': 0.4539350127079049, 'Total loss': 0.4539350127079049}
2022-11-28 04:25:50,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:50,306 INFO:     Epoch: 92
2022-11-28 04:25:50,962 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4672376892783425, 'Total loss': 0.4672376892783425} | train loss {'Reaction outcome loss': 0.45908358924242915, 'Total loss': 0.45908358924242915}
2022-11-28 04:25:50,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:50,963 INFO:     Epoch: 93
2022-11-28 04:25:51,620 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4693365456028418, 'Total loss': 0.4693365456028418} | train loss {'Reaction outcome loss': 0.4579742796567022, 'Total loss': 0.4579742796567022}
2022-11-28 04:25:51,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:51,620 INFO:     Epoch: 94
2022-11-28 04:25:52,274 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4534349553287029, 'Total loss': 0.4534349553287029} | train loss {'Reaction outcome loss': 0.4575881557196987, 'Total loss': 0.4575881557196987}
2022-11-28 04:25:52,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:52,274 INFO:     Epoch: 95
2022-11-28 04:25:52,929 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46769197623838077, 'Total loss': 0.46769197623838077} | train loss {'Reaction outcome loss': 0.4592087773035984, 'Total loss': 0.4592087773035984}
2022-11-28 04:25:52,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:52,929 INFO:     Epoch: 96
2022-11-28 04:25:53,587 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.481737324798649, 'Total loss': 0.481737324798649} | train loss {'Reaction outcome loss': 0.4544024876185826, 'Total loss': 0.4544024876185826}
2022-11-28 04:25:53,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:53,588 INFO:     Epoch: 97
2022-11-28 04:25:54,243 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49451019716533745, 'Total loss': 0.49451019716533745} | train loss {'Reaction outcome loss': 0.45938316328184947, 'Total loss': 0.45938316328184947}
2022-11-28 04:25:54,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:54,243 INFO:     Epoch: 98
2022-11-28 04:25:54,900 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4677580574696714, 'Total loss': 0.4677580574696714} | train loss {'Reaction outcome loss': 0.45987788870626567, 'Total loss': 0.45987788870626567}
2022-11-28 04:25:54,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:54,901 INFO:     Epoch: 99
2022-11-28 04:25:55,557 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4708703170445832, 'Total loss': 0.4708703170445832} | train loss {'Reaction outcome loss': 0.45781454355741036, 'Total loss': 0.45781454355741036}
2022-11-28 04:25:55,557 INFO:     Best model found after epoch 56 of 100.
2022-11-28 04:25:55,558 INFO:   Done with stage: TRAINING
2022-11-28 04:25:55,558 INFO:   Starting stage: EVALUATION
2022-11-28 04:25:55,683 INFO:   Done with stage: EVALUATION
2022-11-28 04:25:55,683 INFO:   Leaving out SEQ value Fold_4
2022-11-28 04:25:55,696 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:25:55,696 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:25:56,346 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:25:56,346 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:25:56,416 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:25:56,416 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:25:56,417 INFO:     No hyperparam tuning for this model
2022-11-28 04:25:56,417 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:25:56,417 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:25:56,417 INFO:     None feature selector for col prot
2022-11-28 04:25:56,418 INFO:     None feature selector for col prot
2022-11-28 04:25:56,418 INFO:     None feature selector for col prot
2022-11-28 04:25:56,418 INFO:     None feature selector for col chem
2022-11-28 04:25:56,418 INFO:     None feature selector for col chem
2022-11-28 04:25:56,418 INFO:     None feature selector for col chem
2022-11-28 04:25:56,418 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:25:56,418 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:25:56,420 INFO:     Number of params in model 169651
2022-11-28 04:25:56,423 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:25:56,423 INFO:   Starting stage: TRAINING
2022-11-28 04:25:56,476 INFO:     Val loss before train {'Reaction outcome loss': 0.9988504878499291, 'Total loss': 0.9988504878499291}
2022-11-28 04:25:56,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:56,476 INFO:     Epoch: 0
2022-11-28 04:25:57,138 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5829722888090394, 'Total loss': 0.5829722888090394} | train loss {'Reaction outcome loss': 0.7010701541837893, 'Total loss': 0.7010701541837893}
2022-11-28 04:25:57,138 INFO:     Found new best model at epoch 0
2022-11-28 04:25:57,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:57,139 INFO:     Epoch: 1
2022-11-28 04:25:57,797 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5686208030039613, 'Total loss': 0.5686208030039613} | train loss {'Reaction outcome loss': 0.5996660488518143, 'Total loss': 0.5996660488518143}
2022-11-28 04:25:57,797 INFO:     Found new best model at epoch 1
2022-11-28 04:25:57,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:57,798 INFO:     Epoch: 2
2022-11-28 04:25:58,459 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5437980754808946, 'Total loss': 0.5437980754808946} | train loss {'Reaction outcome loss': 0.5667608588451316, 'Total loss': 0.5667608588451316}
2022-11-28 04:25:58,459 INFO:     Found new best model at epoch 2
2022-11-28 04:25:58,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:58,460 INFO:     Epoch: 3
2022-11-28 04:25:59,121 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5785967595875263, 'Total loss': 0.5785967595875263} | train loss {'Reaction outcome loss': 0.5566554404945991, 'Total loss': 0.5566554404945991}
2022-11-28 04:25:59,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:59,122 INFO:     Epoch: 4
2022-11-28 04:25:59,782 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5405931591310285, 'Total loss': 0.5405931591310285} | train loss {'Reaction outcome loss': 0.5317855284809463, 'Total loss': 0.5317855284809463}
2022-11-28 04:25:59,782 INFO:     Found new best model at epoch 4
2022-11-28 04:25:59,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:25:59,783 INFO:     Epoch: 5
2022-11-28 04:26:00,442 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5128978192806244, 'Total loss': 0.5128978192806244} | train loss {'Reaction outcome loss': 0.5239304318601786, 'Total loss': 0.5239304318601786}
2022-11-28 04:26:00,442 INFO:     Found new best model at epoch 5
2022-11-28 04:26:00,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:00,443 INFO:     Epoch: 6
2022-11-28 04:26:01,105 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.513010514730757, 'Total loss': 0.513010514730757} | train loss {'Reaction outcome loss': 0.5298123282459584, 'Total loss': 0.5298123282459584}
2022-11-28 04:26:01,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:01,106 INFO:     Epoch: 7
2022-11-28 04:26:01,765 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5226668762889776, 'Total loss': 0.5226668762889776} | train loss {'Reaction outcome loss': 0.5124716184399871, 'Total loss': 0.5124716184399871}
2022-11-28 04:26:01,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:01,765 INFO:     Epoch: 8
2022-11-28 04:26:02,424 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47893126783045853, 'Total loss': 0.47893126783045853} | train loss {'Reaction outcome loss': 0.4953311832267263, 'Total loss': 0.4953311832267263}
2022-11-28 04:26:02,424 INFO:     Found new best model at epoch 8
2022-11-28 04:26:02,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:02,425 INFO:     Epoch: 9
2022-11-28 04:26:03,087 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5889963494105772, 'Total loss': 0.5889963494105772} | train loss {'Reaction outcome loss': 0.500884259338321, 'Total loss': 0.500884259338321}
2022-11-28 04:26:03,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:03,088 INFO:     Epoch: 10
2022-11-28 04:26:03,745 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5023576552894983, 'Total loss': 0.5023576552894983} | train loss {'Reaction outcome loss': 0.499619741354756, 'Total loss': 0.499619741354756}
2022-11-28 04:26:03,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:03,745 INFO:     Epoch: 11
2022-11-28 04:26:04,407 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4819501099938696, 'Total loss': 0.4819501099938696} | train loss {'Reaction outcome loss': 0.5017041299145232, 'Total loss': 0.5017041299145232}
2022-11-28 04:26:04,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:04,408 INFO:     Epoch: 12
2022-11-28 04:26:05,070 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.513990314846689, 'Total loss': 0.513990314846689} | train loss {'Reaction outcome loss': 0.5018190991902641, 'Total loss': 0.5018190991902641}
2022-11-28 04:26:05,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:05,071 INFO:     Epoch: 13
2022-11-28 04:26:05,732 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5205058543519541, 'Total loss': 0.5205058543519541} | train loss {'Reaction outcome loss': 0.4898318823291223, 'Total loss': 0.4898318823291223}
2022-11-28 04:26:05,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:05,733 INFO:     Epoch: 14
2022-11-28 04:26:06,393 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5109451755203984, 'Total loss': 0.5109451755203984} | train loss {'Reaction outcome loss': 0.49073355902846044, 'Total loss': 0.49073355902846044}
2022-11-28 04:26:06,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:06,394 INFO:     Epoch: 15
2022-11-28 04:26:07,056 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5145798505029895, 'Total loss': 0.5145798505029895} | train loss {'Reaction outcome loss': 0.48531168065814356, 'Total loss': 0.48531168065814356}
2022-11-28 04:26:07,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:07,056 INFO:     Epoch: 16
2022-11-28 04:26:07,715 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4828364381735975, 'Total loss': 0.4828364381735975} | train loss {'Reaction outcome loss': 0.48645509797551856, 'Total loss': 0.48645509797551856}
2022-11-28 04:26:07,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:07,715 INFO:     Epoch: 17
2022-11-28 04:26:08,375 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.547492937269536, 'Total loss': 0.547492937269536} | train loss {'Reaction outcome loss': 0.4826615397264118, 'Total loss': 0.4826615397264118}
2022-11-28 04:26:08,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:08,375 INFO:     Epoch: 18
2022-11-28 04:26:09,036 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4918481301177632, 'Total loss': 0.4918481301177632} | train loss {'Reaction outcome loss': 0.4922417861518831, 'Total loss': 0.4922417861518831}
2022-11-28 04:26:09,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:09,036 INFO:     Epoch: 19
2022-11-28 04:26:09,700 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4943772161548788, 'Total loss': 0.4943772161548788} | train loss {'Reaction outcome loss': 0.48095234343216486, 'Total loss': 0.48095234343216486}
2022-11-28 04:26:09,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:09,700 INFO:     Epoch: 20
2022-11-28 04:26:10,360 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5274671255187555, 'Total loss': 0.5274671255187555} | train loss {'Reaction outcome loss': 0.480673706302276, 'Total loss': 0.480673706302276}
2022-11-28 04:26:10,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:10,360 INFO:     Epoch: 21
2022-11-28 04:26:11,024 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.501910391178998, 'Total loss': 0.501910391178998} | train loss {'Reaction outcome loss': 0.49335170633759096, 'Total loss': 0.49335170633759096}
2022-11-28 04:26:11,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:11,024 INFO:     Epoch: 22
2022-11-28 04:26:11,686 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4628378017382188, 'Total loss': 0.4628378017382188} | train loss {'Reaction outcome loss': 0.4822312777462276, 'Total loss': 0.4822312777462276}
2022-11-28 04:26:11,686 INFO:     Found new best model at epoch 22
2022-11-28 04:26:11,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:11,687 INFO:     Epoch: 23
2022-11-28 04:26:12,349 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48677271367474034, 'Total loss': 0.48677271367474034} | train loss {'Reaction outcome loss': 0.4776786252844943, 'Total loss': 0.4776786252844943}
2022-11-28 04:26:12,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:12,350 INFO:     Epoch: 24
2022-11-28 04:26:13,011 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5126068019731478, 'Total loss': 0.5126068019731478} | train loss {'Reaction outcome loss': 0.47283778191819364, 'Total loss': 0.47283778191819364}
2022-11-28 04:26:13,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:13,012 INFO:     Epoch: 25
2022-11-28 04:26:13,674 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49748185446316545, 'Total loss': 0.49748185446316545} | train loss {'Reaction outcome loss': 0.4718390272455177, 'Total loss': 0.4718390272455177}
2022-11-28 04:26:13,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:13,674 INFO:     Epoch: 26
2022-11-28 04:26:14,337 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4997966756874865, 'Total loss': 0.4997966756874865} | train loss {'Reaction outcome loss': 0.47317586246659216, 'Total loss': 0.47317586246659216}
2022-11-28 04:26:14,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:14,338 INFO:     Epoch: 27
2022-11-28 04:26:15,002 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.55872986770489, 'Total loss': 0.55872986770489} | train loss {'Reaction outcome loss': 0.4786889672219029, 'Total loss': 0.4786889672219029}
2022-11-28 04:26:15,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:15,002 INFO:     Epoch: 28
2022-11-28 04:26:15,664 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4973392445932735, 'Total loss': 0.4973392445932735} | train loss {'Reaction outcome loss': 0.4809506428145204, 'Total loss': 0.4809506428145204}
2022-11-28 04:26:15,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:15,664 INFO:     Epoch: 29
2022-11-28 04:26:16,326 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47531919316811994, 'Total loss': 0.47531919316811994} | train loss {'Reaction outcome loss': 0.4673848679130859, 'Total loss': 0.4673848679130859}
2022-11-28 04:26:16,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:16,326 INFO:     Epoch: 30
2022-11-28 04:26:16,989 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4882552921772003, 'Total loss': 0.4882552921772003} | train loss {'Reaction outcome loss': 0.4736298838487038, 'Total loss': 0.4736298838487038}
2022-11-28 04:26:16,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:16,989 INFO:     Epoch: 31
2022-11-28 04:26:17,651 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4910877814347094, 'Total loss': 0.4910877814347094} | train loss {'Reaction outcome loss': 0.46978664108616136, 'Total loss': 0.46978664108616136}
2022-11-28 04:26:17,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:17,651 INFO:     Epoch: 32
2022-11-28 04:26:18,316 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49018101969903166, 'Total loss': 0.49018101969903166} | train loss {'Reaction outcome loss': 0.47339520482761177, 'Total loss': 0.47339520482761177}
2022-11-28 04:26:18,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:18,317 INFO:     Epoch: 33
2022-11-28 04:26:18,980 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4730053848840974, 'Total loss': 0.4730053848840974} | train loss {'Reaction outcome loss': 0.4667298192505231, 'Total loss': 0.4667298192505231}
2022-11-28 04:26:18,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:18,980 INFO:     Epoch: 34
2022-11-28 04:26:19,645 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5545544881712307, 'Total loss': 0.5545544881712307} | train loss {'Reaction outcome loss': 0.4702705511680016, 'Total loss': 0.4702705511680016}
2022-11-28 04:26:19,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:19,645 INFO:     Epoch: 35
2022-11-28 04:26:20,308 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4695513668385419, 'Total loss': 0.4695513668385419} | train loss {'Reaction outcome loss': 0.47845118357102395, 'Total loss': 0.47845118357102395}
2022-11-28 04:26:20,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:20,308 INFO:     Epoch: 36
2022-11-28 04:26:20,970 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4832779395986687, 'Total loss': 0.4832779395986687} | train loss {'Reaction outcome loss': 0.485415493549123, 'Total loss': 0.485415493549123}
2022-11-28 04:26:20,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:20,971 INFO:     Epoch: 37
2022-11-28 04:26:21,631 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48291807012124494, 'Total loss': 0.48291807012124494} | train loss {'Reaction outcome loss': 0.47620504396224794, 'Total loss': 0.47620504396224794}
2022-11-28 04:26:21,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:21,631 INFO:     Epoch: 38
2022-11-28 04:26:22,292 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4870431260629134, 'Total loss': 0.4870431260629134} | train loss {'Reaction outcome loss': 0.4658103414230531, 'Total loss': 0.4658103414230531}
2022-11-28 04:26:22,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:22,292 INFO:     Epoch: 39
2022-11-28 04:26:22,954 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4995991069484841, 'Total loss': 0.4995991069484841} | train loss {'Reaction outcome loss': 0.46436296321964454, 'Total loss': 0.46436296321964454}
2022-11-28 04:26:22,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:22,954 INFO:     Epoch: 40
2022-11-28 04:26:23,612 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5450580004941333, 'Total loss': 0.5450580004941333} | train loss {'Reaction outcome loss': 0.4654286546775928, 'Total loss': 0.4654286546775928}
2022-11-28 04:26:23,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:23,612 INFO:     Epoch: 41
2022-11-28 04:26:24,272 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5060944160954519, 'Total loss': 0.5060944160954519} | train loss {'Reaction outcome loss': 0.47111591639427036, 'Total loss': 0.47111591639427036}
2022-11-28 04:26:24,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:24,272 INFO:     Epoch: 42
2022-11-28 04:26:24,933 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48108564960685646, 'Total loss': 0.48108564960685646} | train loss {'Reaction outcome loss': 0.4680837501398465, 'Total loss': 0.4680837501398465}
2022-11-28 04:26:24,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:24,934 INFO:     Epoch: 43
2022-11-28 04:26:25,593 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5068873607299544, 'Total loss': 0.5068873607299544} | train loss {'Reaction outcome loss': 0.46226831804112595, 'Total loss': 0.46226831804112595}
2022-11-28 04:26:25,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:25,593 INFO:     Epoch: 44
2022-11-28 04:26:26,254 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4986960942094976, 'Total loss': 0.4986960942094976} | train loss {'Reaction outcome loss': 0.47197106420269863, 'Total loss': 0.47197106420269863}
2022-11-28 04:26:26,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:26,254 INFO:     Epoch: 45
2022-11-28 04:26:26,916 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5236570306799628, 'Total loss': 0.5236570306799628} | train loss {'Reaction outcome loss': 0.46812284418083877, 'Total loss': 0.46812284418083877}
2022-11-28 04:26:26,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:26,917 INFO:     Epoch: 46
2022-11-28 04:26:27,578 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49136948585510254, 'Total loss': 0.49136948585510254} | train loss {'Reaction outcome loss': 0.4761433304562742, 'Total loss': 0.4761433304562742}
2022-11-28 04:26:27,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:27,578 INFO:     Epoch: 47
2022-11-28 04:26:28,238 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4909412207251245, 'Total loss': 0.4909412207251245} | train loss {'Reaction outcome loss': 0.46995238772016545, 'Total loss': 0.46995238772016545}
2022-11-28 04:26:28,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:28,238 INFO:     Epoch: 48
2022-11-28 04:26:28,900 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5201799937269904, 'Total loss': 0.5201799937269904} | train loss {'Reaction outcome loss': 0.46578267040221316, 'Total loss': 0.46578267040221316}
2022-11-28 04:26:28,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:28,900 INFO:     Epoch: 49
2022-11-28 04:26:29,566 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49044816771691496, 'Total loss': 0.49044816771691496} | train loss {'Reaction outcome loss': 0.4704180139037762, 'Total loss': 0.4704180139037762}
2022-11-28 04:26:29,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:29,567 INFO:     Epoch: 50
2022-11-28 04:26:30,228 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4775651056658138, 'Total loss': 0.4775651056658138} | train loss {'Reaction outcome loss': 0.4736571777084096, 'Total loss': 0.4736571777084096}
2022-11-28 04:26:30,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:30,229 INFO:     Epoch: 51
2022-11-28 04:26:30,890 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48165190423076804, 'Total loss': 0.48165190423076804} | train loss {'Reaction outcome loss': 0.4703700885719616, 'Total loss': 0.4703700885719616}
2022-11-28 04:26:30,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:30,890 INFO:     Epoch: 52
2022-11-28 04:26:31,553 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.521097139201381, 'Total loss': 0.521097139201381} | train loss {'Reaction outcome loss': 0.47260224445146104, 'Total loss': 0.47260224445146104}
2022-11-28 04:26:31,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:31,554 INFO:     Epoch: 53
2022-11-28 04:26:32,218 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4762940129095858, 'Total loss': 0.4762940129095858} | train loss {'Reaction outcome loss': 0.4746993934143682, 'Total loss': 0.4746993934143682}
2022-11-28 04:26:32,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:32,218 INFO:     Epoch: 54
2022-11-28 04:26:32,881 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5113399929621003, 'Total loss': 0.5113399929621003} | train loss {'Reaction outcome loss': 0.4666731089715533, 'Total loss': 0.4666731089715533}
2022-11-28 04:26:32,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:32,881 INFO:     Epoch: 55
2022-11-28 04:26:33,541 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47651728174903174, 'Total loss': 0.47651728174903174} | train loss {'Reaction outcome loss': 0.47120558250288247, 'Total loss': 0.47120558250288247}
2022-11-28 04:26:33,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:33,542 INFO:     Epoch: 56
2022-11-28 04:26:34,201 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47862526740540157, 'Total loss': 0.47862526740540157} | train loss {'Reaction outcome loss': 0.468585505659281, 'Total loss': 0.468585505659281}
2022-11-28 04:26:34,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:34,201 INFO:     Epoch: 57
2022-11-28 04:26:34,860 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4725660315968774, 'Total loss': 0.4725660315968774} | train loss {'Reaction outcome loss': 0.4709611793731147, 'Total loss': 0.4709611793731147}
2022-11-28 04:26:34,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:34,861 INFO:     Epoch: 58
2022-11-28 04:26:35,515 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47123074904084206, 'Total loss': 0.47123074904084206} | train loss {'Reaction outcome loss': 0.4734902260033225, 'Total loss': 0.4734902260033225}
2022-11-28 04:26:35,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:35,515 INFO:     Epoch: 59
2022-11-28 04:26:36,169 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49602081084793265, 'Total loss': 0.49602081084793265} | train loss {'Reaction outcome loss': 0.4602339130709408, 'Total loss': 0.4602339130709408}
2022-11-28 04:26:36,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:36,170 INFO:     Epoch: 60
2022-11-28 04:26:36,828 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4632330452176658, 'Total loss': 0.4632330452176658} | train loss {'Reaction outcome loss': 0.4723203906163513, 'Total loss': 0.4723203906163513}
2022-11-28 04:26:36,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:36,829 INFO:     Epoch: 61
2022-11-28 04:26:37,485 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48366736552932044, 'Total loss': 0.48366736552932044} | train loss {'Reaction outcome loss': 0.47079183119028684, 'Total loss': 0.47079183119028684}
2022-11-28 04:26:37,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:37,485 INFO:     Epoch: 62
2022-11-28 04:26:38,141 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4684194160456007, 'Total loss': 0.4684194160456007} | train loss {'Reaction outcome loss': 0.46617759040251433, 'Total loss': 0.46617759040251433}
2022-11-28 04:26:38,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:38,141 INFO:     Epoch: 63
2022-11-28 04:26:38,801 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4731095460328189, 'Total loss': 0.4731095460328189} | train loss {'Reaction outcome loss': 0.4683288448011344, 'Total loss': 0.4683288448011344}
2022-11-28 04:26:38,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:38,801 INFO:     Epoch: 64
2022-11-28 04:26:39,460 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4735198339278048, 'Total loss': 0.4735198339278048} | train loss {'Reaction outcome loss': 0.4672263068889799, 'Total loss': 0.4672263068889799}
2022-11-28 04:26:39,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:39,460 INFO:     Epoch: 65
2022-11-28 04:26:40,115 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5756905952637846, 'Total loss': 0.5756905952637846} | train loss {'Reaction outcome loss': 0.4734777962328934, 'Total loss': 0.4734777962328934}
2022-11-28 04:26:40,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:40,116 INFO:     Epoch: 66
2022-11-28 04:26:40,774 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47886377335949376, 'Total loss': 0.47886377335949376} | train loss {'Reaction outcome loss': 0.4852663104833379, 'Total loss': 0.4852663104833379}
2022-11-28 04:26:40,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:40,774 INFO:     Epoch: 67
2022-11-28 04:26:41,437 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48010212724859064, 'Total loss': 0.48010212724859064} | train loss {'Reaction outcome loss': 0.4720171926173604, 'Total loss': 0.4720171926173604}
2022-11-28 04:26:41,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:41,437 INFO:     Epoch: 68
2022-11-28 04:26:42,098 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5405107377605005, 'Total loss': 0.5405107377605005} | train loss {'Reaction outcome loss': 0.4777804025512958, 'Total loss': 0.4777804025512958}
2022-11-28 04:26:42,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:42,098 INFO:     Epoch: 69
2022-11-28 04:26:42,751 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46431758627295494, 'Total loss': 0.46431758627295494} | train loss {'Reaction outcome loss': 0.4741810539413078, 'Total loss': 0.4741810539413078}
2022-11-28 04:26:42,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:42,751 INFO:     Epoch: 70
2022-11-28 04:26:43,404 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4871360585093498, 'Total loss': 0.4871360585093498} | train loss {'Reaction outcome loss': 0.46570132321844004, 'Total loss': 0.46570132321844004}
2022-11-28 04:26:43,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:43,404 INFO:     Epoch: 71
2022-11-28 04:26:44,061 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4854577722197229, 'Total loss': 0.4854577722197229} | train loss {'Reaction outcome loss': 0.4601407669756094, 'Total loss': 0.4601407669756094}
2022-11-28 04:26:44,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:44,061 INFO:     Epoch: 72
2022-11-28 04:26:44,719 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5190436542034149, 'Total loss': 0.5190436542034149} | train loss {'Reaction outcome loss': 0.4656571436386842, 'Total loss': 0.4656571436386842}
2022-11-28 04:26:44,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:44,719 INFO:     Epoch: 73
2022-11-28 04:26:45,375 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4740180579776114, 'Total loss': 0.4740180579776114} | train loss {'Reaction outcome loss': 0.4689444466022707, 'Total loss': 0.4689444466022707}
2022-11-28 04:26:45,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:45,375 INFO:     Epoch: 74
2022-11-28 04:26:46,029 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5086712308905341, 'Total loss': 0.5086712308905341} | train loss {'Reaction outcome loss': 0.47795599861907573, 'Total loss': 0.47795599861907573}
2022-11-28 04:26:46,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:46,029 INFO:     Epoch: 75
2022-11-28 04:26:46,684 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4838805804875764, 'Total loss': 0.4838805804875764} | train loss {'Reaction outcome loss': 0.4824854659768734, 'Total loss': 0.4824854659768734}
2022-11-28 04:26:46,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:46,685 INFO:     Epoch: 76
2022-11-28 04:26:47,343 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47036050564863463, 'Total loss': 0.47036050564863463} | train loss {'Reaction outcome loss': 0.47995150879568416, 'Total loss': 0.47995150879568416}
2022-11-28 04:26:47,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:47,344 INFO:     Epoch: 77
2022-11-28 04:26:47,999 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4601263925433159, 'Total loss': 0.4601263925433159} | train loss {'Reaction outcome loss': 0.46217132972926656, 'Total loss': 0.46217132972926656}
2022-11-28 04:26:47,999 INFO:     Found new best model at epoch 77
2022-11-28 04:26:48,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:48,000 INFO:     Epoch: 78
2022-11-28 04:26:48,661 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46547473035752773, 'Total loss': 0.46547473035752773} | train loss {'Reaction outcome loss': 0.46622862558253864, 'Total loss': 0.46622862558253864}
2022-11-28 04:26:48,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:48,662 INFO:     Epoch: 79
2022-11-28 04:26:49,318 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4921510151841424, 'Total loss': 0.4921510151841424} | train loss {'Reaction outcome loss': 0.46616334320321257, 'Total loss': 0.46616334320321257}
2022-11-28 04:26:49,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:49,319 INFO:     Epoch: 80
2022-11-28 04:26:49,974 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4905814514918761, 'Total loss': 0.4905814514918761} | train loss {'Reaction outcome loss': 0.458295719750859, 'Total loss': 0.458295719750859}
2022-11-28 04:26:49,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:49,975 INFO:     Epoch: 81
2022-11-28 04:26:50,630 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4694493731314486, 'Total loss': 0.4694493731314486} | train loss {'Reaction outcome loss': 0.4613590365961978, 'Total loss': 0.4613590365961978}
2022-11-28 04:26:50,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:50,630 INFO:     Epoch: 82
2022-11-28 04:26:51,287 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4758167859505523, 'Total loss': 0.4758167859505523} | train loss {'Reaction outcome loss': 0.46697813013063266, 'Total loss': 0.46697813013063266}
2022-11-28 04:26:51,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:51,288 INFO:     Epoch: 83
2022-11-28 04:26:51,944 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4782524478029121, 'Total loss': 0.4782524478029121} | train loss {'Reaction outcome loss': 0.4645714585665568, 'Total loss': 0.4645714585665568}
2022-11-28 04:26:51,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:51,944 INFO:     Epoch: 84
2022-11-28 04:26:52,600 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5080735182220285, 'Total loss': 0.5080735182220285} | train loss {'Reaction outcome loss': 0.4682749201683139, 'Total loss': 0.4682749201683139}
2022-11-28 04:26:52,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:52,600 INFO:     Epoch: 85
2022-11-28 04:26:53,259 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49984557554125786, 'Total loss': 0.49984557554125786} | train loss {'Reaction outcome loss': 0.4683644727536059, 'Total loss': 0.4683644727536059}
2022-11-28 04:26:53,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:53,259 INFO:     Epoch: 86
2022-11-28 04:26:53,915 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4788445098833604, 'Total loss': 0.4788445098833604} | train loss {'Reaction outcome loss': 0.46731982175812226, 'Total loss': 0.46731982175812226}
2022-11-28 04:26:53,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:53,916 INFO:     Epoch: 87
2022-11-28 04:26:54,571 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47926563092253427, 'Total loss': 0.47926563092253427} | train loss {'Reaction outcome loss': 0.46749382945690077, 'Total loss': 0.46749382945690077}
2022-11-28 04:26:54,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:54,572 INFO:     Epoch: 88
2022-11-28 04:26:55,232 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5004433552649888, 'Total loss': 0.5004433552649888} | train loss {'Reaction outcome loss': 0.47123826801897545, 'Total loss': 0.47123826801897545}
2022-11-28 04:26:55,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:55,232 INFO:     Epoch: 89
2022-11-28 04:26:55,888 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5676109499552033, 'Total loss': 0.5676109499552033} | train loss {'Reaction outcome loss': 0.48150911142951563, 'Total loss': 0.48150911142951563}
2022-11-28 04:26:55,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:55,888 INFO:     Epoch: 90
2022-11-28 04:26:56,546 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.465086555108428, 'Total loss': 0.465086555108428} | train loss {'Reaction outcome loss': 0.4716396021999811, 'Total loss': 0.4716396021999811}
2022-11-28 04:26:56,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:56,547 INFO:     Epoch: 91
2022-11-28 04:26:57,204 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5131048756566915, 'Total loss': 0.5131048756566915} | train loss {'Reaction outcome loss': 0.4736314000267732, 'Total loss': 0.4736314000267732}
2022-11-28 04:26:57,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:57,204 INFO:     Epoch: 92
2022-11-28 04:26:57,863 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4774188321422447, 'Total loss': 0.4774188321422447} | train loss {'Reaction outcome loss': 0.4658411900524186, 'Total loss': 0.4658411900524186}
2022-11-28 04:26:57,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:57,863 INFO:     Epoch: 93
2022-11-28 04:26:58,522 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49416461891748686, 'Total loss': 0.49416461891748686} | train loss {'Reaction outcome loss': 0.46451081788008997, 'Total loss': 0.46451081788008997}
2022-11-28 04:26:58,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:58,523 INFO:     Epoch: 94
2022-11-28 04:26:59,181 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4485123015262864, 'Total loss': 0.4485123015262864} | train loss {'Reaction outcome loss': 0.46234413898485877, 'Total loss': 0.46234413898485877}
2022-11-28 04:26:59,182 INFO:     Found new best model at epoch 94
2022-11-28 04:26:59,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:59,182 INFO:     Epoch: 95
2022-11-28 04:26:59,841 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4560144631700082, 'Total loss': 0.4560144631700082} | train loss {'Reaction outcome loss': 0.4698428923531854, 'Total loss': 0.4698428923531854}
2022-11-28 04:26:59,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:26:59,841 INFO:     Epoch: 96
2022-11-28 04:27:00,497 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45791069011796603, 'Total loss': 0.45791069011796603} | train loss {'Reaction outcome loss': 0.47207420105152287, 'Total loss': 0.47207420105152287}
2022-11-28 04:27:00,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:00,498 INFO:     Epoch: 97
2022-11-28 04:27:01,161 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47758678685535083, 'Total loss': 0.47758678685535083} | train loss {'Reaction outcome loss': 0.4670879246689651, 'Total loss': 0.4670879246689651}
2022-11-28 04:27:01,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:01,161 INFO:     Epoch: 98
2022-11-28 04:27:01,823 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46655046465722, 'Total loss': 0.46655046465722} | train loss {'Reaction outcome loss': 0.4680436087644052, 'Total loss': 0.4680436087644052}
2022-11-28 04:27:01,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:01,823 INFO:     Epoch: 99
2022-11-28 04:27:02,482 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47962423346259375, 'Total loss': 0.47962423346259375} | train loss {'Reaction outcome loss': 0.4671937101765683, 'Total loss': 0.4671937101765683}
2022-11-28 04:27:02,482 INFO:     Best model found after epoch 95 of 100.
2022-11-28 04:27:02,482 INFO:   Done with stage: TRAINING
2022-11-28 04:27:02,482 INFO:   Starting stage: EVALUATION
2022-11-28 04:27:02,601 INFO:   Done with stage: EVALUATION
2022-11-28 04:27:02,601 INFO:   Leaving out SEQ value Fold_5
2022-11-28 04:27:02,614 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:27:02,614 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:27:03,262 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:27:03,262 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:27:03,331 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:27:03,331 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:27:03,331 INFO:     No hyperparam tuning for this model
2022-11-28 04:27:03,331 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:27:03,331 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:27:03,332 INFO:     None feature selector for col prot
2022-11-28 04:27:03,332 INFO:     None feature selector for col prot
2022-11-28 04:27:03,332 INFO:     None feature selector for col prot
2022-11-28 04:27:03,332 INFO:     None feature selector for col chem
2022-11-28 04:27:03,332 INFO:     None feature selector for col chem
2022-11-28 04:27:03,332 INFO:     None feature selector for col chem
2022-11-28 04:27:03,333 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:27:03,333 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:27:03,334 INFO:     Number of params in model 169651
2022-11-28 04:27:03,337 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:27:03,338 INFO:   Starting stage: TRAINING
2022-11-28 04:27:03,389 INFO:     Val loss before train {'Reaction outcome loss': 1.0064118206501007, 'Total loss': 1.0064118206501007}
2022-11-28 04:27:03,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:03,389 INFO:     Epoch: 0
2022-11-28 04:27:04,054 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.587071796709841, 'Total loss': 0.587071796709841} | train loss {'Reaction outcome loss': 0.6866884488732584, 'Total loss': 0.6866884488732584}
2022-11-28 04:27:04,054 INFO:     Found new best model at epoch 0
2022-11-28 04:27:04,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:04,055 INFO:     Epoch: 1
2022-11-28 04:27:04,720 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5459933653473854, 'Total loss': 0.5459933653473854} | train loss {'Reaction outcome loss': 0.5886309014693383, 'Total loss': 0.5886309014693383}
2022-11-28 04:27:04,720 INFO:     Found new best model at epoch 1
2022-11-28 04:27:04,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:04,721 INFO:     Epoch: 2
2022-11-28 04:27:05,383 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5222105634483424, 'Total loss': 0.5222105634483424} | train loss {'Reaction outcome loss': 0.558016964564881, 'Total loss': 0.558016964564881}
2022-11-28 04:27:05,383 INFO:     Found new best model at epoch 2
2022-11-28 04:27:05,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:05,384 INFO:     Epoch: 3
2022-11-28 04:27:06,043 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5619116500020027, 'Total loss': 0.5619116500020027} | train loss {'Reaction outcome loss': 0.5305221309705127, 'Total loss': 0.5305221309705127}
2022-11-28 04:27:06,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:06,044 INFO:     Epoch: 4
2022-11-28 04:27:06,706 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5347276878627863, 'Total loss': 0.5347276878627863} | train loss {'Reaction outcome loss': 0.5245329105565625, 'Total loss': 0.5245329105565625}
2022-11-28 04:27:06,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:06,707 INFO:     Epoch: 5
2022-11-28 04:27:07,366 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5305832556702874, 'Total loss': 0.5305832556702874} | train loss {'Reaction outcome loss': 0.5096771569261628, 'Total loss': 0.5096771569261628}
2022-11-28 04:27:07,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:07,367 INFO:     Epoch: 6
2022-11-28 04:27:08,030 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49070368165319617, 'Total loss': 0.49070368165319617} | train loss {'Reaction outcome loss': 0.5070037414590197, 'Total loss': 0.5070037414590197}
2022-11-28 04:27:08,030 INFO:     Found new best model at epoch 6
2022-11-28 04:27:08,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:08,031 INFO:     Epoch: 7
2022-11-28 04:27:08,693 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49760445613752713, 'Total loss': 0.49760445613752713} | train loss {'Reaction outcome loss': 0.4979804556576475, 'Total loss': 0.4979804556576475}
2022-11-28 04:27:08,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:08,693 INFO:     Epoch: 8
2022-11-28 04:27:09,353 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5074317428198728, 'Total loss': 0.5074317428198728} | train loss {'Reaction outcome loss': 0.503827573070603, 'Total loss': 0.503827573070603}
2022-11-28 04:27:09,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:09,353 INFO:     Epoch: 9
2022-11-28 04:27:10,015 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5278255685486577, 'Total loss': 0.5278255685486577} | train loss {'Reaction outcome loss': 0.5002165212626418, 'Total loss': 0.5002165212626418}
2022-11-28 04:27:10,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:10,015 INFO:     Epoch: 10
2022-11-28 04:27:10,675 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5062969774007797, 'Total loss': 0.5062969774007797} | train loss {'Reaction outcome loss': 0.48847524863818, 'Total loss': 0.48847524863818}
2022-11-28 04:27:10,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:10,675 INFO:     Epoch: 11
2022-11-28 04:27:11,337 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48186256804249505, 'Total loss': 0.48186256804249505} | train loss {'Reaction outcome loss': 0.49115254958310434, 'Total loss': 0.49115254958310434}
2022-11-28 04:27:11,337 INFO:     Found new best model at epoch 11
2022-11-28 04:27:11,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:11,337 INFO:     Epoch: 12
2022-11-28 04:27:12,000 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5220543847165324, 'Total loss': 0.5220543847165324} | train loss {'Reaction outcome loss': 0.47650852366801233, 'Total loss': 0.47650852366801233}
2022-11-28 04:27:12,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:12,000 INFO:     Epoch: 13
2022-11-28 04:27:12,659 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48709360002116725, 'Total loss': 0.48709360002116725} | train loss {'Reaction outcome loss': 0.4873224064827927, 'Total loss': 0.4873224064827927}
2022-11-28 04:27:12,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:12,659 INFO:     Epoch: 14
2022-11-28 04:27:13,321 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49137330427765846, 'Total loss': 0.49137330427765846} | train loss {'Reaction outcome loss': 0.47653532589996056, 'Total loss': 0.47653532589996056}
2022-11-28 04:27:13,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:13,321 INFO:     Epoch: 15
2022-11-28 04:27:13,983 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5006348152052272, 'Total loss': 0.5006348152052272} | train loss {'Reaction outcome loss': 0.4749597394238076, 'Total loss': 0.4749597394238076}
2022-11-28 04:27:13,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:13,984 INFO:     Epoch: 16
2022-11-28 04:27:14,644 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5184073448181152, 'Total loss': 0.5184073448181152} | train loss {'Reaction outcome loss': 0.4728712050184127, 'Total loss': 0.4728712050184127}
2022-11-28 04:27:14,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:14,644 INFO:     Epoch: 17
2022-11-28 04:27:15,304 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49106317826292734, 'Total loss': 0.49106317826292734} | train loss {'Reaction outcome loss': 0.4762266147280893, 'Total loss': 0.4762266147280893}
2022-11-28 04:27:15,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:15,304 INFO:     Epoch: 18
2022-11-28 04:27:15,967 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5040697722949765, 'Total loss': 0.5040697722949765} | train loss {'Reaction outcome loss': 0.47504547881262915, 'Total loss': 0.47504547881262915}
2022-11-28 04:27:15,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:15,967 INFO:     Epoch: 19
2022-11-28 04:27:16,630 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4783863089978695, 'Total loss': 0.4783863089978695} | train loss {'Reaction outcome loss': 0.4726713608589865, 'Total loss': 0.4726713608589865}
2022-11-28 04:27:16,630 INFO:     Found new best model at epoch 19
2022-11-28 04:27:16,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:16,631 INFO:     Epoch: 20
2022-11-28 04:27:17,294 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47570539536801254, 'Total loss': 0.47570539536801254} | train loss {'Reaction outcome loss': 0.4706812871079291, 'Total loss': 0.4706812871079291}
2022-11-28 04:27:17,294 INFO:     Found new best model at epoch 20
2022-11-28 04:27:17,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:17,295 INFO:     Epoch: 21
2022-11-28 04:27:17,956 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4817203919995915, 'Total loss': 0.4817203919995915} | train loss {'Reaction outcome loss': 0.46819237529510455, 'Total loss': 0.46819237529510455}
2022-11-28 04:27:17,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:17,956 INFO:     Epoch: 22
2022-11-28 04:27:18,620 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49009647051041777, 'Total loss': 0.49009647051041777} | train loss {'Reaction outcome loss': 0.4642304676554857, 'Total loss': 0.4642304676554857}
2022-11-28 04:27:18,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:18,620 INFO:     Epoch: 23
2022-11-28 04:27:19,284 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4846292500468818, 'Total loss': 0.4846292500468818} | train loss {'Reaction outcome loss': 0.47430200165798586, 'Total loss': 0.47430200165798586}
2022-11-28 04:27:19,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:19,285 INFO:     Epoch: 24
2022-11-28 04:27:19,950 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4747963168404319, 'Total loss': 0.4747963168404319} | train loss {'Reaction outcome loss': 0.4689739305646189, 'Total loss': 0.4689739305646189}
2022-11-28 04:27:19,951 INFO:     Found new best model at epoch 24
2022-11-28 04:27:19,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:19,951 INFO:     Epoch: 25
2022-11-28 04:27:20,614 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4771182679317214, 'Total loss': 0.4771182679317214} | train loss {'Reaction outcome loss': 0.46030436732595964, 'Total loss': 0.46030436732595964}
2022-11-28 04:27:20,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:20,614 INFO:     Epoch: 26
2022-11-28 04:27:21,274 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4557307663966309, 'Total loss': 0.4557307663966309} | train loss {'Reaction outcome loss': 0.4728401765948342, 'Total loss': 0.4728401765948342}
2022-11-28 04:27:21,274 INFO:     Found new best model at epoch 26
2022-11-28 04:27:21,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:21,275 INFO:     Epoch: 27
2022-11-28 04:27:21,941 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4989705051888119, 'Total loss': 0.4989705051888119} | train loss {'Reaction outcome loss': 0.4720298132949298, 'Total loss': 0.4720298132949298}
2022-11-28 04:27:21,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:21,942 INFO:     Epoch: 28
2022-11-28 04:27:22,605 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5080664157867432, 'Total loss': 0.5080664157867432} | train loss {'Reaction outcome loss': 0.469514656151014, 'Total loss': 0.469514656151014}
2022-11-28 04:27:22,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:22,605 INFO:     Epoch: 29
2022-11-28 04:27:23,266 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48115736517039215, 'Total loss': 0.48115736517039215} | train loss {'Reaction outcome loss': 0.4622043434590582, 'Total loss': 0.4622043434590582}
2022-11-28 04:27:23,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:23,266 INFO:     Epoch: 30
2022-11-28 04:27:23,933 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.532419366254048, 'Total loss': 0.532419366254048} | train loss {'Reaction outcome loss': 0.4646243344271375, 'Total loss': 0.4646243344271375}
2022-11-28 04:27:23,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:23,934 INFO:     Epoch: 31
2022-11-28 04:27:24,600 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4784632254053246, 'Total loss': 0.4784632254053246} | train loss {'Reaction outcome loss': 0.4658119920941611, 'Total loss': 0.4658119920941611}
2022-11-28 04:27:24,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:24,601 INFO:     Epoch: 32
2022-11-28 04:27:25,266 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4765302525325255, 'Total loss': 0.4765302525325255} | train loss {'Reaction outcome loss': 0.470902758980951, 'Total loss': 0.470902758980951}
2022-11-28 04:27:25,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:25,266 INFO:     Epoch: 33
2022-11-28 04:27:25,932 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4994397055019032, 'Total loss': 0.4994397055019032} | train loss {'Reaction outcome loss': 0.4631093559606421, 'Total loss': 0.4631093559606421}
2022-11-28 04:27:25,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:25,932 INFO:     Epoch: 34
2022-11-28 04:27:26,598 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46708517420020973, 'Total loss': 0.46708517420020973} | train loss {'Reaction outcome loss': 0.46730366595570116, 'Total loss': 0.46730366595570116}
2022-11-28 04:27:26,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:26,599 INFO:     Epoch: 35
2022-11-28 04:27:27,257 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4716305336491628, 'Total loss': 0.4716305336491628} | train loss {'Reaction outcome loss': 0.45995781540630326, 'Total loss': 0.45995781540630326}
2022-11-28 04:27:27,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:27,258 INFO:     Epoch: 36
2022-11-28 04:27:27,917 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5087735910307277, 'Total loss': 0.5087735910307277} | train loss {'Reaction outcome loss': 0.46383340236160064, 'Total loss': 0.46383340236160064}
2022-11-28 04:27:27,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:27,917 INFO:     Epoch: 37
2022-11-28 04:27:28,578 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.517079309983687, 'Total loss': 0.517079309983687} | train loss {'Reaction outcome loss': 0.4672129553772749, 'Total loss': 0.4672129553772749}
2022-11-28 04:27:28,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:28,578 INFO:     Epoch: 38
2022-11-28 04:27:29,238 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5097907402298667, 'Total loss': 0.5097907402298667} | train loss {'Reaction outcome loss': 0.4585866758659963, 'Total loss': 0.4585866758659963}
2022-11-28 04:27:29,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:29,238 INFO:     Epoch: 39
2022-11-28 04:27:29,899 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49580375647003, 'Total loss': 0.49580375647003} | train loss {'Reaction outcome loss': 0.46565076762870433, 'Total loss': 0.46565076762870433}
2022-11-28 04:27:29,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:29,899 INFO:     Epoch: 40
2022-11-28 04:27:30,556 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48406843773343344, 'Total loss': 0.48406843773343344} | train loss {'Reaction outcome loss': 0.4645541925584116, 'Total loss': 0.4645541925584116}
2022-11-28 04:27:30,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:30,556 INFO:     Epoch: 41
2022-11-28 04:27:31,212 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4866930104114793, 'Total loss': 0.4866930104114793} | train loss {'Reaction outcome loss': 0.4633410135584493, 'Total loss': 0.4633410135584493}
2022-11-28 04:27:31,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:31,213 INFO:     Epoch: 42
2022-11-28 04:27:31,870 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4839517850090157, 'Total loss': 0.4839517850090157} | train loss {'Reaction outcome loss': 0.46478590459352537, 'Total loss': 0.46478590459352537}
2022-11-28 04:27:31,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:31,870 INFO:     Epoch: 43
2022-11-28 04:27:32,526 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47134071453051135, 'Total loss': 0.47134071453051135} | train loss {'Reaction outcome loss': 0.4632769537669036, 'Total loss': 0.4632769537669036}
2022-11-28 04:27:32,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:32,527 INFO:     Epoch: 44
2022-11-28 04:27:33,185 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4624460908499631, 'Total loss': 0.4624460908499631} | train loss {'Reaction outcome loss': 0.46440475878696286, 'Total loss': 0.46440475878696286}
2022-11-28 04:27:33,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:33,185 INFO:     Epoch: 45
2022-11-28 04:27:33,845 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4879288178953258, 'Total loss': 0.4879288178953258} | train loss {'Reaction outcome loss': 0.4652719455620935, 'Total loss': 0.4652719455620935}
2022-11-28 04:27:33,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:33,845 INFO:     Epoch: 46
2022-11-28 04:27:34,505 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4719759269871495, 'Total loss': 0.4719759269871495} | train loss {'Reaction outcome loss': 0.45856647082274, 'Total loss': 0.45856647082274}
2022-11-28 04:27:34,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:34,506 INFO:     Epoch: 47
2022-11-28 04:27:35,166 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.506806109439243, 'Total loss': 0.506806109439243} | train loss {'Reaction outcome loss': 0.46497051634134784, 'Total loss': 0.46497051634134784}
2022-11-28 04:27:35,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:35,166 INFO:     Epoch: 48
2022-11-28 04:27:35,823 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4854771203615449, 'Total loss': 0.4854771203615449} | train loss {'Reaction outcome loss': 0.4645364483998668, 'Total loss': 0.4645364483998668}
2022-11-28 04:27:35,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:35,824 INFO:     Epoch: 49
2022-11-28 04:27:36,485 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48259499364278535, 'Total loss': 0.48259499364278535} | train loss {'Reaction outcome loss': 0.45907726992041836, 'Total loss': 0.45907726992041836}
2022-11-28 04:27:36,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:36,486 INFO:     Epoch: 50
2022-11-28 04:27:37,143 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46258211305195635, 'Total loss': 0.46258211305195635} | train loss {'Reaction outcome loss': 0.45879960156256155, 'Total loss': 0.45879960156256155}
2022-11-28 04:27:37,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:37,143 INFO:     Epoch: 51
2022-11-28 04:27:37,799 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4714162221009081, 'Total loss': 0.4714162221009081} | train loss {'Reaction outcome loss': 0.46580730330559517, 'Total loss': 0.46580730330559517}
2022-11-28 04:27:37,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:37,800 INFO:     Epoch: 52
2022-11-28 04:27:38,457 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47106522253968497, 'Total loss': 0.47106522253968497} | train loss {'Reaction outcome loss': 0.45562098103184856, 'Total loss': 0.45562098103184856}
2022-11-28 04:27:38,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:38,457 INFO:     Epoch: 53
2022-11-28 04:27:39,115 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4633512002500621, 'Total loss': 0.4633512002500621} | train loss {'Reaction outcome loss': 0.45609787473034474, 'Total loss': 0.45609787473034474}
2022-11-28 04:27:39,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:39,115 INFO:     Epoch: 54
2022-11-28 04:27:39,773 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4628011513162743, 'Total loss': 0.4628011513162743} | train loss {'Reaction outcome loss': 0.45701330783025873, 'Total loss': 0.45701330783025873}
2022-11-28 04:27:39,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:39,773 INFO:     Epoch: 55
2022-11-28 04:27:40,433 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5262683274393732, 'Total loss': 0.5262683274393732} | train loss {'Reaction outcome loss': 0.46203370650689446, 'Total loss': 0.46203370650689446}
2022-11-28 04:27:40,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:40,433 INFO:     Epoch: 56
2022-11-28 04:27:41,090 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48077554729851807, 'Total loss': 0.48077554729851807} | train loss {'Reaction outcome loss': 0.457414916446132, 'Total loss': 0.457414916446132}
2022-11-28 04:27:41,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:41,090 INFO:     Epoch: 57
2022-11-28 04:27:41,747 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46468204056674783, 'Total loss': 0.46468204056674783} | train loss {'Reaction outcome loss': 0.4636956902761613, 'Total loss': 0.4636956902761613}
2022-11-28 04:27:41,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:41,748 INFO:     Epoch: 58
2022-11-28 04:27:42,409 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.476526889950037, 'Total loss': 0.476526889950037} | train loss {'Reaction outcome loss': 0.4574274144345714, 'Total loss': 0.4574274144345714}
2022-11-28 04:27:42,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:42,409 INFO:     Epoch: 59
2022-11-28 04:27:43,068 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47187657857483084, 'Total loss': 0.47187657857483084} | train loss {'Reaction outcome loss': 0.4624536805035126, 'Total loss': 0.4624536805035126}
2022-11-28 04:27:43,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:43,068 INFO:     Epoch: 60
2022-11-28 04:27:43,728 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4782061475244435, 'Total loss': 0.4782061475244435} | train loss {'Reaction outcome loss': 0.4616281744693556, 'Total loss': 0.4616281744693556}
2022-11-28 04:27:43,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:43,728 INFO:     Epoch: 61
2022-11-28 04:27:44,386 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4727781902660023, 'Total loss': 0.4727781902660023} | train loss {'Reaction outcome loss': 0.46419455856084824, 'Total loss': 0.46419455856084824}
2022-11-28 04:27:44,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:44,386 INFO:     Epoch: 62
2022-11-28 04:27:45,042 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.527693176472729, 'Total loss': 0.527693176472729} | train loss {'Reaction outcome loss': 0.4578951325628065, 'Total loss': 0.4578951325628065}
2022-11-28 04:27:45,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:45,043 INFO:     Epoch: 63
2022-11-28 04:27:45,698 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49045440927147865, 'Total loss': 0.49045440927147865} | train loss {'Reaction outcome loss': 0.4586376780343632, 'Total loss': 0.4586376780343632}
2022-11-28 04:27:45,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:45,699 INFO:     Epoch: 64
2022-11-28 04:27:46,366 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4794151166623289, 'Total loss': 0.4794151166623289} | train loss {'Reaction outcome loss': 0.46020885040202447, 'Total loss': 0.46020885040202447}
2022-11-28 04:27:46,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:46,367 INFO:     Epoch: 65
2022-11-28 04:27:47,027 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4734065522524444, 'Total loss': 0.4734065522524444} | train loss {'Reaction outcome loss': 0.4625894846394658, 'Total loss': 0.4625894846394658}
2022-11-28 04:27:47,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:47,028 INFO:     Epoch: 66
2022-11-28 04:27:47,689 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5120826058767058, 'Total loss': 0.5120826058767058} | train loss {'Reaction outcome loss': 0.4680330643670694, 'Total loss': 0.4680330643670694}
2022-11-28 04:27:47,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:47,689 INFO:     Epoch: 67
2022-11-28 04:27:48,349 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4828598482364958, 'Total loss': 0.4828598482364958} | train loss {'Reaction outcome loss': 0.4662972245846064, 'Total loss': 0.4662972245846064}
2022-11-28 04:27:48,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:48,349 INFO:     Epoch: 68
2022-11-28 04:27:49,007 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4724001921713352, 'Total loss': 0.4724001921713352} | train loss {'Reaction outcome loss': 0.45686817571761146, 'Total loss': 0.45686817571761146}
2022-11-28 04:27:49,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:49,007 INFO:     Epoch: 69
2022-11-28 04:27:49,665 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4867828004062176, 'Total loss': 0.4867828004062176} | train loss {'Reaction outcome loss': 0.46273694205428323, 'Total loss': 0.46273694205428323}
2022-11-28 04:27:49,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:49,665 INFO:     Epoch: 70
2022-11-28 04:27:50,319 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4653154283084653, 'Total loss': 0.4653154283084653} | train loss {'Reaction outcome loss': 0.46249708271915874, 'Total loss': 0.46249708271915874}
2022-11-28 04:27:50,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:50,320 INFO:     Epoch: 71
2022-11-28 04:27:50,977 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45408144322308625, 'Total loss': 0.45408144322308625} | train loss {'Reaction outcome loss': 0.4606331699798184, 'Total loss': 0.4606331699798184}
2022-11-28 04:27:50,977 INFO:     Found new best model at epoch 71
2022-11-28 04:27:50,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:50,978 INFO:     Epoch: 72
2022-11-28 04:27:51,637 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4902760906314308, 'Total loss': 0.4902760906314308} | train loss {'Reaction outcome loss': 0.45579924906093267, 'Total loss': 0.45579924906093267}
2022-11-28 04:27:51,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:51,637 INFO:     Epoch: 73
2022-11-28 04:27:52,292 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48484381897882983, 'Total loss': 0.48484381897882983} | train loss {'Reaction outcome loss': 0.4579142865634734, 'Total loss': 0.4579142865634734}
2022-11-28 04:27:52,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:52,293 INFO:     Epoch: 74
2022-11-28 04:27:52,949 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49065604738213797, 'Total loss': 0.49065604738213797} | train loss {'Reaction outcome loss': 0.4614417990970035, 'Total loss': 0.4614417990970035}
2022-11-28 04:27:52,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:52,950 INFO:     Epoch: 75
2022-11-28 04:27:53,607 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5155308077281172, 'Total loss': 0.5155308077281172} | train loss {'Reaction outcome loss': 0.4563493419799112, 'Total loss': 0.4563493419799112}
2022-11-28 04:27:53,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:53,608 INFO:     Epoch: 76
2022-11-28 04:27:54,268 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48554170063950797, 'Total loss': 0.48554170063950797} | train loss {'Reaction outcome loss': 0.4706859700982609, 'Total loss': 0.4706859700982609}
2022-11-28 04:27:54,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:54,268 INFO:     Epoch: 77
2022-11-28 04:27:54,926 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45734538341110403, 'Total loss': 0.45734538341110403} | train loss {'Reaction outcome loss': 0.4611903904005885, 'Total loss': 0.4611903904005885}
2022-11-28 04:27:54,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:54,927 INFO:     Epoch: 78
2022-11-28 04:27:55,587 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5062532303008166, 'Total loss': 0.5062532303008166} | train loss {'Reaction outcome loss': 0.46314760558908025, 'Total loss': 0.46314760558908025}
2022-11-28 04:27:55,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:55,587 INFO:     Epoch: 79
2022-11-28 04:27:56,249 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48875363306565717, 'Total loss': 0.48875363306565717} | train loss {'Reaction outcome loss': 0.4548274475420194, 'Total loss': 0.4548274475420194}
2022-11-28 04:27:56,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:56,250 INFO:     Epoch: 80
2022-11-28 04:27:56,913 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47082417424429546, 'Total loss': 0.47082417424429546} | train loss {'Reaction outcome loss': 0.46485074525398595, 'Total loss': 0.46485074525398595}
2022-11-28 04:27:56,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:56,913 INFO:     Epoch: 81
2022-11-28 04:27:57,576 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4706679829819636, 'Total loss': 0.4706679829819636} | train loss {'Reaction outcome loss': 0.4612182505849388, 'Total loss': 0.4612182505849388}
2022-11-28 04:27:57,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:57,576 INFO:     Epoch: 82
2022-11-28 04:27:58,236 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4547474015165459, 'Total loss': 0.4547474015165459} | train loss {'Reaction outcome loss': 0.46220732312048635, 'Total loss': 0.46220732312048635}
2022-11-28 04:27:58,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:58,236 INFO:     Epoch: 83
2022-11-28 04:27:58,895 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47531126642769034, 'Total loss': 0.47531126642769034} | train loss {'Reaction outcome loss': 0.4605075567359886, 'Total loss': 0.4605075567359886}
2022-11-28 04:27:58,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:58,895 INFO:     Epoch: 84
2022-11-28 04:27:59,561 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4785009544681419, 'Total loss': 0.4785009544681419} | train loss {'Reaction outcome loss': 0.457249725838342, 'Total loss': 0.457249725838342}
2022-11-28 04:27:59,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:27:59,561 INFO:     Epoch: 85
2022-11-28 04:28:00,226 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4501239183274182, 'Total loss': 0.4501239183274182} | train loss {'Reaction outcome loss': 0.46244823782434386, 'Total loss': 0.46244823782434386}
2022-11-28 04:28:00,226 INFO:     Found new best model at epoch 85
2022-11-28 04:28:00,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:00,227 INFO:     Epoch: 86
2022-11-28 04:28:00,888 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49492453919215634, 'Total loss': 0.49492453919215634} | train loss {'Reaction outcome loss': 0.4664356323980516, 'Total loss': 0.4664356323980516}
2022-11-28 04:28:00,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:00,888 INFO:     Epoch: 87
2022-11-28 04:28:01,549 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48323732309720735, 'Total loss': 0.48323732309720735} | train loss {'Reaction outcome loss': 0.4521378408516607, 'Total loss': 0.4521378408516607}
2022-11-28 04:28:01,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:01,550 INFO:     Epoch: 88
2022-11-28 04:28:02,210 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4807067361067642, 'Total loss': 0.4807067361067642} | train loss {'Reaction outcome loss': 0.46446390209659455, 'Total loss': 0.46446390209659455}
2022-11-28 04:28:02,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:02,211 INFO:     Epoch: 89
2022-11-28 04:28:02,875 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5022427233105357, 'Total loss': 0.5022427233105357} | train loss {'Reaction outcome loss': 0.4559797951651196, 'Total loss': 0.4559797951651196}
2022-11-28 04:28:02,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:02,875 INFO:     Epoch: 90
2022-11-28 04:28:03,540 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47881589050997386, 'Total loss': 0.47881589050997386} | train loss {'Reaction outcome loss': 0.47000206964871577, 'Total loss': 0.47000206964871577}
2022-11-28 04:28:03,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:03,540 INFO:     Epoch: 91
2022-11-28 04:28:04,203 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48814301091161644, 'Total loss': 0.48814301091161644} | train loss {'Reaction outcome loss': 0.4551663744834162, 'Total loss': 0.4551663744834162}
2022-11-28 04:28:04,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:04,203 INFO:     Epoch: 92
2022-11-28 04:28:04,862 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4746792611073364, 'Total loss': 0.4746792611073364} | train loss {'Reaction outcome loss': 0.46593170156401975, 'Total loss': 0.46593170156401975}
2022-11-28 04:28:04,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:04,862 INFO:     Epoch: 93
2022-11-28 04:28:05,523 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4941916966980154, 'Total loss': 0.4941916966980154} | train loss {'Reaction outcome loss': 0.46121667307471076, 'Total loss': 0.46121667307471076}
2022-11-28 04:28:05,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:05,524 INFO:     Epoch: 94
2022-11-28 04:28:06,184 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4710426689548926, 'Total loss': 0.4710426689548926} | train loss {'Reaction outcome loss': 0.4597666163237826, 'Total loss': 0.4597666163237826}
2022-11-28 04:28:06,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:06,184 INFO:     Epoch: 95
2022-11-28 04:28:06,843 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4653719568794424, 'Total loss': 0.4653719568794424} | train loss {'Reaction outcome loss': 0.46064007029898707, 'Total loss': 0.46064007029898707}
2022-11-28 04:28:06,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:06,843 INFO:     Epoch: 96
2022-11-28 04:28:07,500 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4562198594212532, 'Total loss': 0.4562198594212532} | train loss {'Reaction outcome loss': 0.4674859009683132, 'Total loss': 0.4674859009683132}
2022-11-28 04:28:07,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:07,501 INFO:     Epoch: 97
2022-11-28 04:28:08,161 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4858312511985952, 'Total loss': 0.4858312511985952} | train loss {'Reaction outcome loss': 0.46501879970873555, 'Total loss': 0.46501879970873555}
2022-11-28 04:28:08,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:08,161 INFO:     Epoch: 98
2022-11-28 04:28:08,824 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4653863581744107, 'Total loss': 0.4653863581744107} | train loss {'Reaction outcome loss': 0.46449978763778366, 'Total loss': 0.46449978763778366}
2022-11-28 04:28:08,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:08,824 INFO:     Epoch: 99
2022-11-28 04:28:09,483 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5249459066174247, 'Total loss': 0.5249459066174247} | train loss {'Reaction outcome loss': 0.4617420493835403, 'Total loss': 0.4617420493835403}
2022-11-28 04:28:09,483 INFO:     Best model found after epoch 86 of 100.
2022-11-28 04:28:09,483 INFO:   Done with stage: TRAINING
2022-11-28 04:28:09,483 INFO:   Starting stage: EVALUATION
2022-11-28 04:28:09,597 INFO:   Done with stage: EVALUATION
2022-11-28 04:28:09,597 INFO:   Leaving out SEQ value Fold_6
2022-11-28 04:28:09,610 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:28:09,610 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:28:10,252 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:28:10,252 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:28:10,320 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:28:10,320 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:28:10,320 INFO:     No hyperparam tuning for this model
2022-11-28 04:28:10,320 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:28:10,320 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:28:10,321 INFO:     None feature selector for col prot
2022-11-28 04:28:10,321 INFO:     None feature selector for col prot
2022-11-28 04:28:10,321 INFO:     None feature selector for col prot
2022-11-28 04:28:10,321 INFO:     None feature selector for col chem
2022-11-28 04:28:10,321 INFO:     None feature selector for col chem
2022-11-28 04:28:10,322 INFO:     None feature selector for col chem
2022-11-28 04:28:10,322 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:28:10,322 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:28:10,323 INFO:     Number of params in model 169651
2022-11-28 04:28:10,326 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:28:10,326 INFO:   Starting stage: TRAINING
2022-11-28 04:28:10,377 INFO:     Val loss before train {'Reaction outcome loss': 1.0411984351548282, 'Total loss': 1.0411984351548282}
2022-11-28 04:28:10,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:10,377 INFO:     Epoch: 0
2022-11-28 04:28:11,036 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.600211045958779, 'Total loss': 0.600211045958779} | train loss {'Reaction outcome loss': 0.6867531097912596, 'Total loss': 0.6867531097912596}
2022-11-28 04:28:11,036 INFO:     Found new best model at epoch 0
2022-11-28 04:28:11,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:11,037 INFO:     Epoch: 1
2022-11-28 04:28:11,694 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5596847276795994, 'Total loss': 0.5596847276795994} | train loss {'Reaction outcome loss': 0.5777742320649054, 'Total loss': 0.5777742320649054}
2022-11-28 04:28:11,694 INFO:     Found new best model at epoch 1
2022-11-28 04:28:11,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:11,694 INFO:     Epoch: 2
2022-11-28 04:28:12,351 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5832967416129329, 'Total loss': 0.5832967416129329} | train loss {'Reaction outcome loss': 0.5522653726551697, 'Total loss': 0.5522653726551697}
2022-11-28 04:28:12,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:12,351 INFO:     Epoch: 3
2022-11-28 04:28:13,009 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5117082958194342, 'Total loss': 0.5117082958194342} | train loss {'Reaction outcome loss': 0.5366359227883671, 'Total loss': 0.5366359227883671}
2022-11-28 04:28:13,010 INFO:     Found new best model at epoch 3
2022-11-28 04:28:13,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:13,010 INFO:     Epoch: 4
2022-11-28 04:28:13,664 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5284304730594158, 'Total loss': 0.5284304730594158} | train loss {'Reaction outcome loss': 0.5148570479350052, 'Total loss': 0.5148570479350052}
2022-11-28 04:28:13,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:13,664 INFO:     Epoch: 5
2022-11-28 04:28:14,321 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4914253042502837, 'Total loss': 0.4914253042502837} | train loss {'Reaction outcome loss': 0.5029041994559137, 'Total loss': 0.5029041994559137}
2022-11-28 04:28:14,321 INFO:     Found new best model at epoch 5
2022-11-28 04:28:14,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:14,322 INFO:     Epoch: 6
2022-11-28 04:28:14,980 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5086717111143199, 'Total loss': 0.5086717111143199} | train loss {'Reaction outcome loss': 0.4982891246857431, 'Total loss': 0.4982891246857431}
2022-11-28 04:28:14,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:14,981 INFO:     Epoch: 7
2022-11-28 04:28:15,640 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4972120719877156, 'Total loss': 0.4972120719877156} | train loss {'Reaction outcome loss': 0.4906493892764997, 'Total loss': 0.4906493892764997}
2022-11-28 04:28:15,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:15,641 INFO:     Epoch: 8
2022-11-28 04:28:16,299 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5014952624386008, 'Total loss': 0.5014952624386008} | train loss {'Reaction outcome loss': 0.4885671748082165, 'Total loss': 0.4885671748082165}
2022-11-28 04:28:16,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:16,299 INFO:     Epoch: 9
2022-11-28 04:28:16,954 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49508589201352815, 'Total loss': 0.49508589201352815} | train loss {'Reaction outcome loss': 0.48813607605543696, 'Total loss': 0.48813607605543696}
2022-11-28 04:28:16,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:16,954 INFO:     Epoch: 10
2022-11-28 04:28:17,610 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.481584950604222, 'Total loss': 0.481584950604222} | train loss {'Reaction outcome loss': 0.4806130731757353, 'Total loss': 0.4806130731757353}
2022-11-28 04:28:17,610 INFO:     Found new best model at epoch 10
2022-11-28 04:28:17,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:17,611 INFO:     Epoch: 11
2022-11-28 04:28:18,264 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4813927970826626, 'Total loss': 0.4813927970826626} | train loss {'Reaction outcome loss': 0.4757387632964111, 'Total loss': 0.4757387632964111}
2022-11-28 04:28:18,264 INFO:     Found new best model at epoch 11
2022-11-28 04:28:18,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:18,265 INFO:     Epoch: 12
2022-11-28 04:28:18,921 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47519800947471097, 'Total loss': 0.47519800947471097} | train loss {'Reaction outcome loss': 0.47267075243447476, 'Total loss': 0.47267075243447476}
2022-11-28 04:28:18,921 INFO:     Found new best model at epoch 12
2022-11-28 04:28:18,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:18,922 INFO:     Epoch: 13
2022-11-28 04:28:19,579 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4627454037016088, 'Total loss': 0.4627454037016088} | train loss {'Reaction outcome loss': 0.47084916072335803, 'Total loss': 0.47084916072335803}
2022-11-28 04:28:19,579 INFO:     Found new best model at epoch 13
2022-11-28 04:28:19,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:19,580 INFO:     Epoch: 14
2022-11-28 04:28:20,234 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5159634267064658, 'Total loss': 0.5159634267064658} | train loss {'Reaction outcome loss': 0.4754145539361938, 'Total loss': 0.4754145539361938}
2022-11-28 04:28:20,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:20,235 INFO:     Epoch: 15
2022-11-28 04:28:20,890 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48067374391989276, 'Total loss': 0.48067374391989276} | train loss {'Reaction outcome loss': 0.47513384483603816, 'Total loss': 0.47513384483603816}
2022-11-28 04:28:20,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:20,891 INFO:     Epoch: 16
2022-11-28 04:28:21,549 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4585535758259622, 'Total loss': 0.4585535758259622} | train loss {'Reaction outcome loss': 0.4650528810405538, 'Total loss': 0.4650528810405538}
2022-11-28 04:28:21,549 INFO:     Found new best model at epoch 16
2022-11-28 04:28:21,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:21,550 INFO:     Epoch: 17
2022-11-28 04:28:22,204 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5252347571605985, 'Total loss': 0.5252347571605985} | train loss {'Reaction outcome loss': 0.47209980384058314, 'Total loss': 0.47209980384058314}
2022-11-28 04:28:22,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:22,204 INFO:     Epoch: 18
2022-11-28 04:28:22,858 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.493745891885324, 'Total loss': 0.493745891885324} | train loss {'Reaction outcome loss': 0.4683812466951517, 'Total loss': 0.4683812466951517}
2022-11-28 04:28:22,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:22,858 INFO:     Epoch: 19
2022-11-28 04:28:23,513 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45406127043745736, 'Total loss': 0.45406127043745736} | train loss {'Reaction outcome loss': 0.46231536876395163, 'Total loss': 0.46231536876395163}
2022-11-28 04:28:23,513 INFO:     Found new best model at epoch 19
2022-11-28 04:28:23,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:23,514 INFO:     Epoch: 20
2022-11-28 04:28:24,166 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49932746453718707, 'Total loss': 0.49932746453718707} | train loss {'Reaction outcome loss': 0.45318734649991094, 'Total loss': 0.45318734649991094}
2022-11-28 04:28:24,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:24,167 INFO:     Epoch: 21
2022-11-28 04:28:24,818 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48755569044839253, 'Total loss': 0.48755569044839253} | train loss {'Reaction outcome loss': 0.4710307346302488, 'Total loss': 0.4710307346302488}
2022-11-28 04:28:24,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:24,818 INFO:     Epoch: 22
2022-11-28 04:28:25,478 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4986653805456378, 'Total loss': 0.4986653805456378} | train loss {'Reaction outcome loss': 0.48529270719661405, 'Total loss': 0.48529270719661405}
2022-11-28 04:28:25,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:25,478 INFO:     Epoch: 23
2022-11-28 04:28:26,131 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4687304246154698, 'Total loss': 0.4687304246154698} | train loss {'Reaction outcome loss': 0.4620546746569184, 'Total loss': 0.4620546746569184}
2022-11-28 04:28:26,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:26,132 INFO:     Epoch: 24
2022-11-28 04:28:26,787 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4765049733898856, 'Total loss': 0.4765049733898856} | train loss {'Reaction outcome loss': 0.45959418197633767, 'Total loss': 0.45959418197633767}
2022-11-28 04:28:26,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:26,787 INFO:     Epoch: 25
2022-11-28 04:28:27,444 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47031247141686355, 'Total loss': 0.47031247141686355} | train loss {'Reaction outcome loss': 0.4645573152945592, 'Total loss': 0.4645573152945592}
2022-11-28 04:28:27,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:27,444 INFO:     Epoch: 26
2022-11-28 04:28:28,098 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49413534152236854, 'Total loss': 0.49413534152236854} | train loss {'Reaction outcome loss': 0.4878059550818161, 'Total loss': 0.4878059550818161}
2022-11-28 04:28:28,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:28,098 INFO:     Epoch: 27
2022-11-28 04:28:28,753 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46069480885158887, 'Total loss': 0.46069480885158887} | train loss {'Reaction outcome loss': 0.4633401707719695, 'Total loss': 0.4633401707719695}
2022-11-28 04:28:28,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:28,753 INFO:     Epoch: 28
2022-11-28 04:28:29,409 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45230099016969855, 'Total loss': 0.45230099016969855} | train loss {'Reaction outcome loss': 0.4583825838227986, 'Total loss': 0.4583825838227986}
2022-11-28 04:28:29,409 INFO:     Found new best model at epoch 28
2022-11-28 04:28:29,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:29,410 INFO:     Epoch: 29
2022-11-28 04:28:30,064 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4945928884500807, 'Total loss': 0.4945928884500807} | train loss {'Reaction outcome loss': 0.46040970810994447, 'Total loss': 0.46040970810994447}
2022-11-28 04:28:30,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:30,064 INFO:     Epoch: 30
2022-11-28 04:28:30,721 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47852615029974416, 'Total loss': 0.47852615029974416} | train loss {'Reaction outcome loss': 0.4639480656563391, 'Total loss': 0.4639480656563391}
2022-11-28 04:28:30,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:30,721 INFO:     Epoch: 31
2022-11-28 04:28:31,379 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44240228967233136, 'Total loss': 0.44240228967233136} | train loss {'Reaction outcome loss': 0.45670329609335314, 'Total loss': 0.45670329609335314}
2022-11-28 04:28:31,379 INFO:     Found new best model at epoch 31
2022-11-28 04:28:31,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:31,379 INFO:     Epoch: 32
2022-11-28 04:28:32,039 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46328739009120246, 'Total loss': 0.46328739009120246} | train loss {'Reaction outcome loss': 0.45873615097420417, 'Total loss': 0.45873615097420417}
2022-11-28 04:28:32,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:32,039 INFO:     Epoch: 33
2022-11-28 04:28:32,695 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4599497572264888, 'Total loss': 0.4599497572264888} | train loss {'Reaction outcome loss': 0.4523028733759274, 'Total loss': 0.4523028733759274}
2022-11-28 04:28:32,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:32,696 INFO:     Epoch: 34
2022-11-28 04:28:33,352 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49327197061343625, 'Total loss': 0.49327197061343625} | train loss {'Reaction outcome loss': 0.4524971740508852, 'Total loss': 0.4524971740508852}
2022-11-28 04:28:33,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:33,352 INFO:     Epoch: 35
2022-11-28 04:28:34,005 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46590573916381056, 'Total loss': 0.46590573916381056} | train loss {'Reaction outcome loss': 0.46387339374314435, 'Total loss': 0.46387339374314435}
2022-11-28 04:28:34,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:34,006 INFO:     Epoch: 36
2022-11-28 04:28:34,658 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4669796506112272, 'Total loss': 0.4669796506112272} | train loss {'Reaction outcome loss': 0.46510091110279683, 'Total loss': 0.46510091110279683}
2022-11-28 04:28:34,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:34,658 INFO:     Epoch: 37
2022-11-28 04:28:35,314 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4680243507027626, 'Total loss': 0.4680243507027626} | train loss {'Reaction outcome loss': 0.4617568846897558, 'Total loss': 0.4617568846897558}
2022-11-28 04:28:35,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:35,314 INFO:     Epoch: 38
2022-11-28 04:28:35,969 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4786361147734252, 'Total loss': 0.4786361147734252} | train loss {'Reaction outcome loss': 0.45426377340366964, 'Total loss': 0.45426377340366964}
2022-11-28 04:28:35,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:35,970 INFO:     Epoch: 39
2022-11-28 04:28:36,626 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5261569937521761, 'Total loss': 0.5261569937521761} | train loss {'Reaction outcome loss': 0.4588424484980734, 'Total loss': 0.4588424484980734}
2022-11-28 04:28:36,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:36,626 INFO:     Epoch: 40
2022-11-28 04:28:37,282 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4969948709688403, 'Total loss': 0.4969948709688403} | train loss {'Reaction outcome loss': 0.4598114368042, 'Total loss': 0.4598114368042}
2022-11-28 04:28:37,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:37,282 INFO:     Epoch: 41
2022-11-28 04:28:37,939 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4646608399396593, 'Total loss': 0.4646608399396593} | train loss {'Reaction outcome loss': 0.45781996598851826, 'Total loss': 0.45781996598851826}
2022-11-28 04:28:37,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:37,939 INFO:     Epoch: 42
2022-11-28 04:28:38,592 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4694677239114588, 'Total loss': 0.4694677239114588} | train loss {'Reaction outcome loss': 0.46681616078828453, 'Total loss': 0.46681616078828453}
2022-11-28 04:28:38,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:38,592 INFO:     Epoch: 43
2022-11-28 04:28:39,244 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4667832654985515, 'Total loss': 0.4667832654985515} | train loss {'Reaction outcome loss': 0.4538716893253833, 'Total loss': 0.4538716893253833}
2022-11-28 04:28:39,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:39,245 INFO:     Epoch: 44
2022-11-28 04:28:39,898 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4688018594275821, 'Total loss': 0.4688018594275821} | train loss {'Reaction outcome loss': 0.4508013897217237, 'Total loss': 0.4508013897217237}
2022-11-28 04:28:39,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:39,898 INFO:     Epoch: 45
2022-11-28 04:28:40,552 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4577182439917868, 'Total loss': 0.4577182439917868} | train loss {'Reaction outcome loss': 0.45703335788085875, 'Total loss': 0.45703335788085875}
2022-11-28 04:28:40,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:40,552 INFO:     Epoch: 46
2022-11-28 04:28:41,208 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4796914593739943, 'Total loss': 0.4796914593739943} | train loss {'Reaction outcome loss': 0.4610980407067156, 'Total loss': 0.4610980407067156}
2022-11-28 04:28:41,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:41,208 INFO:     Epoch: 47
2022-11-28 04:28:41,863 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4444914013147354, 'Total loss': 0.4444914013147354} | train loss {'Reaction outcome loss': 0.45493408383024847, 'Total loss': 0.45493408383024847}
2022-11-28 04:28:41,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:41,863 INFO:     Epoch: 48
2022-11-28 04:28:42,521 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5245312963697043, 'Total loss': 0.5245312963697043} | train loss {'Reaction outcome loss': 0.45788509884343936, 'Total loss': 0.45788509884343936}
2022-11-28 04:28:42,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:42,521 INFO:     Epoch: 49
2022-11-28 04:28:43,175 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4747180877761407, 'Total loss': 0.4747180877761407} | train loss {'Reaction outcome loss': 0.45187929755280376, 'Total loss': 0.45187929755280376}
2022-11-28 04:28:43,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:43,175 INFO:     Epoch: 50
2022-11-28 04:28:43,832 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45229515501044015, 'Total loss': 0.45229515501044015} | train loss {'Reaction outcome loss': 0.45485522794096095, 'Total loss': 0.45485522794096095}
2022-11-28 04:28:43,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:43,832 INFO:     Epoch: 51
2022-11-28 04:28:44,489 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4599507213993506, 'Total loss': 0.4599507213993506} | train loss {'Reaction outcome loss': 0.4498075222377835, 'Total loss': 0.4498075222377835}
2022-11-28 04:28:44,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:44,489 INFO:     Epoch: 52
2022-11-28 04:28:45,146 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4655944026837295, 'Total loss': 0.4655944026837295} | train loss {'Reaction outcome loss': 0.45104369766732605, 'Total loss': 0.45104369766732605}
2022-11-28 04:28:45,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:45,147 INFO:     Epoch: 53
2022-11-28 04:28:45,802 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4574721801010045, 'Total loss': 0.4574721801010045} | train loss {'Reaction outcome loss': 0.4441966317624216, 'Total loss': 0.4441966317624216}
2022-11-28 04:28:45,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:45,802 INFO:     Epoch: 54
2022-11-28 04:28:46,460 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49593341147357767, 'Total loss': 0.49593341147357767} | train loss {'Reaction outcome loss': 0.45791377054776256, 'Total loss': 0.45791377054776256}
2022-11-28 04:28:46,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:46,460 INFO:     Epoch: 55
2022-11-28 04:28:47,113 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4865271107039668, 'Total loss': 0.4865271107039668} | train loss {'Reaction outcome loss': 0.4662204997742224, 'Total loss': 0.4662204997742224}
2022-11-28 04:28:47,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:47,114 INFO:     Epoch: 56
2022-11-28 04:28:47,772 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5003060393712737, 'Total loss': 0.5003060393712737} | train loss {'Reaction outcome loss': 0.457768110294453, 'Total loss': 0.457768110294453}
2022-11-28 04:28:47,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:47,772 INFO:     Epoch: 57
2022-11-28 04:28:48,426 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4792389962822199, 'Total loss': 0.4792389962822199} | train loss {'Reaction outcome loss': 0.4517732247830885, 'Total loss': 0.4517732247830885}
2022-11-28 04:28:48,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:48,427 INFO:     Epoch: 58
2022-11-28 04:28:49,086 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5223541967570782, 'Total loss': 0.5223541967570782} | train loss {'Reaction outcome loss': 0.4616482666870843, 'Total loss': 0.4616482666870843}
2022-11-28 04:28:49,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:49,086 INFO:     Epoch: 59
2022-11-28 04:28:49,740 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5922101946039633, 'Total loss': 0.5922101946039633} | train loss {'Reaction outcome loss': 0.4573047717935161, 'Total loss': 0.4573047717935161}
2022-11-28 04:28:49,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:49,741 INFO:     Epoch: 60
2022-11-28 04:28:50,395 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4685918820852583, 'Total loss': 0.4685918820852583} | train loss {'Reaction outcome loss': 0.4661929863787856, 'Total loss': 0.4661929863787856}
2022-11-28 04:28:50,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:50,395 INFO:     Epoch: 61
2022-11-28 04:28:51,055 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4638619978319515, 'Total loss': 0.4638619978319515} | train loss {'Reaction outcome loss': 0.4525682359692539, 'Total loss': 0.4525682359692539}
2022-11-28 04:28:51,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:51,056 INFO:     Epoch: 62
2022-11-28 04:28:51,713 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47364299575036223, 'Total loss': 0.47364299575036223} | train loss {'Reaction outcome loss': 0.4515199442846542, 'Total loss': 0.4515199442846542}
2022-11-28 04:28:51,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:51,714 INFO:     Epoch: 63
2022-11-28 04:28:52,370 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48028015514666383, 'Total loss': 0.48028015514666383} | train loss {'Reaction outcome loss': 0.452736012004165, 'Total loss': 0.452736012004165}
2022-11-28 04:28:52,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:52,370 INFO:     Epoch: 64
2022-11-28 04:28:53,024 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45619183440100064, 'Total loss': 0.45619183440100064} | train loss {'Reaction outcome loss': 0.45666713846719215, 'Total loss': 0.45666713846719215}
2022-11-28 04:28:53,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:53,024 INFO:     Epoch: 65
2022-11-28 04:28:53,681 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4917698929255659, 'Total loss': 0.4917698929255659} | train loss {'Reaction outcome loss': 0.449845736946247, 'Total loss': 0.449845736946247}
2022-11-28 04:28:53,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:53,681 INFO:     Epoch: 66
2022-11-28 04:28:54,336 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46429160372777417, 'Total loss': 0.46429160372777417} | train loss {'Reaction outcome loss': 0.44229715799739366, 'Total loss': 0.44229715799739366}
2022-11-28 04:28:54,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:54,336 INFO:     Epoch: 67
2022-11-28 04:28:54,993 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46716834807937796, 'Total loss': 0.46716834807937796} | train loss {'Reaction outcome loss': 0.45396455235568134, 'Total loss': 0.45396455235568134}
2022-11-28 04:28:54,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:54,993 INFO:     Epoch: 68
2022-11-28 04:28:55,651 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4407129714434797, 'Total loss': 0.4407129714434797} | train loss {'Reaction outcome loss': 0.45046014824376895, 'Total loss': 0.45046014824376895}
2022-11-28 04:28:55,651 INFO:     Found new best model at epoch 68
2022-11-28 04:28:55,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:55,652 INFO:     Epoch: 69
2022-11-28 04:28:56,306 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44480534676801076, 'Total loss': 0.44480534676801076} | train loss {'Reaction outcome loss': 0.45149177721577133, 'Total loss': 0.45149177721577133}
2022-11-28 04:28:56,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:56,307 INFO:     Epoch: 70
2022-11-28 04:28:56,966 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5121535056016662, 'Total loss': 0.5121535056016662} | train loss {'Reaction outcome loss': 0.45654630516222133, 'Total loss': 0.45654630516222133}
2022-11-28 04:28:56,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:56,966 INFO:     Epoch: 71
2022-11-28 04:28:57,627 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5127604099159891, 'Total loss': 0.5127604099159891} | train loss {'Reaction outcome loss': 0.45529317746348, 'Total loss': 0.45529317746348}
2022-11-28 04:28:57,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:57,627 INFO:     Epoch: 72
2022-11-28 04:28:58,290 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48441037332469766, 'Total loss': 0.48441037332469766} | train loss {'Reaction outcome loss': 0.4515273762670787, 'Total loss': 0.4515273762670787}
2022-11-28 04:28:58,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:58,290 INFO:     Epoch: 73
2022-11-28 04:28:58,952 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45195008983666246, 'Total loss': 0.45195008983666246} | train loss {'Reaction outcome loss': 0.4529172974499131, 'Total loss': 0.4529172974499131}
2022-11-28 04:28:58,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:58,952 INFO:     Epoch: 74
2022-11-28 04:28:59,612 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4660796926102855, 'Total loss': 0.4660796926102855} | train loss {'Reaction outcome loss': 0.45744258632906054, 'Total loss': 0.45744258632906054}
2022-11-28 04:28:59,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:28:59,612 INFO:     Epoch: 75
2022-11-28 04:29:00,273 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48537127673625946, 'Total loss': 0.48537127673625946} | train loss {'Reaction outcome loss': 0.4589933337349641, 'Total loss': 0.4589933337349641}
2022-11-28 04:29:00,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:00,273 INFO:     Epoch: 76
2022-11-28 04:29:00,934 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4921938942914659, 'Total loss': 0.4921938942914659} | train loss {'Reaction outcome loss': 0.4541175313867055, 'Total loss': 0.4541175313867055}
2022-11-28 04:29:00,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:00,934 INFO:     Epoch: 77
2022-11-28 04:29:01,595 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4575470489534465, 'Total loss': 0.4575470489534465} | train loss {'Reaction outcome loss': 0.46412944582551113, 'Total loss': 0.46412944582551113}
2022-11-28 04:29:01,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:01,595 INFO:     Epoch: 78
2022-11-28 04:29:02,254 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4726094420660626, 'Total loss': 0.4726094420660626} | train loss {'Reaction outcome loss': 0.4561996462977367, 'Total loss': 0.4561996462977367}
2022-11-28 04:29:02,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:02,254 INFO:     Epoch: 79
2022-11-28 04:29:02,917 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.423908837816932, 'Total loss': 0.423908837816932} | train loss {'Reaction outcome loss': 0.4556354889985521, 'Total loss': 0.4556354889985521}
2022-11-28 04:29:02,917 INFO:     Found new best model at epoch 79
2022-11-28 04:29:02,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:02,918 INFO:     Epoch: 80
2022-11-28 04:29:03,580 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4842402291568843, 'Total loss': 0.4842402291568843} | train loss {'Reaction outcome loss': 0.45495054584283096, 'Total loss': 0.45495054584283096}
2022-11-28 04:29:03,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:03,580 INFO:     Epoch: 81
2022-11-28 04:29:04,241 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4569227583706379, 'Total loss': 0.4569227583706379} | train loss {'Reaction outcome loss': 0.46000151353867474, 'Total loss': 0.46000151353867474}
2022-11-28 04:29:04,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:04,242 INFO:     Epoch: 82
2022-11-28 04:29:04,906 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47572729804299096, 'Total loss': 0.47572729804299096} | train loss {'Reaction outcome loss': 0.4581737897475721, 'Total loss': 0.4581737897475721}
2022-11-28 04:29:04,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:04,907 INFO:     Epoch: 83
2022-11-28 04:29:05,569 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.473650376227769, 'Total loss': 0.473650376227769} | train loss {'Reaction outcome loss': 0.4616903067540061, 'Total loss': 0.4616903067540061}
2022-11-28 04:29:05,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:05,569 INFO:     Epoch: 84
2022-11-28 04:29:06,230 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46166172792965715, 'Total loss': 0.46166172792965715} | train loss {'Reaction outcome loss': 0.4652525054419089, 'Total loss': 0.4652525054419089}
2022-11-28 04:29:06,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:06,230 INFO:     Epoch: 85
2022-11-28 04:29:06,892 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4854237718338316, 'Total loss': 0.4854237718338316} | train loss {'Reaction outcome loss': 0.5185097046950569, 'Total loss': 0.5185097046950569}
2022-11-28 04:29:06,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:06,893 INFO:     Epoch: 86
2022-11-28 04:29:07,555 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4574246751991185, 'Total loss': 0.4574246751991185} | train loss {'Reaction outcome loss': 0.4876709821735799, 'Total loss': 0.4876709821735799}
2022-11-28 04:29:07,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:07,555 INFO:     Epoch: 87
2022-11-28 04:29:08,216 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43750210174105386, 'Total loss': 0.43750210174105386} | train loss {'Reaction outcome loss': 0.4580563175669204, 'Total loss': 0.4580563175669204}
2022-11-28 04:29:08,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:08,216 INFO:     Epoch: 88
2022-11-28 04:29:08,876 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4783228388564153, 'Total loss': 0.4783228388564153} | train loss {'Reaction outcome loss': 0.4531834248589118, 'Total loss': 0.4531834248589118}
2022-11-28 04:29:08,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:08,877 INFO:     Epoch: 89
2022-11-28 04:29:09,539 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4631423902782527, 'Total loss': 0.4631423902782527} | train loss {'Reaction outcome loss': 0.4587566058645364, 'Total loss': 0.4587566058645364}
2022-11-28 04:29:09,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:09,540 INFO:     Epoch: 90
2022-11-28 04:29:10,201 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4391792883927172, 'Total loss': 0.4391792883927172} | train loss {'Reaction outcome loss': 0.4600761354210888, 'Total loss': 0.4600761354210888}
2022-11-28 04:29:10,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:10,201 INFO:     Epoch: 91
2022-11-28 04:29:10,859 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4834159399298104, 'Total loss': 0.4834159399298104} | train loss {'Reaction outcome loss': 0.45242171036268053, 'Total loss': 0.45242171036268053}
2022-11-28 04:29:10,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:10,860 INFO:     Epoch: 92
2022-11-28 04:29:11,520 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5416803339665587, 'Total loss': 0.5416803339665587} | train loss {'Reaction outcome loss': 0.45347332767388115, 'Total loss': 0.45347332767388115}
2022-11-28 04:29:11,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:11,520 INFO:     Epoch: 93
2022-11-28 04:29:12,182 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4635951383547349, 'Total loss': 0.4635951383547349} | train loss {'Reaction outcome loss': 0.4644582903819528, 'Total loss': 0.4644582903819528}
2022-11-28 04:29:12,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:12,182 INFO:     Epoch: 94
2022-11-28 04:29:12,844 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4593858021226796, 'Total loss': 0.4593858021226796} | train loss {'Reaction outcome loss': 0.45453712120953843, 'Total loss': 0.45453712120953843}
2022-11-28 04:29:12,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:12,844 INFO:     Epoch: 95
2022-11-28 04:29:13,503 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5464901226488027, 'Total loss': 0.5464901226488027} | train loss {'Reaction outcome loss': 0.4522775012381405, 'Total loss': 0.4522775012381405}
2022-11-28 04:29:13,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:13,503 INFO:     Epoch: 96
2022-11-28 04:29:14,164 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5087227228690278, 'Total loss': 0.5087227228690278} | train loss {'Reaction outcome loss': 0.45263979225023554, 'Total loss': 0.45263979225023554}
2022-11-28 04:29:14,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:14,164 INFO:     Epoch: 97
2022-11-28 04:29:14,825 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4578284580599178, 'Total loss': 0.4578284580599178} | train loss {'Reaction outcome loss': 0.46221870352864747, 'Total loss': 0.46221870352864747}
2022-11-28 04:29:14,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:14,825 INFO:     Epoch: 98
2022-11-28 04:29:15,485 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45066173848780716, 'Total loss': 0.45066173848780716} | train loss {'Reaction outcome loss': 0.4576364023241437, 'Total loss': 0.4576364023241437}
2022-11-28 04:29:15,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:15,486 INFO:     Epoch: 99
2022-11-28 04:29:16,145 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49236133525317366, 'Total loss': 0.49236133525317366} | train loss {'Reaction outcome loss': 0.4596608162589884, 'Total loss': 0.4596608162589884}
2022-11-28 04:29:16,145 INFO:     Best model found after epoch 80 of 100.
2022-11-28 04:29:16,145 INFO:   Done with stage: TRAINING
2022-11-28 04:29:16,145 INFO:   Starting stage: EVALUATION
2022-11-28 04:29:16,265 INFO:   Done with stage: EVALUATION
2022-11-28 04:29:16,265 INFO:   Leaving out SEQ value Fold_7
2022-11-28 04:29:16,278 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:29:16,278 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:29:16,924 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:29:16,925 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:29:16,992 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:29:16,992 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:29:16,992 INFO:     No hyperparam tuning for this model
2022-11-28 04:29:16,992 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:29:16,992 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:29:16,993 INFO:     None feature selector for col prot
2022-11-28 04:29:16,993 INFO:     None feature selector for col prot
2022-11-28 04:29:16,993 INFO:     None feature selector for col prot
2022-11-28 04:29:16,994 INFO:     None feature selector for col chem
2022-11-28 04:29:16,994 INFO:     None feature selector for col chem
2022-11-28 04:29:16,994 INFO:     None feature selector for col chem
2022-11-28 04:29:16,994 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:29:16,994 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:29:16,996 INFO:     Number of params in model 169651
2022-11-28 04:29:16,999 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:29:16,999 INFO:   Starting stage: TRAINING
2022-11-28 04:29:17,050 INFO:     Val loss before train {'Reaction outcome loss': 1.0653941604224118, 'Total loss': 1.0653941604224118}
2022-11-28 04:29:17,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:17,050 INFO:     Epoch: 0
2022-11-28 04:29:17,714 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6711248735135252, 'Total loss': 0.6711248735135252} | train loss {'Reaction outcome loss': 0.6683725082439932, 'Total loss': 0.6683725082439932}
2022-11-28 04:29:17,714 INFO:     Found new best model at epoch 0
2022-11-28 04:29:17,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:17,715 INFO:     Epoch: 1
2022-11-28 04:29:18,377 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6470117209987207, 'Total loss': 0.6470117209987207} | train loss {'Reaction outcome loss': 0.5677095814513774, 'Total loss': 0.5677095814513774}
2022-11-28 04:29:18,377 INFO:     Found new best model at epoch 1
2022-11-28 04:29:18,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:18,378 INFO:     Epoch: 2
2022-11-28 04:29:19,041 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5792255747047338, 'Total loss': 0.5792255747047338} | train loss {'Reaction outcome loss': 0.5486868875712035, 'Total loss': 0.5486868875712035}
2022-11-28 04:29:19,042 INFO:     Found new best model at epoch 2
2022-11-28 04:29:19,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:19,042 INFO:     Epoch: 3
2022-11-28 04:29:19,706 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5870292139324275, 'Total loss': 0.5870292139324275} | train loss {'Reaction outcome loss': 0.5253142166264385, 'Total loss': 0.5253142166264385}
2022-11-28 04:29:19,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:19,706 INFO:     Epoch: 4
2022-11-28 04:29:20,366 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6027622771534052, 'Total loss': 0.6027622771534052} | train loss {'Reaction outcome loss': 0.509808386265025, 'Total loss': 0.509808386265025}
2022-11-28 04:29:20,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:20,366 INFO:     Epoch: 5
2022-11-28 04:29:21,027 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5869521451267329, 'Total loss': 0.5869521451267329} | train loss {'Reaction outcome loss': 0.5164286038774227, 'Total loss': 0.5164286038774227}
2022-11-28 04:29:21,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:21,027 INFO:     Epoch: 6
2022-11-28 04:29:21,686 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5726899646899917, 'Total loss': 0.5726899646899917} | train loss {'Reaction outcome loss': 0.5029933167855266, 'Total loss': 0.5029933167855266}
2022-11-28 04:29:21,686 INFO:     Found new best model at epoch 6
2022-11-28 04:29:21,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:21,687 INFO:     Epoch: 7
2022-11-28 04:29:22,349 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5751145272092386, 'Total loss': 0.5751145272092386} | train loss {'Reaction outcome loss': 0.5046354957558365, 'Total loss': 0.5046354957558365}
2022-11-28 04:29:22,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:22,349 INFO:     Epoch: 8
2022-11-28 04:29:23,009 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5528655465353619, 'Total loss': 0.5528655465353619} | train loss {'Reaction outcome loss': 0.4957133978303627, 'Total loss': 0.4957133978303627}
2022-11-28 04:29:23,010 INFO:     Found new best model at epoch 8
2022-11-28 04:29:23,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:23,010 INFO:     Epoch: 9
2022-11-28 04:29:23,668 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5607005513527177, 'Total loss': 0.5607005513527177} | train loss {'Reaction outcome loss': 0.49050494437275627, 'Total loss': 0.49050494437275627}
2022-11-28 04:29:23,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:23,668 INFO:     Epoch: 10
2022-11-28 04:29:24,325 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5482818457213315, 'Total loss': 0.5482818457213315} | train loss {'Reaction outcome loss': 0.48955531786327905, 'Total loss': 0.48955531786327905}
2022-11-28 04:29:24,325 INFO:     Found new best model at epoch 10
2022-11-28 04:29:24,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:24,326 INFO:     Epoch: 11
2022-11-28 04:29:24,983 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5265670848841016, 'Total loss': 0.5265670848841016} | train loss {'Reaction outcome loss': 0.48110565761865876, 'Total loss': 0.48110565761865876}
2022-11-28 04:29:24,983 INFO:     Found new best model at epoch 11
2022-11-28 04:29:24,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:24,983 INFO:     Epoch: 12
2022-11-28 04:29:25,643 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5467294149778106, 'Total loss': 0.5467294149778106} | train loss {'Reaction outcome loss': 0.47455998127035764, 'Total loss': 0.47455998127035764}
2022-11-28 04:29:25,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:25,643 INFO:     Epoch: 13
2022-11-28 04:29:26,303 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5407600863413378, 'Total loss': 0.5407600863413378} | train loss {'Reaction outcome loss': 0.4918018342994968, 'Total loss': 0.4918018342994968}
2022-11-28 04:29:26,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:26,304 INFO:     Epoch: 14
2022-11-28 04:29:26,964 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.564436980269172, 'Total loss': 0.564436980269172} | train loss {'Reaction outcome loss': 0.5308140773035828, 'Total loss': 0.5308140773035828}
2022-11-28 04:29:26,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:26,964 INFO:     Epoch: 15
2022-11-28 04:29:27,622 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5358242351900447, 'Total loss': 0.5358242351900447} | train loss {'Reaction outcome loss': 0.4644954011507845, 'Total loss': 0.4644954011507845}
2022-11-28 04:29:27,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:27,622 INFO:     Epoch: 16
2022-11-28 04:29:28,283 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.530682389031757, 'Total loss': 0.530682389031757} | train loss {'Reaction outcome loss': 0.4695436791611104, 'Total loss': 0.4695436791611104}
2022-11-28 04:29:28,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:28,283 INFO:     Epoch: 17
2022-11-28 04:29:28,945 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5817681882869113, 'Total loss': 0.5817681882869113} | train loss {'Reaction outcome loss': 0.48110565693996216, 'Total loss': 0.48110565693996216}
2022-11-28 04:29:28,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:28,945 INFO:     Epoch: 18
2022-11-28 04:29:29,605 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5203325606205247, 'Total loss': 0.5203325606205247} | train loss {'Reaction outcome loss': 0.5061242855361358, 'Total loss': 0.5061242855361358}
2022-11-28 04:29:29,605 INFO:     Found new best model at epoch 18
2022-11-28 04:29:29,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:29,605 INFO:     Epoch: 19
2022-11-28 04:29:30,267 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5395475842735984, 'Total loss': 0.5395475842735984} | train loss {'Reaction outcome loss': 0.4680037673427026, 'Total loss': 0.4680037673427026}
2022-11-28 04:29:30,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:30,267 INFO:     Epoch: 20
2022-11-28 04:29:30,926 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5235123390501196, 'Total loss': 0.5235123390501196} | train loss {'Reaction outcome loss': 0.4725785637764554, 'Total loss': 0.4725785637764554}
2022-11-28 04:29:30,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:30,927 INFO:     Epoch: 21
2022-11-28 04:29:31,586 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5400853753089905, 'Total loss': 0.5400853753089905} | train loss {'Reaction outcome loss': 0.46649750611680724, 'Total loss': 0.46649750611680724}
2022-11-28 04:29:31,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:31,586 INFO:     Epoch: 22
2022-11-28 04:29:32,246 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5370903340252963, 'Total loss': 0.5370903340252963} | train loss {'Reaction outcome loss': 0.4694437187934211, 'Total loss': 0.4694437187934211}
2022-11-28 04:29:32,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:32,246 INFO:     Epoch: 23
2022-11-28 04:29:32,905 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5139777230268175, 'Total loss': 0.5139777230268175} | train loss {'Reaction outcome loss': 0.4642521443999248, 'Total loss': 0.4642521443999248}
2022-11-28 04:29:32,905 INFO:     Found new best model at epoch 23
2022-11-28 04:29:32,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:32,906 INFO:     Epoch: 24
2022-11-28 04:29:33,567 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5468012155456976, 'Total loss': 0.5468012155456976} | train loss {'Reaction outcome loss': 0.46966658905902614, 'Total loss': 0.46966658905902614}
2022-11-28 04:29:33,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:33,567 INFO:     Epoch: 25
2022-11-28 04:29:34,225 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4982011133635586, 'Total loss': 0.4982011133635586} | train loss {'Reaction outcome loss': 0.4611421569518232, 'Total loss': 0.4611421569518232}
2022-11-28 04:29:34,225 INFO:     Found new best model at epoch 25
2022-11-28 04:29:34,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:34,226 INFO:     Epoch: 26
2022-11-28 04:29:34,887 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5227307033809748, 'Total loss': 0.5227307033809748} | train loss {'Reaction outcome loss': 0.46626504534772534, 'Total loss': 0.46626504534772534}
2022-11-28 04:29:34,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:34,888 INFO:     Epoch: 27
2022-11-28 04:29:35,548 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4998783536932685, 'Total loss': 0.4998783536932685} | train loss {'Reaction outcome loss': 0.45790984943086804, 'Total loss': 0.45790984943086804}
2022-11-28 04:29:35,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:35,549 INFO:     Epoch: 28
2022-11-28 04:29:36,212 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5307347398589958, 'Total loss': 0.5307347398589958} | train loss {'Reaction outcome loss': 0.4538970199915079, 'Total loss': 0.4538970199915079}
2022-11-28 04:29:36,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:36,212 INFO:     Epoch: 29
2022-11-28 04:29:36,874 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4771671603349122, 'Total loss': 0.4771671603349122} | train loss {'Reaction outcome loss': 0.4627908492981181, 'Total loss': 0.4627908492981181}
2022-11-28 04:29:36,874 INFO:     Found new best model at epoch 29
2022-11-28 04:29:36,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:36,875 INFO:     Epoch: 30
2022-11-28 04:29:37,537 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5349372472952713, 'Total loss': 0.5349372472952713} | train loss {'Reaction outcome loss': 0.4644109849678541, 'Total loss': 0.4644109849678541}
2022-11-28 04:29:37,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:37,537 INFO:     Epoch: 31
2022-11-28 04:29:38,199 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.539261055263606, 'Total loss': 0.539261055263606} | train loss {'Reaction outcome loss': 0.4592160363700467, 'Total loss': 0.4592160363700467}
2022-11-28 04:29:38,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:38,199 INFO:     Epoch: 32
2022-11-28 04:29:38,859 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5933452411131426, 'Total loss': 0.5933452411131426} | train loss {'Reaction outcome loss': 0.4674060650561985, 'Total loss': 0.4674060650561985}
2022-11-28 04:29:38,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:38,859 INFO:     Epoch: 33
2022-11-28 04:29:39,521 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.6010108617219058, 'Total loss': 0.6010108617219058} | train loss {'Reaction outcome loss': 0.4715132619205274, 'Total loss': 0.4715132619205274}
2022-11-28 04:29:39,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:39,522 INFO:     Epoch: 34
2022-11-28 04:29:40,181 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5079755823720585, 'Total loss': 0.5079755823720585} | train loss {'Reaction outcome loss': 0.4660496834801276, 'Total loss': 0.4660496834801276}
2022-11-28 04:29:40,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:40,182 INFO:     Epoch: 35
2022-11-28 04:29:40,840 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5272591659291224, 'Total loss': 0.5272591659291224} | train loss {'Reaction outcome loss': 0.46313401097469487, 'Total loss': 0.46313401097469487}
2022-11-28 04:29:40,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:40,841 INFO:     Epoch: 36
2022-11-28 04:29:41,503 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5052482793954286, 'Total loss': 0.5052482793954286} | train loss {'Reaction outcome loss': 0.47807811297144487, 'Total loss': 0.47807811297144487}
2022-11-28 04:29:41,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:41,504 INFO:     Epoch: 37
2022-11-28 04:29:42,163 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5116267827424136, 'Total loss': 0.5116267827424136} | train loss {'Reaction outcome loss': 0.45377883785555084, 'Total loss': 0.45377883785555084}
2022-11-28 04:29:42,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:42,163 INFO:     Epoch: 38
2022-11-28 04:29:42,826 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49217867106199265, 'Total loss': 0.49217867106199265} | train loss {'Reaction outcome loss': 0.4577703279884238, 'Total loss': 0.4577703279884238}
2022-11-28 04:29:42,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:42,826 INFO:     Epoch: 39
2022-11-28 04:29:43,488 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5402711440216411, 'Total loss': 0.5402711440216411} | train loss {'Reaction outcome loss': 0.4750256241574461, 'Total loss': 0.4750256241574461}
2022-11-28 04:29:43,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:43,488 INFO:     Epoch: 40
2022-11-28 04:29:44,147 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5028401000255888, 'Total loss': 0.5028401000255888} | train loss {'Reaction outcome loss': 0.482149681853138, 'Total loss': 0.482149681853138}
2022-11-28 04:29:44,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:44,147 INFO:     Epoch: 41
2022-11-28 04:29:44,808 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5191556330431591, 'Total loss': 0.5191556330431591} | train loss {'Reaction outcome loss': 0.4561932389794091, 'Total loss': 0.4561932389794091}
2022-11-28 04:29:44,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:44,808 INFO:     Epoch: 42
2022-11-28 04:29:45,466 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5152262456037782, 'Total loss': 0.5152262456037782} | train loss {'Reaction outcome loss': 0.45976527246386417, 'Total loss': 0.45976527246386417}
2022-11-28 04:29:45,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:45,467 INFO:     Epoch: 43
2022-11-28 04:29:46,125 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5114165906879035, 'Total loss': 0.5114165906879035} | train loss {'Reaction outcome loss': 0.45881760591708937, 'Total loss': 0.45881760591708937}
2022-11-28 04:29:46,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:46,125 INFO:     Epoch: 44
2022-11-28 04:29:46,792 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5094979777932167, 'Total loss': 0.5094979777932167} | train loss {'Reaction outcome loss': 0.458864835532088, 'Total loss': 0.458864835532088}
2022-11-28 04:29:46,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:46,792 INFO:     Epoch: 45
2022-11-28 04:29:47,459 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5256893797354265, 'Total loss': 0.5256893797354265} | train loss {'Reaction outcome loss': 0.4601958818160571, 'Total loss': 0.4601958818160571}
2022-11-28 04:29:47,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:47,460 INFO:     Epoch: 46
2022-11-28 04:29:48,125 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5219800092957236, 'Total loss': 0.5219800092957236} | train loss {'Reaction outcome loss': 0.45742866390871134, 'Total loss': 0.45742866390871134}
2022-11-28 04:29:48,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:48,125 INFO:     Epoch: 47
2022-11-28 04:29:48,792 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5129934776235711, 'Total loss': 0.5129934776235711} | train loss {'Reaction outcome loss': 0.46464107541540856, 'Total loss': 0.46464107541540856}
2022-11-28 04:29:48,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:48,792 INFO:     Epoch: 48
2022-11-28 04:29:49,453 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49670933390205557, 'Total loss': 0.49670933390205557} | train loss {'Reaction outcome loss': 0.45818105753254795, 'Total loss': 0.45818105753254795}
2022-11-28 04:29:49,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:49,453 INFO:     Epoch: 49
2022-11-28 04:29:50,115 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5889168219132856, 'Total loss': 0.5889168219132856} | train loss {'Reaction outcome loss': 0.4570616095775535, 'Total loss': 0.4570616095775535}
2022-11-28 04:29:50,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:50,115 INFO:     Epoch: 50
2022-11-28 04:29:50,782 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5211592133749615, 'Total loss': 0.5211592133749615} | train loss {'Reaction outcome loss': 0.45998462473573953, 'Total loss': 0.45998462473573953}
2022-11-28 04:29:50,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:50,782 INFO:     Epoch: 51
2022-11-28 04:29:51,451 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5072608861056241, 'Total loss': 0.5072608861056241} | train loss {'Reaction outcome loss': 0.4633545580542522, 'Total loss': 0.4633545580542522}
2022-11-28 04:29:51,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:51,451 INFO:     Epoch: 52
2022-11-28 04:29:52,113 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49029340053146536, 'Total loss': 0.49029340053146536} | train loss {'Reaction outcome loss': 0.45801490062644123, 'Total loss': 0.45801490062644123}
2022-11-28 04:29:52,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:52,113 INFO:     Epoch: 53
2022-11-28 04:29:52,775 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5019418935884129, 'Total loss': 0.5019418935884129} | train loss {'Reaction outcome loss': 0.4557298228129564, 'Total loss': 0.4557298228129564}
2022-11-28 04:29:52,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:52,775 INFO:     Epoch: 54
2022-11-28 04:29:53,436 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5171212906187231, 'Total loss': 0.5171212906187231} | train loss {'Reaction outcome loss': 0.4687592672553622, 'Total loss': 0.4687592672553622}
2022-11-28 04:29:53,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:53,437 INFO:     Epoch: 55
2022-11-28 04:29:54,102 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47969433495944197, 'Total loss': 0.47969433495944197} | train loss {'Reaction outcome loss': 0.47869047619070604, 'Total loss': 0.47869047619070604}
2022-11-28 04:29:54,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:54,103 INFO:     Epoch: 56
2022-11-28 04:29:54,766 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4970489733598449, 'Total loss': 0.4970489733598449} | train loss {'Reaction outcome loss': 0.45557758200023823, 'Total loss': 0.45557758200023823}
2022-11-28 04:29:54,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:54,766 INFO:     Epoch: 57
2022-11-28 04:29:55,429 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4743358482691375, 'Total loss': 0.4743358482691375} | train loss {'Reaction outcome loss': 0.45616002815213763, 'Total loss': 0.45616002815213763}
2022-11-28 04:29:55,429 INFO:     Found new best model at epoch 57
2022-11-28 04:29:55,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:55,429 INFO:     Epoch: 58
2022-11-28 04:29:56,091 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5129446888511832, 'Total loss': 0.5129446888511832} | train loss {'Reaction outcome loss': 0.45858563365120636, 'Total loss': 0.45858563365120636}
2022-11-28 04:29:56,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:56,091 INFO:     Epoch: 59
2022-11-28 04:29:56,753 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49434976279735565, 'Total loss': 0.49434976279735565} | train loss {'Reaction outcome loss': 0.46582057408475686, 'Total loss': 0.46582057408475686}
2022-11-28 04:29:56,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:56,753 INFO:     Epoch: 60
2022-11-28 04:29:57,420 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5363972559571266, 'Total loss': 0.5363972559571266} | train loss {'Reaction outcome loss': 0.4518750566642294, 'Total loss': 0.4518750566642294}
2022-11-28 04:29:57,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:57,420 INFO:     Epoch: 61
2022-11-28 04:29:58,087 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5104709755290638, 'Total loss': 0.5104709755290638} | train loss {'Reaction outcome loss': 0.4570933841615453, 'Total loss': 0.4570933841615453}
2022-11-28 04:29:58,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:58,087 INFO:     Epoch: 62
2022-11-28 04:29:58,757 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47443085570227017, 'Total loss': 0.47443085570227017} | train loss {'Reaction outcome loss': 0.4453848889059866, 'Total loss': 0.4453848889059866}
2022-11-28 04:29:58,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:58,757 INFO:     Epoch: 63
2022-11-28 04:29:59,425 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5612911785190756, 'Total loss': 0.5612911785190756} | train loss {'Reaction outcome loss': 0.45458910629334237, 'Total loss': 0.45458910629334237}
2022-11-28 04:29:59,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:29:59,425 INFO:     Epoch: 64
2022-11-28 04:30:00,093 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48663419451225887, 'Total loss': 0.48663419451225887} | train loss {'Reaction outcome loss': 0.4791184823944984, 'Total loss': 0.4791184823944984}
2022-11-28 04:30:00,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:00,093 INFO:     Epoch: 65
2022-11-28 04:30:00,764 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48267029835419223, 'Total loss': 0.48267029835419223} | train loss {'Reaction outcome loss': 0.44929846068504853, 'Total loss': 0.44929846068504853}
2022-11-28 04:30:00,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:00,764 INFO:     Epoch: 66
2022-11-28 04:30:01,434 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4911112812432376, 'Total loss': 0.4911112812432376} | train loss {'Reaction outcome loss': 0.4415749632018177, 'Total loss': 0.4415749632018177}
2022-11-28 04:30:01,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:01,434 INFO:     Epoch: 67
2022-11-28 04:30:02,101 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48803203078833496, 'Total loss': 0.48803203078833496} | train loss {'Reaction outcome loss': 0.4556928400387648, 'Total loss': 0.4556928400387648}
2022-11-28 04:30:02,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:02,101 INFO:     Epoch: 68
2022-11-28 04:30:02,763 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5436088212511756, 'Total loss': 0.5436088212511756} | train loss {'Reaction outcome loss': 0.45525547445785663, 'Total loss': 0.45525547445785663}
2022-11-28 04:30:02,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:02,763 INFO:     Epoch: 69
2022-11-28 04:30:03,427 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48763795603405347, 'Total loss': 0.48763795603405347} | train loss {'Reaction outcome loss': 0.45377466324075816, 'Total loss': 0.45377466324075816}
2022-11-28 04:30:03,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:03,428 INFO:     Epoch: 70
2022-11-28 04:30:04,090 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5318003479729999, 'Total loss': 0.5318003479729999} | train loss {'Reaction outcome loss': 0.4555446133922469, 'Total loss': 0.4555446133922469}
2022-11-28 04:30:04,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:04,090 INFO:     Epoch: 71
2022-11-28 04:30:04,757 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4890109862793576, 'Total loss': 0.4890109862793576} | train loss {'Reaction outcome loss': 0.4546898548238673, 'Total loss': 0.4546898548238673}
2022-11-28 04:30:04,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:04,757 INFO:     Epoch: 72
2022-11-28 04:30:05,416 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5374133573337034, 'Total loss': 0.5374133573337034} | train loss {'Reaction outcome loss': 0.454185469038332, 'Total loss': 0.454185469038332}
2022-11-28 04:30:05,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:05,417 INFO:     Epoch: 73
2022-11-28 04:30:06,075 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5495571724393151, 'Total loss': 0.5495571724393151} | train loss {'Reaction outcome loss': 0.4600840466104538, 'Total loss': 0.4600840466104538}
2022-11-28 04:30:06,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:06,075 INFO:     Epoch: 74
2022-11-28 04:30:06,734 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5224646370519291, 'Total loss': 0.5224646370519291} | train loss {'Reaction outcome loss': 0.46517906455617203, 'Total loss': 0.46517906455617203}
2022-11-28 04:30:06,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:06,735 INFO:     Epoch: 75
2022-11-28 04:30:07,391 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4691643596372821, 'Total loss': 0.4691643596372821} | train loss {'Reaction outcome loss': 0.4468386341565051, 'Total loss': 0.4468386341565051}
2022-11-28 04:30:07,391 INFO:     Found new best model at epoch 75
2022-11-28 04:30:07,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:07,392 INFO:     Epoch: 76
2022-11-28 04:30:08,050 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5145688233050433, 'Total loss': 0.5145688233050433} | train loss {'Reaction outcome loss': 0.4537052167089362, 'Total loss': 0.4537052167089362}
2022-11-28 04:30:08,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:08,050 INFO:     Epoch: 77
2022-11-28 04:30:08,711 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5141892060637474, 'Total loss': 0.5141892060637474} | train loss {'Reaction outcome loss': 0.45738580310151644, 'Total loss': 0.45738580310151644}
2022-11-28 04:30:08,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:08,712 INFO:     Epoch: 78
2022-11-28 04:30:09,372 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49386952580376103, 'Total loss': 0.49386952580376103} | train loss {'Reaction outcome loss': 0.45319794223979415, 'Total loss': 0.45319794223979415}
2022-11-28 04:30:09,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:09,372 INFO:     Epoch: 79
2022-11-28 04:30:10,033 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.510248522866856, 'Total loss': 0.510248522866856} | train loss {'Reaction outcome loss': 0.4481125400375258, 'Total loss': 0.4481125400375258}
2022-11-28 04:30:10,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:10,034 INFO:     Epoch: 80
2022-11-28 04:30:10,692 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4907398398288272, 'Total loss': 0.4907398398288272} | train loss {'Reaction outcome loss': 0.44269945731891797, 'Total loss': 0.44269945731891797}
2022-11-28 04:30:10,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:10,692 INFO:     Epoch: 81
2022-11-28 04:30:11,347 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5003672431815754, 'Total loss': 0.5003672431815754} | train loss {'Reaction outcome loss': 0.4529879450918692, 'Total loss': 0.4529879450918692}
2022-11-28 04:30:11,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:11,347 INFO:     Epoch: 82
2022-11-28 04:30:12,004 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4968109462748874, 'Total loss': 0.4968109462748874} | train loss {'Reaction outcome loss': 0.460357780549449, 'Total loss': 0.460357780549449}
2022-11-28 04:30:12,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:12,005 INFO:     Epoch: 83
2022-11-28 04:30:12,662 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.522733441808007, 'Total loss': 0.522733441808007} | train loss {'Reaction outcome loss': 0.463657858159378, 'Total loss': 0.463657858159378}
2022-11-28 04:30:12,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:12,662 INFO:     Epoch: 84
2022-11-28 04:30:13,319 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5170708766037767, 'Total loss': 0.5170708766037767} | train loss {'Reaction outcome loss': 0.45069702342152596, 'Total loss': 0.45069702342152596}
2022-11-28 04:30:13,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:13,320 INFO:     Epoch: 85
2022-11-28 04:30:13,976 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5191776186905124, 'Total loss': 0.5191776186905124} | train loss {'Reaction outcome loss': 0.4503413608923615, 'Total loss': 0.4503413608923615}
2022-11-28 04:30:13,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:13,976 INFO:     Epoch: 86
2022-11-28 04:30:14,631 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5103925381871787, 'Total loss': 0.5103925381871787} | train loss {'Reaction outcome loss': 0.4591012668271779, 'Total loss': 0.4591012668271779}
2022-11-28 04:30:14,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:14,631 INFO:     Epoch: 87
2022-11-28 04:30:15,288 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5212827853181146, 'Total loss': 0.5212827853181146} | train loss {'Reaction outcome loss': 0.4463122340469708, 'Total loss': 0.4463122340469708}
2022-11-28 04:30:15,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:15,289 INFO:     Epoch: 88
2022-11-28 04:30:15,947 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5003896233710375, 'Total loss': 0.5003896233710375} | train loss {'Reaction outcome loss': 0.44977592076608525, 'Total loss': 0.44977592076608525}
2022-11-28 04:30:15,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:15,947 INFO:     Epoch: 89
2022-11-28 04:30:16,602 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48627063022418454, 'Total loss': 0.48627063022418454} | train loss {'Reaction outcome loss': 0.45374936411375943, 'Total loss': 0.45374936411375943}
2022-11-28 04:30:16,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:16,602 INFO:     Epoch: 90
2022-11-28 04:30:17,258 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.510507425123995, 'Total loss': 0.510507425123995} | train loss {'Reaction outcome loss': 0.4526609209072041, 'Total loss': 0.4526609209072041}
2022-11-28 04:30:17,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:17,258 INFO:     Epoch: 91
2022-11-28 04:30:17,917 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48482964831319725, 'Total loss': 0.48482964831319725} | train loss {'Reaction outcome loss': 0.4428338363525356, 'Total loss': 0.4428338363525356}
2022-11-28 04:30:17,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:17,917 INFO:     Epoch: 92
2022-11-28 04:30:18,578 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4764721200547435, 'Total loss': 0.4764721200547435} | train loss {'Reaction outcome loss': 0.44294042643989145, 'Total loss': 0.44294042643989145}
2022-11-28 04:30:18,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:18,578 INFO:     Epoch: 93
2022-11-28 04:30:19,237 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5113375728780573, 'Total loss': 0.5113375728780573} | train loss {'Reaction outcome loss': 0.45458614868432407, 'Total loss': 0.45458614868432407}
2022-11-28 04:30:19,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:19,237 INFO:     Epoch: 94
2022-11-28 04:30:19,894 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48942505703731015, 'Total loss': 0.48942505703731015} | train loss {'Reaction outcome loss': 0.5004356999142541, 'Total loss': 0.5004356999142541}
2022-11-28 04:30:19,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:19,894 INFO:     Epoch: 95
2022-11-28 04:30:20,551 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4852857251058925, 'Total loss': 0.4852857251058925} | train loss {'Reaction outcome loss': 0.4383378688562737, 'Total loss': 0.4383378688562737}
2022-11-28 04:30:20,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:20,551 INFO:     Epoch: 96
2022-11-28 04:30:21,206 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5085335658355192, 'Total loss': 0.5085335658355192} | train loss {'Reaction outcome loss': 0.4447749216629848, 'Total loss': 0.4447749216629848}
2022-11-28 04:30:21,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:21,207 INFO:     Epoch: 97
2022-11-28 04:30:21,859 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.497373814271255, 'Total loss': 0.497373814271255} | train loss {'Reaction outcome loss': 0.446159431477066, 'Total loss': 0.446159431477066}
2022-11-28 04:30:21,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:21,859 INFO:     Epoch: 98
2022-11-28 04:30:22,511 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5591891018504446, 'Total loss': 0.5591891018504446} | train loss {'Reaction outcome loss': 0.448290625386796, 'Total loss': 0.448290625386796}
2022-11-28 04:30:22,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:22,512 INFO:     Epoch: 99
2022-11-28 04:30:23,164 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4956735050813718, 'Total loss': 0.4956735050813718} | train loss {'Reaction outcome loss': 0.44489592678754436, 'Total loss': 0.44489592678754436}
2022-11-28 04:30:23,164 INFO:     Best model found after epoch 76 of 100.
2022-11-28 04:30:23,164 INFO:   Done with stage: TRAINING
2022-11-28 04:30:23,164 INFO:   Starting stage: EVALUATION
2022-11-28 04:30:23,283 INFO:   Done with stage: EVALUATION
2022-11-28 04:30:23,283 INFO:   Leaving out SEQ value Fold_8
2022-11-28 04:30:23,295 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 04:30:23,295 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:30:23,928 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:30:23,928 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:30:23,995 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:30:23,996 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:30:23,996 INFO:     No hyperparam tuning for this model
2022-11-28 04:30:23,996 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:30:23,996 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:30:23,996 INFO:     None feature selector for col prot
2022-11-28 04:30:23,997 INFO:     None feature selector for col prot
2022-11-28 04:30:23,997 INFO:     None feature selector for col prot
2022-11-28 04:30:23,997 INFO:     None feature selector for col chem
2022-11-28 04:30:23,997 INFO:     None feature selector for col chem
2022-11-28 04:30:23,997 INFO:     None feature selector for col chem
2022-11-28 04:30:23,997 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:30:23,997 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:30:23,999 INFO:     Number of params in model 169651
2022-11-28 04:30:24,002 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:30:24,003 INFO:   Starting stage: TRAINING
2022-11-28 04:30:24,053 INFO:     Val loss before train {'Reaction outcome loss': 1.0065628484238025, 'Total loss': 1.0065628484238025}
2022-11-28 04:30:24,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:24,053 INFO:     Epoch: 0
2022-11-28 04:30:24,699 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6177575893180315, 'Total loss': 0.6177575893180315} | train loss {'Reaction outcome loss': 0.6835228929632022, 'Total loss': 0.6835228929632022}
2022-11-28 04:30:24,699 INFO:     Found new best model at epoch 0
2022-11-28 04:30:24,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:24,700 INFO:     Epoch: 1
2022-11-28 04:30:25,350 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5314361099586931, 'Total loss': 0.5314361099586931} | train loss {'Reaction outcome loss': 0.5794420900037054, 'Total loss': 0.5794420900037054}
2022-11-28 04:30:25,350 INFO:     Found new best model at epoch 1
2022-11-28 04:30:25,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:25,351 INFO:     Epoch: 2
2022-11-28 04:30:25,996 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5298387325087259, 'Total loss': 0.5298387325087259} | train loss {'Reaction outcome loss': 0.5482637383898751, 'Total loss': 0.5482637383898751}
2022-11-28 04:30:25,996 INFO:     Found new best model at epoch 2
2022-11-28 04:30:25,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:25,997 INFO:     Epoch: 3
2022-11-28 04:30:26,645 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5169479382592578, 'Total loss': 0.5169479382592578} | train loss {'Reaction outcome loss': 0.5333181657507772, 'Total loss': 0.5333181657507772}
2022-11-28 04:30:26,645 INFO:     Found new best model at epoch 3
2022-11-28 04:30:26,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:26,646 INFO:     Epoch: 4
2022-11-28 04:30:27,297 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.530525931785273, 'Total loss': 0.530525931785273} | train loss {'Reaction outcome loss': 0.5133589893335202, 'Total loss': 0.5133589893335202}
2022-11-28 04:30:27,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:27,297 INFO:     Epoch: 5
2022-11-28 04:30:27,947 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5357705590336822, 'Total loss': 0.5357705590336822} | train loss {'Reaction outcome loss': 0.5125808618718484, 'Total loss': 0.5125808618718484}
2022-11-28 04:30:27,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:27,947 INFO:     Epoch: 6
2022-11-28 04:30:28,597 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5387634835964026, 'Total loss': 0.5387634835964026} | train loss {'Reaction outcome loss': 0.4926377951976706, 'Total loss': 0.4926377951976706}
2022-11-28 04:30:28,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:28,597 INFO:     Epoch: 7
2022-11-28 04:30:29,247 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4995349805022395, 'Total loss': 0.4995349805022395} | train loss {'Reaction outcome loss': 0.4937133626615415, 'Total loss': 0.4937133626615415}
2022-11-28 04:30:29,247 INFO:     Found new best model at epoch 7
2022-11-28 04:30:29,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:29,248 INFO:     Epoch: 8
2022-11-28 04:30:29,898 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5050192648588225, 'Total loss': 0.5050192648588225} | train loss {'Reaction outcome loss': 0.48652698001900657, 'Total loss': 0.48652698001900657}
2022-11-28 04:30:29,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:29,898 INFO:     Epoch: 9
2022-11-28 04:30:30,548 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5191690138606138, 'Total loss': 0.5191690138606138} | train loss {'Reaction outcome loss': 0.48483528624304006, 'Total loss': 0.48483528624304006}
2022-11-28 04:30:30,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:30,548 INFO:     Epoch: 10
2022-11-28 04:30:31,199 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5841176953426627, 'Total loss': 0.5841176953426627} | train loss {'Reaction outcome loss': 0.47908110678440236, 'Total loss': 0.47908110678440236}
2022-11-28 04:30:31,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:31,199 INFO:     Epoch: 11
2022-11-28 04:30:31,849 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4932401339675105, 'Total loss': 0.4932401339675105} | train loss {'Reaction outcome loss': 0.4780424374048827, 'Total loss': 0.4780424374048827}
2022-11-28 04:30:31,849 INFO:     Found new best model at epoch 11
2022-11-28 04:30:31,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:31,850 INFO:     Epoch: 12
2022-11-28 04:30:32,498 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5124447837818501, 'Total loss': 0.5124447837818501} | train loss {'Reaction outcome loss': 0.4759060758791986, 'Total loss': 0.4759060758791986}
2022-11-28 04:30:32,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:32,498 INFO:     Epoch: 13
2022-11-28 04:30:33,147 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5090126547702524, 'Total loss': 0.5090126547702524} | train loss {'Reaction outcome loss': 0.47293570729308443, 'Total loss': 0.47293570729308443}
2022-11-28 04:30:33,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:33,147 INFO:     Epoch: 14
2022-11-28 04:30:33,796 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5077320517495622, 'Total loss': 0.5077320517495622} | train loss {'Reaction outcome loss': 0.4716455904980663, 'Total loss': 0.4716455904980663}
2022-11-28 04:30:33,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:33,797 INFO:     Epoch: 15
2022-11-28 04:30:34,447 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49129942891209627, 'Total loss': 0.49129942891209627} | train loss {'Reaction outcome loss': 0.4693075838636179, 'Total loss': 0.4693075838636179}
2022-11-28 04:30:34,448 INFO:     Found new best model at epoch 15
2022-11-28 04:30:34,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:34,448 INFO:     Epoch: 16
2022-11-28 04:30:35,099 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.513486324008121, 'Total loss': 0.513486324008121} | train loss {'Reaction outcome loss': 0.46819094537955813, 'Total loss': 0.46819094537955813}
2022-11-28 04:30:35,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:35,099 INFO:     Epoch: 17
2022-11-28 04:30:35,749 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5183501590129941, 'Total loss': 0.5183501590129941} | train loss {'Reaction outcome loss': 0.46838799802983394, 'Total loss': 0.46838799802983394}
2022-11-28 04:30:35,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:35,750 INFO:     Epoch: 18
2022-11-28 04:30:36,398 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48602002477923106, 'Total loss': 0.48602002477923106} | train loss {'Reaction outcome loss': 0.47503126699660647, 'Total loss': 0.47503126699660647}
2022-11-28 04:30:36,398 INFO:     Found new best model at epoch 18
2022-11-28 04:30:36,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:36,399 INFO:     Epoch: 19
2022-11-28 04:30:37,048 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5052741585775863, 'Total loss': 0.5052741585775863} | train loss {'Reaction outcome loss': 0.46796066582691476, 'Total loss': 0.46796066582691476}
2022-11-28 04:30:37,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:37,050 INFO:     Epoch: 20
2022-11-28 04:30:37,696 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49313756823539734, 'Total loss': 0.49313756823539734} | train loss {'Reaction outcome loss': 0.47082121377108527, 'Total loss': 0.47082121377108527}
2022-11-28 04:30:37,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:37,696 INFO:     Epoch: 21
2022-11-28 04:30:38,344 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49199736049008924, 'Total loss': 0.49199736049008924} | train loss {'Reaction outcome loss': 0.46995764909709087, 'Total loss': 0.46995764909709087}
2022-11-28 04:30:38,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:38,344 INFO:     Epoch: 22
2022-11-28 04:30:38,995 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5314820502386537, 'Total loss': 0.5314820502386537} | train loss {'Reaction outcome loss': 0.46263224060540314, 'Total loss': 0.46263224060540314}
2022-11-28 04:30:38,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:38,996 INFO:     Epoch: 23
2022-11-28 04:30:39,646 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4753478547168333, 'Total loss': 0.4753478547168333} | train loss {'Reaction outcome loss': 0.470152632012719, 'Total loss': 0.470152632012719}
2022-11-28 04:30:39,646 INFO:     Found new best model at epoch 23
2022-11-28 04:30:39,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:39,647 INFO:     Epoch: 24
2022-11-28 04:30:40,295 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5084289007408674, 'Total loss': 0.5084289007408674} | train loss {'Reaction outcome loss': 0.4655096127239407, 'Total loss': 0.4655096127239407}
2022-11-28 04:30:40,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:40,295 INFO:     Epoch: 25
2022-11-28 04:30:40,945 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4807167233422745, 'Total loss': 0.4807167233422745} | train loss {'Reaction outcome loss': 0.46467907647373247, 'Total loss': 0.46467907647373247}
2022-11-28 04:30:40,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:40,945 INFO:     Epoch: 26
2022-11-28 04:30:41,595 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48101390378419745, 'Total loss': 0.48101390378419745} | train loss {'Reaction outcome loss': 0.46201588940180716, 'Total loss': 0.46201588940180716}
2022-11-28 04:30:41,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:41,595 INFO:     Epoch: 27
2022-11-28 04:30:42,242 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4944264452124751, 'Total loss': 0.4944264452124751} | train loss {'Reaction outcome loss': 0.45891434430587486, 'Total loss': 0.45891434430587486}
2022-11-28 04:30:42,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:42,242 INFO:     Epoch: 28
2022-11-28 04:30:42,890 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5348362739002982, 'Total loss': 0.5348362739002982} | train loss {'Reaction outcome loss': 0.4693553164967748, 'Total loss': 0.4693553164967748}
2022-11-28 04:30:42,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:42,890 INFO:     Epoch: 29
2022-11-28 04:30:43,543 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5024122155682985, 'Total loss': 0.5024122155682985} | train loss {'Reaction outcome loss': 0.4597175870640356, 'Total loss': 0.4597175870640356}
2022-11-28 04:30:43,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:43,544 INFO:     Epoch: 30
2022-11-28 04:30:44,191 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48880190835442655, 'Total loss': 0.48880190835442655} | train loss {'Reaction outcome loss': 0.47041845327762305, 'Total loss': 0.47041845327762305}
2022-11-28 04:30:44,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:44,191 INFO:     Epoch: 31
2022-11-28 04:30:44,840 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46035237437070803, 'Total loss': 0.46035237437070803} | train loss {'Reaction outcome loss': 0.45783959066525837, 'Total loss': 0.45783959066525837}
2022-11-28 04:30:44,840 INFO:     Found new best model at epoch 31
2022-11-28 04:30:44,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:44,841 INFO:     Epoch: 32
2022-11-28 04:30:45,487 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46969157561313274, 'Total loss': 0.46969157561313274} | train loss {'Reaction outcome loss': 0.46199685451192934, 'Total loss': 0.46199685451192934}
2022-11-28 04:30:45,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:45,488 INFO:     Epoch: 33
2022-11-28 04:30:46,145 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49871905806452727, 'Total loss': 0.49871905806452727} | train loss {'Reaction outcome loss': 0.4661130869119871, 'Total loss': 0.4661130869119871}
2022-11-28 04:30:46,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:46,145 INFO:     Epoch: 34
2022-11-28 04:30:46,794 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5147428069003793, 'Total loss': 0.5147428069003793} | train loss {'Reaction outcome loss': 0.46181534557435355, 'Total loss': 0.46181534557435355}
2022-11-28 04:30:46,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:46,795 INFO:     Epoch: 35
2022-11-28 04:30:47,447 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47827508629754534, 'Total loss': 0.47827508629754534} | train loss {'Reaction outcome loss': 0.45663552108358163, 'Total loss': 0.45663552108358163}
2022-11-28 04:30:47,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:47,447 INFO:     Epoch: 36
2022-11-28 04:30:48,098 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49485747516155243, 'Total loss': 0.49485747516155243} | train loss {'Reaction outcome loss': 0.4682234556826412, 'Total loss': 0.4682234556826412}
2022-11-28 04:30:48,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:48,098 INFO:     Epoch: 37
2022-11-28 04:30:48,750 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48502885463625883, 'Total loss': 0.48502885463625883} | train loss {'Reaction outcome loss': 0.4615942568930446, 'Total loss': 0.4615942568930446}
2022-11-28 04:30:48,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:48,750 INFO:     Epoch: 38
2022-11-28 04:30:49,402 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4787200446738753, 'Total loss': 0.4787200446738753} | train loss {'Reaction outcome loss': 0.4644664891797011, 'Total loss': 0.4644664891797011}
2022-11-28 04:30:49,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:49,402 INFO:     Epoch: 39
2022-11-28 04:30:50,054 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5107789247534996, 'Total loss': 0.5107789247534996} | train loss {'Reaction outcome loss': 0.46043499589699216, 'Total loss': 0.46043499589699216}
2022-11-28 04:30:50,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:50,054 INFO:     Epoch: 40
2022-11-28 04:30:50,705 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4818327724933624, 'Total loss': 0.4818327724933624} | train loss {'Reaction outcome loss': 0.46540822540638876, 'Total loss': 0.46540822540638876}
2022-11-28 04:30:50,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:50,705 INFO:     Epoch: 41
2022-11-28 04:30:51,354 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.481556715660317, 'Total loss': 0.481556715660317} | train loss {'Reaction outcome loss': 0.4630279402996673, 'Total loss': 0.4630279402996673}
2022-11-28 04:30:51,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:51,354 INFO:     Epoch: 42
2022-11-28 04:30:52,004 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5456824739312016, 'Total loss': 0.5456824739312016} | train loss {'Reaction outcome loss': 0.46702823274936833, 'Total loss': 0.46702823274936833}
2022-11-28 04:30:52,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:52,004 INFO:     Epoch: 43
2022-11-28 04:30:52,652 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5089876332948374, 'Total loss': 0.5089876332948374} | train loss {'Reaction outcome loss': 0.4599838776544469, 'Total loss': 0.4599838776544469}
2022-11-28 04:30:52,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:52,652 INFO:     Epoch: 44
2022-11-28 04:30:53,303 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4810271512630374, 'Total loss': 0.4810271512630374} | train loss {'Reaction outcome loss': 0.4706474215280814, 'Total loss': 0.4706474215280814}
2022-11-28 04:30:53,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:53,303 INFO:     Epoch: 45
2022-11-28 04:30:53,953 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48961022426915723, 'Total loss': 0.48961022426915723} | train loss {'Reaction outcome loss': 0.45988329420568513, 'Total loss': 0.45988329420568513}
2022-11-28 04:30:53,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:53,953 INFO:     Epoch: 46
2022-11-28 04:30:54,604 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4768384175245152, 'Total loss': 0.4768384175245152} | train loss {'Reaction outcome loss': 0.4581910534838184, 'Total loss': 0.4581910534838184}
2022-11-28 04:30:54,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:54,604 INFO:     Epoch: 47
2022-11-28 04:30:55,256 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48148766333280607, 'Total loss': 0.48148766333280607} | train loss {'Reaction outcome loss': 0.46239000717636014, 'Total loss': 0.46239000717636014}
2022-11-28 04:30:55,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:55,256 INFO:     Epoch: 48
2022-11-28 04:30:55,908 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4905643764623376, 'Total loss': 0.4905643764623376} | train loss {'Reaction outcome loss': 0.4655454484898536, 'Total loss': 0.4655454484898536}
2022-11-28 04:30:55,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:55,909 INFO:     Epoch: 49
2022-11-28 04:30:56,562 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49925637037255044, 'Total loss': 0.49925637037255044} | train loss {'Reaction outcome loss': 0.4596819656549907, 'Total loss': 0.4596819656549907}
2022-11-28 04:30:56,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:56,562 INFO:     Epoch: 50
2022-11-28 04:30:57,211 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5458450047082679, 'Total loss': 0.5458450047082679} | train loss {'Reaction outcome loss': 0.46765129255955334, 'Total loss': 0.46765129255955334}
2022-11-28 04:30:57,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:57,212 INFO:     Epoch: 51
2022-11-28 04:30:57,858 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4772773170193961, 'Total loss': 0.4772773170193961} | train loss {'Reaction outcome loss': 0.4590622958589773, 'Total loss': 0.4590622958589773}
2022-11-28 04:30:57,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:57,859 INFO:     Epoch: 52
2022-11-28 04:30:58,509 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49016515668048416, 'Total loss': 0.49016515668048416} | train loss {'Reaction outcome loss': 0.46134674988809177, 'Total loss': 0.46134674988809177}
2022-11-28 04:30:58,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:58,509 INFO:     Epoch: 53
2022-11-28 04:30:59,160 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48705096542835236, 'Total loss': 0.48705096542835236} | train loss {'Reaction outcome loss': 0.46686359177358816, 'Total loss': 0.46686359177358816}
2022-11-28 04:30:59,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:59,161 INFO:     Epoch: 54
2022-11-28 04:30:59,812 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5145289669203204, 'Total loss': 0.5145289669203204} | train loss {'Reaction outcome loss': 0.46385376509584364, 'Total loss': 0.46385376509584364}
2022-11-28 04:30:59,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:30:59,812 INFO:     Epoch: 55
2022-11-28 04:31:00,461 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.469039760010187, 'Total loss': 0.469039760010187} | train loss {'Reaction outcome loss': 0.4669215376259851, 'Total loss': 0.4669215376259851}
2022-11-28 04:31:00,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:00,462 INFO:     Epoch: 56
2022-11-28 04:31:01,113 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5158886327299961, 'Total loss': 0.5158886327299961} | train loss {'Reaction outcome loss': 0.46443339217393126, 'Total loss': 0.46443339217393126}
2022-11-28 04:31:01,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:01,114 INFO:     Epoch: 57
2022-11-28 04:31:01,765 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49696022480033164, 'Total loss': 0.49696022480033164} | train loss {'Reaction outcome loss': 0.46513907248001607, 'Total loss': 0.46513907248001607}
2022-11-28 04:31:01,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:01,765 INFO:     Epoch: 58
2022-11-28 04:31:02,417 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.526227633966956, 'Total loss': 0.526227633966956} | train loss {'Reaction outcome loss': 0.4678352554557753, 'Total loss': 0.4678352554557753}
2022-11-28 04:31:02,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:02,417 INFO:     Epoch: 59
2022-11-28 04:31:03,068 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5015493769978367, 'Total loss': 0.5015493769978367} | train loss {'Reaction outcome loss': 0.46880179405456684, 'Total loss': 0.46880179405456684}
2022-11-28 04:31:03,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:03,068 INFO:     Epoch: 60
2022-11-28 04:31:03,716 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46635471838851306, 'Total loss': 0.46635471838851306} | train loss {'Reaction outcome loss': 0.46732688640229036, 'Total loss': 0.46732688640229036}
2022-11-28 04:31:03,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:03,717 INFO:     Epoch: 61
2022-11-28 04:31:04,364 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4644137385279633, 'Total loss': 0.4644137385279633} | train loss {'Reaction outcome loss': 0.4594962732469449, 'Total loss': 0.4594962732469449}
2022-11-28 04:31:04,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:04,365 INFO:     Epoch: 62
2022-11-28 04:31:05,015 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4919732781343682, 'Total loss': 0.4919732781343682} | train loss {'Reaction outcome loss': 0.46588640812723364, 'Total loss': 0.46588640812723364}
2022-11-28 04:31:05,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:05,015 INFO:     Epoch: 63
2022-11-28 04:31:05,666 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4739038639290388, 'Total loss': 0.4739038639290388} | train loss {'Reaction outcome loss': 0.46526830495319893, 'Total loss': 0.46526830495319893}
2022-11-28 04:31:05,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:05,666 INFO:     Epoch: 64
2022-11-28 04:31:06,315 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5386007189057594, 'Total loss': 0.5386007189057594} | train loss {'Reaction outcome loss': 0.4595558054623057, 'Total loss': 0.4595558054623057}
2022-11-28 04:31:06,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:06,315 INFO:     Epoch: 65
2022-11-28 04:31:06,963 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47824827980163487, 'Total loss': 0.47824827980163487} | train loss {'Reaction outcome loss': 0.4623495114387059, 'Total loss': 0.4623495114387059}
2022-11-28 04:31:06,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:06,963 INFO:     Epoch: 66
2022-11-28 04:31:07,611 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4665240804816401, 'Total loss': 0.4665240804816401} | train loss {'Reaction outcome loss': 0.46631741804666205, 'Total loss': 0.46631741804666205}
2022-11-28 04:31:07,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:07,612 INFO:     Epoch: 67
2022-11-28 04:31:08,260 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49158571071402973, 'Total loss': 0.49158571071402973} | train loss {'Reaction outcome loss': 0.4584912387806861, 'Total loss': 0.4584912387806861}
2022-11-28 04:31:08,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:08,260 INFO:     Epoch: 68
2022-11-28 04:31:08,911 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4847120063942532, 'Total loss': 0.4847120063942532} | train loss {'Reaction outcome loss': 0.46283337516618556, 'Total loss': 0.46283337516618556}
2022-11-28 04:31:08,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:08,912 INFO:     Epoch: 69
2022-11-28 04:31:09,565 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49650562052116837, 'Total loss': 0.49650562052116837} | train loss {'Reaction outcome loss': 0.46103966657499795, 'Total loss': 0.46103966657499795}
2022-11-28 04:31:09,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:09,565 INFO:     Epoch: 70
2022-11-28 04:31:10,211 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48572093109751857, 'Total loss': 0.48572093109751857} | train loss {'Reaction outcome loss': 0.4626995377608987, 'Total loss': 0.4626995377608987}
2022-11-28 04:31:10,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:10,212 INFO:     Epoch: 71
2022-11-28 04:31:10,861 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4677776631920837, 'Total loss': 0.4677776631920837} | train loss {'Reaction outcome loss': 0.4559665283218759, 'Total loss': 0.4559665283218759}
2022-11-28 04:31:10,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:10,861 INFO:     Epoch: 72
2022-11-28 04:31:11,512 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46702643605165706, 'Total loss': 0.46702643605165706} | train loss {'Reaction outcome loss': 0.4559099903543953, 'Total loss': 0.4559099903543953}
2022-11-28 04:31:11,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:11,512 INFO:     Epoch: 73
2022-11-28 04:31:12,157 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47984449149564257, 'Total loss': 0.47984449149564257} | train loss {'Reaction outcome loss': 0.4606241802455949, 'Total loss': 0.4606241802455949}
2022-11-28 04:31:12,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:12,158 INFO:     Epoch: 74
2022-11-28 04:31:12,808 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4636856269004733, 'Total loss': 0.4636856269004733} | train loss {'Reaction outcome loss': 0.46253612600877636, 'Total loss': 0.46253612600877636}
2022-11-28 04:31:12,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:12,809 INFO:     Epoch: 75
2022-11-28 04:31:13,457 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4613200301347777, 'Total loss': 0.4613200301347777} | train loss {'Reaction outcome loss': 0.46092114689164476, 'Total loss': 0.46092114689164476}
2022-11-28 04:31:13,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:13,457 INFO:     Epoch: 76
2022-11-28 04:31:14,106 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49237055764641874, 'Total loss': 0.49237055764641874} | train loss {'Reaction outcome loss': 0.46564151841353196, 'Total loss': 0.46564151841353196}
2022-11-28 04:31:14,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:14,107 INFO:     Epoch: 77
2022-11-28 04:31:14,758 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5033342148675475, 'Total loss': 0.5033342148675475} | train loss {'Reaction outcome loss': 0.4614707558247887, 'Total loss': 0.4614707558247887}
2022-11-28 04:31:14,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:14,758 INFO:     Epoch: 78
2022-11-28 04:31:15,407 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.496292406043341, 'Total loss': 0.496292406043341} | train loss {'Reaction outcome loss': 0.45857847265166335, 'Total loss': 0.45857847265166335}
2022-11-28 04:31:15,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:15,407 INFO:     Epoch: 79
2022-11-28 04:31:16,060 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49656871550304943, 'Total loss': 0.49656871550304943} | train loss {'Reaction outcome loss': 0.46058941015698873, 'Total loss': 0.46058941015698873}
2022-11-28 04:31:16,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:16,061 INFO:     Epoch: 80
2022-11-28 04:31:16,707 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4972284200579621, 'Total loss': 0.4972284200579621} | train loss {'Reaction outcome loss': 0.459292222364027, 'Total loss': 0.459292222364027}
2022-11-28 04:31:16,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:16,707 INFO:     Epoch: 81
2022-11-28 04:31:17,354 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47920534707779106, 'Total loss': 0.47920534707779106} | train loss {'Reaction outcome loss': 0.46190409802022525, 'Total loss': 0.46190409802022525}
2022-11-28 04:31:17,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:17,354 INFO:     Epoch: 82
2022-11-28 04:31:18,006 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4950942722863929, 'Total loss': 0.4950942722863929} | train loss {'Reaction outcome loss': 0.46514402928410986, 'Total loss': 0.46514402928410986}
2022-11-28 04:31:18,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:18,006 INFO:     Epoch: 83
2022-11-28 04:31:18,655 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49109535508377605, 'Total loss': 0.49109535508377605} | train loss {'Reaction outcome loss': 0.4602447219315122, 'Total loss': 0.4602447219315122}
2022-11-28 04:31:18,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:18,656 INFO:     Epoch: 84
2022-11-28 04:31:19,303 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5031792230384294, 'Total loss': 0.5031792230384294} | train loss {'Reaction outcome loss': 0.46167845535473745, 'Total loss': 0.46167845535473745}
2022-11-28 04:31:19,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:19,303 INFO:     Epoch: 85
2022-11-28 04:31:19,953 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47764412885488466, 'Total loss': 0.47764412885488466} | train loss {'Reaction outcome loss': 0.4558033929740796, 'Total loss': 0.4558033929740796}
2022-11-28 04:31:19,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:19,953 INFO:     Epoch: 86
2022-11-28 04:31:20,602 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46408821087937024, 'Total loss': 0.46408821087937024} | train loss {'Reaction outcome loss': 0.45700217181908304, 'Total loss': 0.45700217181908304}
2022-11-28 04:31:20,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:20,602 INFO:     Epoch: 87
2022-11-28 04:31:21,255 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4787411176881125, 'Total loss': 0.4787411176881125} | train loss {'Reaction outcome loss': 0.46139010103022465, 'Total loss': 0.46139010103022465}
2022-11-28 04:31:21,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:21,256 INFO:     Epoch: 88
2022-11-28 04:31:21,909 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4940400199834691, 'Total loss': 0.4940400199834691} | train loss {'Reaction outcome loss': 0.4576153705110315, 'Total loss': 0.4576153705110315}
2022-11-28 04:31:21,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:21,909 INFO:     Epoch: 89
2022-11-28 04:31:22,558 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45761364143948224, 'Total loss': 0.45761364143948224} | train loss {'Reaction outcome loss': 0.4638771843470511, 'Total loss': 0.4638771843470511}
2022-11-28 04:31:22,559 INFO:     Found new best model at epoch 89
2022-11-28 04:31:22,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:22,559 INFO:     Epoch: 90
2022-11-28 04:31:23,206 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46619478491849675, 'Total loss': 0.46619478491849675} | train loss {'Reaction outcome loss': 0.4658614631559028, 'Total loss': 0.4658614631559028}
2022-11-28 04:31:23,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:23,206 INFO:     Epoch: 91
2022-11-28 04:31:23,857 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5133181456909623, 'Total loss': 0.5133181456909623} | train loss {'Reaction outcome loss': 0.4574632587857911, 'Total loss': 0.4574632587857911}
2022-11-28 04:31:23,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:23,857 INFO:     Epoch: 92
2022-11-28 04:31:24,502 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5045475121154341, 'Total loss': 0.5045475121154341} | train loss {'Reaction outcome loss': 0.46123358918750873, 'Total loss': 0.46123358918750873}
2022-11-28 04:31:24,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:24,503 INFO:     Epoch: 93
2022-11-28 04:31:25,146 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5031609625317329, 'Total loss': 0.5031609625317329} | train loss {'Reaction outcome loss': 0.461542421768679, 'Total loss': 0.461542421768679}
2022-11-28 04:31:25,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:25,147 INFO:     Epoch: 94
2022-11-28 04:31:25,797 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5070022607958594, 'Total loss': 0.5070022607958594} | train loss {'Reaction outcome loss': 0.4600241881047116, 'Total loss': 0.4600241881047116}
2022-11-28 04:31:25,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:25,797 INFO:     Epoch: 95
2022-11-28 04:31:26,445 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5150123626686806, 'Total loss': 0.5150123626686806} | train loss {'Reaction outcome loss': 0.4618396693687947, 'Total loss': 0.4618396693687947}
2022-11-28 04:31:26,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:26,446 INFO:     Epoch: 96
2022-11-28 04:31:27,092 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4778250580610231, 'Total loss': 0.4778250580610231} | train loss {'Reaction outcome loss': 0.4604734942683431, 'Total loss': 0.4604734942683431}
2022-11-28 04:31:27,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:27,092 INFO:     Epoch: 97
2022-11-28 04:31:27,744 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5106008129064427, 'Total loss': 0.5106008129064427} | train loss {'Reaction outcome loss': 0.4669013785534218, 'Total loss': 0.4669013785534218}
2022-11-28 04:31:27,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:27,744 INFO:     Epoch: 98
2022-11-28 04:31:28,395 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4941555566565935, 'Total loss': 0.4941555566565935} | train loss {'Reaction outcome loss': 0.4658224196096913, 'Total loss': 0.4658224196096913}
2022-11-28 04:31:28,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:28,395 INFO:     Epoch: 99
2022-11-28 04:31:29,043 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48481810335503067, 'Total loss': 0.48481810335503067} | train loss {'Reaction outcome loss': 0.4586734172017848, 'Total loss': 0.4586734172017848}
2022-11-28 04:31:29,043 INFO:     Best model found after epoch 90 of 100.
2022-11-28 04:31:29,043 INFO:   Done with stage: TRAINING
2022-11-28 04:31:29,043 INFO:   Starting stage: EVALUATION
2022-11-28 04:31:29,173 INFO:   Done with stage: EVALUATION
2022-11-28 04:31:29,173 INFO:   Leaving out SEQ value Fold_9
2022-11-28 04:31:29,185 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:31:29,185 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:31:29,829 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:31:29,829 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:31:29,897 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:31:29,897 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:31:29,897 INFO:     No hyperparam tuning for this model
2022-11-28 04:31:29,897 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:31:29,897 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:31:29,898 INFO:     None feature selector for col prot
2022-11-28 04:31:29,898 INFO:     None feature selector for col prot
2022-11-28 04:31:29,898 INFO:     None feature selector for col prot
2022-11-28 04:31:29,899 INFO:     None feature selector for col chem
2022-11-28 04:31:29,899 INFO:     None feature selector for col chem
2022-11-28 04:31:29,899 INFO:     None feature selector for col chem
2022-11-28 04:31:29,899 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:31:29,899 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:31:29,900 INFO:     Number of params in model 169651
2022-11-28 04:31:29,904 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:31:29,904 INFO:   Starting stage: TRAINING
2022-11-28 04:31:29,955 INFO:     Val loss before train {'Reaction outcome loss': 1.0814947072755208, 'Total loss': 1.0814947072755208}
2022-11-28 04:31:29,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:29,955 INFO:     Epoch: 0
2022-11-28 04:31:30,614 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5662078762596304, 'Total loss': 0.5662078762596304} | train loss {'Reaction outcome loss': 0.6774433217791893, 'Total loss': 0.6774433217791893}
2022-11-28 04:31:30,614 INFO:     Found new best model at epoch 0
2022-11-28 04:31:30,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:30,615 INFO:     Epoch: 1
2022-11-28 04:31:31,276 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5691132193261926, 'Total loss': 0.5691132193261926} | train loss {'Reaction outcome loss': 0.5759865366495572, 'Total loss': 0.5759865366495572}
2022-11-28 04:31:31,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:31,276 INFO:     Epoch: 2
2022-11-28 04:31:31,937 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5432574667713859, 'Total loss': 0.5432574667713859} | train loss {'Reaction outcome loss': 0.553769034171394, 'Total loss': 0.553769034171394}
2022-11-28 04:31:31,937 INFO:     Found new best model at epoch 2
2022-11-28 04:31:31,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:31,938 INFO:     Epoch: 3
2022-11-28 04:31:32,597 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5669884844259783, 'Total loss': 0.5669884844259783} | train loss {'Reaction outcome loss': 0.5403262600604339, 'Total loss': 0.5403262600604339}
2022-11-28 04:31:32,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:32,597 INFO:     Epoch: 4
2022-11-28 04:31:33,253 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.552039641209624, 'Total loss': 0.552039641209624} | train loss {'Reaction outcome loss': 0.5569662167596431, 'Total loss': 0.5569662167596431}
2022-11-28 04:31:33,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:33,253 INFO:     Epoch: 5
2022-11-28 04:31:33,913 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5714939311146736, 'Total loss': 0.5714939311146736} | train loss {'Reaction outcome loss': 0.521647922076315, 'Total loss': 0.521647922076315}
2022-11-28 04:31:33,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:33,913 INFO:     Epoch: 6
2022-11-28 04:31:34,574 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4755652993917465, 'Total loss': 0.4755652993917465} | train loss {'Reaction outcome loss': 0.5031954351707026, 'Total loss': 0.5031954351707026}
2022-11-28 04:31:34,574 INFO:     Found new best model at epoch 6
2022-11-28 04:31:34,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:34,575 INFO:     Epoch: 7
2022-11-28 04:31:35,229 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49834964153441513, 'Total loss': 0.49834964153441513} | train loss {'Reaction outcome loss': 0.49685115882983577, 'Total loss': 0.49685115882983577}
2022-11-28 04:31:35,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:35,229 INFO:     Epoch: 8
2022-11-28 04:31:35,886 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.526386178352616, 'Total loss': 0.526386178352616} | train loss {'Reaction outcome loss': 0.5007909923671228, 'Total loss': 0.5007909923671228}
2022-11-28 04:31:35,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:35,887 INFO:     Epoch: 9
2022-11-28 04:31:36,546 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5400951460681178, 'Total loss': 0.5400951460681178} | train loss {'Reaction outcome loss': 0.4839681653901633, 'Total loss': 0.4839681653901633}
2022-11-28 04:31:36,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:36,546 INFO:     Epoch: 10
2022-11-28 04:31:37,204 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4829154052686962, 'Total loss': 0.4829154052686962} | train loss {'Reaction outcome loss': 0.49294123917003635, 'Total loss': 0.49294123917003635}
2022-11-28 04:31:37,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:37,204 INFO:     Epoch: 11
2022-11-28 04:31:37,861 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45392908359115774, 'Total loss': 0.45392908359115774} | train loss {'Reaction outcome loss': 0.4796373239050993, 'Total loss': 0.4796373239050993}
2022-11-28 04:31:37,861 INFO:     Found new best model at epoch 11
2022-11-28 04:31:37,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:37,862 INFO:     Epoch: 12
2022-11-28 04:31:38,519 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.524459616873752, 'Total loss': 0.524459616873752} | train loss {'Reaction outcome loss': 0.48148354622516554, 'Total loss': 0.48148354622516554}
2022-11-28 04:31:38,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:38,520 INFO:     Epoch: 13
2022-11-28 04:31:39,181 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47844246944243257, 'Total loss': 0.47844246944243257} | train loss {'Reaction outcome loss': 0.4863459511475283, 'Total loss': 0.4863459511475283}
2022-11-28 04:31:39,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:39,182 INFO:     Epoch: 14
2022-11-28 04:31:39,840 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44801743904298, 'Total loss': 0.44801743904298} | train loss {'Reaction outcome loss': 0.4690851356215805, 'Total loss': 0.4690851356215805}
2022-11-28 04:31:39,840 INFO:     Found new best model at epoch 14
2022-11-28 04:31:39,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:39,840 INFO:     Epoch: 15
2022-11-28 04:31:40,498 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4811815013262359, 'Total loss': 0.4811815013262359} | train loss {'Reaction outcome loss': 0.4775132911528653, 'Total loss': 0.4775132911528653}
2022-11-28 04:31:40,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:40,498 INFO:     Epoch: 16
2022-11-28 04:31:41,153 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.475367779081518, 'Total loss': 0.475367779081518} | train loss {'Reaction outcome loss': 0.4780461144471458, 'Total loss': 0.4780461144471458}
2022-11-28 04:31:41,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:41,153 INFO:     Epoch: 17
2022-11-28 04:31:41,810 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5093798691576178, 'Total loss': 0.5093798691576178} | train loss {'Reaction outcome loss': 0.47332853894786314, 'Total loss': 0.47332853894786314}
2022-11-28 04:31:41,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:41,810 INFO:     Epoch: 18
2022-11-28 04:31:42,464 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4843194769187407, 'Total loss': 0.4843194769187407} | train loss {'Reaction outcome loss': 0.4667071367874138, 'Total loss': 0.4667071367874138}
2022-11-28 04:31:42,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:42,464 INFO:     Epoch: 19
2022-11-28 04:31:43,116 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4874936603009701, 'Total loss': 0.4874936603009701} | train loss {'Reaction outcome loss': 0.47751299297881994, 'Total loss': 0.47751299297881994}
2022-11-28 04:31:43,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:43,116 INFO:     Epoch: 20
2022-11-28 04:31:43,769 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4606627898121422, 'Total loss': 0.4606627898121422} | train loss {'Reaction outcome loss': 0.4697650625155522, 'Total loss': 0.4697650625155522}
2022-11-28 04:31:43,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:43,769 INFO:     Epoch: 21
2022-11-28 04:31:44,422 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46137915043668315, 'Total loss': 0.46137915043668315} | train loss {'Reaction outcome loss': 0.47200063890532445, 'Total loss': 0.47200063890532445}
2022-11-28 04:31:44,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:44,422 INFO:     Epoch: 22
2022-11-28 04:31:45,078 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4743279577656226, 'Total loss': 0.4743279577656226} | train loss {'Reaction outcome loss': 0.47733521021088127, 'Total loss': 0.47733521021088127}
2022-11-28 04:31:45,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:45,079 INFO:     Epoch: 23
2022-11-28 04:31:45,731 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4483305974440141, 'Total loss': 0.4483305974440141} | train loss {'Reaction outcome loss': 0.4674373540559761, 'Total loss': 0.4674373540559761}
2022-11-28 04:31:45,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:45,732 INFO:     Epoch: 24
2022-11-28 04:31:46,384 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4613810635425828, 'Total loss': 0.4613810635425828} | train loss {'Reaction outcome loss': 0.46340886793035246, 'Total loss': 0.46340886793035246}
2022-11-28 04:31:46,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:46,384 INFO:     Epoch: 25
2022-11-28 04:31:47,038 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46981262568045745, 'Total loss': 0.46981262568045745} | train loss {'Reaction outcome loss': 0.4656015098818883, 'Total loss': 0.4656015098818883}
2022-11-28 04:31:47,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:47,038 INFO:     Epoch: 26
2022-11-28 04:31:47,692 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44458587670868094, 'Total loss': 0.44458587670868094} | train loss {'Reaction outcome loss': 0.4736081414256501, 'Total loss': 0.4736081414256501}
2022-11-28 04:31:47,692 INFO:     Found new best model at epoch 26
2022-11-28 04:31:47,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:47,693 INFO:     Epoch: 27
2022-11-28 04:31:48,348 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48775129968469794, 'Total loss': 0.48775129968469794} | train loss {'Reaction outcome loss': 0.46478719062285934, 'Total loss': 0.46478719062285934}
2022-11-28 04:31:48,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:48,348 INFO:     Epoch: 28
2022-11-28 04:31:48,999 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4762370003895326, 'Total loss': 0.4762370003895326} | train loss {'Reaction outcome loss': 0.4693420829198621, 'Total loss': 0.4693420829198621}
2022-11-28 04:31:48,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:48,999 INFO:     Epoch: 29
2022-11-28 04:31:49,650 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4655714153566144, 'Total loss': 0.4655714153566144} | train loss {'Reaction outcome loss': 0.46956312674501166, 'Total loss': 0.46956312674501166}
2022-11-28 04:31:49,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:49,650 INFO:     Epoch: 30
2022-11-28 04:31:50,301 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4623911262235858, 'Total loss': 0.4623911262235858} | train loss {'Reaction outcome loss': 0.48081482934806996, 'Total loss': 0.48081482934806996}
2022-11-28 04:31:50,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:50,302 INFO:     Epoch: 31
2022-11-28 04:31:50,952 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4623612002892928, 'Total loss': 0.4623612002892928} | train loss {'Reaction outcome loss': 0.47798403516140303, 'Total loss': 0.47798403516140303}
2022-11-28 04:31:50,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:50,953 INFO:     Epoch: 32
2022-11-28 04:31:51,610 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48563715476881375, 'Total loss': 0.48563715476881375} | train loss {'Reaction outcome loss': 0.4658104453409309, 'Total loss': 0.4658104453409309}
2022-11-28 04:31:51,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:51,611 INFO:     Epoch: 33
2022-11-28 04:31:52,265 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4799614616415717, 'Total loss': 0.4799614616415717} | train loss {'Reaction outcome loss': 0.4747209314875275, 'Total loss': 0.4747209314875275}
2022-11-28 04:31:52,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:52,265 INFO:     Epoch: 34
2022-11-28 04:31:52,920 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5083691846917976, 'Total loss': 0.5083691846917976} | train loss {'Reaction outcome loss': 0.47943045132555945, 'Total loss': 0.47943045132555945}
2022-11-28 04:31:52,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:52,920 INFO:     Epoch: 35
2022-11-28 04:31:53,572 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4726593423296105, 'Total loss': 0.4726593423296105} | train loss {'Reaction outcome loss': 0.4766398659541539, 'Total loss': 0.4766398659541539}
2022-11-28 04:31:53,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:53,573 INFO:     Epoch: 36
2022-11-28 04:31:54,230 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4690741344609044, 'Total loss': 0.4690741344609044} | train loss {'Reaction outcome loss': 0.4666978410682697, 'Total loss': 0.4666978410682697}
2022-11-28 04:31:54,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:54,230 INFO:     Epoch: 37
2022-11-28 04:31:54,886 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43823092261498625, 'Total loss': 0.43823092261498625} | train loss {'Reaction outcome loss': 0.4821893541436446, 'Total loss': 0.4821893541436446}
2022-11-28 04:31:54,886 INFO:     Found new best model at epoch 37
2022-11-28 04:31:54,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:54,887 INFO:     Epoch: 38
2022-11-28 04:31:55,539 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4466761238873005, 'Total loss': 0.4466761238873005} | train loss {'Reaction outcome loss': 0.47129919165783085, 'Total loss': 0.47129919165783085}
2022-11-28 04:31:55,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:55,540 INFO:     Epoch: 39
2022-11-28 04:31:56,193 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45050271769816225, 'Total loss': 0.45050271769816225} | train loss {'Reaction outcome loss': 0.4720108961226486, 'Total loss': 0.4720108961226486}
2022-11-28 04:31:56,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:56,193 INFO:     Epoch: 40
2022-11-28 04:31:56,848 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4936406978152015, 'Total loss': 0.4936406978152015} | train loss {'Reaction outcome loss': 0.46716748992441154, 'Total loss': 0.46716748992441154}
2022-11-28 04:31:56,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:56,848 INFO:     Epoch: 41
2022-11-28 04:31:57,499 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5338951484723524, 'Total loss': 0.5338951484723524} | train loss {'Reaction outcome loss': 0.47168089913935796, 'Total loss': 0.47168089913935796}
2022-11-28 04:31:57,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:57,499 INFO:     Epoch: 42
2022-11-28 04:31:58,150 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43858604065396567, 'Total loss': 0.43858604065396567} | train loss {'Reaction outcome loss': 0.47905870423339275, 'Total loss': 0.47905870423339275}
2022-11-28 04:31:58,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:58,151 INFO:     Epoch: 43
2022-11-28 04:31:58,808 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4742966317995028, 'Total loss': 0.4742966317995028} | train loss {'Reaction outcome loss': 0.47436000635990727, 'Total loss': 0.47436000635990727}
2022-11-28 04:31:58,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:58,808 INFO:     Epoch: 44
2022-11-28 04:31:59,459 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.478628777644851, 'Total loss': 0.478628777644851} | train loss {'Reaction outcome loss': 0.46915256192809657, 'Total loss': 0.46915256192809657}
2022-11-28 04:31:59,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:31:59,460 INFO:     Epoch: 45
2022-11-28 04:32:00,114 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4428366906940937, 'Total loss': 0.4428366906940937} | train loss {'Reaction outcome loss': 0.46467890469772133, 'Total loss': 0.46467890469772133}
2022-11-28 04:32:00,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:00,114 INFO:     Epoch: 46
2022-11-28 04:32:00,764 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47297966039993544, 'Total loss': 0.47297966039993544} | train loss {'Reaction outcome loss': 0.47652011298336966, 'Total loss': 0.47652011298336966}
2022-11-28 04:32:00,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:00,764 INFO:     Epoch: 47
2022-11-28 04:32:01,415 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46658163754777476, 'Total loss': 0.46658163754777476} | train loss {'Reaction outcome loss': 0.46700604465085005, 'Total loss': 0.46700604465085005}
2022-11-28 04:32:01,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:01,415 INFO:     Epoch: 48
2022-11-28 04:32:02,073 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4382268810136752, 'Total loss': 0.4382268810136752} | train loss {'Reaction outcome loss': 0.4629872318824776, 'Total loss': 0.4629872318824776}
2022-11-28 04:32:02,073 INFO:     Found new best model at epoch 48
2022-11-28 04:32:02,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:02,074 INFO:     Epoch: 49
2022-11-28 04:32:02,729 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45567354221235623, 'Total loss': 0.45567354221235623} | train loss {'Reaction outcome loss': 0.466860856544151, 'Total loss': 0.466860856544151}
2022-11-28 04:32:02,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:02,729 INFO:     Epoch: 50
2022-11-28 04:32:03,382 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44140215996991505, 'Total loss': 0.44140215996991505} | train loss {'Reaction outcome loss': 0.46674019084330876, 'Total loss': 0.46674019084330876}
2022-11-28 04:32:03,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:03,382 INFO:     Epoch: 51
2022-11-28 04:32:04,037 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5216205661947076, 'Total loss': 0.5216205661947076} | train loss {'Reaction outcome loss': 0.4644428659909167, 'Total loss': 0.4644428659909167}
2022-11-28 04:32:04,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:04,037 INFO:     Epoch: 52
2022-11-28 04:32:04,691 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45863619819283485, 'Total loss': 0.45863619819283485} | train loss {'Reaction outcome loss': 0.46804761222982216, 'Total loss': 0.46804761222982216}
2022-11-28 04:32:04,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:04,691 INFO:     Epoch: 53
2022-11-28 04:32:05,345 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44588172842155804, 'Total loss': 0.44588172842155804} | train loss {'Reaction outcome loss': 0.45764346232945063, 'Total loss': 0.45764346232945063}
2022-11-28 04:32:05,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:05,345 INFO:     Epoch: 54
2022-11-28 04:32:06,003 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46717283434488555, 'Total loss': 0.46717283434488555} | train loss {'Reaction outcome loss': 0.46435669649709094, 'Total loss': 0.46435669649709094}
2022-11-28 04:32:06,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:06,003 INFO:     Epoch: 55
2022-11-28 04:32:06,657 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4788167415694757, 'Total loss': 0.4788167415694757} | train loss {'Reaction outcome loss': 0.46809000787815375, 'Total loss': 0.46809000787815375}
2022-11-28 04:32:06,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:06,658 INFO:     Epoch: 56
2022-11-28 04:32:07,313 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45937011729587207, 'Total loss': 0.45937011729587207} | train loss {'Reaction outcome loss': 0.46884014271482494, 'Total loss': 0.46884014271482494}
2022-11-28 04:32:07,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:07,313 INFO:     Epoch: 57
2022-11-28 04:32:07,968 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46778432008895005, 'Total loss': 0.46778432008895005} | train loss {'Reaction outcome loss': 0.46165042261966327, 'Total loss': 0.46165042261966327}
2022-11-28 04:32:07,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:07,968 INFO:     Epoch: 58
2022-11-28 04:32:08,620 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46048800325529143, 'Total loss': 0.46048800325529143} | train loss {'Reaction outcome loss': 0.4726578452085194, 'Total loss': 0.4726578452085194}
2022-11-28 04:32:08,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:08,620 INFO:     Epoch: 59
2022-11-28 04:32:09,276 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4542842995036732, 'Total loss': 0.4542842995036732} | train loss {'Reaction outcome loss': 0.45897085032603036, 'Total loss': 0.45897085032603036}
2022-11-28 04:32:09,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:09,276 INFO:     Epoch: 60
2022-11-28 04:32:09,929 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4841366113925522, 'Total loss': 0.4841366113925522} | train loss {'Reaction outcome loss': 0.4623453088617518, 'Total loss': 0.4623453088617518}
2022-11-28 04:32:09,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:09,930 INFO:     Epoch: 61
2022-11-28 04:32:10,586 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43848535452376713, 'Total loss': 0.43848535452376713} | train loss {'Reaction outcome loss': 0.4652451019176105, 'Total loss': 0.4652451019176105}
2022-11-28 04:32:10,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:10,586 INFO:     Epoch: 62
2022-11-28 04:32:11,241 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45599650049751456, 'Total loss': 0.45599650049751456} | train loss {'Reaction outcome loss': 0.47553151079758943, 'Total loss': 0.47553151079758943}
2022-11-28 04:32:11,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:11,241 INFO:     Epoch: 63
2022-11-28 04:32:11,896 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4301734810525721, 'Total loss': 0.4301734810525721} | train loss {'Reaction outcome loss': 0.46653166684785835, 'Total loss': 0.46653166684785835}
2022-11-28 04:32:11,896 INFO:     Found new best model at epoch 63
2022-11-28 04:32:11,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:11,897 INFO:     Epoch: 64
2022-11-28 04:32:12,551 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47926615889776836, 'Total loss': 0.47926615889776836} | train loss {'Reaction outcome loss': 0.45964138734678506, 'Total loss': 0.45964138734678506}
2022-11-28 04:32:12,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:12,551 INFO:     Epoch: 65
2022-11-28 04:32:13,204 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46961165067147126, 'Total loss': 0.46961165067147126} | train loss {'Reaction outcome loss': 0.4735979963290064, 'Total loss': 0.4735979963290064}
2022-11-28 04:32:13,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:13,204 INFO:     Epoch: 66
2022-11-28 04:32:13,859 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5302661562507803, 'Total loss': 0.5302661562507803} | train loss {'Reaction outcome loss': 0.4635913150483056, 'Total loss': 0.4635913150483056}
2022-11-28 04:32:13,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:13,859 INFO:     Epoch: 67
2022-11-28 04:32:14,514 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46116870878772304, 'Total loss': 0.46116870878772304} | train loss {'Reaction outcome loss': 0.4673212274554589, 'Total loss': 0.4673212274554589}
2022-11-28 04:32:14,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:14,515 INFO:     Epoch: 68
2022-11-28 04:32:15,168 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4798430089246143, 'Total loss': 0.4798430089246143} | train loss {'Reaction outcome loss': 0.4680772030401809, 'Total loss': 0.4680772030401809}
2022-11-28 04:32:15,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:15,169 INFO:     Epoch: 69
2022-11-28 04:32:15,821 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4558210013942285, 'Total loss': 0.4558210013942285} | train loss {'Reaction outcome loss': 0.48127099720813965, 'Total loss': 0.48127099720813965}
2022-11-28 04:32:15,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:15,821 INFO:     Epoch: 70
2022-11-28 04:32:16,475 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4952845746143298, 'Total loss': 0.4952845746143298} | train loss {'Reaction outcome loss': 0.4780419988308841, 'Total loss': 0.4780419988308841}
2022-11-28 04:32:16,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:16,475 INFO:     Epoch: 71
2022-11-28 04:32:17,132 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4536030942743475, 'Total loss': 0.4536030942743475} | train loss {'Reaction outcome loss': 0.4705045373001803, 'Total loss': 0.4705045373001803}
2022-11-28 04:32:17,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:17,132 INFO:     Epoch: 72
2022-11-28 04:32:17,787 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5247219079597429, 'Total loss': 0.5247219079597429} | train loss {'Reaction outcome loss': 0.4777703582938866, 'Total loss': 0.4777703582938866}
2022-11-28 04:32:17,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:17,787 INFO:     Epoch: 73
2022-11-28 04:32:18,438 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45363782955841586, 'Total loss': 0.45363782955841586} | train loss {'Reaction outcome loss': 0.48660735787469367, 'Total loss': 0.48660735787469367}
2022-11-28 04:32:18,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:18,439 INFO:     Epoch: 74
2022-11-28 04:32:19,092 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49812396277080884, 'Total loss': 0.49812396277080884} | train loss {'Reaction outcome loss': 0.46931558898706666, 'Total loss': 0.46931558898706666}
2022-11-28 04:32:19,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:19,092 INFO:     Epoch: 75
2022-11-28 04:32:19,745 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.449628545479341, 'Total loss': 0.449628545479341} | train loss {'Reaction outcome loss': 0.4807986065685025, 'Total loss': 0.4807986065685025}
2022-11-28 04:32:19,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:19,745 INFO:     Epoch: 76
2022-11-28 04:32:20,399 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4597214521332221, 'Total loss': 0.4597214521332221} | train loss {'Reaction outcome loss': 0.4693769361326086, 'Total loss': 0.4693769361326086}
2022-11-28 04:32:20,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:20,399 INFO:     Epoch: 77
2022-11-28 04:32:21,057 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45457926426421513, 'Total loss': 0.45457926426421513} | train loss {'Reaction outcome loss': 0.4730450297717141, 'Total loss': 0.4730450297717141}
2022-11-28 04:32:21,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:21,057 INFO:     Epoch: 78
2022-11-28 04:32:21,710 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4669299555773085, 'Total loss': 0.4669299555773085} | train loss {'Reaction outcome loss': 0.4732964789185688, 'Total loss': 0.4732964789185688}
2022-11-28 04:32:21,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:21,710 INFO:     Epoch: 79
2022-11-28 04:32:22,365 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4689127918840809, 'Total loss': 0.4689127918840809} | train loss {'Reaction outcome loss': 0.4574901752988337, 'Total loss': 0.4574901752988337}
2022-11-28 04:32:22,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:22,365 INFO:     Epoch: 80
2022-11-28 04:32:23,017 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4649142531508749, 'Total loss': 0.4649142531508749} | train loss {'Reaction outcome loss': 0.4659907938497752, 'Total loss': 0.4659907938497752}
2022-11-28 04:32:23,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:23,017 INFO:     Epoch: 81
2022-11-28 04:32:23,672 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49654785137284885, 'Total loss': 0.49654785137284885} | train loss {'Reaction outcome loss': 0.46221974516204495, 'Total loss': 0.46221974516204495}
2022-11-28 04:32:23,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:23,673 INFO:     Epoch: 82
2022-11-28 04:32:24,323 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4463345201855356, 'Total loss': 0.4463345201855356} | train loss {'Reaction outcome loss': 0.4671655318394364, 'Total loss': 0.4671655318394364}
2022-11-28 04:32:24,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:24,323 INFO:     Epoch: 83
2022-11-28 04:32:24,971 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4443823539397933, 'Total loss': 0.4443823539397933} | train loss {'Reaction outcome loss': 0.46919603555308664, 'Total loss': 0.46919603555308664}
2022-11-28 04:32:24,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:24,972 INFO:     Epoch: 84
2022-11-28 04:32:25,623 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.478109789842909, 'Total loss': 0.478109789842909} | train loss {'Reaction outcome loss': 0.47640390995784326, 'Total loss': 0.47640390995784326}
2022-11-28 04:32:25,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:25,623 INFO:     Epoch: 85
2022-11-28 04:32:26,274 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5089993707158349, 'Total loss': 0.5089993707158349} | train loss {'Reaction outcome loss': 0.500379928391472, 'Total loss': 0.500379928391472}
2022-11-28 04:32:26,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:26,274 INFO:     Epoch: 86
2022-11-28 04:32:26,927 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.461037334732034, 'Total loss': 0.461037334732034} | train loss {'Reaction outcome loss': 0.4754299099146113, 'Total loss': 0.4754299099146113}
2022-11-28 04:32:26,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:26,927 INFO:     Epoch: 87
2022-11-28 04:32:27,580 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46778630126606335, 'Total loss': 0.46778630126606335} | train loss {'Reaction outcome loss': 0.4774596265211762, 'Total loss': 0.4774596265211762}
2022-11-28 04:32:27,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:27,580 INFO:     Epoch: 88
2022-11-28 04:32:28,233 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4480783177370375, 'Total loss': 0.4480783177370375} | train loss {'Reaction outcome loss': 0.4641788680000826, 'Total loss': 0.4641788680000826}
2022-11-28 04:32:28,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:28,233 INFO:     Epoch: 89
2022-11-28 04:32:28,888 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44381856816736137, 'Total loss': 0.44381856816736137} | train loss {'Reaction outcome loss': 0.47557650476332136, 'Total loss': 0.47557650476332136}
2022-11-28 04:32:28,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:28,888 INFO:     Epoch: 90
2022-11-28 04:32:29,542 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46057955074039375, 'Total loss': 0.46057955074039375} | train loss {'Reaction outcome loss': 0.45852551910166556, 'Total loss': 0.45852551910166556}
2022-11-28 04:32:29,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:29,542 INFO:     Epoch: 91
2022-11-28 04:32:30,193 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4651095934889533, 'Total loss': 0.4651095934889533} | train loss {'Reaction outcome loss': 0.4589757505834465, 'Total loss': 0.4589757505834465}
2022-11-28 04:32:30,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:30,194 INFO:     Epoch: 92
2022-11-28 04:32:30,845 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47184759310700675, 'Total loss': 0.47184759310700675} | train loss {'Reaction outcome loss': 0.4661288140916646, 'Total loss': 0.4661288140916646}
2022-11-28 04:32:30,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:30,845 INFO:     Epoch: 93
2022-11-28 04:32:31,504 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.480597562071952, 'Total loss': 0.480597562071952} | train loss {'Reaction outcome loss': 0.46385139123035163, 'Total loss': 0.46385139123035163}
2022-11-28 04:32:31,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:31,504 INFO:     Epoch: 94
2022-11-28 04:32:32,156 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48639683764089237, 'Total loss': 0.48639683764089237} | train loss {'Reaction outcome loss': 0.4621341442349951, 'Total loss': 0.4621341442349951}
2022-11-28 04:32:32,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:32,156 INFO:     Epoch: 95
2022-11-28 04:32:32,807 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4861953468485312, 'Total loss': 0.4861953468485312} | train loss {'Reaction outcome loss': 0.4642581008827155, 'Total loss': 0.4642581008827155}
2022-11-28 04:32:32,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:32,807 INFO:     Epoch: 96
2022-11-28 04:32:33,463 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4540955905209888, 'Total loss': 0.4540955905209888} | train loss {'Reaction outcome loss': 0.46985242924528564, 'Total loss': 0.46985242924528564}
2022-11-28 04:32:33,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:33,463 INFO:     Epoch: 97
2022-11-28 04:32:34,116 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5265152982690118, 'Total loss': 0.5265152982690118} | train loss {'Reaction outcome loss': 0.4615151252039531, 'Total loss': 0.4615151252039531}
2022-11-28 04:32:34,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:34,117 INFO:     Epoch: 98
2022-11-28 04:32:34,771 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4642257114703005, 'Total loss': 0.4642257114703005} | train loss {'Reaction outcome loss': 0.4756783701268285, 'Total loss': 0.4756783701268285}
2022-11-28 04:32:34,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:34,772 INFO:     Epoch: 99
2022-11-28 04:32:35,423 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5172458189454946, 'Total loss': 0.5172458189454946} | train loss {'Reaction outcome loss': 0.4668865804730157, 'Total loss': 0.4668865804730157}
2022-11-28 04:32:35,423 INFO:     Best model found after epoch 64 of 100.
2022-11-28 04:32:35,423 INFO:   Done with stage: TRAINING
2022-11-28 04:32:35,423 INFO:   Starting stage: EVALUATION
2022-11-28 04:32:35,542 INFO:   Done with stage: EVALUATION
2022-11-28 04:32:35,551 INFO:   Leaving out SEQ value Fold_0
2022-11-28 04:32:35,564 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:32:35,564 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:32:36,209 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:32:36,209 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:32:36,276 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:32:36,277 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:32:36,277 INFO:     No hyperparam tuning for this model
2022-11-28 04:32:36,277 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:32:36,277 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:32:36,277 INFO:     None feature selector for col prot
2022-11-28 04:32:36,278 INFO:     None feature selector for col prot
2022-11-28 04:32:36,278 INFO:     None feature selector for col prot
2022-11-28 04:32:36,278 INFO:     None feature selector for col chem
2022-11-28 04:32:36,278 INFO:     None feature selector for col chem
2022-11-28 04:32:36,278 INFO:     None feature selector for col chem
2022-11-28 04:32:36,278 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:32:36,278 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:32:36,280 INFO:     Number of params in model 169651
2022-11-28 04:32:36,283 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:32:36,283 INFO:   Starting stage: TRAINING
2022-11-28 04:32:36,334 INFO:     Val loss before train {'Reaction outcome loss': 0.9618252983147447, 'Total loss': 0.9618252983147447}
2022-11-28 04:32:36,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:36,334 INFO:     Epoch: 0
2022-11-28 04:32:36,988 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5667336156422441, 'Total loss': 0.5667336156422441} | train loss {'Reaction outcome loss': 0.7027310110055484, 'Total loss': 0.7027310110055484}
2022-11-28 04:32:36,988 INFO:     Found new best model at epoch 0
2022-11-28 04:32:36,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:36,989 INFO:     Epoch: 1
2022-11-28 04:32:37,643 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5924447260119698, 'Total loss': 0.5924447260119698} | train loss {'Reaction outcome loss': 0.5972668861570628, 'Total loss': 0.5972668861570628}
2022-11-28 04:32:37,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:37,643 INFO:     Epoch: 2
2022-11-28 04:32:38,295 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5180038078264757, 'Total loss': 0.5180038078264757} | train loss {'Reaction outcome loss': 0.5735590555045286, 'Total loss': 0.5735590555045286}
2022-11-28 04:32:38,295 INFO:     Found new best model at epoch 2
2022-11-28 04:32:38,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:38,295 INFO:     Epoch: 3
2022-11-28 04:32:38,952 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5045176764780824, 'Total loss': 0.5045176764780824} | train loss {'Reaction outcome loss': 0.5491443220752212, 'Total loss': 0.5491443220752212}
2022-11-28 04:32:38,952 INFO:     Found new best model at epoch 3
2022-11-28 04:32:38,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:38,953 INFO:     Epoch: 4
2022-11-28 04:32:39,605 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5141525722362779, 'Total loss': 0.5141525722362779} | train loss {'Reaction outcome loss': 0.53426016826439, 'Total loss': 0.53426016826439}
2022-11-28 04:32:39,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:39,605 INFO:     Epoch: 5
2022-11-28 04:32:40,261 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5031082606451078, 'Total loss': 0.5031082606451078} | train loss {'Reaction outcome loss': 0.532640842291025, 'Total loss': 0.532640842291025}
2022-11-28 04:32:40,261 INFO:     Found new best model at epoch 5
2022-11-28 04:32:40,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:40,262 INFO:     Epoch: 6
2022-11-28 04:32:40,916 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4986779953945767, 'Total loss': 0.4986779953945767} | train loss {'Reaction outcome loss': 0.5208251536013144, 'Total loss': 0.5208251536013144}
2022-11-28 04:32:40,916 INFO:     Found new best model at epoch 6
2022-11-28 04:32:40,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:40,917 INFO:     Epoch: 7
2022-11-28 04:32:41,571 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5461753572929989, 'Total loss': 0.5461753572929989} | train loss {'Reaction outcome loss': 0.5126719860518388, 'Total loss': 0.5126719860518388}
2022-11-28 04:32:41,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:41,573 INFO:     Epoch: 8
2022-11-28 04:32:42,221 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48383812741799787, 'Total loss': 0.48383812741799787} | train loss {'Reaction outcome loss': 0.5005895432069717, 'Total loss': 0.5005895432069717}
2022-11-28 04:32:42,222 INFO:     Found new best model at epoch 8
2022-11-28 04:32:42,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:42,222 INFO:     Epoch: 9
2022-11-28 04:32:42,878 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4536974633281881, 'Total loss': 0.4536974633281881} | train loss {'Reaction outcome loss': 0.5078711031902174, 'Total loss': 0.5078711031902174}
2022-11-28 04:32:42,879 INFO:     Found new best model at epoch 9
2022-11-28 04:32:42,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:42,879 INFO:     Epoch: 10
2022-11-28 04:32:43,529 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5427796441045675, 'Total loss': 0.5427796441045675} | train loss {'Reaction outcome loss': 0.5049431130953645, 'Total loss': 0.5049431130953645}
2022-11-28 04:32:43,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:43,530 INFO:     Epoch: 11
2022-11-28 04:32:44,180 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4619860757480968, 'Total loss': 0.4619860757480968} | train loss {'Reaction outcome loss': 0.4970207349793148, 'Total loss': 0.4970207349793148}
2022-11-28 04:32:44,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:44,180 INFO:     Epoch: 12
2022-11-28 04:32:44,834 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46451920846646483, 'Total loss': 0.46451920846646483} | train loss {'Reaction outcome loss': 0.4911535747107948, 'Total loss': 0.4911535747107948}
2022-11-28 04:32:44,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:44,834 INFO:     Epoch: 13
2022-11-28 04:32:45,491 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4581318385899067, 'Total loss': 0.4581318385899067} | train loss {'Reaction outcome loss': 0.4865634677562154, 'Total loss': 0.4865634677562154}
2022-11-28 04:32:45,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:45,492 INFO:     Epoch: 14
2022-11-28 04:32:46,145 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4669638052582741, 'Total loss': 0.4669638052582741} | train loss {'Reaction outcome loss': 0.49853089355264113, 'Total loss': 0.49853089355264113}
2022-11-28 04:32:46,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:46,145 INFO:     Epoch: 15
2022-11-28 04:32:46,800 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5214555636048317, 'Total loss': 0.5214555636048317} | train loss {'Reaction outcome loss': 0.5000803435017706, 'Total loss': 0.5000803435017706}
2022-11-28 04:32:46,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:46,800 INFO:     Epoch: 16
2022-11-28 04:32:47,452 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4849839345975356, 'Total loss': 0.4849839345975356} | train loss {'Reaction outcome loss': 0.5029449413421183, 'Total loss': 0.5029449413421183}
2022-11-28 04:32:47,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:47,452 INFO:     Epoch: 17
2022-11-28 04:32:48,104 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4783084060658108, 'Total loss': 0.4783084060658108} | train loss {'Reaction outcome loss': 0.4942016760377507, 'Total loss': 0.4942016760377507}
2022-11-28 04:32:48,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:48,105 INFO:     Epoch: 18
2022-11-28 04:32:48,754 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4373313466256315, 'Total loss': 0.4373313466256315} | train loss {'Reaction outcome loss': 0.47732536817489846, 'Total loss': 0.47732536817489846}
2022-11-28 04:32:48,754 INFO:     Found new best model at epoch 18
2022-11-28 04:32:48,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:48,755 INFO:     Epoch: 19
2022-11-28 04:32:49,407 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45439915460619057, 'Total loss': 0.45439915460619057} | train loss {'Reaction outcome loss': 0.4824238762802441, 'Total loss': 0.4824238762802441}
2022-11-28 04:32:49,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:49,407 INFO:     Epoch: 20
2022-11-28 04:32:50,057 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5420228534124114, 'Total loss': 0.5420228534124114} | train loss {'Reaction outcome loss': 0.4727233975281117, 'Total loss': 0.4727233975281117}
2022-11-28 04:32:50,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:50,058 INFO:     Epoch: 21
2022-11-28 04:32:50,708 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45528564331206406, 'Total loss': 0.45528564331206406} | train loss {'Reaction outcome loss': 0.47432935636053203, 'Total loss': 0.47432935636053203}
2022-11-28 04:32:50,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:50,708 INFO:     Epoch: 22
2022-11-28 04:32:51,360 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48491394316608255, 'Total loss': 0.48491394316608255} | train loss {'Reaction outcome loss': 0.48568167522368644, 'Total loss': 0.48568167522368644}
2022-11-28 04:32:51,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:51,360 INFO:     Epoch: 23
2022-11-28 04:32:52,011 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5000085488639094, 'Total loss': 0.5000085488639094} | train loss {'Reaction outcome loss': 0.47034221097284, 'Total loss': 0.47034221097284}
2022-11-28 04:32:52,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:52,012 INFO:     Epoch: 24
2022-11-28 04:32:52,663 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45958915081891144, 'Total loss': 0.45958915081891144} | train loss {'Reaction outcome loss': 0.4763710705435228, 'Total loss': 0.4763710705435228}
2022-11-28 04:32:52,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:52,663 INFO:     Epoch: 25
2022-11-28 04:32:53,314 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4508205188268965, 'Total loss': 0.4508205188268965} | train loss {'Reaction outcome loss': 0.47386771523175, 'Total loss': 0.47386771523175}
2022-11-28 04:32:53,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:53,314 INFO:     Epoch: 26
2022-11-28 04:32:53,970 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4525020102208311, 'Total loss': 0.4525020102208311} | train loss {'Reaction outcome loss': 0.46925710158249145, 'Total loss': 0.46925710158249145}
2022-11-28 04:32:53,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:53,970 INFO:     Epoch: 27
2022-11-28 04:32:54,620 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4698880829594352, 'Total loss': 0.4698880829594352} | train loss {'Reaction outcome loss': 0.4647551492640847, 'Total loss': 0.4647551492640847}
2022-11-28 04:32:54,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:54,621 INFO:     Epoch: 28
2022-11-28 04:32:55,272 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46638873321088875, 'Total loss': 0.46638873321088875} | train loss {'Reaction outcome loss': 0.4765008582397994, 'Total loss': 0.4765008582397994}
2022-11-28 04:32:55,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:55,272 INFO:     Epoch: 29
2022-11-28 04:32:55,927 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44137057408013125, 'Total loss': 0.44137057408013125} | train loss {'Reaction outcome loss': 0.4701453755017717, 'Total loss': 0.4701453755017717}
2022-11-28 04:32:55,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:55,927 INFO:     Epoch: 30
2022-11-28 04:32:56,582 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4509317360141061, 'Total loss': 0.4509317360141061} | train loss {'Reaction outcome loss': 0.4609947698077692, 'Total loss': 0.4609947698077692}
2022-11-28 04:32:56,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:56,582 INFO:     Epoch: 31
2022-11-28 04:32:57,233 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4362075027417053, 'Total loss': 0.4362075027417053} | train loss {'Reaction outcome loss': 0.46953992702459035, 'Total loss': 0.46953992702459035}
2022-11-28 04:32:57,233 INFO:     Found new best model at epoch 31
2022-11-28 04:32:57,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:57,234 INFO:     Epoch: 32
2022-11-28 04:32:57,888 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4684805135157975, 'Total loss': 0.4684805135157975} | train loss {'Reaction outcome loss': 0.4619711820745034, 'Total loss': 0.4619711820745034}
2022-11-28 04:32:57,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:57,888 INFO:     Epoch: 33
2022-11-28 04:32:58,540 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46388069133866916, 'Total loss': 0.46388069133866916} | train loss {'Reaction outcome loss': 0.47028964733787876, 'Total loss': 0.47028964733787876}
2022-11-28 04:32:58,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:58,541 INFO:     Epoch: 34
2022-11-28 04:32:59,193 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.450031693008813, 'Total loss': 0.450031693008813} | train loss {'Reaction outcome loss': 0.4704261525752785, 'Total loss': 0.4704261525752785}
2022-11-28 04:32:59,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:59,193 INFO:     Epoch: 35
2022-11-28 04:32:59,846 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45346506786617363, 'Total loss': 0.45346506786617363} | train loss {'Reaction outcome loss': 0.463458800484777, 'Total loss': 0.463458800484777}
2022-11-28 04:32:59,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:32:59,846 INFO:     Epoch: 36
2022-11-28 04:33:00,496 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5083544020625678, 'Total loss': 0.5083544020625678} | train loss {'Reaction outcome loss': 0.47094220888276817, 'Total loss': 0.47094220888276817}
2022-11-28 04:33:00,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:00,496 INFO:     Epoch: 37
2022-11-28 04:33:01,147 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46456068280068313, 'Total loss': 0.46456068280068313} | train loss {'Reaction outcome loss': 0.4679758957764398, 'Total loss': 0.4679758957764398}
2022-11-28 04:33:01,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:01,147 INFO:     Epoch: 38
2022-11-28 04:33:01,797 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45656647194515576, 'Total loss': 0.45656647194515576} | train loss {'Reaction outcome loss': 0.4688040300419456, 'Total loss': 0.4688040300419456}
2022-11-28 04:33:01,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:01,797 INFO:     Epoch: 39
2022-11-28 04:33:02,447 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44100678305734287, 'Total loss': 0.44100678305734287} | train loss {'Reaction outcome loss': 0.4686797111924843, 'Total loss': 0.4686797111924843}
2022-11-28 04:33:02,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:02,447 INFO:     Epoch: 40
2022-11-28 04:33:03,099 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47282027995044534, 'Total loss': 0.47282027995044534} | train loss {'Reaction outcome loss': 0.4645692900969432, 'Total loss': 0.4645692900969432}
2022-11-28 04:33:03,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:03,100 INFO:     Epoch: 41
2022-11-28 04:33:03,752 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4599233940243721, 'Total loss': 0.4599233940243721} | train loss {'Reaction outcome loss': 0.4654294757949196, 'Total loss': 0.4654294757949196}
2022-11-28 04:33:03,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:03,752 INFO:     Epoch: 42
2022-11-28 04:33:04,404 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4436857422644442, 'Total loss': 0.4436857422644442} | train loss {'Reaction outcome loss': 0.4743676196467056, 'Total loss': 0.4743676196467056}
2022-11-28 04:33:04,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:04,404 INFO:     Epoch: 43
2022-11-28 04:33:05,058 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4505127106200565, 'Total loss': 0.4505127106200565} | train loss {'Reaction outcome loss': 0.4685003444069793, 'Total loss': 0.4685003444069793}
2022-11-28 04:33:05,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:05,058 INFO:     Epoch: 44
2022-11-28 04:33:05,709 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44807626205411827, 'Total loss': 0.44807626205411827} | train loss {'Reaction outcome loss': 0.46352963692504867, 'Total loss': 0.46352963692504867}
2022-11-28 04:33:05,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:05,709 INFO:     Epoch: 45
2022-11-28 04:33:06,363 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4515592228959907, 'Total loss': 0.4515592228959907} | train loss {'Reaction outcome loss': 0.4662049816306756, 'Total loss': 0.4662049816306756}
2022-11-28 04:33:06,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:06,363 INFO:     Epoch: 46
2022-11-28 04:33:07,015 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44639080661264335, 'Total loss': 0.44639080661264335} | train loss {'Reaction outcome loss': 0.4581003417128976, 'Total loss': 0.4581003417128976}
2022-11-28 04:33:07,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:07,015 INFO:     Epoch: 47
2022-11-28 04:33:07,671 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4657712263817137, 'Total loss': 0.4657712263817137} | train loss {'Reaction outcome loss': 0.4709383456209893, 'Total loss': 0.4709383456209893}
2022-11-28 04:33:07,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:07,671 INFO:     Epoch: 48
2022-11-28 04:33:08,321 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.468586112965237, 'Total loss': 0.468586112965237} | train loss {'Reaction outcome loss': 0.4641562766633053, 'Total loss': 0.4641562766633053}
2022-11-28 04:33:08,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:08,321 INFO:     Epoch: 49
2022-11-28 04:33:08,978 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4484284489669583, 'Total loss': 0.4484284489669583} | train loss {'Reaction outcome loss': 0.47210655617810454, 'Total loss': 0.47210655617810454}
2022-11-28 04:33:08,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:08,978 INFO:     Epoch: 50
2022-11-28 04:33:09,633 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4444586180827834, 'Total loss': 0.4444586180827834} | train loss {'Reaction outcome loss': 0.465021570262156, 'Total loss': 0.465021570262156}
2022-11-28 04:33:09,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:09,634 INFO:     Epoch: 51
2022-11-28 04:33:10,282 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47948987782001495, 'Total loss': 0.47948987782001495} | train loss {'Reaction outcome loss': 0.4604229262223098, 'Total loss': 0.4604229262223098}
2022-11-28 04:33:10,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:10,282 INFO:     Epoch: 52
2022-11-28 04:33:10,937 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4878166885199872, 'Total loss': 0.4878166885199872} | train loss {'Reaction outcome loss': 0.4560613272643765, 'Total loss': 0.4560613272643765}
2022-11-28 04:33:10,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:10,938 INFO:     Epoch: 53
2022-11-28 04:33:11,590 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4642500308426944, 'Total loss': 0.4642500308426944} | train loss {'Reaction outcome loss': 0.46927196511372865, 'Total loss': 0.46927196511372865}
2022-11-28 04:33:11,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:11,590 INFO:     Epoch: 54
2022-11-28 04:33:12,241 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4344013306227597, 'Total loss': 0.4344013306227597} | train loss {'Reaction outcome loss': 0.463532222358525, 'Total loss': 0.463532222358525}
2022-11-28 04:33:12,242 INFO:     Found new best model at epoch 54
2022-11-28 04:33:12,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:12,243 INFO:     Epoch: 55
2022-11-28 04:33:12,894 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43909085101701995, 'Total loss': 0.43909085101701995} | train loss {'Reaction outcome loss': 0.464625622338129, 'Total loss': 0.464625622338129}
2022-11-28 04:33:12,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:12,894 INFO:     Epoch: 56
2022-11-28 04:33:13,548 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4777121835134246, 'Total loss': 0.4777121835134246} | train loss {'Reaction outcome loss': 0.4691884664871432, 'Total loss': 0.4691884664871432}
2022-11-28 04:33:13,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:13,548 INFO:     Epoch: 57
2022-11-28 04:33:14,199 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4546982381831516, 'Total loss': 0.4546982381831516} | train loss {'Reaction outcome loss': 0.4768276306299063, 'Total loss': 0.4768276306299063}
2022-11-28 04:33:14,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:14,199 INFO:     Epoch: 58
2022-11-28 04:33:14,851 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4438215009868145, 'Total loss': 0.4438215009868145} | train loss {'Reaction outcome loss': 0.4865069256017083, 'Total loss': 0.4865069256017083}
2022-11-28 04:33:14,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:14,852 INFO:     Epoch: 59
2022-11-28 04:33:15,500 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4468889893455939, 'Total loss': 0.4468889893455939} | train loss {'Reaction outcome loss': 0.4752082784890163, 'Total loss': 0.4752082784890163}
2022-11-28 04:33:15,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:15,500 INFO:     Epoch: 60
2022-11-28 04:33:16,151 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5344099412587556, 'Total loss': 0.5344099412587556} | train loss {'Reaction outcome loss': 0.47162073361781626, 'Total loss': 0.47162073361781626}
2022-11-28 04:33:16,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:16,152 INFO:     Epoch: 61
2022-11-28 04:33:16,803 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5018844970247962, 'Total loss': 0.5018844970247962} | train loss {'Reaction outcome loss': 0.45764073470102146, 'Total loss': 0.45764073470102146}
2022-11-28 04:33:16,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:16,803 INFO:     Epoch: 62
2022-11-28 04:33:17,454 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.498592465438626, 'Total loss': 0.498592465438626} | train loss {'Reaction outcome loss': 0.47133547598533787, 'Total loss': 0.47133547598533787}
2022-11-28 04:33:17,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:17,454 INFO:     Epoch: 63
2022-11-28 04:33:18,105 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42896631664850493, 'Total loss': 0.42896631664850493} | train loss {'Reaction outcome loss': 0.4739681163176834, 'Total loss': 0.4739681163176834}
2022-11-28 04:33:18,105 INFO:     Found new best model at epoch 63
2022-11-28 04:33:18,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:18,106 INFO:     Epoch: 64
2022-11-28 04:33:18,759 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44529224119403144, 'Total loss': 0.44529224119403144} | train loss {'Reaction outcome loss': 0.4639678686434923, 'Total loss': 0.4639678686434923}
2022-11-28 04:33:18,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:18,760 INFO:     Epoch: 65
2022-11-28 04:33:19,410 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5252797075293281, 'Total loss': 0.5252797075293281} | train loss {'Reaction outcome loss': 0.46195171278739267, 'Total loss': 0.46195171278739267}
2022-11-28 04:33:19,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:19,410 INFO:     Epoch: 66
2022-11-28 04:33:20,061 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47428437593308365, 'Total loss': 0.47428437593308365} | train loss {'Reaction outcome loss': 0.46569045008676735, 'Total loss': 0.46569045008676735}
2022-11-28 04:33:20,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:20,061 INFO:     Epoch: 67
2022-11-28 04:33:20,712 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49190342460166325, 'Total loss': 0.49190342460166325} | train loss {'Reaction outcome loss': 0.47134159831141653, 'Total loss': 0.47134159831141653}
2022-11-28 04:33:20,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:20,712 INFO:     Epoch: 68
2022-11-28 04:33:21,366 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4478469640016556, 'Total loss': 0.4478469640016556} | train loss {'Reaction outcome loss': 0.4575549595148457, 'Total loss': 0.4575549595148457}
2022-11-28 04:33:21,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:21,366 INFO:     Epoch: 69
2022-11-28 04:33:22,017 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45620725202289497, 'Total loss': 0.45620725202289497} | train loss {'Reaction outcome loss': 0.46505137192092927, 'Total loss': 0.46505137192092927}
2022-11-28 04:33:22,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:22,017 INFO:     Epoch: 70
2022-11-28 04:33:22,669 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4524365622888912, 'Total loss': 0.4524365622888912} | train loss {'Reaction outcome loss': 0.4861849417329317, 'Total loss': 0.4861849417329317}
2022-11-28 04:33:22,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:22,669 INFO:     Epoch: 71
2022-11-28 04:33:23,321 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4584541249681603, 'Total loss': 0.4584541249681603} | train loss {'Reaction outcome loss': 0.47603966790979146, 'Total loss': 0.47603966790979146}
2022-11-28 04:33:23,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:23,321 INFO:     Epoch: 72
2022-11-28 04:33:23,972 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43615213747728954, 'Total loss': 0.43615213747728954} | train loss {'Reaction outcome loss': 0.46157230114091097, 'Total loss': 0.46157230114091097}
2022-11-28 04:33:23,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:23,973 INFO:     Epoch: 73
2022-11-28 04:33:24,625 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4743361137807369, 'Total loss': 0.4743361137807369} | train loss {'Reaction outcome loss': 0.45286709389947205, 'Total loss': 0.45286709389947205}
2022-11-28 04:33:24,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:24,625 INFO:     Epoch: 74
2022-11-28 04:33:25,276 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48712055114182556, 'Total loss': 0.48712055114182556} | train loss {'Reaction outcome loss': 0.4577403101119918, 'Total loss': 0.4577403101119918}
2022-11-28 04:33:25,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:25,277 INFO:     Epoch: 75
2022-11-28 04:33:25,928 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4311433197422461, 'Total loss': 0.4311433197422461} | train loss {'Reaction outcome loss': 0.4878344377766737, 'Total loss': 0.4878344377766737}
2022-11-28 04:33:25,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:25,928 INFO:     Epoch: 76
2022-11-28 04:33:26,579 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4566508352079175, 'Total loss': 0.4566508352079175} | train loss {'Reaction outcome loss': 0.46616727131822333, 'Total loss': 0.46616727131822333}
2022-11-28 04:33:26,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:26,579 INFO:     Epoch: 77
2022-11-28 04:33:27,233 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46788195486773143, 'Total loss': 0.46788195486773143} | train loss {'Reaction outcome loss': 0.4714279474034483, 'Total loss': 0.4714279474034483}
2022-11-28 04:33:27,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:27,234 INFO:     Epoch: 78
2022-11-28 04:33:27,886 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48429563506083056, 'Total loss': 0.48429563506083056} | train loss {'Reaction outcome loss': 0.461036226225768, 'Total loss': 0.461036226225768}
2022-11-28 04:33:27,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:27,887 INFO:     Epoch: 79
2022-11-28 04:33:28,538 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4388634745370258, 'Total loss': 0.4388634745370258} | train loss {'Reaction outcome loss': 0.4768771294519486, 'Total loss': 0.4768771294519486}
2022-11-28 04:33:28,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:28,538 INFO:     Epoch: 80
2022-11-28 04:33:29,190 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5269960591738875, 'Total loss': 0.5269960591738875} | train loss {'Reaction outcome loss': 0.4669706232031347, 'Total loss': 0.4669706232031347}
2022-11-28 04:33:29,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:29,190 INFO:     Epoch: 81
2022-11-28 04:33:29,844 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44125773842361843, 'Total loss': 0.44125773842361843} | train loss {'Reaction outcome loss': 0.46316818470655663, 'Total loss': 0.46316818470655663}
2022-11-28 04:33:29,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:29,845 INFO:     Epoch: 82
2022-11-28 04:33:30,500 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4478433017026294, 'Total loss': 0.4478433017026294} | train loss {'Reaction outcome loss': 0.46927647552026913, 'Total loss': 0.46927647552026913}
2022-11-28 04:33:30,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:30,500 INFO:     Epoch: 83
2022-11-28 04:33:31,150 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46612614731897006, 'Total loss': 0.46612614731897006} | train loss {'Reaction outcome loss': 0.46424607009540203, 'Total loss': 0.46424607009540203}
2022-11-28 04:33:31,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:31,151 INFO:     Epoch: 84
2022-11-28 04:33:31,805 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.464671098373153, 'Total loss': 0.464671098373153} | train loss {'Reaction outcome loss': 0.46327130436173336, 'Total loss': 0.46327130436173336}
2022-11-28 04:33:31,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:31,806 INFO:     Epoch: 85
2022-11-28 04:33:32,458 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5418072200634263, 'Total loss': 0.5418072200634263} | train loss {'Reaction outcome loss': 0.46748712957508654, 'Total loss': 0.46748712957508654}
2022-11-28 04:33:32,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:32,458 INFO:     Epoch: 86
2022-11-28 04:33:33,107 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46238975938070903, 'Total loss': 0.46238975938070903} | train loss {'Reaction outcome loss': 0.4746711185345283, 'Total loss': 0.4746711185345283}
2022-11-28 04:33:33,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:33,107 INFO:     Epoch: 87
2022-11-28 04:33:33,759 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48211301321333105, 'Total loss': 0.48211301321333105} | train loss {'Reaction outcome loss': 0.4725603937258122, 'Total loss': 0.4725603937258122}
2022-11-28 04:33:33,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:33,759 INFO:     Epoch: 88
2022-11-28 04:33:34,413 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4693515673279762, 'Total loss': 0.4693515673279762} | train loss {'Reaction outcome loss': 0.49909617374783105, 'Total loss': 0.49909617374783105}
2022-11-28 04:33:34,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:34,413 INFO:     Epoch: 89
2022-11-28 04:33:35,067 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4353652003813874, 'Total loss': 0.4353652003813874} | train loss {'Reaction outcome loss': 0.4786390311684203, 'Total loss': 0.4786390311684203}
2022-11-28 04:33:35,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:35,067 INFO:     Epoch: 90
2022-11-28 04:33:35,720 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4458029368384318, 'Total loss': 0.4458029368384318} | train loss {'Reaction outcome loss': 0.46404966657702257, 'Total loss': 0.46404966657702257}
2022-11-28 04:33:35,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:35,721 INFO:     Epoch: 91
2022-11-28 04:33:36,373 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47243192893537606, 'Total loss': 0.47243192893537606} | train loss {'Reaction outcome loss': 0.466620945586608, 'Total loss': 0.466620945586608}
2022-11-28 04:33:36,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:36,373 INFO:     Epoch: 92
2022-11-28 04:33:37,027 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4491038871082393, 'Total loss': 0.4491038871082393} | train loss {'Reaction outcome loss': 0.4729723594253242, 'Total loss': 0.4729723594253242}
2022-11-28 04:33:37,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:37,028 INFO:     Epoch: 93
2022-11-28 04:33:37,682 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4529482034797018, 'Total loss': 0.4529482034797018} | train loss {'Reaction outcome loss': 0.46712792510928414, 'Total loss': 0.46712792510928414}
2022-11-28 04:33:37,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:37,682 INFO:     Epoch: 94
2022-11-28 04:33:38,338 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4681957492774183, 'Total loss': 0.4681957492774183} | train loss {'Reaction outcome loss': 0.47023691351597124, 'Total loss': 0.47023691351597124}
2022-11-28 04:33:38,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:38,338 INFO:     Epoch: 95
2022-11-28 04:33:38,994 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46508835459297354, 'Total loss': 0.46508835459297354} | train loss {'Reaction outcome loss': 0.49485087525929033, 'Total loss': 0.49485087525929033}
2022-11-28 04:33:38,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:38,994 INFO:     Epoch: 96
2022-11-28 04:33:39,646 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46567747979001567, 'Total loss': 0.46567747979001567} | train loss {'Reaction outcome loss': 0.47337292337239634, 'Total loss': 0.47337292337239634}
2022-11-28 04:33:39,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:39,647 INFO:     Epoch: 97
2022-11-28 04:33:40,298 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47561939738013526, 'Total loss': 0.47561939738013526} | train loss {'Reaction outcome loss': 0.4719920551973708, 'Total loss': 0.4719920551973708}
2022-11-28 04:33:40,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:40,298 INFO:     Epoch: 98
2022-11-28 04:33:40,950 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47322404553944414, 'Total loss': 0.47322404553944414} | train loss {'Reaction outcome loss': 0.4639467940880702, 'Total loss': 0.4639467940880702}
2022-11-28 04:33:40,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:40,950 INFO:     Epoch: 99
2022-11-28 04:33:41,605 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.459054657342759, 'Total loss': 0.459054657342759} | train loss {'Reaction outcome loss': 0.46828994746150276, 'Total loss': 0.46828994746150276}
2022-11-28 04:33:41,605 INFO:     Best model found after epoch 64 of 100.
2022-11-28 04:33:41,605 INFO:   Done with stage: TRAINING
2022-11-28 04:33:41,605 INFO:   Starting stage: EVALUATION
2022-11-28 04:33:41,724 INFO:   Done with stage: EVALUATION
2022-11-28 04:33:41,724 INFO:   Leaving out SEQ value Fold_1
2022-11-28 04:33:41,737 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:33:41,737 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:33:42,384 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:33:42,384 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:33:42,452 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:33:42,452 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:33:42,452 INFO:     No hyperparam tuning for this model
2022-11-28 04:33:42,452 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:33:42,452 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:33:42,453 INFO:     None feature selector for col prot
2022-11-28 04:33:42,453 INFO:     None feature selector for col prot
2022-11-28 04:33:42,453 INFO:     None feature selector for col prot
2022-11-28 04:33:42,454 INFO:     None feature selector for col chem
2022-11-28 04:33:42,454 INFO:     None feature selector for col chem
2022-11-28 04:33:42,454 INFO:     None feature selector for col chem
2022-11-28 04:33:42,454 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:33:42,454 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:33:42,455 INFO:     Number of params in model 169651
2022-11-28 04:33:42,459 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:33:42,459 INFO:   Starting stage: TRAINING
2022-11-28 04:33:42,509 INFO:     Val loss before train {'Reaction outcome loss': 0.98548978025263, 'Total loss': 0.98548978025263}
2022-11-28 04:33:42,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:42,509 INFO:     Epoch: 0
2022-11-28 04:33:43,163 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6346615065227855, 'Total loss': 0.6346615065227855} | train loss {'Reaction outcome loss': 0.6852193206910663, 'Total loss': 0.6852193206910663}
2022-11-28 04:33:43,163 INFO:     Found new best model at epoch 0
2022-11-28 04:33:43,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:43,164 INFO:     Epoch: 1
2022-11-28 04:33:43,818 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5602505559271033, 'Total loss': 0.5602505559271033} | train loss {'Reaction outcome loss': 0.5901531027893909, 'Total loss': 0.5901531027893909}
2022-11-28 04:33:43,819 INFO:     Found new best model at epoch 1
2022-11-28 04:33:43,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:43,820 INFO:     Epoch: 2
2022-11-28 04:33:44,474 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5368958911435171, 'Total loss': 0.5368958911435171} | train loss {'Reaction outcome loss': 0.5711023480544689, 'Total loss': 0.5711023480544689}
2022-11-28 04:33:44,474 INFO:     Found new best model at epoch 2
2022-11-28 04:33:44,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:44,475 INFO:     Epoch: 3
2022-11-28 04:33:45,126 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.533679533411156, 'Total loss': 0.533679533411156} | train loss {'Reaction outcome loss': 0.560559122185958, 'Total loss': 0.560559122185958}
2022-11-28 04:33:45,126 INFO:     Found new best model at epoch 3
2022-11-28 04:33:45,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:45,127 INFO:     Epoch: 4
2022-11-28 04:33:45,776 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.567976753142747, 'Total loss': 0.567976753142747} | train loss {'Reaction outcome loss': 0.5316495999150913, 'Total loss': 0.5316495999150913}
2022-11-28 04:33:45,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:45,776 INFO:     Epoch: 5
2022-11-28 04:33:46,429 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4964127676053481, 'Total loss': 0.4964127676053481} | train loss {'Reaction outcome loss': 0.5332629577471659, 'Total loss': 0.5332629577471659}
2022-11-28 04:33:46,430 INFO:     Found new best model at epoch 5
2022-11-28 04:33:46,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:46,430 INFO:     Epoch: 6
2022-11-28 04:33:47,080 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5031949837099422, 'Total loss': 0.5031949837099422} | train loss {'Reaction outcome loss': 0.5156203474593066, 'Total loss': 0.5156203474593066}
2022-11-28 04:33:47,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:47,080 INFO:     Epoch: 7
2022-11-28 04:33:47,731 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49020652676170523, 'Total loss': 0.49020652676170523} | train loss {'Reaction outcome loss': 0.5171436271686786, 'Total loss': 0.5171436271686786}
2022-11-28 04:33:47,731 INFO:     Found new best model at epoch 7
2022-11-28 04:33:47,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:47,732 INFO:     Epoch: 8
2022-11-28 04:33:48,385 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5021435222165151, 'Total loss': 0.5021435222165151} | train loss {'Reaction outcome loss': 0.49205013838132866, 'Total loss': 0.49205013838132866}
2022-11-28 04:33:48,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:48,386 INFO:     Epoch: 9
2022-11-28 04:33:49,039 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48226186565377493, 'Total loss': 0.48226186565377493} | train loss {'Reaction outcome loss': 0.4936248674528741, 'Total loss': 0.4936248674528741}
2022-11-28 04:33:49,039 INFO:     Found new best model at epoch 9
2022-11-28 04:33:49,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:49,040 INFO:     Epoch: 10
2022-11-28 04:33:49,696 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5638440190391107, 'Total loss': 0.5638440190391107} | train loss {'Reaction outcome loss': 0.49876603818034776, 'Total loss': 0.49876603818034776}
2022-11-28 04:33:49,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:49,697 INFO:     Epoch: 11
2022-11-28 04:33:50,353 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47685499827970157, 'Total loss': 0.47685499827970157} | train loss {'Reaction outcome loss': 0.49149213743354625, 'Total loss': 0.49149213743354625}
2022-11-28 04:33:50,354 INFO:     Found new best model at epoch 11
2022-11-28 04:33:50,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:50,354 INFO:     Epoch: 12
2022-11-28 04:33:51,008 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4843970699743791, 'Total loss': 0.4843970699743791} | train loss {'Reaction outcome loss': 0.4924729765064803, 'Total loss': 0.4924729765064803}
2022-11-28 04:33:51,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:51,008 INFO:     Epoch: 13
2022-11-28 04:33:51,658 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5504739426753738, 'Total loss': 0.5504739426753738} | train loss {'Reaction outcome loss': 0.48308960623993924, 'Total loss': 0.48308960623993924}
2022-11-28 04:33:51,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:51,658 INFO:     Epoch: 14
2022-11-28 04:33:52,309 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5139652287418192, 'Total loss': 0.5139652287418192} | train loss {'Reaction outcome loss': 0.4795509472325339, 'Total loss': 0.4795509472325339}
2022-11-28 04:33:52,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:52,309 INFO:     Epoch: 15
2022-11-28 04:33:52,964 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5006684091958132, 'Total loss': 0.5006684091958132} | train loss {'Reaction outcome loss': 0.48457805583110225, 'Total loss': 0.48457805583110225}
2022-11-28 04:33:52,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:52,965 INFO:     Epoch: 16
2022-11-28 04:33:53,617 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5079129372130741, 'Total loss': 0.5079129372130741} | train loss {'Reaction outcome loss': 0.479349450905796, 'Total loss': 0.479349450905796}
2022-11-28 04:33:53,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:53,617 INFO:     Epoch: 17
2022-11-28 04:33:54,272 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4602068916640498, 'Total loss': 0.4602068916640498} | train loss {'Reaction outcome loss': 0.4875299802223439, 'Total loss': 0.4875299802223439}
2022-11-28 04:33:54,273 INFO:     Found new best model at epoch 17
2022-11-28 04:33:54,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:54,273 INFO:     Epoch: 18
2022-11-28 04:33:54,926 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5186072703112256, 'Total loss': 0.5186072703112256} | train loss {'Reaction outcome loss': 0.47198625542374273, 'Total loss': 0.47198625542374273}
2022-11-28 04:33:54,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:54,926 INFO:     Epoch: 19
2022-11-28 04:33:55,579 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5096942216835239, 'Total loss': 0.5096942216835239} | train loss {'Reaction outcome loss': 0.4778364256989618, 'Total loss': 0.4778364256989618}
2022-11-28 04:33:55,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:55,579 INFO:     Epoch: 20
2022-11-28 04:33:56,227 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48618475686420093, 'Total loss': 0.48618475686420093} | train loss {'Reaction outcome loss': 0.5114855560976522, 'Total loss': 0.5114855560976522}
2022-11-28 04:33:56,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:56,227 INFO:     Epoch: 21
2022-11-28 04:33:56,878 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48152166909792204, 'Total loss': 0.48152166909792204} | train loss {'Reaction outcome loss': 0.4747294780575795, 'Total loss': 0.4747294780575795}
2022-11-28 04:33:56,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:56,878 INFO:     Epoch: 22
2022-11-28 04:33:57,529 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5025333470918916, 'Total loss': 0.5025333470918916} | train loss {'Reaction outcome loss': 0.48104604378885585, 'Total loss': 0.48104604378885585}
2022-11-28 04:33:57,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:57,529 INFO:     Epoch: 23
2022-11-28 04:33:58,181 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5112750299952247, 'Total loss': 0.5112750299952247} | train loss {'Reaction outcome loss': 0.46696111674492174, 'Total loss': 0.46696111674492174}
2022-11-28 04:33:58,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:58,181 INFO:     Epoch: 24
2022-11-28 04:33:58,832 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4984428953718055, 'Total loss': 0.4984428953718055} | train loss {'Reaction outcome loss': 0.4740345135391483, 'Total loss': 0.4740345135391483}
2022-11-28 04:33:58,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:58,833 INFO:     Epoch: 25
2022-11-28 04:33:59,485 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.481609107079831, 'Total loss': 0.481609107079831} | train loss {'Reaction outcome loss': 0.4680376682083616, 'Total loss': 0.4680376682083616}
2022-11-28 04:33:59,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:33:59,485 INFO:     Epoch: 26
2022-11-28 04:34:00,138 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5077483687888492, 'Total loss': 0.5077483687888492} | train loss {'Reaction outcome loss': 0.4672885037089513, 'Total loss': 0.4672885037089513}
2022-11-28 04:34:00,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:00,138 INFO:     Epoch: 27
2022-11-28 04:34:00,791 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4722736918113448, 'Total loss': 0.4722736918113448} | train loss {'Reaction outcome loss': 0.47098771449525345, 'Total loss': 0.47098771449525345}
2022-11-28 04:34:00,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:00,792 INFO:     Epoch: 28
2022-11-28 04:34:01,445 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.465307281775908, 'Total loss': 0.465307281775908} | train loss {'Reaction outcome loss': 0.4728385085251318, 'Total loss': 0.4728385085251318}
2022-11-28 04:34:01,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:01,445 INFO:     Epoch: 29
2022-11-28 04:34:02,099 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5166633274744857, 'Total loss': 0.5166633274744857} | train loss {'Reaction outcome loss': 0.4626905203830858, 'Total loss': 0.4626905203830858}
2022-11-28 04:34:02,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:02,099 INFO:     Epoch: 30
2022-11-28 04:34:02,754 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49972300637852063, 'Total loss': 0.49972300637852063} | train loss {'Reaction outcome loss': 0.468081535960016, 'Total loss': 0.468081535960016}
2022-11-28 04:34:02,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:02,755 INFO:     Epoch: 31
2022-11-28 04:34:03,411 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5090468048372052, 'Total loss': 0.5090468048372052} | train loss {'Reaction outcome loss': 0.4715593533009773, 'Total loss': 0.4715593533009773}
2022-11-28 04:34:03,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:03,411 INFO:     Epoch: 32
2022-11-28 04:34:04,068 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5016377845948393, 'Total loss': 0.5016377845948393} | train loss {'Reaction outcome loss': 0.46166413514177324, 'Total loss': 0.46166413514177324}
2022-11-28 04:34:04,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:04,068 INFO:     Epoch: 33
2022-11-28 04:34:04,720 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5157019451937892, 'Total loss': 0.5157019451937892} | train loss {'Reaction outcome loss': 0.4648862881095786, 'Total loss': 0.4648862881095786}
2022-11-28 04:34:04,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:04,720 INFO:     Epoch: 34
2022-11-28 04:34:05,373 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5018950700759888, 'Total loss': 0.5018950700759888} | train loss {'Reaction outcome loss': 0.46416423083678915, 'Total loss': 0.46416423083678915}
2022-11-28 04:34:05,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:05,374 INFO:     Epoch: 35
2022-11-28 04:34:06,031 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45313642106272956, 'Total loss': 0.45313642106272956} | train loss {'Reaction outcome loss': 0.4711898964818431, 'Total loss': 0.4711898964818431}
2022-11-28 04:34:06,031 INFO:     Found new best model at epoch 35
2022-11-28 04:34:06,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:06,032 INFO:     Epoch: 36
2022-11-28 04:34:06,689 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5006680160083554, 'Total loss': 0.5006680160083554} | train loss {'Reaction outcome loss': 0.46092208502022364, 'Total loss': 0.46092208502022364}
2022-11-28 04:34:06,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:06,689 INFO:     Epoch: 37
2022-11-28 04:34:07,343 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4736254272813147, 'Total loss': 0.4736254272813147} | train loss {'Reaction outcome loss': 0.4698092948328628, 'Total loss': 0.4698092948328628}
2022-11-28 04:34:07,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:07,343 INFO:     Epoch: 38
2022-11-28 04:34:07,998 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5074288215149533, 'Total loss': 0.5074288215149533} | train loss {'Reaction outcome loss': 0.4793577147157569, 'Total loss': 0.4793577147157569}
2022-11-28 04:34:07,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:07,999 INFO:     Epoch: 39
2022-11-28 04:34:08,655 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49360488626089966, 'Total loss': 0.49360488626089966} | train loss {'Reaction outcome loss': 0.46974934984058864, 'Total loss': 0.46974934984058864}
2022-11-28 04:34:08,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:08,655 INFO:     Epoch: 40
2022-11-28 04:34:09,311 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47313069619915704, 'Total loss': 0.47313069619915704} | train loss {'Reaction outcome loss': 0.46845834831959804, 'Total loss': 0.46845834831959804}
2022-11-28 04:34:09,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:09,311 INFO:     Epoch: 41
2022-11-28 04:34:09,965 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5010742328383706, 'Total loss': 0.5010742328383706} | train loss {'Reaction outcome loss': 0.46578593013302877, 'Total loss': 0.46578593013302877}
2022-11-28 04:34:09,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:09,965 INFO:     Epoch: 42
2022-11-28 04:34:10,622 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4832499453967268, 'Total loss': 0.4832499453967268} | train loss {'Reaction outcome loss': 0.468004964352378, 'Total loss': 0.468004964352378}
2022-11-28 04:34:10,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:10,622 INFO:     Epoch: 43
2022-11-28 04:34:11,280 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45208275792273606, 'Total loss': 0.45208275792273606} | train loss {'Reaction outcome loss': 0.4772427821388611, 'Total loss': 0.4772427821388611}
2022-11-28 04:34:11,280 INFO:     Found new best model at epoch 43
2022-11-28 04:34:11,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:11,281 INFO:     Epoch: 44
2022-11-28 04:34:11,937 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45670105991038407, 'Total loss': 0.45670105991038407} | train loss {'Reaction outcome loss': 0.46887595473453103, 'Total loss': 0.46887595473453103}
2022-11-28 04:34:11,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:11,938 INFO:     Epoch: 45
2022-11-28 04:34:12,590 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4562323509969495, 'Total loss': 0.4562323509969495} | train loss {'Reaction outcome loss': 0.4600517472274873, 'Total loss': 0.4600517472274873}
2022-11-28 04:34:12,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:12,590 INFO:     Epoch: 46
2022-11-28 04:34:13,242 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5319254527037794, 'Total loss': 0.5319254527037794} | train loss {'Reaction outcome loss': 0.468154452831639, 'Total loss': 0.468154452831639}
2022-11-28 04:34:13,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:13,242 INFO:     Epoch: 47
2022-11-28 04:34:13,896 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48332579908045853, 'Total loss': 0.48332579908045853} | train loss {'Reaction outcome loss': 0.4747213952333821, 'Total loss': 0.4747213952333821}
2022-11-28 04:34:13,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:13,896 INFO:     Epoch: 48
2022-11-28 04:34:14,550 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4680424634028565, 'Total loss': 0.4680424634028565} | train loss {'Reaction outcome loss': 0.46455408059633696, 'Total loss': 0.46455408059633696}
2022-11-28 04:34:14,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:14,550 INFO:     Epoch: 49
2022-11-28 04:34:15,204 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46392861516638234, 'Total loss': 0.46392861516638234} | train loss {'Reaction outcome loss': 0.4770046515382736, 'Total loss': 0.4770046515382736}
2022-11-28 04:34:15,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:15,205 INFO:     Epoch: 50
2022-11-28 04:34:15,859 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4676925167441368, 'Total loss': 0.4676925167441368} | train loss {'Reaction outcome loss': 0.46395037682191564, 'Total loss': 0.46395037682191564}
2022-11-28 04:34:15,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:15,859 INFO:     Epoch: 51
2022-11-28 04:34:16,514 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4782776527784087, 'Total loss': 0.4782776527784087} | train loss {'Reaction outcome loss': 0.47009246319773706, 'Total loss': 0.47009246319773706}
2022-11-28 04:34:16,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:16,514 INFO:     Epoch: 52
2022-11-28 04:34:17,174 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47162632745775307, 'Total loss': 0.47162632745775307} | train loss {'Reaction outcome loss': 0.4663304047072721, 'Total loss': 0.4663304047072721}
2022-11-28 04:34:17,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:17,174 INFO:     Epoch: 53
2022-11-28 04:34:17,833 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47140148654580116, 'Total loss': 0.47140148654580116} | train loss {'Reaction outcome loss': 0.46100333918202746, 'Total loss': 0.46100333918202746}
2022-11-28 04:34:17,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:17,833 INFO:     Epoch: 54
2022-11-28 04:34:18,488 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5453412180597131, 'Total loss': 0.5453412180597131} | train loss {'Reaction outcome loss': 0.4599241911158388, 'Total loss': 0.4599241911158388}
2022-11-28 04:34:18,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:18,489 INFO:     Epoch: 55
2022-11-28 04:34:19,141 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4501619543880224, 'Total loss': 0.4501619543880224} | train loss {'Reaction outcome loss': 0.45693408091541243, 'Total loss': 0.45693408091541243}
2022-11-28 04:34:19,141 INFO:     Found new best model at epoch 55
2022-11-28 04:34:19,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:19,142 INFO:     Epoch: 56
2022-11-28 04:34:19,796 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4938419007442214, 'Total loss': 0.4938419007442214} | train loss {'Reaction outcome loss': 0.46862669035732024, 'Total loss': 0.46862669035732024}
2022-11-28 04:34:19,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:19,796 INFO:     Epoch: 57
2022-11-28 04:34:20,453 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4593256065113978, 'Total loss': 0.4593256065113978} | train loss {'Reaction outcome loss': 0.4700356885670168, 'Total loss': 0.4700356885670168}
2022-11-28 04:34:20,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:20,453 INFO:     Epoch: 58
2022-11-28 04:34:21,107 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5136037926104936, 'Total loss': 0.5136037926104936} | train loss {'Reaction outcome loss': 0.4639774742215751, 'Total loss': 0.4639774742215751}
2022-11-28 04:34:21,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:21,107 INFO:     Epoch: 59
2022-11-28 04:34:21,764 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4647718864408406, 'Total loss': 0.4647718864408406} | train loss {'Reaction outcome loss': 0.4573282223451234, 'Total loss': 0.4573282223451234}
2022-11-28 04:34:21,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:21,764 INFO:     Epoch: 60
2022-11-28 04:34:22,421 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4596539949151603, 'Total loss': 0.4596539949151603} | train loss {'Reaction outcome loss': 0.46858543652271933, 'Total loss': 0.46858543652271933}
2022-11-28 04:34:22,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:22,421 INFO:     Epoch: 61
2022-11-28 04:34:23,078 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4803519587625157, 'Total loss': 0.4803519587625157} | train loss {'Reaction outcome loss': 0.4711244578665567, 'Total loss': 0.4711244578665567}
2022-11-28 04:34:23,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:23,078 INFO:     Epoch: 62
2022-11-28 04:34:23,732 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46525826440616086, 'Total loss': 0.46525826440616086} | train loss {'Reaction outcome loss': 0.4658288348782883, 'Total loss': 0.4658288348782883}
2022-11-28 04:34:23,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:23,732 INFO:     Epoch: 63
2022-11-28 04:34:24,388 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.459031380712986, 'Total loss': 0.459031380712986} | train loss {'Reaction outcome loss': 0.47554354644135427, 'Total loss': 0.47554354644135427}
2022-11-28 04:34:24,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:24,389 INFO:     Epoch: 64
2022-11-28 04:34:25,045 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49042442915114487, 'Total loss': 0.49042442915114487} | train loss {'Reaction outcome loss': 0.4703128832554528, 'Total loss': 0.4703128832554528}
2022-11-28 04:34:25,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:25,046 INFO:     Epoch: 65
2022-11-28 04:34:25,702 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4927374551242048, 'Total loss': 0.4927374551242048} | train loss {'Reaction outcome loss': 0.47965670444037356, 'Total loss': 0.47965670444037356}
2022-11-28 04:34:25,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:25,702 INFO:     Epoch: 66
2022-11-28 04:34:26,357 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4446322958577763, 'Total loss': 0.4446322958577763} | train loss {'Reaction outcome loss': 0.4683272713863174, 'Total loss': 0.4683272713863174}
2022-11-28 04:34:26,357 INFO:     Found new best model at epoch 66
2022-11-28 04:34:26,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:26,358 INFO:     Epoch: 67
2022-11-28 04:34:27,014 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48544939946044574, 'Total loss': 0.48544939946044574} | train loss {'Reaction outcome loss': 0.46041852594749166, 'Total loss': 0.46041852594749166}
2022-11-28 04:34:27,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:27,014 INFO:     Epoch: 68
2022-11-28 04:34:27,674 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48528295111927117, 'Total loss': 0.48528295111927117} | train loss {'Reaction outcome loss': 0.4636079771566744, 'Total loss': 0.4636079771566744}
2022-11-28 04:34:27,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:27,674 INFO:     Epoch: 69
2022-11-28 04:34:28,328 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48648066649382765, 'Total loss': 0.48648066649382765} | train loss {'Reaction outcome loss': 0.4638797301150527, 'Total loss': 0.4638797301150527}
2022-11-28 04:34:28,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:28,328 INFO:     Epoch: 70
2022-11-28 04:34:28,982 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4827857329086824, 'Total loss': 0.4827857329086824} | train loss {'Reaction outcome loss': 0.45995221923855756, 'Total loss': 0.45995221923855756}
2022-11-28 04:34:28,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:28,983 INFO:     Epoch: 71
2022-11-28 04:34:29,634 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4697744246910919, 'Total loss': 0.4697744246910919} | train loss {'Reaction outcome loss': 0.4548434993772492, 'Total loss': 0.4548434993772492}
2022-11-28 04:34:29,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:29,634 INFO:     Epoch: 72
2022-11-28 04:34:30,290 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5051917498084632, 'Total loss': 0.5051917498084632} | train loss {'Reaction outcome loss': 0.4638361910938734, 'Total loss': 0.4638361910938734}
2022-11-28 04:34:30,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:30,290 INFO:     Epoch: 73
2022-11-28 04:34:30,943 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46216371045871213, 'Total loss': 0.46216371045871213} | train loss {'Reaction outcome loss': 0.476119176699565, 'Total loss': 0.476119176699565}
2022-11-28 04:34:30,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:30,943 INFO:     Epoch: 74
2022-11-28 04:34:31,596 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4846971741115505, 'Total loss': 0.4846971741115505} | train loss {'Reaction outcome loss': 0.466166680037734, 'Total loss': 0.466166680037734}
2022-11-28 04:34:31,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:31,596 INFO:     Epoch: 75
2022-11-28 04:34:32,252 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4874039329588413, 'Total loss': 0.4874039329588413} | train loss {'Reaction outcome loss': 0.46225741110470614, 'Total loss': 0.46225741110470614}
2022-11-28 04:34:32,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:32,253 INFO:     Epoch: 76
2022-11-28 04:34:32,910 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4612815708599307, 'Total loss': 0.4612815708599307} | train loss {'Reaction outcome loss': 0.47035279707146077, 'Total loss': 0.47035279707146077}
2022-11-28 04:34:32,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:32,910 INFO:     Epoch: 77
2022-11-28 04:34:33,567 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5147456790913235, 'Total loss': 0.5147456790913235} | train loss {'Reaction outcome loss': 0.46859961075459416, 'Total loss': 0.46859961075459416}
2022-11-28 04:34:33,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:33,568 INFO:     Epoch: 78
2022-11-28 04:34:34,226 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47922283004630695, 'Total loss': 0.47922283004630695} | train loss {'Reaction outcome loss': 0.4664084764747967, 'Total loss': 0.4664084764747967}
2022-11-28 04:34:34,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:34,226 INFO:     Epoch: 79
2022-11-28 04:34:34,887 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47810580175031314, 'Total loss': 0.47810580175031314} | train loss {'Reaction outcome loss': 0.4592197871039271, 'Total loss': 0.4592197871039271}
2022-11-28 04:34:34,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:34,888 INFO:     Epoch: 80
2022-11-28 04:34:35,546 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48561261662028055, 'Total loss': 0.48561261662028055} | train loss {'Reaction outcome loss': 0.46037500849378254, 'Total loss': 0.46037500849378254}
2022-11-28 04:34:35,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:35,546 INFO:     Epoch: 81
2022-11-28 04:34:36,203 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.476700287650932, 'Total loss': 0.476700287650932} | train loss {'Reaction outcome loss': 0.4654871367732523, 'Total loss': 0.4654871367732523}
2022-11-28 04:34:36,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:36,203 INFO:     Epoch: 82
2022-11-28 04:34:36,859 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45986754447221756, 'Total loss': 0.45986754447221756} | train loss {'Reaction outcome loss': 0.46328601156651733, 'Total loss': 0.46328601156651733}
2022-11-28 04:34:36,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:36,860 INFO:     Epoch: 83
2022-11-28 04:34:37,514 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4848334999247031, 'Total loss': 0.4848334999247031} | train loss {'Reaction outcome loss': 0.4748409809151133, 'Total loss': 0.4748409809151133}
2022-11-28 04:34:37,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:37,514 INFO:     Epoch: 84
2022-11-28 04:34:38,172 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47662087936292996, 'Total loss': 0.47662087936292996} | train loss {'Reaction outcome loss': 0.4556739563160097, 'Total loss': 0.4556739563160097}
2022-11-28 04:34:38,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:38,172 INFO:     Epoch: 85
2022-11-28 04:34:38,827 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49156009541316464, 'Total loss': 0.49156009541316464} | train loss {'Reaction outcome loss': 0.4610622843750093, 'Total loss': 0.4610622843750093}
2022-11-28 04:34:38,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:38,827 INFO:     Epoch: 86
2022-11-28 04:34:39,480 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5054756294597279, 'Total loss': 0.5054756294597279} | train loss {'Reaction outcome loss': 0.4697855326690172, 'Total loss': 0.4697855326690172}
2022-11-28 04:34:39,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:39,480 INFO:     Epoch: 87
2022-11-28 04:34:40,136 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4967479102990844, 'Total loss': 0.4967479102990844} | train loss {'Reaction outcome loss': 0.4695225782722597, 'Total loss': 0.4695225782722597}
2022-11-28 04:34:40,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:40,137 INFO:     Epoch: 88
2022-11-28 04:34:40,794 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.50870627571236, 'Total loss': 0.50870627571236} | train loss {'Reaction outcome loss': 0.4687607444140321, 'Total loss': 0.4687607444140321}
2022-11-28 04:34:40,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:40,795 INFO:     Epoch: 89
2022-11-28 04:34:41,452 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5394209189848467, 'Total loss': 0.5394209189848467} | train loss {'Reaction outcome loss': 0.4651082080707844, 'Total loss': 0.4651082080707844}
2022-11-28 04:34:41,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:41,452 INFO:     Epoch: 90
2022-11-28 04:34:42,104 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4926280172711069, 'Total loss': 0.4926280172711069} | train loss {'Reaction outcome loss': 0.4605507475704799, 'Total loss': 0.4605507475704799}
2022-11-28 04:34:42,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:42,105 INFO:     Epoch: 91
2022-11-28 04:34:42,759 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4851813685487617, 'Total loss': 0.4851813685487617} | train loss {'Reaction outcome loss': 0.4676770043336911, 'Total loss': 0.4676770043336911}
2022-11-28 04:34:42,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:42,760 INFO:     Epoch: 92
2022-11-28 04:34:43,417 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46442888338457455, 'Total loss': 0.46442888338457455} | train loss {'Reaction outcome loss': 0.46259370488435153, 'Total loss': 0.46259370488435153}
2022-11-28 04:34:43,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:43,417 INFO:     Epoch: 93
2022-11-28 04:34:44,070 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4810569567436522, 'Total loss': 0.4810569567436522} | train loss {'Reaction outcome loss': 0.47390767420841917, 'Total loss': 0.47390767420841917}
2022-11-28 04:34:44,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:44,070 INFO:     Epoch: 94
2022-11-28 04:34:44,726 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46746242689815437, 'Total loss': 0.46746242689815437} | train loss {'Reaction outcome loss': 0.4617514650710681, 'Total loss': 0.4617514650710681}
2022-11-28 04:34:44,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:44,726 INFO:     Epoch: 95
2022-11-28 04:34:45,383 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46940078789537604, 'Total loss': 0.46940078789537604} | train loss {'Reaction outcome loss': 0.47201168531107035, 'Total loss': 0.47201168531107035}
2022-11-28 04:34:45,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:45,383 INFO:     Epoch: 96
2022-11-28 04:34:46,038 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49674825641241943, 'Total loss': 0.49674825641241943} | train loss {'Reaction outcome loss': 0.46724868424025623, 'Total loss': 0.46724868424025623}
2022-11-28 04:34:46,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:46,039 INFO:     Epoch: 97
2022-11-28 04:34:46,696 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49969480457631027, 'Total loss': 0.49969480457631027} | train loss {'Reaction outcome loss': 0.46564940420480877, 'Total loss': 0.46564940420480877}
2022-11-28 04:34:46,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:46,696 INFO:     Epoch: 98
2022-11-28 04:34:47,353 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47938526201654563, 'Total loss': 0.47938526201654563} | train loss {'Reaction outcome loss': 0.4678478244586512, 'Total loss': 0.4678478244586512}
2022-11-28 04:34:47,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:47,353 INFO:     Epoch: 99
2022-11-28 04:34:48,008 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48434012688019057, 'Total loss': 0.48434012688019057} | train loss {'Reaction outcome loss': 0.465732691500351, 'Total loss': 0.465732691500351}
2022-11-28 04:34:48,008 INFO:     Best model found after epoch 67 of 100.
2022-11-28 04:34:48,008 INFO:   Done with stage: TRAINING
2022-11-28 04:34:48,008 INFO:   Starting stage: EVALUATION
2022-11-28 04:34:48,128 INFO:   Done with stage: EVALUATION
2022-11-28 04:34:48,128 INFO:   Leaving out SEQ value Fold_2
2022-11-28 04:34:48,141 INFO:   examples: 20,544| examples in train: 15,422 | examples in val: 2,722| examples in test: 2,400
2022-11-28 04:34:48,141 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:34:48,766 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:34:48,767 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:34:48,833 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:34:48,833 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:34:48,833 INFO:     No hyperparam tuning for this model
2022-11-28 04:34:48,833 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:34:48,833 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:34:48,834 INFO:     None feature selector for col prot
2022-11-28 04:34:48,834 INFO:     None feature selector for col prot
2022-11-28 04:34:48,834 INFO:     None feature selector for col prot
2022-11-28 04:34:48,835 INFO:     None feature selector for col chem
2022-11-28 04:34:48,835 INFO:     None feature selector for col chem
2022-11-28 04:34:48,835 INFO:     None feature selector for col chem
2022-11-28 04:34:48,835 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:34:48,835 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:34:48,836 INFO:     Number of params in model 169651
2022-11-28 04:34:48,839 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:34:48,839 INFO:   Starting stage: TRAINING
2022-11-28 04:34:48,889 INFO:     Val loss before train {'Reaction outcome loss': 1.0190707500590834, 'Total loss': 1.0190707500590834}
2022-11-28 04:34:48,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:48,889 INFO:     Epoch: 0
2022-11-28 04:34:49,531 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5928042655767396, 'Total loss': 0.5928042655767396} | train loss {'Reaction outcome loss': 0.6749199311020958, 'Total loss': 0.6749199311020958}
2022-11-28 04:34:49,531 INFO:     Found new best model at epoch 0
2022-11-28 04:34:49,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:49,531 INFO:     Epoch: 1
2022-11-28 04:34:50,167 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5437900742819143, 'Total loss': 0.5437900742819143} | train loss {'Reaction outcome loss': 0.5729668394534915, 'Total loss': 0.5729668394534915}
2022-11-28 04:34:50,168 INFO:     Found new best model at epoch 1
2022-11-28 04:34:50,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:50,168 INFO:     Epoch: 2
2022-11-28 04:34:50,809 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5069862396218056, 'Total loss': 0.5069862396218056} | train loss {'Reaction outcome loss': 0.5485567655182478, 'Total loss': 0.5485567655182478}
2022-11-28 04:34:50,809 INFO:     Found new best model at epoch 2
2022-11-28 04:34:50,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:50,809 INFO:     Epoch: 3
2022-11-28 04:34:51,449 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.511777771420257, 'Total loss': 0.511777771420257} | train loss {'Reaction outcome loss': 0.5267763964491761, 'Total loss': 0.5267763964491761}
2022-11-28 04:34:51,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:51,449 INFO:     Epoch: 4
2022-11-28 04:34:52,086 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5144154519535774, 'Total loss': 0.5144154519535774} | train loss {'Reaction outcome loss': 0.516788729740871, 'Total loss': 0.516788729740871}
2022-11-28 04:34:52,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:52,087 INFO:     Epoch: 5
2022-11-28 04:34:52,726 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47480025263719783, 'Total loss': 0.47480025263719783} | train loss {'Reaction outcome loss': 0.5236334554634648, 'Total loss': 0.5236334554634648}
2022-11-28 04:34:52,726 INFO:     Found new best model at epoch 5
2022-11-28 04:34:52,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:52,726 INFO:     Epoch: 6
2022-11-28 04:34:53,364 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4822676975366681, 'Total loss': 0.4822676975366681} | train loss {'Reaction outcome loss': 0.505420739318078, 'Total loss': 0.505420739318078}
2022-11-28 04:34:53,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:53,364 INFO:     Epoch: 7
2022-11-28 04:34:54,004 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5076855247796968, 'Total loss': 0.5076855247796968} | train loss {'Reaction outcome loss': 0.4919512703458303, 'Total loss': 0.4919512703458303}
2022-11-28 04:34:54,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:54,004 INFO:     Epoch: 8
2022-11-28 04:34:54,642 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4773207227157992, 'Total loss': 0.4773207227157992} | train loss {'Reaction outcome loss': 0.49339211296243785, 'Total loss': 0.49339211296243785}
2022-11-28 04:34:54,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:54,642 INFO:     Epoch: 9
2022-11-28 04:34:55,279 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4835118644459303, 'Total loss': 0.4835118644459303} | train loss {'Reaction outcome loss': 0.48606041203643274, 'Total loss': 0.48606041203643274}
2022-11-28 04:34:55,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:55,279 INFO:     Epoch: 10
2022-11-28 04:34:55,912 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5254202897465506, 'Total loss': 0.5254202897465506} | train loss {'Reaction outcome loss': 0.47894017670411787, 'Total loss': 0.47894017670411787}
2022-11-28 04:34:55,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:55,912 INFO:     Epoch: 11
2022-11-28 04:34:56,545 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4758551737596822, 'Total loss': 0.4758551737596822} | train loss {'Reaction outcome loss': 0.4912903209939537, 'Total loss': 0.4912903209939537}
2022-11-28 04:34:56,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:56,546 INFO:     Epoch: 12
2022-11-28 04:34:57,183 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47486101853293045, 'Total loss': 0.47486101853293045} | train loss {'Reaction outcome loss': 0.47123666991831353, 'Total loss': 0.47123666991831353}
2022-11-28 04:34:57,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:57,183 INFO:     Epoch: 13
2022-11-28 04:34:57,824 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46250916878844417, 'Total loss': 0.46250916878844417} | train loss {'Reaction outcome loss': 0.47319905509345267, 'Total loss': 0.47319905509345267}
2022-11-28 04:34:57,824 INFO:     Found new best model at epoch 13
2022-11-28 04:34:57,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:57,825 INFO:     Epoch: 14
2022-11-28 04:34:58,462 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49380204843920333, 'Total loss': 0.49380204843920333} | train loss {'Reaction outcome loss': 0.4741018194998943, 'Total loss': 0.4741018194998943}
2022-11-28 04:34:58,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:58,462 INFO:     Epoch: 15
2022-11-28 04:34:59,101 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45918346560278606, 'Total loss': 0.45918346560278606} | train loss {'Reaction outcome loss': 0.4704877421940016, 'Total loss': 0.4704877421940016}
2022-11-28 04:34:59,101 INFO:     Found new best model at epoch 15
2022-11-28 04:34:59,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:59,102 INFO:     Epoch: 16
2022-11-28 04:34:59,737 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4617454749207164, 'Total loss': 0.4617454749207164} | train loss {'Reaction outcome loss': 0.4726402462765389, 'Total loss': 0.4726402462765389}
2022-11-28 04:34:59,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:34:59,737 INFO:     Epoch: 17
2022-11-28 04:35:00,374 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5103278846241707, 'Total loss': 0.5103278846241707} | train loss {'Reaction outcome loss': 0.4757612101517278, 'Total loss': 0.4757612101517278}
2022-11-28 04:35:00,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:00,374 INFO:     Epoch: 18
2022-11-28 04:35:01,011 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4648600244937941, 'Total loss': 0.4648600244937941} | train loss {'Reaction outcome loss': 0.4623603250104857, 'Total loss': 0.4623603250104857}
2022-11-28 04:35:01,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:01,012 INFO:     Epoch: 19
2022-11-28 04:35:01,650 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47675373491852785, 'Total loss': 0.47675373491852785} | train loss {'Reaction outcome loss': 0.46725404182163016, 'Total loss': 0.46725404182163016}
2022-11-28 04:35:01,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:01,650 INFO:     Epoch: 20
2022-11-28 04:35:02,287 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4597745981327323, 'Total loss': 0.4597745981327323} | train loss {'Reaction outcome loss': 0.4576602012413666, 'Total loss': 0.4576602012413666}
2022-11-28 04:35:02,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:02,287 INFO:     Epoch: 21
2022-11-28 04:35:02,927 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49394783446955126, 'Total loss': 0.49394783446955126} | train loss {'Reaction outcome loss': 0.4579695089724054, 'Total loss': 0.4579695089724054}
2022-11-28 04:35:02,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:02,927 INFO:     Epoch: 22
2022-11-28 04:35:03,564 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4489415132029112, 'Total loss': 0.4489415132029112} | train loss {'Reaction outcome loss': 0.45697439508319393, 'Total loss': 0.45697439508319393}
2022-11-28 04:35:03,564 INFO:     Found new best model at epoch 22
2022-11-28 04:35:03,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:03,565 INFO:     Epoch: 23
2022-11-28 04:35:04,207 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45991593564665595, 'Total loss': 0.45991593564665595} | train loss {'Reaction outcome loss': 0.4580607871791634, 'Total loss': 0.4580607871791634}
2022-11-28 04:35:04,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:04,208 INFO:     Epoch: 24
2022-11-28 04:35:04,842 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5256480560746304, 'Total loss': 0.5256480560746304} | train loss {'Reaction outcome loss': 0.46276324653526557, 'Total loss': 0.46276324653526557}
2022-11-28 04:35:04,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:04,842 INFO:     Epoch: 25
2022-11-28 04:35:05,477 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.455316943831222, 'Total loss': 0.455316943831222} | train loss {'Reaction outcome loss': 0.4601713290353039, 'Total loss': 0.4601713290353039}
2022-11-28 04:35:05,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:05,477 INFO:     Epoch: 26
2022-11-28 04:35:06,117 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4873494010332019, 'Total loss': 0.4873494010332019} | train loss {'Reaction outcome loss': 0.4523531652337783, 'Total loss': 0.4523531652337783}
2022-11-28 04:35:06,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:06,117 INFO:     Epoch: 27
2022-11-28 04:35:06,756 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48478739310142605, 'Total loss': 0.48478739310142605} | train loss {'Reaction outcome loss': 0.44611648071356336, 'Total loss': 0.44611648071356336}
2022-11-28 04:35:06,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:06,756 INFO:     Epoch: 28
2022-11-28 04:35:07,393 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5148379331411317, 'Total loss': 0.5148379331411317} | train loss {'Reaction outcome loss': 0.4647400687097019, 'Total loss': 0.4647400687097019}
2022-11-28 04:35:07,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:07,393 INFO:     Epoch: 29
2022-11-28 04:35:08,029 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4625772639762524, 'Total loss': 0.4625772639762524} | train loss {'Reaction outcome loss': 0.4513654000284266, 'Total loss': 0.4513654000284266}
2022-11-28 04:35:08,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:08,029 INFO:     Epoch: 30
2022-11-28 04:35:08,665 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46019039701583775, 'Total loss': 0.46019039701583775} | train loss {'Reaction outcome loss': 0.4530861758592218, 'Total loss': 0.4530861758592218}
2022-11-28 04:35:08,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:08,665 INFO:     Epoch: 31
2022-11-28 04:35:09,305 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4406588590422342, 'Total loss': 0.4406588590422342} | train loss {'Reaction outcome loss': 0.45049158356991054, 'Total loss': 0.45049158356991054}
2022-11-28 04:35:09,305 INFO:     Found new best model at epoch 31
2022-11-28 04:35:09,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:09,306 INFO:     Epoch: 32
2022-11-28 04:35:09,944 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48584738650987314, 'Total loss': 0.48584738650987314} | train loss {'Reaction outcome loss': 0.4410572580034802, 'Total loss': 0.4410572580034802}
2022-11-28 04:35:09,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:09,944 INFO:     Epoch: 33
2022-11-28 04:35:10,583 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46343343271765597, 'Total loss': 0.46343343271765597} | train loss {'Reaction outcome loss': 0.45258657541512454, 'Total loss': 0.45258657541512454}
2022-11-28 04:35:10,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:10,583 INFO:     Epoch: 34
2022-11-28 04:35:11,220 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46295190342636994, 'Total loss': 0.46295190342636994} | train loss {'Reaction outcome loss': 0.4486324326347761, 'Total loss': 0.4486324326347761}
2022-11-28 04:35:11,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:11,220 INFO:     Epoch: 35
2022-11-28 04:35:11,857 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5125453402829725, 'Total loss': 0.5125453402829725} | train loss {'Reaction outcome loss': 0.45262730133978657, 'Total loss': 0.45262730133978657}
2022-11-28 04:35:11,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:11,858 INFO:     Epoch: 36
2022-11-28 04:35:12,496 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44850027665149333, 'Total loss': 0.44850027665149333} | train loss {'Reaction outcome loss': 0.45278020274218683, 'Total loss': 0.45278020274218683}
2022-11-28 04:35:12,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:12,497 INFO:     Epoch: 37
2022-11-28 04:35:13,134 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45832275893799096, 'Total loss': 0.45832275893799096} | train loss {'Reaction outcome loss': 0.4493255147177154, 'Total loss': 0.4493255147177154}
2022-11-28 04:35:13,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:13,134 INFO:     Epoch: 38
2022-11-28 04:35:13,770 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47525647421215855, 'Total loss': 0.47525647421215855} | train loss {'Reaction outcome loss': 0.4475982048823131, 'Total loss': 0.4475982048823131}
2022-11-28 04:35:13,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:13,770 INFO:     Epoch: 39
2022-11-28 04:35:14,410 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.510633084663125, 'Total loss': 0.510633084663125} | train loss {'Reaction outcome loss': 0.4484177289909347, 'Total loss': 0.4484177289909347}
2022-11-28 04:35:14,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:14,411 INFO:     Epoch: 40
2022-11-28 04:35:15,051 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4734535099462021, 'Total loss': 0.4734535099462021} | train loss {'Reaction outcome loss': 0.4484741354508024, 'Total loss': 0.4484741354508024}
2022-11-28 04:35:15,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:15,051 INFO:     Epoch: 41
2022-11-28 04:35:15,692 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4915417301100354, 'Total loss': 0.4915417301100354} | train loss {'Reaction outcome loss': 0.4521087087783576, 'Total loss': 0.4521087087783576}
2022-11-28 04:35:15,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:15,692 INFO:     Epoch: 42
2022-11-28 04:35:16,330 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48587922751903534, 'Total loss': 0.48587922751903534} | train loss {'Reaction outcome loss': 0.4473308602432987, 'Total loss': 0.4473308602432987}
2022-11-28 04:35:16,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:16,330 INFO:     Epoch: 43
2022-11-28 04:35:16,969 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47397754497306294, 'Total loss': 0.47397754497306294} | train loss {'Reaction outcome loss': 0.45176983868927384, 'Total loss': 0.45176983868927384}
2022-11-28 04:35:16,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:16,970 INFO:     Epoch: 44
2022-11-28 04:35:17,611 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49263194688530854, 'Total loss': 0.49263194688530854} | train loss {'Reaction outcome loss': 0.4343422982084306, 'Total loss': 0.4343422982084306}
2022-11-28 04:35:17,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:17,611 INFO:     Epoch: 45
2022-11-28 04:35:18,250 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4939943413401759, 'Total loss': 0.4939943413401759} | train loss {'Reaction outcome loss': 0.4463627803993423, 'Total loss': 0.4463627803993423}
2022-11-28 04:35:18,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:18,250 INFO:     Epoch: 46
2022-11-28 04:35:18,889 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4816417739141819, 'Total loss': 0.4816417739141819} | train loss {'Reaction outcome loss': 0.44930222887097554, 'Total loss': 0.44930222887097554}
2022-11-28 04:35:18,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:18,889 INFO:     Epoch: 47
2022-11-28 04:35:19,534 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.465463837738647, 'Total loss': 0.465463837738647} | train loss {'Reaction outcome loss': 0.4487829734551956, 'Total loss': 0.4487829734551956}
2022-11-28 04:35:19,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:19,535 INFO:     Epoch: 48
2022-11-28 04:35:20,177 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5014045886522116, 'Total loss': 0.5014045886522116} | train loss {'Reaction outcome loss': 0.44413056907812093, 'Total loss': 0.44413056907812093}
2022-11-28 04:35:20,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:20,178 INFO:     Epoch: 49
2022-11-28 04:35:20,821 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46611753175424975, 'Total loss': 0.46611753175424975} | train loss {'Reaction outcome loss': 0.4470578808631145, 'Total loss': 0.4470578808631145}
2022-11-28 04:35:20,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:20,821 INFO:     Epoch: 50
2022-11-28 04:35:21,461 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4688539588174155, 'Total loss': 0.4688539588174155} | train loss {'Reaction outcome loss': 0.4494435875618606, 'Total loss': 0.4494435875618606}
2022-11-28 04:35:21,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:21,461 INFO:     Epoch: 51
2022-11-28 04:35:22,102 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46489747215149013, 'Total loss': 0.46489747215149013} | train loss {'Reaction outcome loss': 0.4498106502769399, 'Total loss': 0.4498106502769399}
2022-11-28 04:35:22,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:22,103 INFO:     Epoch: 52
2022-11-28 04:35:22,738 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4499124129151189, 'Total loss': 0.4499124129151189} | train loss {'Reaction outcome loss': 0.44123829734275943, 'Total loss': 0.44123829734275943}
2022-11-28 04:35:22,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:22,739 INFO:     Epoch: 53
2022-11-28 04:35:23,377 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4603800350843474, 'Total loss': 0.4603800350843474} | train loss {'Reaction outcome loss': 0.4404489728796037, 'Total loss': 0.4404489728796037}
2022-11-28 04:35:23,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:23,378 INFO:     Epoch: 54
2022-11-28 04:35:24,020 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45860762045133946, 'Total loss': 0.45860762045133946} | train loss {'Reaction outcome loss': 0.45467408087985645, 'Total loss': 0.45467408087985645}
2022-11-28 04:35:24,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:24,020 INFO:     Epoch: 55
2022-11-28 04:35:24,655 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4507722515006398, 'Total loss': 0.4507722515006398} | train loss {'Reaction outcome loss': 0.4485420938349364, 'Total loss': 0.4485420938349364}
2022-11-28 04:35:24,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:24,656 INFO:     Epoch: 56
2022-11-28 04:35:25,294 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4537682380787162, 'Total loss': 0.4537682380787162} | train loss {'Reaction outcome loss': 0.448593481014873, 'Total loss': 0.448593481014873}
2022-11-28 04:35:25,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:25,294 INFO:     Epoch: 57
2022-11-28 04:35:25,929 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46686634109463804, 'Total loss': 0.46686634109463804} | train loss {'Reaction outcome loss': 0.44702038218371604, 'Total loss': 0.44702038218371604}
2022-11-28 04:35:25,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:25,929 INFO:     Epoch: 58
2022-11-28 04:35:26,568 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4818602536999902, 'Total loss': 0.4818602536999902} | train loss {'Reaction outcome loss': 0.4541195518495631, 'Total loss': 0.4541195518495631}
2022-11-28 04:35:26,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:26,568 INFO:     Epoch: 59
2022-11-28 04:35:27,206 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4606394001910853, 'Total loss': 0.4606394001910853} | train loss {'Reaction outcome loss': 0.44829810129409015, 'Total loss': 0.44829810129409015}
2022-11-28 04:35:27,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:27,206 INFO:     Epoch: 60
2022-11-28 04:35:27,847 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44922048234662343, 'Total loss': 0.44922048234662343} | train loss {'Reaction outcome loss': 0.44243237286558784, 'Total loss': 0.44243237286558784}
2022-11-28 04:35:27,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:27,847 INFO:     Epoch: 61
2022-11-28 04:35:28,486 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45959415477375654, 'Total loss': 0.45959415477375654} | train loss {'Reaction outcome loss': 0.4584924416670661, 'Total loss': 0.4584924416670661}
2022-11-28 04:35:28,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:28,487 INFO:     Epoch: 62
2022-11-28 04:35:29,127 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4399850999200067, 'Total loss': 0.4399850999200067} | train loss {'Reaction outcome loss': 0.4429725701012552, 'Total loss': 0.4429725701012552}
2022-11-28 04:35:29,127 INFO:     Found new best model at epoch 62
2022-11-28 04:35:29,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:29,128 INFO:     Epoch: 63
2022-11-28 04:35:29,770 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47743427614833034, 'Total loss': 0.47743427614833034} | train loss {'Reaction outcome loss': 0.45176634235748114, 'Total loss': 0.45176634235748114}
2022-11-28 04:35:29,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:29,770 INFO:     Epoch: 64
2022-11-28 04:35:30,411 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45134977996349335, 'Total loss': 0.45134977996349335} | train loss {'Reaction outcome loss': 0.4556504622163614, 'Total loss': 0.4556504622163614}
2022-11-28 04:35:30,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:30,411 INFO:     Epoch: 65
2022-11-28 04:35:31,053 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4801623498977617, 'Total loss': 0.4801623498977617} | train loss {'Reaction outcome loss': 0.4503315062072762, 'Total loss': 0.4503315062072762}
2022-11-28 04:35:31,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:31,053 INFO:     Epoch: 66
2022-11-28 04:35:31,696 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49249278216861014, 'Total loss': 0.49249278216861014} | train loss {'Reaction outcome loss': 0.44913582454331186, 'Total loss': 0.44913582454331186}
2022-11-28 04:35:31,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:31,697 INFO:     Epoch: 67
2022-11-28 04:35:32,339 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45958849891673687, 'Total loss': 0.45958849891673687} | train loss {'Reaction outcome loss': 0.4489588854347522, 'Total loss': 0.4489588854347522}
2022-11-28 04:35:32,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:32,340 INFO:     Epoch: 68
2022-11-28 04:35:32,977 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4777547446794288, 'Total loss': 0.4777547446794288} | train loss {'Reaction outcome loss': 0.44667847961558343, 'Total loss': 0.44667847961558343}
2022-11-28 04:35:32,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:32,977 INFO:     Epoch: 69
2022-11-28 04:35:33,617 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4681937964849694, 'Total loss': 0.4681937964849694} | train loss {'Reaction outcome loss': 0.45095749353966774, 'Total loss': 0.45095749353966774}
2022-11-28 04:35:33,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:33,617 INFO:     Epoch: 70
2022-11-28 04:35:34,257 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46173407172047815, 'Total loss': 0.46173407172047815} | train loss {'Reaction outcome loss': 0.4533531770295622, 'Total loss': 0.4533531770295622}
2022-11-28 04:35:34,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:34,257 INFO:     Epoch: 71
2022-11-28 04:35:34,900 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47533693632414176, 'Total loss': 0.47533693632414176} | train loss {'Reaction outcome loss': 0.4539314488652336, 'Total loss': 0.4539314488652336}
2022-11-28 04:35:34,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:34,900 INFO:     Epoch: 72
2022-11-28 04:35:35,540 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4735230630220369, 'Total loss': 0.4735230630220369} | train loss {'Reaction outcome loss': 0.45302965748606877, 'Total loss': 0.45302965748606877}
2022-11-28 04:35:35,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:35,541 INFO:     Epoch: 73
2022-11-28 04:35:36,184 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4642500589753306, 'Total loss': 0.4642500589753306} | train loss {'Reaction outcome loss': 0.44950169219762953, 'Total loss': 0.44950169219762953}
2022-11-28 04:35:36,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:36,185 INFO:     Epoch: 74
2022-11-28 04:35:36,825 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44324103794818703, 'Total loss': 0.44324103794818703} | train loss {'Reaction outcome loss': 0.4441021607871867, 'Total loss': 0.4441021607871867}
2022-11-28 04:35:36,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:36,826 INFO:     Epoch: 75
2022-11-28 04:35:37,470 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4781693646381068, 'Total loss': 0.4781693646381068} | train loss {'Reaction outcome loss': 0.4535214155294094, 'Total loss': 0.4535214155294094}
2022-11-28 04:35:37,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:37,470 INFO:     Epoch: 76
2022-11-28 04:35:38,111 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46805188406345455, 'Total loss': 0.46805188406345455} | train loss {'Reaction outcome loss': 0.4552277105539666, 'Total loss': 0.4552277105539666}
2022-11-28 04:35:38,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:38,111 INFO:     Epoch: 77
2022-11-28 04:35:38,751 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4860280090293219, 'Total loss': 0.4860280090293219} | train loss {'Reaction outcome loss': 0.44880565178592174, 'Total loss': 0.44880565178592174}
2022-11-28 04:35:38,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:38,752 INFO:     Epoch: 78
2022-11-28 04:35:39,391 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46855772858442263, 'Total loss': 0.46855772858442263} | train loss {'Reaction outcome loss': 0.45108034687418164, 'Total loss': 0.45108034687418164}
2022-11-28 04:35:39,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:39,392 INFO:     Epoch: 79
2022-11-28 04:35:40,034 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4545237796251164, 'Total loss': 0.4545237796251164} | train loss {'Reaction outcome loss': 0.4469579213387739, 'Total loss': 0.4469579213387739}
2022-11-28 04:35:40,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:40,034 INFO:     Epoch: 80
2022-11-28 04:35:40,674 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4934070546959722, 'Total loss': 0.4934070546959722} | train loss {'Reaction outcome loss': 0.450850030940598, 'Total loss': 0.450850030940598}
2022-11-28 04:35:40,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:40,674 INFO:     Epoch: 81
2022-11-28 04:35:41,313 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46053761122531667, 'Total loss': 0.46053761122531667} | train loss {'Reaction outcome loss': 0.45222870170822776, 'Total loss': 0.45222870170822776}
2022-11-28 04:35:41,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:41,313 INFO:     Epoch: 82
2022-11-28 04:35:41,951 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.451495124157085, 'Total loss': 0.451495124157085} | train loss {'Reaction outcome loss': 0.45968058130305833, 'Total loss': 0.45968058130305833}
2022-11-28 04:35:41,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:41,952 INFO:     Epoch: 83
2022-11-28 04:35:42,592 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47029751210018644, 'Total loss': 0.47029751210018644} | train loss {'Reaction outcome loss': 0.4539310110431489, 'Total loss': 0.4539310110431489}
2022-11-28 04:35:42,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:42,592 INFO:     Epoch: 84
2022-11-28 04:35:43,237 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46165910224581874, 'Total loss': 0.46165910224581874} | train loss {'Reaction outcome loss': 0.45242646262358827, 'Total loss': 0.45242646262358827}
2022-11-28 04:35:43,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:43,237 INFO:     Epoch: 85
2022-11-28 04:35:43,877 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.482404540791068, 'Total loss': 0.482404540791068} | train loss {'Reaction outcome loss': 0.45616183587624326, 'Total loss': 0.45616183587624326}
2022-11-28 04:35:43,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:43,878 INFO:     Epoch: 86
2022-11-28 04:35:44,518 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46030754128167795, 'Total loss': 0.46030754128167795} | train loss {'Reaction outcome loss': 0.46431341043893726, 'Total loss': 0.46431341043893726}
2022-11-28 04:35:44,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:44,519 INFO:     Epoch: 87
2022-11-28 04:35:45,159 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47290524216585383, 'Total loss': 0.47290524216585383} | train loss {'Reaction outcome loss': 0.4516446440484514, 'Total loss': 0.4516446440484514}
2022-11-28 04:35:45,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:45,159 INFO:     Epoch: 88
2022-11-28 04:35:45,800 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4541959863069446, 'Total loss': 0.4541959863069446} | train loss {'Reaction outcome loss': 0.45362686517327655, 'Total loss': 0.45362686517327655}
2022-11-28 04:35:45,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:45,800 INFO:     Epoch: 89
2022-11-28 04:35:46,439 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4540299359102582, 'Total loss': 0.4540299359102582} | train loss {'Reaction outcome loss': 0.45152277375776245, 'Total loss': 0.45152277375776245}
2022-11-28 04:35:46,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:46,439 INFO:     Epoch: 90
2022-11-28 04:35:47,079 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4889880924723869, 'Total loss': 0.4889880924723869} | train loss {'Reaction outcome loss': 0.4578491827449858, 'Total loss': 0.4578491827449858}
2022-11-28 04:35:47,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:47,080 INFO:     Epoch: 91
2022-11-28 04:35:47,719 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4577191440865051, 'Total loss': 0.4577191440865051} | train loss {'Reaction outcome loss': 0.4508750891908076, 'Total loss': 0.4508750891908076}
2022-11-28 04:35:47,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:47,720 INFO:     Epoch: 92
2022-11-28 04:35:48,360 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4740675067485765, 'Total loss': 0.4740675067485765} | train loss {'Reaction outcome loss': 0.45105591286514807, 'Total loss': 0.45105591286514807}
2022-11-28 04:35:48,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:48,360 INFO:     Epoch: 93
2022-11-28 04:35:49,001 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4671710909799088, 'Total loss': 0.4671710909799088} | train loss {'Reaction outcome loss': 0.4565905552372893, 'Total loss': 0.4565905552372893}
2022-11-28 04:35:49,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:49,001 INFO:     Epoch: 94
2022-11-28 04:35:49,646 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4781702812327895, 'Total loss': 0.4781702812327895} | train loss {'Reaction outcome loss': 0.45840965155743957, 'Total loss': 0.45840965155743957}
2022-11-28 04:35:49,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:49,646 INFO:     Epoch: 95
2022-11-28 04:35:50,290 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5375339631424394, 'Total loss': 0.5375339631424394} | train loss {'Reaction outcome loss': 0.4561241060742699, 'Total loss': 0.4561241060742699}
2022-11-28 04:35:50,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:50,290 INFO:     Epoch: 96
2022-11-28 04:35:50,934 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4658070154661356, 'Total loss': 0.4658070154661356} | train loss {'Reaction outcome loss': 0.46222582224493697, 'Total loss': 0.46222582224493697}
2022-11-28 04:35:50,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:50,934 INFO:     Epoch: 97
2022-11-28 04:35:51,578 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44914953722510226, 'Total loss': 0.44914953722510226} | train loss {'Reaction outcome loss': 0.45987484743238977, 'Total loss': 0.45987484743238977}
2022-11-28 04:35:51,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:51,578 INFO:     Epoch: 98
2022-11-28 04:35:52,219 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48980769376422084, 'Total loss': 0.48980769376422084} | train loss {'Reaction outcome loss': 0.45585592418785414, 'Total loss': 0.45585592418785414}
2022-11-28 04:35:52,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:52,220 INFO:     Epoch: 99
2022-11-28 04:35:52,858 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49453268633332365, 'Total loss': 0.49453268633332365} | train loss {'Reaction outcome loss': 0.4502200413788997, 'Total loss': 0.4502200413788997}
2022-11-28 04:35:52,858 INFO:     Best model found after epoch 63 of 100.
2022-11-28 04:35:52,858 INFO:   Done with stage: TRAINING
2022-11-28 04:35:52,858 INFO:   Starting stage: EVALUATION
2022-11-28 04:35:52,999 INFO:   Done with stage: EVALUATION
2022-11-28 04:35:52,999 INFO:   Leaving out SEQ value Fold_3
2022-11-28 04:35:53,012 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 04:35:53,012 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:35:53,644 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:35:53,645 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:35:53,711 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:35:53,711 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:35:53,711 INFO:     No hyperparam tuning for this model
2022-11-28 04:35:53,711 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:35:53,711 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:35:53,712 INFO:     None feature selector for col prot
2022-11-28 04:35:53,712 INFO:     None feature selector for col prot
2022-11-28 04:35:53,712 INFO:     None feature selector for col prot
2022-11-28 04:35:53,712 INFO:     None feature selector for col chem
2022-11-28 04:35:53,712 INFO:     None feature selector for col chem
2022-11-28 04:35:53,712 INFO:     None feature selector for col chem
2022-11-28 04:35:53,713 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:35:53,713 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:35:53,714 INFO:     Number of params in model 169651
2022-11-28 04:35:53,717 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:35:53,717 INFO:   Starting stage: TRAINING
2022-11-28 04:35:53,766 INFO:     Val loss before train {'Reaction outcome loss': 1.0041098511496256, 'Total loss': 1.0041098511496256}
2022-11-28 04:35:53,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:53,767 INFO:     Epoch: 0
2022-11-28 04:35:54,416 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.585617427909097, 'Total loss': 0.585617427909097} | train loss {'Reaction outcome loss': 0.6786295116924849, 'Total loss': 0.6786295116924849}
2022-11-28 04:35:54,417 INFO:     Found new best model at epoch 0
2022-11-28 04:35:54,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:54,417 INFO:     Epoch: 1
2022-11-28 04:35:55,060 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5387445695178453, 'Total loss': 0.5387445695178453} | train loss {'Reaction outcome loss': 0.594171227917808, 'Total loss': 0.594171227917808}
2022-11-28 04:35:55,061 INFO:     Found new best model at epoch 1
2022-11-28 04:35:55,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:55,061 INFO:     Epoch: 2
2022-11-28 04:35:55,709 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5712577187737753, 'Total loss': 0.5712577187737753} | train loss {'Reaction outcome loss': 0.5528205961721843, 'Total loss': 0.5528205961721843}
2022-11-28 04:35:55,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:55,710 INFO:     Epoch: 3
2022-11-28 04:35:56,356 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5458973209525264, 'Total loss': 0.5458973209525264} | train loss {'Reaction outcome loss': 0.5403767828447897, 'Total loss': 0.5403767828447897}
2022-11-28 04:35:56,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:56,356 INFO:     Epoch: 4
2022-11-28 04:35:57,001 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4969018268030743, 'Total loss': 0.4969018268030743} | train loss {'Reaction outcome loss': 0.5297636976007556, 'Total loss': 0.5297636976007556}
2022-11-28 04:35:57,001 INFO:     Found new best model at epoch 4
2022-11-28 04:35:57,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:57,002 INFO:     Epoch: 5
2022-11-28 04:35:57,646 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5307796361834504, 'Total loss': 0.5307796361834504} | train loss {'Reaction outcome loss': 0.5140839785215308, 'Total loss': 0.5140839785215308}
2022-11-28 04:35:57,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:57,646 INFO:     Epoch: 6
2022-11-28 04:35:58,291 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5145428076732991, 'Total loss': 0.5145428076732991} | train loss {'Reaction outcome loss': 0.5078698818068035, 'Total loss': 0.5078698818068035}
2022-11-28 04:35:58,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:58,291 INFO:     Epoch: 7
2022-11-28 04:35:58,935 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.52034328843272, 'Total loss': 0.52034328843272} | train loss {'Reaction outcome loss': 0.5027114630478328, 'Total loss': 0.5027114630478328}
2022-11-28 04:35:58,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:58,935 INFO:     Epoch: 8
2022-11-28 04:35:59,578 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4937684321126273, 'Total loss': 0.4937684321126273} | train loss {'Reaction outcome loss': 0.49519166750375365, 'Total loss': 0.49519166750375365}
2022-11-28 04:35:59,578 INFO:     Found new best model at epoch 8
2022-11-28 04:35:59,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:35:59,579 INFO:     Epoch: 9
2022-11-28 04:36:00,224 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5066708111485769, 'Total loss': 0.5066708111485769} | train loss {'Reaction outcome loss': 0.48798296203623054, 'Total loss': 0.48798296203623054}
2022-11-28 04:36:00,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:00,224 INFO:     Epoch: 10
2022-11-28 04:36:00,866 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4924975495005763, 'Total loss': 0.4924975495005763} | train loss {'Reaction outcome loss': 0.4963264340137849, 'Total loss': 0.4963264340137849}
2022-11-28 04:36:00,866 INFO:     Found new best model at epoch 10
2022-11-28 04:36:00,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:00,867 INFO:     Epoch: 11
2022-11-28 04:36:01,511 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5491417334523312, 'Total loss': 0.5491417334523312} | train loss {'Reaction outcome loss': 0.4814927224069834, 'Total loss': 0.4814927224069834}
2022-11-28 04:36:01,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:01,512 INFO:     Epoch: 12
2022-11-28 04:36:02,157 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4791356259307196, 'Total loss': 0.4791356259307196} | train loss {'Reaction outcome loss': 0.48651582185850767, 'Total loss': 0.48651582185850767}
2022-11-28 04:36:02,157 INFO:     Found new best model at epoch 12
2022-11-28 04:36:02,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:02,158 INFO:     Epoch: 13
2022-11-28 04:36:02,801 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48012996863487156, 'Total loss': 0.48012996863487156} | train loss {'Reaction outcome loss': 0.4889982766548141, 'Total loss': 0.4889982766548141}
2022-11-28 04:36:02,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:02,801 INFO:     Epoch: 14
2022-11-28 04:36:03,445 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5011896789073944, 'Total loss': 0.5011896789073944} | train loss {'Reaction outcome loss': 0.48094071173032776, 'Total loss': 0.48094071173032776}
2022-11-28 04:36:03,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:03,445 INFO:     Epoch: 15
2022-11-28 04:36:04,093 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5088339427182841, 'Total loss': 0.5088339427182841} | train loss {'Reaction outcome loss': 0.48638758411417243, 'Total loss': 0.48638758411417243}
2022-11-28 04:36:04,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:04,093 INFO:     Epoch: 16
2022-11-28 04:36:04,739 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5133415287317231, 'Total loss': 0.5133415287317231} | train loss {'Reaction outcome loss': 0.4803914419207417, 'Total loss': 0.4803914419207417}
2022-11-28 04:36:04,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:04,740 INFO:     Epoch: 17
2022-11-28 04:36:05,384 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.484328945015752, 'Total loss': 0.484328945015752} | train loss {'Reaction outcome loss': 0.4725090726965763, 'Total loss': 0.4725090726965763}
2022-11-28 04:36:05,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:05,384 INFO:     Epoch: 18
2022-11-28 04:36:06,028 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4722207271775534, 'Total loss': 0.4722207271775534} | train loss {'Reaction outcome loss': 0.472308592046382, 'Total loss': 0.472308592046382}
2022-11-28 04:36:06,029 INFO:     Found new best model at epoch 18
2022-11-28 04:36:06,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:06,030 INFO:     Epoch: 19
2022-11-28 04:36:06,673 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5748733167731485, 'Total loss': 0.5748733167731485} | train loss {'Reaction outcome loss': 0.4694301613652315, 'Total loss': 0.4694301613652315}
2022-11-28 04:36:06,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:06,673 INFO:     Epoch: 20
2022-11-28 04:36:07,320 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4650741129420524, 'Total loss': 0.4650741129420524} | train loss {'Reaction outcome loss': 0.4818853240032665, 'Total loss': 0.4818853240032665}
2022-11-28 04:36:07,320 INFO:     Found new best model at epoch 20
2022-11-28 04:36:07,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:07,321 INFO:     Epoch: 21
2022-11-28 04:36:07,968 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49208528565806015, 'Total loss': 0.49208528565806015} | train loss {'Reaction outcome loss': 0.4690593707024074, 'Total loss': 0.4690593707024074}
2022-11-28 04:36:07,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:07,968 INFO:     Epoch: 22
2022-11-28 04:36:08,616 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4644382658392884, 'Total loss': 0.4644382658392884} | train loss {'Reaction outcome loss': 0.4682958874790395, 'Total loss': 0.4682958874790395}
2022-11-28 04:36:08,616 INFO:     Found new best model at epoch 22
2022-11-28 04:36:08,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:08,616 INFO:     Epoch: 23
2022-11-28 04:36:09,263 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49350201633087426, 'Total loss': 0.49350201633087426} | train loss {'Reaction outcome loss': 0.4707147186530418, 'Total loss': 0.4707147186530418}
2022-11-28 04:36:09,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:09,263 INFO:     Epoch: 24
2022-11-28 04:36:09,907 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4868119331293328, 'Total loss': 0.4868119331293328} | train loss {'Reaction outcome loss': 0.46686715254041017, 'Total loss': 0.46686715254041017}
2022-11-28 04:36:09,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:09,907 INFO:     Epoch: 25
2022-11-28 04:36:10,547 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5147280582161837, 'Total loss': 0.5147280582161837} | train loss {'Reaction outcome loss': 0.46746652380975545, 'Total loss': 0.46746652380975545}
2022-11-28 04:36:10,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:10,547 INFO:     Epoch: 26
2022-11-28 04:36:11,192 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47508756331233093, 'Total loss': 0.47508756331233093} | train loss {'Reaction outcome loss': 0.46337152263302295, 'Total loss': 0.46337152263302295}
2022-11-28 04:36:11,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:11,192 INFO:     Epoch: 27
2022-11-28 04:36:11,838 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5084077847558398, 'Total loss': 0.5084077847558398} | train loss {'Reaction outcome loss': 0.461718601525807, 'Total loss': 0.461718601525807}
2022-11-28 04:36:11,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:11,838 INFO:     Epoch: 28
2022-11-28 04:36:12,482 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4624841954818992, 'Total loss': 0.4624841954818992} | train loss {'Reaction outcome loss': 0.4676194721680196, 'Total loss': 0.4676194721680196}
2022-11-28 04:36:12,482 INFO:     Found new best model at epoch 28
2022-11-28 04:36:12,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:12,483 INFO:     Epoch: 29
2022-11-28 04:36:13,129 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4711014417021774, 'Total loss': 0.4711014417021774} | train loss {'Reaction outcome loss': 0.4757435998467148, 'Total loss': 0.4757435998467148}
2022-11-28 04:36:13,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:13,130 INFO:     Epoch: 30
2022-11-28 04:36:13,776 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.475925216148066, 'Total loss': 0.475925216148066} | train loss {'Reaction outcome loss': 0.46800916935088205, 'Total loss': 0.46800916935088205}
2022-11-28 04:36:13,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:13,776 INFO:     Epoch: 31
2022-11-28 04:36:14,422 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5259922181451043, 'Total loss': 0.5259922181451043} | train loss {'Reaction outcome loss': 0.472498285904771, 'Total loss': 0.472498285904771}
2022-11-28 04:36:14,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:14,422 INFO:     Epoch: 32
2022-11-28 04:36:15,070 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46318761138028874, 'Total loss': 0.46318761138028874} | train loss {'Reaction outcome loss': 0.47407007608257357, 'Total loss': 0.47407007608257357}
2022-11-28 04:36:15,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:15,070 INFO:     Epoch: 33
2022-11-28 04:36:15,716 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5278951473707376, 'Total loss': 0.5278951473707376} | train loss {'Reaction outcome loss': 0.46767533420905716, 'Total loss': 0.46767533420905716}
2022-11-28 04:36:15,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:15,716 INFO:     Epoch: 34
2022-11-28 04:36:16,362 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4592059608115706, 'Total loss': 0.4592059608115706} | train loss {'Reaction outcome loss': 0.4710258334630825, 'Total loss': 0.4710258334630825}
2022-11-28 04:36:16,363 INFO:     Found new best model at epoch 34
2022-11-28 04:36:16,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:16,363 INFO:     Epoch: 35
2022-11-28 04:36:17,006 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48490147188652394, 'Total loss': 0.48490147188652394} | train loss {'Reaction outcome loss': 0.4594284468254105, 'Total loss': 0.4594284468254105}
2022-11-28 04:36:17,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:17,006 INFO:     Epoch: 36
2022-11-28 04:36:17,653 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5037838016138521, 'Total loss': 0.5037838016138521} | train loss {'Reaction outcome loss': 0.4688041743929269, 'Total loss': 0.4688041743929269}
2022-11-28 04:36:17,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:17,653 INFO:     Epoch: 37
2022-11-28 04:36:18,300 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4674120476079542, 'Total loss': 0.4674120476079542} | train loss {'Reaction outcome loss': 0.46569386594852463, 'Total loss': 0.46569386594852463}
2022-11-28 04:36:18,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:18,300 INFO:     Epoch: 38
2022-11-28 04:36:18,945 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46913484847822856, 'Total loss': 0.46913484847822856} | train loss {'Reaction outcome loss': 0.4622178199227716, 'Total loss': 0.4622178199227716}
2022-11-28 04:36:18,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:18,946 INFO:     Epoch: 39
2022-11-28 04:36:19,592 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4681365746398305, 'Total loss': 0.4681365746398305} | train loss {'Reaction outcome loss': 0.46160608823182153, 'Total loss': 0.46160608823182153}
2022-11-28 04:36:19,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:19,592 INFO:     Epoch: 40
2022-11-28 04:36:20,238 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4789763725427694, 'Total loss': 0.4789763725427694} | train loss {'Reaction outcome loss': 0.46122808540697957, 'Total loss': 0.46122808540697957}
2022-11-28 04:36:20,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:20,238 INFO:     Epoch: 41
2022-11-28 04:36:20,882 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4790173699689466, 'Total loss': 0.4790173699689466} | train loss {'Reaction outcome loss': 0.4627893816862927, 'Total loss': 0.4627893816862927}
2022-11-28 04:36:20,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:20,882 INFO:     Epoch: 42
2022-11-28 04:36:21,524 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47580565685449644, 'Total loss': 0.47580565685449644} | train loss {'Reaction outcome loss': 0.4620536344095332, 'Total loss': 0.4620536344095332}
2022-11-28 04:36:21,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:21,524 INFO:     Epoch: 43
2022-11-28 04:36:22,168 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47493301297343055, 'Total loss': 0.47493301297343055} | train loss {'Reaction outcome loss': 0.46197129285237826, 'Total loss': 0.46197129285237826}
2022-11-28 04:36:22,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:22,168 INFO:     Epoch: 44
2022-11-28 04:36:22,810 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4798284380934959, 'Total loss': 0.4798284380934959} | train loss {'Reaction outcome loss': 0.4643517865753565, 'Total loss': 0.4643517865753565}
2022-11-28 04:36:22,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:22,811 INFO:     Epoch: 45
2022-11-28 04:36:23,456 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5130637381658998, 'Total loss': 0.5130637381658998} | train loss {'Reaction outcome loss': 0.46251871827684465, 'Total loss': 0.46251871827684465}
2022-11-28 04:36:23,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:23,456 INFO:     Epoch: 46
2022-11-28 04:36:24,101 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5447951271090397, 'Total loss': 0.5447951271090397} | train loss {'Reaction outcome loss': 0.4594145688671069, 'Total loss': 0.4594145688671069}
2022-11-28 04:36:24,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:24,101 INFO:     Epoch: 47
2022-11-28 04:36:24,744 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4637190727300422, 'Total loss': 0.4637190727300422} | train loss {'Reaction outcome loss': 0.45551576752398837, 'Total loss': 0.45551576752398837}
2022-11-28 04:36:24,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:24,745 INFO:     Epoch: 48
2022-11-28 04:36:25,389 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4694831395565077, 'Total loss': 0.4694831395565077} | train loss {'Reaction outcome loss': 0.45867885603401504, 'Total loss': 0.45867885603401504}
2022-11-28 04:36:25,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:25,390 INFO:     Epoch: 49
2022-11-28 04:36:26,038 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5245880983596625, 'Total loss': 0.5245880983596625} | train loss {'Reaction outcome loss': 0.46041351654490487, 'Total loss': 0.46041351654490487}
2022-11-28 04:36:26,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:26,038 INFO:     Epoch: 50
2022-11-28 04:36:26,682 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4916715029367181, 'Total loss': 0.4916715029367181} | train loss {'Reaction outcome loss': 0.4671862006920283, 'Total loss': 0.4671862006920283}
2022-11-28 04:36:26,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:26,683 INFO:     Epoch: 51
2022-11-28 04:36:27,324 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46658997029759164, 'Total loss': 0.46658997029759164} | train loss {'Reaction outcome loss': 0.4640987964927173, 'Total loss': 0.4640987964927173}
2022-11-28 04:36:27,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:27,324 INFO:     Epoch: 52
2022-11-28 04:36:27,970 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4742694160965986, 'Total loss': 0.4742694160965986} | train loss {'Reaction outcome loss': 0.4613737658460121, 'Total loss': 0.4613737658460121}
2022-11-28 04:36:27,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:27,971 INFO:     Epoch: 53
2022-11-28 04:36:28,617 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47673861509145693, 'Total loss': 0.47673861509145693} | train loss {'Reaction outcome loss': 0.4660875855899248, 'Total loss': 0.4660875855899248}
2022-11-28 04:36:28,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:28,618 INFO:     Epoch: 54
2022-11-28 04:36:29,266 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4957634823959927, 'Total loss': 0.4957634823959927} | train loss {'Reaction outcome loss': 0.4641326852142811, 'Total loss': 0.4641326852142811}
2022-11-28 04:36:29,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:29,266 INFO:     Epoch: 55
2022-11-28 04:36:29,913 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4848122291786726, 'Total loss': 0.4848122291786726} | train loss {'Reaction outcome loss': 0.4576643893464667, 'Total loss': 0.4576643893464667}
2022-11-28 04:36:29,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:29,913 INFO:     Epoch: 56
2022-11-28 04:36:30,561 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5130342449559722, 'Total loss': 0.5130342449559722} | train loss {'Reaction outcome loss': 0.45955567935206854, 'Total loss': 0.45955567935206854}
2022-11-28 04:36:30,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:30,561 INFO:     Epoch: 57
2022-11-28 04:36:31,206 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5040208350780399, 'Total loss': 0.5040208350780399} | train loss {'Reaction outcome loss': 0.4645709649461215, 'Total loss': 0.4645709649461215}
2022-11-28 04:36:31,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:31,207 INFO:     Epoch: 58
2022-11-28 04:36:31,851 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45239239480606347, 'Total loss': 0.45239239480606347} | train loss {'Reaction outcome loss': 0.46202010893430867, 'Total loss': 0.46202010893430867}
2022-11-28 04:36:31,851 INFO:     Found new best model at epoch 58
2022-11-28 04:36:31,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:31,852 INFO:     Epoch: 59
2022-11-28 04:36:32,501 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4670184424450231, 'Total loss': 0.4670184424450231} | train loss {'Reaction outcome loss': 0.4623764266000419, 'Total loss': 0.4623764266000419}
2022-11-28 04:36:32,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:32,501 INFO:     Epoch: 60
2022-11-28 04:36:33,147 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4836623582035996, 'Total loss': 0.4836623582035996} | train loss {'Reaction outcome loss': 0.4587593056017258, 'Total loss': 0.4587593056017258}
2022-11-28 04:36:33,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:33,147 INFO:     Epoch: 61
2022-11-28 04:36:33,794 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4537663771662601, 'Total loss': 0.4537663771662601} | train loss {'Reaction outcome loss': 0.4570628599737023, 'Total loss': 0.4570628599737023}
2022-11-28 04:36:33,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:33,795 INFO:     Epoch: 62
2022-11-28 04:36:34,437 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4528458846169849, 'Total loss': 0.4528458846169849} | train loss {'Reaction outcome loss': 0.4588581955701601, 'Total loss': 0.4588581955701601}
2022-11-28 04:36:34,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:34,437 INFO:     Epoch: 63
2022-11-28 04:36:35,083 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49146862362706384, 'Total loss': 0.49146862362706384} | train loss {'Reaction outcome loss': 0.45794677074815404, 'Total loss': 0.45794677074815404}
2022-11-28 04:36:35,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:35,084 INFO:     Epoch: 64
2022-11-28 04:36:35,736 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4623976439930672, 'Total loss': 0.4623976439930672} | train loss {'Reaction outcome loss': 0.4655803555592162, 'Total loss': 0.4655803555592162}
2022-11-28 04:36:35,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:35,736 INFO:     Epoch: 65
2022-11-28 04:36:36,382 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48822101465491363, 'Total loss': 0.48822101465491363} | train loss {'Reaction outcome loss': 0.4591526595539734, 'Total loss': 0.4591526595539734}
2022-11-28 04:36:36,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:36,382 INFO:     Epoch: 66
2022-11-28 04:36:37,025 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4601049842529519, 'Total loss': 0.4601049842529519} | train loss {'Reaction outcome loss': 0.46386802068254984, 'Total loss': 0.46386802068254984}
2022-11-28 04:36:37,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:37,025 INFO:     Epoch: 67
2022-11-28 04:36:37,670 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4933379881603773, 'Total loss': 0.4933379881603773} | train loss {'Reaction outcome loss': 0.46164452089149444, 'Total loss': 0.46164452089149444}
2022-11-28 04:36:37,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:37,671 INFO:     Epoch: 68
2022-11-28 04:36:38,314 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5026927320070045, 'Total loss': 0.5026927320070045} | train loss {'Reaction outcome loss': 0.4631748038237212, 'Total loss': 0.4631748038237212}
2022-11-28 04:36:38,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:38,314 INFO:     Epoch: 69
2022-11-28 04:36:38,960 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45877808748289595, 'Total loss': 0.45877808748289595} | train loss {'Reaction outcome loss': 0.4690526438052537, 'Total loss': 0.4690526438052537}
2022-11-28 04:36:38,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:38,960 INFO:     Epoch: 70
2022-11-28 04:36:39,605 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4977302086907764, 'Total loss': 0.4977302086907764} | train loss {'Reaction outcome loss': 0.4613045396619156, 'Total loss': 0.4613045396619156}
2022-11-28 04:36:39,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:39,605 INFO:     Epoch: 71
2022-11-28 04:36:40,252 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.507930805863336, 'Total loss': 0.507930805863336} | train loss {'Reaction outcome loss': 0.4598111207367944, 'Total loss': 0.4598111207367944}
2022-11-28 04:36:40,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:40,252 INFO:     Epoch: 72
2022-11-28 04:36:40,899 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49349865819825683, 'Total loss': 0.49349865819825683} | train loss {'Reaction outcome loss': 0.4629744854984713, 'Total loss': 0.4629744854984713}
2022-11-28 04:36:40,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:40,900 INFO:     Epoch: 73
2022-11-28 04:36:41,549 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4670073941003445, 'Total loss': 0.4670073941003445} | train loss {'Reaction outcome loss': 0.45666485646220506, 'Total loss': 0.45666485646220506}
2022-11-28 04:36:41,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:41,549 INFO:     Epoch: 74
2022-11-28 04:36:42,199 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4558379511500514, 'Total loss': 0.4558379511500514} | train loss {'Reaction outcome loss': 0.45715468114272495, 'Total loss': 0.45715468114272495}
2022-11-28 04:36:42,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:42,199 INFO:     Epoch: 75
2022-11-28 04:36:42,843 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45972079385158626, 'Total loss': 0.45972079385158626} | train loss {'Reaction outcome loss': 0.46002269701146686, 'Total loss': 0.46002269701146686}
2022-11-28 04:36:42,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:42,844 INFO:     Epoch: 76
2022-11-28 04:36:43,488 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.473070023364799, 'Total loss': 0.473070023364799} | train loss {'Reaction outcome loss': 0.4616763649783174, 'Total loss': 0.4616763649783174}
2022-11-28 04:36:43,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:43,488 INFO:     Epoch: 77
2022-11-28 04:36:44,135 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46024236360261606, 'Total loss': 0.46024236360261606} | train loss {'Reaction outcome loss': 0.4578718219074558, 'Total loss': 0.4578718219074558}
2022-11-28 04:36:44,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:44,135 INFO:     Epoch: 78
2022-11-28 04:36:44,781 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44831561557082245, 'Total loss': 0.44831561557082245} | train loss {'Reaction outcome loss': 0.46236206322419837, 'Total loss': 0.46236206322419837}
2022-11-28 04:36:44,782 INFO:     Found new best model at epoch 78
2022-11-28 04:36:44,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:44,782 INFO:     Epoch: 79
2022-11-28 04:36:45,433 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49226651115472925, 'Total loss': 0.49226651115472925} | train loss {'Reaction outcome loss': 0.45541229135677463, 'Total loss': 0.45541229135677463}
2022-11-28 04:36:45,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:45,433 INFO:     Epoch: 80
2022-11-28 04:36:46,081 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46248995460743125, 'Total loss': 0.46248995460743125} | train loss {'Reaction outcome loss': 0.46212733176643733, 'Total loss': 0.46212733176643733}
2022-11-28 04:36:46,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:46,081 INFO:     Epoch: 81
2022-11-28 04:36:46,727 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48721696817597676, 'Total loss': 0.48721696817597676} | train loss {'Reaction outcome loss': 0.4644572179703439, 'Total loss': 0.4644572179703439}
2022-11-28 04:36:46,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:46,727 INFO:     Epoch: 82
2022-11-28 04:36:47,369 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4666524848272634, 'Total loss': 0.4666524848272634} | train loss {'Reaction outcome loss': 0.46290947686209055, 'Total loss': 0.46290947686209055}
2022-11-28 04:36:47,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:47,369 INFO:     Epoch: 83
2022-11-28 04:36:48,016 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5291320698898893, 'Total loss': 0.5291320698898893} | train loss {'Reaction outcome loss': 0.46374609541209016, 'Total loss': 0.46374609541209016}
2022-11-28 04:36:48,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:48,016 INFO:     Epoch: 84
2022-11-28 04:36:48,666 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.505642460875733, 'Total loss': 0.505642460875733} | train loss {'Reaction outcome loss': 0.46024844196976206, 'Total loss': 0.46024844196976206}
2022-11-28 04:36:48,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:48,666 INFO:     Epoch: 85
2022-11-28 04:36:49,315 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4726592052814572, 'Total loss': 0.4726592052814572} | train loss {'Reaction outcome loss': 0.45945267034236525, 'Total loss': 0.45945267034236525}
2022-11-28 04:36:49,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:49,315 INFO:     Epoch: 86
2022-11-28 04:36:49,963 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4652364777271138, 'Total loss': 0.4652364777271138} | train loss {'Reaction outcome loss': 0.45740715976132723, 'Total loss': 0.45740715976132723}
2022-11-28 04:36:49,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:49,963 INFO:     Epoch: 87
2022-11-28 04:36:50,612 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4708271120176759, 'Total loss': 0.4708271120176759} | train loss {'Reaction outcome loss': 0.4644190921890931, 'Total loss': 0.4644190921890931}
2022-11-28 04:36:50,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:50,613 INFO:     Epoch: 88
2022-11-28 04:36:51,260 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45900687402070955, 'Total loss': 0.45900687402070955} | train loss {'Reaction outcome loss': 0.4537672135429304, 'Total loss': 0.4537672135429304}
2022-11-28 04:36:51,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:51,261 INFO:     Epoch: 89
2022-11-28 04:36:51,910 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47112006364866743, 'Total loss': 0.47112006364866743} | train loss {'Reaction outcome loss': 0.46725543191442725, 'Total loss': 0.46725543191442725}
2022-11-28 04:36:51,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:51,911 INFO:     Epoch: 90
2022-11-28 04:36:52,558 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48511895537376404, 'Total loss': 0.48511895537376404} | train loss {'Reaction outcome loss': 0.4579159831170176, 'Total loss': 0.4579159831170176}
2022-11-28 04:36:52,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:52,558 INFO:     Epoch: 91
2022-11-28 04:36:53,206 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46775257206240367, 'Total loss': 0.46775257206240367} | train loss {'Reaction outcome loss': 0.46282190340952795, 'Total loss': 0.46282190340952795}
2022-11-28 04:36:53,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:53,206 INFO:     Epoch: 92
2022-11-28 04:36:53,854 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4786808275899222, 'Total loss': 0.4786808275899222} | train loss {'Reaction outcome loss': 0.4603675335157113, 'Total loss': 0.4603675335157113}
2022-11-28 04:36:53,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:53,854 INFO:     Epoch: 93
2022-11-28 04:36:54,502 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4793531756068385, 'Total loss': 0.4793531756068385} | train loss {'Reaction outcome loss': 0.4709698879083649, 'Total loss': 0.4709698879083649}
2022-11-28 04:36:54,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:54,503 INFO:     Epoch: 94
2022-11-28 04:36:55,152 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49791469407636063, 'Total loss': 0.49791469407636063} | train loss {'Reaction outcome loss': 0.4603921583563578, 'Total loss': 0.4603921583563578}
2022-11-28 04:36:55,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:55,152 INFO:     Epoch: 95
2022-11-28 04:36:55,799 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4725853010665539, 'Total loss': 0.4725853010665539} | train loss {'Reaction outcome loss': 0.4600401796766969, 'Total loss': 0.4600401796766969}
2022-11-28 04:36:55,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:55,799 INFO:     Epoch: 96
2022-11-28 04:36:56,451 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48892253983852474, 'Total loss': 0.48892253983852474} | train loss {'Reaction outcome loss': 0.4683027624717501, 'Total loss': 0.4683027624717501}
2022-11-28 04:36:56,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:56,451 INFO:     Epoch: 97
2022-11-28 04:36:57,102 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4787866403890211, 'Total loss': 0.4787866403890211} | train loss {'Reaction outcome loss': 0.4617291987858346, 'Total loss': 0.4617291987858346}
2022-11-28 04:36:57,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:57,103 INFO:     Epoch: 98
2022-11-28 04:36:57,755 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4911409852116607, 'Total loss': 0.4911409852116607} | train loss {'Reaction outcome loss': 0.46351533010602, 'Total loss': 0.46351533010602}
2022-11-28 04:36:57,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:57,755 INFO:     Epoch: 99
2022-11-28 04:36:58,407 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4906712056592453, 'Total loss': 0.4906712056592453} | train loss {'Reaction outcome loss': 0.4633839846145911, 'Total loss': 0.4633839846145911}
2022-11-28 04:36:58,407 INFO:     Best model found after epoch 79 of 100.
2022-11-28 04:36:58,407 INFO:   Done with stage: TRAINING
2022-11-28 04:36:58,407 INFO:   Starting stage: EVALUATION
2022-11-28 04:36:58,537 INFO:   Done with stage: EVALUATION
2022-11-28 04:36:58,538 INFO:   Leaving out SEQ value Fold_4
2022-11-28 04:36:58,550 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:36:58,551 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:36:59,201 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:36:59,201 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:36:59,268 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:36:59,268 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:36:59,268 INFO:     No hyperparam tuning for this model
2022-11-28 04:36:59,268 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:36:59,268 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:36:59,269 INFO:     None feature selector for col prot
2022-11-28 04:36:59,269 INFO:     None feature selector for col prot
2022-11-28 04:36:59,269 INFO:     None feature selector for col prot
2022-11-28 04:36:59,270 INFO:     None feature selector for col chem
2022-11-28 04:36:59,270 INFO:     None feature selector for col chem
2022-11-28 04:36:59,270 INFO:     None feature selector for col chem
2022-11-28 04:36:59,270 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:36:59,270 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:36:59,271 INFO:     Number of params in model 169651
2022-11-28 04:36:59,274 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:36:59,274 INFO:   Starting stage: TRAINING
2022-11-28 04:36:59,325 INFO:     Val loss before train {'Reaction outcome loss': 0.9736129126765511, 'Total loss': 0.9736129126765511}
2022-11-28 04:36:59,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:59,326 INFO:     Epoch: 0
2022-11-28 04:36:59,985 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5961455817927014, 'Total loss': 0.5961455817927014} | train loss {'Reaction outcome loss': 0.6859155825154502, 'Total loss': 0.6859155825154502}
2022-11-28 04:36:59,985 INFO:     Found new best model at epoch 0
2022-11-28 04:36:59,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:36:59,986 INFO:     Epoch: 1
2022-11-28 04:37:00,642 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5272891562093388, 'Total loss': 0.5272891562093388} | train loss {'Reaction outcome loss': 0.5723259450739574, 'Total loss': 0.5723259450739574}
2022-11-28 04:37:00,642 INFO:     Found new best model at epoch 1
2022-11-28 04:37:00,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:00,643 INFO:     Epoch: 2
2022-11-28 04:37:01,305 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5260290391743183, 'Total loss': 0.5260290391743183} | train loss {'Reaction outcome loss': 0.5503221061306927, 'Total loss': 0.5503221061306927}
2022-11-28 04:37:01,305 INFO:     Found new best model at epoch 2
2022-11-28 04:37:01,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:01,305 INFO:     Epoch: 3
2022-11-28 04:37:01,962 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5166018540886316, 'Total loss': 0.5166018540886316} | train loss {'Reaction outcome loss': 0.5332940404835017, 'Total loss': 0.5332940404835017}
2022-11-28 04:37:01,962 INFO:     Found new best model at epoch 3
2022-11-28 04:37:01,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:01,963 INFO:     Epoch: 4
2022-11-28 04:37:02,621 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4984663748605685, 'Total loss': 0.4984663748605685} | train loss {'Reaction outcome loss': 0.5068693487501519, 'Total loss': 0.5068693487501519}
2022-11-28 04:37:02,621 INFO:     Found new best model at epoch 4
2022-11-28 04:37:02,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:02,622 INFO:     Epoch: 5
2022-11-28 04:37:03,279 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5261272811754183, 'Total loss': 0.5261272811754183} | train loss {'Reaction outcome loss': 0.5041708300712138, 'Total loss': 0.5041708300712138}
2022-11-28 04:37:03,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:03,279 INFO:     Epoch: 6
2022-11-28 04:37:03,937 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4848189797591079, 'Total loss': 0.4848189797591079} | train loss {'Reaction outcome loss': 0.49883246819982646, 'Total loss': 0.49883246819982646}
2022-11-28 04:37:03,937 INFO:     Found new best model at epoch 6
2022-11-28 04:37:03,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:03,937 INFO:     Epoch: 7
2022-11-28 04:37:04,596 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5136607577177611, 'Total loss': 0.5136607577177611} | train loss {'Reaction outcome loss': 0.5029749583136215, 'Total loss': 0.5029749583136215}
2022-11-28 04:37:04,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:04,597 INFO:     Epoch: 8
2022-11-28 04:37:05,255 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5220396213910796, 'Total loss': 0.5220396213910796} | train loss {'Reaction outcome loss': 0.5053026306967021, 'Total loss': 0.5053026306967021}
2022-11-28 04:37:05,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:05,256 INFO:     Epoch: 9
2022-11-28 04:37:05,918 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4764805327762257, 'Total loss': 0.4764805327762257} | train loss {'Reaction outcome loss': 0.5035727754054282, 'Total loss': 0.5035727754054282}
2022-11-28 04:37:05,919 INFO:     Found new best model at epoch 9
2022-11-28 04:37:05,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:05,919 INFO:     Epoch: 10
2022-11-28 04:37:06,578 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.487535723908381, 'Total loss': 0.487535723908381} | train loss {'Reaction outcome loss': 0.48652200504142024, 'Total loss': 0.48652200504142024}
2022-11-28 04:37:06,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:06,578 INFO:     Epoch: 11
2022-11-28 04:37:07,236 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5010068728165193, 'Total loss': 0.5010068728165193} | train loss {'Reaction outcome loss': 0.4844483317513215, 'Total loss': 0.4844483317513215}
2022-11-28 04:37:07,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:07,237 INFO:     Epoch: 12
2022-11-28 04:37:07,895 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5098103183236989, 'Total loss': 0.5098103183236989} | train loss {'Reaction outcome loss': 0.4900666202987857, 'Total loss': 0.4900666202987857}
2022-11-28 04:37:07,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:07,895 INFO:     Epoch: 13
2022-11-28 04:37:08,552 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5011375079100783, 'Total loss': 0.5011375079100783} | train loss {'Reaction outcome loss': 0.4983202409647737, 'Total loss': 0.4983202409647737}
2022-11-28 04:37:08,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:08,552 INFO:     Epoch: 14
2022-11-28 04:37:09,210 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5848358937285163, 'Total loss': 0.5848358937285163} | train loss {'Reaction outcome loss': 0.48026452204476483, 'Total loss': 0.48026452204476483}
2022-11-28 04:37:09,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:09,211 INFO:     Epoch: 15
2022-11-28 04:37:09,874 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49433869699185545, 'Total loss': 0.49433869699185545} | train loss {'Reaction outcome loss': 0.4798011357183399, 'Total loss': 0.4798011357183399}
2022-11-28 04:37:09,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:09,874 INFO:     Epoch: 16
2022-11-28 04:37:10,534 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49585739319974725, 'Total loss': 0.49585739319974725} | train loss {'Reaction outcome loss': 0.4745711360262473, 'Total loss': 0.4745711360262473}
2022-11-28 04:37:10,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:10,535 INFO:     Epoch: 17
2022-11-28 04:37:11,190 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4660014235837893, 'Total loss': 0.4660014235837893} | train loss {'Reaction outcome loss': 0.48083558962171374, 'Total loss': 0.48083558962171374}
2022-11-28 04:37:11,190 INFO:     Found new best model at epoch 17
2022-11-28 04:37:11,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:11,191 INFO:     Epoch: 18
2022-11-28 04:37:11,850 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48305767300454056, 'Total loss': 0.48305767300454056} | train loss {'Reaction outcome loss': 0.4799477051988787, 'Total loss': 0.4799477051988787}
2022-11-28 04:37:11,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:11,851 INFO:     Epoch: 19
2022-11-28 04:37:12,511 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4579046368598938, 'Total loss': 0.4579046368598938} | train loss {'Reaction outcome loss': 0.4771161574553623, 'Total loss': 0.4771161574553623}
2022-11-28 04:37:12,511 INFO:     Found new best model at epoch 19
2022-11-28 04:37:12,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:12,512 INFO:     Epoch: 20
2022-11-28 04:37:13,170 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4536394490437074, 'Total loss': 0.4536394490437074} | train loss {'Reaction outcome loss': 0.4698061534488264, 'Total loss': 0.4698061534488264}
2022-11-28 04:37:13,170 INFO:     Found new best model at epoch 20
2022-11-28 04:37:13,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:13,171 INFO:     Epoch: 21
2022-11-28 04:37:13,829 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4946284971453927, 'Total loss': 0.4946284971453927} | train loss {'Reaction outcome loss': 0.4719968783831307, 'Total loss': 0.4719968783831307}
2022-11-28 04:37:13,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:13,829 INFO:     Epoch: 22
2022-11-28 04:37:14,487 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48482522470029915, 'Total loss': 0.48482522470029915} | train loss {'Reaction outcome loss': 0.4751765616388939, 'Total loss': 0.4751765616388939}
2022-11-28 04:37:14,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:14,487 INFO:     Epoch: 23
2022-11-28 04:37:15,146 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5049956109036099, 'Total loss': 0.5049956109036099} | train loss {'Reaction outcome loss': 0.4712351421384435, 'Total loss': 0.4712351421384435}
2022-11-28 04:37:15,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:15,147 INFO:     Epoch: 24
2022-11-28 04:37:15,806 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4839484122666446, 'Total loss': 0.4839484122666446} | train loss {'Reaction outcome loss': 0.47910141432092257, 'Total loss': 0.47910141432092257}
2022-11-28 04:37:15,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:15,806 INFO:     Epoch: 25
2022-11-28 04:37:16,465 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45517912608656014, 'Total loss': 0.45517912608656014} | train loss {'Reaction outcome loss': 0.4890967615944171, 'Total loss': 0.4890967615944171}
2022-11-28 04:37:16,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:16,465 INFO:     Epoch: 26
2022-11-28 04:37:17,123 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4775223345919089, 'Total loss': 0.4775223345919089} | train loss {'Reaction outcome loss': 0.468378285768061, 'Total loss': 0.468378285768061}
2022-11-28 04:37:17,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:17,124 INFO:     Epoch: 27
2022-11-28 04:37:17,784 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4776933206753297, 'Total loss': 0.4776933206753297} | train loss {'Reaction outcome loss': 0.47239238134611716, 'Total loss': 0.47239238134611716}
2022-11-28 04:37:17,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:17,785 INFO:     Epoch: 28
2022-11-28 04:37:18,446 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4634003649381074, 'Total loss': 0.4634003649381074} | train loss {'Reaction outcome loss': 0.47258601672494943, 'Total loss': 0.47258601672494943}
2022-11-28 04:37:18,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:18,446 INFO:     Epoch: 29
2022-11-28 04:37:19,105 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4437031024558978, 'Total loss': 0.4437031024558978} | train loss {'Reaction outcome loss': 0.4809045699323237, 'Total loss': 0.4809045699323237}
2022-11-28 04:37:19,105 INFO:     Found new best model at epoch 29
2022-11-28 04:37:19,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:19,106 INFO:     Epoch: 30
2022-11-28 04:37:19,766 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4586845934391022, 'Total loss': 0.4586845934391022} | train loss {'Reaction outcome loss': 0.4647276874797547, 'Total loss': 0.4647276874797547}
2022-11-28 04:37:19,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:19,767 INFO:     Epoch: 31
2022-11-28 04:37:20,426 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4643293233080344, 'Total loss': 0.4643293233080344} | train loss {'Reaction outcome loss': 0.4690133593401491, 'Total loss': 0.4690133593401491}
2022-11-28 04:37:20,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:20,426 INFO:     Epoch: 32
2022-11-28 04:37:21,086 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5096341618760065, 'Total loss': 0.5096341618760065} | train loss {'Reaction outcome loss': 0.4711368719213887, 'Total loss': 0.4711368719213887}
2022-11-28 04:37:21,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:21,087 INFO:     Epoch: 33
2022-11-28 04:37:21,750 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5022619041529569, 'Total loss': 0.5022619041529569} | train loss {'Reaction outcome loss': 0.46762217437237624, 'Total loss': 0.46762217437237624}
2022-11-28 04:37:21,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:21,751 INFO:     Epoch: 34
2022-11-28 04:37:22,408 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4842219657518647, 'Total loss': 0.4842219657518647} | train loss {'Reaction outcome loss': 0.4801483821531056, 'Total loss': 0.4801483821531056}
2022-11-28 04:37:22,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:22,408 INFO:     Epoch: 35
2022-11-28 04:37:23,068 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4734505553814498, 'Total loss': 0.4734505553814498} | train loss {'Reaction outcome loss': 0.4692786630348638, 'Total loss': 0.4692786630348638}
2022-11-28 04:37:23,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:23,068 INFO:     Epoch: 36
2022-11-28 04:37:23,727 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46562319418246095, 'Total loss': 0.46562319418246095} | train loss {'Reaction outcome loss': 0.4716175710292239, 'Total loss': 0.4716175710292239}
2022-11-28 04:37:23,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:23,728 INFO:     Epoch: 37
2022-11-28 04:37:24,385 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5147507952695544, 'Total loss': 0.5147507952695544} | train loss {'Reaction outcome loss': 0.46982705330679775, 'Total loss': 0.46982705330679775}
2022-11-28 04:37:24,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:24,385 INFO:     Epoch: 38
2022-11-28 04:37:25,046 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47355554456060583, 'Total loss': 0.47355554456060583} | train loss {'Reaction outcome loss': 0.4780880176586661, 'Total loss': 0.4780880176586661}
2022-11-28 04:37:25,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:25,046 INFO:     Epoch: 39
2022-11-28 04:37:25,703 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.497405545278029, 'Total loss': 0.497405545278029} | train loss {'Reaction outcome loss': 0.47223206558208236, 'Total loss': 0.47223206558208236}
2022-11-28 04:37:25,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:25,703 INFO:     Epoch: 40
2022-11-28 04:37:26,360 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4550469419495626, 'Total loss': 0.4550469419495626} | train loss {'Reaction outcome loss': 0.47387968727692903, 'Total loss': 0.47387968727692903}
2022-11-28 04:37:26,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:26,360 INFO:     Epoch: 41
2022-11-28 04:37:27,019 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49025052785873413, 'Total loss': 0.49025052785873413} | train loss {'Reaction outcome loss': 0.4701536431642785, 'Total loss': 0.4701536431642785}
2022-11-28 04:37:27,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:27,019 INFO:     Epoch: 42
2022-11-28 04:37:27,675 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48195991529659793, 'Total loss': 0.48195991529659793} | train loss {'Reaction outcome loss': 0.47132990795832413, 'Total loss': 0.47132990795832413}
2022-11-28 04:37:27,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:27,676 INFO:     Epoch: 43
2022-11-28 04:37:28,331 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4832735586572777, 'Total loss': 0.4832735586572777} | train loss {'Reaction outcome loss': 0.4691679074093398, 'Total loss': 0.4691679074093398}
2022-11-28 04:37:28,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:28,331 INFO:     Epoch: 44
2022-11-28 04:37:28,991 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4668258814649148, 'Total loss': 0.4668258814649148} | train loss {'Reaction outcome loss': 0.4662492335566625, 'Total loss': 0.4662492335566625}
2022-11-28 04:37:28,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:28,991 INFO:     Epoch: 45
2022-11-28 04:37:29,650 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4887095500122417, 'Total loss': 0.4887095500122417} | train loss {'Reaction outcome loss': 0.47061825148489794, 'Total loss': 0.47061825148489794}
2022-11-28 04:37:29,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:29,650 INFO:     Epoch: 46
2022-11-28 04:37:30,311 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4749387627975507, 'Total loss': 0.4749387627975507} | train loss {'Reaction outcome loss': 0.4678012266574118, 'Total loss': 0.4678012266574118}
2022-11-28 04:37:30,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:30,311 INFO:     Epoch: 47
2022-11-28 04:37:30,971 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46325822174549103, 'Total loss': 0.46325822174549103} | train loss {'Reaction outcome loss': 0.4587571953954967, 'Total loss': 0.4587571953954967}
2022-11-28 04:37:30,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:30,971 INFO:     Epoch: 48
2022-11-28 04:37:31,630 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48087482222101907, 'Total loss': 0.48087482222101907} | train loss {'Reaction outcome loss': 0.45473163786084064, 'Total loss': 0.45473163786084064}
2022-11-28 04:37:31,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:31,630 INFO:     Epoch: 49
2022-11-28 04:37:32,285 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47832722250710835, 'Total loss': 0.47832722250710835} | train loss {'Reaction outcome loss': 0.46434819529413696, 'Total loss': 0.46434819529413696}
2022-11-28 04:37:32,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:32,285 INFO:     Epoch: 50
2022-11-28 04:37:32,945 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5089953264052217, 'Total loss': 0.5089953264052217} | train loss {'Reaction outcome loss': 0.4621016857353782, 'Total loss': 0.4621016857353782}
2022-11-28 04:37:32,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:32,945 INFO:     Epoch: 51
2022-11-28 04:37:33,605 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4622101072560657, 'Total loss': 0.4622101072560657} | train loss {'Reaction outcome loss': 0.4653565494517083, 'Total loss': 0.4653565494517083}
2022-11-28 04:37:33,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:33,606 INFO:     Epoch: 52
2022-11-28 04:37:34,264 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4609180394221436, 'Total loss': 0.4609180394221436} | train loss {'Reaction outcome loss': 0.46777408888001704, 'Total loss': 0.46777408888001704}
2022-11-28 04:37:34,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:34,264 INFO:     Epoch: 53
2022-11-28 04:37:34,924 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4683305892077359, 'Total loss': 0.4683305892077359} | train loss {'Reaction outcome loss': 0.46032370545482826, 'Total loss': 0.46032370545482826}
2022-11-28 04:37:34,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:34,924 INFO:     Epoch: 54
2022-11-28 04:37:35,583 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5009404908527028, 'Total loss': 0.5009404908527028} | train loss {'Reaction outcome loss': 0.46288168118882034, 'Total loss': 0.46288168118882034}
2022-11-28 04:37:35,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:35,583 INFO:     Epoch: 55
2022-11-28 04:37:36,244 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4585989137942141, 'Total loss': 0.4585989137942141} | train loss {'Reaction outcome loss': 0.4737441854076347, 'Total loss': 0.4737441854076347}
2022-11-28 04:37:36,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:36,244 INFO:     Epoch: 56
2022-11-28 04:37:36,902 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46505449001084675, 'Total loss': 0.46505449001084675} | train loss {'Reaction outcome loss': 0.46547905322511185, 'Total loss': 0.46547905322511185}
2022-11-28 04:37:36,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:36,903 INFO:     Epoch: 57
2022-11-28 04:37:37,563 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49278724837032234, 'Total loss': 0.49278724837032234} | train loss {'Reaction outcome loss': 0.46712901703787113, 'Total loss': 0.46712901703787113}
2022-11-28 04:37:37,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:37,563 INFO:     Epoch: 58
2022-11-28 04:37:38,221 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4718202782625502, 'Total loss': 0.4718202782625502} | train loss {'Reaction outcome loss': 0.4662694056114928, 'Total loss': 0.4662694056114928}
2022-11-28 04:37:38,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:38,221 INFO:     Epoch: 59
2022-11-28 04:37:38,882 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47462014718489215, 'Total loss': 0.47462014718489215} | train loss {'Reaction outcome loss': 0.4603479772444196, 'Total loss': 0.4603479772444196}
2022-11-28 04:37:38,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:38,883 INFO:     Epoch: 60
2022-11-28 04:37:39,544 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5056496188044548, 'Total loss': 0.5056496188044548} | train loss {'Reaction outcome loss': 0.46763179206896405, 'Total loss': 0.46763179206896405}
2022-11-28 04:37:39,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:39,544 INFO:     Epoch: 61
2022-11-28 04:37:40,207 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49509232863783836, 'Total loss': 0.49509232863783836} | train loss {'Reaction outcome loss': 0.4715360758999581, 'Total loss': 0.4715360758999581}
2022-11-28 04:37:40,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:40,208 INFO:     Epoch: 62
2022-11-28 04:37:40,865 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4769547043198889, 'Total loss': 0.4769547043198889} | train loss {'Reaction outcome loss': 0.46608836261125713, 'Total loss': 0.46608836261125713}
2022-11-28 04:37:40,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:40,865 INFO:     Epoch: 63
2022-11-28 04:37:41,522 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48235880820588634, 'Total loss': 0.48235880820588634} | train loss {'Reaction outcome loss': 0.4728731557666531, 'Total loss': 0.4728731557666531}
2022-11-28 04:37:41,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:41,522 INFO:     Epoch: 64
2022-11-28 04:37:42,180 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48767589472911577, 'Total loss': 0.48767589472911577} | train loss {'Reaction outcome loss': 0.4698909521706191, 'Total loss': 0.4698909521706191}
2022-11-28 04:37:42,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:42,181 INFO:     Epoch: 65
2022-11-28 04:37:42,843 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45741356892341917, 'Total loss': 0.45741356892341917} | train loss {'Reaction outcome loss': 0.4776652933735597, 'Total loss': 0.4776652933735597}
2022-11-28 04:37:42,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:42,844 INFO:     Epoch: 66
2022-11-28 04:37:43,501 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4674253416332332, 'Total loss': 0.4674253416332332} | train loss {'Reaction outcome loss': 0.46510425744472667, 'Total loss': 0.46510425744472667}
2022-11-28 04:37:43,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:43,501 INFO:     Epoch: 67
2022-11-28 04:37:44,158 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44812227683988487, 'Total loss': 0.44812227683988487} | train loss {'Reaction outcome loss': 0.45864073757217966, 'Total loss': 0.45864073757217966}
2022-11-28 04:37:44,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:44,158 INFO:     Epoch: 68
2022-11-28 04:37:44,819 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46931352059949527, 'Total loss': 0.46931352059949527} | train loss {'Reaction outcome loss': 0.4646363091251628, 'Total loss': 0.4646363091251628}
2022-11-28 04:37:44,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:44,819 INFO:     Epoch: 69
2022-11-28 04:37:45,481 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4654200639237057, 'Total loss': 0.4654200639237057} | train loss {'Reaction outcome loss': 0.4696999349695468, 'Total loss': 0.4696999349695468}
2022-11-28 04:37:45,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:45,482 INFO:     Epoch: 70
2022-11-28 04:37:46,141 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45668760856444185, 'Total loss': 0.45668760856444185} | train loss {'Reaction outcome loss': 0.4567170728088511, 'Total loss': 0.4567170728088511}
2022-11-28 04:37:46,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:46,142 INFO:     Epoch: 71
2022-11-28 04:37:46,800 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49158617650920694, 'Total loss': 0.49158617650920694} | train loss {'Reaction outcome loss': 0.46313393568461725, 'Total loss': 0.46313393568461725}
2022-11-28 04:37:46,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:46,800 INFO:     Epoch: 72
2022-11-28 04:37:47,458 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47445622289722617, 'Total loss': 0.47445622289722617} | train loss {'Reaction outcome loss': 0.4655630345407285, 'Total loss': 0.4655630345407285}
2022-11-28 04:37:47,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:47,458 INFO:     Epoch: 73
2022-11-28 04:37:48,117 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4602657908743078, 'Total loss': 0.4602657908743078} | train loss {'Reaction outcome loss': 0.46244183086190627, 'Total loss': 0.46244183086190627}
2022-11-28 04:37:48,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:48,118 INFO:     Epoch: 74
2022-11-28 04:37:48,780 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48267103934829886, 'Total loss': 0.48267103934829886} | train loss {'Reaction outcome loss': 0.4584392943543944, 'Total loss': 0.4584392943543944}
2022-11-28 04:37:48,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:48,780 INFO:     Epoch: 75
2022-11-28 04:37:49,444 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4558193470266732, 'Total loss': 0.4558193470266732} | train loss {'Reaction outcome loss': 0.46487361337491856, 'Total loss': 0.46487361337491856}
2022-11-28 04:37:49,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:49,444 INFO:     Epoch: 76
2022-11-28 04:37:50,104 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48218026300045574, 'Total loss': 0.48218026300045574} | train loss {'Reaction outcome loss': 0.46301755414679946, 'Total loss': 0.46301755414679946}
2022-11-28 04:37:50,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:50,104 INFO:     Epoch: 77
2022-11-28 04:37:50,762 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4655428843742067, 'Total loss': 0.4655428843742067} | train loss {'Reaction outcome loss': 0.4645578907086299, 'Total loss': 0.4645578907086299}
2022-11-28 04:37:50,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:50,762 INFO:     Epoch: 78
2022-11-28 04:37:51,421 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.509030129421841, 'Total loss': 0.509030129421841} | train loss {'Reaction outcome loss': 0.46696250768084274, 'Total loss': 0.46696250768084274}
2022-11-28 04:37:51,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:51,421 INFO:     Epoch: 79
2022-11-28 04:37:52,080 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4700428301637823, 'Total loss': 0.4700428301637823} | train loss {'Reaction outcome loss': 0.4661723794934042, 'Total loss': 0.4661723794934042}
2022-11-28 04:37:52,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:52,080 INFO:     Epoch: 80
2022-11-28 04:37:52,740 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47587162256240845, 'Total loss': 0.47587162256240845} | train loss {'Reaction outcome loss': 0.4582706665552338, 'Total loss': 0.4582706665552338}
2022-11-28 04:37:52,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:52,742 INFO:     Epoch: 81
2022-11-28 04:37:53,405 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46528545733202586, 'Total loss': 0.46528545733202586} | train loss {'Reaction outcome loss': 0.46103408069987045, 'Total loss': 0.46103408069987045}
2022-11-28 04:37:53,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:53,405 INFO:     Epoch: 82
2022-11-28 04:37:54,065 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4486539607698267, 'Total loss': 0.4486539607698267} | train loss {'Reaction outcome loss': 0.46136231458018184, 'Total loss': 0.46136231458018184}
2022-11-28 04:37:54,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:54,065 INFO:     Epoch: 83
2022-11-28 04:37:54,724 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6052223921499469, 'Total loss': 0.6052223921499469} | train loss {'Reaction outcome loss': 0.46190337728150943, 'Total loss': 0.46190337728150943}
2022-11-28 04:37:54,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:54,724 INFO:     Epoch: 84
2022-11-28 04:37:55,385 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48276079005815764, 'Total loss': 0.48276079005815764} | train loss {'Reaction outcome loss': 0.47687638604915455, 'Total loss': 0.47687638604915455}
2022-11-28 04:37:55,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:55,385 INFO:     Epoch: 85
2022-11-28 04:37:56,044 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4696947488595139, 'Total loss': 0.4696947488595139} | train loss {'Reaction outcome loss': 0.46163552534966334, 'Total loss': 0.46163552534966334}
2022-11-28 04:37:56,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:56,045 INFO:     Epoch: 86
2022-11-28 04:37:56,702 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4958979589017955, 'Total loss': 0.4958979589017955} | train loss {'Reaction outcome loss': 0.47340048988338423, 'Total loss': 0.47340048988338423}
2022-11-28 04:37:56,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:56,703 INFO:     Epoch: 87
2022-11-28 04:37:57,365 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4880730638449842, 'Total loss': 0.4880730638449842} | train loss {'Reaction outcome loss': 0.4719364807190683, 'Total loss': 0.4719364807190683}
2022-11-28 04:37:57,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:57,365 INFO:     Epoch: 88
2022-11-28 04:37:58,027 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4720435460860079, 'Total loss': 0.4720435460860079} | train loss {'Reaction outcome loss': 0.4861353342591027, 'Total loss': 0.4861353342591027}
2022-11-28 04:37:58,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:58,027 INFO:     Epoch: 89
2022-11-28 04:37:58,681 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5214628089557994, 'Total loss': 0.5214628089557994} | train loss {'Reaction outcome loss': 0.5082635980868629, 'Total loss': 0.5082635980868629}
2022-11-28 04:37:58,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:58,681 INFO:     Epoch: 90
2022-11-28 04:37:59,336 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4745764691721309, 'Total loss': 0.4745764691721309} | train loss {'Reaction outcome loss': 0.47512684008370526, 'Total loss': 0.47512684008370526}
2022-11-28 04:37:59,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:59,337 INFO:     Epoch: 91
2022-11-28 04:37:59,990 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4706377996639772, 'Total loss': 0.4706377996639772} | train loss {'Reaction outcome loss': 0.4673072624544383, 'Total loss': 0.4673072624544383}
2022-11-28 04:37:59,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:37:59,990 INFO:     Epoch: 92
2022-11-28 04:38:00,639 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4681104513054544, 'Total loss': 0.4681104513054544} | train loss {'Reaction outcome loss': 0.45999323223766525, 'Total loss': 0.45999323223766525}
2022-11-28 04:38:00,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:00,639 INFO:     Epoch: 93
2022-11-28 04:38:01,291 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4777886589819735, 'Total loss': 0.4777886589819735} | train loss {'Reaction outcome loss': 0.4629974453615756, 'Total loss': 0.4629974453615756}
2022-11-28 04:38:01,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:01,291 INFO:     Epoch: 94
2022-11-28 04:38:01,949 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49998826669021085, 'Total loss': 0.49998826669021085} | train loss {'Reaction outcome loss': 0.46196455342566917, 'Total loss': 0.46196455342566917}
2022-11-28 04:38:01,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:01,950 INFO:     Epoch: 95
2022-11-28 04:38:02,605 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5169526880437677, 'Total loss': 0.5169526880437677} | train loss {'Reaction outcome loss': 0.46721485745810304, 'Total loss': 0.46721485745810304}
2022-11-28 04:38:02,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:02,606 INFO:     Epoch: 96
2022-11-28 04:38:03,259 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4588160342113538, 'Total loss': 0.4588160342113538} | train loss {'Reaction outcome loss': 0.4706680013945228, 'Total loss': 0.4706680013945228}
2022-11-28 04:38:03,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:03,259 INFO:     Epoch: 97
2022-11-28 04:38:03,913 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45044973357157275, 'Total loss': 0.45044973357157275} | train loss {'Reaction outcome loss': 0.4614293367153237, 'Total loss': 0.4614293367153237}
2022-11-28 04:38:03,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:03,913 INFO:     Epoch: 98
2022-11-28 04:38:04,571 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5178240889852698, 'Total loss': 0.5178240889852698} | train loss {'Reaction outcome loss': 0.4739525055716395, 'Total loss': 0.4739525055716395}
2022-11-28 04:38:04,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:04,572 INFO:     Epoch: 99
2022-11-28 04:38:05,225 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47122302786870435, 'Total loss': 0.47122302786870435} | train loss {'Reaction outcome loss': 0.46652668750720466, 'Total loss': 0.46652668750720466}
2022-11-28 04:38:05,225 INFO:     Best model found after epoch 30 of 100.
2022-11-28 04:38:05,225 INFO:   Done with stage: TRAINING
2022-11-28 04:38:05,225 INFO:   Starting stage: EVALUATION
2022-11-28 04:38:05,344 INFO:   Done with stage: EVALUATION
2022-11-28 04:38:05,344 INFO:   Leaving out SEQ value Fold_5
2022-11-28 04:38:05,356 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:38:05,356 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:38:05,997 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:38:05,998 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:38:06,065 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:38:06,065 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:38:06,065 INFO:     No hyperparam tuning for this model
2022-11-28 04:38:06,065 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:38:06,065 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:38:06,066 INFO:     None feature selector for col prot
2022-11-28 04:38:06,066 INFO:     None feature selector for col prot
2022-11-28 04:38:06,066 INFO:     None feature selector for col prot
2022-11-28 04:38:06,067 INFO:     None feature selector for col chem
2022-11-28 04:38:06,067 INFO:     None feature selector for col chem
2022-11-28 04:38:06,067 INFO:     None feature selector for col chem
2022-11-28 04:38:06,067 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:38:06,067 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:38:06,068 INFO:     Number of params in model 169651
2022-11-28 04:38:06,071 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:38:06,071 INFO:   Starting stage: TRAINING
2022-11-28 04:38:06,122 INFO:     Val loss before train {'Reaction outcome loss': 1.0245427787303925, 'Total loss': 1.0245427787303925}
2022-11-28 04:38:06,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:06,122 INFO:     Epoch: 0
2022-11-28 04:38:06,783 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6655905544757843, 'Total loss': 0.6655905544757843} | train loss {'Reaction outcome loss': 0.691443636470478, 'Total loss': 0.691443636470478}
2022-11-28 04:38:06,784 INFO:     Found new best model at epoch 0
2022-11-28 04:38:06,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:06,784 INFO:     Epoch: 1
2022-11-28 04:38:07,444 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6466307308186184, 'Total loss': 0.6466307308186184} | train loss {'Reaction outcome loss': 0.5914736403386119, 'Total loss': 0.5914736403386119}
2022-11-28 04:38:07,444 INFO:     Found new best model at epoch 1
2022-11-28 04:38:07,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:07,445 INFO:     Epoch: 2
2022-11-28 04:38:08,104 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5861198407682505, 'Total loss': 0.5861198407682505} | train loss {'Reaction outcome loss': 0.5808978475298476, 'Total loss': 0.5808978475298476}
2022-11-28 04:38:08,104 INFO:     Found new best model at epoch 2
2022-11-28 04:38:08,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:08,105 INFO:     Epoch: 3
2022-11-28 04:38:08,767 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5777039971541275, 'Total loss': 0.5777039971541275} | train loss {'Reaction outcome loss': 0.5460812539344857, 'Total loss': 0.5460812539344857}
2022-11-28 04:38:08,767 INFO:     Found new best model at epoch 3
2022-11-28 04:38:08,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:08,768 INFO:     Epoch: 4
2022-11-28 04:38:09,425 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5471986637196757, 'Total loss': 0.5471986637196757} | train loss {'Reaction outcome loss': 0.53637417729073, 'Total loss': 0.53637417729073}
2022-11-28 04:38:09,425 INFO:     Found new best model at epoch 4
2022-11-28 04:38:09,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:09,426 INFO:     Epoch: 5
2022-11-28 04:38:10,082 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5375510840253397, 'Total loss': 0.5375510840253397} | train loss {'Reaction outcome loss': 0.5127884572454793, 'Total loss': 0.5127884572454793}
2022-11-28 04:38:10,083 INFO:     Found new best model at epoch 5
2022-11-28 04:38:10,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:10,083 INFO:     Epoch: 6
2022-11-28 04:38:10,741 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5323592058636926, 'Total loss': 0.5323592058636926} | train loss {'Reaction outcome loss': 0.5035431802514111, 'Total loss': 0.5035431802514111}
2022-11-28 04:38:10,741 INFO:     Found new best model at epoch 6
2022-11-28 04:38:10,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:10,742 INFO:     Epoch: 7
2022-11-28 04:38:11,399 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.532893331213431, 'Total loss': 0.532893331213431} | train loss {'Reaction outcome loss': 0.5044411710399365, 'Total loss': 0.5044411710399365}
2022-11-28 04:38:11,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:11,400 INFO:     Epoch: 8
2022-11-28 04:38:12,058 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5078755505383015, 'Total loss': 0.5078755505383015} | train loss {'Reaction outcome loss': 0.5140374787302635, 'Total loss': 0.5140374787302635}
2022-11-28 04:38:12,058 INFO:     Found new best model at epoch 8
2022-11-28 04:38:12,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:12,059 INFO:     Epoch: 9
2022-11-28 04:38:12,715 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5194091112776236, 'Total loss': 0.5194091112776236} | train loss {'Reaction outcome loss': 0.4982389150194914, 'Total loss': 0.4982389150194914}
2022-11-28 04:38:12,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:12,715 INFO:     Epoch: 10
2022-11-28 04:38:13,371 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5113275809721514, 'Total loss': 0.5113275809721514} | train loss {'Reaction outcome loss': 0.49310774817640485, 'Total loss': 0.49310774817640485}
2022-11-28 04:38:13,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:13,371 INFO:     Epoch: 11
2022-11-28 04:38:14,028 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5580463131720369, 'Total loss': 0.5580463131720369} | train loss {'Reaction outcome loss': 0.4913796526097093, 'Total loss': 0.4913796526097093}
2022-11-28 04:38:14,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:14,028 INFO:     Epoch: 12
2022-11-28 04:38:14,682 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5044517571275885, 'Total loss': 0.5044517571275885} | train loss {'Reaction outcome loss': 0.495632684846156, 'Total loss': 0.495632684846156}
2022-11-28 04:38:14,682 INFO:     Found new best model at epoch 12
2022-11-28 04:38:14,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:14,683 INFO:     Epoch: 13
2022-11-28 04:38:15,339 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5195856858044863, 'Total loss': 0.5195856858044863} | train loss {'Reaction outcome loss': 0.481389605142327, 'Total loss': 0.481389605142327}
2022-11-28 04:38:15,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:15,339 INFO:     Epoch: 14
2022-11-28 04:38:15,994 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5105208266865123, 'Total loss': 0.5105208266865123} | train loss {'Reaction outcome loss': 0.49569202995923184, 'Total loss': 0.49569202995923184}
2022-11-28 04:38:15,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:15,995 INFO:     Epoch: 15
2022-11-28 04:38:16,650 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48536444997245615, 'Total loss': 0.48536444997245615} | train loss {'Reaction outcome loss': 0.4757843707680612, 'Total loss': 0.4757843707680612}
2022-11-28 04:38:16,650 INFO:     Found new best model at epoch 15
2022-11-28 04:38:16,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:16,651 INFO:     Epoch: 16
2022-11-28 04:38:17,306 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5918585901910608, 'Total loss': 0.5918585901910608} | train loss {'Reaction outcome loss': 0.478973405503551, 'Total loss': 0.478973405503551}
2022-11-28 04:38:17,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:17,307 INFO:     Epoch: 17
2022-11-28 04:38:17,965 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5191037925806913, 'Total loss': 0.5191037925806913} | train loss {'Reaction outcome loss': 0.4871592366189398, 'Total loss': 0.4871592366189398}
2022-11-28 04:38:17,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:17,965 INFO:     Epoch: 18
2022-11-28 04:38:18,621 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4983245981010524, 'Total loss': 0.4983245981010524} | train loss {'Reaction outcome loss': 0.4706415590125057, 'Total loss': 0.4706415590125057}
2022-11-28 04:38:18,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:18,621 INFO:     Epoch: 19
2022-11-28 04:38:19,275 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5047568800774488, 'Total loss': 0.5047568800774488} | train loss {'Reaction outcome loss': 0.47652127385622095, 'Total loss': 0.47652127385622095}
2022-11-28 04:38:19,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:19,276 INFO:     Epoch: 20
2022-11-28 04:38:19,933 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48391941155899654, 'Total loss': 0.48391941155899654} | train loss {'Reaction outcome loss': 0.47463242745562834, 'Total loss': 0.47463242745562834}
2022-11-28 04:38:19,933 INFO:     Found new best model at epoch 20
2022-11-28 04:38:19,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:19,934 INFO:     Epoch: 21
2022-11-28 04:38:20,592 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5062383497980508, 'Total loss': 0.5062383497980508} | train loss {'Reaction outcome loss': 0.4786414485952632, 'Total loss': 0.4786414485952632}
2022-11-28 04:38:20,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:20,592 INFO:     Epoch: 22
2022-11-28 04:38:21,248 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47667484324086795, 'Total loss': 0.47667484324086795} | train loss {'Reaction outcome loss': 0.47875952179193015, 'Total loss': 0.47875952179193015}
2022-11-28 04:38:21,248 INFO:     Found new best model at epoch 22
2022-11-28 04:38:21,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:21,248 INFO:     Epoch: 23
2022-11-28 04:38:21,910 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5175078863447363, 'Total loss': 0.5175078863447363} | train loss {'Reaction outcome loss': 0.46800408177530234, 'Total loss': 0.46800408177530234}
2022-11-28 04:38:21,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:21,911 INFO:     Epoch: 24
2022-11-28 04:38:22,572 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5342218388210643, 'Total loss': 0.5342218388210643} | train loss {'Reaction outcome loss': 0.474055251430886, 'Total loss': 0.474055251430886}
2022-11-28 04:38:22,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:22,572 INFO:     Epoch: 25
2022-11-28 04:38:23,232 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5503390119834379, 'Total loss': 0.5503390119834379} | train loss {'Reaction outcome loss': 0.46527098963105, 'Total loss': 0.46527098963105}
2022-11-28 04:38:23,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:23,233 INFO:     Epoch: 26
2022-11-28 04:38:23,891 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.532294652340087, 'Total loss': 0.532294652340087} | train loss {'Reaction outcome loss': 0.47070869640541463, 'Total loss': 0.47070869640541463}
2022-11-28 04:38:23,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:23,891 INFO:     Epoch: 27
2022-11-28 04:38:24,549 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5066627206450159, 'Total loss': 0.5066627206450159} | train loss {'Reaction outcome loss': 0.4753093753869717, 'Total loss': 0.4753093753869717}
2022-11-28 04:38:24,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:24,549 INFO:     Epoch: 28
2022-11-28 04:38:25,205 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48870161785320804, 'Total loss': 0.48870161785320804} | train loss {'Reaction outcome loss': 0.47758741335950883, 'Total loss': 0.47758741335950883}
2022-11-28 04:38:25,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:25,205 INFO:     Epoch: 29
2022-11-28 04:38:25,864 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5351924789561466, 'Total loss': 0.5351924789561466} | train loss {'Reaction outcome loss': 0.47156964978467114, 'Total loss': 0.47156964978467114}
2022-11-28 04:38:25,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:25,864 INFO:     Epoch: 30
2022-11-28 04:38:26,519 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5222753804515708, 'Total loss': 0.5222753804515708} | train loss {'Reaction outcome loss': 0.46657035623484777, 'Total loss': 0.46657035623484777}
2022-11-28 04:38:26,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:26,519 INFO:     Epoch: 31
2022-11-28 04:38:27,179 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48847747627984395, 'Total loss': 0.48847747627984395} | train loss {'Reaction outcome loss': 0.4783389862732366, 'Total loss': 0.4783389862732366}
2022-11-28 04:38:27,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:27,179 INFO:     Epoch: 32
2022-11-28 04:38:27,837 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5200423191894185, 'Total loss': 0.5200423191894185} | train loss {'Reaction outcome loss': 0.48270086865676076, 'Total loss': 0.48270086865676076}
2022-11-28 04:38:27,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:27,837 INFO:     Epoch: 33
2022-11-28 04:38:28,498 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49640713361176575, 'Total loss': 0.49640713361176575} | train loss {'Reaction outcome loss': 0.4826650728098294, 'Total loss': 0.4826650728098294}
2022-11-28 04:38:28,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:28,498 INFO:     Epoch: 34
2022-11-28 04:38:29,159 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49886633963747457, 'Total loss': 0.49886633963747457} | train loss {'Reaction outcome loss': 0.4759282701411228, 'Total loss': 0.4759282701411228}
2022-11-28 04:38:29,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:29,160 INFO:     Epoch: 35
2022-11-28 04:38:29,818 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5086069134148684, 'Total loss': 0.5086069134148684} | train loss {'Reaction outcome loss': 0.47393410480939424, 'Total loss': 0.47393410480939424}
2022-11-28 04:38:29,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:29,819 INFO:     Epoch: 36
2022-11-28 04:38:30,476 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4929098923775283, 'Total loss': 0.4929098923775283} | train loss {'Reaction outcome loss': 0.4778744489678487, 'Total loss': 0.4778744489678487}
2022-11-28 04:38:30,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:30,476 INFO:     Epoch: 37
2022-11-28 04:38:31,135 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5147893882610581, 'Total loss': 0.5147893882610581} | train loss {'Reaction outcome loss': 0.47111578629567075, 'Total loss': 0.47111578629567075}
2022-11-28 04:38:31,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:31,135 INFO:     Epoch: 38
2022-11-28 04:38:31,798 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47945489090952004, 'Total loss': 0.47945489090952004} | train loss {'Reaction outcome loss': 0.4644091912594281, 'Total loss': 0.4644091912594281}
2022-11-28 04:38:31,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:31,798 INFO:     Epoch: 39
2022-11-28 04:38:32,459 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48140205239707773, 'Total loss': 0.48140205239707773} | train loss {'Reaction outcome loss': 0.4620568833129126, 'Total loss': 0.4620568833129126}
2022-11-28 04:38:32,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:32,459 INFO:     Epoch: 40
2022-11-28 04:38:33,120 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4960691078820012, 'Total loss': 0.4960691078820012} | train loss {'Reaction outcome loss': 0.4765759297469367, 'Total loss': 0.4765759297469367}
2022-11-28 04:38:33,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:33,121 INFO:     Epoch: 41
2022-11-28 04:38:33,781 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.517364002764225, 'Total loss': 0.517364002764225} | train loss {'Reaction outcome loss': 0.4793370031763004, 'Total loss': 0.4793370031763004}
2022-11-28 04:38:33,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:33,782 INFO:     Epoch: 42
2022-11-28 04:38:34,442 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5166404917836189, 'Total loss': 0.5166404917836189} | train loss {'Reaction outcome loss': 0.46869925325095413, 'Total loss': 0.46869925325095413}
2022-11-28 04:38:34,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:34,443 INFO:     Epoch: 43
2022-11-28 04:38:35,102 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48228592019189487, 'Total loss': 0.48228592019189487} | train loss {'Reaction outcome loss': 0.47310735442136465, 'Total loss': 0.47310735442136465}
2022-11-28 04:38:35,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:35,102 INFO:     Epoch: 44
2022-11-28 04:38:35,762 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5108236585828391, 'Total loss': 0.5108236585828391} | train loss {'Reaction outcome loss': 0.48232197459892706, 'Total loss': 0.48232197459892706}
2022-11-28 04:38:35,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:35,762 INFO:     Epoch: 45
2022-11-28 04:38:36,425 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5005328572270545, 'Total loss': 0.5005328572270545} | train loss {'Reaction outcome loss': 0.47153393646724795, 'Total loss': 0.47153393646724795}
2022-11-28 04:38:36,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:36,425 INFO:     Epoch: 46
2022-11-28 04:38:37,087 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4794046055864204, 'Total loss': 0.4794046055864204} | train loss {'Reaction outcome loss': 0.46883614463844764, 'Total loss': 0.46883614463844764}
2022-11-28 04:38:37,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:37,087 INFO:     Epoch: 47
2022-11-28 04:38:37,747 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4941084391691468, 'Total loss': 0.4941084391691468} | train loss {'Reaction outcome loss': 0.4712671286121071, 'Total loss': 0.4712671286121071}
2022-11-28 04:38:37,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:37,747 INFO:     Epoch: 48
2022-11-28 04:38:38,410 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.514618959616531, 'Total loss': 0.514618959616531} | train loss {'Reaction outcome loss': 0.46814494331929124, 'Total loss': 0.46814494331929124}
2022-11-28 04:38:38,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:38,410 INFO:     Epoch: 49
2022-11-28 04:38:39,075 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5025977383960377, 'Total loss': 0.5025977383960377} | train loss {'Reaction outcome loss': 0.4679343698900721, 'Total loss': 0.4679343698900721}
2022-11-28 04:38:39,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:39,076 INFO:     Epoch: 50
2022-11-28 04:38:39,738 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5158061405474489, 'Total loss': 0.5158061405474489} | train loss {'Reaction outcome loss': 0.4724618841701674, 'Total loss': 0.4724618841701674}
2022-11-28 04:38:39,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:39,738 INFO:     Epoch: 51
2022-11-28 04:38:40,401 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46790279989892786, 'Total loss': 0.46790279989892786} | train loss {'Reaction outcome loss': 0.4761296115553587, 'Total loss': 0.4761296115553587}
2022-11-28 04:38:40,401 INFO:     Found new best model at epoch 51
2022-11-28 04:38:40,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:40,402 INFO:     Epoch: 52
2022-11-28 04:38:41,061 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.494051359932531, 'Total loss': 0.494051359932531} | train loss {'Reaction outcome loss': 0.4782536637324553, 'Total loss': 0.4782536637324553}
2022-11-28 04:38:41,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:41,061 INFO:     Epoch: 53
2022-11-28 04:38:41,719 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48334386030381377, 'Total loss': 0.48334386030381377} | train loss {'Reaction outcome loss': 0.47552672517203126, 'Total loss': 0.47552672517203126}
2022-11-28 04:38:41,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:41,719 INFO:     Epoch: 54
2022-11-28 04:38:42,381 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5133782567625697, 'Total loss': 0.5133782567625697} | train loss {'Reaction outcome loss': 0.4676407719038517, 'Total loss': 0.4676407719038517}
2022-11-28 04:38:42,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:42,382 INFO:     Epoch: 55
2022-11-28 04:38:43,044 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4942416311665015, 'Total loss': 0.4942416311665015} | train loss {'Reaction outcome loss': 0.4668087333380452, 'Total loss': 0.4668087333380452}
2022-11-28 04:38:43,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:43,044 INFO:     Epoch: 56
2022-11-28 04:38:43,707 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5032949887893416, 'Total loss': 0.5032949887893416} | train loss {'Reaction outcome loss': 0.46498661624033927, 'Total loss': 0.46498661624033927}
2022-11-28 04:38:43,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:43,707 INFO:     Epoch: 57
2022-11-28 04:38:44,366 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5151504373008554, 'Total loss': 0.5151504373008554} | train loss {'Reaction outcome loss': 0.4833951973722049, 'Total loss': 0.4833951973722049}
2022-11-28 04:38:44,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:44,366 INFO:     Epoch: 58
2022-11-28 04:38:45,024 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5054505094885826, 'Total loss': 0.5054505094885826} | train loss {'Reaction outcome loss': 0.4750350234117585, 'Total loss': 0.4750350234117585}
2022-11-28 04:38:45,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:45,024 INFO:     Epoch: 59
2022-11-28 04:38:45,682 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.530680197883736, 'Total loss': 0.530680197883736} | train loss {'Reaction outcome loss': 0.47964291099594675, 'Total loss': 0.47964291099594675}
2022-11-28 04:38:45,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:45,682 INFO:     Epoch: 60
2022-11-28 04:38:46,336 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48623310977762396, 'Total loss': 0.48623310977762396} | train loss {'Reaction outcome loss': 0.4748814914993912, 'Total loss': 0.4748814914993912}
2022-11-28 04:38:46,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:46,336 INFO:     Epoch: 61
2022-11-28 04:38:46,996 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49913907186551526, 'Total loss': 0.49913907186551526} | train loss {'Reaction outcome loss': 0.47178156582661246, 'Total loss': 0.47178156582661246}
2022-11-28 04:38:46,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:46,996 INFO:     Epoch: 62
2022-11-28 04:38:47,657 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5203324837440794, 'Total loss': 0.5203324837440794} | train loss {'Reaction outcome loss': 0.4703522454419358, 'Total loss': 0.4703522454419358}
2022-11-28 04:38:47,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:47,657 INFO:     Epoch: 63
2022-11-28 04:38:48,314 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4853571883656762, 'Total loss': 0.4853571883656762} | train loss {'Reaction outcome loss': 0.4697741781802554, 'Total loss': 0.4697741781802554}
2022-11-28 04:38:48,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:48,315 INFO:     Epoch: 64
2022-11-28 04:38:48,971 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5120141262357886, 'Total loss': 0.5120141262357886} | train loss {'Reaction outcome loss': 0.4715719139165724, 'Total loss': 0.4715719139165724}
2022-11-28 04:38:48,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:48,972 INFO:     Epoch: 65
2022-11-28 04:38:49,631 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.6009821248325434, 'Total loss': 0.6009821248325434} | train loss {'Reaction outcome loss': 0.47166317797865465, 'Total loss': 0.47166317797865465}
2022-11-28 04:38:49,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:49,631 INFO:     Epoch: 66
2022-11-28 04:38:50,286 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.567014024338939, 'Total loss': 0.567014024338939} | train loss {'Reaction outcome loss': 0.46904760381953436, 'Total loss': 0.46904760381953436}
2022-11-28 04:38:50,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:50,287 INFO:     Epoch: 67
2022-11-28 04:38:50,942 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.502073908732696, 'Total loss': 0.502073908732696} | train loss {'Reaction outcome loss': 0.4818583075937472, 'Total loss': 0.4818583075937472}
2022-11-28 04:38:50,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:50,943 INFO:     Epoch: 68
2022-11-28 04:38:51,602 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4942260858687488, 'Total loss': 0.4942260858687488} | train loss {'Reaction outcome loss': 0.4812186855656898, 'Total loss': 0.4812186855656898}
2022-11-28 04:38:51,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:51,602 INFO:     Epoch: 69
2022-11-28 04:38:52,260 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48138015006076207, 'Total loss': 0.48138015006076207} | train loss {'Reaction outcome loss': 0.4800142341176508, 'Total loss': 0.4800142341176508}
2022-11-28 04:38:52,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:52,260 INFO:     Epoch: 70
2022-11-28 04:38:52,921 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4966561072929339, 'Total loss': 0.4966561072929339} | train loss {'Reaction outcome loss': 0.47750981767409245, 'Total loss': 0.47750981767409245}
2022-11-28 04:38:52,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:52,922 INFO:     Epoch: 71
2022-11-28 04:38:53,585 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5050289508971301, 'Total loss': 0.5050289508971301} | train loss {'Reaction outcome loss': 0.4707964829994961, 'Total loss': 0.4707964829994961}
2022-11-28 04:38:53,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:53,585 INFO:     Epoch: 72
2022-11-28 04:38:54,242 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5016302882947705, 'Total loss': 0.5016302882947705} | train loss {'Reaction outcome loss': 0.4708451821246309, 'Total loss': 0.4708451821246309}
2022-11-28 04:38:54,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:54,242 INFO:     Epoch: 73
2022-11-28 04:38:54,897 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.510469874875112, 'Total loss': 0.510469874875112} | train loss {'Reaction outcome loss': 0.47181808321099533, 'Total loss': 0.47181808321099533}
2022-11-28 04:38:54,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:54,898 INFO:     Epoch: 74
2022-11-28 04:38:55,558 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5034829456020485, 'Total loss': 0.5034829456020485} | train loss {'Reaction outcome loss': 0.47688830695171586, 'Total loss': 0.47688830695171586}
2022-11-28 04:38:55,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:55,559 INFO:     Epoch: 75
2022-11-28 04:38:56,216 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5057264420796524, 'Total loss': 0.5057264420796524} | train loss {'Reaction outcome loss': 0.4753265488545904, 'Total loss': 0.4753265488545904}
2022-11-28 04:38:56,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:56,216 INFO:     Epoch: 76
2022-11-28 04:38:56,877 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49680754948746075, 'Total loss': 0.49680754948746075} | train loss {'Reaction outcome loss': 0.4806968400232222, 'Total loss': 0.4806968400232222}
2022-11-28 04:38:56,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:56,877 INFO:     Epoch: 77
2022-11-28 04:38:57,530 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49906889179890807, 'Total loss': 0.49906889179890807} | train loss {'Reaction outcome loss': 0.48238433131322206, 'Total loss': 0.48238433131322206}
2022-11-28 04:38:57,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:57,530 INFO:     Epoch: 78
2022-11-28 04:38:58,187 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.490756920454177, 'Total loss': 0.490756920454177} | train loss {'Reaction outcome loss': 0.47526889234057323, 'Total loss': 0.47526889234057323}
2022-11-28 04:38:58,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:58,187 INFO:     Epoch: 79
2022-11-28 04:38:58,846 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4963029721243815, 'Total loss': 0.4963029721243815} | train loss {'Reaction outcome loss': 0.4705598486459207, 'Total loss': 0.4705598486459207}
2022-11-28 04:38:58,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:58,846 INFO:     Epoch: 80
2022-11-28 04:38:59,504 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4972587955946272, 'Total loss': 0.4972587955946272} | train loss {'Reaction outcome loss': 0.47960693271536575, 'Total loss': 0.47960693271536575}
2022-11-28 04:38:59,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:38:59,504 INFO:     Epoch: 81
2022-11-28 04:39:00,163 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4924157617444342, 'Total loss': 0.4924157617444342} | train loss {'Reaction outcome loss': 0.47208584259878766, 'Total loss': 0.47208584259878766}
2022-11-28 04:39:00,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:00,163 INFO:     Epoch: 82
2022-11-28 04:39:00,822 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.518364084715193, 'Total loss': 0.518364084715193} | train loss {'Reaction outcome loss': 0.4674737197365838, 'Total loss': 0.4674737197365838}
2022-11-28 04:39:00,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:00,822 INFO:     Epoch: 83
2022-11-28 04:39:01,480 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5271708565679464, 'Total loss': 0.5271708565679464} | train loss {'Reaction outcome loss': 0.47125708872852057, 'Total loss': 0.47125708872852057}
2022-11-28 04:39:01,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:01,481 INFO:     Epoch: 84
2022-11-28 04:39:02,143 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4830691350454634, 'Total loss': 0.4830691350454634} | train loss {'Reaction outcome loss': 0.47558323526189394, 'Total loss': 0.47558323526189394}
2022-11-28 04:39:02,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:02,143 INFO:     Epoch: 85
2022-11-28 04:39:02,800 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5137216787446629, 'Total loss': 0.5137216787446629} | train loss {'Reaction outcome loss': 0.4733455651081525, 'Total loss': 0.4733455651081525}
2022-11-28 04:39:02,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:02,800 INFO:     Epoch: 86
2022-11-28 04:39:03,461 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5194174901328303, 'Total loss': 0.5194174901328303} | train loss {'Reaction outcome loss': 0.4779105391579601, 'Total loss': 0.4779105391579601}
2022-11-28 04:39:03,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:03,461 INFO:     Epoch: 87
2022-11-28 04:39:04,118 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4902269897813147, 'Total loss': 0.4902269897813147} | train loss {'Reaction outcome loss': 0.4734768887928985, 'Total loss': 0.4734768887928985}
2022-11-28 04:39:04,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:04,118 INFO:     Epoch: 88
2022-11-28 04:39:04,774 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4769603047858585, 'Total loss': 0.4769603047858585} | train loss {'Reaction outcome loss': 0.4748397171195702, 'Total loss': 0.4748397171195702}
2022-11-28 04:39:04,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:04,775 INFO:     Epoch: 89
2022-11-28 04:39:05,432 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5141978175802664, 'Total loss': 0.5141978175802664} | train loss {'Reaction outcome loss': 0.4726830711248915, 'Total loss': 0.4726830711248915}
2022-11-28 04:39:05,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:05,432 INFO:     Epoch: 90
2022-11-28 04:39:06,086 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4942719248885458, 'Total loss': 0.4942719248885458} | train loss {'Reaction outcome loss': 0.47519263299370584, 'Total loss': 0.47519263299370584}
2022-11-28 04:39:06,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:06,086 INFO:     Epoch: 91
2022-11-28 04:39:06,747 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47457467900081113, 'Total loss': 0.47457467900081113} | train loss {'Reaction outcome loss': 0.47476736281579923, 'Total loss': 0.47476736281579923}
2022-11-28 04:39:06,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:06,747 INFO:     Epoch: 92
2022-11-28 04:39:07,406 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49415022575042467, 'Total loss': 0.49415022575042467} | train loss {'Reaction outcome loss': 0.4815916264588051, 'Total loss': 0.4815916264588051}
2022-11-28 04:39:07,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:07,406 INFO:     Epoch: 93
2022-11-28 04:39:08,072 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5292377803813327, 'Total loss': 0.5292377803813327} | train loss {'Reaction outcome loss': 0.5130344731243033, 'Total loss': 0.5130344731243033}
2022-11-28 04:39:08,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:08,072 INFO:     Epoch: 94
2022-11-28 04:39:08,739 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48643625663085416, 'Total loss': 0.48643625663085416} | train loss {'Reaction outcome loss': 0.48590318309633357, 'Total loss': 0.48590318309633357}
2022-11-28 04:39:08,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:08,739 INFO:     Epoch: 95
2022-11-28 04:39:09,403 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4869499846615575, 'Total loss': 0.4869499846615575} | train loss {'Reaction outcome loss': 0.47263875989778803, 'Total loss': 0.47263875989778803}
2022-11-28 04:39:09,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:09,403 INFO:     Epoch: 96
2022-11-28 04:39:10,065 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.519034013829448, 'Total loss': 0.519034013829448} | train loss {'Reaction outcome loss': 0.4775282659149363, 'Total loss': 0.4775282659149363}
2022-11-28 04:39:10,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:10,065 INFO:     Epoch: 97
2022-11-28 04:39:10,728 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5147894698787819, 'Total loss': 0.5147894698787819} | train loss {'Reaction outcome loss': 0.4842130998488863, 'Total loss': 0.4842130998488863}
2022-11-28 04:39:10,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:10,728 INFO:     Epoch: 98
2022-11-28 04:39:11,392 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48435506935824046, 'Total loss': 0.48435506935824046} | train loss {'Reaction outcome loss': 0.4759161430693831, 'Total loss': 0.4759161430693831}
2022-11-28 04:39:11,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:11,393 INFO:     Epoch: 99
2022-11-28 04:39:12,054 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5044535364617001, 'Total loss': 0.5044535364617001} | train loss {'Reaction outcome loss': 0.48159639428742984, 'Total loss': 0.48159639428742984}
2022-11-28 04:39:12,054 INFO:     Best model found after epoch 52 of 100.
2022-11-28 04:39:12,055 INFO:   Done with stage: TRAINING
2022-11-28 04:39:12,055 INFO:   Starting stage: EVALUATION
2022-11-28 04:39:12,174 INFO:   Done with stage: EVALUATION
2022-11-28 04:39:12,174 INFO:   Leaving out SEQ value Fold_6
2022-11-28 04:39:12,186 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:39:12,187 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:39:12,835 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:39:12,835 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:39:12,903 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:39:12,903 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:39:12,903 INFO:     No hyperparam tuning for this model
2022-11-28 04:39:12,903 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:39:12,903 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:39:12,904 INFO:     None feature selector for col prot
2022-11-28 04:39:12,904 INFO:     None feature selector for col prot
2022-11-28 04:39:12,904 INFO:     None feature selector for col prot
2022-11-28 04:39:12,905 INFO:     None feature selector for col chem
2022-11-28 04:39:12,905 INFO:     None feature selector for col chem
2022-11-28 04:39:12,905 INFO:     None feature selector for col chem
2022-11-28 04:39:12,905 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:39:12,905 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:39:12,906 INFO:     Number of params in model 169651
2022-11-28 04:39:12,909 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:39:12,909 INFO:   Starting stage: TRAINING
2022-11-28 04:39:12,960 INFO:     Val loss before train {'Reaction outcome loss': 1.0402493165297941, 'Total loss': 1.0402493165297941}
2022-11-28 04:39:12,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:12,961 INFO:     Epoch: 0
2022-11-28 04:39:13,620 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6451269787820902, 'Total loss': 0.6451269787820902} | train loss {'Reaction outcome loss': 0.6879201892175173, 'Total loss': 0.6879201892175173}
2022-11-28 04:39:13,620 INFO:     Found new best model at epoch 0
2022-11-28 04:39:13,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:13,621 INFO:     Epoch: 1
2022-11-28 04:39:14,282 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5642701404338534, 'Total loss': 0.5642701404338534} | train loss {'Reaction outcome loss': 0.5957906194906003, 'Total loss': 0.5957906194906003}
2022-11-28 04:39:14,282 INFO:     Found new best model at epoch 1
2022-11-28 04:39:14,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:14,283 INFO:     Epoch: 2
2022-11-28 04:39:14,945 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6079517521641471, 'Total loss': 0.6079517521641471} | train loss {'Reaction outcome loss': 0.5588522777244117, 'Total loss': 0.5588522777244117}
2022-11-28 04:39:14,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:14,945 INFO:     Epoch: 3
2022-11-28 04:39:15,606 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5522657903757963, 'Total loss': 0.5522657903757963} | train loss {'Reaction outcome loss': 0.5322950525805052, 'Total loss': 0.5322950525805052}
2022-11-28 04:39:15,606 INFO:     Found new best model at epoch 3
2022-11-28 04:39:15,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:15,607 INFO:     Epoch: 4
2022-11-28 04:39:16,269 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5806678824804046, 'Total loss': 0.5806678824804046} | train loss {'Reaction outcome loss': 0.5272630460952458, 'Total loss': 0.5272630460952458}
2022-11-28 04:39:16,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:16,269 INFO:     Epoch: 5
2022-11-28 04:39:16,934 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5471127338030122, 'Total loss': 0.5471127338030122} | train loss {'Reaction outcome loss': 0.5041145883342214, 'Total loss': 0.5041145883342214}
2022-11-28 04:39:16,934 INFO:     Found new best model at epoch 5
2022-11-28 04:39:16,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:16,935 INFO:     Epoch: 6
2022-11-28 04:39:17,596 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5381256321614439, 'Total loss': 0.5381256321614439} | train loss {'Reaction outcome loss': 0.49993877227489764, 'Total loss': 0.49993877227489764}
2022-11-28 04:39:17,596 INFO:     Found new best model at epoch 6
2022-11-28 04:39:17,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:17,596 INFO:     Epoch: 7
2022-11-28 04:39:18,260 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5410336615009741, 'Total loss': 0.5410336615009741} | train loss {'Reaction outcome loss': 0.5146713854088957, 'Total loss': 0.5146713854088957}
2022-11-28 04:39:18,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:18,260 INFO:     Epoch: 8
2022-11-28 04:39:18,923 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5015215606174686, 'Total loss': 0.5015215606174686} | train loss {'Reaction outcome loss': 0.5053007622901727, 'Total loss': 0.5053007622901727}
2022-11-28 04:39:18,923 INFO:     Found new best model at epoch 8
2022-11-28 04:39:18,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:18,924 INFO:     Epoch: 9
2022-11-28 04:39:19,588 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5234815268353983, 'Total loss': 0.5234815268353983} | train loss {'Reaction outcome loss': 0.48734142629407073, 'Total loss': 0.48734142629407073}
2022-11-28 04:39:19,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:19,588 INFO:     Epoch: 10
2022-11-28 04:39:20,252 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5684301307932897, 'Total loss': 0.5684301307932897} | train loss {'Reaction outcome loss': 0.49578797503521566, 'Total loss': 0.49578797503521566}
2022-11-28 04:39:20,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:20,252 INFO:     Epoch: 11
2022-11-28 04:39:20,915 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49861218881877983, 'Total loss': 0.49861218881877983} | train loss {'Reaction outcome loss': 0.49485402864965833, 'Total loss': 0.49485402864965833}
2022-11-28 04:39:20,915 INFO:     Found new best model at epoch 11
2022-11-28 04:39:20,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:20,916 INFO:     Epoch: 12
2022-11-28 04:39:21,579 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5057418011128902, 'Total loss': 0.5057418011128902} | train loss {'Reaction outcome loss': 0.47198020310899025, 'Total loss': 0.47198020310899025}
2022-11-28 04:39:21,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:21,579 INFO:     Epoch: 13
2022-11-28 04:39:22,241 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5537853620269082, 'Total loss': 0.5537853620269082} | train loss {'Reaction outcome loss': 0.475078367409466, 'Total loss': 0.475078367409466}
2022-11-28 04:39:22,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:22,242 INFO:     Epoch: 14
2022-11-28 04:39:22,901 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5451094223694368, 'Total loss': 0.5451094223694368} | train loss {'Reaction outcome loss': 0.46882477034682685, 'Total loss': 0.46882477034682685}
2022-11-28 04:39:22,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:22,902 INFO:     Epoch: 15
2022-11-28 04:39:23,562 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49298662556843326, 'Total loss': 0.49298662556843326} | train loss {'Reaction outcome loss': 0.47233214461610384, 'Total loss': 0.47233214461610384}
2022-11-28 04:39:23,562 INFO:     Found new best model at epoch 15
2022-11-28 04:39:23,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:23,563 INFO:     Epoch: 16
2022-11-28 04:39:24,222 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5458927784453739, 'Total loss': 0.5458927784453739} | train loss {'Reaction outcome loss': 0.4699132634884855, 'Total loss': 0.4699132634884855}
2022-11-28 04:39:24,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:24,222 INFO:     Epoch: 17
2022-11-28 04:39:24,882 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4990214522589337, 'Total loss': 0.4990214522589337} | train loss {'Reaction outcome loss': 0.47422802357779825, 'Total loss': 0.47422802357779825}
2022-11-28 04:39:24,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:24,882 INFO:     Epoch: 18
2022-11-28 04:39:25,545 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5547305460680615, 'Total loss': 0.5547305460680615} | train loss {'Reaction outcome loss': 0.4785842306097509, 'Total loss': 0.4785842306097509}
2022-11-28 04:39:25,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:25,547 INFO:     Epoch: 19
2022-11-28 04:39:26,206 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48913767662915314, 'Total loss': 0.48913767662915314} | train loss {'Reaction outcome loss': 0.4677521424285072, 'Total loss': 0.4677521424285072}
2022-11-28 04:39:26,206 INFO:     Found new best model at epoch 19
2022-11-28 04:39:26,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:26,207 INFO:     Epoch: 20
2022-11-28 04:39:26,868 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4922313771464608, 'Total loss': 0.4922313771464608} | train loss {'Reaction outcome loss': 0.468070544046067, 'Total loss': 0.468070544046067}
2022-11-28 04:39:26,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:26,869 INFO:     Epoch: 21
2022-11-28 04:39:27,530 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.521024963395162, 'Total loss': 0.521024963395162} | train loss {'Reaction outcome loss': 0.45164426138647173, 'Total loss': 0.45164426138647173}
2022-11-28 04:39:27,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:27,530 INFO:     Epoch: 22
2022-11-28 04:39:28,193 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.532664823599837, 'Total loss': 0.532664823599837} | train loss {'Reaction outcome loss': 0.47548699517723036, 'Total loss': 0.47548699517723036}
2022-11-28 04:39:28,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:28,193 INFO:     Epoch: 23
2022-11-28 04:39:28,852 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49119342965158547, 'Total loss': 0.49119342965158547} | train loss {'Reaction outcome loss': 0.4711094638295019, 'Total loss': 0.4711094638295019}
2022-11-28 04:39:28,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:28,853 INFO:     Epoch: 24
2022-11-28 04:39:29,514 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5168508318337527, 'Total loss': 0.5168508318337527} | train loss {'Reaction outcome loss': 0.47098188934779844, 'Total loss': 0.47098188934779844}
2022-11-28 04:39:29,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:29,514 INFO:     Epoch: 25
2022-11-28 04:39:30,176 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46912136910991237, 'Total loss': 0.46912136910991237} | train loss {'Reaction outcome loss': 0.47442785937052506, 'Total loss': 0.47442785937052506}
2022-11-28 04:39:30,176 INFO:     Found new best model at epoch 25
2022-11-28 04:39:30,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:30,177 INFO:     Epoch: 26
2022-11-28 04:39:30,837 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5199299576607618, 'Total loss': 0.5199299576607618} | train loss {'Reaction outcome loss': 0.45765163623379085, 'Total loss': 0.45765163623379085}
2022-11-28 04:39:30,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:30,837 INFO:     Epoch: 27
2022-11-28 04:39:31,496 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5740993022918701, 'Total loss': 0.5740993022918701} | train loss {'Reaction outcome loss': 0.45281006775886906, 'Total loss': 0.45281006775886906}
2022-11-28 04:39:31,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:31,496 INFO:     Epoch: 28
2022-11-28 04:39:32,156 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4786634157327088, 'Total loss': 0.4786634157327088} | train loss {'Reaction outcome loss': 0.4740862854820514, 'Total loss': 0.4740862854820514}
2022-11-28 04:39:32,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:32,157 INFO:     Epoch: 29
2022-11-28 04:39:32,818 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4939502382820303, 'Total loss': 0.4939502382820303} | train loss {'Reaction outcome loss': 0.4619241197619904, 'Total loss': 0.4619241197619904}
2022-11-28 04:39:32,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:32,818 INFO:     Epoch: 30
2022-11-28 04:39:33,478 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5116810124706138, 'Total loss': 0.5116810124706138} | train loss {'Reaction outcome loss': 0.46257117806899883, 'Total loss': 0.46257117806899883}
2022-11-28 04:39:33,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:33,478 INFO:     Epoch: 31
2022-11-28 04:39:34,137 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4873611425811594, 'Total loss': 0.4873611425811594} | train loss {'Reaction outcome loss': 0.46813329553555866, 'Total loss': 0.46813329553555866}
2022-11-28 04:39:34,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:34,137 INFO:     Epoch: 32
2022-11-28 04:39:34,800 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47482886436310684, 'Total loss': 0.47482886436310684} | train loss {'Reaction outcome loss': 0.4610934015288044, 'Total loss': 0.4610934015288044}
2022-11-28 04:39:34,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:34,800 INFO:     Epoch: 33
2022-11-28 04:39:35,459 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4726751870052381, 'Total loss': 0.4726751870052381} | train loss {'Reaction outcome loss': 0.46013411773964463, 'Total loss': 0.46013411773964463}
2022-11-28 04:39:35,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:35,459 INFO:     Epoch: 34
2022-11-28 04:39:36,118 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5143953505903482, 'Total loss': 0.5143953505903482} | train loss {'Reaction outcome loss': 0.46381362373770973, 'Total loss': 0.46381362373770973}
2022-11-28 04:39:36,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:36,118 INFO:     Epoch: 35
2022-11-28 04:39:36,781 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4837584305893291, 'Total loss': 0.4837584305893291} | train loss {'Reaction outcome loss': 0.4605982515372728, 'Total loss': 0.4605982515372728}
2022-11-28 04:39:36,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:36,781 INFO:     Epoch: 36
2022-11-28 04:39:37,444 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.52531753920696, 'Total loss': 0.52531753920696} | train loss {'Reaction outcome loss': 0.45348027872622976, 'Total loss': 0.45348027872622976}
2022-11-28 04:39:37,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:37,444 INFO:     Epoch: 37
2022-11-28 04:39:38,108 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49852504107085144, 'Total loss': 0.49852504107085144} | train loss {'Reaction outcome loss': 0.45920368630876424, 'Total loss': 0.45920368630876424}
2022-11-28 04:39:38,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:38,108 INFO:     Epoch: 38
2022-11-28 04:39:38,771 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4695912880653685, 'Total loss': 0.4695912880653685} | train loss {'Reaction outcome loss': 0.4615429396692075, 'Total loss': 0.4615429396692075}
2022-11-28 04:39:38,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:38,772 INFO:     Epoch: 39
2022-11-28 04:39:39,433 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5084020844237371, 'Total loss': 0.5084020844237371} | train loss {'Reaction outcome loss': 0.46667140402533264, 'Total loss': 0.46667140402533264}
2022-11-28 04:39:39,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:39,433 INFO:     Epoch: 40
2022-11-28 04:39:40,094 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5022076869552786, 'Total loss': 0.5022076869552786} | train loss {'Reaction outcome loss': 0.46686693694186115, 'Total loss': 0.46686693694186115}
2022-11-28 04:39:40,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:40,095 INFO:     Epoch: 41
2022-11-28 04:39:40,756 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5754133720289577, 'Total loss': 0.5754133720289577} | train loss {'Reaction outcome loss': 0.48804006082437523, 'Total loss': 0.48804006082437523}
2022-11-28 04:39:40,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:40,756 INFO:     Epoch: 42
2022-11-28 04:39:41,416 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5343744792044163, 'Total loss': 0.5343744792044163} | train loss {'Reaction outcome loss': 0.4694935547919408, 'Total loss': 0.4694935547919408}
2022-11-28 04:39:41,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:41,416 INFO:     Epoch: 43
2022-11-28 04:39:42,076 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5302973464131355, 'Total loss': 0.5302973464131355} | train loss {'Reaction outcome loss': 0.46709742731893594, 'Total loss': 0.46709742731893594}
2022-11-28 04:39:42,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:42,076 INFO:     Epoch: 44
2022-11-28 04:39:42,738 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48381825671954587, 'Total loss': 0.48381825671954587} | train loss {'Reaction outcome loss': 0.47003269180474494, 'Total loss': 0.47003269180474494}
2022-11-28 04:39:42,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:42,738 INFO:     Epoch: 45
2022-11-28 04:39:43,397 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49607234515927057, 'Total loss': 0.49607234515927057} | train loss {'Reaction outcome loss': 0.4574950580232539, 'Total loss': 0.4574950580232539}
2022-11-28 04:39:43,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:43,397 INFO:     Epoch: 46
2022-11-28 04:39:44,054 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4526442140340805, 'Total loss': 0.4526442140340805} | train loss {'Reaction outcome loss': 0.4639018639499842, 'Total loss': 0.4639018639499842}
2022-11-28 04:39:44,054 INFO:     Found new best model at epoch 46
2022-11-28 04:39:44,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:44,055 INFO:     Epoch: 47
2022-11-28 04:39:44,715 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4917185472493822, 'Total loss': 0.4917185472493822} | train loss {'Reaction outcome loss': 0.45587398986584743, 'Total loss': 0.45587398986584743}
2022-11-28 04:39:44,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:44,716 INFO:     Epoch: 48
2022-11-28 04:39:45,378 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.513193354010582, 'Total loss': 0.513193354010582} | train loss {'Reaction outcome loss': 0.4620260901537984, 'Total loss': 0.4620260901537984}
2022-11-28 04:39:45,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:45,378 INFO:     Epoch: 49
2022-11-28 04:39:46,037 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4797764759172093, 'Total loss': 0.4797764759172093} | train loss {'Reaction outcome loss': 0.46514907479286194, 'Total loss': 0.46514907479286194}
2022-11-28 04:39:46,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:46,037 INFO:     Epoch: 50
2022-11-28 04:39:46,697 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.498657320372083, 'Total loss': 0.498657320372083} | train loss {'Reaction outcome loss': 0.4607624279086286, 'Total loss': 0.4607624279086286}
2022-11-28 04:39:46,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:46,697 INFO:     Epoch: 51
2022-11-28 04:39:47,352 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49470762705261057, 'Total loss': 0.49470762705261057} | train loss {'Reaction outcome loss': 0.46530576991407496, 'Total loss': 0.46530576991407496}
2022-11-28 04:39:47,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:47,352 INFO:     Epoch: 52
2022-11-28 04:39:48,012 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5089059663428501, 'Total loss': 0.5089059663428501} | train loss {'Reaction outcome loss': 0.4796244099072599, 'Total loss': 0.4796244099072599}
2022-11-28 04:39:48,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:48,012 INFO:     Epoch: 53
2022-11-28 04:39:48,668 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4841752177612348, 'Total loss': 0.4841752177612348} | train loss {'Reaction outcome loss': 0.471143879690151, 'Total loss': 0.471143879690151}
2022-11-28 04:39:48,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:48,669 INFO:     Epoch: 54
2022-11-28 04:39:49,323 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.592955344779925, 'Total loss': 0.592955344779925} | train loss {'Reaction outcome loss': 0.4640195632149816, 'Total loss': 0.4640195632149816}
2022-11-28 04:39:49,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:49,323 INFO:     Epoch: 55
2022-11-28 04:39:49,979 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4810495214028792, 'Total loss': 0.4810495214028792} | train loss {'Reaction outcome loss': 0.4790443977725651, 'Total loss': 0.4790443977725651}
2022-11-28 04:39:49,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:49,979 INFO:     Epoch: 56
2022-11-28 04:39:50,631 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.6525203456932848, 'Total loss': 0.6525203456932848} | train loss {'Reaction outcome loss': 0.4540544453808502, 'Total loss': 0.4540544453808502}
2022-11-28 04:39:50,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:50,631 INFO:     Epoch: 57
2022-11-28 04:39:51,285 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.6139730194752867, 'Total loss': 0.6139730194752867} | train loss {'Reaction outcome loss': 0.4639745997755151, 'Total loss': 0.4639745997755151}
2022-11-28 04:39:51,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:51,285 INFO:     Epoch: 58
2022-11-28 04:39:51,940 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4752774726260792, 'Total loss': 0.4752774726260792} | train loss {'Reaction outcome loss': 0.4675790418244838, 'Total loss': 0.4675790418244838}
2022-11-28 04:39:51,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:51,940 INFO:     Epoch: 59
2022-11-28 04:39:52,592 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49872819876128976, 'Total loss': 0.49872819876128976} | train loss {'Reaction outcome loss': 0.4557342091311327, 'Total loss': 0.4557342091311327}
2022-11-28 04:39:52,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:52,592 INFO:     Epoch: 60
2022-11-28 04:39:53,243 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5152164054187861, 'Total loss': 0.5152164054187861} | train loss {'Reaction outcome loss': 0.4741208078528223, 'Total loss': 0.4741208078528223}
2022-11-28 04:39:53,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:53,244 INFO:     Epoch: 61
2022-11-28 04:39:53,895 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5136068605563857, 'Total loss': 0.5136068605563857} | train loss {'Reaction outcome loss': 0.45588392339013367, 'Total loss': 0.45588392339013367}
2022-11-28 04:39:53,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:53,896 INFO:     Epoch: 62
2022-11-28 04:39:54,550 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5149941891431808, 'Total loss': 0.5149941891431808} | train loss {'Reaction outcome loss': 0.46188432708578675, 'Total loss': 0.46188432708578675}
2022-11-28 04:39:54,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:54,551 INFO:     Epoch: 63
2022-11-28 04:39:55,201 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4792388548905199, 'Total loss': 0.4792388548905199} | train loss {'Reaction outcome loss': 0.4661191318350041, 'Total loss': 0.4661191318350041}
2022-11-28 04:39:55,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:55,201 INFO:     Epoch: 64
2022-11-28 04:39:55,851 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5028861351311207, 'Total loss': 0.5028861351311207} | train loss {'Reaction outcome loss': 0.46133098042445625, 'Total loss': 0.46133098042445625}
2022-11-28 04:39:55,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:55,851 INFO:     Epoch: 65
2022-11-28 04:39:56,504 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5507355244322256, 'Total loss': 0.5507355244322256} | train loss {'Reaction outcome loss': 0.45995254920199813, 'Total loss': 0.45995254920199813}
2022-11-28 04:39:56,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:56,504 INFO:     Epoch: 66
2022-11-28 04:39:57,158 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4945491047745401, 'Total loss': 0.4945491047745401} | train loss {'Reaction outcome loss': 0.46241636218329674, 'Total loss': 0.46241636218329674}
2022-11-28 04:39:57,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:57,159 INFO:     Epoch: 67
2022-11-28 04:39:57,814 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5088723268021237, 'Total loss': 0.5088723268021237} | train loss {'Reaction outcome loss': 0.47184539354040556, 'Total loss': 0.47184539354040556}
2022-11-28 04:39:57,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:57,814 INFO:     Epoch: 68
2022-11-28 04:39:58,476 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49452351473949174, 'Total loss': 0.49452351473949174} | train loss {'Reaction outcome loss': 0.45691209292672724, 'Total loss': 0.45691209292672724}
2022-11-28 04:39:58,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:58,476 INFO:     Epoch: 69
2022-11-28 04:39:59,135 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48711948503147473, 'Total loss': 0.48711948503147473} | train loss {'Reaction outcome loss': 0.4614438848336216, 'Total loss': 0.4614438848336216}
2022-11-28 04:39:59,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:59,135 INFO:     Epoch: 70
2022-11-28 04:39:59,794 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5612146925519813, 'Total loss': 0.5612146925519813} | train loss {'Reaction outcome loss': 0.46007012291566324, 'Total loss': 0.46007012291566324}
2022-11-28 04:39:59,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:39:59,795 INFO:     Epoch: 71
2022-11-28 04:40:00,448 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45889678834514186, 'Total loss': 0.45889678834514186} | train loss {'Reaction outcome loss': 0.4592363928126073, 'Total loss': 0.4592363928126073}
2022-11-28 04:40:00,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:00,448 INFO:     Epoch: 72
2022-11-28 04:40:01,103 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47293087806213985, 'Total loss': 0.47293087806213985} | train loss {'Reaction outcome loss': 0.448009080973714, 'Total loss': 0.448009080973714}
2022-11-28 04:40:01,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:01,104 INFO:     Epoch: 73
2022-11-28 04:40:01,760 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5159675519574772, 'Total loss': 0.5159675519574772} | train loss {'Reaction outcome loss': 0.45654819899725047, 'Total loss': 0.45654819899725047}
2022-11-28 04:40:01,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:01,761 INFO:     Epoch: 74
2022-11-28 04:40:02,415 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5220450979064811, 'Total loss': 0.5220450979064811} | train loss {'Reaction outcome loss': 0.45856232597277713, 'Total loss': 0.45856232597277713}
2022-11-28 04:40:02,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:02,415 INFO:     Epoch: 75
2022-11-28 04:40:03,066 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5313501073555513, 'Total loss': 0.5313501073555513} | train loss {'Reaction outcome loss': 0.45986850632105764, 'Total loss': 0.45986850632105764}
2022-11-28 04:40:03,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:03,066 INFO:     Epoch: 76
2022-11-28 04:40:03,718 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5143445618450642, 'Total loss': 0.5143445618450642} | train loss {'Reaction outcome loss': 0.4575318301714927, 'Total loss': 0.4575318301714927}
2022-11-28 04:40:03,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:03,719 INFO:     Epoch: 77
2022-11-28 04:40:04,374 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4925298623063348, 'Total loss': 0.4925298623063348} | train loss {'Reaction outcome loss': 0.44974013668322854, 'Total loss': 0.44974013668322854}
2022-11-28 04:40:04,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:04,374 INFO:     Epoch: 78
2022-11-28 04:40:05,029 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5667333501306447, 'Total loss': 0.5667333501306447} | train loss {'Reaction outcome loss': 0.4709533229470253, 'Total loss': 0.4709533229470253}
2022-11-28 04:40:05,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:05,029 INFO:     Epoch: 79
2022-11-28 04:40:05,686 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.477598733861338, 'Total loss': 0.477598733861338} | train loss {'Reaction outcome loss': 0.4640793285147864, 'Total loss': 0.4640793285147864}
2022-11-28 04:40:05,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:05,686 INFO:     Epoch: 80
2022-11-28 04:40:06,340 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5258718576620925, 'Total loss': 0.5258718576620925} | train loss {'Reaction outcome loss': 0.4633679870169172, 'Total loss': 0.4633679870169172}
2022-11-28 04:40:06,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:06,340 INFO:     Epoch: 81
2022-11-28 04:40:06,994 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5280747847123579, 'Total loss': 0.5280747847123579} | train loss {'Reaction outcome loss': 0.510624524703634, 'Total loss': 0.510624524703634}
2022-11-28 04:40:06,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:06,994 INFO:     Epoch: 82
2022-11-28 04:40:07,649 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5193659361790527, 'Total loss': 0.5193659361790527} | train loss {'Reaction outcome loss': 0.4889706400362586, 'Total loss': 0.4889706400362586}
2022-11-28 04:40:07,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:07,649 INFO:     Epoch: 83
2022-11-28 04:40:08,302 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4806440536948768, 'Total loss': 0.4806440536948768} | train loss {'Reaction outcome loss': 0.48084477636857553, 'Total loss': 0.48084477636857553}
2022-11-28 04:40:08,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:08,302 INFO:     Epoch: 84
2022-11-28 04:40:08,953 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5150196294892918, 'Total loss': 0.5150196294892918} | train loss {'Reaction outcome loss': 0.47524785181047463, 'Total loss': 0.47524785181047463}
2022-11-28 04:40:08,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:08,953 INFO:     Epoch: 85
2022-11-28 04:40:09,604 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4894956177608533, 'Total loss': 0.4894956177608533} | train loss {'Reaction outcome loss': 0.478076781881483, 'Total loss': 0.478076781881483}
2022-11-28 04:40:09,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:09,605 INFO:     Epoch: 86
2022-11-28 04:40:10,262 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4946484626694159, 'Total loss': 0.4946484626694159} | train loss {'Reaction outcome loss': 0.4731590008808051, 'Total loss': 0.4731590008808051}
2022-11-28 04:40:10,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:10,262 INFO:     Epoch: 87
2022-11-28 04:40:10,917 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4870615425434979, 'Total loss': 0.4870615425434979} | train loss {'Reaction outcome loss': 0.4688038457682741, 'Total loss': 0.4688038457682741}
2022-11-28 04:40:10,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:10,917 INFO:     Epoch: 88
2022-11-28 04:40:11,573 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5269832434979352, 'Total loss': 0.5269832434979352} | train loss {'Reaction outcome loss': 0.45693666460313026, 'Total loss': 0.45693666460313026}
2022-11-28 04:40:11,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:11,574 INFO:     Epoch: 89
2022-11-28 04:40:12,230 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5080185867846012, 'Total loss': 0.5080185867846012} | train loss {'Reaction outcome loss': 0.4646964444352789, 'Total loss': 0.4646964444352789}
2022-11-28 04:40:12,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:12,230 INFO:     Epoch: 90
2022-11-28 04:40:12,887 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4892977516759526, 'Total loss': 0.4892977516759526} | train loss {'Reaction outcome loss': 0.4640598920313453, 'Total loss': 0.4640598920313453}
2022-11-28 04:40:12,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:12,887 INFO:     Epoch: 91
2022-11-28 04:40:13,543 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5071100789037618, 'Total loss': 0.5071100789037618} | train loss {'Reaction outcome loss': 0.4580020019841128, 'Total loss': 0.4580020019841128}
2022-11-28 04:40:13,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:13,544 INFO:     Epoch: 92
2022-11-28 04:40:14,202 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47315594486214896, 'Total loss': 0.47315594486214896} | train loss {'Reaction outcome loss': 0.4693117661152774, 'Total loss': 0.4693117661152774}
2022-11-28 04:40:14,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:14,202 INFO:     Epoch: 93
2022-11-28 04:40:14,859 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5097818340767514, 'Total loss': 0.5097818340767514} | train loss {'Reaction outcome loss': 0.45963525180874565, 'Total loss': 0.45963525180874565}
2022-11-28 04:40:14,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:14,859 INFO:     Epoch: 94
2022-11-28 04:40:15,511 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5023599344898354, 'Total loss': 0.5023599344898354} | train loss {'Reaction outcome loss': 0.4645367614050143, 'Total loss': 0.4645367614050143}
2022-11-28 04:40:15,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:15,511 INFO:     Epoch: 95
2022-11-28 04:40:16,170 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48121402446519246, 'Total loss': 0.48121402446519246} | train loss {'Reaction outcome loss': 0.46471475155247366, 'Total loss': 0.46471475155247366}
2022-11-28 04:40:16,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:16,171 INFO:     Epoch: 96
2022-11-28 04:40:16,830 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46619979495351965, 'Total loss': 0.46619979495351965} | train loss {'Reaction outcome loss': 0.4627648931041903, 'Total loss': 0.4627648931041903}
2022-11-28 04:40:16,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:16,830 INFO:     Epoch: 97
2022-11-28 04:40:17,489 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4831700413064523, 'Total loss': 0.4831700413064523} | train loss {'Reaction outcome loss': 0.4587097818556012, 'Total loss': 0.4587097818556012}
2022-11-28 04:40:17,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:17,489 INFO:     Epoch: 98
2022-11-28 04:40:18,148 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5100748748941855, 'Total loss': 0.5100748748941855} | train loss {'Reaction outcome loss': 0.46516708999510237, 'Total loss': 0.46516708999510237}
2022-11-28 04:40:18,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:18,149 INFO:     Epoch: 99
2022-11-28 04:40:18,808 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48644300347024744, 'Total loss': 0.48644300347024744} | train loss {'Reaction outcome loss': 0.47717452924019893, 'Total loss': 0.47717452924019893}
2022-11-28 04:40:18,808 INFO:     Best model found after epoch 47 of 100.
2022-11-28 04:40:18,808 INFO:   Done with stage: TRAINING
2022-11-28 04:40:18,808 INFO:   Starting stage: EVALUATION
2022-11-28 04:40:18,928 INFO:   Done with stage: EVALUATION
2022-11-28 04:40:18,928 INFO:   Leaving out SEQ value Fold_7
2022-11-28 04:40:18,940 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:40:18,941 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:40:19,587 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:40:19,587 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:40:19,657 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:40:19,657 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:40:19,657 INFO:     No hyperparam tuning for this model
2022-11-28 04:40:19,657 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:40:19,657 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:40:19,658 INFO:     None feature selector for col prot
2022-11-28 04:40:19,658 INFO:     None feature selector for col prot
2022-11-28 04:40:19,658 INFO:     None feature selector for col prot
2022-11-28 04:40:19,658 INFO:     None feature selector for col chem
2022-11-28 04:40:19,659 INFO:     None feature selector for col chem
2022-11-28 04:40:19,659 INFO:     None feature selector for col chem
2022-11-28 04:40:19,659 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:40:19,659 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:40:19,660 INFO:     Number of params in model 169651
2022-11-28 04:40:19,663 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:40:19,663 INFO:   Starting stage: TRAINING
2022-11-28 04:40:19,715 INFO:     Val loss before train {'Reaction outcome loss': 0.9888464205644347, 'Total loss': 0.9888464205644347}
2022-11-28 04:40:19,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:19,715 INFO:     Epoch: 0
2022-11-28 04:40:20,382 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5734406872229143, 'Total loss': 0.5734406872229143} | train loss {'Reaction outcome loss': 0.6820846125483513, 'Total loss': 0.6820846125483513}
2022-11-28 04:40:20,382 INFO:     Found new best model at epoch 0
2022-11-28 04:40:20,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:20,383 INFO:     Epoch: 1
2022-11-28 04:40:21,045 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5326089588078585, 'Total loss': 0.5326089588078585} | train loss {'Reaction outcome loss': 0.5862984739003643, 'Total loss': 0.5862984739003643}
2022-11-28 04:40:21,045 INFO:     Found new best model at epoch 1
2022-11-28 04:40:21,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:21,046 INFO:     Epoch: 2
2022-11-28 04:40:21,714 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5034946040673689, 'Total loss': 0.5034946040673689} | train loss {'Reaction outcome loss': 0.552708559158829, 'Total loss': 0.552708559158829}
2022-11-28 04:40:21,714 INFO:     Found new best model at epoch 2
2022-11-28 04:40:21,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:21,715 INFO:     Epoch: 3
2022-11-28 04:40:22,381 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4672091254456477, 'Total loss': 0.4672091254456477} | train loss {'Reaction outcome loss': 0.5363454969539758, 'Total loss': 0.5363454969539758}
2022-11-28 04:40:22,381 INFO:     Found new best model at epoch 3
2022-11-28 04:40:22,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:22,382 INFO:     Epoch: 4
2022-11-28 04:40:23,044 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47949362444606697, 'Total loss': 0.47949362444606697} | train loss {'Reaction outcome loss': 0.5265814689618926, 'Total loss': 0.5265814689618926}
2022-11-28 04:40:23,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:23,044 INFO:     Epoch: 5
2022-11-28 04:40:23,707 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4598951238122853, 'Total loss': 0.4598951238122853} | train loss {'Reaction outcome loss': 0.510503867581006, 'Total loss': 0.510503867581006}
2022-11-28 04:40:23,707 INFO:     Found new best model at epoch 5
2022-11-28 04:40:23,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:23,707 INFO:     Epoch: 6
2022-11-28 04:40:24,373 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45115696198560973, 'Total loss': 0.45115696198560973} | train loss {'Reaction outcome loss': 0.4969150690482028, 'Total loss': 0.4969150690482028}
2022-11-28 04:40:24,373 INFO:     Found new best model at epoch 6
2022-11-28 04:40:24,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:24,374 INFO:     Epoch: 7
2022-11-28 04:40:25,034 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44085217944600363, 'Total loss': 0.44085217944600363} | train loss {'Reaction outcome loss': 0.49387019572238766, 'Total loss': 0.49387019572238766}
2022-11-28 04:40:25,035 INFO:     Found new best model at epoch 7
2022-11-28 04:40:25,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:25,035 INFO:     Epoch: 8
2022-11-28 04:40:25,691 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4619935622269457, 'Total loss': 0.4619935622269457} | train loss {'Reaction outcome loss': 0.4969150757477168, 'Total loss': 0.4969150757477168}
2022-11-28 04:40:25,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:25,691 INFO:     Epoch: 9
2022-11-28 04:40:26,353 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4530213339762254, 'Total loss': 0.4530213339762254} | train loss {'Reaction outcome loss': 0.4870790299028158, 'Total loss': 0.4870790299028158}
2022-11-28 04:40:26,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:26,353 INFO:     Epoch: 10
2022-11-28 04:40:27,012 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43600808998400514, 'Total loss': 0.43600808998400514} | train loss {'Reaction outcome loss': 0.4856078851547453, 'Total loss': 0.4856078851547453}
2022-11-28 04:40:27,013 INFO:     Found new best model at epoch 10
2022-11-28 04:40:27,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:27,013 INFO:     Epoch: 11
2022-11-28 04:40:27,670 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4660709293728525, 'Total loss': 0.4660709293728525} | train loss {'Reaction outcome loss': 0.4771612346052162, 'Total loss': 0.4771612346052162}
2022-11-28 04:40:27,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:27,671 INFO:     Epoch: 12
2022-11-28 04:40:28,330 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45928178422830324, 'Total loss': 0.45928178422830324} | train loss {'Reaction outcome loss': 0.4749053090570434, 'Total loss': 0.4749053090570434}
2022-11-28 04:40:28,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:28,330 INFO:     Epoch: 13
2022-11-28 04:40:28,990 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.464036668904803, 'Total loss': 0.464036668904803} | train loss {'Reaction outcome loss': 0.4809712208206615, 'Total loss': 0.4809712208206615}
2022-11-28 04:40:28,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:28,991 INFO:     Epoch: 14
2022-11-28 04:40:29,650 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45501596514474263, 'Total loss': 0.45501596514474263} | train loss {'Reaction outcome loss': 0.4724513691279196, 'Total loss': 0.4724513691279196}
2022-11-28 04:40:29,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:29,650 INFO:     Epoch: 15
2022-11-28 04:40:30,311 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42772868512706325, 'Total loss': 0.42772868512706325} | train loss {'Reaction outcome loss': 0.47143169264158896, 'Total loss': 0.47143169264158896}
2022-11-28 04:40:30,311 INFO:     Found new best model at epoch 15
2022-11-28 04:40:30,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:30,312 INFO:     Epoch: 16
2022-11-28 04:40:30,976 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45639430121942, 'Total loss': 0.45639430121942} | train loss {'Reaction outcome loss': 0.4703989579312263, 'Total loss': 0.4703989579312263}
2022-11-28 04:40:30,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:30,976 INFO:     Epoch: 17
2022-11-28 04:40:31,635 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4464684362438592, 'Total loss': 0.4464684362438592} | train loss {'Reaction outcome loss': 0.46311454153469495, 'Total loss': 0.46311454153469495}
2022-11-28 04:40:31,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:31,636 INFO:     Epoch: 18
2022-11-28 04:40:32,301 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4902412871068174, 'Total loss': 0.4902412871068174} | train loss {'Reaction outcome loss': 0.47070921053208653, 'Total loss': 0.47070921053208653}
2022-11-28 04:40:32,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:32,301 INFO:     Epoch: 19
2022-11-28 04:40:32,963 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45577572557059204, 'Total loss': 0.45577572557059204} | train loss {'Reaction outcome loss': 0.4617519658659735, 'Total loss': 0.4617519658659735}
2022-11-28 04:40:32,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:32,963 INFO:     Epoch: 20
2022-11-28 04:40:33,624 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4463771151548082, 'Total loss': 0.4463771151548082} | train loss {'Reaction outcome loss': 0.46757610178282183, 'Total loss': 0.46757610178282183}
2022-11-28 04:40:33,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:33,625 INFO:     Epoch: 21
2022-11-28 04:40:34,285 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4490161284127019, 'Total loss': 0.4490161284127019} | train loss {'Reaction outcome loss': 0.4657304440174372, 'Total loss': 0.4657304440174372}
2022-11-28 04:40:34,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:34,286 INFO:     Epoch: 22
2022-11-28 04:40:34,948 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4428437758575786, 'Total loss': 0.4428437758575786} | train loss {'Reaction outcome loss': 0.4638941411169306, 'Total loss': 0.4638941411169306}
2022-11-28 04:40:34,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:34,948 INFO:     Epoch: 23
2022-11-28 04:40:35,610 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4174771129407666, 'Total loss': 0.4174771129407666} | train loss {'Reaction outcome loss': 0.4611233413940476, 'Total loss': 0.4611233413940476}
2022-11-28 04:40:35,610 INFO:     Found new best model at epoch 23
2022-11-28 04:40:35,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:35,611 INFO:     Epoch: 24
2022-11-28 04:40:36,273 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43853677809238434, 'Total loss': 0.43853677809238434} | train loss {'Reaction outcome loss': 0.4597890513438371, 'Total loss': 0.4597890513438371}
2022-11-28 04:40:36,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:36,273 INFO:     Epoch: 25
2022-11-28 04:40:36,939 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45054534382440825, 'Total loss': 0.45054534382440825} | train loss {'Reaction outcome loss': 0.46653574687098304, 'Total loss': 0.46653574687098304}
2022-11-28 04:40:36,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:36,940 INFO:     Epoch: 26
2022-11-28 04:40:37,602 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45582538013431156, 'Total loss': 0.45582538013431156} | train loss {'Reaction outcome loss': 0.46565098525776016, 'Total loss': 0.46565098525776016}
2022-11-28 04:40:37,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:37,602 INFO:     Epoch: 27
2022-11-28 04:40:38,265 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43472912128676067, 'Total loss': 0.43472912128676067} | train loss {'Reaction outcome loss': 0.4656130167385263, 'Total loss': 0.4656130167385263}
2022-11-28 04:40:38,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:38,265 INFO:     Epoch: 28
2022-11-28 04:40:38,933 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4794969958337871, 'Total loss': 0.4794969958337871} | train loss {'Reaction outcome loss': 0.4615379396465517, 'Total loss': 0.4615379396465517}
2022-11-28 04:40:38,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:38,933 INFO:     Epoch: 29
2022-11-28 04:40:39,595 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4578527760776607, 'Total loss': 0.4578527760776607} | train loss {'Reaction outcome loss': 0.4636618836272147, 'Total loss': 0.4636618836272147}
2022-11-28 04:40:39,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:39,596 INFO:     Epoch: 30
2022-11-28 04:40:40,259 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46607874875718897, 'Total loss': 0.46607874875718897} | train loss {'Reaction outcome loss': 0.47000836553953346, 'Total loss': 0.47000836553953346}
2022-11-28 04:40:40,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:40,259 INFO:     Epoch: 31
2022-11-28 04:40:40,924 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4370004317977212, 'Total loss': 0.4370004317977212} | train loss {'Reaction outcome loss': 0.4633113913718731, 'Total loss': 0.4633113913718731}
2022-11-28 04:40:40,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:40,924 INFO:     Epoch: 32
2022-11-28 04:40:41,586 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44333386522802437, 'Total loss': 0.44333386522802437} | train loss {'Reaction outcome loss': 0.46400015134244194, 'Total loss': 0.46400015134244194}
2022-11-28 04:40:41,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:41,586 INFO:     Epoch: 33
2022-11-28 04:40:42,249 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4840996499088677, 'Total loss': 0.4840996499088677} | train loss {'Reaction outcome loss': 0.4669500844733369, 'Total loss': 0.4669500844733369}
2022-11-28 04:40:42,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:42,249 INFO:     Epoch: 34
2022-11-28 04:40:42,909 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4251493638889356, 'Total loss': 0.4251493638889356} | train loss {'Reaction outcome loss': 0.45546618572646574, 'Total loss': 0.45546618572646574}
2022-11-28 04:40:42,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:42,910 INFO:     Epoch: 35
2022-11-28 04:40:43,569 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45560903948816384, 'Total loss': 0.45560903948816384} | train loss {'Reaction outcome loss': 0.4668899019879679, 'Total loss': 0.4668899019879679}
2022-11-28 04:40:43,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:43,569 INFO:     Epoch: 36
2022-11-28 04:40:44,233 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45313321155580605, 'Total loss': 0.45313321155580605} | train loss {'Reaction outcome loss': 0.4662732875815803, 'Total loss': 0.4662732875815803}
2022-11-28 04:40:44,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:44,234 INFO:     Epoch: 37
2022-11-28 04:40:44,902 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45592311092398385, 'Total loss': 0.45592311092398385} | train loss {'Reaction outcome loss': 0.4639015673028846, 'Total loss': 0.4639015673028846}
2022-11-28 04:40:44,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:44,902 INFO:     Epoch: 38
2022-11-28 04:40:45,570 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46000820804725995, 'Total loss': 0.46000820804725995} | train loss {'Reaction outcome loss': 0.4598810897779561, 'Total loss': 0.4598810897779561}
2022-11-28 04:40:45,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:45,571 INFO:     Epoch: 39
2022-11-28 04:40:46,237 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43765328926118935, 'Total loss': 0.43765328926118935} | train loss {'Reaction outcome loss': 0.46680115535855293, 'Total loss': 0.46680115535855293}
2022-11-28 04:40:46,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:46,237 INFO:     Epoch: 40
2022-11-28 04:40:46,903 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4617196863347834, 'Total loss': 0.4617196863347834} | train loss {'Reaction outcome loss': 0.4641580895310448, 'Total loss': 0.4641580895310448}
2022-11-28 04:40:46,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:46,904 INFO:     Epoch: 41
2022-11-28 04:40:47,568 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4317269181324677, 'Total loss': 0.4317269181324677} | train loss {'Reaction outcome loss': 0.47205271197843457, 'Total loss': 0.47205271197843457}
2022-11-28 04:40:47,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:47,568 INFO:     Epoch: 42
2022-11-28 04:40:48,232 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42812192169102753, 'Total loss': 0.42812192169102753} | train loss {'Reaction outcome loss': 0.46366005198609445, 'Total loss': 0.46366005198609445}
2022-11-28 04:40:48,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:48,232 INFO:     Epoch: 43
2022-11-28 04:40:48,892 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42884747379205446, 'Total loss': 0.42884747379205446} | train loss {'Reaction outcome loss': 0.46183482815902077, 'Total loss': 0.46183482815902077}
2022-11-28 04:40:48,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:48,892 INFO:     Epoch: 44
2022-11-28 04:40:49,554 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4359885501590642, 'Total loss': 0.4359885501590642} | train loss {'Reaction outcome loss': 0.46414061990236083, 'Total loss': 0.46414061990236083}
2022-11-28 04:40:49,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:49,554 INFO:     Epoch: 45
2022-11-28 04:40:50,216 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4705239493738521, 'Total loss': 0.4705239493738521} | train loss {'Reaction outcome loss': 0.45677266089666274, 'Total loss': 0.45677266089666274}
2022-11-28 04:40:50,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:50,216 INFO:     Epoch: 46
2022-11-28 04:40:50,881 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4451503523371436, 'Total loss': 0.4451503523371436} | train loss {'Reaction outcome loss': 0.4618313499395886, 'Total loss': 0.4618313499395886}
2022-11-28 04:40:50,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:50,881 INFO:     Epoch: 47
2022-11-28 04:40:51,547 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43943816321817314, 'Total loss': 0.43943816321817314} | train loss {'Reaction outcome loss': 0.4683357021741329, 'Total loss': 0.4683357021741329}
2022-11-28 04:40:51,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:51,547 INFO:     Epoch: 48
2022-11-28 04:40:52,209 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4296374185518785, 'Total loss': 0.4296374185518785} | train loss {'Reaction outcome loss': 0.4626577766311745, 'Total loss': 0.4626577766311745}
2022-11-28 04:40:52,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:52,209 INFO:     Epoch: 49
2022-11-28 04:40:52,872 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45876516740430484, 'Total loss': 0.45876516740430484} | train loss {'Reaction outcome loss': 0.4671949604826589, 'Total loss': 0.4671949604826589}
2022-11-28 04:40:52,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:52,872 INFO:     Epoch: 50
2022-11-28 04:40:53,537 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45017826387828047, 'Total loss': 0.45017826387828047} | train loss {'Reaction outcome loss': 0.4688639552482674, 'Total loss': 0.4688639552482674}
2022-11-28 04:40:53,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:53,537 INFO:     Epoch: 51
2022-11-28 04:40:54,200 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44794130765578966, 'Total loss': 0.44794130765578966} | train loss {'Reaction outcome loss': 0.4591104335662338, 'Total loss': 0.4591104335662338}
2022-11-28 04:40:54,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:54,200 INFO:     Epoch: 52
2022-11-28 04:40:54,864 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48294038799676026, 'Total loss': 0.48294038799676026} | train loss {'Reaction outcome loss': 0.4631498320208442, 'Total loss': 0.4631498320208442}
2022-11-28 04:40:54,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:54,864 INFO:     Epoch: 53
2022-11-28 04:40:55,526 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4492368728599765, 'Total loss': 0.4492368728599765} | train loss {'Reaction outcome loss': 0.4692189848471072, 'Total loss': 0.4692189848471072}
2022-11-28 04:40:55,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:55,526 INFO:     Epoch: 54
2022-11-28 04:40:56,190 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4507481929930774, 'Total loss': 0.4507481929930774} | train loss {'Reaction outcome loss': 0.466970469802618, 'Total loss': 0.466970469802618}
2022-11-28 04:40:56,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:56,190 INFO:     Epoch: 55
2022-11-28 04:40:56,853 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4524893977425315, 'Total loss': 0.4524893977425315} | train loss {'Reaction outcome loss': 0.45745844556198967, 'Total loss': 0.45745844556198967}
2022-11-28 04:40:56,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:56,853 INFO:     Epoch: 56
2022-11-28 04:40:57,514 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43966627662832086, 'Total loss': 0.43966627662832086} | train loss {'Reaction outcome loss': 0.4647614679209167, 'Total loss': 0.4647614679209167}
2022-11-28 04:40:57,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:57,514 INFO:     Epoch: 57
2022-11-28 04:40:58,179 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4331317452544516, 'Total loss': 0.4331317452544516} | train loss {'Reaction outcome loss': 0.463931932534662, 'Total loss': 0.463931932534662}
2022-11-28 04:40:58,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:58,179 INFO:     Epoch: 58
2022-11-28 04:40:58,846 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43067917464808986, 'Total loss': 0.43067917464808986} | train loss {'Reaction outcome loss': 0.46120908979566827, 'Total loss': 0.46120908979566827}
2022-11-28 04:40:58,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:58,847 INFO:     Epoch: 59
2022-11-28 04:40:59,508 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4214817915450443, 'Total loss': 0.4214817915450443} | train loss {'Reaction outcome loss': 0.46537505048176936, 'Total loss': 0.46537505048176936}
2022-11-28 04:40:59,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:40:59,508 INFO:     Epoch: 60
2022-11-28 04:41:00,170 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4299156865613027, 'Total loss': 0.4299156865613027} | train loss {'Reaction outcome loss': 0.4602249063431255, 'Total loss': 0.4602249063431255}
2022-11-28 04:41:00,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:00,170 INFO:     Epoch: 61
2022-11-28 04:41:00,834 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4429664195261218, 'Total loss': 0.4429664195261218} | train loss {'Reaction outcome loss': 0.460085227364494, 'Total loss': 0.460085227364494}
2022-11-28 04:41:00,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:00,834 INFO:     Epoch: 62
2022-11-28 04:41:01,494 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4524573280730031, 'Total loss': 0.4524573280730031} | train loss {'Reaction outcome loss': 0.46887202891370944, 'Total loss': 0.46887202891370944}
2022-11-28 04:41:01,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:01,494 INFO:     Epoch: 63
2022-11-28 04:41:02,154 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4370127862150019, 'Total loss': 0.4370127862150019} | train loss {'Reaction outcome loss': 0.4533570317190982, 'Total loss': 0.4533570317190982}
2022-11-28 04:41:02,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:02,155 INFO:     Epoch: 64
2022-11-28 04:41:02,818 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45195818827910855, 'Total loss': 0.45195818827910855} | train loss {'Reaction outcome loss': 0.46520152573864304, 'Total loss': 0.46520152573864304}
2022-11-28 04:41:02,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:02,818 INFO:     Epoch: 65
2022-11-28 04:41:03,478 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42768756774338806, 'Total loss': 0.42768756774338806} | train loss {'Reaction outcome loss': 0.4563847154739403, 'Total loss': 0.4563847154739403}
2022-11-28 04:41:03,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:03,479 INFO:     Epoch: 66
2022-11-28 04:41:04,141 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42857746305790817, 'Total loss': 0.42857746305790817} | train loss {'Reaction outcome loss': 0.4614490944171144, 'Total loss': 0.4614490944171144}
2022-11-28 04:41:04,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:04,141 INFO:     Epoch: 67
2022-11-28 04:41:04,803 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44161044535311783, 'Total loss': 0.44161044535311783} | train loss {'Reaction outcome loss': 0.455222922767843, 'Total loss': 0.455222922767843}
2022-11-28 04:41:04,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:04,804 INFO:     Epoch: 68
2022-11-28 04:41:05,464 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4594201570884748, 'Total loss': 0.4594201570884748} | train loss {'Reaction outcome loss': 0.4556477610622683, 'Total loss': 0.4556477610622683}
2022-11-28 04:41:05,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:05,465 INFO:     Epoch: 69
2022-11-28 04:41:06,127 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4435618374158036, 'Total loss': 0.4435618374158036} | train loss {'Reaction outcome loss': 0.46510026573894486, 'Total loss': 0.46510026573894486}
2022-11-28 04:41:06,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:06,127 INFO:     Epoch: 70
2022-11-28 04:41:06,792 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43152072856372053, 'Total loss': 0.43152072856372053} | train loss {'Reaction outcome loss': 0.46028767820567856, 'Total loss': 0.46028767820567856}
2022-11-28 04:41:06,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:06,792 INFO:     Epoch: 71
2022-11-28 04:41:07,459 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4457294514233416, 'Total loss': 0.4457294514233416} | train loss {'Reaction outcome loss': 0.45476768952944585, 'Total loss': 0.45476768952944585}
2022-11-28 04:41:07,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:07,459 INFO:     Epoch: 72
2022-11-28 04:41:08,123 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.478864579715512, 'Total loss': 0.478864579715512} | train loss {'Reaction outcome loss': 0.45647037972605997, 'Total loss': 0.45647037972605997}
2022-11-28 04:41:08,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:08,123 INFO:     Epoch: 73
2022-11-28 04:41:08,786 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4576964053240689, 'Total loss': 0.4576964053240689} | train loss {'Reaction outcome loss': 0.4611119222977469, 'Total loss': 0.4611119222977469}
2022-11-28 04:41:08,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:08,786 INFO:     Epoch: 74
2022-11-28 04:41:09,446 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46218806674534624, 'Total loss': 0.46218806674534624} | train loss {'Reaction outcome loss': 0.45363243110477924, 'Total loss': 0.45363243110477924}
2022-11-28 04:41:09,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:09,446 INFO:     Epoch: 75
2022-11-28 04:41:10,105 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4608316868543625, 'Total loss': 0.4608316868543625} | train loss {'Reaction outcome loss': 0.45815125564413683, 'Total loss': 0.45815125564413683}
2022-11-28 04:41:10,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:10,106 INFO:     Epoch: 76
2022-11-28 04:41:10,768 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4691295857456597, 'Total loss': 0.4691295857456597} | train loss {'Reaction outcome loss': 0.4566704109611531, 'Total loss': 0.4566704109611531}
2022-11-28 04:41:10,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:10,768 INFO:     Epoch: 77
2022-11-28 04:41:11,433 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4417323111133142, 'Total loss': 0.4417323111133142} | train loss {'Reaction outcome loss': 0.4526548900250946, 'Total loss': 0.4526548900250946}
2022-11-28 04:41:11,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:11,433 INFO:     Epoch: 78
2022-11-28 04:41:12,091 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45547487180341373, 'Total loss': 0.45547487180341373} | train loss {'Reaction outcome loss': 0.45405663303550214, 'Total loss': 0.45405663303550214}
2022-11-28 04:41:12,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:12,091 INFO:     Epoch: 79
2022-11-28 04:41:12,753 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4433109032159502, 'Total loss': 0.4433109032159502} | train loss {'Reaction outcome loss': 0.4565972380580441, 'Total loss': 0.4565972380580441}
2022-11-28 04:41:12,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:12,753 INFO:     Epoch: 80
2022-11-28 04:41:13,415 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4643971771001816, 'Total loss': 0.4643971771001816} | train loss {'Reaction outcome loss': 0.450971637221594, 'Total loss': 0.450971637221594}
2022-11-28 04:41:13,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:13,415 INFO:     Epoch: 81
2022-11-28 04:41:14,078 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4610322991555387, 'Total loss': 0.4610322991555387} | train loss {'Reaction outcome loss': 0.45330469250198335, 'Total loss': 0.45330469250198335}
2022-11-28 04:41:14,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:14,078 INFO:     Epoch: 82
2022-11-28 04:41:14,742 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4447926648638465, 'Total loss': 0.4447926648638465} | train loss {'Reaction outcome loss': 0.4554802763966783, 'Total loss': 0.4554802763966783}
2022-11-28 04:41:14,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:14,743 INFO:     Epoch: 83
2022-11-28 04:41:15,401 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4579751650718125, 'Total loss': 0.4579751650718125} | train loss {'Reaction outcome loss': 0.4542041869173127, 'Total loss': 0.4542041869173127}
2022-11-28 04:41:15,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:15,401 INFO:     Epoch: 84
2022-11-28 04:41:16,065 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4947943524880843, 'Total loss': 0.4947943524880843} | train loss {'Reaction outcome loss': 0.45426412467514315, 'Total loss': 0.45426412467514315}
2022-11-28 04:41:16,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:16,065 INFO:     Epoch: 85
2022-11-28 04:41:16,730 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44562538306821475, 'Total loss': 0.44562538306821475} | train loss {'Reaction outcome loss': 0.4538041557215394, 'Total loss': 0.4538041557215394}
2022-11-28 04:41:16,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:16,730 INFO:     Epoch: 86
2022-11-28 04:41:17,395 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4341346086426215, 'Total loss': 0.4341346086426215} | train loss {'Reaction outcome loss': 0.45648229422588504, 'Total loss': 0.45648229422588504}
2022-11-28 04:41:17,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:17,395 INFO:     Epoch: 87
2022-11-28 04:41:18,060 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45939965749328787, 'Total loss': 0.45939965749328787} | train loss {'Reaction outcome loss': 0.45506589132691583, 'Total loss': 0.45506589132691583}
2022-11-28 04:41:18,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:18,061 INFO:     Epoch: 88
2022-11-28 04:41:18,723 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48941957544196735, 'Total loss': 0.48941957544196735} | train loss {'Reaction outcome loss': 0.4524613377608119, 'Total loss': 0.4524613377608119}
2022-11-28 04:41:18,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:18,723 INFO:     Epoch: 89
2022-11-28 04:41:19,385 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4350628697059371, 'Total loss': 0.4350628697059371} | train loss {'Reaction outcome loss': 0.46244357156777577, 'Total loss': 0.46244357156777577}
2022-11-28 04:41:19,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:19,385 INFO:     Epoch: 90
2022-11-28 04:41:20,051 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45594217628240585, 'Total loss': 0.45594217628240585} | train loss {'Reaction outcome loss': 0.4599602745485402, 'Total loss': 0.4599602745485402}
2022-11-28 04:41:20,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:20,051 INFO:     Epoch: 91
2022-11-28 04:41:20,715 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43746592510830273, 'Total loss': 0.43746592510830273} | train loss {'Reaction outcome loss': 0.45390939610379355, 'Total loss': 0.45390939610379355}
2022-11-28 04:41:20,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:20,715 INFO:     Epoch: 92
2022-11-28 04:41:21,378 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4885536303574389, 'Total loss': 0.4885536303574389} | train loss {'Reaction outcome loss': 0.45232727330538536, 'Total loss': 0.45232727330538536}
2022-11-28 04:41:21,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:21,378 INFO:     Epoch: 93
2022-11-28 04:41:22,042 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4566322033378211, 'Total loss': 0.4566322033378211} | train loss {'Reaction outcome loss': 0.4535931907293777, 'Total loss': 0.4535931907293777}
2022-11-28 04:41:22,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:22,042 INFO:     Epoch: 94
2022-11-28 04:41:22,706 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44023105773058807, 'Total loss': 0.44023105773058807} | train loss {'Reaction outcome loss': 0.4548905166166444, 'Total loss': 0.4548905166166444}
2022-11-28 04:41:22,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:22,706 INFO:     Epoch: 95
2022-11-28 04:41:23,368 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44396975196220656, 'Total loss': 0.44396975196220656} | train loss {'Reaction outcome loss': 0.46026785212058213, 'Total loss': 0.46026785212058213}
2022-11-28 04:41:23,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:23,368 INFO:     Epoch: 96
2022-11-28 04:41:24,032 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4480433836579323, 'Total loss': 0.4480433836579323} | train loss {'Reaction outcome loss': 0.4599630483576367, 'Total loss': 0.4599630483576367}
2022-11-28 04:41:24,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:24,032 INFO:     Epoch: 97
2022-11-28 04:41:24,695 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4514849842949347, 'Total loss': 0.4514849842949347} | train loss {'Reaction outcome loss': 0.4585375896384639, 'Total loss': 0.4585375896384639}
2022-11-28 04:41:24,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:24,695 INFO:     Epoch: 98
2022-11-28 04:41:25,357 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45390522039749404, 'Total loss': 0.45390522039749404} | train loss {'Reaction outcome loss': 0.45399943889389116, 'Total loss': 0.45399943889389116}
2022-11-28 04:41:25,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:25,357 INFO:     Epoch: 99
2022-11-28 04:41:26,022 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42441158098253334, 'Total loss': 0.42441158098253334} | train loss {'Reaction outcome loss': 0.46065426575801066, 'Total loss': 0.46065426575801066}
2022-11-28 04:41:26,022 INFO:     Best model found after epoch 24 of 100.
2022-11-28 04:41:26,022 INFO:   Done with stage: TRAINING
2022-11-28 04:41:26,022 INFO:   Starting stage: EVALUATION
2022-11-28 04:41:26,135 INFO:   Done with stage: EVALUATION
2022-11-28 04:41:26,135 INFO:   Leaving out SEQ value Fold_8
2022-11-28 04:41:26,147 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:41:26,148 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:41:26,789 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:41:26,789 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:41:26,858 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:41:26,858 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:41:26,858 INFO:     No hyperparam tuning for this model
2022-11-28 04:41:26,858 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:41:26,858 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:41:26,859 INFO:     None feature selector for col prot
2022-11-28 04:41:26,859 INFO:     None feature selector for col prot
2022-11-28 04:41:26,859 INFO:     None feature selector for col prot
2022-11-28 04:41:26,859 INFO:     None feature selector for col chem
2022-11-28 04:41:26,860 INFO:     None feature selector for col chem
2022-11-28 04:41:26,860 INFO:     None feature selector for col chem
2022-11-28 04:41:26,860 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:41:26,860 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:41:26,861 INFO:     Number of params in model 169651
2022-11-28 04:41:26,864 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:41:26,864 INFO:   Starting stage: TRAINING
2022-11-28 04:41:26,916 INFO:     Val loss before train {'Reaction outcome loss': 1.0569838678294963, 'Total loss': 1.0569838678294963}
2022-11-28 04:41:26,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:26,916 INFO:     Epoch: 0
2022-11-28 04:41:27,575 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5739718540148302, 'Total loss': 0.5739718540148302} | train loss {'Reaction outcome loss': 0.7114568433213618, 'Total loss': 0.7114568433213618}
2022-11-28 04:41:27,575 INFO:     Found new best model at epoch 0
2022-11-28 04:41:27,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:27,576 INFO:     Epoch: 1
2022-11-28 04:41:28,234 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5546811778437007, 'Total loss': 0.5546811778437007} | train loss {'Reaction outcome loss': 0.5989082570398047, 'Total loss': 0.5989082570398047}
2022-11-28 04:41:28,234 INFO:     Found new best model at epoch 1
2022-11-28 04:41:28,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:28,235 INFO:     Epoch: 2
2022-11-28 04:41:28,896 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5911434130235151, 'Total loss': 0.5911434130235151} | train loss {'Reaction outcome loss': 0.559962519294312, 'Total loss': 0.559962519294312}
2022-11-28 04:41:28,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:28,897 INFO:     Epoch: 3
2022-11-28 04:41:29,559 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5157247229733251, 'Total loss': 0.5157247229733251} | train loss {'Reaction outcome loss': 0.5405444215021787, 'Total loss': 0.5405444215021787}
2022-11-28 04:41:29,559 INFO:     Found new best model at epoch 3
2022-11-28 04:41:29,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:29,559 INFO:     Epoch: 4
2022-11-28 04:41:30,220 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49273305995897815, 'Total loss': 0.49273305995897815} | train loss {'Reaction outcome loss': 0.5205511781236818, 'Total loss': 0.5205511781236818}
2022-11-28 04:41:30,221 INFO:     Found new best model at epoch 4
2022-11-28 04:41:30,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:30,221 INFO:     Epoch: 5
2022-11-28 04:41:30,883 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5254324125972661, 'Total loss': 0.5254324125972661} | train loss {'Reaction outcome loss': 0.5085571824963535, 'Total loss': 0.5085571824963535}
2022-11-28 04:41:30,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:30,884 INFO:     Epoch: 6
2022-11-28 04:41:31,548 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4873423173346303, 'Total loss': 0.4873423173346303} | train loss {'Reaction outcome loss': 0.503525692488878, 'Total loss': 0.503525692488878}
2022-11-28 04:41:31,548 INFO:     Found new best model at epoch 6
2022-11-28 04:41:31,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:31,549 INFO:     Epoch: 7
2022-11-28 04:41:32,210 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5178013704717159, 'Total loss': 0.5178013704717159} | train loss {'Reaction outcome loss': 0.4960324844165194, 'Total loss': 0.4960324844165194}
2022-11-28 04:41:32,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:32,210 INFO:     Epoch: 8
2022-11-28 04:41:32,872 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5033893619071353, 'Total loss': 0.5033893619071353} | train loss {'Reaction outcome loss': 0.49554291649931864, 'Total loss': 0.49554291649931864}
2022-11-28 04:41:32,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:32,872 INFO:     Epoch: 9
2022-11-28 04:41:33,533 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47590026598085056, 'Total loss': 0.47590026598085056} | train loss {'Reaction outcome loss': 0.4923590266656491, 'Total loss': 0.4923590266656491}
2022-11-28 04:41:33,533 INFO:     Found new best model at epoch 9
2022-11-28 04:41:33,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:33,534 INFO:     Epoch: 10
2022-11-28 04:41:34,195 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5149979171427813, 'Total loss': 0.5149979171427813} | train loss {'Reaction outcome loss': 0.47773214724035035, 'Total loss': 0.47773214724035035}
2022-11-28 04:41:34,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:34,195 INFO:     Epoch: 11
2022-11-28 04:41:34,864 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4703813296827403, 'Total loss': 0.4703813296827403} | train loss {'Reaction outcome loss': 0.4921949925802408, 'Total loss': 0.4921949925802408}
2022-11-28 04:41:34,864 INFO:     Found new best model at epoch 11
2022-11-28 04:41:34,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:34,865 INFO:     Epoch: 12
2022-11-28 04:41:35,532 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4838406690819697, 'Total loss': 0.4838406690819697} | train loss {'Reaction outcome loss': 0.48324760812665185, 'Total loss': 0.48324760812665185}
2022-11-28 04:41:35,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:35,533 INFO:     Epoch: 13
2022-11-28 04:41:36,199 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5140029865909707, 'Total loss': 0.5140029865909707} | train loss {'Reaction outcome loss': 0.47284571171527906, 'Total loss': 0.47284571171527906}
2022-11-28 04:41:36,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:36,199 INFO:     Epoch: 14
2022-11-28 04:41:36,864 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4877860762856223, 'Total loss': 0.4877860762856223} | train loss {'Reaction outcome loss': 0.4767384550143634, 'Total loss': 0.4767384550143634}
2022-11-28 04:41:36,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:36,865 INFO:     Epoch: 15
2022-11-28 04:41:37,531 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5186844051561572, 'Total loss': 0.5186844051561572} | train loss {'Reaction outcome loss': 0.4720156379644909, 'Total loss': 0.4720156379644909}
2022-11-28 04:41:37,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:37,531 INFO:     Epoch: 16
2022-11-28 04:41:38,192 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4626294784247875, 'Total loss': 0.4626294784247875} | train loss {'Reaction outcome loss': 0.4768440410975487, 'Total loss': 0.4768440410975487}
2022-11-28 04:41:38,192 INFO:     Found new best model at epoch 16
2022-11-28 04:41:38,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:38,193 INFO:     Epoch: 17
2022-11-28 04:41:38,859 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4774851433255456, 'Total loss': 0.4774851433255456} | train loss {'Reaction outcome loss': 0.4825735947778148, 'Total loss': 0.4825735947778148}
2022-11-28 04:41:38,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:38,859 INFO:     Epoch: 18
2022-11-28 04:41:39,524 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47093490206382493, 'Total loss': 0.47093490206382493} | train loss {'Reaction outcome loss': 0.48191830503844446, 'Total loss': 0.48191830503844446}
2022-11-28 04:41:39,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:39,524 INFO:     Epoch: 19
2022-11-28 04:41:40,187 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48161710934205487, 'Total loss': 0.48161710934205487} | train loss {'Reaction outcome loss': 0.4671130643015908, 'Total loss': 0.4671130643015908}
2022-11-28 04:41:40,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:40,187 INFO:     Epoch: 20
2022-11-28 04:41:40,849 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4986642152070999, 'Total loss': 0.4986642152070999} | train loss {'Reaction outcome loss': 0.46824836742974096, 'Total loss': 0.46824836742974096}
2022-11-28 04:41:40,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:40,849 INFO:     Epoch: 21
2022-11-28 04:41:41,513 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45294648815285077, 'Total loss': 0.45294648815285077} | train loss {'Reaction outcome loss': 0.4734201433677827, 'Total loss': 0.4734201433677827}
2022-11-28 04:41:41,513 INFO:     Found new best model at epoch 21
2022-11-28 04:41:41,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:41,514 INFO:     Epoch: 22
2022-11-28 04:41:42,173 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44841188395565207, 'Total loss': 0.44841188395565207} | train loss {'Reaction outcome loss': 0.47403986433580997, 'Total loss': 0.47403986433580997}
2022-11-28 04:41:42,173 INFO:     Found new best model at epoch 22
2022-11-28 04:41:42,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:42,174 INFO:     Epoch: 23
2022-11-28 04:41:42,836 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4826477041298693, 'Total loss': 0.4826477041298693} | train loss {'Reaction outcome loss': 0.4665844600287176, 'Total loss': 0.4665844600287176}
2022-11-28 04:41:42,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:42,836 INFO:     Epoch: 24
2022-11-28 04:41:43,500 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4762490259652788, 'Total loss': 0.4762490259652788} | train loss {'Reaction outcome loss': 0.4702981857643012, 'Total loss': 0.4702981857643012}
2022-11-28 04:41:43,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:43,501 INFO:     Epoch: 25
2022-11-28 04:41:44,162 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48669765246185387, 'Total loss': 0.48669765246185387} | train loss {'Reaction outcome loss': 0.4580981105325683, 'Total loss': 0.4580981105325683}
2022-11-28 04:41:44,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:44,162 INFO:     Epoch: 26
2022-11-28 04:41:44,824 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4545976787128232, 'Total loss': 0.4545976787128232} | train loss {'Reaction outcome loss': 0.4786815522539039, 'Total loss': 0.4786815522539039}
2022-11-28 04:41:44,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:44,824 INFO:     Epoch: 27
2022-11-28 04:41:45,483 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4885184859687632, 'Total loss': 0.4885184859687632} | train loss {'Reaction outcome loss': 0.47282347257339186, 'Total loss': 0.47282347257339186}
2022-11-28 04:41:45,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:45,483 INFO:     Epoch: 28
2022-11-28 04:41:46,144 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4695167023349892, 'Total loss': 0.4695167023349892} | train loss {'Reaction outcome loss': 0.4533091214515509, 'Total loss': 0.4533091214515509}
2022-11-28 04:41:46,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:46,144 INFO:     Epoch: 29
2022-11-28 04:41:46,805 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4645806063305248, 'Total loss': 0.4645806063305248} | train loss {'Reaction outcome loss': 0.4710527596875064, 'Total loss': 0.4710527596875064}
2022-11-28 04:41:46,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:46,805 INFO:     Epoch: 30
2022-11-28 04:41:47,468 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45524588227272034, 'Total loss': 0.45524588227272034} | train loss {'Reaction outcome loss': 0.46496058597920403, 'Total loss': 0.46496058597920403}
2022-11-28 04:41:47,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:47,468 INFO:     Epoch: 31
2022-11-28 04:41:48,131 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4822070141407577, 'Total loss': 0.4822070141407577} | train loss {'Reaction outcome loss': 0.4601611555704186, 'Total loss': 0.4601611555704186}
2022-11-28 04:41:48,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:48,131 INFO:     Epoch: 32
2022-11-28 04:41:48,789 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4719392426989295, 'Total loss': 0.4719392426989295} | train loss {'Reaction outcome loss': 0.46368092574900194, 'Total loss': 0.46368092574900194}
2022-11-28 04:41:48,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:48,789 INFO:     Epoch: 33
2022-11-28 04:41:49,452 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.447394209490581, 'Total loss': 0.447394209490581} | train loss {'Reaction outcome loss': 0.4627697842736398, 'Total loss': 0.4627697842736398}
2022-11-28 04:41:49,452 INFO:     Found new best model at epoch 33
2022-11-28 04:41:49,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:49,453 INFO:     Epoch: 34
2022-11-28 04:41:50,116 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4642221771857955, 'Total loss': 0.4642221771857955} | train loss {'Reaction outcome loss': 0.46529143766289754, 'Total loss': 0.46529143766289754}
2022-11-28 04:41:50,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:50,116 INFO:     Epoch: 35
2022-11-28 04:41:50,777 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49152146008881653, 'Total loss': 0.49152146008881653} | train loss {'Reaction outcome loss': 0.461309589265335, 'Total loss': 0.461309589265335}
2022-11-28 04:41:50,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:50,778 INFO:     Epoch: 36
2022-11-28 04:41:51,439 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4355921311811967, 'Total loss': 0.4355921311811967} | train loss {'Reaction outcome loss': 0.4656341899967482, 'Total loss': 0.4656341899967482}
2022-11-28 04:41:51,440 INFO:     Found new best model at epoch 36
2022-11-28 04:41:51,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:51,440 INFO:     Epoch: 37
2022-11-28 04:41:52,104 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4383745291693644, 'Total loss': 0.4383745291693644} | train loss {'Reaction outcome loss': 0.4686082596139562, 'Total loss': 0.4686082596139562}
2022-11-28 04:41:52,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:52,104 INFO:     Epoch: 38
2022-11-28 04:41:52,766 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49429594285108824, 'Total loss': 0.49429594285108824} | train loss {'Reaction outcome loss': 0.45623125592547076, 'Total loss': 0.45623125592547076}
2022-11-28 04:41:52,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:52,766 INFO:     Epoch: 39
2022-11-28 04:41:53,431 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4602054757150737, 'Total loss': 0.4602054757150737} | train loss {'Reaction outcome loss': 0.46151771820000104, 'Total loss': 0.46151771820000104}
2022-11-28 04:41:53,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:53,431 INFO:     Epoch: 40
2022-11-28 04:41:54,096 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4617354453287341, 'Total loss': 0.4617354453287341} | train loss {'Reaction outcome loss': 0.4633678802319111, 'Total loss': 0.4633678802319111}
2022-11-28 04:41:54,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:54,096 INFO:     Epoch: 41
2022-11-28 04:41:54,756 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4671316146850586, 'Total loss': 0.4671316146850586} | train loss {'Reaction outcome loss': 0.4649690383624646, 'Total loss': 0.4649690383624646}
2022-11-28 04:41:54,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:54,757 INFO:     Epoch: 42
2022-11-28 04:41:55,423 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45578100193630566, 'Total loss': 0.45578100193630566} | train loss {'Reaction outcome loss': 0.4620380510966624, 'Total loss': 0.4620380510966624}
2022-11-28 04:41:55,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:55,423 INFO:     Epoch: 43
2022-11-28 04:41:56,090 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46164527840235015, 'Total loss': 0.46164527840235015} | train loss {'Reaction outcome loss': 0.46385465057626846, 'Total loss': 0.46385465057626846}
2022-11-28 04:41:56,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:56,090 INFO:     Epoch: 44
2022-11-28 04:41:56,755 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.463835612278093, 'Total loss': 0.463835612278093} | train loss {'Reaction outcome loss': 0.46893906971860316, 'Total loss': 0.46893906971860316}
2022-11-28 04:41:56,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:56,755 INFO:     Epoch: 45
2022-11-28 04:41:57,418 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48853630369359796, 'Total loss': 0.48853630369359796} | train loss {'Reaction outcome loss': 0.46294269794898646, 'Total loss': 0.46294269794898646}
2022-11-28 04:41:57,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:57,418 INFO:     Epoch: 46
2022-11-28 04:41:58,085 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45408197898756375, 'Total loss': 0.45408197898756375} | train loss {'Reaction outcome loss': 0.47010419289431266, 'Total loss': 0.47010419289431266}
2022-11-28 04:41:58,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:58,086 INFO:     Epoch: 47
2022-11-28 04:41:58,752 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46663264591585507, 'Total loss': 0.46663264591585507} | train loss {'Reaction outcome loss': 0.46409037643142287, 'Total loss': 0.46409037643142287}
2022-11-28 04:41:58,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:58,752 INFO:     Epoch: 48
2022-11-28 04:41:59,416 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46670232103629544, 'Total loss': 0.46670232103629544} | train loss {'Reaction outcome loss': 0.46029685690037664, 'Total loss': 0.46029685690037664}
2022-11-28 04:41:59,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:41:59,416 INFO:     Epoch: 49
2022-11-28 04:42:00,079 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4709252461113713, 'Total loss': 0.4709252461113713} | train loss {'Reaction outcome loss': 0.4692251164345972, 'Total loss': 0.4692251164345972}
2022-11-28 04:42:00,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:00,079 INFO:     Epoch: 50
2022-11-28 04:42:00,740 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4623647437176921, 'Total loss': 0.4623647437176921} | train loss {'Reaction outcome loss': 0.4612960869506482, 'Total loss': 0.4612960869506482}
2022-11-28 04:42:00,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:00,741 INFO:     Epoch: 51
2022-11-28 04:42:01,403 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46198624846610153, 'Total loss': 0.46198624846610153} | train loss {'Reaction outcome loss': 0.4664922065191692, 'Total loss': 0.4664922065191692}
2022-11-28 04:42:01,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:01,404 INFO:     Epoch: 52
2022-11-28 04:42:02,067 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4600254703651775, 'Total loss': 0.4600254703651775} | train loss {'Reaction outcome loss': 0.4655769170231877, 'Total loss': 0.4655769170231877}
2022-11-28 04:42:02,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:02,067 INFO:     Epoch: 53
2022-11-28 04:42:02,729 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46241673454642296, 'Total loss': 0.46241673454642296} | train loss {'Reaction outcome loss': 0.46233153247064157, 'Total loss': 0.46233153247064157}
2022-11-28 04:42:02,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:02,729 INFO:     Epoch: 54
2022-11-28 04:42:03,390 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5070041275837205, 'Total loss': 0.5070041275837205} | train loss {'Reaction outcome loss': 0.4699886568010815, 'Total loss': 0.4699886568010815}
2022-11-28 04:42:03,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:03,391 INFO:     Epoch: 55
2022-11-28 04:42:04,057 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5015000362287868, 'Total loss': 0.5015000362287868} | train loss {'Reaction outcome loss': 0.45918194691260017, 'Total loss': 0.45918194691260017}
2022-11-28 04:42:04,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:04,057 INFO:     Epoch: 56
2022-11-28 04:42:04,720 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4795371327887882, 'Total loss': 0.4795371327887882} | train loss {'Reaction outcome loss': 0.46517925679443345, 'Total loss': 0.46517925679443345}
2022-11-28 04:42:04,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:04,720 INFO:     Epoch: 57
2022-11-28 04:42:05,380 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4736900065432895, 'Total loss': 0.4736900065432895} | train loss {'Reaction outcome loss': 0.46843945919986696, 'Total loss': 0.46843945919986696}
2022-11-28 04:42:05,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:05,381 INFO:     Epoch: 58
2022-11-28 04:42:06,044 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45739527080546727, 'Total loss': 0.45739527080546727} | train loss {'Reaction outcome loss': 0.4649884576999372, 'Total loss': 0.4649884576999372}
2022-11-28 04:42:06,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:06,045 INFO:     Epoch: 59
2022-11-28 04:42:06,709 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46332107789137145, 'Total loss': 0.46332107789137145} | train loss {'Reaction outcome loss': 0.46284558509867035, 'Total loss': 0.46284558509867035}
2022-11-28 04:42:06,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:06,710 INFO:     Epoch: 60
2022-11-28 04:42:07,373 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49700929393822496, 'Total loss': 0.49700929393822496} | train loss {'Reaction outcome loss': 0.4618484991933069, 'Total loss': 0.4618484991933069}
2022-11-28 04:42:07,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:07,374 INFO:     Epoch: 61
2022-11-28 04:42:08,039 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4643968418240547, 'Total loss': 0.4643968418240547} | train loss {'Reaction outcome loss': 0.47074699389838404, 'Total loss': 0.47074699389838404}
2022-11-28 04:42:08,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:08,039 INFO:     Epoch: 62
2022-11-28 04:42:08,703 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43758986246856774, 'Total loss': 0.43758986246856774} | train loss {'Reaction outcome loss': 0.4647772418064696, 'Total loss': 0.4647772418064696}
2022-11-28 04:42:08,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:08,703 INFO:     Epoch: 63
2022-11-28 04:42:09,368 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46449175544760446, 'Total loss': 0.46449175544760446} | train loss {'Reaction outcome loss': 0.4634338551831822, 'Total loss': 0.4634338551831822}
2022-11-28 04:42:09,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:09,368 INFO:     Epoch: 64
2022-11-28 04:42:10,029 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4499024464325471, 'Total loss': 0.4499024464325471} | train loss {'Reaction outcome loss': 0.4659619285394588, 'Total loss': 0.4659619285394588}
2022-11-28 04:42:10,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:10,029 INFO:     Epoch: 65
2022-11-28 04:42:10,690 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5009211420335553, 'Total loss': 0.5009211420335553} | train loss {'Reaction outcome loss': 0.45904860831797123, 'Total loss': 0.45904860831797123}
2022-11-28 04:42:10,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:10,691 INFO:     Epoch: 66
2022-11-28 04:42:11,352 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4516910429705273, 'Total loss': 0.4516910429705273} | train loss {'Reaction outcome loss': 0.46590546797960997, 'Total loss': 0.46590546797960997}
2022-11-28 04:42:11,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:11,352 INFO:     Epoch: 67
2022-11-28 04:42:12,012 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4543634754690257, 'Total loss': 0.4543634754690257} | train loss {'Reaction outcome loss': 0.4647873742806335, 'Total loss': 0.4647873742806335}
2022-11-28 04:42:12,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:12,013 INFO:     Epoch: 68
2022-11-28 04:42:12,678 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47884112867442047, 'Total loss': 0.47884112867442047} | train loss {'Reaction outcome loss': 0.46378405290024893, 'Total loss': 0.46378405290024893}
2022-11-28 04:42:12,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:12,678 INFO:     Epoch: 69
2022-11-28 04:42:13,344 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4806953990323977, 'Total loss': 0.4806953990323977} | train loss {'Reaction outcome loss': 0.46371747388113893, 'Total loss': 0.46371747388113893}
2022-11-28 04:42:13,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:13,344 INFO:     Epoch: 70
2022-11-28 04:42:14,006 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4590193995020606, 'Total loss': 0.4590193995020606} | train loss {'Reaction outcome loss': 0.4615798594970857, 'Total loss': 0.4615798594970857}
2022-11-28 04:42:14,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:14,006 INFO:     Epoch: 71
2022-11-28 04:42:14,668 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4674511152234944, 'Total loss': 0.4674511152234944} | train loss {'Reaction outcome loss': 0.46211321369534536, 'Total loss': 0.46211321369534536}
2022-11-28 04:42:14,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:14,668 INFO:     Epoch: 72
2022-11-28 04:42:15,332 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46678251976316626, 'Total loss': 0.46678251976316626} | train loss {'Reaction outcome loss': 0.46574566369095155, 'Total loss': 0.46574566369095155}
2022-11-28 04:42:15,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:15,332 INFO:     Epoch: 73
2022-11-28 04:42:15,993 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46366096897558734, 'Total loss': 0.46366096897558734} | train loss {'Reaction outcome loss': 0.46050481945877114, 'Total loss': 0.46050481945877114}
2022-11-28 04:42:15,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:15,993 INFO:     Epoch: 74
2022-11-28 04:42:16,661 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45776094259186223, 'Total loss': 0.45776094259186223} | train loss {'Reaction outcome loss': 0.46059181451076464, 'Total loss': 0.46059181451076464}
2022-11-28 04:42:16,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:16,662 INFO:     Epoch: 75
2022-11-28 04:42:17,326 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4372390474785458, 'Total loss': 0.4372390474785458} | train loss {'Reaction outcome loss': 0.4638825455199807, 'Total loss': 0.4638825455199807}
2022-11-28 04:42:17,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:17,326 INFO:     Epoch: 76
2022-11-28 04:42:17,991 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4467335563491691, 'Total loss': 0.4467335563491691} | train loss {'Reaction outcome loss': 0.46113157969328666, 'Total loss': 0.46113157969328666}
2022-11-28 04:42:17,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:17,991 INFO:     Epoch: 77
2022-11-28 04:42:18,655 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46311134709553287, 'Total loss': 0.46311134709553287} | train loss {'Reaction outcome loss': 0.4610386812879193, 'Total loss': 0.4610386812879193}
2022-11-28 04:42:18,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:18,655 INFO:     Epoch: 78
2022-11-28 04:42:19,321 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.462000175294551, 'Total loss': 0.462000175294551} | train loss {'Reaction outcome loss': 0.46756471858750426, 'Total loss': 0.46756471858750426}
2022-11-28 04:42:19,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:19,321 INFO:     Epoch: 79
2022-11-28 04:42:19,989 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44981206343932584, 'Total loss': 0.44981206343932584} | train loss {'Reaction outcome loss': 0.46645344244015796, 'Total loss': 0.46645344244015796}
2022-11-28 04:42:19,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:19,990 INFO:     Epoch: 80
2022-11-28 04:42:20,660 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5407233461737633, 'Total loss': 0.5407233461737633} | train loss {'Reaction outcome loss': 0.45582051319821226, 'Total loss': 0.45582051319821226}
2022-11-28 04:42:20,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:20,660 INFO:     Epoch: 81
2022-11-28 04:42:21,328 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43587038022550667, 'Total loss': 0.43587038022550667} | train loss {'Reaction outcome loss': 0.4669144005785065, 'Total loss': 0.4669144005785065}
2022-11-28 04:42:21,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:21,329 INFO:     Epoch: 82
2022-11-28 04:42:21,994 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.457277158444578, 'Total loss': 0.457277158444578} | train loss {'Reaction outcome loss': 0.4659612093481325, 'Total loss': 0.4659612093481325}
2022-11-28 04:42:21,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:21,994 INFO:     Epoch: 83
2022-11-28 04:42:22,657 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4639690250835635, 'Total loss': 0.4639690250835635} | train loss {'Reaction outcome loss': 0.45848814872724397, 'Total loss': 0.45848814872724397}
2022-11-28 04:42:22,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:22,657 INFO:     Epoch: 84
2022-11-28 04:42:23,321 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4497342648153955, 'Total loss': 0.4497342648153955} | train loss {'Reaction outcome loss': 0.4634024126515273, 'Total loss': 0.4634024126515273}
2022-11-28 04:42:23,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:23,322 INFO:     Epoch: 85
2022-11-28 04:42:23,987 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49641253596002405, 'Total loss': 0.49641253596002405} | train loss {'Reaction outcome loss': 0.4673672415496361, 'Total loss': 0.4673672415496361}
2022-11-28 04:42:23,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:23,987 INFO:     Epoch: 86
2022-11-28 04:42:24,650 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.490899981084195, 'Total loss': 0.490899981084195} | train loss {'Reaction outcome loss': 0.4638874681005555, 'Total loss': 0.4638874681005555}
2022-11-28 04:42:24,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:24,651 INFO:     Epoch: 87
2022-11-28 04:42:25,313 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49844700436700473, 'Total loss': 0.49844700436700473} | train loss {'Reaction outcome loss': 0.45524456784609824, 'Total loss': 0.45524456784609824}
2022-11-28 04:42:25,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:25,313 INFO:     Epoch: 88
2022-11-28 04:42:25,976 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.463955042545091, 'Total loss': 0.463955042545091} | train loss {'Reaction outcome loss': 0.46650188007662374, 'Total loss': 0.46650188007662374}
2022-11-28 04:42:25,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:25,976 INFO:     Epoch: 89
2022-11-28 04:42:26,639 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4647357413037257, 'Total loss': 0.4647357413037257} | train loss {'Reaction outcome loss': 0.4599282366013335, 'Total loss': 0.4599282366013335}
2022-11-28 04:42:26,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:26,639 INFO:     Epoch: 90
2022-11-28 04:42:27,305 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4747239463031292, 'Total loss': 0.4747239463031292} | train loss {'Reaction outcome loss': 0.45904954288515354, 'Total loss': 0.45904954288515354}
2022-11-28 04:42:27,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:27,305 INFO:     Epoch: 91
2022-11-28 04:42:27,972 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4511941915208643, 'Total loss': 0.4511941915208643} | train loss {'Reaction outcome loss': 0.4649879409661216, 'Total loss': 0.4649879409661216}
2022-11-28 04:42:27,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:27,972 INFO:     Epoch: 92
2022-11-28 04:42:28,640 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4759251211177219, 'Total loss': 0.4759251211177219} | train loss {'Reaction outcome loss': 0.46810590830301085, 'Total loss': 0.46810590830301085}
2022-11-28 04:42:28,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:28,640 INFO:     Epoch: 93
2022-11-28 04:42:29,309 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48409834334796126, 'Total loss': 0.48409834334796126} | train loss {'Reaction outcome loss': 0.45847987626949627, 'Total loss': 0.45847987626949627}
2022-11-28 04:42:29,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:29,309 INFO:     Epoch: 94
2022-11-28 04:42:29,978 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46605636043982074, 'Total loss': 0.46605636043982074} | train loss {'Reaction outcome loss': 0.4610243682118674, 'Total loss': 0.4610243682118674}
2022-11-28 04:42:29,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:29,978 INFO:     Epoch: 95
2022-11-28 04:42:30,639 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4731992408633232, 'Total loss': 0.4731992408633232} | train loss {'Reaction outcome loss': 0.459157386554345, 'Total loss': 0.459157386554345}
2022-11-28 04:42:30,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:30,640 INFO:     Epoch: 96
2022-11-28 04:42:31,303 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46827040206302295, 'Total loss': 0.46827040206302295} | train loss {'Reaction outcome loss': 0.46551851534675204, 'Total loss': 0.46551851534675204}
2022-11-28 04:42:31,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:31,303 INFO:     Epoch: 97
2022-11-28 04:42:31,963 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.473451167345047, 'Total loss': 0.473451167345047} | train loss {'Reaction outcome loss': 0.4641236099264314, 'Total loss': 0.4641236099264314}
2022-11-28 04:42:31,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:31,964 INFO:     Epoch: 98
2022-11-28 04:42:32,624 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45869059759107506, 'Total loss': 0.45869059759107506} | train loss {'Reaction outcome loss': 0.4683618424159865, 'Total loss': 0.4683618424159865}
2022-11-28 04:42:32,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:32,624 INFO:     Epoch: 99
2022-11-28 04:42:33,290 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4666924679821188, 'Total loss': 0.4666924679821188} | train loss {'Reaction outcome loss': 0.4665317915740513, 'Total loss': 0.4665317915740513}
2022-11-28 04:42:33,291 INFO:     Best model found after epoch 37 of 100.
2022-11-28 04:42:33,291 INFO:   Done with stage: TRAINING
2022-11-28 04:42:33,291 INFO:   Starting stage: EVALUATION
2022-11-28 04:42:33,405 INFO:   Done with stage: EVALUATION
2022-11-28 04:42:33,405 INFO:   Leaving out SEQ value Fold_9
2022-11-28 04:42:33,418 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:42:33,418 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:42:34,073 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:42:34,074 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:42:34,141 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:42:34,142 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:42:34,142 INFO:     No hyperparam tuning for this model
2022-11-28 04:42:34,142 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:42:34,142 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:42:34,142 INFO:     None feature selector for col prot
2022-11-28 04:42:34,143 INFO:     None feature selector for col prot
2022-11-28 04:42:34,143 INFO:     None feature selector for col prot
2022-11-28 04:42:34,143 INFO:     None feature selector for col chem
2022-11-28 04:42:34,143 INFO:     None feature selector for col chem
2022-11-28 04:42:34,143 INFO:     None feature selector for col chem
2022-11-28 04:42:34,143 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:42:34,143 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:42:34,145 INFO:     Number of params in model 169651
2022-11-28 04:42:34,148 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:42:34,148 INFO:   Starting stage: TRAINING
2022-11-28 04:42:34,199 INFO:     Val loss before train {'Reaction outcome loss': 1.0069073370911859, 'Total loss': 1.0069073370911859}
2022-11-28 04:42:34,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:34,200 INFO:     Epoch: 0
2022-11-28 04:42:34,859 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5740994695912708, 'Total loss': 0.5740994695912708} | train loss {'Reaction outcome loss': 0.704725546121356, 'Total loss': 0.704725546121356}
2022-11-28 04:42:34,859 INFO:     Found new best model at epoch 0
2022-11-28 04:42:34,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:34,860 INFO:     Epoch: 1
2022-11-28 04:42:35,521 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5627581294287335, 'Total loss': 0.5627581294287335} | train loss {'Reaction outcome loss': 0.5964764979392713, 'Total loss': 0.5964764979392713}
2022-11-28 04:42:35,521 INFO:     Found new best model at epoch 1
2022-11-28 04:42:35,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:35,522 INFO:     Epoch: 2
2022-11-28 04:42:36,179 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49210938675837085, 'Total loss': 0.49210938675837085} | train loss {'Reaction outcome loss': 0.5635601398553926, 'Total loss': 0.5635601398553926}
2022-11-28 04:42:36,179 INFO:     Found new best model at epoch 2
2022-11-28 04:42:36,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:36,180 INFO:     Epoch: 3
2022-11-28 04:42:36,835 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4720568518069657, 'Total loss': 0.4720568518069657} | train loss {'Reaction outcome loss': 0.5381216581171824, 'Total loss': 0.5381216581171824}
2022-11-28 04:42:36,835 INFO:     Found new best model at epoch 3
2022-11-28 04:42:36,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:36,836 INFO:     Epoch: 4
2022-11-28 04:42:37,494 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48163483799858525, 'Total loss': 0.48163483799858525} | train loss {'Reaction outcome loss': 0.5361614322161626, 'Total loss': 0.5361614322161626}
2022-11-28 04:42:37,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:37,494 INFO:     Epoch: 5
2022-11-28 04:42:38,154 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4861733378334479, 'Total loss': 0.4861733378334479} | train loss {'Reaction outcome loss': 0.5130844489230137, 'Total loss': 0.5130844489230137}
2022-11-28 04:42:38,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:38,155 INFO:     Epoch: 6
2022-11-28 04:42:38,812 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5075292597440156, 'Total loss': 0.5075292597440156} | train loss {'Reaction outcome loss': 0.5150644764726461, 'Total loss': 0.5150644764726461}
2022-11-28 04:42:38,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:38,812 INFO:     Epoch: 7
2022-11-28 04:42:39,469 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.507008858025074, 'Total loss': 0.507008858025074} | train loss {'Reaction outcome loss': 0.5156271597031157, 'Total loss': 0.5156271597031157}
2022-11-28 04:42:39,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:39,469 INFO:     Epoch: 8
2022-11-28 04:42:40,129 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4763954390179027, 'Total loss': 0.4763954390179027} | train loss {'Reaction outcome loss': 0.5038014834950327, 'Total loss': 0.5038014834950327}
2022-11-28 04:42:40,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:40,129 INFO:     Epoch: 9
2022-11-28 04:42:40,788 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4583899819038131, 'Total loss': 0.4583899819038131} | train loss {'Reaction outcome loss': 0.5202949847648983, 'Total loss': 0.5202949847648983}
2022-11-28 04:42:40,789 INFO:     Found new best model at epoch 9
2022-11-28 04:42:40,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:40,789 INFO:     Epoch: 10
2022-11-28 04:42:41,445 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5465148314833641, 'Total loss': 0.5465148314833641} | train loss {'Reaction outcome loss': 0.49549915624955887, 'Total loss': 0.49549915624955887}
2022-11-28 04:42:41,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:41,445 INFO:     Epoch: 11
2022-11-28 04:42:42,103 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.464475713331591, 'Total loss': 0.464475713331591} | train loss {'Reaction outcome loss': 0.49412326712579835, 'Total loss': 0.49412326712579835}
2022-11-28 04:42:42,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:42,103 INFO:     Epoch: 12
2022-11-28 04:42:42,762 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4568767864257097, 'Total loss': 0.4568767864257097} | train loss {'Reaction outcome loss': 0.485126495964614, 'Total loss': 0.485126495964614}
2022-11-28 04:42:42,762 INFO:     Found new best model at epoch 12
2022-11-28 04:42:42,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:42,763 INFO:     Epoch: 13
2022-11-28 04:42:43,422 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4433332878080281, 'Total loss': 0.4433332878080281} | train loss {'Reaction outcome loss': 0.4893008526037579, 'Total loss': 0.4893008526037579}
2022-11-28 04:42:43,422 INFO:     Found new best model at epoch 13
2022-11-28 04:42:43,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:43,423 INFO:     Epoch: 14
2022-11-28 04:42:44,082 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45600949363275006, 'Total loss': 0.45600949363275006} | train loss {'Reaction outcome loss': 0.48139275676808374, 'Total loss': 0.48139275676808374}
2022-11-28 04:42:44,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:44,082 INFO:     Epoch: 15
2022-11-28 04:42:44,742 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48362506248734216, 'Total loss': 0.48362506248734216} | train loss {'Reaction outcome loss': 0.48074466104690844, 'Total loss': 0.48074466104690844}
2022-11-28 04:42:44,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:44,742 INFO:     Epoch: 16
2022-11-28 04:42:45,402 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4709587666121396, 'Total loss': 0.4709587666121396} | train loss {'Reaction outcome loss': 0.4847163299799931, 'Total loss': 0.4847163299799931}
2022-11-28 04:42:45,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:45,402 INFO:     Epoch: 17
2022-11-28 04:42:46,061 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4435839798640121, 'Total loss': 0.4435839798640121} | train loss {'Reaction outcome loss': 0.4816405352898817, 'Total loss': 0.4816405352898817}
2022-11-28 04:42:46,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:46,061 INFO:     Epoch: 18
2022-11-28 04:42:46,719 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44238976219838316, 'Total loss': 0.44238976219838316} | train loss {'Reaction outcome loss': 0.47710041339822146, 'Total loss': 0.47710041339822146}
2022-11-28 04:42:46,719 INFO:     Found new best model at epoch 18
2022-11-28 04:42:46,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:46,720 INFO:     Epoch: 19
2022-11-28 04:42:47,381 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44496083157983696, 'Total loss': 0.44496083157983696} | train loss {'Reaction outcome loss': 0.4848652697255013, 'Total loss': 0.4848652697255013}
2022-11-28 04:42:47,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:47,381 INFO:     Epoch: 20
2022-11-28 04:42:48,037 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44770008427175606, 'Total loss': 0.44770008427175606} | train loss {'Reaction outcome loss': 0.471894371530667, 'Total loss': 0.471894371530667}
2022-11-28 04:42:48,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:48,038 INFO:     Epoch: 21
2022-11-28 04:42:48,694 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45782755789431656, 'Total loss': 0.45782755789431656} | train loss {'Reaction outcome loss': 0.4723858808729089, 'Total loss': 0.4723858808729089}
2022-11-28 04:42:48,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:48,694 INFO:     Epoch: 22
2022-11-28 04:42:49,350 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.454487026415088, 'Total loss': 0.454487026415088} | train loss {'Reaction outcome loss': 0.474998799171525, 'Total loss': 0.474998799171525}
2022-11-28 04:42:49,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:49,350 INFO:     Epoch: 23
2022-11-28 04:42:50,009 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4615448039363731, 'Total loss': 0.4615448039363731} | train loss {'Reaction outcome loss': 0.481702392641832, 'Total loss': 0.481702392641832}
2022-11-28 04:42:50,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:50,010 INFO:     Epoch: 24
2022-11-28 04:42:50,671 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44474849629808555, 'Total loss': 0.44474849629808555} | train loss {'Reaction outcome loss': 0.47481531345168587, 'Total loss': 0.47481531345168587}
2022-11-28 04:42:50,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:50,672 INFO:     Epoch: 25
2022-11-28 04:42:51,332 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.437376814132387, 'Total loss': 0.437376814132387} | train loss {'Reaction outcome loss': 0.4795780517311714, 'Total loss': 0.4795780517311714}
2022-11-28 04:42:51,333 INFO:     Found new best model at epoch 25
2022-11-28 04:42:51,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:51,333 INFO:     Epoch: 26
2022-11-28 04:42:51,994 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43923167647285893, 'Total loss': 0.43923167647285893} | train loss {'Reaction outcome loss': 0.48698557316050356, 'Total loss': 0.48698557316050356}
2022-11-28 04:42:51,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:51,994 INFO:     Epoch: 27
2022-11-28 04:42:52,652 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4283115623349493, 'Total loss': 0.4283115623349493} | train loss {'Reaction outcome loss': 0.4769800474286562, 'Total loss': 0.4769800474286562}
2022-11-28 04:42:52,652 INFO:     Found new best model at epoch 27
2022-11-28 04:42:52,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:52,653 INFO:     Epoch: 28
2022-11-28 04:42:53,312 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4667310352352532, 'Total loss': 0.4667310352352532} | train loss {'Reaction outcome loss': 0.46891484023467733, 'Total loss': 0.46891484023467733}
2022-11-28 04:42:53,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:53,312 INFO:     Epoch: 29
2022-11-28 04:42:53,976 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4626319103620269, 'Total loss': 0.4626319103620269} | train loss {'Reaction outcome loss': 0.47940396448137307, 'Total loss': 0.47940396448137307}
2022-11-28 04:42:53,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:53,976 INFO:     Epoch: 30
2022-11-28 04:42:54,638 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4365016066215255, 'Total loss': 0.4365016066215255} | train loss {'Reaction outcome loss': 0.48270887510496596, 'Total loss': 0.48270887510496596}
2022-11-28 04:42:54,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:54,639 INFO:     Epoch: 31
2022-11-28 04:42:55,300 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44987923550334846, 'Total loss': 0.44987923550334846} | train loss {'Reaction outcome loss': 0.47097927880914586, 'Total loss': 0.47097927880914586}
2022-11-28 04:42:55,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:55,301 INFO:     Epoch: 32
2022-11-28 04:42:55,960 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4745869299566204, 'Total loss': 0.4745869299566204} | train loss {'Reaction outcome loss': 0.47565130274064144, 'Total loss': 0.47565130274064144}
2022-11-28 04:42:55,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:55,960 INFO:     Epoch: 33
2022-11-28 04:42:56,621 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4470632607963952, 'Total loss': 0.4470632607963952} | train loss {'Reaction outcome loss': 0.4927924538129254, 'Total loss': 0.4927924538129254}
2022-11-28 04:42:56,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:56,621 INFO:     Epoch: 34
2022-11-28 04:42:57,279 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4442068155516278, 'Total loss': 0.4442068155516278} | train loss {'Reaction outcome loss': 0.46955649809334954, 'Total loss': 0.46955649809334954}
2022-11-28 04:42:57,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:57,279 INFO:     Epoch: 35
2022-11-28 04:42:57,941 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.441016353497451, 'Total loss': 0.441016353497451} | train loss {'Reaction outcome loss': 0.47033533996898635, 'Total loss': 0.47033533996898635}
2022-11-28 04:42:57,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:57,942 INFO:     Epoch: 36
2022-11-28 04:42:58,597 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4406850046732209, 'Total loss': 0.4406850046732209} | train loss {'Reaction outcome loss': 0.47525498022887147, 'Total loss': 0.47525498022887147}
2022-11-28 04:42:58,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:58,597 INFO:     Epoch: 37
2022-11-28 04:42:59,256 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5062119486657056, 'Total loss': 0.5062119486657056} | train loss {'Reaction outcome loss': 0.47562982424950373, 'Total loss': 0.47562982424950373}
2022-11-28 04:42:59,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:59,256 INFO:     Epoch: 38
2022-11-28 04:42:59,915 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46484326368028467, 'Total loss': 0.46484326368028467} | train loss {'Reaction outcome loss': 0.4645576211906638, 'Total loss': 0.4645576211906638}
2022-11-28 04:42:59,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:42:59,915 INFO:     Epoch: 39
2022-11-28 04:43:00,575 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4632010720670223, 'Total loss': 0.4632010720670223} | train loss {'Reaction outcome loss': 0.48527363190042827, 'Total loss': 0.48527363190042827}
2022-11-28 04:43:00,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:00,575 INFO:     Epoch: 40
2022-11-28 04:43:01,234 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4204502288590778, 'Total loss': 0.4204502288590778} | train loss {'Reaction outcome loss': 0.47476175155958183, 'Total loss': 0.47476175155958183}
2022-11-28 04:43:01,234 INFO:     Found new best model at epoch 40
2022-11-28 04:43:01,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:01,235 INFO:     Epoch: 41
2022-11-28 04:43:01,897 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4768763015216047, 'Total loss': 0.4768763015216047} | train loss {'Reaction outcome loss': 0.47266704809704896, 'Total loss': 0.47266704809704896}
2022-11-28 04:43:01,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:01,898 INFO:     Epoch: 42
2022-11-28 04:43:02,558 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44172015007246623, 'Total loss': 0.44172015007246623} | train loss {'Reaction outcome loss': 0.4718363544175982, 'Total loss': 0.4718363544175982}
2022-11-28 04:43:02,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:02,558 INFO:     Epoch: 43
2022-11-28 04:43:03,219 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4402880604294213, 'Total loss': 0.4402880604294213} | train loss {'Reaction outcome loss': 0.47018482533815176, 'Total loss': 0.47018482533815176}
2022-11-28 04:43:03,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:03,220 INFO:     Epoch: 44
2022-11-28 04:43:03,879 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46354912797158415, 'Total loss': 0.46354912797158415} | train loss {'Reaction outcome loss': 0.4678827871376204, 'Total loss': 0.4678827871376204}
2022-11-28 04:43:03,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:03,879 INFO:     Epoch: 45
2022-11-28 04:43:04,540 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4771841476586732, 'Total loss': 0.4771841476586732} | train loss {'Reaction outcome loss': 0.4757970849029448, 'Total loss': 0.4757970849029448}
2022-11-28 04:43:04,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:04,541 INFO:     Epoch: 46
2022-11-28 04:43:05,204 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4443731521340934, 'Total loss': 0.4443731521340934} | train loss {'Reaction outcome loss': 0.4774191099622472, 'Total loss': 0.4774191099622472}
2022-11-28 04:43:05,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:05,204 INFO:     Epoch: 47
2022-11-28 04:43:05,867 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4569599178027023, 'Total loss': 0.4569599178027023} | train loss {'Reaction outcome loss': 0.4753424753302987, 'Total loss': 0.4753424753302987}
2022-11-28 04:43:05,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:05,867 INFO:     Epoch: 48
2022-11-28 04:43:06,529 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45061229982159356, 'Total loss': 0.45061229982159356} | train loss {'Reaction outcome loss': 0.47439531595842077, 'Total loss': 0.47439531595842077}
2022-11-28 04:43:06,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:06,529 INFO:     Epoch: 49
2022-11-28 04:43:07,189 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4526090171526779, 'Total loss': 0.4526090171526779} | train loss {'Reaction outcome loss': 0.47080281358740106, 'Total loss': 0.47080281358740106}
2022-11-28 04:43:07,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:07,189 INFO:     Epoch: 50
2022-11-28 04:43:07,849 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4613431714136492, 'Total loss': 0.4613431714136492} | train loss {'Reaction outcome loss': 0.4790035623770494, 'Total loss': 0.4790035623770494}
2022-11-28 04:43:07,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:07,849 INFO:     Epoch: 51
2022-11-28 04:43:08,507 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44848997247490013, 'Total loss': 0.44848997247490013} | train loss {'Reaction outcome loss': 0.4711815678412736, 'Total loss': 0.4711815678412736}
2022-11-28 04:43:08,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:08,507 INFO:     Epoch: 52
2022-11-28 04:43:09,166 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45982512696222827, 'Total loss': 0.45982512696222827} | train loss {'Reaction outcome loss': 0.46757672021263524, 'Total loss': 0.46757672021263524}
2022-11-28 04:43:09,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:09,166 INFO:     Epoch: 53
2022-11-28 04:43:09,827 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41988143528049643, 'Total loss': 0.41988143528049643} | train loss {'Reaction outcome loss': 0.48121983729876006, 'Total loss': 0.48121983729876006}
2022-11-28 04:43:09,828 INFO:     Found new best model at epoch 53
2022-11-28 04:43:09,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:09,828 INFO:     Epoch: 54
2022-11-28 04:43:10,485 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4645946581255306, 'Total loss': 0.4645946581255306} | train loss {'Reaction outcome loss': 0.4796080434853249, 'Total loss': 0.4796080434853249}
2022-11-28 04:43:10,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:10,486 INFO:     Epoch: 55
2022-11-28 04:43:11,143 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4825489724224264, 'Total loss': 0.4825489724224264} | train loss {'Reaction outcome loss': 0.47106511194093026, 'Total loss': 0.47106511194093026}
2022-11-28 04:43:11,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:11,144 INFO:     Epoch: 56
2022-11-28 04:43:11,806 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4518517249009826, 'Total loss': 0.4518517249009826} | train loss {'Reaction outcome loss': 0.48267446425158966, 'Total loss': 0.48267446425158966}
2022-11-28 04:43:11,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:11,807 INFO:     Epoch: 57
2022-11-28 04:43:12,466 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4702875167131424, 'Total loss': 0.4702875167131424} | train loss {'Reaction outcome loss': 0.494193381143485, 'Total loss': 0.494193381143485}
2022-11-28 04:43:12,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:12,466 INFO:     Epoch: 58
2022-11-28 04:43:13,122 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4437009851363572, 'Total loss': 0.4437009851363572} | train loss {'Reaction outcome loss': 0.4755838787869403, 'Total loss': 0.4755838787869403}
2022-11-28 04:43:13,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:13,122 INFO:     Epoch: 59
2022-11-28 04:43:13,780 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4461536854505539, 'Total loss': 0.4461536854505539} | train loss {'Reaction outcome loss': 0.47425207046241413, 'Total loss': 0.47425207046241413}
2022-11-28 04:43:13,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:13,780 INFO:     Epoch: 60
2022-11-28 04:43:14,441 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4518228942020373, 'Total loss': 0.4518228942020373} | train loss {'Reaction outcome loss': 0.4779700399772358, 'Total loss': 0.4779700399772358}
2022-11-28 04:43:14,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:14,441 INFO:     Epoch: 61
2022-11-28 04:43:15,100 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44245179065249185, 'Total loss': 0.44245179065249185} | train loss {'Reaction outcome loss': 0.47783954637615306, 'Total loss': 0.47783954637615306}
2022-11-28 04:43:15,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:15,100 INFO:     Epoch: 62
2022-11-28 04:43:15,762 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4432931190187281, 'Total loss': 0.4432931190187281} | train loss {'Reaction outcome loss': 0.4891479961302599, 'Total loss': 0.4891479961302599}
2022-11-28 04:43:15,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:15,763 INFO:     Epoch: 63
2022-11-28 04:43:16,428 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4804519059305841, 'Total loss': 0.4804519059305841} | train loss {'Reaction outcome loss': 0.4846789944871717, 'Total loss': 0.4846789944871717}
2022-11-28 04:43:16,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:16,429 INFO:     Epoch: 64
2022-11-28 04:43:17,085 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5042313435538248, 'Total loss': 0.5042313435538248} | train loss {'Reaction outcome loss': 0.5395428461705142, 'Total loss': 0.5395428461705142}
2022-11-28 04:43:17,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:17,085 INFO:     Epoch: 65
2022-11-28 04:43:17,745 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45522518117319455, 'Total loss': 0.45522518117319455} | train loss {'Reaction outcome loss': 0.5000094024517275, 'Total loss': 0.5000094024517275}
2022-11-28 04:43:17,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:17,745 INFO:     Epoch: 66
2022-11-28 04:43:18,400 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44532458551905374, 'Total loss': 0.44532458551905374} | train loss {'Reaction outcome loss': 0.4779936607534948, 'Total loss': 0.4779936607534948}
2022-11-28 04:43:18,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:18,401 INFO:     Epoch: 67
2022-11-28 04:43:19,056 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5060339996760542, 'Total loss': 0.5060339996760542} | train loss {'Reaction outcome loss': 0.4783047491058647, 'Total loss': 0.4783047491058647}
2022-11-28 04:43:19,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:19,056 INFO:     Epoch: 68
2022-11-28 04:43:19,716 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.50843441283161, 'Total loss': 0.50843441283161} | train loss {'Reaction outcome loss': 0.49575118126294876, 'Total loss': 0.49575118126294876}
2022-11-28 04:43:19,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:19,717 INFO:     Epoch: 69
2022-11-28 04:43:20,376 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44696341759779235, 'Total loss': 0.44696341759779235} | train loss {'Reaction outcome loss': 0.49604394211460223, 'Total loss': 0.49604394211460223}
2022-11-28 04:43:20,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:20,376 INFO:     Epoch: 70
2022-11-28 04:43:21,035 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44744282351298764, 'Total loss': 0.44744282351298764} | train loss {'Reaction outcome loss': 0.4827400010629644, 'Total loss': 0.4827400010629644}
2022-11-28 04:43:21,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:21,035 INFO:     Epoch: 71
2022-11-28 04:43:21,688 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43993124094876374, 'Total loss': 0.43993124094876374} | train loss {'Reaction outcome loss': 0.4850531073234342, 'Total loss': 0.4850531073234342}
2022-11-28 04:43:21,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:21,688 INFO:     Epoch: 72
2022-11-28 04:43:22,344 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47960949824614957, 'Total loss': 0.47960949824614957} | train loss {'Reaction outcome loss': 0.4747653924483006, 'Total loss': 0.4747653924483006}
2022-11-28 04:43:22,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:22,345 INFO:     Epoch: 73
2022-11-28 04:43:23,001 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49626420031894336, 'Total loss': 0.49626420031894336} | train loss {'Reaction outcome loss': 0.4804455858734455, 'Total loss': 0.4804455858734455}
2022-11-28 04:43:23,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:23,002 INFO:     Epoch: 74
2022-11-28 04:43:23,656 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44457885893908416, 'Total loss': 0.44457885893908416} | train loss {'Reaction outcome loss': 0.4877081628934092, 'Total loss': 0.4877081628934092}
2022-11-28 04:43:23,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:23,657 INFO:     Epoch: 75
2022-11-28 04:43:24,309 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4302961521527984, 'Total loss': 0.4302961521527984} | train loss {'Reaction outcome loss': 0.4928157276168526, 'Total loss': 0.4928157276168526}
2022-11-28 04:43:24,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:24,309 INFO:     Epoch: 76
2022-11-28 04:43:24,965 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4452927800064737, 'Total loss': 0.4452927800064737} | train loss {'Reaction outcome loss': 0.4865093733738308, 'Total loss': 0.4865093733738308}
2022-11-28 04:43:24,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:24,965 INFO:     Epoch: 77
2022-11-28 04:43:25,622 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4553261585533619, 'Total loss': 0.4553261585533619} | train loss {'Reaction outcome loss': 0.47558420274014535, 'Total loss': 0.47558420274014535}
2022-11-28 04:43:25,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:25,622 INFO:     Epoch: 78
2022-11-28 04:43:26,277 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4718953005292199, 'Total loss': 0.4718953005292199} | train loss {'Reaction outcome loss': 0.48488458122319056, 'Total loss': 0.48488458122319056}
2022-11-28 04:43:26,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:26,278 INFO:     Epoch: 79
2022-11-28 04:43:26,932 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4415108726613901, 'Total loss': 0.4415108726613901} | train loss {'Reaction outcome loss': 0.47891176890144466, 'Total loss': 0.47891176890144466}
2022-11-28 04:43:26,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:26,932 INFO:     Epoch: 80
2022-11-28 04:43:27,589 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45274918763474986, 'Total loss': 0.45274918763474986} | train loss {'Reaction outcome loss': 0.47772564597216693, 'Total loss': 0.47772564597216693}
2022-11-28 04:43:27,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:27,589 INFO:     Epoch: 81
2022-11-28 04:43:28,248 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4382876298305663, 'Total loss': 0.4382876298305663} | train loss {'Reaction outcome loss': 0.48412329000741366, 'Total loss': 0.48412329000741366}
2022-11-28 04:43:28,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:28,248 INFO:     Epoch: 82
2022-11-28 04:43:28,907 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5005791776559569, 'Total loss': 0.5005791776559569} | train loss {'Reaction outcome loss': 0.47153601870845685, 'Total loss': 0.47153601870845685}
2022-11-28 04:43:28,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:28,907 INFO:     Epoch: 83
2022-11-28 04:43:29,564 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4779843721877445, 'Total loss': 0.4779843721877445} | train loss {'Reaction outcome loss': 0.4766112019445536, 'Total loss': 0.4766112019445536}
2022-11-28 04:43:29,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:29,565 INFO:     Epoch: 84
2022-11-28 04:43:30,223 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45010805130004883, 'Total loss': 0.45010805130004883} | train loss {'Reaction outcome loss': 0.4785936222023327, 'Total loss': 0.4785936222023327}
2022-11-28 04:43:30,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:30,224 INFO:     Epoch: 85
2022-11-28 04:43:30,882 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45937272533774376, 'Total loss': 0.45937272533774376} | train loss {'Reaction outcome loss': 0.4837080934028394, 'Total loss': 0.4837080934028394}
2022-11-28 04:43:30,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:30,882 INFO:     Epoch: 86
2022-11-28 04:43:31,539 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.481476522304795, 'Total loss': 0.481476522304795} | train loss {'Reaction outcome loss': 0.48090805749782184, 'Total loss': 0.48090805749782184}
2022-11-28 04:43:31,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:31,539 INFO:     Epoch: 87
2022-11-28 04:43:32,197 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4390301806005565, 'Total loss': 0.4390301806005565} | train loss {'Reaction outcome loss': 0.48411852694474733, 'Total loss': 0.48411852694474733}
2022-11-28 04:43:32,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:32,197 INFO:     Epoch: 88
2022-11-28 04:43:32,857 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46880149909041147, 'Total loss': 0.46880149909041147} | train loss {'Reaction outcome loss': 0.4718407512362481, 'Total loss': 0.4718407512362481}
2022-11-28 04:43:32,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:32,857 INFO:     Epoch: 89
2022-11-28 04:43:33,515 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4412933899597688, 'Total loss': 0.4412933899597688} | train loss {'Reaction outcome loss': 0.47699809029155416, 'Total loss': 0.47699809029155416}
2022-11-28 04:43:33,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:33,515 INFO:     Epoch: 90
2022-11-28 04:43:34,171 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5038816928863525, 'Total loss': 0.5038816928863525} | train loss {'Reaction outcome loss': 0.47868000562133095, 'Total loss': 0.47868000562133095}
2022-11-28 04:43:34,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:34,171 INFO:     Epoch: 91
2022-11-28 04:43:34,831 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47279342433268373, 'Total loss': 0.47279342433268373} | train loss {'Reaction outcome loss': 0.49270690078677437, 'Total loss': 0.49270690078677437}
2022-11-28 04:43:34,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:34,832 INFO:     Epoch: 92
2022-11-28 04:43:35,487 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5243348475884307, 'Total loss': 0.5243348475884307} | train loss {'Reaction outcome loss': 0.480621816658298, 'Total loss': 0.480621816658298}
2022-11-28 04:43:35,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:35,488 INFO:     Epoch: 93
2022-11-28 04:43:36,142 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.448953434147618, 'Total loss': 0.448953434147618} | train loss {'Reaction outcome loss': 0.5137243454876216, 'Total loss': 0.5137243454876216}
2022-11-28 04:43:36,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:36,142 INFO:     Epoch: 94
2022-11-28 04:43:36,797 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4604739990424026, 'Total loss': 0.4604739990424026} | train loss {'Reaction outcome loss': 0.48799434399254893, 'Total loss': 0.48799434399254893}
2022-11-28 04:43:36,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:36,797 INFO:     Epoch: 95
2022-11-28 04:43:37,453 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4590464454482902, 'Total loss': 0.4590464454482902} | train loss {'Reaction outcome loss': 0.4836086214855615, 'Total loss': 0.4836086214855615}
2022-11-28 04:43:37,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:37,453 INFO:     Epoch: 96
2022-11-28 04:43:38,106 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4867057475176724, 'Total loss': 0.4867057475176724} | train loss {'Reaction outcome loss': 0.4846989432809807, 'Total loss': 0.4846989432809807}
2022-11-28 04:43:38,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:38,107 INFO:     Epoch: 97
2022-11-28 04:43:38,762 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49502585929903115, 'Total loss': 0.49502585929903115} | train loss {'Reaction outcome loss': 0.4986278848488804, 'Total loss': 0.4986278848488804}
2022-11-28 04:43:38,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:38,763 INFO:     Epoch: 98
2022-11-28 04:43:39,418 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44725867293097754, 'Total loss': 0.44725867293097754} | train loss {'Reaction outcome loss': 0.4849199527489994, 'Total loss': 0.4849199527489994}
2022-11-28 04:43:39,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:39,419 INFO:     Epoch: 99
2022-11-28 04:43:40,073 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4419318810105324, 'Total loss': 0.4419318810105324} | train loss {'Reaction outcome loss': 0.48531090555173395, 'Total loss': 0.48531090555173395}
2022-11-28 04:43:40,073 INFO:     Best model found after epoch 54 of 100.
2022-11-28 04:43:40,073 INFO:   Done with stage: TRAINING
2022-11-28 04:43:40,073 INFO:   Starting stage: EVALUATION
2022-11-28 04:43:40,193 INFO:   Done with stage: EVALUATION
2022-11-28 04:43:40,193 INFO: Done with stage: RUNNING SPLITS
2022-11-28 04:43:40,193 INFO: Starting stage: COMPUTE METRICS
2022-11-28 04:43:41,367 INFO: Done with stage: COMPUTE METRICS
2022-11-28 04:43:41,367 INFO: Starting stage: EXPORT RESULTS
2022-11-28 04:43:41,385 INFO:   Final results averaged over 50 folds: 
2022-11-28 04:43:41,388 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.189842           NaN  0.314733       NaN
2022-11-28 04:43:43,047 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-28 04:43:43,053 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-28 04:43:43,054 DEBUG:   interactive is False
2022-11-28 04:43:43,054 DEBUG:   platform is linux
2022-11-28 04:43:43,054 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-28 04:43:43,227 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-28 04:43:43,229 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-28 04:43:43,660 DEBUG:   Loaded backend agg version unknown.
2022-11-28 04:43:43,662 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 04:43:43,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,665 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,665 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 04:43:43,665 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,665 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,665 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,665 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 04:43:43,665 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,665 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 04:43:43,701 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-28 04:43:43,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 04:43:43,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,703 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 04:43:43,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,704 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 04:43:43,712 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 04:43:43,712 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,712 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,712 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,712 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,712 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 04:43:43,713 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,714 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 04:43:43,715 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 04:43:43,715 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,715 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,715 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 04:43:43,715 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 04:43:43,715 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 04:43:43,715 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 04:43:44,046 INFO: Done with stage: EXPORT RESULTS
2022-11-28 04:43:44,046 INFO: Starting stage: SAVE MODEL
2022-11-28 04:43:44,094 INFO: Done with stage: SAVE MODEL
2022-11-28 04:43:44,094 INFO: Wall time for program:  3334.38 seconds
