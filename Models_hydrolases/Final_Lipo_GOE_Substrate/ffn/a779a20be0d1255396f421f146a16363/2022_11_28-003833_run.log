2022-11-28 05:39:45,453 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/a779a20be0d1255396f421f146a16363/2022_11_28-003833",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "jtvae",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-28 05:39:45,464 INFO: Starting stage: BUILD FEATURIZERS
2022-11-28 05:39:45,470 INFO:   Creating esm representation model
2022-11-28 05:39:45,470 INFO:   Done esm representation model
2022-11-28 05:39:45,470 INFO: Done with stage: BUILD FEATURIZERS
2022-11-28 05:39:45,470 INFO: Starting stage: BUILDING DATASET
2022-11-28 05:39:45,523 INFO: Done with stage: BUILDING DATASET
2022-11-28 05:39:45,523 INFO: Starting stage: FEATURIZING DATA
2022-11-28 05:39:45,523 INFO:   Featurizing proteins
2022-11-28 05:39:45,525 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-28 05:39:45,542 INFO:   Loaded feature cache of size 204
2022-11-28 05:39:45,543 INFO:   Starting to pool ESM Embeddings
2022-11-28 05:39:45,638 INFO:   Featurizing molecules
2022-11-28 05:39:45,660 INFO: Done with stage: FEATURIZING DATA
2022-11-28 05:39:45,661 INFO: Starting stage: RUNNING SPLITS
2022-11-28 05:39:45,669 INFO:   Leaving out SEQ value Fold_0
2022-11-28 05:39:45,683 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 05:39:45,683 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:39:46,347 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:39:46,347 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:39:46,415 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:39:46,415 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:39:46,415 INFO:     No hyperparam tuning for this model
2022-11-28 05:39:46,415 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:39:46,416 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:39:46,416 INFO:     None feature selector for col prot
2022-11-28 05:39:46,416 INFO:     None feature selector for col prot
2022-11-28 05:39:46,416 INFO:     None feature selector for col prot
2022-11-28 05:39:46,417 INFO:     None feature selector for col chem
2022-11-28 05:39:46,417 INFO:     None feature selector for col chem
2022-11-28 05:39:46,417 INFO:     None feature selector for col chem
2022-11-28 05:39:46,417 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:39:46,417 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:39:46,419 INFO:     Number of params in model 169651
2022-11-28 05:39:46,419 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:39:46,419 INFO:   Starting stage: TRAINING
2022-11-28 05:39:48,452 INFO:     Val loss before train {'Reaction outcome loss': 1.060997061951216, 'Total loss': 1.060997061951216}
2022-11-28 05:39:48,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:48,453 INFO:     Epoch: 0
2022-11-28 05:39:49,106 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6247416665387708, 'Total loss': 0.6247416665387708} | train loss {'Reaction outcome loss': 0.6635712376627766, 'Total loss': 0.6635712376627766}
2022-11-28 05:39:49,106 INFO:     Found new best model at epoch 0
2022-11-28 05:39:49,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:49,107 INFO:     Epoch: 1
2022-11-28 05:39:49,758 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6193421115708906, 'Total loss': 0.6193421115708906} | train loss {'Reaction outcome loss': 0.5641042788009174, 'Total loss': 0.5641042788009174}
2022-11-28 05:39:49,758 INFO:     Found new best model at epoch 1
2022-11-28 05:39:49,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:49,759 INFO:     Epoch: 2
2022-11-28 05:39:50,405 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5639104461947153, 'Total loss': 0.5639104461947153} | train loss {'Reaction outcome loss': 0.5479060639856291, 'Total loss': 0.5479060639856291}
2022-11-28 05:39:50,405 INFO:     Found new best model at epoch 2
2022-11-28 05:39:50,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:50,406 INFO:     Epoch: 3
2022-11-28 05:39:51,060 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5946483910083771, 'Total loss': 0.5946483910083771} | train loss {'Reaction outcome loss': 0.5253008914286973, 'Total loss': 0.5253008914286973}
2022-11-28 05:39:51,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:51,060 INFO:     Epoch: 4
2022-11-28 05:39:51,711 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5435739724442016, 'Total loss': 0.5435739724442016} | train loss {'Reaction outcome loss': 0.5175360962748528, 'Total loss': 0.5175360962748528}
2022-11-28 05:39:51,711 INFO:     Found new best model at epoch 4
2022-11-28 05:39:51,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:51,712 INFO:     Epoch: 5
2022-11-28 05:39:52,360 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5439750746239064, 'Total loss': 0.5439750746239064} | train loss {'Reaction outcome loss': 0.498702810130647, 'Total loss': 0.498702810130647}
2022-11-28 05:39:52,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:52,360 INFO:     Epoch: 6
2022-11-28 05:39:53,011 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5485426395438439, 'Total loss': 0.5485426395438439} | train loss {'Reaction outcome loss': 0.5014608695370252, 'Total loss': 0.5014608695370252}
2022-11-28 05:39:53,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:53,011 INFO:     Epoch: 7
2022-11-28 05:39:53,659 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5346345499504445, 'Total loss': 0.5346345499504445} | train loss {'Reaction outcome loss': 0.4877107666164148, 'Total loss': 0.4877107666164148}
2022-11-28 05:39:53,659 INFO:     Found new best model at epoch 7
2022-11-28 05:39:53,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:53,660 INFO:     Epoch: 8
2022-11-28 05:39:54,308 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.511253023909968, 'Total loss': 0.511253023909968} | train loss {'Reaction outcome loss': 0.48530458017695144, 'Total loss': 0.48530458017695144}
2022-11-28 05:39:54,308 INFO:     Found new best model at epoch 8
2022-11-28 05:39:54,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:54,309 INFO:     Epoch: 9
2022-11-28 05:39:54,962 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5353791914707007, 'Total loss': 0.5353791914707007} | train loss {'Reaction outcome loss': 0.4791554293793733, 'Total loss': 0.4791554293793733}
2022-11-28 05:39:54,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:54,963 INFO:     Epoch: 10
2022-11-28 05:39:55,610 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5184707863386288, 'Total loss': 0.5184707863386288} | train loss {'Reaction outcome loss': 0.47891621560346886, 'Total loss': 0.47891621560346886}
2022-11-28 05:39:55,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:55,611 INFO:     Epoch: 11
2022-11-28 05:39:56,257 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5294703473878462, 'Total loss': 0.5294703473878462} | train loss {'Reaction outcome loss': 0.4739043867123909, 'Total loss': 0.4739043867123909}
2022-11-28 05:39:56,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:56,257 INFO:     Epoch: 12
2022-11-28 05:39:56,904 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5272835649030153, 'Total loss': 0.5272835649030153} | train loss {'Reaction outcome loss': 0.4734751922307444, 'Total loss': 0.4734751922307444}
2022-11-28 05:39:56,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:56,904 INFO:     Epoch: 13
2022-11-28 05:39:57,552 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5160209675167882, 'Total loss': 0.5160209675167882} | train loss {'Reaction outcome loss': 0.4747207987076435, 'Total loss': 0.4747207987076435}
2022-11-28 05:39:57,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:57,552 INFO:     Epoch: 14
2022-11-28 05:39:58,205 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4801579776198365, 'Total loss': 0.4801579776198365} | train loss {'Reaction outcome loss': 0.47725502682513876, 'Total loss': 0.47725502682513876}
2022-11-28 05:39:58,205 INFO:     Found new best model at epoch 14
2022-11-28 05:39:58,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:58,206 INFO:     Epoch: 15
2022-11-28 05:39:58,857 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5533612048210099, 'Total loss': 0.5533612048210099} | train loss {'Reaction outcome loss': 0.47484608977788784, 'Total loss': 0.47484608977788784}
2022-11-28 05:39:58,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:58,857 INFO:     Epoch: 16
2022-11-28 05:39:59,506 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.521809654873471, 'Total loss': 0.521809654873471} | train loss {'Reaction outcome loss': 0.4710224924883882, 'Total loss': 0.4710224924883882}
2022-11-28 05:39:59,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:59,506 INFO:     Epoch: 17
2022-11-28 05:40:00,157 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5180768682513126, 'Total loss': 0.5180768682513126} | train loss {'Reaction outcome loss': 0.4664642908228714, 'Total loss': 0.4664642908228714}
2022-11-28 05:40:00,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:00,157 INFO:     Epoch: 18
2022-11-28 05:40:00,802 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.51626331619052, 'Total loss': 0.51626331619052} | train loss {'Reaction outcome loss': 0.46282448723423675, 'Total loss': 0.46282448723423675}
2022-11-28 05:40:00,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:00,802 INFO:     Epoch: 19
2022-11-28 05:40:01,450 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5328788091970045, 'Total loss': 0.5328788091970045} | train loss {'Reaction outcome loss': 0.46660598562877686, 'Total loss': 0.46660598562877686}
2022-11-28 05:40:01,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:01,450 INFO:     Epoch: 20
2022-11-28 05:40:02,098 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49477480351924896, 'Total loss': 0.49477480351924896} | train loss {'Reaction outcome loss': 0.4662958918536296, 'Total loss': 0.4662958918536296}
2022-11-28 05:40:02,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:02,098 INFO:     Epoch: 21
2022-11-28 05:40:02,744 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5272353180619174, 'Total loss': 0.5272353180619174} | train loss {'Reaction outcome loss': 0.4655006131859588, 'Total loss': 0.4655006131859588}
2022-11-28 05:40:02,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:02,744 INFO:     Epoch: 22
2022-11-28 05:40:03,388 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5624513931052629, 'Total loss': 0.5624513931052629} | train loss {'Reaction outcome loss': 0.46614404547898497, 'Total loss': 0.46614404547898497}
2022-11-28 05:40:03,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:03,389 INFO:     Epoch: 23
2022-11-28 05:40:04,036 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5117393780586331, 'Total loss': 0.5117393780586331} | train loss {'Reaction outcome loss': 0.47031652988469014, 'Total loss': 0.47031652988469014}
2022-11-28 05:40:04,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:04,037 INFO:     Epoch: 24
2022-11-28 05:40:04,686 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5312745113705479, 'Total loss': 0.5312745113705479} | train loss {'Reaction outcome loss': 0.4678251650489745, 'Total loss': 0.4678251650489745}
2022-11-28 05:40:04,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:04,686 INFO:     Epoch: 25
2022-11-28 05:40:05,334 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5074970722198486, 'Total loss': 0.5074970722198486} | train loss {'Reaction outcome loss': 0.47169844705428254, 'Total loss': 0.47169844705428254}
2022-11-28 05:40:05,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:05,334 INFO:     Epoch: 26
2022-11-28 05:40:05,986 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5300303233224292, 'Total loss': 0.5300303233224292} | train loss {'Reaction outcome loss': 0.4648073638071779, 'Total loss': 0.4648073638071779}
2022-11-28 05:40:05,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:05,987 INFO:     Epoch: 27
2022-11-28 05:40:06,633 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5019634899704956, 'Total loss': 0.5019634899704956} | train loss {'Reaction outcome loss': 0.4606277494401228, 'Total loss': 0.4606277494401228}
2022-11-28 05:40:06,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:06,633 INFO:     Epoch: 28
2022-11-28 05:40:07,281 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5121747057798297, 'Total loss': 0.5121747057798297} | train loss {'Reaction outcome loss': 0.47268477198286135, 'Total loss': 0.47268477198286135}
2022-11-28 05:40:07,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:07,282 INFO:     Epoch: 29
2022-11-28 05:40:07,932 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5014671413011329, 'Total loss': 0.5014671413011329} | train loss {'Reaction outcome loss': 0.4539702562767951, 'Total loss': 0.4539702562767951}
2022-11-28 05:40:07,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:07,932 INFO:     Epoch: 30
2022-11-28 05:40:08,586 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.521304362735083, 'Total loss': 0.521304362735083} | train loss {'Reaction outcome loss': 0.4701317748451819, 'Total loss': 0.4701317748451819}
2022-11-28 05:40:08,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:08,586 INFO:     Epoch: 31
2022-11-28 05:40:09,234 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5087485240642414, 'Total loss': 0.5087485240642414} | train loss {'Reaction outcome loss': 0.46215180808403455, 'Total loss': 0.46215180808403455}
2022-11-28 05:40:09,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:09,234 INFO:     Epoch: 32
2022-11-28 05:40:09,879 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5138143072294634, 'Total loss': 0.5138143072294634} | train loss {'Reaction outcome loss': 0.469365229311048, 'Total loss': 0.469365229311048}
2022-11-28 05:40:09,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:09,880 INFO:     Epoch: 33
2022-11-28 05:40:10,525 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5590784553178522, 'Total loss': 0.5590784553178522} | train loss {'Reaction outcome loss': 0.46420150555548123, 'Total loss': 0.46420150555548123}
2022-11-28 05:40:10,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:10,525 INFO:     Epoch: 34
2022-11-28 05:40:11,172 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5163125832413518, 'Total loss': 0.5163125832413518} | train loss {'Reaction outcome loss': 0.45835782789060325, 'Total loss': 0.45835782789060325}
2022-11-28 05:40:11,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:11,173 INFO:     Epoch: 35
2022-11-28 05:40:11,819 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5399572776500569, 'Total loss': 0.5399572776500569} | train loss {'Reaction outcome loss': 0.46131580158090985, 'Total loss': 0.46131580158090985}
2022-11-28 05:40:11,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:11,820 INFO:     Epoch: 36
2022-11-28 05:40:12,467 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.518686480300371, 'Total loss': 0.518686480300371} | train loss {'Reaction outcome loss': 0.45987262216503505, 'Total loss': 0.45987262216503505}
2022-11-28 05:40:12,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:12,467 INFO:     Epoch: 37
2022-11-28 05:40:13,116 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5175713823978291, 'Total loss': 0.5175713823978291} | train loss {'Reaction outcome loss': 0.46507172518577733, 'Total loss': 0.46507172518577733}
2022-11-28 05:40:13,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:13,116 INFO:     Epoch: 38
2022-11-28 05:40:13,763 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5025782335636227, 'Total loss': 0.5025782335636227} | train loss {'Reaction outcome loss': 0.4520097583165911, 'Total loss': 0.4520097583165911}
2022-11-28 05:40:13,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:13,763 INFO:     Epoch: 39
2022-11-28 05:40:14,412 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.524634953155074, 'Total loss': 0.524634953155074} | train loss {'Reaction outcome loss': 0.46457600969149443, 'Total loss': 0.46457600969149443}
2022-11-28 05:40:14,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:14,412 INFO:     Epoch: 40
2022-11-28 05:40:15,061 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5251045823097229, 'Total loss': 0.5251045823097229} | train loss {'Reaction outcome loss': 0.4642680367057929, 'Total loss': 0.4642680367057929}
2022-11-28 05:40:15,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:15,061 INFO:     Epoch: 41
2022-11-28 05:40:15,710 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5586687853169996, 'Total loss': 0.5586687853169996} | train loss {'Reaction outcome loss': 0.45844726582042505, 'Total loss': 0.45844726582042505}
2022-11-28 05:40:15,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:15,710 INFO:     Epoch: 42
2022-11-28 05:40:16,364 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.528490261976109, 'Total loss': 0.528490261976109} | train loss {'Reaction outcome loss': 0.45998910270997734, 'Total loss': 0.45998910270997734}
2022-11-28 05:40:16,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:16,365 INFO:     Epoch: 43
2022-11-28 05:40:17,023 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5123489107503447, 'Total loss': 0.5123489107503447} | train loss {'Reaction outcome loss': 0.45627829716464535, 'Total loss': 0.45627829716464535}
2022-11-28 05:40:17,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:17,024 INFO:     Epoch: 44
2022-11-28 05:40:17,679 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5347518823867621, 'Total loss': 0.5347518823867621} | train loss {'Reaction outcome loss': 0.4622920297819083, 'Total loss': 0.4622920297819083}
2022-11-28 05:40:17,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:17,679 INFO:     Epoch: 45
2022-11-28 05:40:18,334 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49093023704928024, 'Total loss': 0.49093023704928024} | train loss {'Reaction outcome loss': 0.46108201207196126, 'Total loss': 0.46108201207196126}
2022-11-28 05:40:18,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:18,335 INFO:     Epoch: 46
2022-11-28 05:40:18,997 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5148931152598802, 'Total loss': 0.5148931152598802} | train loss {'Reaction outcome loss': 0.46711387625727496, 'Total loss': 0.46711387625727496}
2022-11-28 05:40:18,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:18,998 INFO:     Epoch: 47
2022-11-28 05:40:19,660 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5539279209319935, 'Total loss': 0.5539279209319935} | train loss {'Reaction outcome loss': 0.46032531834283813, 'Total loss': 0.46032531834283813}
2022-11-28 05:40:19,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:19,660 INFO:     Epoch: 48
2022-11-28 05:40:20,321 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5027151648388353, 'Total loss': 0.5027151648388353} | train loss {'Reaction outcome loss': 0.46331556623832126, 'Total loss': 0.46331556623832126}
2022-11-28 05:40:20,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:20,321 INFO:     Epoch: 49
2022-11-28 05:40:20,982 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5213556695123052, 'Total loss': 0.5213556695123052} | train loss {'Reaction outcome loss': 0.45976808734360286, 'Total loss': 0.45976808734360286}
2022-11-28 05:40:20,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:20,983 INFO:     Epoch: 50
2022-11-28 05:40:21,644 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5209203196126361, 'Total loss': 0.5209203196126361} | train loss {'Reaction outcome loss': 0.4679231047019607, 'Total loss': 0.4679231047019607}
2022-11-28 05:40:21,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:21,645 INFO:     Epoch: 51
2022-11-28 05:40:22,305 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5133276709983515, 'Total loss': 0.5133276709983515} | train loss {'Reaction outcome loss': 0.4680443310835322, 'Total loss': 0.4680443310835322}
2022-11-28 05:40:22,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:22,305 INFO:     Epoch: 52
2022-11-28 05:40:22,965 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.531489628692006, 'Total loss': 0.531489628692006} | train loss {'Reaction outcome loss': 0.45898876494926505, 'Total loss': 0.45898876494926505}
2022-11-28 05:40:22,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:22,966 INFO:     Epoch: 53
2022-11-28 05:40:23,628 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5439743517443191, 'Total loss': 0.5439743517443191} | train loss {'Reaction outcome loss': 0.46510681058051156, 'Total loss': 0.46510681058051156}
2022-11-28 05:40:23,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:23,628 INFO:     Epoch: 54
2022-11-28 05:40:24,292 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5059543671303017, 'Total loss': 0.5059543671303017} | train loss {'Reaction outcome loss': 0.4586921128764993, 'Total loss': 0.4586921128764993}
2022-11-28 05:40:24,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:24,292 INFO:     Epoch: 55
2022-11-28 05:40:24,952 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.488155844253163, 'Total loss': 0.488155844253163} | train loss {'Reaction outcome loss': 0.4577382538528716, 'Total loss': 0.4577382538528716}
2022-11-28 05:40:24,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:24,952 INFO:     Epoch: 56
2022-11-28 05:40:25,616 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5192556076271589, 'Total loss': 0.5192556076271589} | train loss {'Reaction outcome loss': 0.45560856419997137, 'Total loss': 0.45560856419997137}
2022-11-28 05:40:25,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:25,616 INFO:     Epoch: 57
2022-11-28 05:40:26,279 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4997529917678168, 'Total loss': 0.4997529917678168} | train loss {'Reaction outcome loss': 0.46419622785732395, 'Total loss': 0.46419622785732395}
2022-11-28 05:40:26,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:26,279 INFO:     Epoch: 58
2022-11-28 05:40:26,939 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5006258342155191, 'Total loss': 0.5006258342155191} | train loss {'Reaction outcome loss': 0.45452073952335803, 'Total loss': 0.45452073952335803}
2022-11-28 05:40:26,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:26,939 INFO:     Epoch: 59
2022-11-28 05:40:27,592 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5231375638828721, 'Total loss': 0.5231375638828721} | train loss {'Reaction outcome loss': 0.4625576293309692, 'Total loss': 0.4625576293309692}
2022-11-28 05:40:27,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:27,593 INFO:     Epoch: 60
2022-11-28 05:40:28,249 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5249590468268062, 'Total loss': 0.5249590468268062} | train loss {'Reaction outcome loss': 0.4669374137445063, 'Total loss': 0.4669374137445063}
2022-11-28 05:40:28,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:28,250 INFO:     Epoch: 61
2022-11-28 05:40:28,905 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.521410720292912, 'Total loss': 0.521410720292912} | train loss {'Reaction outcome loss': 0.464202739542625, 'Total loss': 0.464202739542625}
2022-11-28 05:40:28,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:28,905 INFO:     Epoch: 62
2022-11-28 05:40:29,559 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5078422288561977, 'Total loss': 0.5078422288561977} | train loss {'Reaction outcome loss': 0.4595870456856782, 'Total loss': 0.4595870456856782}
2022-11-28 05:40:29,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:29,559 INFO:     Epoch: 63
2022-11-28 05:40:30,211 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4901999335649402, 'Total loss': 0.4901999335649402} | train loss {'Reaction outcome loss': 0.45321305932813005, 'Total loss': 0.45321305932813005}
2022-11-28 05:40:30,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:30,211 INFO:     Epoch: 64
2022-11-28 05:40:30,868 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5147638875384664, 'Total loss': 0.5147638875384664} | train loss {'Reaction outcome loss': 0.45463806885432023, 'Total loss': 0.45463806885432023}
2022-11-28 05:40:30,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:30,868 INFO:     Epoch: 65
2022-11-28 05:40:31,521 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5560560552186744, 'Total loss': 0.5560560552186744} | train loss {'Reaction outcome loss': 0.4514893182843435, 'Total loss': 0.4514893182843435}
2022-11-28 05:40:31,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:31,521 INFO:     Epoch: 66
2022-11-28 05:40:32,174 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48994715477144996, 'Total loss': 0.48994715477144996} | train loss {'Reaction outcome loss': 0.454956233257153, 'Total loss': 0.454956233257153}
2022-11-28 05:40:32,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:32,174 INFO:     Epoch: 67
2022-11-28 05:40:32,830 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5515673617983974, 'Total loss': 0.5515673617983974} | train loss {'Reaction outcome loss': 0.45902065193799674, 'Total loss': 0.45902065193799674}
2022-11-28 05:40:32,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:32,830 INFO:     Epoch: 68
2022-11-28 05:40:33,485 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5857159900803899, 'Total loss': 0.5857159900803899} | train loss {'Reaction outcome loss': 0.4570864526341196, 'Total loss': 0.4570864526341196}
2022-11-28 05:40:33,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:33,485 INFO:     Epoch: 69
2022-11-28 05:40:34,139 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.58858379097872, 'Total loss': 0.58858379097872} | train loss {'Reaction outcome loss': 0.4531293043591937, 'Total loss': 0.4531293043591937}
2022-11-28 05:40:34,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:34,139 INFO:     Epoch: 70
2022-11-28 05:40:34,792 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5076283410538075, 'Total loss': 0.5076283410538075} | train loss {'Reaction outcome loss': 0.4552725238389656, 'Total loss': 0.4552725238389656}
2022-11-28 05:40:34,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:34,792 INFO:     Epoch: 71
2022-11-28 05:40:35,446 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5098086041073466, 'Total loss': 0.5098086041073466} | train loss {'Reaction outcome loss': 0.45642691526989465, 'Total loss': 0.45642691526989465}
2022-11-28 05:40:35,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:35,447 INFO:     Epoch: 72
2022-11-28 05:40:36,098 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.584706325863683, 'Total loss': 0.584706325863683} | train loss {'Reaction outcome loss': 0.4568342096248611, 'Total loss': 0.4568342096248611}
2022-11-28 05:40:36,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:36,098 INFO:     Epoch: 73
2022-11-28 05:40:36,751 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5312698178513106, 'Total loss': 0.5312698178513106} | train loss {'Reaction outcome loss': 0.452859637190084, 'Total loss': 0.452859637190084}
2022-11-28 05:40:36,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:36,751 INFO:     Epoch: 74
2022-11-28 05:40:37,409 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5440746590841649, 'Total loss': 0.5440746590841649} | train loss {'Reaction outcome loss': 0.4467283400294722, 'Total loss': 0.4467283400294722}
2022-11-28 05:40:37,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:37,410 INFO:     Epoch: 75
2022-11-28 05:40:38,064 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.521084152681883, 'Total loss': 0.521084152681883} | train loss {'Reaction outcome loss': 0.4576858771873302, 'Total loss': 0.4576858771873302}
2022-11-28 05:40:38,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:38,064 INFO:     Epoch: 76
2022-11-28 05:40:38,718 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5031270332807718, 'Total loss': 0.5031270332807718} | train loss {'Reaction outcome loss': 0.4557671625106061, 'Total loss': 0.4557671625106061}
2022-11-28 05:40:38,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:38,718 INFO:     Epoch: 77
2022-11-28 05:40:39,372 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4835950926292774, 'Total loss': 0.4835950926292774} | train loss {'Reaction outcome loss': 0.460190620517633, 'Total loss': 0.460190620517633}
2022-11-28 05:40:39,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:39,373 INFO:     Epoch: 78
2022-11-28 05:40:40,027 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.509363739642986, 'Total loss': 0.509363739642986} | train loss {'Reaction outcome loss': 0.4517465518390546, 'Total loss': 0.4517465518390546}
2022-11-28 05:40:40,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:40,028 INFO:     Epoch: 79
2022-11-28 05:40:40,682 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4948183415934097, 'Total loss': 0.4948183415934097} | train loss {'Reaction outcome loss': 0.4511557269047518, 'Total loss': 0.4511557269047518}
2022-11-28 05:40:40,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:40,682 INFO:     Epoch: 80
2022-11-28 05:40:41,335 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5222547009240749, 'Total loss': 0.5222547009240749} | train loss {'Reaction outcome loss': 0.4610926307982109, 'Total loss': 0.4610926307982109}
2022-11-28 05:40:41,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:41,335 INFO:     Epoch: 81
2022-11-28 05:40:41,990 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49393868654273276, 'Total loss': 0.49393868654273276} | train loss {'Reaction outcome loss': 0.45368503580694314, 'Total loss': 0.45368503580694314}
2022-11-28 05:40:41,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:41,990 INFO:     Epoch: 82
2022-11-28 05:40:42,647 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5159203022025353, 'Total loss': 0.5159203022025353} | train loss {'Reaction outcome loss': 0.4670847936487589, 'Total loss': 0.4670847936487589}
2022-11-28 05:40:42,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:42,648 INFO:     Epoch: 83
2022-11-28 05:40:43,305 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4864509736382684, 'Total loss': 0.4864509736382684} | train loss {'Reaction outcome loss': 0.44620856050340857, 'Total loss': 0.44620856050340857}
2022-11-28 05:40:43,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:43,305 INFO:     Epoch: 84
2022-11-28 05:40:43,962 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5009781101415324, 'Total loss': 0.5009781101415324} | train loss {'Reaction outcome loss': 0.4542056959061349, 'Total loss': 0.4542056959061349}
2022-11-28 05:40:43,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:43,963 INFO:     Epoch: 85
2022-11-28 05:40:44,617 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5146732177845267, 'Total loss': 0.5146732177845267} | train loss {'Reaction outcome loss': 0.4539439162147827, 'Total loss': 0.4539439162147827}
2022-11-28 05:40:44,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:44,617 INFO:     Epoch: 86
2022-11-28 05:40:45,273 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5674890238185262, 'Total loss': 0.5674890238185262} | train loss {'Reaction outcome loss': 0.4506917438301884, 'Total loss': 0.4506917438301884}
2022-11-28 05:40:45,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:45,273 INFO:     Epoch: 87
2022-11-28 05:40:45,931 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5039779481499694, 'Total loss': 0.5039779481499694} | train loss {'Reaction outcome loss': 0.4514385428218568, 'Total loss': 0.4514385428218568}
2022-11-28 05:40:45,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:45,931 INFO:     Epoch: 88
2022-11-28 05:40:46,587 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5288247833418291, 'Total loss': 0.5288247833418291} | train loss {'Reaction outcome loss': 0.4520829530646566, 'Total loss': 0.4520829530646566}
2022-11-28 05:40:46,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:46,587 INFO:     Epoch: 89
2022-11-28 05:40:47,241 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5055519418660984, 'Total loss': 0.5055519418660984} | train loss {'Reaction outcome loss': 0.45615084637261805, 'Total loss': 0.45615084637261805}
2022-11-28 05:40:47,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:47,242 INFO:     Epoch: 90
2022-11-28 05:40:47,898 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4821505061415739, 'Total loss': 0.4821505061415739} | train loss {'Reaction outcome loss': 0.44835445645158406, 'Total loss': 0.44835445645158406}
2022-11-28 05:40:47,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:47,898 INFO:     Epoch: 91
2022-11-28 05:40:48,553 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5248809460290643, 'Total loss': 0.5248809460290643} | train loss {'Reaction outcome loss': 0.4568789396740374, 'Total loss': 0.4568789396740374}
2022-11-28 05:40:48,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:48,554 INFO:     Epoch: 92
2022-11-28 05:40:49,209 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4991527806187785, 'Total loss': 0.4991527806187785} | train loss {'Reaction outcome loss': 0.4494584313914424, 'Total loss': 0.4494584313914424}
2022-11-28 05:40:49,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:49,209 INFO:     Epoch: 93
2022-11-28 05:40:49,865 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.515694793227107, 'Total loss': 0.515694793227107} | train loss {'Reaction outcome loss': 0.452547269216815, 'Total loss': 0.452547269216815}
2022-11-28 05:40:49,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:49,865 INFO:     Epoch: 94
2022-11-28 05:40:50,522 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5211054259954497, 'Total loss': 0.5211054259954497} | train loss {'Reaction outcome loss': 0.4509365301518167, 'Total loss': 0.4509365301518167}
2022-11-28 05:40:50,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:50,522 INFO:     Epoch: 95
2022-11-28 05:40:51,180 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5169858724571937, 'Total loss': 0.5169858724571937} | train loss {'Reaction outcome loss': 0.45493576981005124, 'Total loss': 0.45493576981005124}
2022-11-28 05:40:51,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:51,180 INFO:     Epoch: 96
2022-11-28 05:40:51,836 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5250766214936279, 'Total loss': 0.5250766214936279} | train loss {'Reaction outcome loss': 0.4540032105611973, 'Total loss': 0.4540032105611973}
2022-11-28 05:40:51,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:51,836 INFO:     Epoch: 97
2022-11-28 05:40:52,489 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4740698146958684, 'Total loss': 0.4740698146958684} | train loss {'Reaction outcome loss': 0.45123866459996, 'Total loss': 0.45123866459996}
2022-11-28 05:40:52,489 INFO:     Found new best model at epoch 97
2022-11-28 05:40:52,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:52,490 INFO:     Epoch: 98
2022-11-28 05:40:53,147 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47040481172328774, 'Total loss': 0.47040481172328774} | train loss {'Reaction outcome loss': 0.4502596581263132, 'Total loss': 0.4502596581263132}
2022-11-28 05:40:53,148 INFO:     Found new best model at epoch 98
2022-11-28 05:40:53,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:53,149 INFO:     Epoch: 99
2022-11-28 05:40:53,806 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4782852731471838, 'Total loss': 0.4782852731471838} | train loss {'Reaction outcome loss': 0.4556696870532192, 'Total loss': 0.4556696870532192}
2022-11-28 05:40:53,806 INFO:     Best model found after epoch 99 of 100.
2022-11-28 05:40:53,806 INFO:   Done with stage: TRAINING
2022-11-28 05:40:53,806 INFO:   Starting stage: EVALUATION
2022-11-28 05:40:53,936 INFO:   Done with stage: EVALUATION
2022-11-28 05:40:53,936 INFO:   Leaving out SEQ value Fold_1
2022-11-28 05:40:53,949 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:40:53,949 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:40:54,607 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:40:54,607 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:40:54,678 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:40:54,679 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:40:54,679 INFO:     No hyperparam tuning for this model
2022-11-28 05:40:54,679 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:40:54,679 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:40:54,679 INFO:     None feature selector for col prot
2022-11-28 05:40:54,680 INFO:     None feature selector for col prot
2022-11-28 05:40:54,680 INFO:     None feature selector for col prot
2022-11-28 05:40:54,680 INFO:     None feature selector for col chem
2022-11-28 05:40:54,680 INFO:     None feature selector for col chem
2022-11-28 05:40:54,680 INFO:     None feature selector for col chem
2022-11-28 05:40:54,681 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:40:54,681 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:40:54,682 INFO:     Number of params in model 169651
2022-11-28 05:40:54,685 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:40:54,685 INFO:   Starting stage: TRAINING
2022-11-28 05:40:54,738 INFO:     Val loss before train {'Reaction outcome loss': 1.014261354776946, 'Total loss': 1.014261354776946}
2022-11-28 05:40:54,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:54,738 INFO:     Epoch: 0
2022-11-28 05:40:55,404 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6475316540084102, 'Total loss': 0.6475316540084102} | train loss {'Reaction outcome loss': 0.6956478289445402, 'Total loss': 0.6956478289445402}
2022-11-28 05:40:55,405 INFO:     Found new best model at epoch 0
2022-11-28 05:40:55,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:55,405 INFO:     Epoch: 1
2022-11-28 05:40:56,077 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5863376849076964, 'Total loss': 0.5863376849076964} | train loss {'Reaction outcome loss': 0.5944470438035393, 'Total loss': 0.5944470438035393}
2022-11-28 05:40:56,077 INFO:     Found new best model at epoch 1
2022-11-28 05:40:56,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:56,078 INFO:     Epoch: 2
2022-11-28 05:40:56,751 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5266408056698062, 'Total loss': 0.5266408056698062} | train loss {'Reaction outcome loss': 0.5658439002056354, 'Total loss': 0.5658439002056354}
2022-11-28 05:40:56,751 INFO:     Found new best model at epoch 2
2022-11-28 05:40:56,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:56,752 INFO:     Epoch: 3
2022-11-28 05:40:57,422 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5181497789242051, 'Total loss': 0.5181497789242051} | train loss {'Reaction outcome loss': 0.5389794685994747, 'Total loss': 0.5389794685994747}
2022-11-28 05:40:57,422 INFO:     Found new best model at epoch 3
2022-11-28 05:40:57,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:57,423 INFO:     Epoch: 4
2022-11-28 05:40:58,093 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5468166545033455, 'Total loss': 0.5468166545033455} | train loss {'Reaction outcome loss': 0.5380039250078471, 'Total loss': 0.5380039250078471}
2022-11-28 05:40:58,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:58,093 INFO:     Epoch: 5
2022-11-28 05:40:58,760 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49861806123094127, 'Total loss': 0.49861806123094127} | train loss {'Reaction outcome loss': 0.5352961725926758, 'Total loss': 0.5352961725926758}
2022-11-28 05:40:58,760 INFO:     Found new best model at epoch 5
2022-11-28 05:40:58,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:58,760 INFO:     Epoch: 6
2022-11-28 05:40:59,426 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4900049888952212, 'Total loss': 0.4900049888952212} | train loss {'Reaction outcome loss': 0.5174022898801908, 'Total loss': 0.5174022898801908}
2022-11-28 05:40:59,427 INFO:     Found new best model at epoch 6
2022-11-28 05:40:59,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:40:59,427 INFO:     Epoch: 7
2022-11-28 05:41:00,092 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4705101746049794, 'Total loss': 0.4705101746049794} | train loss {'Reaction outcome loss': 0.5260015276038212, 'Total loss': 0.5260015276038212}
2022-11-28 05:41:00,092 INFO:     Found new best model at epoch 7
2022-11-28 05:41:00,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:00,093 INFO:     Epoch: 8
2022-11-28 05:41:00,759 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5173887441104109, 'Total loss': 0.5173887441104109} | train loss {'Reaction outcome loss': 0.5104021120529908, 'Total loss': 0.5104021120529908}
2022-11-28 05:41:00,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:00,759 INFO:     Epoch: 9
2022-11-28 05:41:01,424 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5112290822646834, 'Total loss': 0.5112290822646834} | train loss {'Reaction outcome loss': 0.5159838544091715, 'Total loss': 0.5159838544091715}
2022-11-28 05:41:01,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:01,424 INFO:     Epoch: 10
2022-11-28 05:41:02,092 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46930450133301993, 'Total loss': 0.46930450133301993} | train loss {'Reaction outcome loss': 0.5017086420555105, 'Total loss': 0.5017086420555105}
2022-11-28 05:41:02,092 INFO:     Found new best model at epoch 10
2022-11-28 05:41:02,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:02,093 INFO:     Epoch: 11
2022-11-28 05:41:02,762 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5215324715457179, 'Total loss': 0.5215324715457179} | train loss {'Reaction outcome loss': 0.504750051177465, 'Total loss': 0.504750051177465}
2022-11-28 05:41:02,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:02,762 INFO:     Epoch: 12
2022-11-28 05:41:03,429 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46697876805608923, 'Total loss': 0.46697876805608923} | train loss {'Reaction outcome loss': 0.51099165151959, 'Total loss': 0.51099165151959}
2022-11-28 05:41:03,429 INFO:     Found new best model at epoch 12
2022-11-28 05:41:03,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:03,430 INFO:     Epoch: 13
2022-11-28 05:41:04,098 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5129170749675144, 'Total loss': 0.5129170749675144} | train loss {'Reaction outcome loss': 0.5067503908234328, 'Total loss': 0.5067503908234328}
2022-11-28 05:41:04,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:04,098 INFO:     Epoch: 14
2022-11-28 05:41:04,762 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47259638898751954, 'Total loss': 0.47259638898751954} | train loss {'Reaction outcome loss': 0.4978078794382844, 'Total loss': 0.4978078794382844}
2022-11-28 05:41:04,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:04,763 INFO:     Epoch: 15
2022-11-28 05:41:05,429 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46352028101682663, 'Total loss': 0.46352028101682663} | train loss {'Reaction outcome loss': 0.5021869853169088, 'Total loss': 0.5021869853169088}
2022-11-28 05:41:05,429 INFO:     Found new best model at epoch 15
2022-11-28 05:41:05,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:05,430 INFO:     Epoch: 16
2022-11-28 05:41:06,096 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.516179636459459, 'Total loss': 0.516179636459459} | train loss {'Reaction outcome loss': 0.49556978095156945, 'Total loss': 0.49556978095156945}
2022-11-28 05:41:06,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:06,096 INFO:     Epoch: 17
2022-11-28 05:41:06,762 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5495683205398646, 'Total loss': 0.5495683205398646} | train loss {'Reaction outcome loss': 0.49590168087950603, 'Total loss': 0.49590168087950603}
2022-11-28 05:41:06,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:06,762 INFO:     Epoch: 18
2022-11-28 05:41:07,424 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49386204000223766, 'Total loss': 0.49386204000223766} | train loss {'Reaction outcome loss': 0.5081066148363145, 'Total loss': 0.5081066148363145}
2022-11-28 05:41:07,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:07,424 INFO:     Epoch: 19
2022-11-28 05:41:08,091 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45800023153424263, 'Total loss': 0.45800023153424263} | train loss {'Reaction outcome loss': 0.5000949289634643, 'Total loss': 0.5000949289634643}
2022-11-28 05:41:08,091 INFO:     Found new best model at epoch 19
2022-11-28 05:41:08,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:08,092 INFO:     Epoch: 20
2022-11-28 05:41:08,763 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4835333759811791, 'Total loss': 0.4835333759811791} | train loss {'Reaction outcome loss': 0.5052631832810066, 'Total loss': 0.5052631832810066}
2022-11-28 05:41:08,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:08,763 INFO:     Epoch: 21
2022-11-28 05:41:09,432 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47377076745033264, 'Total loss': 0.47377076745033264} | train loss {'Reaction outcome loss': 0.5017851528368498, 'Total loss': 0.5017851528368498}
2022-11-28 05:41:09,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:09,432 INFO:     Epoch: 22
2022-11-28 05:41:10,101 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45979987999255006, 'Total loss': 0.45979987999255006} | train loss {'Reaction outcome loss': 0.49611318726771275, 'Total loss': 0.49611318726771275}
2022-11-28 05:41:10,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:10,101 INFO:     Epoch: 23
2022-11-28 05:41:10,767 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47157116437500174, 'Total loss': 0.47157116437500174} | train loss {'Reaction outcome loss': 0.4896855362755084, 'Total loss': 0.4896855362755084}
2022-11-28 05:41:10,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:10,767 INFO:     Epoch: 24
2022-11-28 05:41:11,435 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4626324498517947, 'Total loss': 0.4626324498517947} | train loss {'Reaction outcome loss': 0.49825493665600595, 'Total loss': 0.49825493665600595}
2022-11-28 05:41:11,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:11,436 INFO:     Epoch: 25
2022-11-28 05:41:12,101 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4842126081612977, 'Total loss': 0.4842126081612977} | train loss {'Reaction outcome loss': 0.49211191214047945, 'Total loss': 0.49211191214047945}
2022-11-28 05:41:12,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:12,101 INFO:     Epoch: 26
2022-11-28 05:41:12,770 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4745404144579714, 'Total loss': 0.4745404144579714} | train loss {'Reaction outcome loss': 0.4804150221891973, 'Total loss': 0.4804150221891973}
2022-11-28 05:41:12,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:12,771 INFO:     Epoch: 27
2022-11-28 05:41:13,436 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4504444406113841, 'Total loss': 0.4504444406113841} | train loss {'Reaction outcome loss': 0.4903927703014752, 'Total loss': 0.4903927703014752}
2022-11-28 05:41:13,436 INFO:     Found new best model at epoch 27
2022-11-28 05:41:13,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:13,437 INFO:     Epoch: 28
2022-11-28 05:41:14,102 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4867037030106241, 'Total loss': 0.4867037030106241} | train loss {'Reaction outcome loss': 0.4932564039100037, 'Total loss': 0.4932564039100037}
2022-11-28 05:41:14,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:14,102 INFO:     Epoch: 29
2022-11-28 05:41:14,774 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48735637217760086, 'Total loss': 0.48735637217760086} | train loss {'Reaction outcome loss': 0.49075693435031875, 'Total loss': 0.49075693435031875}
2022-11-28 05:41:14,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:14,774 INFO:     Epoch: 30
2022-11-28 05:41:15,440 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5081424506550486, 'Total loss': 0.5081424506550486} | train loss {'Reaction outcome loss': 0.49524000932383333, 'Total loss': 0.49524000932383333}
2022-11-28 05:41:15,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:15,440 INFO:     Epoch: 31
2022-11-28 05:41:16,109 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4708856310356747, 'Total loss': 0.4708856310356747} | train loss {'Reaction outcome loss': 0.4840648331743503, 'Total loss': 0.4840648331743503}
2022-11-28 05:41:16,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:16,109 INFO:     Epoch: 32
2022-11-28 05:41:16,777 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48752778802405705, 'Total loss': 0.48752778802405705} | train loss {'Reaction outcome loss': 0.4841839520313479, 'Total loss': 0.4841839520313479}
2022-11-28 05:41:16,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:16,777 INFO:     Epoch: 33
2022-11-28 05:41:17,446 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48881245302883064, 'Total loss': 0.48881245302883064} | train loss {'Reaction outcome loss': 0.49489896189466664, 'Total loss': 0.49489896189466664}
2022-11-28 05:41:17,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:17,447 INFO:     Epoch: 34
2022-11-28 05:41:18,119 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4524736668575894, 'Total loss': 0.4524736668575894} | train loss {'Reaction outcome loss': 0.4949865965587407, 'Total loss': 0.4949865965587407}
2022-11-28 05:41:18,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:18,119 INFO:     Epoch: 35
2022-11-28 05:41:18,787 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46039156514135277, 'Total loss': 0.46039156514135277} | train loss {'Reaction outcome loss': 0.4827535502944398, 'Total loss': 0.4827535502944398}
2022-11-28 05:41:18,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:18,788 INFO:     Epoch: 36
2022-11-28 05:41:19,455 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4543296674435789, 'Total loss': 0.4543296674435789} | train loss {'Reaction outcome loss': 0.4888889119933974, 'Total loss': 0.4888889119933974}
2022-11-28 05:41:19,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:19,456 INFO:     Epoch: 37
2022-11-28 05:41:20,125 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.441318173638799, 'Total loss': 0.441318173638799} | train loss {'Reaction outcome loss': 0.4795642877186117, 'Total loss': 0.4795642877186117}
2022-11-28 05:41:20,125 INFO:     Found new best model at epoch 37
2022-11-28 05:41:20,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:20,126 INFO:     Epoch: 38
2022-11-28 05:41:20,795 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48293701525438915, 'Total loss': 0.48293701525438915} | train loss {'Reaction outcome loss': 0.4752319063029821, 'Total loss': 0.4752319063029821}
2022-11-28 05:41:20,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:20,795 INFO:     Epoch: 39
2022-11-28 05:41:21,466 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5592776266011324, 'Total loss': 0.5592776266011324} | train loss {'Reaction outcome loss': 0.4822203343515454, 'Total loss': 0.4822203343515454}
2022-11-28 05:41:21,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:21,466 INFO:     Epoch: 40
2022-11-28 05:41:22,134 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44898389957167884, 'Total loss': 0.44898389957167884} | train loss {'Reaction outcome loss': 0.48904148715469037, 'Total loss': 0.48904148715469037}
2022-11-28 05:41:22,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:22,134 INFO:     Epoch: 41
2022-11-28 05:41:22,799 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45289337025447324, 'Total loss': 0.45289337025447324} | train loss {'Reaction outcome loss': 0.47733742300315424, 'Total loss': 0.47733742300315424}
2022-11-28 05:41:22,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:22,799 INFO:     Epoch: 42
2022-11-28 05:41:23,464 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44215951453555713, 'Total loss': 0.44215951453555713} | train loss {'Reaction outcome loss': 0.47797413996839333, 'Total loss': 0.47797413996839333}
2022-11-28 05:41:23,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:23,464 INFO:     Epoch: 43
2022-11-28 05:41:24,131 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4655554396185008, 'Total loss': 0.4655554396185008} | train loss {'Reaction outcome loss': 0.4880785872096475, 'Total loss': 0.4880785872096475}
2022-11-28 05:41:24,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:24,132 INFO:     Epoch: 44
2022-11-28 05:41:24,797 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.477354054085233, 'Total loss': 0.477354054085233} | train loss {'Reaction outcome loss': 0.4808080187934613, 'Total loss': 0.4808080187934613}
2022-11-28 05:41:24,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:24,798 INFO:     Epoch: 45
2022-11-28 05:41:25,466 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4886466163125905, 'Total loss': 0.4886466163125905} | train loss {'Reaction outcome loss': 0.4773731736639733, 'Total loss': 0.4773731736639733}
2022-11-28 05:41:25,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:25,466 INFO:     Epoch: 46
2022-11-28 05:41:26,134 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4879125780002637, 'Total loss': 0.4879125780002637} | train loss {'Reaction outcome loss': 0.4873362295178749, 'Total loss': 0.4873362295178749}
2022-11-28 05:41:26,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:26,134 INFO:     Epoch: 47
2022-11-28 05:41:26,801 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4793796400454911, 'Total loss': 0.4793796400454911} | train loss {'Reaction outcome loss': 0.4772827876241584, 'Total loss': 0.4772827876241584}
2022-11-28 05:41:26,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:26,802 INFO:     Epoch: 48
2022-11-28 05:41:27,471 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.449735400351611, 'Total loss': 0.449735400351611} | train loss {'Reaction outcome loss': 0.48844040743252526, 'Total loss': 0.48844040743252526}
2022-11-28 05:41:27,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:27,471 INFO:     Epoch: 49
2022-11-28 05:41:28,137 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4709019366313111, 'Total loss': 0.4709019366313111} | train loss {'Reaction outcome loss': 0.4764938259173019, 'Total loss': 0.4764938259173019}
2022-11-28 05:41:28,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:28,137 INFO:     Epoch: 50
2022-11-28 05:41:28,804 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4796570160172202, 'Total loss': 0.4796570160172202} | train loss {'Reaction outcome loss': 0.47798959328698726, 'Total loss': 0.47798959328698726}
2022-11-28 05:41:28,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:28,804 INFO:     Epoch: 51
2022-11-28 05:41:29,472 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46279667250134726, 'Total loss': 0.46279667250134726} | train loss {'Reaction outcome loss': 0.4855896983190104, 'Total loss': 0.4855896983190104}
2022-11-28 05:41:29,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:29,472 INFO:     Epoch: 52
2022-11-28 05:41:30,141 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.522601033476266, 'Total loss': 0.522601033476266} | train loss {'Reaction outcome loss': 0.4859320501747884, 'Total loss': 0.4859320501747884}
2022-11-28 05:41:30,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:30,142 INFO:     Epoch: 53
2022-11-28 05:41:30,812 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4824212274768136, 'Total loss': 0.4824212274768136} | train loss {'Reaction outcome loss': 0.4820171230762956, 'Total loss': 0.4820171230762956}
2022-11-28 05:41:30,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:30,812 INFO:     Epoch: 54
2022-11-28 05:41:31,486 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46372008459134534, 'Total loss': 0.46372008459134534} | train loss {'Reaction outcome loss': 0.4802342579673659, 'Total loss': 0.4802342579673659}
2022-11-28 05:41:31,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:31,486 INFO:     Epoch: 55
2022-11-28 05:41:32,156 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47794481976465747, 'Total loss': 0.47794481976465747} | train loss {'Reaction outcome loss': 0.49247219965525485, 'Total loss': 0.49247219965525485}
2022-11-28 05:41:32,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:32,156 INFO:     Epoch: 56
2022-11-28 05:41:32,822 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49032472344962036, 'Total loss': 0.49032472344962036} | train loss {'Reaction outcome loss': 0.495480409457616, 'Total loss': 0.495480409457616}
2022-11-28 05:41:32,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:32,822 INFO:     Epoch: 57
2022-11-28 05:41:33,490 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4634616994722323, 'Total loss': 0.4634616994722323} | train loss {'Reaction outcome loss': 0.4927039830549526, 'Total loss': 0.4927039830549526}
2022-11-28 05:41:33,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:33,491 INFO:     Epoch: 58
2022-11-28 05:41:34,157 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.470784860917113, 'Total loss': 0.470784860917113} | train loss {'Reaction outcome loss': 0.482254164662921, 'Total loss': 0.482254164662921}
2022-11-28 05:41:34,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:34,157 INFO:     Epoch: 59
2022-11-28 05:41:34,827 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44870287315412, 'Total loss': 0.44870287315412} | train loss {'Reaction outcome loss': 0.4923791725505219, 'Total loss': 0.4923791725505219}
2022-11-28 05:41:34,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:34,827 INFO:     Epoch: 60
2022-11-28 05:41:35,495 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45010950721123, 'Total loss': 0.45010950721123} | train loss {'Reaction outcome loss': 0.4800195002905753, 'Total loss': 0.4800195002905753}
2022-11-28 05:41:35,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:35,495 INFO:     Epoch: 61
2022-11-28 05:41:36,163 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46381084485487506, 'Total loss': 0.46381084485487506} | train loss {'Reaction outcome loss': 0.4774377163921894, 'Total loss': 0.4774377163921894}
2022-11-28 05:41:36,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:36,164 INFO:     Epoch: 62
2022-11-28 05:41:36,835 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5297652279788797, 'Total loss': 0.5297652279788797} | train loss {'Reaction outcome loss': 0.48146496435649966, 'Total loss': 0.48146496435649966}
2022-11-28 05:41:36,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:36,835 INFO:     Epoch: 63
2022-11-28 05:41:37,505 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46313638578761707, 'Total loss': 0.46313638578761707} | train loss {'Reaction outcome loss': 0.4915679597073359, 'Total loss': 0.4915679597073359}
2022-11-28 05:41:37,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:37,505 INFO:     Epoch: 64
2022-11-28 05:41:38,179 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4461314007639885, 'Total loss': 0.4461314007639885} | train loss {'Reaction outcome loss': 0.4816667096395242, 'Total loss': 0.4816667096395242}
2022-11-28 05:41:38,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:38,179 INFO:     Epoch: 65
2022-11-28 05:41:38,853 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47131475975567644, 'Total loss': 0.47131475975567644} | train loss {'Reaction outcome loss': 0.4912098693521882, 'Total loss': 0.4912098693521882}
2022-11-28 05:41:38,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:38,853 INFO:     Epoch: 66
2022-11-28 05:41:39,526 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.472781087864529, 'Total loss': 0.472781087864529} | train loss {'Reaction outcome loss': 0.481644143670918, 'Total loss': 0.481644143670918}
2022-11-28 05:41:39,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:39,527 INFO:     Epoch: 67
2022-11-28 05:41:40,197 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4921687353741039, 'Total loss': 0.4921687353741039} | train loss {'Reaction outcome loss': 0.48193253806004155, 'Total loss': 0.48193253806004155}
2022-11-28 05:41:40,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:40,197 INFO:     Epoch: 68
2022-11-28 05:41:40,870 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47509482130408287, 'Total loss': 0.47509482130408287} | train loss {'Reaction outcome loss': 0.47713423156092766, 'Total loss': 0.47713423156092766}
2022-11-28 05:41:40,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:40,871 INFO:     Epoch: 69
2022-11-28 05:41:41,541 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47305491295727814, 'Total loss': 0.47305491295727814} | train loss {'Reaction outcome loss': 0.47823476827578987, 'Total loss': 0.47823476827578987}
2022-11-28 05:41:41,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:41,541 INFO:     Epoch: 70
2022-11-28 05:41:42,209 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4533015689389272, 'Total loss': 0.4533015689389272} | train loss {'Reaction outcome loss': 0.4755954750274357, 'Total loss': 0.4755954750274357}
2022-11-28 05:41:42,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:42,210 INFO:     Epoch: 71
2022-11-28 05:41:42,881 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43444221636111086, 'Total loss': 0.43444221636111086} | train loss {'Reaction outcome loss': 0.48015582505688975, 'Total loss': 0.48015582505688975}
2022-11-28 05:41:42,881 INFO:     Found new best model at epoch 71
2022-11-28 05:41:42,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:42,882 INFO:     Epoch: 72
2022-11-28 05:41:43,550 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49060597541657364, 'Total loss': 0.49060597541657364} | train loss {'Reaction outcome loss': 0.4850225306430884, 'Total loss': 0.4850225306430884}
2022-11-28 05:41:43,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:43,550 INFO:     Epoch: 73
2022-11-28 05:41:44,213 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4730733602561734, 'Total loss': 0.4730733602561734} | train loss {'Reaction outcome loss': 0.4806387733879239, 'Total loss': 0.4806387733879239}
2022-11-28 05:41:44,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:44,214 INFO:     Epoch: 74
2022-11-28 05:41:44,882 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47412447732957924, 'Total loss': 0.47412447732957924} | train loss {'Reaction outcome loss': 0.4786306032797827, 'Total loss': 0.4786306032797827}
2022-11-28 05:41:44,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:44,883 INFO:     Epoch: 75
2022-11-28 05:41:45,550 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48445688120343466, 'Total loss': 0.48445688120343466} | train loss {'Reaction outcome loss': 0.4794388196246344, 'Total loss': 0.4794388196246344}
2022-11-28 05:41:45,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:45,550 INFO:     Epoch: 76
2022-11-28 05:41:46,220 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46958066760139033, 'Total loss': 0.46958066760139033} | train loss {'Reaction outcome loss': 0.48494104214525413, 'Total loss': 0.48494104214525413}
2022-11-28 05:41:46,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:46,220 INFO:     Epoch: 77
2022-11-28 05:41:46,887 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4613810415295037, 'Total loss': 0.4613810415295037} | train loss {'Reaction outcome loss': 0.48807423576893594, 'Total loss': 0.48807423576893594}
2022-11-28 05:41:46,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:46,888 INFO:     Epoch: 78
2022-11-28 05:41:47,557 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49010181054472923, 'Total loss': 0.49010181054472923} | train loss {'Reaction outcome loss': 0.4902876414026809, 'Total loss': 0.4902876414026809}
2022-11-28 05:41:47,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:47,557 INFO:     Epoch: 79
2022-11-28 05:41:48,220 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45928759839047084, 'Total loss': 0.45928759839047084} | train loss {'Reaction outcome loss': 0.48659138858077017, 'Total loss': 0.48659138858077017}
2022-11-28 05:41:48,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:48,220 INFO:     Epoch: 80
2022-11-28 05:41:48,889 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5988302583044226, 'Total loss': 0.5988302583044226} | train loss {'Reaction outcome loss': 0.48571642002596066, 'Total loss': 0.48571642002596066}
2022-11-28 05:41:48,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:48,889 INFO:     Epoch: 81
2022-11-28 05:41:49,557 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4762364842674949, 'Total loss': 0.4762364842674949} | train loss {'Reaction outcome loss': 0.5080988244851109, 'Total loss': 0.5080988244851109}
2022-11-28 05:41:49,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:49,558 INFO:     Epoch: 82
2022-11-28 05:41:50,226 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47144395587119187, 'Total loss': 0.47144395587119187} | train loss {'Reaction outcome loss': 0.48456096816393224, 'Total loss': 0.48456096816393224}
2022-11-28 05:41:50,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:50,226 INFO:     Epoch: 83
2022-11-28 05:41:50,893 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45382854308594356, 'Total loss': 0.45382854308594356} | train loss {'Reaction outcome loss': 0.48174527604585354, 'Total loss': 0.48174527604585354}
2022-11-28 05:41:50,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:50,893 INFO:     Epoch: 84
2022-11-28 05:41:51,559 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4645714922384782, 'Total loss': 0.4645714922384782} | train loss {'Reaction outcome loss': 0.4829055766465693, 'Total loss': 0.4829055766465693}
2022-11-28 05:41:51,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:51,559 INFO:     Epoch: 85
2022-11-28 05:41:52,227 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4777699282223528, 'Total loss': 0.4777699282223528} | train loss {'Reaction outcome loss': 0.47981505614784564, 'Total loss': 0.47981505614784564}
2022-11-28 05:41:52,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:52,227 INFO:     Epoch: 86
2022-11-28 05:41:52,895 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47655525329438125, 'Total loss': 0.47655525329438125} | train loss {'Reaction outcome loss': 0.48120821381990725, 'Total loss': 0.48120821381990725}
2022-11-28 05:41:52,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:52,895 INFO:     Epoch: 87
2022-11-28 05:41:53,565 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4517906494438648, 'Total loss': 0.4517906494438648} | train loss {'Reaction outcome loss': 0.4833028791283789, 'Total loss': 0.4833028791283789}
2022-11-28 05:41:53,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:53,565 INFO:     Epoch: 88
2022-11-28 05:41:54,234 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4838440025394613, 'Total loss': 0.4838440025394613} | train loss {'Reaction outcome loss': 0.49221788256274546, 'Total loss': 0.49221788256274546}
2022-11-28 05:41:54,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:54,235 INFO:     Epoch: 89
2022-11-28 05:41:54,901 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47336658666079695, 'Total loss': 0.47336658666079695} | train loss {'Reaction outcome loss': 0.49916449159021803, 'Total loss': 0.49916449159021803}
2022-11-28 05:41:54,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:54,902 INFO:     Epoch: 90
2022-11-28 05:41:55,571 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46338170902295545, 'Total loss': 0.46338170902295545} | train loss {'Reaction outcome loss': 0.48721821980196456, 'Total loss': 0.48721821980196456}
2022-11-28 05:41:55,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:55,571 INFO:     Epoch: 91
2022-11-28 05:41:56,239 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4423044489865953, 'Total loss': 0.4423044489865953} | train loss {'Reaction outcome loss': 0.48208516187634065, 'Total loss': 0.48208516187634065}
2022-11-28 05:41:56,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:56,239 INFO:     Epoch: 92
2022-11-28 05:41:56,908 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4915113926611163, 'Total loss': 0.4915113926611163} | train loss {'Reaction outcome loss': 0.4804936799094428, 'Total loss': 0.4804936799094428}
2022-11-28 05:41:56,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:56,908 INFO:     Epoch: 93
2022-11-28 05:41:57,576 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44503960555249994, 'Total loss': 0.44503960555249994} | train loss {'Reaction outcome loss': 0.48074716220983127, 'Total loss': 0.48074716220983127}
2022-11-28 05:41:57,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:57,576 INFO:     Epoch: 94
2022-11-28 05:41:58,243 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46090044250542467, 'Total loss': 0.46090044250542467} | train loss {'Reaction outcome loss': 0.48680383292769613, 'Total loss': 0.48680383292769613}
2022-11-28 05:41:58,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:58,243 INFO:     Epoch: 95
2022-11-28 05:41:58,911 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48232004046440125, 'Total loss': 0.48232004046440125} | train loss {'Reaction outcome loss': 0.4844419662407053, 'Total loss': 0.4844419662407053}
2022-11-28 05:41:58,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:58,912 INFO:     Epoch: 96
2022-11-28 05:41:59,578 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43580736829475925, 'Total loss': 0.43580736829475925} | train loss {'Reaction outcome loss': 0.48271019615021793, 'Total loss': 0.48271019615021793}
2022-11-28 05:41:59,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:41:59,578 INFO:     Epoch: 97
2022-11-28 05:42:00,245 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4587103131819855, 'Total loss': 0.4587103131819855} | train loss {'Reaction outcome loss': 0.4852939748812301, 'Total loss': 0.4852939748812301}
2022-11-28 05:42:00,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:00,245 INFO:     Epoch: 98
2022-11-28 05:42:00,911 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45895841040394525, 'Total loss': 0.45895841040394525} | train loss {'Reaction outcome loss': 0.4756850893590373, 'Total loss': 0.4756850893590373}
2022-11-28 05:42:00,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:00,912 INFO:     Epoch: 99
2022-11-28 05:42:01,581 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4765731973404234, 'Total loss': 0.4765731973404234} | train loss {'Reaction outcome loss': 0.4921094687431221, 'Total loss': 0.4921094687431221}
2022-11-28 05:42:01,581 INFO:     Best model found after epoch 72 of 100.
2022-11-28 05:42:01,581 INFO:   Done with stage: TRAINING
2022-11-28 05:42:01,582 INFO:   Starting stage: EVALUATION
2022-11-28 05:42:01,700 INFO:   Done with stage: EVALUATION
2022-11-28 05:42:01,700 INFO:   Leaving out SEQ value Fold_2
2022-11-28 05:42:01,712 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 05:42:01,713 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:42:02,359 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:42:02,359 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:42:02,430 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:42:02,430 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:42:02,430 INFO:     No hyperparam tuning for this model
2022-11-28 05:42:02,430 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:42:02,430 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:42:02,431 INFO:     None feature selector for col prot
2022-11-28 05:42:02,431 INFO:     None feature selector for col prot
2022-11-28 05:42:02,431 INFO:     None feature selector for col prot
2022-11-28 05:42:02,431 INFO:     None feature selector for col chem
2022-11-28 05:42:02,432 INFO:     None feature selector for col chem
2022-11-28 05:42:02,432 INFO:     None feature selector for col chem
2022-11-28 05:42:02,432 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:42:02,432 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:42:02,433 INFO:     Number of params in model 169651
2022-11-28 05:42:02,436 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:42:02,436 INFO:   Starting stage: TRAINING
2022-11-28 05:42:02,487 INFO:     Val loss before train {'Reaction outcome loss': 0.952563228995301, 'Total loss': 0.952563228995301}
2022-11-28 05:42:02,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:02,488 INFO:     Epoch: 0
2022-11-28 05:42:03,145 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.596642543410146, 'Total loss': 0.596642543410146} | train loss {'Reaction outcome loss': 0.6970372971941213, 'Total loss': 0.6970372971941213}
2022-11-28 05:42:03,145 INFO:     Found new best model at epoch 0
2022-11-28 05:42:03,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:03,146 INFO:     Epoch: 1
2022-11-28 05:42:03,803 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5171021292375964, 'Total loss': 0.5171021292375964} | train loss {'Reaction outcome loss': 0.5933261539359562, 'Total loss': 0.5933261539359562}
2022-11-28 05:42:03,803 INFO:     Found new best model at epoch 1
2022-11-28 05:42:03,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:03,804 INFO:     Epoch: 2
2022-11-28 05:42:04,463 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5031911439673845, 'Total loss': 0.5031911439673845} | train loss {'Reaction outcome loss': 0.5557943863458321, 'Total loss': 0.5557943863458321}
2022-11-28 05:42:04,464 INFO:     Found new best model at epoch 2
2022-11-28 05:42:04,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:04,464 INFO:     Epoch: 3
2022-11-28 05:42:05,122 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5304725835489672, 'Total loss': 0.5304725835489672} | train loss {'Reaction outcome loss': 0.5406792115603314, 'Total loss': 0.5406792115603314}
2022-11-28 05:42:05,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:05,122 INFO:     Epoch: 4
2022-11-28 05:42:05,781 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4889785564223001, 'Total loss': 0.4889785564223001} | train loss {'Reaction outcome loss': 0.520798920852239, 'Total loss': 0.520798920852239}
2022-11-28 05:42:05,781 INFO:     Found new best model at epoch 4
2022-11-28 05:42:05,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:05,782 INFO:     Epoch: 5
2022-11-28 05:42:06,441 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45468491315841675, 'Total loss': 0.45468491315841675} | train loss {'Reaction outcome loss': 0.5156195942984253, 'Total loss': 0.5156195942984253}
2022-11-28 05:42:06,441 INFO:     Found new best model at epoch 5
2022-11-28 05:42:06,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:06,442 INFO:     Epoch: 6
2022-11-28 05:42:07,102 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49987283175767855, 'Total loss': 0.49987283175767855} | train loss {'Reaction outcome loss': 0.5108458913984846, 'Total loss': 0.5108458913984846}
2022-11-28 05:42:07,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:07,102 INFO:     Epoch: 7
2022-11-28 05:42:07,762 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5069716919300168, 'Total loss': 0.5069716919300168} | train loss {'Reaction outcome loss': 0.49784783884638645, 'Total loss': 0.49784783884638645}
2022-11-28 05:42:07,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:07,763 INFO:     Epoch: 8
2022-11-28 05:42:08,421 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4797767903222594, 'Total loss': 0.4797767903222594} | train loss {'Reaction outcome loss': 0.4924265932230676, 'Total loss': 0.4924265932230676}
2022-11-28 05:42:08,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:08,421 INFO:     Epoch: 9
2022-11-28 05:42:09,079 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44820853062840393, 'Total loss': 0.44820853062840393} | train loss {'Reaction outcome loss': 0.49483605767371225, 'Total loss': 0.49483605767371225}
2022-11-28 05:42:09,079 INFO:     Found new best model at epoch 9
2022-11-28 05:42:09,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:09,080 INFO:     Epoch: 10
2022-11-28 05:42:09,739 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46010321933169696, 'Total loss': 0.46010321933169696} | train loss {'Reaction outcome loss': 0.4826114511147874, 'Total loss': 0.4826114511147874}
2022-11-28 05:42:09,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:09,739 INFO:     Epoch: 11
2022-11-28 05:42:10,397 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4474794320588888, 'Total loss': 0.4474794320588888} | train loss {'Reaction outcome loss': 0.4925852923608217, 'Total loss': 0.4925852923608217}
2022-11-28 05:42:10,397 INFO:     Found new best model at epoch 11
2022-11-28 05:42:10,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:10,398 INFO:     Epoch: 12
2022-11-28 05:42:11,056 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4515023027048555, 'Total loss': 0.4515023027048555} | train loss {'Reaction outcome loss': 0.48499854373150186, 'Total loss': 0.48499854373150186}
2022-11-28 05:42:11,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:11,056 INFO:     Epoch: 13
2022-11-28 05:42:11,714 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45553391756013384, 'Total loss': 0.45553391756013384} | train loss {'Reaction outcome loss': 0.4731900979016648, 'Total loss': 0.4731900979016648}
2022-11-28 05:42:11,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:11,714 INFO:     Epoch: 14
2022-11-28 05:42:12,371 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4423998920030372, 'Total loss': 0.4423998920030372} | train loss {'Reaction outcome loss': 0.4774844528588115, 'Total loss': 0.4774844528588115}
2022-11-28 05:42:12,372 INFO:     Found new best model at epoch 14
2022-11-28 05:42:12,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:12,372 INFO:     Epoch: 15
2022-11-28 05:42:13,033 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4563925023688826, 'Total loss': 0.4563925023688826} | train loss {'Reaction outcome loss': 0.4732323994279885, 'Total loss': 0.4732323994279885}
2022-11-28 05:42:13,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:13,034 INFO:     Epoch: 16
2022-11-28 05:42:13,694 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4310869480981383, 'Total loss': 0.4310869480981383} | train loss {'Reaction outcome loss': 0.4784862609793905, 'Total loss': 0.4784862609793905}
2022-11-28 05:42:13,694 INFO:     Found new best model at epoch 16
2022-11-28 05:42:13,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:13,695 INFO:     Epoch: 17
2022-11-28 05:42:14,356 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44165627727674883, 'Total loss': 0.44165627727674883} | train loss {'Reaction outcome loss': 0.4731071159304654, 'Total loss': 0.4731071159304654}
2022-11-28 05:42:14,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:14,356 INFO:     Epoch: 18
2022-11-28 05:42:15,012 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4772712744252626, 'Total loss': 0.4772712744252626} | train loss {'Reaction outcome loss': 0.4623023361334058, 'Total loss': 0.4623023361334058}
2022-11-28 05:42:15,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:15,012 INFO:     Epoch: 19
2022-11-28 05:42:15,672 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4763711843379708, 'Total loss': 0.4763711843379708} | train loss {'Reaction outcome loss': 0.4626505316891631, 'Total loss': 0.4626505316891631}
2022-11-28 05:42:15,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:15,672 INFO:     Epoch: 20
2022-11-28 05:42:16,335 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4298066621602968, 'Total loss': 0.4298066621602968} | train loss {'Reaction outcome loss': 0.4705252624193176, 'Total loss': 0.4705252624193176}
2022-11-28 05:42:16,335 INFO:     Found new best model at epoch 20
2022-11-28 05:42:16,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:16,336 INFO:     Epoch: 21
2022-11-28 05:42:16,992 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44452471476654676, 'Total loss': 0.44452471476654676} | train loss {'Reaction outcome loss': 0.4621773891639514, 'Total loss': 0.4621773891639514}
2022-11-28 05:42:16,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:16,992 INFO:     Epoch: 22
2022-11-28 05:42:17,647 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46242256150689237, 'Total loss': 0.46242256150689237} | train loss {'Reaction outcome loss': 0.4632514555801134, 'Total loss': 0.4632514555801134}
2022-11-28 05:42:17,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:17,647 INFO:     Epoch: 23
2022-11-28 05:42:18,301 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4190766884143962, 'Total loss': 0.4190766884143962} | train loss {'Reaction outcome loss': 0.46507156731896715, 'Total loss': 0.46507156731896715}
2022-11-28 05:42:18,301 INFO:     Found new best model at epoch 23
2022-11-28 05:42:18,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:18,302 INFO:     Epoch: 24
2022-11-28 05:42:18,956 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4870130152896393, 'Total loss': 0.4870130152896393} | train loss {'Reaction outcome loss': 0.4637503725339155, 'Total loss': 0.4637503725339155}
2022-11-28 05:42:18,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:18,956 INFO:     Epoch: 25
2022-11-28 05:42:19,613 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44262285807798074, 'Total loss': 0.44262285807798074} | train loss {'Reaction outcome loss': 0.46260353302980056, 'Total loss': 0.46260353302980056}
2022-11-28 05:42:19,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:19,613 INFO:     Epoch: 26
2022-11-28 05:42:20,269 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45071068787297536, 'Total loss': 0.45071068787297536} | train loss {'Reaction outcome loss': 0.46118284105399593, 'Total loss': 0.46118284105399593}
2022-11-28 05:42:20,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:20,269 INFO:     Epoch: 27
2022-11-28 05:42:20,926 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4460947607145753, 'Total loss': 0.4460947607145753} | train loss {'Reaction outcome loss': 0.46387597756674054, 'Total loss': 0.46387597756674054}
2022-11-28 05:42:20,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:20,927 INFO:     Epoch: 28
2022-11-28 05:42:21,584 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43840549054533934, 'Total loss': 0.43840549054533934} | train loss {'Reaction outcome loss': 0.46108964277950465, 'Total loss': 0.46108964277950465}
2022-11-28 05:42:21,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:21,584 INFO:     Epoch: 29
2022-11-28 05:42:22,239 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45529664359813515, 'Total loss': 0.45529664359813515} | train loss {'Reaction outcome loss': 0.47094482696447215, 'Total loss': 0.47094482696447215}
2022-11-28 05:42:22,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:22,246 INFO:     Epoch: 30
2022-11-28 05:42:22,899 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43956140064915944, 'Total loss': 0.43956140064915944} | train loss {'Reaction outcome loss': 0.4593506081671011, 'Total loss': 0.4593506081671011}
2022-11-28 05:42:22,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:22,899 INFO:     Epoch: 31
2022-11-28 05:42:23,554 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46537318063336747, 'Total loss': 0.46537318063336747} | train loss {'Reaction outcome loss': 0.4644441151472389, 'Total loss': 0.4644441151472389}
2022-11-28 05:42:23,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:23,554 INFO:     Epoch: 32
2022-11-28 05:42:24,208 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4319167681211649, 'Total loss': 0.4319167681211649} | train loss {'Reaction outcome loss': 0.46528485356295696, 'Total loss': 0.46528485356295696}
2022-11-28 05:42:24,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:24,208 INFO:     Epoch: 33
2022-11-28 05:42:24,864 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4421553563239963, 'Total loss': 0.4421553563239963} | train loss {'Reaction outcome loss': 0.45890717110672935, 'Total loss': 0.45890717110672935}
2022-11-28 05:42:24,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:24,864 INFO:     Epoch: 34
2022-11-28 05:42:25,518 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48154309391975403, 'Total loss': 0.48154309391975403} | train loss {'Reaction outcome loss': 0.465192579587952, 'Total loss': 0.465192579587952}
2022-11-28 05:42:25,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:25,519 INFO:     Epoch: 35
2022-11-28 05:42:26,176 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43427437959715376, 'Total loss': 0.43427437959715376} | train loss {'Reaction outcome loss': 0.46097025250802276, 'Total loss': 0.46097025250802276}
2022-11-28 05:42:26,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:26,176 INFO:     Epoch: 36
2022-11-28 05:42:26,832 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.438144164029942, 'Total loss': 0.438144164029942} | train loss {'Reaction outcome loss': 0.46032408081361503, 'Total loss': 0.46032408081361503}
2022-11-28 05:42:26,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:26,832 INFO:     Epoch: 37
2022-11-28 05:42:27,490 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4394014356441276, 'Total loss': 0.4394014356441276} | train loss {'Reaction outcome loss': 0.46165768429636955, 'Total loss': 0.46165768429636955}
2022-11-28 05:42:27,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:27,490 INFO:     Epoch: 38
2022-11-28 05:42:28,145 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44923157608786296, 'Total loss': 0.44923157608786296} | train loss {'Reaction outcome loss': 0.46747872419655323, 'Total loss': 0.46747872419655323}
2022-11-28 05:42:28,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:28,145 INFO:     Epoch: 39
2022-11-28 05:42:28,802 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46471373702204505, 'Total loss': 0.46471373702204505} | train loss {'Reaction outcome loss': 0.45794111545212934, 'Total loss': 0.45794111545212934}
2022-11-28 05:42:28,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:28,803 INFO:     Epoch: 40
2022-11-28 05:42:29,460 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42617732043876205, 'Total loss': 0.42617732043876205} | train loss {'Reaction outcome loss': 0.46596517682564065, 'Total loss': 0.46596517682564065}
2022-11-28 05:42:29,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:29,460 INFO:     Epoch: 41
2022-11-28 05:42:30,116 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4512299053197683, 'Total loss': 0.4512299053197683} | train loss {'Reaction outcome loss': 0.46070780965392705, 'Total loss': 0.46070780965392705}
2022-11-28 05:42:30,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:30,117 INFO:     Epoch: 42
2022-11-28 05:42:30,769 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41895491716473604, 'Total loss': 0.41895491716473604} | train loss {'Reaction outcome loss': 0.4613185085844798, 'Total loss': 0.4613185085844798}
2022-11-28 05:42:30,769 INFO:     Found new best model at epoch 42
2022-11-28 05:42:30,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:30,770 INFO:     Epoch: 43
2022-11-28 05:42:31,427 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4639383083166078, 'Total loss': 0.4639383083166078} | train loss {'Reaction outcome loss': 0.4581921587957711, 'Total loss': 0.4581921587957711}
2022-11-28 05:42:31,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:31,428 INFO:     Epoch: 44
2022-11-28 05:42:32,087 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4414686324984528, 'Total loss': 0.4414686324984528} | train loss {'Reaction outcome loss': 0.4617937775786783, 'Total loss': 0.4617937775786783}
2022-11-28 05:42:32,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:32,088 INFO:     Epoch: 45
2022-11-28 05:42:32,748 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46437049397202423, 'Total loss': 0.46437049397202423} | train loss {'Reaction outcome loss': 0.46704549204985624, 'Total loss': 0.46704549204985624}
2022-11-28 05:42:32,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:32,748 INFO:     Epoch: 46
2022-11-28 05:42:33,406 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4460984253606131, 'Total loss': 0.4460984253606131} | train loss {'Reaction outcome loss': 0.46856740776632655, 'Total loss': 0.46856740776632655}
2022-11-28 05:42:33,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:33,406 INFO:     Epoch: 47
2022-11-28 05:42:34,060 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43080243468284607, 'Total loss': 0.43080243468284607} | train loss {'Reaction outcome loss': 0.4616164399585763, 'Total loss': 0.4616164399585763}
2022-11-28 05:42:34,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:34,060 INFO:     Epoch: 48
2022-11-28 05:42:34,715 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4378955090461775, 'Total loss': 0.4378955090461775} | train loss {'Reaction outcome loss': 0.46411339950854663, 'Total loss': 0.46411339950854663}
2022-11-28 05:42:34,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:34,715 INFO:     Epoch: 49
2022-11-28 05:42:35,369 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4559990181479343, 'Total loss': 0.4559990181479343} | train loss {'Reaction outcome loss': 0.4647307150432321, 'Total loss': 0.4647307150432321}
2022-11-28 05:42:35,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:35,369 INFO:     Epoch: 50
2022-11-28 05:42:36,024 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4601062893174415, 'Total loss': 0.4601062893174415} | train loss {'Reaction outcome loss': 0.4615217558734241, 'Total loss': 0.4615217558734241}
2022-11-28 05:42:36,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:36,024 INFO:     Epoch: 51
2022-11-28 05:42:36,683 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4491235038568807, 'Total loss': 0.4491235038568807} | train loss {'Reaction outcome loss': 0.4637398394893427, 'Total loss': 0.4637398394893427}
2022-11-28 05:42:36,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:36,683 INFO:     Epoch: 52
2022-11-28 05:42:37,340 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43519020738989805, 'Total loss': 0.43519020738989805} | train loss {'Reaction outcome loss': 0.4667589273609099, 'Total loss': 0.4667589273609099}
2022-11-28 05:42:37,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:37,341 INFO:     Epoch: 53
2022-11-28 05:42:37,997 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44817891994187997, 'Total loss': 0.44817891994187997} | train loss {'Reaction outcome loss': 0.4655875903783274, 'Total loss': 0.4655875903783274}
2022-11-28 05:42:37,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:37,998 INFO:     Epoch: 54
2022-11-28 05:42:38,654 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46309533230094024, 'Total loss': 0.46309533230094024} | train loss {'Reaction outcome loss': 0.464294429746319, 'Total loss': 0.464294429746319}
2022-11-28 05:42:38,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:38,654 INFO:     Epoch: 55
2022-11-28 05:42:39,312 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4716240191875502, 'Total loss': 0.4716240191875502} | train loss {'Reaction outcome loss': 0.4652981041151969, 'Total loss': 0.4652981041151969}
2022-11-28 05:42:39,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:39,312 INFO:     Epoch: 56
2022-11-28 05:42:39,967 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41896547255821004, 'Total loss': 0.41896547255821004} | train loss {'Reaction outcome loss': 0.46109389987026084, 'Total loss': 0.46109389987026084}
2022-11-28 05:42:39,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:39,968 INFO:     Epoch: 57
2022-11-28 05:42:40,622 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4339102898226228, 'Total loss': 0.4339102898226228} | train loss {'Reaction outcome loss': 0.46275483004626683, 'Total loss': 0.46275483004626683}
2022-11-28 05:42:40,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:40,622 INFO:     Epoch: 58
2022-11-28 05:42:41,276 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.434976301567499, 'Total loss': 0.434976301567499} | train loss {'Reaction outcome loss': 0.4628951799002339, 'Total loss': 0.4628951799002339}
2022-11-28 05:42:41,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:41,276 INFO:     Epoch: 59
2022-11-28 05:42:41,933 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48484291829342063, 'Total loss': 0.48484291829342063} | train loss {'Reaction outcome loss': 0.4592195972800255, 'Total loss': 0.4592195972800255}
2022-11-28 05:42:41,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:41,933 INFO:     Epoch: 60
2022-11-28 05:42:42,587 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44264527704826623, 'Total loss': 0.44264527704826623} | train loss {'Reaction outcome loss': 0.4654386873494406, 'Total loss': 0.4654386873494406}
2022-11-28 05:42:42,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:42,587 INFO:     Epoch: 61
2022-11-28 05:42:43,246 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4452059109543645, 'Total loss': 0.4452059109543645} | train loss {'Reaction outcome loss': 0.4619812677751799, 'Total loss': 0.4619812677751799}
2022-11-28 05:42:43,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:43,246 INFO:     Epoch: 62
2022-11-28 05:42:43,899 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46716612820015396, 'Total loss': 0.46716612820015396} | train loss {'Reaction outcome loss': 0.4588440484443649, 'Total loss': 0.4588440484443649}
2022-11-28 05:42:43,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:43,900 INFO:     Epoch: 63
2022-11-28 05:42:44,557 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4404072328362354, 'Total loss': 0.4404072328362354} | train loss {'Reaction outcome loss': 0.4681861473277944, 'Total loss': 0.4681861473277944}
2022-11-28 05:42:44,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:44,558 INFO:     Epoch: 64
2022-11-28 05:42:45,213 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44555800841298215, 'Total loss': 0.44555800841298215} | train loss {'Reaction outcome loss': 0.4648044125528121, 'Total loss': 0.4648044125528121}
2022-11-28 05:42:45,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:45,213 INFO:     Epoch: 65
2022-11-28 05:42:45,868 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4685482694659122, 'Total loss': 0.4685482694659122} | train loss {'Reaction outcome loss': 0.46569845459011733, 'Total loss': 0.46569845459011733}
2022-11-28 05:42:45,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:45,868 INFO:     Epoch: 66
2022-11-28 05:42:46,538 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4796020475237869, 'Total loss': 0.4796020475237869} | train loss {'Reaction outcome loss': 0.46467912459715466, 'Total loss': 0.46467912459715466}
2022-11-28 05:42:46,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:46,538 INFO:     Epoch: 67
2022-11-28 05:42:47,192 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4599735047235045, 'Total loss': 0.4599735047235045} | train loss {'Reaction outcome loss': 0.46748981429416625, 'Total loss': 0.46748981429416625}
2022-11-28 05:42:47,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:47,192 INFO:     Epoch: 68
2022-11-28 05:42:47,848 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43384898991085763, 'Total loss': 0.43384898991085763} | train loss {'Reaction outcome loss': 0.4659670359287106, 'Total loss': 0.4659670359287106}
2022-11-28 05:42:47,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:47,848 INFO:     Epoch: 69
2022-11-28 05:42:48,504 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49261050376781196, 'Total loss': 0.49261050376781196} | train loss {'Reaction outcome loss': 0.46386978876028884, 'Total loss': 0.46386978876028884}
2022-11-28 05:42:48,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:48,504 INFO:     Epoch: 70
2022-11-28 05:42:49,157 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4306503697190174, 'Total loss': 0.4306503697190174} | train loss {'Reaction outcome loss': 0.4661317763269925, 'Total loss': 0.4661317763269925}
2022-11-28 05:42:49,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:49,157 INFO:     Epoch: 71
2022-11-28 05:42:49,811 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45521992306376613, 'Total loss': 0.45521992306376613} | train loss {'Reaction outcome loss': 0.4645962718813146, 'Total loss': 0.4645962718813146}
2022-11-28 05:42:49,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:49,811 INFO:     Epoch: 72
2022-11-28 05:42:50,468 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45418249451836873, 'Total loss': 0.45418249451836873} | train loss {'Reaction outcome loss': 0.4673400199437728, 'Total loss': 0.4673400199437728}
2022-11-28 05:42:50,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:50,469 INFO:     Epoch: 73
2022-11-28 05:42:51,124 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44554541797138925, 'Total loss': 0.44554541797138925} | train loss {'Reaction outcome loss': 0.4609132484822977, 'Total loss': 0.4609132484822977}
2022-11-28 05:42:51,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:51,124 INFO:     Epoch: 74
2022-11-28 05:42:51,780 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46656011495479316, 'Total loss': 0.46656011495479316} | train loss {'Reaction outcome loss': 0.45871065251651355, 'Total loss': 0.45871065251651355}
2022-11-28 05:42:51,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:51,781 INFO:     Epoch: 75
2022-11-28 05:42:52,435 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42718526409115903, 'Total loss': 0.42718526409115903} | train loss {'Reaction outcome loss': 0.466912232308847, 'Total loss': 0.466912232308847}
2022-11-28 05:42:52,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:52,435 INFO:     Epoch: 76
2022-11-28 05:42:53,090 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4400000904881677, 'Total loss': 0.4400000904881677} | train loss {'Reaction outcome loss': 0.4596092211174183, 'Total loss': 0.4596092211174183}
2022-11-28 05:42:53,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:53,090 INFO:     Epoch: 77
2022-11-28 05:42:53,745 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4336332072352254, 'Total loss': 0.4336332072352254} | train loss {'Reaction outcome loss': 0.4688218708653919, 'Total loss': 0.4688218708653919}
2022-11-28 05:42:53,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:53,745 INFO:     Epoch: 78
2022-11-28 05:42:54,400 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4475683878327525, 'Total loss': 0.4475683878327525} | train loss {'Reaction outcome loss': 0.4635986167876447, 'Total loss': 0.4635986167876447}
2022-11-28 05:42:54,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:54,401 INFO:     Epoch: 79
2022-11-28 05:42:55,058 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4695929410152657, 'Total loss': 0.4695929410152657} | train loss {'Reaction outcome loss': 0.46507511309302246, 'Total loss': 0.46507511309302246}
2022-11-28 05:42:55,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:55,058 INFO:     Epoch: 80
2022-11-28 05:42:55,714 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4600468340308167, 'Total loss': 0.4600468340308167} | train loss {'Reaction outcome loss': 0.45731161253862695, 'Total loss': 0.45731161253862695}
2022-11-28 05:42:55,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:55,714 INFO:     Epoch: 81
2022-11-28 05:42:56,366 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4360687025757723, 'Total loss': 0.4360687025757723} | train loss {'Reaction outcome loss': 0.4672158630412133, 'Total loss': 0.4672158630412133}
2022-11-28 05:42:56,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:56,368 INFO:     Epoch: 82
2022-11-28 05:42:57,024 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4579559571521227, 'Total loss': 0.4579559571521227} | train loss {'Reaction outcome loss': 0.464654268299947, 'Total loss': 0.464654268299947}
2022-11-28 05:42:57,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:57,024 INFO:     Epoch: 83
2022-11-28 05:42:57,682 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.50744285555773, 'Total loss': 0.50744285555773} | train loss {'Reaction outcome loss': 0.4610078322594283, 'Total loss': 0.4610078322594283}
2022-11-28 05:42:57,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:57,682 INFO:     Epoch: 84
2022-11-28 05:42:58,340 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4342351604339688, 'Total loss': 0.4342351604339688} | train loss {'Reaction outcome loss': 0.45759126049329024, 'Total loss': 0.45759126049329024}
2022-11-28 05:42:58,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:58,340 INFO:     Epoch: 85
2022-11-28 05:42:58,998 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46510677074277124, 'Total loss': 0.46510677074277124} | train loss {'Reaction outcome loss': 0.46372304908686973, 'Total loss': 0.46372304908686973}
2022-11-28 05:42:58,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:58,999 INFO:     Epoch: 86
2022-11-28 05:42:59,664 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46337244815604633, 'Total loss': 0.46337244815604633} | train loss {'Reaction outcome loss': 0.4635562491832209, 'Total loss': 0.4635562491832209}
2022-11-28 05:42:59,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:42:59,664 INFO:     Epoch: 87
2022-11-28 05:43:00,318 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4385198593832726, 'Total loss': 0.4385198593832726} | train loss {'Reaction outcome loss': 0.46491006941946805, 'Total loss': 0.46491006941946805}
2022-11-28 05:43:00,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:00,318 INFO:     Epoch: 88
2022-11-28 05:43:00,973 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4194506850353507, 'Total loss': 0.4194506850353507} | train loss {'Reaction outcome loss': 0.4697183830755167, 'Total loss': 0.4697183830755167}
2022-11-28 05:43:00,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:00,974 INFO:     Epoch: 89
2022-11-28 05:43:01,630 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4437089874300846, 'Total loss': 0.4437089874300846} | train loss {'Reaction outcome loss': 0.46877460291639705, 'Total loss': 0.46877460291639705}
2022-11-28 05:43:01,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:01,630 INFO:     Epoch: 90
2022-11-28 05:43:02,284 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44143077939055686, 'Total loss': 0.44143077939055686} | train loss {'Reaction outcome loss': 0.46323123910143726, 'Total loss': 0.46323123910143726}
2022-11-28 05:43:02,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:02,284 INFO:     Epoch: 91
2022-11-28 05:43:02,941 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45124346676260924, 'Total loss': 0.45124346676260924} | train loss {'Reaction outcome loss': 0.44919417419883073, 'Total loss': 0.44919417419883073}
2022-11-28 05:43:02,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:02,942 INFO:     Epoch: 92
2022-11-28 05:43:03,600 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4313794267038966, 'Total loss': 0.4313794267038966} | train loss {'Reaction outcome loss': 0.47148645547081214, 'Total loss': 0.47148645547081214}
2022-11-28 05:43:03,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:03,600 INFO:     Epoch: 93
2022-11-28 05:43:04,255 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45360654245975407, 'Total loss': 0.45360654245975407} | train loss {'Reaction outcome loss': 0.4657325700047563, 'Total loss': 0.4657325700047563}
2022-11-28 05:43:04,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:04,255 INFO:     Epoch: 94
2022-11-28 05:43:04,913 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4490395316550898, 'Total loss': 0.4490395316550898} | train loss {'Reaction outcome loss': 0.4652355872094631, 'Total loss': 0.4652355872094631}
2022-11-28 05:43:04,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:04,913 INFO:     Epoch: 95
2022-11-28 05:43:05,571 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4640710208305093, 'Total loss': 0.4640710208305093} | train loss {'Reaction outcome loss': 0.4636248328158113, 'Total loss': 0.4636248328158113}
2022-11-28 05:43:05,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:05,571 INFO:     Epoch: 96
2022-11-28 05:43:06,228 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4617553176574929, 'Total loss': 0.4617553176574929} | train loss {'Reaction outcome loss': 0.4663730500662913, 'Total loss': 0.4663730500662913}
2022-11-28 05:43:06,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:06,228 INFO:     Epoch: 97
2022-11-28 05:43:06,890 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4350159785082174, 'Total loss': 0.4350159785082174} | train loss {'Reaction outcome loss': 0.4645751524166983, 'Total loss': 0.4645751524166983}
2022-11-28 05:43:06,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:06,890 INFO:     Epoch: 98
2022-11-28 05:43:07,546 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44091115372125494, 'Total loss': 0.44091115372125494} | train loss {'Reaction outcome loss': 0.4585143881620931, 'Total loss': 0.4585143881620931}
2022-11-28 05:43:07,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:07,546 INFO:     Epoch: 99
2022-11-28 05:43:08,205 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4347020065368608, 'Total loss': 0.4347020065368608} | train loss {'Reaction outcome loss': 0.4685575539154596, 'Total loss': 0.4685575539154596}
2022-11-28 05:43:08,205 INFO:     Best model found after epoch 43 of 100.
2022-11-28 05:43:08,205 INFO:   Done with stage: TRAINING
2022-11-28 05:43:08,205 INFO:   Starting stage: EVALUATION
2022-11-28 05:43:08,335 INFO:   Done with stage: EVALUATION
2022-11-28 05:43:08,335 INFO:   Leaving out SEQ value Fold_3
2022-11-28 05:43:08,348 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 05:43:08,348 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:43:08,985 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:43:08,985 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:43:09,055 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:43:09,055 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:43:09,055 INFO:     No hyperparam tuning for this model
2022-11-28 05:43:09,055 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:43:09,056 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:43:09,056 INFO:     None feature selector for col prot
2022-11-28 05:43:09,056 INFO:     None feature selector for col prot
2022-11-28 05:43:09,056 INFO:     None feature selector for col prot
2022-11-28 05:43:09,057 INFO:     None feature selector for col chem
2022-11-28 05:43:09,057 INFO:     None feature selector for col chem
2022-11-28 05:43:09,057 INFO:     None feature selector for col chem
2022-11-28 05:43:09,057 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:43:09,057 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:43:09,059 INFO:     Number of params in model 169651
2022-11-28 05:43:09,062 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:43:09,062 INFO:   Starting stage: TRAINING
2022-11-28 05:43:09,112 INFO:     Val loss before train {'Reaction outcome loss': 1.0128885161044985, 'Total loss': 1.0128885161044985}
2022-11-28 05:43:09,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:09,113 INFO:     Epoch: 0
2022-11-28 05:43:09,767 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6066413164831871, 'Total loss': 0.6066413164831871} | train loss {'Reaction outcome loss': 0.6799618118584402, 'Total loss': 0.6799618118584402}
2022-11-28 05:43:09,767 INFO:     Found new best model at epoch 0
2022-11-28 05:43:09,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:09,768 INFO:     Epoch: 1
2022-11-28 05:43:10,419 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5302739524564077, 'Total loss': 0.5302739524564077} | train loss {'Reaction outcome loss': 0.5850204342799913, 'Total loss': 0.5850204342799913}
2022-11-28 05:43:10,419 INFO:     Found new best model at epoch 1
2022-11-28 05:43:10,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:10,420 INFO:     Epoch: 2
2022-11-28 05:43:11,070 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5278797170450521, 'Total loss': 0.5278797170450521} | train loss {'Reaction outcome loss': 0.5405245280437508, 'Total loss': 0.5405245280437508}
2022-11-28 05:43:11,070 INFO:     Found new best model at epoch 2
2022-11-28 05:43:11,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:11,071 INFO:     Epoch: 3
2022-11-28 05:43:11,719 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5015183139679044, 'Total loss': 0.5015183139679044} | train loss {'Reaction outcome loss': 0.5253532329581893, 'Total loss': 0.5253532329581893}
2022-11-28 05:43:11,719 INFO:     Found new best model at epoch 3
2022-11-28 05:43:11,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:11,720 INFO:     Epoch: 4
2022-11-28 05:43:12,372 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4500640963399133, 'Total loss': 0.4500640963399133} | train loss {'Reaction outcome loss': 0.5056977881264294, 'Total loss': 0.5056977881264294}
2022-11-28 05:43:12,372 INFO:     Found new best model at epoch 4
2022-11-28 05:43:12,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:12,373 INFO:     Epoch: 5
2022-11-28 05:43:13,025 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4610581030679304, 'Total loss': 0.4610581030679304} | train loss {'Reaction outcome loss': 0.4917245838990427, 'Total loss': 0.4917245838990427}
2022-11-28 05:43:13,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:13,025 INFO:     Epoch: 6
2022-11-28 05:43:13,678 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47896666235701985, 'Total loss': 0.47896666235701985} | train loss {'Reaction outcome loss': 0.49243039049116183, 'Total loss': 0.49243039049116183}
2022-11-28 05:43:13,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:13,678 INFO:     Epoch: 7
2022-11-28 05:43:14,331 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4660761162292126, 'Total loss': 0.4660761162292126} | train loss {'Reaction outcome loss': 0.4796278736718888, 'Total loss': 0.4796278736718888}
2022-11-28 05:43:14,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:14,332 INFO:     Epoch: 8
2022-11-28 05:43:14,984 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4538071373867434, 'Total loss': 0.4538071373867434} | train loss {'Reaction outcome loss': 0.4760123022789818, 'Total loss': 0.4760123022789818}
2022-11-28 05:43:14,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:14,985 INFO:     Epoch: 9
2022-11-28 05:43:15,636 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47157538456972253, 'Total loss': 0.47157538456972253} | train loss {'Reaction outcome loss': 0.4648788149464768, 'Total loss': 0.4648788149464768}
2022-11-28 05:43:15,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:15,636 INFO:     Epoch: 10
2022-11-28 05:43:16,289 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46120707517446474, 'Total loss': 0.46120707517446474} | train loss {'Reaction outcome loss': 0.46639812268592695, 'Total loss': 0.46639812268592695}
2022-11-28 05:43:16,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:16,289 INFO:     Epoch: 11
2022-11-28 05:43:16,941 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4554978896712148, 'Total loss': 0.4554978896712148} | train loss {'Reaction outcome loss': 0.4634767163682867, 'Total loss': 0.4634767163682867}
2022-11-28 05:43:16,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:16,941 INFO:     Epoch: 12
2022-11-28 05:43:17,592 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4513447014398353, 'Total loss': 0.4513447014398353} | train loss {'Reaction outcome loss': 0.4609266758087731, 'Total loss': 0.4609266758087731}
2022-11-28 05:43:17,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:17,592 INFO:     Epoch: 13
2022-11-28 05:43:18,245 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4397198422703632, 'Total loss': 0.4397198422703632} | train loss {'Reaction outcome loss': 0.4594445745518178, 'Total loss': 0.4594445745518178}
2022-11-28 05:43:18,245 INFO:     Found new best model at epoch 13
2022-11-28 05:43:18,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:18,246 INFO:     Epoch: 14
2022-11-28 05:43:18,900 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44666559994220734, 'Total loss': 0.44666559994220734} | train loss {'Reaction outcome loss': 0.4559245433949639, 'Total loss': 0.4559245433949639}
2022-11-28 05:43:18,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:18,900 INFO:     Epoch: 15
2022-11-28 05:43:19,554 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4612317158039226, 'Total loss': 0.4612317158039226} | train loss {'Reaction outcome loss': 0.4540989810424577, 'Total loss': 0.4540989810424577}
2022-11-28 05:43:19,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:19,554 INFO:     Epoch: 16
2022-11-28 05:43:20,208 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4376098465087802, 'Total loss': 0.4376098465087802} | train loss {'Reaction outcome loss': 0.46353517901995545, 'Total loss': 0.46353517901995545}
2022-11-28 05:43:20,208 INFO:     Found new best model at epoch 16
2022-11-28 05:43:20,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:20,209 INFO:     Epoch: 17
2022-11-28 05:43:20,862 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5050916009864141, 'Total loss': 0.5050916009864141} | train loss {'Reaction outcome loss': 0.4593082909230833, 'Total loss': 0.4593082909230833}
2022-11-28 05:43:20,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:20,862 INFO:     Epoch: 18
2022-11-28 05:43:21,516 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45080087299263755, 'Total loss': 0.45080087299263755} | train loss {'Reaction outcome loss': 0.46399771324033107, 'Total loss': 0.46399771324033107}
2022-11-28 05:43:21,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:21,516 INFO:     Epoch: 19
2022-11-28 05:43:22,170 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43124916976274447, 'Total loss': 0.43124916976274447} | train loss {'Reaction outcome loss': 0.46281605014585175, 'Total loss': 0.46281605014585175}
2022-11-28 05:43:22,170 INFO:     Found new best model at epoch 19
2022-11-28 05:43:22,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:22,170 INFO:     Epoch: 20
2022-11-28 05:43:22,822 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4679640600847643, 'Total loss': 0.4679640600847643} | train loss {'Reaction outcome loss': 0.4535119042352394, 'Total loss': 0.4535119042352394}
2022-11-28 05:43:22,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:22,822 INFO:     Epoch: 21
2022-11-28 05:43:23,477 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44765311652837797, 'Total loss': 0.44765311652837797} | train loss {'Reaction outcome loss': 0.4538132377244808, 'Total loss': 0.4538132377244808}
2022-11-28 05:43:23,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:23,477 INFO:     Epoch: 22
2022-11-28 05:43:24,131 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47735356071660684, 'Total loss': 0.47735356071660684} | train loss {'Reaction outcome loss': 0.45058302323759336, 'Total loss': 0.45058302323759336}
2022-11-28 05:43:24,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:24,131 INFO:     Epoch: 23
2022-11-28 05:43:24,783 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4386225696219954, 'Total loss': 0.4386225696219954} | train loss {'Reaction outcome loss': 0.45884508746886943, 'Total loss': 0.45884508746886943}
2022-11-28 05:43:24,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:24,783 INFO:     Epoch: 24
2022-11-28 05:43:25,436 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43394940433114076, 'Total loss': 0.43394940433114076} | train loss {'Reaction outcome loss': 0.4538131599073057, 'Total loss': 0.4538131599073057}
2022-11-28 05:43:25,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:25,437 INFO:     Epoch: 25
2022-11-28 05:43:26,089 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4360479892686356, 'Total loss': 0.4360479892686356} | train loss {'Reaction outcome loss': 0.4533608192156372, 'Total loss': 0.4533608192156372}
2022-11-28 05:43:26,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:26,089 INFO:     Epoch: 26
2022-11-28 05:43:26,743 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4172516499840936, 'Total loss': 0.4172516499840936} | train loss {'Reaction outcome loss': 0.4536140718700464, 'Total loss': 0.4536140718700464}
2022-11-28 05:43:26,743 INFO:     Found new best model at epoch 26
2022-11-28 05:43:26,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:26,744 INFO:     Epoch: 27
2022-11-28 05:43:27,401 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48863814771175385, 'Total loss': 0.48863814771175385} | train loss {'Reaction outcome loss': 0.45222366021739113, 'Total loss': 0.45222366021739113}
2022-11-28 05:43:27,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:27,402 INFO:     Epoch: 28
2022-11-28 05:43:28,058 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44510419250920763, 'Total loss': 0.44510419250920763} | train loss {'Reaction outcome loss': 0.4597886451845797, 'Total loss': 0.4597886451845797}
2022-11-28 05:43:28,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:28,059 INFO:     Epoch: 29
2022-11-28 05:43:28,712 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.434987434467604, 'Total loss': 0.434987434467604} | train loss {'Reaction outcome loss': 0.4550740408553999, 'Total loss': 0.4550740408553999}
2022-11-28 05:43:28,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:28,713 INFO:     Epoch: 30
2022-11-28 05:43:29,363 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4286152217970338, 'Total loss': 0.4286152217970338} | train loss {'Reaction outcome loss': 0.45532208570727595, 'Total loss': 0.45532208570727595}
2022-11-28 05:43:29,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:29,363 INFO:     Epoch: 31
2022-11-28 05:43:30,016 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45632617348848387, 'Total loss': 0.45632617348848387} | train loss {'Reaction outcome loss': 0.45339151940963884, 'Total loss': 0.45339151940963884}
2022-11-28 05:43:30,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:30,016 INFO:     Epoch: 32
2022-11-28 05:43:30,669 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44345355796259506, 'Total loss': 0.44345355796259506} | train loss {'Reaction outcome loss': 0.44889228714346396, 'Total loss': 0.44889228714346396}
2022-11-28 05:43:30,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:30,669 INFO:     Epoch: 33
2022-11-28 05:43:31,321 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.454059342658797, 'Total loss': 0.454059342658797} | train loss {'Reaction outcome loss': 0.44897140231397414, 'Total loss': 0.44897140231397414}
2022-11-28 05:43:31,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:31,321 INFO:     Epoch: 34
2022-11-28 05:43:31,974 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47514404703018276, 'Total loss': 0.47514404703018276} | train loss {'Reaction outcome loss': 0.45326695404180284, 'Total loss': 0.45326695404180284}
2022-11-28 05:43:31,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:31,974 INFO:     Epoch: 35
2022-11-28 05:43:32,626 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45336016492788184, 'Total loss': 0.45336016492788184} | train loss {'Reaction outcome loss': 0.45730367572709857, 'Total loss': 0.45730367572709857}
2022-11-28 05:43:32,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:32,626 INFO:     Epoch: 36
2022-11-28 05:43:33,278 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4959810178640277, 'Total loss': 0.4959810178640277} | train loss {'Reaction outcome loss': 0.45218330351904096, 'Total loss': 0.45218330351904096}
2022-11-28 05:43:33,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:33,278 INFO:     Epoch: 37
2022-11-28 05:43:33,931 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4783029452312824, 'Total loss': 0.4783029452312824} | train loss {'Reaction outcome loss': 0.45347402180418556, 'Total loss': 0.45347402180418556}
2022-11-28 05:43:33,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:33,931 INFO:     Epoch: 38
2022-11-28 05:43:34,580 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43291482502637907, 'Total loss': 0.43291482502637907} | train loss {'Reaction outcome loss': 0.44975789437078156, 'Total loss': 0.44975789437078156}
2022-11-28 05:43:34,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:34,580 INFO:     Epoch: 39
2022-11-28 05:43:35,235 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44418165572853974, 'Total loss': 0.44418165572853974} | train loss {'Reaction outcome loss': 0.4578187464441292, 'Total loss': 0.4578187464441292}
2022-11-28 05:43:35,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:35,235 INFO:     Epoch: 40
2022-11-28 05:43:35,888 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44565094071765277, 'Total loss': 0.44565094071765277} | train loss {'Reaction outcome loss': 0.451675887430401, 'Total loss': 0.451675887430401}
2022-11-28 05:43:35,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:35,889 INFO:     Epoch: 41
2022-11-28 05:43:36,541 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49832960824633754, 'Total loss': 0.49832960824633754} | train loss {'Reaction outcome loss': 0.45300543608734145, 'Total loss': 0.45300543608734145}
2022-11-28 05:43:36,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:36,541 INFO:     Epoch: 42
2022-11-28 05:43:37,196 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4535319406625836, 'Total loss': 0.4535319406625836} | train loss {'Reaction outcome loss': 0.44934282246440527, 'Total loss': 0.44934282246440527}
2022-11-28 05:43:37,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:37,197 INFO:     Epoch: 43
2022-11-28 05:43:37,853 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44482245729413145, 'Total loss': 0.44482245729413145} | train loss {'Reaction outcome loss': 0.459813618059021, 'Total loss': 0.459813618059021}
2022-11-28 05:43:37,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:37,854 INFO:     Epoch: 44
2022-11-28 05:43:38,509 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46458793067654897, 'Total loss': 0.46458793067654897} | train loss {'Reaction outcome loss': 0.4502522653512994, 'Total loss': 0.4502522653512994}
2022-11-28 05:43:38,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:38,509 INFO:     Epoch: 45
2022-11-28 05:43:39,163 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.453188119586124, 'Total loss': 0.453188119586124} | train loss {'Reaction outcome loss': 0.4590475460813369, 'Total loss': 0.4590475460813369}
2022-11-28 05:43:39,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:39,163 INFO:     Epoch: 46
2022-11-28 05:43:39,817 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4609702551780745, 'Total loss': 0.4609702551780745} | train loss {'Reaction outcome loss': 0.4573060787999581, 'Total loss': 0.4573060787999581}
2022-11-28 05:43:39,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:39,817 INFO:     Epoch: 47
2022-11-28 05:43:40,473 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4386237572098887, 'Total loss': 0.4386237572098887} | train loss {'Reaction outcome loss': 0.45665944156087473, 'Total loss': 0.45665944156087473}
2022-11-28 05:43:40,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:40,473 INFO:     Epoch: 48
2022-11-28 05:43:41,129 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4726904699968737, 'Total loss': 0.4726904699968737} | train loss {'Reaction outcome loss': 0.45332072080408103, 'Total loss': 0.45332072080408103}
2022-11-28 05:43:41,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:41,129 INFO:     Epoch: 49
2022-11-28 05:43:41,784 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46594108329262846, 'Total loss': 0.46594108329262846} | train loss {'Reaction outcome loss': 0.46057356409575223, 'Total loss': 0.46057356409575223}
2022-11-28 05:43:41,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:41,785 INFO:     Epoch: 50
2022-11-28 05:43:42,435 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4375731660876163, 'Total loss': 0.4375731660876163} | train loss {'Reaction outcome loss': 0.4535618631682769, 'Total loss': 0.4535618631682769}
2022-11-28 05:43:42,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:42,435 INFO:     Epoch: 51
2022-11-28 05:43:43,089 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.480056156945783, 'Total loss': 0.480056156945783} | train loss {'Reaction outcome loss': 0.4563693700994484, 'Total loss': 0.4563693700994484}
2022-11-28 05:43:43,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:43,089 INFO:     Epoch: 52
2022-11-28 05:43:43,746 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4303763713254485, 'Total loss': 0.4303763713254485} | train loss {'Reaction outcome loss': 0.45492679800516295, 'Total loss': 0.45492679800516295}
2022-11-28 05:43:43,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:43,746 INFO:     Epoch: 53
2022-11-28 05:43:44,400 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45208084617936334, 'Total loss': 0.45208084617936334} | train loss {'Reaction outcome loss': 0.45430434577994877, 'Total loss': 0.45430434577994877}
2022-11-28 05:43:44,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:44,400 INFO:     Epoch: 54
2022-11-28 05:43:45,053 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44585349739984026, 'Total loss': 0.44585349739984026} | train loss {'Reaction outcome loss': 0.45406366896972733, 'Total loss': 0.45406366896972733}
2022-11-28 05:43:45,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:45,054 INFO:     Epoch: 55
2022-11-28 05:43:45,713 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46754280703012335, 'Total loss': 0.46754280703012335} | train loss {'Reaction outcome loss': 0.451204711579001, 'Total loss': 0.451204711579001}
2022-11-28 05:43:45,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:45,713 INFO:     Epoch: 56
2022-11-28 05:43:46,379 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4206686640201613, 'Total loss': 0.4206686640201613} | train loss {'Reaction outcome loss': 0.4569987513646177, 'Total loss': 0.4569987513646177}
2022-11-28 05:43:46,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:46,380 INFO:     Epoch: 57
2022-11-28 05:43:47,028 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46617753041345017, 'Total loss': 0.46617753041345017} | train loss {'Reaction outcome loss': 0.44934301397192133, 'Total loss': 0.44934301397192133}
2022-11-28 05:43:47,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:47,029 INFO:     Epoch: 58
2022-11-28 05:43:47,682 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4495443417582401, 'Total loss': 0.4495443417582401} | train loss {'Reaction outcome loss': 0.46187948775880133, 'Total loss': 0.46187948775880133}
2022-11-28 05:43:47,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:47,682 INFO:     Epoch: 59
2022-11-28 05:43:48,334 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43841050773165946, 'Total loss': 0.43841050773165946} | train loss {'Reaction outcome loss': 0.4509133942455912, 'Total loss': 0.4509133942455912}
2022-11-28 05:43:48,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:48,334 INFO:     Epoch: 60
2022-11-28 05:43:48,985 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43230754587539405, 'Total loss': 0.43230754587539405} | train loss {'Reaction outcome loss': 0.45336000339239224, 'Total loss': 0.45336000339239224}
2022-11-28 05:43:48,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:48,985 INFO:     Epoch: 61
2022-11-28 05:43:49,641 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.436118452874727, 'Total loss': 0.436118452874727} | train loss {'Reaction outcome loss': 0.45280823574512585, 'Total loss': 0.45280823574512585}
2022-11-28 05:43:49,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:49,641 INFO:     Epoch: 62
2022-11-28 05:43:50,296 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5042240903821102, 'Total loss': 0.5042240903821102} | train loss {'Reaction outcome loss': 0.44529095108126415, 'Total loss': 0.44529095108126415}
2022-11-28 05:43:50,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:50,297 INFO:     Epoch: 63
2022-11-28 05:43:50,954 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4447640665741854, 'Total loss': 0.4447640665741854} | train loss {'Reaction outcome loss': 0.45769400686148265, 'Total loss': 0.45769400686148265}
2022-11-28 05:43:50,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:50,955 INFO:     Epoch: 64
2022-11-28 05:43:51,606 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4859634478424871, 'Total loss': 0.4859634478424871} | train loss {'Reaction outcome loss': 0.45514593785437046, 'Total loss': 0.45514593785437046}
2022-11-28 05:43:51,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:51,606 INFO:     Epoch: 65
2022-11-28 05:43:52,257 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4929438527933387, 'Total loss': 0.4929438527933387} | train loss {'Reaction outcome loss': 0.4496804404344578, 'Total loss': 0.4496804404344578}
2022-11-28 05:43:52,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:52,257 INFO:     Epoch: 66
2022-11-28 05:43:52,908 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4393748190513877, 'Total loss': 0.4393748190513877} | train loss {'Reaction outcome loss': 0.44793596348644776, 'Total loss': 0.44793596348644776}
2022-11-28 05:43:52,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:52,908 INFO:     Epoch: 67
2022-11-28 05:43:53,560 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4526774512473927, 'Total loss': 0.4526774512473927} | train loss {'Reaction outcome loss': 0.4519874980910815, 'Total loss': 0.4519874980910815}
2022-11-28 05:43:53,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:53,561 INFO:     Epoch: 68
2022-11-28 05:43:54,212 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43899779836105746, 'Total loss': 0.43899779836105746} | train loss {'Reaction outcome loss': 0.45179444517740985, 'Total loss': 0.45179444517740985}
2022-11-28 05:43:54,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:54,212 INFO:     Epoch: 69
2022-11-28 05:43:54,868 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4441405472367309, 'Total loss': 0.4441405472367309} | train loss {'Reaction outcome loss': 0.4498031851318147, 'Total loss': 0.4498031851318147}
2022-11-28 05:43:54,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:54,868 INFO:     Epoch: 70
2022-11-28 05:43:55,523 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4309545471224674, 'Total loss': 0.4309545471224674} | train loss {'Reaction outcome loss': 0.4610507295700748, 'Total loss': 0.4610507295700748}
2022-11-28 05:43:55,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:55,523 INFO:     Epoch: 71
2022-11-28 05:43:56,177 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43819808370845265, 'Total loss': 0.43819808370845265} | train loss {'Reaction outcome loss': 0.44950552088488277, 'Total loss': 0.44950552088488277}
2022-11-28 05:43:56,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:56,178 INFO:     Epoch: 72
2022-11-28 05:43:56,830 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4608109586460646, 'Total loss': 0.4608109586460646} | train loss {'Reaction outcome loss': 0.4517320278618071, 'Total loss': 0.4517320278618071}
2022-11-28 05:43:56,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:56,830 INFO:     Epoch: 73
2022-11-28 05:43:57,480 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4655133759559587, 'Total loss': 0.4655133759559587} | train loss {'Reaction outcome loss': 0.46065539961734425, 'Total loss': 0.46065539961734425}
2022-11-28 05:43:57,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:57,481 INFO:     Epoch: 74
2022-11-28 05:43:58,129 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4365845880536146, 'Total loss': 0.4365845880536146} | train loss {'Reaction outcome loss': 0.4481364586716326, 'Total loss': 0.4481364586716326}
2022-11-28 05:43:58,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:58,130 INFO:     Epoch: 75
2022-11-28 05:43:58,780 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43898165329944255, 'Total loss': 0.43898165329944255} | train loss {'Reaction outcome loss': 0.45223770649344835, 'Total loss': 0.45223770649344835}
2022-11-28 05:43:58,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:58,780 INFO:     Epoch: 76
2022-11-28 05:43:59,427 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4407406650310339, 'Total loss': 0.4407406650310339} | train loss {'Reaction outcome loss': 0.456274427136276, 'Total loss': 0.456274427136276}
2022-11-28 05:43:59,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:43:59,428 INFO:     Epoch: 77
2022-11-28 05:44:00,075 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44022057638611906, 'Total loss': 0.44022057638611906} | train loss {'Reaction outcome loss': 0.45502535189375465, 'Total loss': 0.45502535189375465}
2022-11-28 05:44:00,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:00,075 INFO:     Epoch: 78
2022-11-28 05:44:00,722 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4541610933320467, 'Total loss': 0.4541610933320467} | train loss {'Reaction outcome loss': 0.4510535117652681, 'Total loss': 0.4510535117652681}
2022-11-28 05:44:00,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:00,722 INFO:     Epoch: 79
2022-11-28 05:44:01,371 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42260426005651786, 'Total loss': 0.42260426005651786} | train loss {'Reaction outcome loss': 0.4489577936905402, 'Total loss': 0.4489577936905402}
2022-11-28 05:44:01,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:01,372 INFO:     Epoch: 80
2022-11-28 05:44:02,020 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4260236641695333, 'Total loss': 0.4260236641695333} | train loss {'Reaction outcome loss': 0.45125682572278464, 'Total loss': 0.45125682572278464}
2022-11-28 05:44:02,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:02,021 INFO:     Epoch: 81
2022-11-28 05:44:02,669 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44857544954433, 'Total loss': 0.44857544954433} | train loss {'Reaction outcome loss': 0.4465666379580282, 'Total loss': 0.4465666379580282}
2022-11-28 05:44:02,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:02,669 INFO:     Epoch: 82
2022-11-28 05:44:03,313 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4383291283319163, 'Total loss': 0.4383291283319163} | train loss {'Reaction outcome loss': 0.44554376994631417, 'Total loss': 0.44554376994631417}
2022-11-28 05:44:03,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:03,314 INFO:     Epoch: 83
2022-11-28 05:44:03,961 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4308649124794228, 'Total loss': 0.4308649124794228} | train loss {'Reaction outcome loss': 0.4545714560543559, 'Total loss': 0.4545714560543559}
2022-11-28 05:44:03,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:03,961 INFO:     Epoch: 84
2022-11-28 05:44:04,611 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47044353256391924, 'Total loss': 0.47044353256391924} | train loss {'Reaction outcome loss': 0.45279673594260905, 'Total loss': 0.45279673594260905}
2022-11-28 05:44:04,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:04,612 INFO:     Epoch: 85
2022-11-28 05:44:05,259 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49316859383915745, 'Total loss': 0.49316859383915745} | train loss {'Reaction outcome loss': 0.4547844212118981, 'Total loss': 0.4547844212118981}
2022-11-28 05:44:05,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:05,260 INFO:     Epoch: 86
2022-11-28 05:44:05,909 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4515593124683513, 'Total loss': 0.4515593124683513} | train loss {'Reaction outcome loss': 0.4500279830990995, 'Total loss': 0.4500279830990995}
2022-11-28 05:44:05,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:05,909 INFO:     Epoch: 87
2022-11-28 05:44:06,556 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44529381117155387, 'Total loss': 0.44529381117155387} | train loss {'Reaction outcome loss': 0.45311081648608786, 'Total loss': 0.45311081648608786}
2022-11-28 05:44:06,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:06,557 INFO:     Epoch: 88
2022-11-28 05:44:07,202 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4960091516029003, 'Total loss': 0.4960091516029003} | train loss {'Reaction outcome loss': 0.4483093602789773, 'Total loss': 0.4483093602789773}
2022-11-28 05:44:07,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:07,202 INFO:     Epoch: 89
2022-11-28 05:44:07,850 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43345893884814063, 'Total loss': 0.43345893884814063} | train loss {'Reaction outcome loss': 0.44867817983951097, 'Total loss': 0.44867817983951097}
2022-11-28 05:44:07,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:07,850 INFO:     Epoch: 90
2022-11-28 05:44:08,501 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4598165535649588, 'Total loss': 0.4598165535649588} | train loss {'Reaction outcome loss': 0.45070164730396783, 'Total loss': 0.45070164730396783}
2022-11-28 05:44:08,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:08,501 INFO:     Epoch: 91
2022-11-28 05:44:09,148 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48247329648150955, 'Total loss': 0.48247329648150955} | train loss {'Reaction outcome loss': 0.45115238507833993, 'Total loss': 0.45115238507833993}
2022-11-28 05:44:09,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:09,148 INFO:     Epoch: 92
2022-11-28 05:44:09,794 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45104891858821694, 'Total loss': 0.45104891858821694} | train loss {'Reaction outcome loss': 0.4549600997088868, 'Total loss': 0.4549600997088868}
2022-11-28 05:44:09,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:09,794 INFO:     Epoch: 93
2022-11-28 05:44:10,439 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4322849772004194, 'Total loss': 0.4322849772004194} | train loss {'Reaction outcome loss': 0.44673085470258456, 'Total loss': 0.44673085470258456}
2022-11-28 05:44:10,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:10,439 INFO:     Epoch: 94
2022-11-28 05:44:11,085 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4505659438842951, 'Total loss': 0.4505659438842951} | train loss {'Reaction outcome loss': 0.4469729850198997, 'Total loss': 0.4469729850198997}
2022-11-28 05:44:11,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:11,085 INFO:     Epoch: 95
2022-11-28 05:44:11,731 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4676941019851108, 'Total loss': 0.4676941019851108} | train loss {'Reaction outcome loss': 0.45424086438039696, 'Total loss': 0.45424086438039696}
2022-11-28 05:44:11,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:11,731 INFO:     Epoch: 96
2022-11-28 05:44:12,381 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4790123167426087, 'Total loss': 0.4790123167426087} | train loss {'Reaction outcome loss': 0.4487018756905701, 'Total loss': 0.4487018756905701}
2022-11-28 05:44:12,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:12,381 INFO:     Epoch: 97
2022-11-28 05:44:13,027 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4458917559579361, 'Total loss': 0.4458917559579361} | train loss {'Reaction outcome loss': 0.45475035859846774, 'Total loss': 0.45475035859846774}
2022-11-28 05:44:13,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:13,027 INFO:     Epoch: 98
2022-11-28 05:44:13,675 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4514696667360705, 'Total loss': 0.4514696667360705} | train loss {'Reaction outcome loss': 0.45476092198871293, 'Total loss': 0.45476092198871293}
2022-11-28 05:44:13,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:13,676 INFO:     Epoch: 99
2022-11-28 05:44:14,326 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4475834210251653, 'Total loss': 0.4475834210251653} | train loss {'Reaction outcome loss': 0.44673390599128643, 'Total loss': 0.44673390599128643}
2022-11-28 05:44:14,326 INFO:     Best model found after epoch 27 of 100.
2022-11-28 05:44:14,326 INFO:   Done with stage: TRAINING
2022-11-28 05:44:14,326 INFO:   Starting stage: EVALUATION
2022-11-28 05:44:14,460 INFO:   Done with stage: EVALUATION
2022-11-28 05:44:14,461 INFO:   Leaving out SEQ value Fold_4
2022-11-28 05:44:14,473 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:44:14,473 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:44:15,111 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:44:15,112 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:44:15,181 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:44:15,181 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:44:15,181 INFO:     No hyperparam tuning for this model
2022-11-28 05:44:15,181 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:44:15,181 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:44:15,182 INFO:     None feature selector for col prot
2022-11-28 05:44:15,182 INFO:     None feature selector for col prot
2022-11-28 05:44:15,182 INFO:     None feature selector for col prot
2022-11-28 05:44:15,183 INFO:     None feature selector for col chem
2022-11-28 05:44:15,183 INFO:     None feature selector for col chem
2022-11-28 05:44:15,183 INFO:     None feature selector for col chem
2022-11-28 05:44:15,183 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:44:15,183 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:44:15,184 INFO:     Number of params in model 169651
2022-11-28 05:44:15,187 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:44:15,187 INFO:   Starting stage: TRAINING
2022-11-28 05:44:15,238 INFO:     Val loss before train {'Reaction outcome loss': 1.0436337319287388, 'Total loss': 1.0436337319287388}
2022-11-28 05:44:15,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:15,238 INFO:     Epoch: 0
2022-11-28 05:44:15,898 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5699233805591409, 'Total loss': 0.5699233805591409} | train loss {'Reaction outcome loss': 0.6946914825844861, 'Total loss': 0.6946914825844861}
2022-11-28 05:44:15,899 INFO:     Found new best model at epoch 0
2022-11-28 05:44:15,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:15,899 INFO:     Epoch: 1
2022-11-28 05:44:16,556 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49700562723658304, 'Total loss': 0.49700562723658304} | train loss {'Reaction outcome loss': 0.5945409944786234, 'Total loss': 0.5945409944786234}
2022-11-28 05:44:16,556 INFO:     Found new best model at epoch 1
2022-11-28 05:44:16,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:16,556 INFO:     Epoch: 2
2022-11-28 05:44:17,215 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.537551824003458, 'Total loss': 0.537551824003458} | train loss {'Reaction outcome loss': 0.5533268261655622, 'Total loss': 0.5533268261655622}
2022-11-28 05:44:17,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:17,216 INFO:     Epoch: 3
2022-11-28 05:44:17,870 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5198311832818118, 'Total loss': 0.5198311832818118} | train loss {'Reaction outcome loss': 0.5448135369823046, 'Total loss': 0.5448135369823046}
2022-11-28 05:44:17,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:17,870 INFO:     Epoch: 4
2022-11-28 05:44:18,527 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5062082460658117, 'Total loss': 0.5062082460658117} | train loss {'Reaction outcome loss': 0.5318721133748047, 'Total loss': 0.5318721133748047}
2022-11-28 05:44:18,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:18,527 INFO:     Epoch: 5
2022-11-28 05:44:19,185 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5057997744191777, 'Total loss': 0.5057997744191777} | train loss {'Reaction outcome loss': 0.5292007702926875, 'Total loss': 0.5292007702926875}
2022-11-28 05:44:19,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:19,185 INFO:     Epoch: 6
2022-11-28 05:44:19,844 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4847897765311328, 'Total loss': 0.4847897765311328} | train loss {'Reaction outcome loss': 0.5144691433010977, 'Total loss': 0.5144691433010977}
2022-11-28 05:44:19,844 INFO:     Found new best model at epoch 6
2022-11-28 05:44:19,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:19,845 INFO:     Epoch: 7
2022-11-28 05:44:20,500 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49803614955056796, 'Total loss': 0.49803614955056796} | train loss {'Reaction outcome loss': 0.5109613934750499, 'Total loss': 0.5109613934750499}
2022-11-28 05:44:20,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:20,500 INFO:     Epoch: 8
2022-11-28 05:44:21,156 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4928162521259351, 'Total loss': 0.4928162521259351} | train loss {'Reaction outcome loss': 0.514939366564577, 'Total loss': 0.514939366564577}
2022-11-28 05:44:21,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:21,156 INFO:     Epoch: 9
2022-11-28 05:44:21,811 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45687555081465026, 'Total loss': 0.45687555081465026} | train loss {'Reaction outcome loss': 0.5196700993216472, 'Total loss': 0.5196700993216472}
2022-11-28 05:44:21,811 INFO:     Found new best model at epoch 9
2022-11-28 05:44:21,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:21,812 INFO:     Epoch: 10
2022-11-28 05:44:22,469 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4811844859610904, 'Total loss': 0.4811844859610904} | train loss {'Reaction outcome loss': 0.49821833783557057, 'Total loss': 0.49821833783557057}
2022-11-28 05:44:22,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:22,469 INFO:     Epoch: 11
2022-11-28 05:44:23,127 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4821926409547979, 'Total loss': 0.4821926409547979} | train loss {'Reaction outcome loss': 0.49870851453438947, 'Total loss': 0.49870851453438947}
2022-11-28 05:44:23,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:23,128 INFO:     Epoch: 12
2022-11-28 05:44:23,787 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.548996893519705, 'Total loss': 0.548996893519705} | train loss {'Reaction outcome loss': 0.49138083229565366, 'Total loss': 0.49138083229565366}
2022-11-28 05:44:23,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:23,787 INFO:     Epoch: 13
2022-11-28 05:44:24,445 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5043520283969966, 'Total loss': 0.5043520283969966} | train loss {'Reaction outcome loss': 0.4850610428252201, 'Total loss': 0.4850610428252201}
2022-11-28 05:44:24,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:24,445 INFO:     Epoch: 14
2022-11-28 05:44:25,102 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5216248299587857, 'Total loss': 0.5216248299587857} | train loss {'Reaction outcome loss': 0.498769847065331, 'Total loss': 0.498769847065331}
2022-11-28 05:44:25,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:25,102 INFO:     Epoch: 15
2022-11-28 05:44:25,762 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48349862613461236, 'Total loss': 0.48349862613461236} | train loss {'Reaction outcome loss': 0.5295832520690162, 'Total loss': 0.5295832520690162}
2022-11-28 05:44:25,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:25,762 INFO:     Epoch: 16
2022-11-28 05:44:26,423 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49995569444515486, 'Total loss': 0.49995569444515486} | train loss {'Reaction outcome loss': 0.5023706870885031, 'Total loss': 0.5023706870885031}
2022-11-28 05:44:26,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:26,423 INFO:     Epoch: 17
2022-11-28 05:44:27,086 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4466395757415078, 'Total loss': 0.4466395757415078} | train loss {'Reaction outcome loss': 0.5048169278302174, 'Total loss': 0.5048169278302174}
2022-11-28 05:44:27,086 INFO:     Found new best model at epoch 17
2022-11-28 05:44:27,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:27,087 INFO:     Epoch: 18
2022-11-28 05:44:27,747 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5045420690016313, 'Total loss': 0.5045420690016313} | train loss {'Reaction outcome loss': 0.49559987465349525, 'Total loss': 0.49559987465349525}
2022-11-28 05:44:27,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:27,747 INFO:     Epoch: 19
2022-11-28 05:44:28,409 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4582278457554904, 'Total loss': 0.4582278457554904} | train loss {'Reaction outcome loss': 0.49086535881888044, 'Total loss': 0.49086535881888044}
2022-11-28 05:44:28,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:28,410 INFO:     Epoch: 20
2022-11-28 05:44:29,071 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45890022441744804, 'Total loss': 0.45890022441744804} | train loss {'Reaction outcome loss': 0.4880120498147088, 'Total loss': 0.4880120498147088}
2022-11-28 05:44:29,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:29,071 INFO:     Epoch: 21
2022-11-28 05:44:29,735 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4569611061703075, 'Total loss': 0.4569611061703075} | train loss {'Reaction outcome loss': 0.4855696901552726, 'Total loss': 0.4855696901552726}
2022-11-28 05:44:29,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:29,736 INFO:     Epoch: 22
2022-11-28 05:44:30,395 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48017490248788486, 'Total loss': 0.48017490248788486} | train loss {'Reaction outcome loss': 0.48590585746263204, 'Total loss': 0.48590585746263204}
2022-11-28 05:44:30,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:30,395 INFO:     Epoch: 23
2022-11-28 05:44:31,057 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5339079800654541, 'Total loss': 0.5339079800654541} | train loss {'Reaction outcome loss': 0.48196032963059693, 'Total loss': 0.48196032963059693}
2022-11-28 05:44:31,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:31,057 INFO:     Epoch: 24
2022-11-28 05:44:31,715 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46556317670778796, 'Total loss': 0.46556317670778796} | train loss {'Reaction outcome loss': 0.48367039982968496, 'Total loss': 0.48367039982968496}
2022-11-28 05:44:31,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:31,715 INFO:     Epoch: 25
2022-11-28 05:44:32,376 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44006952541795646, 'Total loss': 0.44006952541795646} | train loss {'Reaction outcome loss': 0.4867835332929847, 'Total loss': 0.4867835332929847}
2022-11-28 05:44:32,376 INFO:     Found new best model at epoch 25
2022-11-28 05:44:32,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:32,377 INFO:     Epoch: 26
2022-11-28 05:44:33,039 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4879532618956132, 'Total loss': 0.4879532618956132} | train loss {'Reaction outcome loss': 0.48219481689727256, 'Total loss': 0.48219481689727256}
2022-11-28 05:44:33,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:33,039 INFO:     Epoch: 27
2022-11-28 05:44:33,698 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4550259526480328, 'Total loss': 0.4550259526480328} | train loss {'Reaction outcome loss': 0.48270005005815253, 'Total loss': 0.48270005005815253}
2022-11-28 05:44:33,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:33,698 INFO:     Epoch: 28
2022-11-28 05:44:34,360 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4755227762189778, 'Total loss': 0.4755227762189778} | train loss {'Reaction outcome loss': 0.4850329871361072, 'Total loss': 0.4850329871361072}
2022-11-28 05:44:34,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:34,360 INFO:     Epoch: 29
2022-11-28 05:44:35,020 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.459644367410378, 'Total loss': 0.459644367410378} | train loss {'Reaction outcome loss': 0.4840235868506586, 'Total loss': 0.4840235868506586}
2022-11-28 05:44:35,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:35,020 INFO:     Epoch: 30
2022-11-28 05:44:35,681 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5053726170550693, 'Total loss': 0.5053726170550693} | train loss {'Reaction outcome loss': 0.47062057078729275, 'Total loss': 0.47062057078729275}
2022-11-28 05:44:35,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:35,681 INFO:     Epoch: 31
2022-11-28 05:44:36,348 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4516231600533832, 'Total loss': 0.4516231600533832} | train loss {'Reaction outcome loss': 0.47677563197217004, 'Total loss': 0.47677563197217004}
2022-11-28 05:44:36,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:36,348 INFO:     Epoch: 32
2022-11-28 05:44:37,011 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4698533151637424, 'Total loss': 0.4698533151637424} | train loss {'Reaction outcome loss': 0.47138912782736636, 'Total loss': 0.47138912782736636}
2022-11-28 05:44:37,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:37,011 INFO:     Epoch: 33
2022-11-28 05:44:37,677 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.461312876844948, 'Total loss': 0.461312876844948} | train loss {'Reaction outcome loss': 0.473007001555883, 'Total loss': 0.473007001555883}
2022-11-28 05:44:37,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:37,677 INFO:     Epoch: 34
2022-11-28 05:44:38,339 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46949299120090227, 'Total loss': 0.46949299120090227} | train loss {'Reaction outcome loss': 0.4789090546277853, 'Total loss': 0.4789090546277853}
2022-11-28 05:44:38,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:38,339 INFO:     Epoch: 35
2022-11-28 05:44:38,997 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4989349574527957, 'Total loss': 0.4989349574527957} | train loss {'Reaction outcome loss': 0.46278729683225633, 'Total loss': 0.46278729683225633}
2022-11-28 05:44:38,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:38,998 INFO:     Epoch: 36
2022-11-28 05:44:39,657 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48749028315598314, 'Total loss': 0.48749028315598314} | train loss {'Reaction outcome loss': 0.47407488181040836, 'Total loss': 0.47407488181040836}
2022-11-28 05:44:39,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:39,657 INFO:     Epoch: 37
2022-11-28 05:44:40,319 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46579927883364936, 'Total loss': 0.46579927883364936} | train loss {'Reaction outcome loss': 0.46904614543625217, 'Total loss': 0.46904614543625217}
2022-11-28 05:44:40,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:40,319 INFO:     Epoch: 38
2022-11-28 05:44:40,979 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4800327078185298, 'Total loss': 0.4800327078185298} | train loss {'Reaction outcome loss': 0.482069023948932, 'Total loss': 0.482069023948932}
2022-11-28 05:44:40,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:40,979 INFO:     Epoch: 39
2022-11-28 05:44:41,640 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4770943695171313, 'Total loss': 0.4770943695171313} | train loss {'Reaction outcome loss': 0.4789234131936602, 'Total loss': 0.4789234131936602}
2022-11-28 05:44:41,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:41,640 INFO:     Epoch: 40
2022-11-28 05:44:42,301 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4485802762210369, 'Total loss': 0.4485802762210369} | train loss {'Reaction outcome loss': 0.47698943805598054, 'Total loss': 0.47698943805598054}
2022-11-28 05:44:42,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:42,301 INFO:     Epoch: 41
2022-11-28 05:44:42,965 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4417704211717302, 'Total loss': 0.4417704211717302} | train loss {'Reaction outcome loss': 0.473899550585129, 'Total loss': 0.473899550585129}
2022-11-28 05:44:42,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:42,965 INFO:     Epoch: 42
2022-11-28 05:44:43,628 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44063550064509566, 'Total loss': 0.44063550064509566} | train loss {'Reaction outcome loss': 0.47830432804248596, 'Total loss': 0.47830432804248596}
2022-11-28 05:44:43,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:43,628 INFO:     Epoch: 43
2022-11-28 05:44:44,291 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4640679989348758, 'Total loss': 0.4640679989348758} | train loss {'Reaction outcome loss': 0.46398851496397486, 'Total loss': 0.46398851496397486}
2022-11-28 05:44:44,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:44,292 INFO:     Epoch: 44
2022-11-28 05:44:44,952 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46249580586498434, 'Total loss': 0.46249580586498434} | train loss {'Reaction outcome loss': 0.47018156644062475, 'Total loss': 0.47018156644062475}
2022-11-28 05:44:44,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:44,952 INFO:     Epoch: 45
2022-11-28 05:44:45,615 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4484892206435854, 'Total loss': 0.4484892206435854} | train loss {'Reaction outcome loss': 0.470482688080444, 'Total loss': 0.470482688080444}
2022-11-28 05:44:45,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:45,615 INFO:     Epoch: 46
2022-11-28 05:44:46,275 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5340828380801461, 'Total loss': 0.5340828380801461} | train loss {'Reaction outcome loss': 0.4806910432231337, 'Total loss': 0.4806910432231337}
2022-11-28 05:44:46,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:46,276 INFO:     Epoch: 47
2022-11-28 05:44:46,938 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47287984463301574, 'Total loss': 0.47287984463301574} | train loss {'Reaction outcome loss': 0.4694049857285341, 'Total loss': 0.4694049857285341}
2022-11-28 05:44:46,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:46,938 INFO:     Epoch: 48
2022-11-28 05:44:47,599 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4765004366636276, 'Total loss': 0.4765004366636276} | train loss {'Reaction outcome loss': 0.4871905129327465, 'Total loss': 0.4871905129327465}
2022-11-28 05:44:47,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:47,599 INFO:     Epoch: 49
2022-11-28 05:44:48,259 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44590417024764145, 'Total loss': 0.44590417024764145} | train loss {'Reaction outcome loss': 0.477552685117432, 'Total loss': 0.477552685117432}
2022-11-28 05:44:48,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:48,260 INFO:     Epoch: 50
2022-11-28 05:44:48,918 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4588342505422505, 'Total loss': 0.4588342505422505} | train loss {'Reaction outcome loss': 0.4724646509296981, 'Total loss': 0.4724646509296981}
2022-11-28 05:44:48,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:48,919 INFO:     Epoch: 51
2022-11-28 05:44:49,579 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4429613863202659, 'Total loss': 0.4429613863202659} | train loss {'Reaction outcome loss': 0.47814548540453194, 'Total loss': 0.47814548540453194}
2022-11-28 05:44:49,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:49,579 INFO:     Epoch: 52
2022-11-28 05:44:50,239 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4577017829499461, 'Total loss': 0.4577017829499461} | train loss {'Reaction outcome loss': 0.47257351293134303, 'Total loss': 0.47257351293134303}
2022-11-28 05:44:50,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:50,239 INFO:     Epoch: 53
2022-11-28 05:44:50,898 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44963055645877664, 'Total loss': 0.44963055645877664} | train loss {'Reaction outcome loss': 0.47785351627510086, 'Total loss': 0.47785351627510086}
2022-11-28 05:44:50,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:50,898 INFO:     Epoch: 54
2022-11-28 05:44:51,556 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4427539567378434, 'Total loss': 0.4427539567378434} | train loss {'Reaction outcome loss': 0.47338046809198403, 'Total loss': 0.47338046809198403}
2022-11-28 05:44:51,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:51,556 INFO:     Epoch: 55
2022-11-28 05:44:52,210 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4693116122348742, 'Total loss': 0.4693116122348742} | train loss {'Reaction outcome loss': 0.4658120264287902, 'Total loss': 0.4658120264287902}
2022-11-28 05:44:52,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:52,210 INFO:     Epoch: 56
2022-11-28 05:44:52,867 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4508696371181445, 'Total loss': 0.4508696371181445} | train loss {'Reaction outcome loss': 0.4709508802123398, 'Total loss': 0.4709508802123398}
2022-11-28 05:44:52,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:52,867 INFO:     Epoch: 57
2022-11-28 05:44:53,526 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4774326411160556, 'Total loss': 0.4774326411160556} | train loss {'Reaction outcome loss': 0.47414458066466364, 'Total loss': 0.47414458066466364}
2022-11-28 05:44:53,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:53,526 INFO:     Epoch: 58
2022-11-28 05:44:54,183 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5521229187195952, 'Total loss': 0.5521229187195952} | train loss {'Reaction outcome loss': 0.48401492731532586, 'Total loss': 0.48401492731532586}
2022-11-28 05:44:54,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:54,183 INFO:     Epoch: 59
2022-11-28 05:44:54,840 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43255377967249264, 'Total loss': 0.43255377967249264} | train loss {'Reaction outcome loss': 0.4768595648507648, 'Total loss': 0.4768595648507648}
2022-11-28 05:44:54,840 INFO:     Found new best model at epoch 59
2022-11-28 05:44:54,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:54,841 INFO:     Epoch: 60
2022-11-28 05:44:55,498 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43597623536532576, 'Total loss': 0.43597623536532576} | train loss {'Reaction outcome loss': 0.4714041513651006, 'Total loss': 0.4714041513651006}
2022-11-28 05:44:55,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:55,498 INFO:     Epoch: 61
2022-11-28 05:44:56,155 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4747016162357547, 'Total loss': 0.4747016162357547} | train loss {'Reaction outcome loss': 0.468576417308346, 'Total loss': 0.468576417308346}
2022-11-28 05:44:56,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:56,155 INFO:     Epoch: 62
2022-11-28 05:44:56,816 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4859396466477351, 'Total loss': 0.4859396466477351} | train loss {'Reaction outcome loss': 0.47082719401369694, 'Total loss': 0.47082719401369694}
2022-11-28 05:44:56,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:56,816 INFO:     Epoch: 63
2022-11-28 05:44:57,476 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44441430270671844, 'Total loss': 0.44441430270671844} | train loss {'Reaction outcome loss': 0.46949347352933307, 'Total loss': 0.46949347352933307}
2022-11-28 05:44:57,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:57,477 INFO:     Epoch: 64
2022-11-28 05:44:58,134 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4436428513039242, 'Total loss': 0.4436428513039242} | train loss {'Reaction outcome loss': 0.46595713224729546, 'Total loss': 0.46595713224729546}
2022-11-28 05:44:58,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:58,134 INFO:     Epoch: 65
2022-11-28 05:44:58,791 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44748457250269974, 'Total loss': 0.44748457250269974} | train loss {'Reaction outcome loss': 0.472676347202135, 'Total loss': 0.472676347202135}
2022-11-28 05:44:58,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:58,792 INFO:     Epoch: 66
2022-11-28 05:44:59,449 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4603480777957223, 'Total loss': 0.4603480777957223} | train loss {'Reaction outcome loss': 0.4779792172826736, 'Total loss': 0.4779792172826736}
2022-11-28 05:44:59,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:44:59,449 INFO:     Epoch: 67
2022-11-28 05:45:00,105 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43886073848063295, 'Total loss': 0.43886073848063295} | train loss {'Reaction outcome loss': 0.47150784247339916, 'Total loss': 0.47150784247339916}
2022-11-28 05:45:00,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:00,106 INFO:     Epoch: 68
2022-11-28 05:45:00,762 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4548194059594111, 'Total loss': 0.4548194059594111} | train loss {'Reaction outcome loss': 0.46236419026185627, 'Total loss': 0.46236419026185627}
2022-11-28 05:45:00,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:00,764 INFO:     Epoch: 69
2022-11-28 05:45:01,422 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4883322952823205, 'Total loss': 0.4883322952823205} | train loss {'Reaction outcome loss': 0.470788582676818, 'Total loss': 0.470788582676818}
2022-11-28 05:45:01,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:01,422 INFO:     Epoch: 70
2022-11-28 05:45:02,078 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48195737278596923, 'Total loss': 0.48195737278596923} | train loss {'Reaction outcome loss': 0.47198678933174504, 'Total loss': 0.47198678933174504}
2022-11-28 05:45:02,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:02,078 INFO:     Epoch: 71
2022-11-28 05:45:02,737 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48274748569185083, 'Total loss': 0.48274748569185083} | train loss {'Reaction outcome loss': 0.47826737243878215, 'Total loss': 0.47826737243878215}
2022-11-28 05:45:02,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:02,737 INFO:     Epoch: 72
2022-11-28 05:45:03,390 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43136581947857683, 'Total loss': 0.43136581947857683} | train loss {'Reaction outcome loss': 0.4754852008014193, 'Total loss': 0.4754852008014193}
2022-11-28 05:45:03,391 INFO:     Found new best model at epoch 72
2022-11-28 05:45:03,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:03,391 INFO:     Epoch: 73
2022-11-28 05:45:04,049 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46562975543466484, 'Total loss': 0.46562975543466484} | train loss {'Reaction outcome loss': 0.46205768264407815, 'Total loss': 0.46205768264407815}
2022-11-28 05:45:04,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:04,049 INFO:     Epoch: 74
2022-11-28 05:45:04,709 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43729944967410783, 'Total loss': 0.43729944967410783} | train loss {'Reaction outcome loss': 0.467879142114508, 'Total loss': 0.467879142114508}
2022-11-28 05:45:04,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:04,710 INFO:     Epoch: 75
2022-11-28 05:45:05,369 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4450533047995784, 'Total loss': 0.4450533047995784} | train loss {'Reaction outcome loss': 0.4660953478171275, 'Total loss': 0.4660953478171275}
2022-11-28 05:45:05,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:05,370 INFO:     Epoch: 76
2022-11-28 05:45:06,025 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4231305806474252, 'Total loss': 0.4231305806474252} | train loss {'Reaction outcome loss': 0.48380925979932793, 'Total loss': 0.48380925979932793}
2022-11-28 05:45:06,025 INFO:     Found new best model at epoch 76
2022-11-28 05:45:06,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:06,026 INFO:     Epoch: 77
2022-11-28 05:45:06,685 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43933392654765735, 'Total loss': 0.43933392654765735} | train loss {'Reaction outcome loss': 0.4675962980459576, 'Total loss': 0.4675962980459576}
2022-11-28 05:45:06,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:06,685 INFO:     Epoch: 78
2022-11-28 05:45:07,346 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5072454644197767, 'Total loss': 0.5072454644197767} | train loss {'Reaction outcome loss': 0.4658483704815992, 'Total loss': 0.4658483704815992}
2022-11-28 05:45:07,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:07,347 INFO:     Epoch: 79
2022-11-28 05:45:08,008 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45448953353545885, 'Total loss': 0.45448953353545885} | train loss {'Reaction outcome loss': 0.49312821038157834, 'Total loss': 0.49312821038157834}
2022-11-28 05:45:08,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:08,008 INFO:     Epoch: 80
2022-11-28 05:45:08,663 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5135940374298529, 'Total loss': 0.5135940374298529} | train loss {'Reaction outcome loss': 0.47112550619642746, 'Total loss': 0.47112550619642746}
2022-11-28 05:45:08,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:08,663 INFO:     Epoch: 81
2022-11-28 05:45:09,322 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45865182917226444, 'Total loss': 0.45865182917226444} | train loss {'Reaction outcome loss': 0.485610613637125, 'Total loss': 0.485610613637125}
2022-11-28 05:45:09,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:09,322 INFO:     Epoch: 82
2022-11-28 05:45:09,978 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4366482360796495, 'Total loss': 0.4366482360796495} | train loss {'Reaction outcome loss': 0.4757289433520031, 'Total loss': 0.4757289433520031}
2022-11-28 05:45:09,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:09,978 INFO:     Epoch: 83
2022-11-28 05:45:10,637 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4318389438770034, 'Total loss': 0.4318389438770034} | train loss {'Reaction outcome loss': 0.4683629296539042, 'Total loss': 0.4683629296539042}
2022-11-28 05:45:10,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:10,637 INFO:     Epoch: 84
2022-11-28 05:45:11,297 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45571003820408473, 'Total loss': 0.45571003820408473} | train loss {'Reaction outcome loss': 0.46137813166507824, 'Total loss': 0.46137813166507824}
2022-11-28 05:45:11,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:11,297 INFO:     Epoch: 85
2022-11-28 05:45:11,959 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4998764263635332, 'Total loss': 0.4998764263635332} | train loss {'Reaction outcome loss': 0.4667346687018419, 'Total loss': 0.4667346687018419}
2022-11-28 05:45:11,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:11,959 INFO:     Epoch: 86
2022-11-28 05:45:12,624 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44286197965795343, 'Total loss': 0.44286197965795343} | train loss {'Reaction outcome loss': 0.4721694860139839, 'Total loss': 0.4721694860139839}
2022-11-28 05:45:12,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:12,624 INFO:     Epoch: 87
2022-11-28 05:45:13,284 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42985912412405014, 'Total loss': 0.42985912412405014} | train loss {'Reaction outcome loss': 0.4719239715863819, 'Total loss': 0.4719239715863819}
2022-11-28 05:45:13,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:13,285 INFO:     Epoch: 88
2022-11-28 05:45:13,943 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4369479915635152, 'Total loss': 0.4369479915635152} | train loss {'Reaction outcome loss': 0.473616093759112, 'Total loss': 0.473616093759112}
2022-11-28 05:45:13,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:13,943 INFO:     Epoch: 89
2022-11-28 05:45:14,600 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4892628555270759, 'Total loss': 0.4892628555270759} | train loss {'Reaction outcome loss': 0.468242682328048, 'Total loss': 0.468242682328048}
2022-11-28 05:45:14,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:14,600 INFO:     Epoch: 90
2022-11-28 05:45:15,259 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4535693580454046, 'Total loss': 0.4535693580454046} | train loss {'Reaction outcome loss': 0.46610545587201835, 'Total loss': 0.46610545587201835}
2022-11-28 05:45:15,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:15,259 INFO:     Epoch: 91
2022-11-28 05:45:15,916 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45620062066750094, 'Total loss': 0.45620062066750094} | train loss {'Reaction outcome loss': 0.4735465745935556, 'Total loss': 0.4735465745935556}
2022-11-28 05:45:15,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:15,916 INFO:     Epoch: 92
2022-11-28 05:45:16,569 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44873714447021484, 'Total loss': 0.44873714447021484} | train loss {'Reaction outcome loss': 0.4741010629696402, 'Total loss': 0.4741010629696402}
2022-11-28 05:45:16,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:16,569 INFO:     Epoch: 93
2022-11-28 05:45:17,225 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4523367610844699, 'Total loss': 0.4523367610844699} | train loss {'Reaction outcome loss': 0.48001676285073824, 'Total loss': 0.48001676285073824}
2022-11-28 05:45:17,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:17,226 INFO:     Epoch: 94
2022-11-28 05:45:17,879 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4580066600306468, 'Total loss': 0.4580066600306468} | train loss {'Reaction outcome loss': 0.47029926489118623, 'Total loss': 0.47029926489118623}
2022-11-28 05:45:17,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:17,880 INFO:     Epoch: 95
2022-11-28 05:45:18,538 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48855039511214604, 'Total loss': 0.48855039511214604} | train loss {'Reaction outcome loss': 0.4768630798891006, 'Total loss': 0.4768630798891006}
2022-11-28 05:45:18,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:18,538 INFO:     Epoch: 96
2022-11-28 05:45:19,196 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4467573531649329, 'Total loss': 0.4467573531649329} | train loss {'Reaction outcome loss': 0.4809315543063739, 'Total loss': 0.4809315543063739}
2022-11-28 05:45:19,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:19,197 INFO:     Epoch: 97
2022-11-28 05:45:19,856 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.447180243039673, 'Total loss': 0.447180243039673} | train loss {'Reaction outcome loss': 0.47843609327216624, 'Total loss': 0.47843609327216624}
2022-11-28 05:45:19,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:19,857 INFO:     Epoch: 98
2022-11-28 05:45:20,515 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43388851156288927, 'Total loss': 0.43388851156288927} | train loss {'Reaction outcome loss': 0.4648353236044949, 'Total loss': 0.4648353236044949}
2022-11-28 05:45:20,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:20,515 INFO:     Epoch: 99
2022-11-28 05:45:21,177 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42994537407701666, 'Total loss': 0.42994537407701666} | train loss {'Reaction outcome loss': 0.4708125070944006, 'Total loss': 0.4708125070944006}
2022-11-28 05:45:21,177 INFO:     Best model found after epoch 77 of 100.
2022-11-28 05:45:21,177 INFO:   Done with stage: TRAINING
2022-11-28 05:45:21,177 INFO:   Starting stage: EVALUATION
2022-11-28 05:45:21,295 INFO:   Done with stage: EVALUATION
2022-11-28 05:45:21,295 INFO:   Leaving out SEQ value Fold_5
2022-11-28 05:45:21,308 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:45:21,308 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:45:21,939 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:45:21,939 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:45:22,008 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:45:22,008 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:45:22,008 INFO:     No hyperparam tuning for this model
2022-11-28 05:45:22,008 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:45:22,009 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:45:22,009 INFO:     None feature selector for col prot
2022-11-28 05:45:22,009 INFO:     None feature selector for col prot
2022-11-28 05:45:22,009 INFO:     None feature selector for col prot
2022-11-28 05:45:22,010 INFO:     None feature selector for col chem
2022-11-28 05:45:22,010 INFO:     None feature selector for col chem
2022-11-28 05:45:22,010 INFO:     None feature selector for col chem
2022-11-28 05:45:22,010 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:45:22,010 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:45:22,012 INFO:     Number of params in model 169651
2022-11-28 05:45:22,014 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:45:22,015 INFO:   Starting stage: TRAINING
2022-11-28 05:45:22,065 INFO:     Val loss before train {'Reaction outcome loss': 0.9764332459731535, 'Total loss': 0.9764332459731535}
2022-11-28 05:45:22,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:22,066 INFO:     Epoch: 0
2022-11-28 05:45:22,732 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6314849650317972, 'Total loss': 0.6314849650317972} | train loss {'Reaction outcome loss': 0.6885572136775685, 'Total loss': 0.6885572136775685}
2022-11-28 05:45:22,732 INFO:     Found new best model at epoch 0
2022-11-28 05:45:22,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:22,733 INFO:     Epoch: 1
2022-11-28 05:45:23,402 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5926898589188402, 'Total loss': 0.5926898589188402} | train loss {'Reaction outcome loss': 0.5956178498774888, 'Total loss': 0.5956178498774888}
2022-11-28 05:45:23,402 INFO:     Found new best model at epoch 1
2022-11-28 05:45:23,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:23,403 INFO:     Epoch: 2
2022-11-28 05:45:24,062 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.609392061829567, 'Total loss': 0.609392061829567} | train loss {'Reaction outcome loss': 0.5787391445263919, 'Total loss': 0.5787391445263919}
2022-11-28 05:45:24,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:24,062 INFO:     Epoch: 3
2022-11-28 05:45:24,720 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.536233826117082, 'Total loss': 0.536233826117082} | train loss {'Reaction outcome loss': 0.5574759808387834, 'Total loss': 0.5574759808387834}
2022-11-28 05:45:24,721 INFO:     Found new best model at epoch 3
2022-11-28 05:45:24,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:24,721 INFO:     Epoch: 4
2022-11-28 05:45:25,381 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5580207698724486, 'Total loss': 0.5580207698724486} | train loss {'Reaction outcome loss': 0.5411540467729453, 'Total loss': 0.5411540467729453}
2022-11-28 05:45:25,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:25,381 INFO:     Epoch: 5
2022-11-28 05:45:26,040 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5356306589462541, 'Total loss': 0.5356306589462541} | train loss {'Reaction outcome loss': 0.5360761613015704, 'Total loss': 0.5360761613015704}
2022-11-28 05:45:26,041 INFO:     Found new best model at epoch 5
2022-11-28 05:45:26,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:26,041 INFO:     Epoch: 6
2022-11-28 05:45:26,701 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5150714570825751, 'Total loss': 0.5150714570825751} | train loss {'Reaction outcome loss': 0.5228801095775264, 'Total loss': 0.5228801095775264}
2022-11-28 05:45:26,701 INFO:     Found new best model at epoch 6
2022-11-28 05:45:26,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:26,702 INFO:     Epoch: 7
2022-11-28 05:45:27,359 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5662927519191395, 'Total loss': 0.5662927519191395} | train loss {'Reaction outcome loss': 0.5196129987355669, 'Total loss': 0.5196129987355669}
2022-11-28 05:45:27,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:27,359 INFO:     Epoch: 8
2022-11-28 05:45:28,015 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4835665632377971, 'Total loss': 0.4835665632377971} | train loss {'Reaction outcome loss': 0.5123662585128657, 'Total loss': 0.5123662585128657}
2022-11-28 05:45:28,015 INFO:     Found new best model at epoch 8
2022-11-28 05:45:28,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:28,016 INFO:     Epoch: 9
2022-11-28 05:45:28,673 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5561521683226932, 'Total loss': 0.5561521683226932} | train loss {'Reaction outcome loss': 0.502212776063455, 'Total loss': 0.502212776063455}
2022-11-28 05:45:28,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:28,673 INFO:     Epoch: 10
2022-11-28 05:45:29,332 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5196066298945383, 'Total loss': 0.5196066298945383} | train loss {'Reaction outcome loss': 0.5056679752553522, 'Total loss': 0.5056679752553522}
2022-11-28 05:45:29,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:29,332 INFO:     Epoch: 11
2022-11-28 05:45:29,989 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5031084662133997, 'Total loss': 0.5031084662133997} | train loss {'Reaction outcome loss': 0.5061094278869359, 'Total loss': 0.5061094278869359}
2022-11-28 05:45:29,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:29,990 INFO:     Epoch: 12
2022-11-28 05:45:30,645 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5023922581564296, 'Total loss': 0.5023922581564296} | train loss {'Reaction outcome loss': 0.49278979667043876, 'Total loss': 0.49278979667043876}
2022-11-28 05:45:30,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:30,645 INFO:     Epoch: 13
2022-11-28 05:45:31,306 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5223196230151437, 'Total loss': 0.5223196230151437} | train loss {'Reaction outcome loss': 0.5085662532190562, 'Total loss': 0.5085662532190562}
2022-11-28 05:45:31,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:31,307 INFO:     Epoch: 14
2022-11-28 05:45:31,964 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4979120028967207, 'Total loss': 0.4979120028967207} | train loss {'Reaction outcome loss': 0.49853811072193177, 'Total loss': 0.49853811072193177}
2022-11-28 05:45:31,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:31,964 INFO:     Epoch: 15
2022-11-28 05:45:32,620 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5353726961395957, 'Total loss': 0.5353726961395957} | train loss {'Reaction outcome loss': 0.4803293619893099, 'Total loss': 0.4803293619893099}
2022-11-28 05:45:32,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:32,621 INFO:     Epoch: 16
2022-11-28 05:45:33,276 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49638624252243474, 'Total loss': 0.49638624252243474} | train loss {'Reaction outcome loss': 0.4843863186083342, 'Total loss': 0.4843863186083342}
2022-11-28 05:45:33,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:33,277 INFO:     Epoch: 17
2022-11-28 05:45:33,937 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5211445218460127, 'Total loss': 0.5211445218460127} | train loss {'Reaction outcome loss': 0.48630097731646255, 'Total loss': 0.48630097731646255}
2022-11-28 05:45:33,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:33,937 INFO:     Epoch: 18
2022-11-28 05:45:34,594 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5020986602387645, 'Total loss': 0.5020986602387645} | train loss {'Reaction outcome loss': 0.4832324898436002, 'Total loss': 0.4832324898436002}
2022-11-28 05:45:34,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:34,594 INFO:     Epoch: 19
2022-11-28 05:45:35,252 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4804642976007678, 'Total loss': 0.4804642976007678} | train loss {'Reaction outcome loss': 0.4863378663551108, 'Total loss': 0.4863378663551108}
2022-11-28 05:45:35,252 INFO:     Found new best model at epoch 19
2022-11-28 05:45:35,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:35,253 INFO:     Epoch: 20
2022-11-28 05:45:35,912 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4954763925210996, 'Total loss': 0.4954763925210996} | train loss {'Reaction outcome loss': 0.4798056968310584, 'Total loss': 0.4798056968310584}
2022-11-28 05:45:35,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:35,912 INFO:     Epoch: 21
2022-11-28 05:45:36,571 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4937940846112641, 'Total loss': 0.4937940846112641} | train loss {'Reaction outcome loss': 0.4865514022120942, 'Total loss': 0.4865514022120942}
2022-11-28 05:45:36,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:36,571 INFO:     Epoch: 22
2022-11-28 05:45:37,230 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5052542103962465, 'Total loss': 0.5052542103962465} | train loss {'Reaction outcome loss': 0.4843887084046839, 'Total loss': 0.4843887084046839}
2022-11-28 05:45:37,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:37,230 INFO:     Epoch: 23
2022-11-28 05:45:37,891 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48263991861180827, 'Total loss': 0.48263991861180827} | train loss {'Reaction outcome loss': 0.4809345422908362, 'Total loss': 0.4809345422908362}
2022-11-28 05:45:37,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:37,892 INFO:     Epoch: 24
2022-11-28 05:45:38,550 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4998673176900907, 'Total loss': 0.4998673176900907} | train loss {'Reaction outcome loss': 0.48600063660004844, 'Total loss': 0.48600063660004844}
2022-11-28 05:45:38,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:38,550 INFO:     Epoch: 25
2022-11-28 05:45:39,208 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49522713029926474, 'Total loss': 0.49522713029926474} | train loss {'Reaction outcome loss': 0.48532875002878395, 'Total loss': 0.48532875002878395}
2022-11-28 05:45:39,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:39,208 INFO:     Epoch: 26
2022-11-28 05:45:39,868 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5754691541872241, 'Total loss': 0.5754691541872241} | train loss {'Reaction outcome loss': 0.48806695157458424, 'Total loss': 0.48806695157458424}
2022-11-28 05:45:39,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:39,869 INFO:     Epoch: 27
2022-11-28 05:45:40,531 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.490643525834788, 'Total loss': 0.490643525834788} | train loss {'Reaction outcome loss': 0.5046056480126206, 'Total loss': 0.5046056480126206}
2022-11-28 05:45:40,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:40,531 INFO:     Epoch: 28
2022-11-28 05:45:41,195 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5449287606911226, 'Total loss': 0.5449287606911226} | train loss {'Reaction outcome loss': 0.4824777444605885, 'Total loss': 0.4824777444605885}
2022-11-28 05:45:41,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:41,195 INFO:     Epoch: 29
2022-11-28 05:45:41,862 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5400801091031595, 'Total loss': 0.5400801091031595} | train loss {'Reaction outcome loss': 0.4995187709206029, 'Total loss': 0.4995187709206029}
2022-11-28 05:45:41,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:41,862 INFO:     Epoch: 30
2022-11-28 05:45:42,523 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4828610071404414, 'Total loss': 0.4828610071404414} | train loss {'Reaction outcome loss': 0.47978549115812247, 'Total loss': 0.47978549115812247}
2022-11-28 05:45:42,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:42,523 INFO:     Epoch: 31
2022-11-28 05:45:43,186 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5368095602501523, 'Total loss': 0.5368095602501523} | train loss {'Reaction outcome loss': 0.47182690973585917, 'Total loss': 0.47182690973585917}
2022-11-28 05:45:43,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:43,187 INFO:     Epoch: 32
2022-11-28 05:45:43,847 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5206812897866423, 'Total loss': 0.5206812897866423} | train loss {'Reaction outcome loss': 0.4757139818207455, 'Total loss': 0.4757139818207455}
2022-11-28 05:45:43,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:43,847 INFO:     Epoch: 33
2022-11-28 05:45:44,513 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5129854614761743, 'Total loss': 0.5129854614761743} | train loss {'Reaction outcome loss': 0.47783021110030804, 'Total loss': 0.47783021110030804}
2022-11-28 05:45:44,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:44,513 INFO:     Epoch: 34
2022-11-28 05:45:45,173 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5052788904444738, 'Total loss': 0.5052788904444738} | train loss {'Reaction outcome loss': 0.48299979150053945, 'Total loss': 0.48299979150053945}
2022-11-28 05:45:45,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:45,173 INFO:     Epoch: 35
2022-11-28 05:45:45,833 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.508952602066777, 'Total loss': 0.508952602066777} | train loss {'Reaction outcome loss': 0.4837889672532255, 'Total loss': 0.4837889672532255}
2022-11-28 05:45:45,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:45,833 INFO:     Epoch: 36
2022-11-28 05:45:46,492 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4980493096465414, 'Total loss': 0.4980493096465414} | train loss {'Reaction outcome loss': 0.490408053644273, 'Total loss': 0.490408053644273}
2022-11-28 05:45:46,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:46,492 INFO:     Epoch: 37
2022-11-28 05:45:47,154 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47805739092555916, 'Total loss': 0.47805739092555916} | train loss {'Reaction outcome loss': 0.49620549954089377, 'Total loss': 0.49620549954089377}
2022-11-28 05:45:47,154 INFO:     Found new best model at epoch 37
2022-11-28 05:45:47,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:47,155 INFO:     Epoch: 38
2022-11-28 05:45:47,817 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5006549045104872, 'Total loss': 0.5006549045104872} | train loss {'Reaction outcome loss': 0.47592654474351087, 'Total loss': 0.47592654474351087}
2022-11-28 05:45:47,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:47,817 INFO:     Epoch: 39
2022-11-28 05:45:48,479 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46319047903472726, 'Total loss': 0.46319047903472726} | train loss {'Reaction outcome loss': 0.47894538288958644, 'Total loss': 0.47894538288958644}
2022-11-28 05:45:48,479 INFO:     Found new best model at epoch 39
2022-11-28 05:45:48,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:48,480 INFO:     Epoch: 40
2022-11-28 05:45:49,144 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4646208757026629, 'Total loss': 0.4646208757026629} | train loss {'Reaction outcome loss': 0.4764998736169174, 'Total loss': 0.4764998736169174}
2022-11-28 05:45:49,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:49,144 INFO:     Epoch: 41
2022-11-28 05:45:49,806 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.503497892821377, 'Total loss': 0.503497892821377} | train loss {'Reaction outcome loss': 0.4765791553355422, 'Total loss': 0.4765791553355422}
2022-11-28 05:45:49,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:49,806 INFO:     Epoch: 42
2022-11-28 05:45:50,469 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5160808102651075, 'Total loss': 0.5160808102651075} | train loss {'Reaction outcome loss': 0.47325942186551045, 'Total loss': 0.47325942186551045}
2022-11-28 05:45:50,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:50,470 INFO:     Epoch: 43
2022-11-28 05:45:51,133 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5108716277913614, 'Total loss': 0.5108716277913614} | train loss {'Reaction outcome loss': 0.4710706460934419, 'Total loss': 0.4710706460934419}
2022-11-28 05:45:51,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:51,134 INFO:     Epoch: 44
2022-11-28 05:45:51,797 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49818385900421575, 'Total loss': 0.49818385900421575} | train loss {'Reaction outcome loss': 0.4808577178460866, 'Total loss': 0.4808577178460866}
2022-11-28 05:45:51,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:51,797 INFO:     Epoch: 45
2022-11-28 05:45:52,461 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4940980076789856, 'Total loss': 0.4940980076789856} | train loss {'Reaction outcome loss': 0.4718159285151524, 'Total loss': 0.4718159285151524}
2022-11-28 05:45:52,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:52,462 INFO:     Epoch: 46
2022-11-28 05:45:53,123 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49155318635431205, 'Total loss': 0.49155318635431205} | train loss {'Reaction outcome loss': 0.4837466860831025, 'Total loss': 0.4837466860831025}
2022-11-28 05:45:53,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:53,123 INFO:     Epoch: 47
2022-11-28 05:45:53,788 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4902526644820517, 'Total loss': 0.4902526644820517} | train loss {'Reaction outcome loss': 0.4922969198600966, 'Total loss': 0.4922969198600966}
2022-11-28 05:45:53,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:53,788 INFO:     Epoch: 48
2022-11-28 05:45:54,451 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.520303797992793, 'Total loss': 0.520303797992793} | train loss {'Reaction outcome loss': 0.47350939004286097, 'Total loss': 0.47350939004286097}
2022-11-28 05:45:54,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:54,451 INFO:     Epoch: 49
2022-11-28 05:45:55,114 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5458970726890997, 'Total loss': 0.5458970726890997} | train loss {'Reaction outcome loss': 0.479749090094798, 'Total loss': 0.479749090094798}
2022-11-28 05:45:55,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:55,114 INFO:     Epoch: 50
2022-11-28 05:45:55,774 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5088886015794494, 'Total loss': 0.5088886015794494} | train loss {'Reaction outcome loss': 0.510004332734023, 'Total loss': 0.510004332734023}
2022-11-28 05:45:55,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:55,774 INFO:     Epoch: 51
2022-11-28 05:45:56,433 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4859966063363986, 'Total loss': 0.4859966063363986} | train loss {'Reaction outcome loss': 0.4811312460947616, 'Total loss': 0.4811312460947616}
2022-11-28 05:45:56,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:56,434 INFO:     Epoch: 52
2022-11-28 05:45:57,093 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4631882719695568, 'Total loss': 0.4631882719695568} | train loss {'Reaction outcome loss': 0.470076949007598, 'Total loss': 0.470076949007598}
2022-11-28 05:45:57,093 INFO:     Found new best model at epoch 52
2022-11-28 05:45:57,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:57,094 INFO:     Epoch: 53
2022-11-28 05:45:57,754 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4920180260457776, 'Total loss': 0.4920180260457776} | train loss {'Reaction outcome loss': 0.47629791848090014, 'Total loss': 0.47629791848090014}
2022-11-28 05:45:57,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:57,754 INFO:     Epoch: 54
2022-11-28 05:45:58,414 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4860995090143247, 'Total loss': 0.4860995090143247} | train loss {'Reaction outcome loss': 0.47145725598441895, 'Total loss': 0.47145725598441895}
2022-11-28 05:45:58,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:58,414 INFO:     Epoch: 55
2022-11-28 05:45:59,075 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5150791813026775, 'Total loss': 0.5150791813026775} | train loss {'Reaction outcome loss': 0.4767757265070672, 'Total loss': 0.4767757265070672}
2022-11-28 05:45:59,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:59,075 INFO:     Epoch: 56
2022-11-28 05:45:59,737 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4763622382147746, 'Total loss': 0.4763622382147746} | train loss {'Reaction outcome loss': 0.4807329918578388, 'Total loss': 0.4807329918578388}
2022-11-28 05:45:59,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:45:59,737 INFO:     Epoch: 57
2022-11-28 05:46:00,398 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49477251652966847, 'Total loss': 0.49477251652966847} | train loss {'Reaction outcome loss': 0.47384112801870354, 'Total loss': 0.47384112801870354}
2022-11-28 05:46:00,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:00,398 INFO:     Epoch: 58
2022-11-28 05:46:01,065 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49829983203248546, 'Total loss': 0.49829983203248546} | train loss {'Reaction outcome loss': 0.47844305544005716, 'Total loss': 0.47844305544005716}
2022-11-28 05:46:01,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:01,065 INFO:     Epoch: 59
2022-11-28 05:46:01,728 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48249372298067267, 'Total loss': 0.48249372298067267} | train loss {'Reaction outcome loss': 0.4793411200474439, 'Total loss': 0.4793411200474439}
2022-11-28 05:46:01,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:01,728 INFO:     Epoch: 60
2022-11-28 05:46:02,387 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5439049388197336, 'Total loss': 0.5439049388197336} | train loss {'Reaction outcome loss': 0.47663559188485627, 'Total loss': 0.47663559188485627}
2022-11-28 05:46:02,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:02,389 INFO:     Epoch: 61
2022-11-28 05:46:03,049 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5014062977649949, 'Total loss': 0.5014062977649949} | train loss {'Reaction outcome loss': 0.47854830605177745, 'Total loss': 0.47854830605177745}
2022-11-28 05:46:03,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:03,049 INFO:     Epoch: 62
2022-11-28 05:46:03,709 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49124136397784407, 'Total loss': 0.49124136397784407} | train loss {'Reaction outcome loss': 0.47685115703717174, 'Total loss': 0.47685115703717174}
2022-11-28 05:46:03,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:03,709 INFO:     Epoch: 63
2022-11-28 05:46:04,371 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49877625839276746, 'Total loss': 0.49877625839276746} | train loss {'Reaction outcome loss': 0.4715814188213242, 'Total loss': 0.4715814188213242}
2022-11-28 05:46:04,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:04,372 INFO:     Epoch: 64
2022-11-28 05:46:05,033 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4839841323820027, 'Total loss': 0.4839841323820027} | train loss {'Reaction outcome loss': 0.4633467949112417, 'Total loss': 0.4633467949112417}
2022-11-28 05:46:05,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:05,033 INFO:     Epoch: 65
2022-11-28 05:46:05,696 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5169541090726852, 'Total loss': 0.5169541090726852} | train loss {'Reaction outcome loss': 0.4759025045855325, 'Total loss': 0.4759025045855325}
2022-11-28 05:46:05,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:05,696 INFO:     Epoch: 66
2022-11-28 05:46:06,359 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5173831968144937, 'Total loss': 0.5173831968144937} | train loss {'Reaction outcome loss': 0.4800233904475927, 'Total loss': 0.4800233904475927}
2022-11-28 05:46:06,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:06,359 INFO:     Epoch: 67
2022-11-28 05:46:07,021 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48530675132166257, 'Total loss': 0.48530675132166257} | train loss {'Reaction outcome loss': 0.4722912990853854, 'Total loss': 0.4722912990853854}
2022-11-28 05:46:07,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:07,021 INFO:     Epoch: 68
2022-11-28 05:46:07,680 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4650078321045095, 'Total loss': 0.4650078321045095} | train loss {'Reaction outcome loss': 0.4788923719030643, 'Total loss': 0.4788923719030643}
2022-11-28 05:46:07,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:07,680 INFO:     Epoch: 69
2022-11-28 05:46:08,337 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48898473754525185, 'Total loss': 0.48898473754525185} | train loss {'Reaction outcome loss': 0.472964343303807, 'Total loss': 0.472964343303807}
2022-11-28 05:46:08,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:08,337 INFO:     Epoch: 70
2022-11-28 05:46:08,993 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4910005364905704, 'Total loss': 0.4910005364905704} | train loss {'Reaction outcome loss': 0.4697392608759254, 'Total loss': 0.4697392608759254}
2022-11-28 05:46:08,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:08,994 INFO:     Epoch: 71
2022-11-28 05:46:09,651 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5712199319492687, 'Total loss': 0.5712199319492687} | train loss {'Reaction outcome loss': 0.47055830352521133, 'Total loss': 0.47055830352521133}
2022-11-28 05:46:09,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:09,652 INFO:     Epoch: 72
2022-11-28 05:46:10,313 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5457720732824369, 'Total loss': 0.5457720732824369} | train loss {'Reaction outcome loss': 0.4725487558585912, 'Total loss': 0.4725487558585912}
2022-11-28 05:46:10,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:10,314 INFO:     Epoch: 73
2022-11-28 05:46:10,971 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.499429927630858, 'Total loss': 0.499429927630858} | train loss {'Reaction outcome loss': 0.4712984686197057, 'Total loss': 0.4712984686197057}
2022-11-28 05:46:10,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:10,972 INFO:     Epoch: 74
2022-11-28 05:46:11,630 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4892082561484792, 'Total loss': 0.4892082561484792} | train loss {'Reaction outcome loss': 0.4680031116463636, 'Total loss': 0.4680031116463636}
2022-11-28 05:46:11,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:11,630 INFO:     Epoch: 75
2022-11-28 05:46:12,290 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.474848021837798, 'Total loss': 0.474848021837798} | train loss {'Reaction outcome loss': 0.46767710082926733, 'Total loss': 0.46767710082926733}
2022-11-28 05:46:12,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:12,290 INFO:     Epoch: 76
2022-11-28 05:46:12,952 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5331375077366829, 'Total loss': 0.5331375077366829} | train loss {'Reaction outcome loss': 0.4725384218128104, 'Total loss': 0.4725384218128104}
2022-11-28 05:46:12,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:12,953 INFO:     Epoch: 77
2022-11-28 05:46:13,613 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47938820719718933, 'Total loss': 0.47938820719718933} | train loss {'Reaction outcome loss': 0.4773006960447983, 'Total loss': 0.4773006960447983}
2022-11-28 05:46:13,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:13,613 INFO:     Epoch: 78
2022-11-28 05:46:14,274 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5001439980485223, 'Total loss': 0.5001439980485223} | train loss {'Reaction outcome loss': 0.47121611400413127, 'Total loss': 0.47121611400413127}
2022-11-28 05:46:14,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:14,274 INFO:     Epoch: 79
2022-11-28 05:46:14,940 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4750556407327002, 'Total loss': 0.4750556407327002} | train loss {'Reaction outcome loss': 0.47831426882882594, 'Total loss': 0.47831426882882594}
2022-11-28 05:46:14,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:14,940 INFO:     Epoch: 80
2022-11-28 05:46:15,598 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48783355680379, 'Total loss': 0.48783355680379} | train loss {'Reaction outcome loss': 0.4623858657201775, 'Total loss': 0.4623858657201775}
2022-11-28 05:46:15,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:15,599 INFO:     Epoch: 81
2022-11-28 05:46:16,259 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5367409182204441, 'Total loss': 0.5367409182204441} | train loss {'Reaction outcome loss': 0.4818478093637146, 'Total loss': 0.4818478093637146}
2022-11-28 05:46:16,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:16,260 INFO:     Epoch: 82
2022-11-28 05:46:16,919 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49063546650789003, 'Total loss': 0.49063546650789003} | train loss {'Reaction outcome loss': 0.493438528975338, 'Total loss': 0.493438528975338}
2022-11-28 05:46:16,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:16,920 INFO:     Epoch: 83
2022-11-28 05:46:17,581 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5292031995274804, 'Total loss': 0.5292031995274804} | train loss {'Reaction outcome loss': 0.47616019778647406, 'Total loss': 0.47616019778647406}
2022-11-28 05:46:17,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:17,582 INFO:     Epoch: 84
2022-11-28 05:46:18,247 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4866859956898473, 'Total loss': 0.4866859956898473} | train loss {'Reaction outcome loss': 0.47110169679529756, 'Total loss': 0.47110169679529756}
2022-11-28 05:46:18,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:18,247 INFO:     Epoch: 85
2022-11-28 05:46:18,910 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48219185965982353, 'Total loss': 0.48219185965982353} | train loss {'Reaction outcome loss': 0.47423235233496075, 'Total loss': 0.47423235233496075}
2022-11-28 05:46:18,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:18,910 INFO:     Epoch: 86
2022-11-28 05:46:19,574 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47929896956140344, 'Total loss': 0.47929896956140344} | train loss {'Reaction outcome loss': 0.47640403022288313, 'Total loss': 0.47640403022288313}
2022-11-28 05:46:19,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:19,574 INFO:     Epoch: 87
2022-11-28 05:46:20,238 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4864528714255853, 'Total loss': 0.4864528714255853} | train loss {'Reaction outcome loss': 0.46784514954939543, 'Total loss': 0.46784514954939543}
2022-11-28 05:46:20,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:20,238 INFO:     Epoch: 88
2022-11-28 05:46:20,903 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49333268336274405, 'Total loss': 0.49333268336274405} | train loss {'Reaction outcome loss': 0.47567171570260514, 'Total loss': 0.47567171570260514}
2022-11-28 05:46:20,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:20,904 INFO:     Epoch: 89
2022-11-28 05:46:21,570 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47343423014337366, 'Total loss': 0.47343423014337366} | train loss {'Reaction outcome loss': 0.4742699744489029, 'Total loss': 0.4742699744489029}
2022-11-28 05:46:21,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:21,571 INFO:     Epoch: 90
2022-11-28 05:46:22,237 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5122545036402616, 'Total loss': 0.5122545036402616} | train loss {'Reaction outcome loss': 0.4771935475503777, 'Total loss': 0.4771935475503777}
2022-11-28 05:46:22,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:22,237 INFO:     Epoch: 91
2022-11-28 05:46:22,902 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5471577265045859, 'Total loss': 0.5471577265045859} | train loss {'Reaction outcome loss': 0.46230023152191146, 'Total loss': 0.46230023152191146}
2022-11-28 05:46:22,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:22,903 INFO:     Epoch: 92
2022-11-28 05:46:23,570 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5001623992892829, 'Total loss': 0.5001623992892829} | train loss {'Reaction outcome loss': 0.4798847570834372, 'Total loss': 0.4798847570834372}
2022-11-28 05:46:23,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:23,570 INFO:     Epoch: 93
2022-11-28 05:46:24,235 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4816854379393838, 'Total loss': 0.4816854379393838} | train loss {'Reaction outcome loss': 0.4687195605473962, 'Total loss': 0.4687195605473962}
2022-11-28 05:46:24,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:24,235 INFO:     Epoch: 94
2022-11-28 05:46:24,901 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4914797707037492, 'Total loss': 0.4914797707037492} | train loss {'Reaction outcome loss': 0.47597191371174474, 'Total loss': 0.47597191371174474}
2022-11-28 05:46:24,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:24,901 INFO:     Epoch: 95
2022-11-28 05:46:25,567 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48827867954969406, 'Total loss': 0.48827867954969406} | train loss {'Reaction outcome loss': 0.4682054823709403, 'Total loss': 0.4682054823709403}
2022-11-28 05:46:25,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:25,568 INFO:     Epoch: 96
2022-11-28 05:46:26,237 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5070738179439848, 'Total loss': 0.5070738179439848} | train loss {'Reaction outcome loss': 0.47078800943457644, 'Total loss': 0.47078800943457644}
2022-11-28 05:46:26,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:26,237 INFO:     Epoch: 97
2022-11-28 05:46:26,904 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4689024446362799, 'Total loss': 0.4689024446362799} | train loss {'Reaction outcome loss': 0.4821713872947674, 'Total loss': 0.4821713872947674}
2022-11-28 05:46:26,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:26,904 INFO:     Epoch: 98
2022-11-28 05:46:27,568 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47532887756824493, 'Total loss': 0.47532887756824493} | train loss {'Reaction outcome loss': 0.49430116166470023, 'Total loss': 0.49430116166470023}
2022-11-28 05:46:27,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:27,568 INFO:     Epoch: 99
2022-11-28 05:46:28,237 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5049275420606136, 'Total loss': 0.5049275420606136} | train loss {'Reaction outcome loss': 0.4704898797359265, 'Total loss': 0.4704898797359265}
2022-11-28 05:46:28,237 INFO:     Best model found after epoch 53 of 100.
2022-11-28 05:46:28,237 INFO:   Done with stage: TRAINING
2022-11-28 05:46:28,237 INFO:   Starting stage: EVALUATION
2022-11-28 05:46:28,356 INFO:   Done with stage: EVALUATION
2022-11-28 05:46:28,356 INFO:   Leaving out SEQ value Fold_6
2022-11-28 05:46:28,368 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:46:28,369 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:46:29,016 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:46:29,016 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:46:29,087 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:46:29,088 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:46:29,088 INFO:     No hyperparam tuning for this model
2022-11-28 05:46:29,088 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:46:29,088 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:46:29,088 INFO:     None feature selector for col prot
2022-11-28 05:46:29,089 INFO:     None feature selector for col prot
2022-11-28 05:46:29,089 INFO:     None feature selector for col prot
2022-11-28 05:46:29,089 INFO:     None feature selector for col chem
2022-11-28 05:46:29,089 INFO:     None feature selector for col chem
2022-11-28 05:46:29,089 INFO:     None feature selector for col chem
2022-11-28 05:46:29,089 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:46:29,090 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:46:29,091 INFO:     Number of params in model 169651
2022-11-28 05:46:29,094 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:46:29,094 INFO:   Starting stage: TRAINING
2022-11-28 05:46:29,146 INFO:     Val loss before train {'Reaction outcome loss': 0.9942819178104401, 'Total loss': 0.9942819178104401}
2022-11-28 05:46:29,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:29,146 INFO:     Epoch: 0
2022-11-28 05:46:29,814 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5751186047088016, 'Total loss': 0.5751186047088016} | train loss {'Reaction outcome loss': 0.6927435704536976, 'Total loss': 0.6927435704536976}
2022-11-28 05:46:29,814 INFO:     Found new best model at epoch 0
2022-11-28 05:46:29,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:29,815 INFO:     Epoch: 1
2022-11-28 05:46:30,484 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5986478586088527, 'Total loss': 0.5986478586088527} | train loss {'Reaction outcome loss': 0.5857804662758305, 'Total loss': 0.5857804662758305}
2022-11-28 05:46:30,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:30,484 INFO:     Epoch: 2
2022-11-28 05:46:31,153 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5343016538430344, 'Total loss': 0.5343016538430344} | train loss {'Reaction outcome loss': 0.5648096170757086, 'Total loss': 0.5648096170757086}
2022-11-28 05:46:31,153 INFO:     Found new best model at epoch 2
2022-11-28 05:46:31,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:31,154 INFO:     Epoch: 3
2022-11-28 05:46:31,819 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5063908963718198, 'Total loss': 0.5063908963718198} | train loss {'Reaction outcome loss': 0.5364940859257213, 'Total loss': 0.5364940859257213}
2022-11-28 05:46:31,819 INFO:     Found new best model at epoch 3
2022-11-28 05:46:31,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:31,820 INFO:     Epoch: 4
2022-11-28 05:46:32,486 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5532867556268518, 'Total loss': 0.5532867556268518} | train loss {'Reaction outcome loss': 0.5329260960701974, 'Total loss': 0.5329260960701974}
2022-11-28 05:46:32,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:32,486 INFO:     Epoch: 5
2022-11-28 05:46:33,154 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5312168171459978, 'Total loss': 0.5312168171459978} | train loss {'Reaction outcome loss': 0.5202993164139409, 'Total loss': 0.5202993164139409}
2022-11-28 05:46:33,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:33,154 INFO:     Epoch: 6
2022-11-28 05:46:33,819 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5122800503264774, 'Total loss': 0.5122800503264774} | train loss {'Reaction outcome loss': 0.51757440860233, 'Total loss': 0.51757440860233}
2022-11-28 05:46:33,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:33,820 INFO:     Epoch: 7
2022-11-28 05:46:34,489 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5252655273811384, 'Total loss': 0.5252655273811384} | train loss {'Reaction outcome loss': 0.5164201201931122, 'Total loss': 0.5164201201931122}
2022-11-28 05:46:34,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:34,489 INFO:     Epoch: 8
2022-11-28 05:46:35,156 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5081469938158989, 'Total loss': 0.5081469938158989} | train loss {'Reaction outcome loss': 0.5007976720770521, 'Total loss': 0.5007976720770521}
2022-11-28 05:46:35,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:35,156 INFO:     Epoch: 9
2022-11-28 05:46:35,824 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5236759734424677, 'Total loss': 0.5236759734424677} | train loss {'Reaction outcome loss': 0.49899002615242233, 'Total loss': 0.49899002615242233}
2022-11-28 05:46:35,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:35,824 INFO:     Epoch: 10
2022-11-28 05:46:36,486 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4892357526855035, 'Total loss': 0.4892357526855035} | train loss {'Reaction outcome loss': 0.49238967829413954, 'Total loss': 0.49238967829413954}
2022-11-28 05:46:36,486 INFO:     Found new best model at epoch 10
2022-11-28 05:46:36,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:36,487 INFO:     Epoch: 11
2022-11-28 05:46:37,153 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47940189933234995, 'Total loss': 0.47940189933234995} | train loss {'Reaction outcome loss': 0.49584273032603726, 'Total loss': 0.49584273032603726}
2022-11-28 05:46:37,153 INFO:     Found new best model at epoch 11
2022-11-28 05:46:37,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:37,154 INFO:     Epoch: 12
2022-11-28 05:46:37,818 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5027815862135454, 'Total loss': 0.5027815862135454} | train loss {'Reaction outcome loss': 0.49059107749452513, 'Total loss': 0.49059107749452513}
2022-11-28 05:46:37,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:37,818 INFO:     Epoch: 13
2022-11-28 05:46:38,483 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4746957340023734, 'Total loss': 0.4746957340023734} | train loss {'Reaction outcome loss': 0.4925711072620846, 'Total loss': 0.4925711072620846}
2022-11-28 05:46:38,483 INFO:     Found new best model at epoch 13
2022-11-28 05:46:38,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:38,484 INFO:     Epoch: 14
2022-11-28 05:46:39,149 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5073232027617368, 'Total loss': 0.5073232027617368} | train loss {'Reaction outcome loss': 0.4995518532251158, 'Total loss': 0.4995518532251158}
2022-11-28 05:46:39,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:39,149 INFO:     Epoch: 15
2022-11-28 05:46:39,813 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4810221567749977, 'Total loss': 0.4810221567749977} | train loss {'Reaction outcome loss': 0.49747074587691215, 'Total loss': 0.49747074587691215}
2022-11-28 05:46:39,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:39,814 INFO:     Epoch: 16
2022-11-28 05:46:40,483 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4859399937770583, 'Total loss': 0.4859399937770583} | train loss {'Reaction outcome loss': 0.48295113161927267, 'Total loss': 0.48295113161927267}
2022-11-28 05:46:40,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:40,484 INFO:     Epoch: 17
2022-11-28 05:46:41,149 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5164480967955156, 'Total loss': 0.5164480967955156} | train loss {'Reaction outcome loss': 0.48559219366119755, 'Total loss': 0.48559219366119755}
2022-11-28 05:46:41,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:41,150 INFO:     Epoch: 18
2022-11-28 05:46:41,812 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5134134326468814, 'Total loss': 0.5134134326468814} | train loss {'Reaction outcome loss': 0.4870367693684755, 'Total loss': 0.4870367693684755}
2022-11-28 05:46:41,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:41,813 INFO:     Epoch: 19
2022-11-28 05:46:42,479 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47565034607594664, 'Total loss': 0.47565034607594664} | train loss {'Reaction outcome loss': 0.4827840867782793, 'Total loss': 0.4827840867782793}
2022-11-28 05:46:42,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:42,480 INFO:     Epoch: 20
2022-11-28 05:46:43,145 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46025086363608186, 'Total loss': 0.46025086363608186} | train loss {'Reaction outcome loss': 0.49220598092482937, 'Total loss': 0.49220598092482937}
2022-11-28 05:46:43,145 INFO:     Found new best model at epoch 20
2022-11-28 05:46:43,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:43,146 INFO:     Epoch: 21
2022-11-28 05:46:43,809 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4684382233430039, 'Total loss': 0.4684382233430039} | train loss {'Reaction outcome loss': 0.4834629938366913, 'Total loss': 0.4834629938366913}
2022-11-28 05:46:43,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:43,809 INFO:     Epoch: 22
2022-11-28 05:46:44,473 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4611666547981175, 'Total loss': 0.4611666547981175} | train loss {'Reaction outcome loss': 0.4843404000444758, 'Total loss': 0.4843404000444758}
2022-11-28 05:46:44,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:44,474 INFO:     Epoch: 23
2022-11-28 05:46:45,140 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5024122406135906, 'Total loss': 0.5024122406135906} | train loss {'Reaction outcome loss': 0.4792084624810565, 'Total loss': 0.4792084624810565}
2022-11-28 05:46:45,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:45,140 INFO:     Epoch: 24
2022-11-28 05:46:45,803 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47587804089892993, 'Total loss': 0.47587804089892993} | train loss {'Reaction outcome loss': 0.4800821141369881, 'Total loss': 0.4800821141369881}
2022-11-28 05:46:45,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:45,803 INFO:     Epoch: 25
2022-11-28 05:46:46,471 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5094331191344694, 'Total loss': 0.5094331191344694} | train loss {'Reaction outcome loss': 0.47155223594557855, 'Total loss': 0.47155223594557855}
2022-11-28 05:46:46,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:46,471 INFO:     Epoch: 26
2022-11-28 05:46:47,134 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4617492512545802, 'Total loss': 0.4617492512545802} | train loss {'Reaction outcome loss': 0.48861663818599715, 'Total loss': 0.48861663818599715}
2022-11-28 05:46:47,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:47,134 INFO:     Epoch: 27
2022-11-28 05:46:47,796 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48588868230581284, 'Total loss': 0.48588868230581284} | train loss {'Reaction outcome loss': 0.48174210337381207, 'Total loss': 0.48174210337381207}
2022-11-28 05:46:47,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:47,796 INFO:     Epoch: 28
2022-11-28 05:46:48,459 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4720453064550053, 'Total loss': 0.4720453064550053} | train loss {'Reaction outcome loss': 0.4779068236990321, 'Total loss': 0.4779068236990321}
2022-11-28 05:46:48,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:48,460 INFO:     Epoch: 29
2022-11-28 05:46:49,125 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5081265490840782, 'Total loss': 0.5081265490840782} | train loss {'Reaction outcome loss': 0.4766623360375243, 'Total loss': 0.4766623360375243}
2022-11-28 05:46:49,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:49,125 INFO:     Epoch: 30
2022-11-28 05:46:49,791 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5101004605266181, 'Total loss': 0.5101004605266181} | train loss {'Reaction outcome loss': 0.4798910013970829, 'Total loss': 0.4798910013970829}
2022-11-28 05:46:49,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:49,791 INFO:     Epoch: 31
2022-11-28 05:46:50,461 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4540208628909154, 'Total loss': 0.4540208628909154} | train loss {'Reaction outcome loss': 0.47935917829313585, 'Total loss': 0.47935917829313585}
2022-11-28 05:46:50,461 INFO:     Found new best model at epoch 31
2022-11-28 05:46:50,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:50,462 INFO:     Epoch: 32
2022-11-28 05:46:51,128 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46486505764451896, 'Total loss': 0.46486505764451896} | train loss {'Reaction outcome loss': 0.47749205011754264, 'Total loss': 0.47749205011754264}
2022-11-28 05:46:51,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:51,128 INFO:     Epoch: 33
2022-11-28 05:46:51,793 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4559929482638836, 'Total loss': 0.4559929482638836} | train loss {'Reaction outcome loss': 0.4733968783891009, 'Total loss': 0.4733968783891009}
2022-11-28 05:46:51,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:51,793 INFO:     Epoch: 34
2022-11-28 05:46:52,454 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4745391593738036, 'Total loss': 0.4745391593738036} | train loss {'Reaction outcome loss': 0.48145472760041874, 'Total loss': 0.48145472760041874}
2022-11-28 05:46:52,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:52,455 INFO:     Epoch: 35
2022-11-28 05:46:53,118 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4636489176614718, 'Total loss': 0.4636489176614718} | train loss {'Reaction outcome loss': 0.47905551756341613, 'Total loss': 0.47905551756341613}
2022-11-28 05:46:53,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:53,119 INFO:     Epoch: 36
2022-11-28 05:46:53,784 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47972807017239655, 'Total loss': 0.47972807017239655} | train loss {'Reaction outcome loss': 0.4854436570237721, 'Total loss': 0.4854436570237721}
2022-11-28 05:46:53,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:53,784 INFO:     Epoch: 37
2022-11-28 05:46:54,446 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4653719788925214, 'Total loss': 0.4653719788925214} | train loss {'Reaction outcome loss': 0.4773308277851151, 'Total loss': 0.4773308277851151}
2022-11-28 05:46:54,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:54,446 INFO:     Epoch: 38
2022-11-28 05:46:55,116 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46425852010195906, 'Total loss': 0.46425852010195906} | train loss {'Reaction outcome loss': 0.47700935608196643, 'Total loss': 0.47700935608196643}
2022-11-28 05:46:55,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:55,116 INFO:     Epoch: 39
2022-11-28 05:46:55,784 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4614497548477216, 'Total loss': 0.4614497548477216} | train loss {'Reaction outcome loss': 0.4802840605017639, 'Total loss': 0.4802840605017639}
2022-11-28 05:46:55,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:55,784 INFO:     Epoch: 40
2022-11-28 05:46:56,449 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4736020910468968, 'Total loss': 0.4736020910468968} | train loss {'Reaction outcome loss': 0.4760062614035222, 'Total loss': 0.4760062614035222}
2022-11-28 05:46:56,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:56,449 INFO:     Epoch: 41
2022-11-28 05:46:57,113 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46183205328204413, 'Total loss': 0.46183205328204413} | train loss {'Reaction outcome loss': 0.48784276915173375, 'Total loss': 0.48784276915173375}
2022-11-28 05:46:57,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:57,113 INFO:     Epoch: 42
2022-11-28 05:46:57,779 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4854748672382398, 'Total loss': 0.4854748672382398} | train loss {'Reaction outcome loss': 0.48336193265934146, 'Total loss': 0.48336193265934146}
2022-11-28 05:46:57,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:57,780 INFO:     Epoch: 43
2022-11-28 05:46:58,444 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4525815505873073, 'Total loss': 0.4525815505873073} | train loss {'Reaction outcome loss': 0.47765069064353743, 'Total loss': 0.47765069064353743}
2022-11-28 05:46:58,445 INFO:     Found new best model at epoch 43
2022-11-28 05:46:58,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:58,445 INFO:     Epoch: 44
2022-11-28 05:46:59,109 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4745730253105814, 'Total loss': 0.4745730253105814} | train loss {'Reaction outcome loss': 0.4808365114994587, 'Total loss': 0.4808365114994587}
2022-11-28 05:46:59,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:59,109 INFO:     Epoch: 45
2022-11-28 05:46:59,774 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47041781923987647, 'Total loss': 0.47041781923987647} | train loss {'Reaction outcome loss': 0.47944007177026043, 'Total loss': 0.47944007177026043}
2022-11-28 05:46:59,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:46:59,774 INFO:     Epoch: 46
2022-11-28 05:47:00,438 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5043040879748084, 'Total loss': 0.5043040879748084} | train loss {'Reaction outcome loss': 0.48143351540690466, 'Total loss': 0.48143351540690466}
2022-11-28 05:47:00,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:00,438 INFO:     Epoch: 47
2022-11-28 05:47:01,102 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47724656388163567, 'Total loss': 0.47724656388163567} | train loss {'Reaction outcome loss': 0.47952676354156387, 'Total loss': 0.47952676354156387}
2022-11-28 05:47:01,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:01,102 INFO:     Epoch: 48
2022-11-28 05:47:01,767 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4542993266474117, 'Total loss': 0.4542993266474117} | train loss {'Reaction outcome loss': 0.4809862431739607, 'Total loss': 0.4809862431739607}
2022-11-28 05:47:01,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:01,767 INFO:     Epoch: 49
2022-11-28 05:47:02,430 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.474761349233714, 'Total loss': 0.474761349233714} | train loss {'Reaction outcome loss': 0.48117488322238766, 'Total loss': 0.48117488322238766}
2022-11-28 05:47:02,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:02,430 INFO:     Epoch: 50
2022-11-28 05:47:03,096 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48077991808002646, 'Total loss': 0.48077991808002646} | train loss {'Reaction outcome loss': 0.48142766051234737, 'Total loss': 0.48142766051234737}
2022-11-28 05:47:03,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:03,096 INFO:     Epoch: 51
2022-11-28 05:47:03,762 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4674266908656467, 'Total loss': 0.4674266908656467} | train loss {'Reaction outcome loss': 0.4813170374761666, 'Total loss': 0.4813170374761666}
2022-11-28 05:47:03,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:03,763 INFO:     Epoch: 52
2022-11-28 05:47:04,428 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4844467968425967, 'Total loss': 0.4844467968425967} | train loss {'Reaction outcome loss': 0.47842750295756326, 'Total loss': 0.47842750295756326}
2022-11-28 05:47:04,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:04,428 INFO:     Epoch: 53
2022-11-28 05:47:05,095 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44552580233324657, 'Total loss': 0.44552580233324657} | train loss {'Reaction outcome loss': 0.4881302534091857, 'Total loss': 0.4881302534091857}
2022-11-28 05:47:05,096 INFO:     Found new best model at epoch 53
2022-11-28 05:47:05,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:05,097 INFO:     Epoch: 54
2022-11-28 05:47:05,761 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.477660364725373, 'Total loss': 0.477660364725373} | train loss {'Reaction outcome loss': 0.4787153346884635, 'Total loss': 0.4787153346884635}
2022-11-28 05:47:05,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:05,761 INFO:     Epoch: 55
2022-11-28 05:47:06,424 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4655953269790519, 'Total loss': 0.4655953269790519} | train loss {'Reaction outcome loss': 0.475660020605691, 'Total loss': 0.475660020605691}
2022-11-28 05:47:06,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:06,424 INFO:     Epoch: 56
2022-11-28 05:47:07,089 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4641670679504221, 'Total loss': 0.4641670679504221} | train loss {'Reaction outcome loss': 0.47490373220775395, 'Total loss': 0.47490373220775395}
2022-11-28 05:47:07,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:07,090 INFO:     Epoch: 57
2022-11-28 05:47:07,756 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45998054065487604, 'Total loss': 0.45998054065487604} | train loss {'Reaction outcome loss': 0.484945266597694, 'Total loss': 0.484945266597694}
2022-11-28 05:47:07,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:07,756 INFO:     Epoch: 58
2022-11-28 05:47:08,421 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4677669317884879, 'Total loss': 0.4677669317884879} | train loss {'Reaction outcome loss': 0.4852903937740672, 'Total loss': 0.4852903937740672}
2022-11-28 05:47:08,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:08,421 INFO:     Epoch: 59
2022-11-28 05:47:09,088 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.463848909532482, 'Total loss': 0.463848909532482} | train loss {'Reaction outcome loss': 0.48160202170331634, 'Total loss': 0.48160202170331634}
2022-11-28 05:47:09,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:09,088 INFO:     Epoch: 60
2022-11-28 05:47:09,756 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46140902692621405, 'Total loss': 0.46140902692621405} | train loss {'Reaction outcome loss': 0.4758332645700824, 'Total loss': 0.4758332645700824}
2022-11-28 05:47:09,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:09,756 INFO:     Epoch: 61
2022-11-28 05:47:10,422 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46896095235239377, 'Total loss': 0.46896095235239377} | train loss {'Reaction outcome loss': 0.48025783169413766, 'Total loss': 0.48025783169413766}
2022-11-28 05:47:10,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:10,422 INFO:     Epoch: 62
2022-11-28 05:47:11,088 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4730192009698261, 'Total loss': 0.4730192009698261} | train loss {'Reaction outcome loss': 0.4830558316842202, 'Total loss': 0.4830558316842202}
2022-11-28 05:47:11,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:11,088 INFO:     Epoch: 63
2022-11-28 05:47:11,754 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4475295536897399, 'Total loss': 0.4475295536897399} | train loss {'Reaction outcome loss': 0.4798784436838281, 'Total loss': 0.4798784436838281}
2022-11-28 05:47:11,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:11,755 INFO:     Epoch: 64
2022-11-28 05:47:12,420 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45507552779533644, 'Total loss': 0.45507552779533644} | train loss {'Reaction outcome loss': 0.4856396437051796, 'Total loss': 0.4856396437051796}
2022-11-28 05:47:12,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:12,420 INFO:     Epoch: 65
2022-11-28 05:47:13,088 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45139557360248134, 'Total loss': 0.45139557360248134} | train loss {'Reaction outcome loss': 0.48692818202318683, 'Total loss': 0.48692818202318683}
2022-11-28 05:47:13,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:13,088 INFO:     Epoch: 66
2022-11-28 05:47:13,756 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4797023961489851, 'Total loss': 0.4797023961489851} | train loss {'Reaction outcome loss': 0.47125867339632205, 'Total loss': 0.47125867339632205}
2022-11-28 05:47:13,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:13,756 INFO:     Epoch: 67
2022-11-28 05:47:14,425 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47554804994301364, 'Total loss': 0.47554804994301364} | train loss {'Reaction outcome loss': 0.48301393316397745, 'Total loss': 0.48301393316397745}
2022-11-28 05:47:14,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:14,425 INFO:     Epoch: 68
2022-11-28 05:47:15,094 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46288622255352413, 'Total loss': 0.46288622255352413} | train loss {'Reaction outcome loss': 0.4808472692365608, 'Total loss': 0.4808472692365608}
2022-11-28 05:47:15,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:15,094 INFO:     Epoch: 69
2022-11-28 05:47:15,760 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46206834370439703, 'Total loss': 0.46206834370439703} | train loss {'Reaction outcome loss': 0.48015140507730747, 'Total loss': 0.48015140507730747}
2022-11-28 05:47:15,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:15,760 INFO:     Epoch: 70
2022-11-28 05:47:16,427 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4582656987688758, 'Total loss': 0.4582656987688758} | train loss {'Reaction outcome loss': 0.4806713326683929, 'Total loss': 0.4806713326683929}
2022-11-28 05:47:16,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:16,427 INFO:     Epoch: 71
2022-11-28 05:47:17,093 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4519337486814369, 'Total loss': 0.4519337486814369} | train loss {'Reaction outcome loss': 0.48503645299182785, 'Total loss': 0.48503645299182785}
2022-11-28 05:47:17,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:17,093 INFO:     Epoch: 72
2022-11-28 05:47:17,758 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4557484130967747, 'Total loss': 0.4557484130967747} | train loss {'Reaction outcome loss': 0.48553196851524616, 'Total loss': 0.48553196851524616}
2022-11-28 05:47:17,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:17,758 INFO:     Epoch: 73
2022-11-28 05:47:18,427 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4451349215074019, 'Total loss': 0.4451349215074019} | train loss {'Reaction outcome loss': 0.4805992696914942, 'Total loss': 0.4805992696914942}
2022-11-28 05:47:18,427 INFO:     Found new best model at epoch 73
2022-11-28 05:47:18,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:18,428 INFO:     Epoch: 74
2022-11-28 05:47:19,094 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4599581465802409, 'Total loss': 0.4599581465802409} | train loss {'Reaction outcome loss': 0.4769471233650561, 'Total loss': 0.4769471233650561}
2022-11-28 05:47:19,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:19,095 INFO:     Epoch: 75
2022-11-28 05:47:19,758 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4467107186263258, 'Total loss': 0.4467107186263258} | train loss {'Reaction outcome loss': 0.47979725750103114, 'Total loss': 0.47979725750103114}
2022-11-28 05:47:19,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:19,758 INFO:     Epoch: 76
2022-11-28 05:47:20,427 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44458070024847984, 'Total loss': 0.44458070024847984} | train loss {'Reaction outcome loss': 0.47360880654906073, 'Total loss': 0.47360880654906073}
2022-11-28 05:47:20,427 INFO:     Found new best model at epoch 76
2022-11-28 05:47:20,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:20,428 INFO:     Epoch: 77
2022-11-28 05:47:21,095 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5012235421348702, 'Total loss': 0.5012235421348702} | train loss {'Reaction outcome loss': 0.47968255938781845, 'Total loss': 0.47968255938781845}
2022-11-28 05:47:21,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:21,095 INFO:     Epoch: 78
2022-11-28 05:47:21,760 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4500007155266675, 'Total loss': 0.4500007155266675} | train loss {'Reaction outcome loss': 0.4782649526192296, 'Total loss': 0.4782649526192296}
2022-11-28 05:47:21,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:21,760 INFO:     Epoch: 79
2022-11-28 05:47:22,429 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46416087685660884, 'Total loss': 0.46416087685660884} | train loss {'Reaction outcome loss': 0.4834203574686281, 'Total loss': 0.4834203574686281}
2022-11-28 05:47:22,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:22,429 INFO:     Epoch: 80
2022-11-28 05:47:23,100 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48683080957694486, 'Total loss': 0.48683080957694486} | train loss {'Reaction outcome loss': 0.4800329433093148, 'Total loss': 0.4800329433093148}
2022-11-28 05:47:23,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:23,100 INFO:     Epoch: 81
2022-11-28 05:47:23,769 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4836076938293197, 'Total loss': 0.4836076938293197} | train loss {'Reaction outcome loss': 0.4763591236044322, 'Total loss': 0.4763591236044322}
2022-11-28 05:47:23,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:23,770 INFO:     Epoch: 82
2022-11-28 05:47:24,435 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47850279306823557, 'Total loss': 0.47850279306823557} | train loss {'Reaction outcome loss': 0.4832467418764868, 'Total loss': 0.4832467418764868}
2022-11-28 05:47:24,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:24,435 INFO:     Epoch: 83
2022-11-28 05:47:25,101 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45525612140243704, 'Total loss': 0.45525612140243704} | train loss {'Reaction outcome loss': 0.4825062524046629, 'Total loss': 0.4825062524046629}
2022-11-28 05:47:25,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:25,101 INFO:     Epoch: 84
2022-11-28 05:47:25,777 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46972017870707944, 'Total loss': 0.46972017870707944} | train loss {'Reaction outcome loss': 0.48760023839291067, 'Total loss': 0.48760023839291067}
2022-11-28 05:47:25,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:25,778 INFO:     Epoch: 85
2022-11-28 05:47:26,448 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4596467766572129, 'Total loss': 0.4596467766572129} | train loss {'Reaction outcome loss': 0.48361671265334855, 'Total loss': 0.48361671265334855}
2022-11-28 05:47:26,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:26,448 INFO:     Epoch: 86
2022-11-28 05:47:27,116 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49206154996698553, 'Total loss': 0.49206154996698553} | train loss {'Reaction outcome loss': 0.47799410172287493, 'Total loss': 0.47799410172287493}
2022-11-28 05:47:27,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:27,116 INFO:     Epoch: 87
2022-11-28 05:47:27,783 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4969345006075772, 'Total loss': 0.4969345006075772} | train loss {'Reaction outcome loss': 0.4810701457843665, 'Total loss': 0.4810701457843665}
2022-11-28 05:47:27,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:27,783 INFO:     Epoch: 88
2022-11-28 05:47:28,448 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4473289827054197, 'Total loss': 0.4473289827054197} | train loss {'Reaction outcome loss': 0.4801085847279718, 'Total loss': 0.4801085847279718}
2022-11-28 05:47:28,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:28,449 INFO:     Epoch: 89
2022-11-28 05:47:29,111 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.488612445240671, 'Total loss': 0.488612445240671} | train loss {'Reaction outcome loss': 0.4845628080769412, 'Total loss': 0.4845628080769412}
2022-11-28 05:47:29,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:29,112 INFO:     Epoch: 90
2022-11-28 05:47:29,777 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4601810137656602, 'Total loss': 0.4601810137656602} | train loss {'Reaction outcome loss': 0.4810779570571838, 'Total loss': 0.4810779570571838}
2022-11-28 05:47:29,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:29,777 INFO:     Epoch: 91
2022-11-28 05:47:30,446 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5074931396679445, 'Total loss': 0.5074931396679445} | train loss {'Reaction outcome loss': 0.47785785565933875, 'Total loss': 0.47785785565933875}
2022-11-28 05:47:30,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:30,446 INFO:     Epoch: 92
2022-11-28 05:47:31,112 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4547568441114642, 'Total loss': 0.4547568441114642} | train loss {'Reaction outcome loss': 0.4780176299353761, 'Total loss': 0.4780176299353761}
2022-11-28 05:47:31,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:31,112 INFO:     Epoch: 93
2022-11-28 05:47:31,778 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4751660754396157, 'Total loss': 0.4751660754396157} | train loss {'Reaction outcome loss': 0.4750470747990954, 'Total loss': 0.4750470747990954}
2022-11-28 05:47:31,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:31,779 INFO:     Epoch: 94
2022-11-28 05:47:32,449 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45675184205174446, 'Total loss': 0.45675184205174446} | train loss {'Reaction outcome loss': 0.48582142603493506, 'Total loss': 0.48582142603493506}
2022-11-28 05:47:32,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:32,449 INFO:     Epoch: 95
2022-11-28 05:47:33,118 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45395675945011055, 'Total loss': 0.45395675945011055} | train loss {'Reaction outcome loss': 0.4793939723242675, 'Total loss': 0.4793939723242675}
2022-11-28 05:47:33,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:33,118 INFO:     Epoch: 96
2022-11-28 05:47:33,784 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4676829752596942, 'Total loss': 0.4676829752596942} | train loss {'Reaction outcome loss': 0.47951278168587913, 'Total loss': 0.47951278168587913}
2022-11-28 05:47:33,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:33,785 INFO:     Epoch: 97
2022-11-28 05:47:34,451 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46223370459946717, 'Total loss': 0.46223370459946717} | train loss {'Reaction outcome loss': 0.4787326263444078, 'Total loss': 0.4787326263444078}
2022-11-28 05:47:34,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:34,451 INFO:     Epoch: 98
2022-11-28 05:47:35,116 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.460137201981111, 'Total loss': 0.460137201981111} | train loss {'Reaction outcome loss': 0.48426063058357083, 'Total loss': 0.48426063058357083}
2022-11-28 05:47:35,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:35,116 INFO:     Epoch: 99
2022-11-28 05:47:35,783 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4641700542785905, 'Total loss': 0.4641700542785905} | train loss {'Reaction outcome loss': 0.4852155202458943, 'Total loss': 0.4852155202458943}
2022-11-28 05:47:35,783 INFO:     Best model found after epoch 77 of 100.
2022-11-28 05:47:35,783 INFO:   Done with stage: TRAINING
2022-11-28 05:47:35,784 INFO:   Starting stage: EVALUATION
2022-11-28 05:47:35,897 INFO:   Done with stage: EVALUATION
2022-11-28 05:47:35,897 INFO:   Leaving out SEQ value Fold_7
2022-11-28 05:47:35,909 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:47:35,910 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:47:36,557 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:47:36,558 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:47:36,628 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:47:36,628 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:47:36,628 INFO:     No hyperparam tuning for this model
2022-11-28 05:47:36,628 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:47:36,628 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:47:36,629 INFO:     None feature selector for col prot
2022-11-28 05:47:36,629 INFO:     None feature selector for col prot
2022-11-28 05:47:36,629 INFO:     None feature selector for col prot
2022-11-28 05:47:36,629 INFO:     None feature selector for col chem
2022-11-28 05:47:36,630 INFO:     None feature selector for col chem
2022-11-28 05:47:36,630 INFO:     None feature selector for col chem
2022-11-28 05:47:36,630 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:47:36,630 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:47:36,631 INFO:     Number of params in model 169651
2022-11-28 05:47:36,634 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:47:36,634 INFO:   Starting stage: TRAINING
2022-11-28 05:47:36,685 INFO:     Val loss before train {'Reaction outcome loss': 1.0523293817585164, 'Total loss': 1.0523293817585164}
2022-11-28 05:47:36,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:36,686 INFO:     Epoch: 0
2022-11-28 05:47:37,349 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6102880551056429, 'Total loss': 0.6102880551056429} | train loss {'Reaction outcome loss': 0.6839651200875096, 'Total loss': 0.6839651200875096}
2022-11-28 05:47:37,349 INFO:     Found new best model at epoch 0
2022-11-28 05:47:37,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:37,350 INFO:     Epoch: 1
2022-11-28 05:47:38,009 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5592889921231703, 'Total loss': 0.5592889921231703} | train loss {'Reaction outcome loss': 0.5799568313577397, 'Total loss': 0.5799568313577397}
2022-11-28 05:47:38,009 INFO:     Found new best model at epoch 1
2022-11-28 05:47:38,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:38,010 INFO:     Epoch: 2
2022-11-28 05:47:38,669 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5374077861620621, 'Total loss': 0.5374077861620621} | train loss {'Reaction outcome loss': 0.5468947527862271, 'Total loss': 0.5468947527862271}
2022-11-28 05:47:38,670 INFO:     Found new best model at epoch 2
2022-11-28 05:47:38,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:38,670 INFO:     Epoch: 3
2022-11-28 05:47:39,329 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5512490123510361, 'Total loss': 0.5512490123510361} | train loss {'Reaction outcome loss': 0.523690022678993, 'Total loss': 0.523690022678993}
2022-11-28 05:47:39,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:39,329 INFO:     Epoch: 4
2022-11-28 05:47:39,989 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5618823549964211, 'Total loss': 0.5618823549964211} | train loss {'Reaction outcome loss': 0.515955912982404, 'Total loss': 0.515955912982404}
2022-11-28 05:47:39,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:39,989 INFO:     Epoch: 5
2022-11-28 05:47:40,652 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5147371444512497, 'Total loss': 0.5147371444512497} | train loss {'Reaction outcome loss': 0.4943668837470534, 'Total loss': 0.4943668837470534}
2022-11-28 05:47:40,652 INFO:     Found new best model at epoch 5
2022-11-28 05:47:40,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:40,653 INFO:     Epoch: 6
2022-11-28 05:47:41,314 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5192601985552094, 'Total loss': 0.5192601985552094} | train loss {'Reaction outcome loss': 0.48690482509522304, 'Total loss': 0.48690482509522304}
2022-11-28 05:47:41,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:41,314 INFO:     Epoch: 7
2022-11-28 05:47:41,975 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5031750987876545, 'Total loss': 0.5031750987876545} | train loss {'Reaction outcome loss': 0.496998417145961, 'Total loss': 0.496998417145961}
2022-11-28 05:47:41,975 INFO:     Found new best model at epoch 7
2022-11-28 05:47:41,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:41,976 INFO:     Epoch: 8
2022-11-28 05:47:42,637 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49671180275353516, 'Total loss': 0.49671180275353516} | train loss {'Reaction outcome loss': 0.48936163265303323, 'Total loss': 0.48936163265303323}
2022-11-28 05:47:42,638 INFO:     Found new best model at epoch 8
2022-11-28 05:47:42,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:42,639 INFO:     Epoch: 9
2022-11-28 05:47:43,300 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4846464842557907, 'Total loss': 0.4846464842557907} | train loss {'Reaction outcome loss': 0.4853396400477481, 'Total loss': 0.4853396400477481}
2022-11-28 05:47:43,300 INFO:     Found new best model at epoch 9
2022-11-28 05:47:43,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:43,301 INFO:     Epoch: 10
2022-11-28 05:47:43,965 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5268411355262453, 'Total loss': 0.5268411355262453} | train loss {'Reaction outcome loss': 0.48343058364835345, 'Total loss': 0.48343058364835345}
2022-11-28 05:47:43,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:43,965 INFO:     Epoch: 11
2022-11-28 05:47:44,628 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5008043938062408, 'Total loss': 0.5008043938062408} | train loss {'Reaction outcome loss': 0.4817438302373114, 'Total loss': 0.4817438302373114}
2022-11-28 05:47:44,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:44,628 INFO:     Epoch: 12
2022-11-28 05:47:45,288 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5167064077474854, 'Total loss': 0.5167064077474854} | train loss {'Reaction outcome loss': 0.4761503017865695, 'Total loss': 0.4761503017865695}
2022-11-28 05:47:45,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:45,288 INFO:     Epoch: 13
2022-11-28 05:47:45,951 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5180346694859591, 'Total loss': 0.5180346694859591} | train loss {'Reaction outcome loss': 0.47967252473116884, 'Total loss': 0.47967252473116884}
2022-11-28 05:47:45,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:45,951 INFO:     Epoch: 14
2022-11-28 05:47:46,613 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5279512777924538, 'Total loss': 0.5279512777924538} | train loss {'Reaction outcome loss': 0.47147944293961475, 'Total loss': 0.47147944293961475}
2022-11-28 05:47:46,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:46,613 INFO:     Epoch: 15
2022-11-28 05:47:47,275 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5050905238498341, 'Total loss': 0.5050905238498341} | train loss {'Reaction outcome loss': 0.4704591470812014, 'Total loss': 0.4704591470812014}
2022-11-28 05:47:47,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:47,275 INFO:     Epoch: 16
2022-11-28 05:47:47,936 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5269673876464367, 'Total loss': 0.5269673876464367} | train loss {'Reaction outcome loss': 0.474200863496736, 'Total loss': 0.474200863496736}
2022-11-28 05:47:47,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:47,937 INFO:     Epoch: 17
2022-11-28 05:47:48,599 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5017701671882109, 'Total loss': 0.5017701671882109} | train loss {'Reaction outcome loss': 0.4629406539595079, 'Total loss': 0.4629406539595079}
2022-11-28 05:47:48,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:48,599 INFO:     Epoch: 18
2022-11-28 05:47:49,259 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47929325293410907, 'Total loss': 0.47929325293410907} | train loss {'Reaction outcome loss': 0.4674199471468868, 'Total loss': 0.4674199471468868}
2022-11-28 05:47:49,259 INFO:     Found new best model at epoch 18
2022-11-28 05:47:49,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:49,260 INFO:     Epoch: 19
2022-11-28 05:47:49,922 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4793761670589447, 'Total loss': 0.4793761670589447} | train loss {'Reaction outcome loss': 0.4807603186079365, 'Total loss': 0.4807603186079365}
2022-11-28 05:47:49,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:49,922 INFO:     Epoch: 20
2022-11-28 05:47:50,580 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.495066181502559, 'Total loss': 0.495066181502559} | train loss {'Reaction outcome loss': 0.4612761434273199, 'Total loss': 0.4612761434273199}
2022-11-28 05:47:50,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:50,581 INFO:     Epoch: 21
2022-11-28 05:47:51,243 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49127834967591544, 'Total loss': 0.49127834967591544} | train loss {'Reaction outcome loss': 0.46692801366450815, 'Total loss': 0.46692801366450815}
2022-11-28 05:47:51,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:51,243 INFO:     Epoch: 22
2022-11-28 05:47:51,906 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49547931111671706, 'Total loss': 0.49547931111671706} | train loss {'Reaction outcome loss': 0.47593225164693376, 'Total loss': 0.47593225164693376}
2022-11-28 05:47:51,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:51,906 INFO:     Epoch: 23
2022-11-28 05:47:52,566 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48521170832894067, 'Total loss': 0.48521170832894067} | train loss {'Reaction outcome loss': 0.472080006712844, 'Total loss': 0.472080006712844}
2022-11-28 05:47:52,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:52,566 INFO:     Epoch: 24
2022-11-28 05:47:53,227 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5378478900952772, 'Total loss': 0.5378478900952772} | train loss {'Reaction outcome loss': 0.47680071430650317, 'Total loss': 0.47680071430650317}
2022-11-28 05:47:53,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:53,227 INFO:     Epoch: 25
2022-11-28 05:47:53,888 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5288819992406801, 'Total loss': 0.5288819992406801} | train loss {'Reaction outcome loss': 0.4902599903374066, 'Total loss': 0.4902599903374066}
2022-11-28 05:47:53,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:53,889 INFO:     Epoch: 26
2022-11-28 05:47:54,550 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47735791179266845, 'Total loss': 0.47735791179266845} | train loss {'Reaction outcome loss': 0.46581988151256853, 'Total loss': 0.46581988151256853}
2022-11-28 05:47:54,550 INFO:     Found new best model at epoch 26
2022-11-28 05:47:54,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:54,551 INFO:     Epoch: 27
2022-11-28 05:47:55,213 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5108882659538225, 'Total loss': 0.5108882659538225} | train loss {'Reaction outcome loss': 0.46925819607598607, 'Total loss': 0.46925819607598607}
2022-11-28 05:47:55,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:55,214 INFO:     Epoch: 28
2022-11-28 05:47:55,878 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49841578982093115, 'Total loss': 0.49841578982093115} | train loss {'Reaction outcome loss': 0.4594579872407532, 'Total loss': 0.4594579872407532}
2022-11-28 05:47:55,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:55,879 INFO:     Epoch: 29
2022-11-28 05:47:56,543 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5139058523557403, 'Total loss': 0.5139058523557403} | train loss {'Reaction outcome loss': 0.46341890350044496, 'Total loss': 0.46341890350044496}
2022-11-28 05:47:56,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:56,544 INFO:     Epoch: 30
2022-11-28 05:47:57,203 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4996885850348256, 'Total loss': 0.4996885850348256} | train loss {'Reaction outcome loss': 0.4706118979796707, 'Total loss': 0.4706118979796707}
2022-11-28 05:47:57,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:57,204 INFO:     Epoch: 31
2022-11-28 05:47:57,863 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5546366254037077, 'Total loss': 0.5546366254037077} | train loss {'Reaction outcome loss': 0.4594219017487306, 'Total loss': 0.4594219017487306}
2022-11-28 05:47:57,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:57,863 INFO:     Epoch: 32
2022-11-28 05:47:58,522 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49259341034022247, 'Total loss': 0.49259341034022247} | train loss {'Reaction outcome loss': 0.4748643963081151, 'Total loss': 0.4748643963081151}
2022-11-28 05:47:58,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:58,522 INFO:     Epoch: 33
2022-11-28 05:47:59,184 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48604781790213153, 'Total loss': 0.48604781790213153} | train loss {'Reaction outcome loss': 0.4688683065928911, 'Total loss': 0.4688683065928911}
2022-11-28 05:47:59,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:59,184 INFO:     Epoch: 34
2022-11-28 05:47:59,848 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4880506277761676, 'Total loss': 0.4880506277761676} | train loss {'Reaction outcome loss': 0.4696280299893275, 'Total loss': 0.4696280299893275}
2022-11-28 05:47:59,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:47:59,848 INFO:     Epoch: 35
2022-11-28 05:48:00,509 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5164642035961151, 'Total loss': 0.5164642035961151} | train loss {'Reaction outcome loss': 0.46968685904977775, 'Total loss': 0.46968685904977775}
2022-11-28 05:48:00,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:00,509 INFO:     Epoch: 36
2022-11-28 05:48:01,170 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49315548383376817, 'Total loss': 0.49315548383376817} | train loss {'Reaction outcome loss': 0.47361837713583277, 'Total loss': 0.47361837713583277}
2022-11-28 05:48:01,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:01,170 INFO:     Epoch: 37
2022-11-28 05:48:01,829 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5229690303518013, 'Total loss': 0.5229690303518013} | train loss {'Reaction outcome loss': 0.45848717265253364, 'Total loss': 0.45848717265253364}
2022-11-28 05:48:01,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:01,829 INFO:     Epoch: 38
2022-11-28 05:48:02,491 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.485975790430199, 'Total loss': 0.485975790430199} | train loss {'Reaction outcome loss': 0.4552851053263977, 'Total loss': 0.4552851053263977}
2022-11-28 05:48:02,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:02,491 INFO:     Epoch: 39
2022-11-28 05:48:03,155 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4917153756726872, 'Total loss': 0.4917153756726872} | train loss {'Reaction outcome loss': 0.460145937002675, 'Total loss': 0.460145937002675}
2022-11-28 05:48:03,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:03,156 INFO:     Epoch: 40
2022-11-28 05:48:03,818 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48266806605864654, 'Total loss': 0.48266806605864654} | train loss {'Reaction outcome loss': 0.460188747628739, 'Total loss': 0.460188747628739}
2022-11-28 05:48:03,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:03,818 INFO:     Epoch: 41
2022-11-28 05:48:04,479 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4979770843955604, 'Total loss': 0.4979770843955604} | train loss {'Reaction outcome loss': 0.4550310603158194, 'Total loss': 0.4550310603158194}
2022-11-28 05:48:04,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:04,480 INFO:     Epoch: 42
2022-11-28 05:48:05,140 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4876562472094189, 'Total loss': 0.4876562472094189} | train loss {'Reaction outcome loss': 0.46911111037409015, 'Total loss': 0.46911111037409015}
2022-11-28 05:48:05,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:05,140 INFO:     Epoch: 43
2022-11-28 05:48:05,802 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4876609349792654, 'Total loss': 0.4876609349792654} | train loss {'Reaction outcome loss': 0.4545000725791522, 'Total loss': 0.4545000725791522}
2022-11-28 05:48:05,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:05,802 INFO:     Epoch: 44
2022-11-28 05:48:06,467 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4951101822609251, 'Total loss': 0.4951101822609251} | train loss {'Reaction outcome loss': 0.45459533033342014, 'Total loss': 0.45459533033342014}
2022-11-28 05:48:06,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:06,467 INFO:     Epoch: 45
2022-11-28 05:48:07,130 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49126012149182235, 'Total loss': 0.49126012149182235} | train loss {'Reaction outcome loss': 0.46059114606353463, 'Total loss': 0.46059114606353463}
2022-11-28 05:48:07,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:07,131 INFO:     Epoch: 46
2022-11-28 05:48:07,797 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4963824315504594, 'Total loss': 0.4963824315504594} | train loss {'Reaction outcome loss': 0.46689673522223346, 'Total loss': 0.46689673522223346}
2022-11-28 05:48:07,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:07,798 INFO:     Epoch: 47
2022-11-28 05:48:08,464 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5105642175132578, 'Total loss': 0.5105642175132578} | train loss {'Reaction outcome loss': 0.4730059042391989, 'Total loss': 0.4730059042391989}
2022-11-28 05:48:08,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:08,464 INFO:     Epoch: 48
2022-11-28 05:48:09,131 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4607758176597682, 'Total loss': 0.4607758176597682} | train loss {'Reaction outcome loss': 0.45856629575221886, 'Total loss': 0.45856629575221886}
2022-11-28 05:48:09,131 INFO:     Found new best model at epoch 48
2022-11-28 05:48:09,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:09,132 INFO:     Epoch: 49
2022-11-28 05:48:09,795 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49488534744490276, 'Total loss': 0.49488534744490276} | train loss {'Reaction outcome loss': 0.45962962015392445, 'Total loss': 0.45962962015392445}
2022-11-28 05:48:09,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:09,795 INFO:     Epoch: 50
2022-11-28 05:48:10,457 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4880505746061152, 'Total loss': 0.4880505746061152} | train loss {'Reaction outcome loss': 0.46602209675529227, 'Total loss': 0.46602209675529227}
2022-11-28 05:48:10,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:10,457 INFO:     Epoch: 51
2022-11-28 05:48:11,121 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5068566104905172, 'Total loss': 0.5068566104905172} | train loss {'Reaction outcome loss': 0.45862188295796813, 'Total loss': 0.45862188295796813}
2022-11-28 05:48:11,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:11,121 INFO:     Epoch: 52
2022-11-28 05:48:11,787 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5476928874850273, 'Total loss': 0.5476928874850273} | train loss {'Reaction outcome loss': 0.4647759110459432, 'Total loss': 0.4647759110459432}
2022-11-28 05:48:11,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:11,788 INFO:     Epoch: 53
2022-11-28 05:48:12,456 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.6578250584954565, 'Total loss': 0.6578250584954565} | train loss {'Reaction outcome loss': 0.4621761891395155, 'Total loss': 0.4621761891395155}
2022-11-28 05:48:12,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:12,456 INFO:     Epoch: 54
2022-11-28 05:48:13,120 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.477789234708656, 'Total loss': 0.477789234708656} | train loss {'Reaction outcome loss': 0.46484074709929435, 'Total loss': 0.46484074709929435}
2022-11-28 05:48:13,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:13,120 INFO:     Epoch: 55
2022-11-28 05:48:13,782 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47516975145448337, 'Total loss': 0.47516975145448337} | train loss {'Reaction outcome loss': 0.47425602255803856, 'Total loss': 0.47425602255803856}
2022-11-28 05:48:13,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:13,782 INFO:     Epoch: 56
2022-11-28 05:48:14,448 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4570003812285987, 'Total loss': 0.4570003812285987} | train loss {'Reaction outcome loss': 0.4608611153280325, 'Total loss': 0.4608611153280325}
2022-11-28 05:48:14,449 INFO:     Found new best model at epoch 56
2022-11-28 05:48:14,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:14,450 INFO:     Epoch: 57
2022-11-28 05:48:15,113 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4893070235848427, 'Total loss': 0.4893070235848427} | train loss {'Reaction outcome loss': 0.45907996745727325, 'Total loss': 0.45907996745727325}
2022-11-28 05:48:15,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:15,113 INFO:     Epoch: 58
2022-11-28 05:48:15,780 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5263133289461787, 'Total loss': 0.5263133289461787} | train loss {'Reaction outcome loss': 0.4710034342550556, 'Total loss': 0.4710034342550556}
2022-11-28 05:48:15,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:15,780 INFO:     Epoch: 59
2022-11-28 05:48:16,442 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49582567980343645, 'Total loss': 0.49582567980343645} | train loss {'Reaction outcome loss': 0.48121568750635335, 'Total loss': 0.48121568750635335}
2022-11-28 05:48:16,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:16,442 INFO:     Epoch: 60
2022-11-28 05:48:17,103 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4645793004469438, 'Total loss': 0.4645793004469438} | train loss {'Reaction outcome loss': 0.46389061842973417, 'Total loss': 0.46389061842973417}
2022-11-28 05:48:17,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:17,103 INFO:     Epoch: 61
2022-11-28 05:48:17,770 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5367217741229318, 'Total loss': 0.5367217741229318} | train loss {'Reaction outcome loss': 0.459001095490417, 'Total loss': 0.459001095490417}
2022-11-28 05:48:17,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:17,770 INFO:     Epoch: 62
2022-11-28 05:48:18,438 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5220261602239176, 'Total loss': 0.5220261602239176} | train loss {'Reaction outcome loss': 0.4640598951250707, 'Total loss': 0.4640598951250707}
2022-11-28 05:48:18,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:18,438 INFO:     Epoch: 63
2022-11-28 05:48:19,105 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5161446549675681, 'Total loss': 0.5161446549675681} | train loss {'Reaction outcome loss': 0.4636672731292875, 'Total loss': 0.4636672731292875}
2022-11-28 05:48:19,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:19,106 INFO:     Epoch: 64
2022-11-28 05:48:19,769 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5097312459891493, 'Total loss': 0.5097312459891493} | train loss {'Reaction outcome loss': 0.47355882167770913, 'Total loss': 0.47355882167770913}
2022-11-28 05:48:19,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:19,769 INFO:     Epoch: 65
2022-11-28 05:48:20,433 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48178222369063983, 'Total loss': 0.48178222369063983} | train loss {'Reaction outcome loss': 0.45674958303269103, 'Total loss': 0.45674958303269103}
2022-11-28 05:48:20,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:20,433 INFO:     Epoch: 66
2022-11-28 05:48:21,100 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5054443884979595, 'Total loss': 0.5054443884979595} | train loss {'Reaction outcome loss': 0.4581723227373019, 'Total loss': 0.4581723227373019}
2022-11-28 05:48:21,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:21,100 INFO:     Epoch: 67
2022-11-28 05:48:21,762 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48142497038299387, 'Total loss': 0.48142497038299387} | train loss {'Reaction outcome loss': 0.4636017391797502, 'Total loss': 0.4636017391797502}
2022-11-28 05:48:21,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:21,763 INFO:     Epoch: 68
2022-11-28 05:48:22,425 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4561248052526604, 'Total loss': 0.4561248052526604} | train loss {'Reaction outcome loss': 0.47088395807183225, 'Total loss': 0.47088395807183225}
2022-11-28 05:48:22,425 INFO:     Found new best model at epoch 68
2022-11-28 05:48:22,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:22,426 INFO:     Epoch: 69
2022-11-28 05:48:23,088 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4712423699145967, 'Total loss': 0.4712423699145967} | train loss {'Reaction outcome loss': 0.4576425108651401, 'Total loss': 0.4576425108651401}
2022-11-28 05:48:23,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:23,088 INFO:     Epoch: 70
2022-11-28 05:48:23,751 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48999284648082475, 'Total loss': 0.48999284648082475} | train loss {'Reaction outcome loss': 0.46858503892716125, 'Total loss': 0.46858503892716125}
2022-11-28 05:48:23,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:23,752 INFO:     Epoch: 71
2022-11-28 05:48:24,416 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.486891470849514, 'Total loss': 0.486891470849514} | train loss {'Reaction outcome loss': 0.47249988970244944, 'Total loss': 0.47249988970244944}
2022-11-28 05:48:24,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:24,416 INFO:     Epoch: 72
2022-11-28 05:48:25,079 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4628763913430951, 'Total loss': 0.4628763913430951} | train loss {'Reaction outcome loss': 0.45580997898315007, 'Total loss': 0.45580997898315007}
2022-11-28 05:48:25,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:25,080 INFO:     Epoch: 73
2022-11-28 05:48:25,740 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49080516905947164, 'Total loss': 0.49080516905947164} | train loss {'Reaction outcome loss': 0.455395716634628, 'Total loss': 0.455395716634628}
2022-11-28 05:48:25,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:25,740 INFO:     Epoch: 74
2022-11-28 05:48:26,401 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5160875567658381, 'Total loss': 0.5160875567658381} | train loss {'Reaction outcome loss': 0.46955044109087724, 'Total loss': 0.46955044109087724}
2022-11-28 05:48:26,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:26,401 INFO:     Epoch: 75
2022-11-28 05:48:27,064 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5024348365312273, 'Total loss': 0.5024348365312273} | train loss {'Reaction outcome loss': 0.4725205555015247, 'Total loss': 0.4725205555015247}
2022-11-28 05:48:27,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:27,065 INFO:     Epoch: 76
2022-11-28 05:48:27,732 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5083928189494393, 'Total loss': 0.5083928189494393} | train loss {'Reaction outcome loss': 0.46289594537816064, 'Total loss': 0.46289594537816064}
2022-11-28 05:48:27,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:27,732 INFO:     Epoch: 77
2022-11-28 05:48:28,398 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4690939611331983, 'Total loss': 0.4690939611331983} | train loss {'Reaction outcome loss': 0.4767821962654832, 'Total loss': 0.4767821962654832}
2022-11-28 05:48:28,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:28,398 INFO:     Epoch: 78
2022-11-28 05:48:29,064 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46548721566796303, 'Total loss': 0.46548721566796303} | train loss {'Reaction outcome loss': 0.47198872105312734, 'Total loss': 0.47198872105312734}
2022-11-28 05:48:29,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:29,064 INFO:     Epoch: 79
2022-11-28 05:48:29,725 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4691407578912648, 'Total loss': 0.4691407578912648} | train loss {'Reaction outcome loss': 0.47374053181786285, 'Total loss': 0.47374053181786285}
2022-11-28 05:48:29,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:29,726 INFO:     Epoch: 80
2022-11-28 05:48:30,389 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4617208858782595, 'Total loss': 0.4617208858782595} | train loss {'Reaction outcome loss': 0.4565077197213887, 'Total loss': 0.4565077197213887}
2022-11-28 05:48:30,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:30,390 INFO:     Epoch: 81
2022-11-28 05:48:31,054 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4714536229995164, 'Total loss': 0.4714536229995164} | train loss {'Reaction outcome loss': 0.45582183655577635, 'Total loss': 0.45582183655577635}
2022-11-28 05:48:31,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:31,054 INFO:     Epoch: 82
2022-11-28 05:48:31,717 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47729397497393866, 'Total loss': 0.47729397497393866} | train loss {'Reaction outcome loss': 0.4588571277905165, 'Total loss': 0.4588571277905165}
2022-11-28 05:48:31,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:31,718 INFO:     Epoch: 83
2022-11-28 05:48:32,379 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47291536832397635, 'Total loss': 0.47291536832397635} | train loss {'Reaction outcome loss': 0.4654531157933749, 'Total loss': 0.4654531157933749}
2022-11-28 05:48:32,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:32,380 INFO:     Epoch: 84
2022-11-28 05:48:33,041 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46666157990694046, 'Total loss': 0.46666157990694046} | train loss {'Reaction outcome loss': 0.4712624428605261, 'Total loss': 0.4712624428605261}
2022-11-28 05:48:33,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:33,041 INFO:     Epoch: 85
2022-11-28 05:48:33,701 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5258519886569544, 'Total loss': 0.5258519886569544} | train loss {'Reaction outcome loss': 0.46030954576214317, 'Total loss': 0.46030954576214317}
2022-11-28 05:48:33,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:33,701 INFO:     Epoch: 86
2022-11-28 05:48:34,364 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49022496153007855, 'Total loss': 0.49022496153007855} | train loss {'Reaction outcome loss': 0.4683801599962991, 'Total loss': 0.4683801599962991}
2022-11-28 05:48:34,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:34,364 INFO:     Epoch: 87
2022-11-28 05:48:35,024 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4452939358624545, 'Total loss': 0.4452939358624545} | train loss {'Reaction outcome loss': 0.4584962523312342, 'Total loss': 0.4584962523312342}
2022-11-28 05:48:35,024 INFO:     Found new best model at epoch 87
2022-11-28 05:48:35,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:35,025 INFO:     Epoch: 88
2022-11-28 05:48:35,682 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4847407154738903, 'Total loss': 0.4847407154738903} | train loss {'Reaction outcome loss': 0.457706810636936, 'Total loss': 0.457706810636936}
2022-11-28 05:48:35,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:35,682 INFO:     Epoch: 89
2022-11-28 05:48:36,337 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.517284144224091, 'Total loss': 0.517284144224091} | train loss {'Reaction outcome loss': 0.457878389097901, 'Total loss': 0.457878389097901}
2022-11-28 05:48:36,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:36,338 INFO:     Epoch: 90
2022-11-28 05:48:36,997 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46424245698885486, 'Total loss': 0.46424245698885486} | train loss {'Reaction outcome loss': 0.46298196932125596, 'Total loss': 0.46298196932125596}
2022-11-28 05:48:36,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:36,997 INFO:     Epoch: 91
2022-11-28 05:48:37,652 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4864673228426413, 'Total loss': 0.4864673228426413} | train loss {'Reaction outcome loss': 0.4635303966429552, 'Total loss': 0.4635303966429552}
2022-11-28 05:48:37,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:37,653 INFO:     Epoch: 92
2022-11-28 05:48:38,308 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4877883605659008, 'Total loss': 0.4877883605659008} | train loss {'Reaction outcome loss': 0.4558765180559776, 'Total loss': 0.4558765180559776}
2022-11-28 05:48:38,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:38,308 INFO:     Epoch: 93
2022-11-28 05:48:38,965 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4795408570630984, 'Total loss': 0.4795408570630984} | train loss {'Reaction outcome loss': 0.4629723957253371, 'Total loss': 0.4629723957253371}
2022-11-28 05:48:38,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:38,966 INFO:     Epoch: 94
2022-11-28 05:48:39,622 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5171788361939517, 'Total loss': 0.5171788361939517} | train loss {'Reaction outcome loss': 0.46913721545143167, 'Total loss': 0.46913721545143167}
2022-11-28 05:48:39,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:39,622 INFO:     Epoch: 95
2022-11-28 05:48:40,278 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48322325640104036, 'Total loss': 0.48322325640104036} | train loss {'Reaction outcome loss': 0.4664617997070073, 'Total loss': 0.4664617997070073}
2022-11-28 05:48:40,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:40,279 INFO:     Epoch: 96
2022-11-28 05:48:40,933 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5041808005083691, 'Total loss': 0.5041808005083691} | train loss {'Reaction outcome loss': 0.4658107726649958, 'Total loss': 0.4658107726649958}
2022-11-28 05:48:40,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:40,933 INFO:     Epoch: 97
2022-11-28 05:48:41,587 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5122318118810654, 'Total loss': 0.5122318118810654} | train loss {'Reaction outcome loss': 0.4588084170813503, 'Total loss': 0.4588084170813503}
2022-11-28 05:48:41,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:41,587 INFO:     Epoch: 98
2022-11-28 05:48:42,244 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5040827542543411, 'Total loss': 0.5040827542543411} | train loss {'Reaction outcome loss': 0.4612704731433498, 'Total loss': 0.4612704731433498}
2022-11-28 05:48:42,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:42,244 INFO:     Epoch: 99
2022-11-28 05:48:42,898 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4878719462589784, 'Total loss': 0.4878719462589784} | train loss {'Reaction outcome loss': 0.46904078964521045, 'Total loss': 0.46904078964521045}
2022-11-28 05:48:42,898 INFO:     Best model found after epoch 88 of 100.
2022-11-28 05:48:42,898 INFO:   Done with stage: TRAINING
2022-11-28 05:48:42,898 INFO:   Starting stage: EVALUATION
2022-11-28 05:48:43,016 INFO:   Done with stage: EVALUATION
2022-11-28 05:48:43,017 INFO:   Leaving out SEQ value Fold_8
2022-11-28 05:48:43,029 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:48:43,029 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:48:43,666 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:48:43,666 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:48:43,735 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:48:43,736 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:48:43,736 INFO:     No hyperparam tuning for this model
2022-11-28 05:48:43,736 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:48:43,736 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:48:43,736 INFO:     None feature selector for col prot
2022-11-28 05:48:43,737 INFO:     None feature selector for col prot
2022-11-28 05:48:43,737 INFO:     None feature selector for col prot
2022-11-28 05:48:43,737 INFO:     None feature selector for col chem
2022-11-28 05:48:43,737 INFO:     None feature selector for col chem
2022-11-28 05:48:43,737 INFO:     None feature selector for col chem
2022-11-28 05:48:43,737 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:48:43,738 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:48:43,739 INFO:     Number of params in model 169651
2022-11-28 05:48:43,742 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:48:43,742 INFO:   Starting stage: TRAINING
2022-11-28 05:48:43,793 INFO:     Val loss before train {'Reaction outcome loss': 1.0165863321586088, 'Total loss': 1.0165863321586088}
2022-11-28 05:48:43,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:43,794 INFO:     Epoch: 0
2022-11-28 05:48:44,456 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5939397032965313, 'Total loss': 0.5939397032965313} | train loss {'Reaction outcome loss': 0.6735664717252215, 'Total loss': 0.6735664717252215}
2022-11-28 05:48:44,456 INFO:     Found new best model at epoch 0
2022-11-28 05:48:44,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:44,457 INFO:     Epoch: 1
2022-11-28 05:48:45,116 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6001686379313469, 'Total loss': 0.6001686379313469} | train loss {'Reaction outcome loss': 0.5804757978166303, 'Total loss': 0.5804757978166303}
2022-11-28 05:48:45,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:45,117 INFO:     Epoch: 2
2022-11-28 05:48:45,775 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5527724054726687, 'Total loss': 0.5527724054726687} | train loss {'Reaction outcome loss': 0.5439409879186461, 'Total loss': 0.5439409879186461}
2022-11-28 05:48:45,776 INFO:     Found new best model at epoch 2
2022-11-28 05:48:45,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:45,776 INFO:     Epoch: 3
2022-11-28 05:48:46,437 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5634618171236732, 'Total loss': 0.5634618171236732} | train loss {'Reaction outcome loss': 0.5246886380257145, 'Total loss': 0.5246886380257145}
2022-11-28 05:48:46,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:46,437 INFO:     Epoch: 4
2022-11-28 05:48:47,100 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6156689595769752, 'Total loss': 0.6156689595769752} | train loss {'Reaction outcome loss': 0.5137182868896953, 'Total loss': 0.5137182868896953}
2022-11-28 05:48:47,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:47,100 INFO:     Epoch: 5
2022-11-28 05:48:47,767 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5310496857220476, 'Total loss': 0.5310496857220476} | train loss {'Reaction outcome loss': 0.5008936333319833, 'Total loss': 0.5008936333319833}
2022-11-28 05:48:47,767 INFO:     Found new best model at epoch 5
2022-11-28 05:48:47,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:47,768 INFO:     Epoch: 6
2022-11-28 05:48:48,430 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5446511131118644, 'Total loss': 0.5446511131118644} | train loss {'Reaction outcome loss': 0.4895989294314096, 'Total loss': 0.4895989294314096}
2022-11-28 05:48:48,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:48,430 INFO:     Epoch: 7
2022-11-28 05:48:49,094 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5768419118090109, 'Total loss': 0.5768419118090109} | train loss {'Reaction outcome loss': 0.4860470370059052, 'Total loss': 0.4860470370059052}
2022-11-28 05:48:49,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:49,094 INFO:     Epoch: 8
2022-11-28 05:48:49,756 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5492410304194147, 'Total loss': 0.5492410304194147} | train loss {'Reaction outcome loss': 0.49633779623095065, 'Total loss': 0.49633779623095065}
2022-11-28 05:48:49,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:49,756 INFO:     Epoch: 9
2022-11-28 05:48:50,414 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5252935479987751, 'Total loss': 0.5252935479987751} | train loss {'Reaction outcome loss': 0.47582069754360184, 'Total loss': 0.47582069754360184}
2022-11-28 05:48:50,414 INFO:     Found new best model at epoch 9
2022-11-28 05:48:50,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:50,415 INFO:     Epoch: 10
2022-11-28 05:48:51,073 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5369540080428123, 'Total loss': 0.5369540080428123} | train loss {'Reaction outcome loss': 0.4691201136747916, 'Total loss': 0.4691201136747916}
2022-11-28 05:48:51,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:51,074 INFO:     Epoch: 11
2022-11-28 05:48:51,735 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5487243143672292, 'Total loss': 0.5487243143672292} | train loss {'Reaction outcome loss': 0.46875613555312157, 'Total loss': 0.46875613555312157}
2022-11-28 05:48:51,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:51,735 INFO:     Epoch: 12
2022-11-28 05:48:52,398 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5468181601979516, 'Total loss': 0.5468181601979516} | train loss {'Reaction outcome loss': 0.47112850274049467, 'Total loss': 0.47112850274049467}
2022-11-28 05:48:52,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:52,398 INFO:     Epoch: 13
2022-11-28 05:48:53,061 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4931003884835677, 'Total loss': 0.4931003884835677} | train loss {'Reaction outcome loss': 0.46446054170448936, 'Total loss': 0.46446054170448936}
2022-11-28 05:48:53,061 INFO:     Found new best model at epoch 13
2022-11-28 05:48:53,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:53,062 INFO:     Epoch: 14
2022-11-28 05:48:53,725 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4887986254285682, 'Total loss': 0.4887986254285682} | train loss {'Reaction outcome loss': 0.46017563493261415, 'Total loss': 0.46017563493261415}
2022-11-28 05:48:53,725 INFO:     Found new best model at epoch 14
2022-11-28 05:48:53,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:53,726 INFO:     Epoch: 15
2022-11-28 05:48:54,384 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5225077759135853, 'Total loss': 0.5225077759135853} | train loss {'Reaction outcome loss': 0.4649122278055837, 'Total loss': 0.4649122278055837}
2022-11-28 05:48:54,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:54,385 INFO:     Epoch: 16
2022-11-28 05:48:55,044 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5010639164935459, 'Total loss': 0.5010639164935459} | train loss {'Reaction outcome loss': 0.46820604747101185, 'Total loss': 0.46820604747101185}
2022-11-28 05:48:55,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:55,044 INFO:     Epoch: 17
2022-11-28 05:48:55,705 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5209393826397982, 'Total loss': 0.5209393826397982} | train loss {'Reaction outcome loss': 0.46127096518513655, 'Total loss': 0.46127096518513655}
2022-11-28 05:48:55,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:55,705 INFO:     Epoch: 18
2022-11-28 05:48:56,370 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5066967606544495, 'Total loss': 0.5066967606544495} | train loss {'Reaction outcome loss': 0.45760652266683116, 'Total loss': 0.45760652266683116}
2022-11-28 05:48:56,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:56,371 INFO:     Epoch: 19
2022-11-28 05:48:57,031 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5148757851936601, 'Total loss': 0.5148757851936601} | train loss {'Reaction outcome loss': 0.45752003677790204, 'Total loss': 0.45752003677790204}
2022-11-28 05:48:57,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:57,031 INFO:     Epoch: 20
2022-11-28 05:48:57,691 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5222042040391401, 'Total loss': 0.5222042040391401} | train loss {'Reaction outcome loss': 0.4623560539536899, 'Total loss': 0.4623560539536899}
2022-11-28 05:48:57,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:57,694 INFO:     Epoch: 21
2022-11-28 05:48:58,356 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5113355527547273, 'Total loss': 0.5113355527547273} | train loss {'Reaction outcome loss': 0.4505888663472668, 'Total loss': 0.4505888663472668}
2022-11-28 05:48:58,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:58,356 INFO:     Epoch: 22
2022-11-28 05:48:59,017 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5016030449081551, 'Total loss': 0.5016030449081551} | train loss {'Reaction outcome loss': 0.46676887301427705, 'Total loss': 0.46676887301427705}
2022-11-28 05:48:59,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:59,017 INFO:     Epoch: 23
2022-11-28 05:48:59,680 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5053368166766383, 'Total loss': 0.5053368166766383} | train loss {'Reaction outcome loss': 0.4562864135950804, 'Total loss': 0.4562864135950804}
2022-11-28 05:48:59,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:48:59,680 INFO:     Epoch: 24
2022-11-28 05:49:00,340 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4944786083969203, 'Total loss': 0.4944786083969203} | train loss {'Reaction outcome loss': 0.4527215610648836, 'Total loss': 0.4527215610648836}
2022-11-28 05:49:00,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:00,341 INFO:     Epoch: 25
2022-11-28 05:49:01,001 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48729745095426386, 'Total loss': 0.48729745095426386} | train loss {'Reaction outcome loss': 0.45485449185775173, 'Total loss': 0.45485449185775173}
2022-11-28 05:49:01,001 INFO:     Found new best model at epoch 25
2022-11-28 05:49:01,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:01,002 INFO:     Epoch: 26
2022-11-28 05:49:01,660 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5085765719413757, 'Total loss': 0.5085765719413757} | train loss {'Reaction outcome loss': 0.46312637999653816, 'Total loss': 0.46312637999653816}
2022-11-28 05:49:01,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:01,661 INFO:     Epoch: 27
2022-11-28 05:49:02,319 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49737714197147975, 'Total loss': 0.49737714197147975} | train loss {'Reaction outcome loss': 0.45017464028581256, 'Total loss': 0.45017464028581256}
2022-11-28 05:49:02,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:02,319 INFO:     Epoch: 28
2022-11-28 05:49:02,976 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.470338817008517, 'Total loss': 0.470338817008517} | train loss {'Reaction outcome loss': 0.45904841748697145, 'Total loss': 0.45904841748697145}
2022-11-28 05:49:02,976 INFO:     Found new best model at epoch 28
2022-11-28 05:49:02,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:02,977 INFO:     Epoch: 29
2022-11-28 05:49:03,634 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5041974295269359, 'Total loss': 0.5041974295269359} | train loss {'Reaction outcome loss': 0.45256350048246885, 'Total loss': 0.45256350048246885}
2022-11-28 05:49:03,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:03,634 INFO:     Epoch: 30
2022-11-28 05:49:04,300 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5147702666846189, 'Total loss': 0.5147702666846189} | train loss {'Reaction outcome loss': 0.4534454221326497, 'Total loss': 0.4534454221326497}
2022-11-28 05:49:04,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:04,300 INFO:     Epoch: 31
2022-11-28 05:49:04,959 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5189628452062607, 'Total loss': 0.5189628452062607} | train loss {'Reaction outcome loss': 0.4547870852533848, 'Total loss': 0.4547870852533848}
2022-11-28 05:49:04,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:04,960 INFO:     Epoch: 32
2022-11-28 05:49:05,619 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5249643928625367, 'Total loss': 0.5249643928625367} | train loss {'Reaction outcome loss': 0.4510056114485187, 'Total loss': 0.4510056114485187}
2022-11-28 05:49:05,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:05,619 INFO:     Epoch: 33
2022-11-28 05:49:06,280 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.502404773099856, 'Total loss': 0.502404773099856} | train loss {'Reaction outcome loss': 0.4542874965756651, 'Total loss': 0.4542874965756651}
2022-11-28 05:49:06,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:06,280 INFO:     Epoch: 34
2022-11-28 05:49:06,941 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48631582680073654, 'Total loss': 0.48631582680073654} | train loss {'Reaction outcome loss': 0.4563171350427212, 'Total loss': 0.4563171350427212}
2022-11-28 05:49:06,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:06,941 INFO:     Epoch: 35
2022-11-28 05:49:07,599 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5117059031670744, 'Total loss': 0.5117059031670744} | train loss {'Reaction outcome loss': 0.44947335532596033, 'Total loss': 0.44947335532596033}
2022-11-28 05:49:07,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:07,599 INFO:     Epoch: 36
2022-11-28 05:49:08,258 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5128119506619193, 'Total loss': 0.5128119506619193} | train loss {'Reaction outcome loss': 0.4504833176972405, 'Total loss': 0.4504833176972405}
2022-11-28 05:49:08,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:08,258 INFO:     Epoch: 37
2022-11-28 05:49:08,920 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5027780011296272, 'Total loss': 0.5027780011296272} | train loss {'Reaction outcome loss': 0.45257896926975055, 'Total loss': 0.45257896926975055}
2022-11-28 05:49:08,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:08,920 INFO:     Epoch: 38
2022-11-28 05:49:09,583 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5004538094455545, 'Total loss': 0.5004538094455545} | train loss {'Reaction outcome loss': 0.44326062446400044, 'Total loss': 0.44326062446400044}
2022-11-28 05:49:09,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:09,583 INFO:     Epoch: 39
2022-11-28 05:49:10,245 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5540052896196191, 'Total loss': 0.5540052896196191} | train loss {'Reaction outcome loss': 0.4510067088469382, 'Total loss': 0.4510067088469382}
2022-11-28 05:49:10,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:10,246 INFO:     Epoch: 40
2022-11-28 05:49:10,907 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5099852505055341, 'Total loss': 0.5099852505055341} | train loss {'Reaction outcome loss': 0.45058337412774563, 'Total loss': 0.45058337412774563}
2022-11-28 05:49:10,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:10,907 INFO:     Epoch: 41
2022-11-28 05:49:11,567 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4869059713726694, 'Total loss': 0.4869059713726694} | train loss {'Reaction outcome loss': 0.45090759028830835, 'Total loss': 0.45090759028830835}
2022-11-28 05:49:11,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:11,568 INFO:     Epoch: 42
2022-11-28 05:49:12,225 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4703147794035348, 'Total loss': 0.4703147794035348} | train loss {'Reaction outcome loss': 0.4524856962924523, 'Total loss': 0.4524856962924523}
2022-11-28 05:49:12,225 INFO:     Found new best model at epoch 42
2022-11-28 05:49:12,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:12,226 INFO:     Epoch: 43
2022-11-28 05:49:12,887 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4912064837461168, 'Total loss': 0.4912064837461168} | train loss {'Reaction outcome loss': 0.44817214290941915, 'Total loss': 0.44817214290941915}
2022-11-28 05:49:12,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:12,888 INFO:     Epoch: 44
2022-11-28 05:49:13,543 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5142726146362044, 'Total loss': 0.5142726146362044} | train loss {'Reaction outcome loss': 0.44509370895403044, 'Total loss': 0.44509370895403044}
2022-11-28 05:49:13,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:13,544 INFO:     Epoch: 45
2022-11-28 05:49:14,198 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5414480433206666, 'Total loss': 0.5414480433206666} | train loss {'Reaction outcome loss': 0.4507728884777715, 'Total loss': 0.4507728884777715}
2022-11-28 05:49:14,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:14,198 INFO:     Epoch: 46
2022-11-28 05:49:14,856 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4887672310525721, 'Total loss': 0.4887672310525721} | train loss {'Reaction outcome loss': 0.4488615252738518, 'Total loss': 0.4488615252738518}
2022-11-28 05:49:14,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:14,857 INFO:     Epoch: 47
2022-11-28 05:49:15,515 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48896642875942314, 'Total loss': 0.48896642875942314} | train loss {'Reaction outcome loss': 0.4456071497932557, 'Total loss': 0.4456071497932557}
2022-11-28 05:49:15,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:15,516 INFO:     Epoch: 48
2022-11-28 05:49:16,177 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5397982461885973, 'Total loss': 0.5397982461885973} | train loss {'Reaction outcome loss': 0.4398622388440755, 'Total loss': 0.4398622388440755}
2022-11-28 05:49:16,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:16,177 INFO:     Epoch: 49
2022-11-28 05:49:16,836 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5076641833240335, 'Total loss': 0.5076641833240335} | train loss {'Reaction outcome loss': 0.43976997578096005, 'Total loss': 0.43976997578096005}
2022-11-28 05:49:16,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:16,836 INFO:     Epoch: 50
2022-11-28 05:49:17,494 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4927638193423098, 'Total loss': 0.4927638193423098} | train loss {'Reaction outcome loss': 0.4494266582713012, 'Total loss': 0.4494266582713012}
2022-11-28 05:49:17,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:17,494 INFO:     Epoch: 51
2022-11-28 05:49:18,152 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49100779640403663, 'Total loss': 0.49100779640403663} | train loss {'Reaction outcome loss': 0.4417542666196823, 'Total loss': 0.4417542666196823}
2022-11-28 05:49:18,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:18,152 INFO:     Epoch: 52
2022-11-28 05:49:18,809 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.515463301403956, 'Total loss': 0.515463301403956} | train loss {'Reaction outcome loss': 0.4482562487884875, 'Total loss': 0.4482562487884875}
2022-11-28 05:49:18,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:18,809 INFO:     Epoch: 53
2022-11-28 05:49:19,466 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48570445383136923, 'Total loss': 0.48570445383136923} | train loss {'Reaction outcome loss': 0.446077992118174, 'Total loss': 0.446077992118174}
2022-11-28 05:49:19,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:19,466 INFO:     Epoch: 54
2022-11-28 05:49:20,124 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4859203628518365, 'Total loss': 0.4859203628518365} | train loss {'Reaction outcome loss': 0.44443648843274963, 'Total loss': 0.44443648843274963}
2022-11-28 05:49:20,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:20,125 INFO:     Epoch: 55
2022-11-28 05:49:20,784 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5119793225418438, 'Total loss': 0.5119793225418438} | train loss {'Reaction outcome loss': 0.44740844899488075, 'Total loss': 0.44740844899488075}
2022-11-28 05:49:20,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:20,784 INFO:     Epoch: 56
2022-11-28 05:49:21,442 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.505130101333965, 'Total loss': 0.505130101333965} | train loss {'Reaction outcome loss': 0.44915528607464605, 'Total loss': 0.44915528607464605}
2022-11-28 05:49:21,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:21,442 INFO:     Epoch: 57
2022-11-28 05:49:22,101 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5055625648661093, 'Total loss': 0.5055625648661093} | train loss {'Reaction outcome loss': 0.4431877586269571, 'Total loss': 0.4431877586269571}
2022-11-28 05:49:22,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:22,101 INFO:     Epoch: 58
2022-11-28 05:49:22,755 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.560707055370916, 'Total loss': 0.560707055370916} | train loss {'Reaction outcome loss': 0.4437253924627458, 'Total loss': 0.4437253924627458}
2022-11-28 05:49:22,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:22,755 INFO:     Epoch: 59
2022-11-28 05:49:23,414 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4943509569222277, 'Total loss': 0.4943509569222277} | train loss {'Reaction outcome loss': 0.45031726732850075, 'Total loss': 0.45031726732850075}
2022-11-28 05:49:23,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:23,414 INFO:     Epoch: 60
2022-11-28 05:49:24,072 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5123637894337828, 'Total loss': 0.5123637894337828} | train loss {'Reaction outcome loss': 0.4446751203147634, 'Total loss': 0.4446751203147634}
2022-11-28 05:49:24,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:24,073 INFO:     Epoch: 61
2022-11-28 05:49:24,730 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4851042492823167, 'Total loss': 0.4851042492823167} | train loss {'Reaction outcome loss': 0.44659318798972714, 'Total loss': 0.44659318798972714}
2022-11-28 05:49:24,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:24,731 INFO:     Epoch: 62
2022-11-28 05:49:25,389 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48711395399136975, 'Total loss': 0.48711395399136975} | train loss {'Reaction outcome loss': 0.44934924601787524, 'Total loss': 0.44934924601787524}
2022-11-28 05:49:25,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:25,389 INFO:     Epoch: 63
2022-11-28 05:49:26,047 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5025738260962747, 'Total loss': 0.5025738260962747} | train loss {'Reaction outcome loss': 0.44739265166102876, 'Total loss': 0.44739265166102876}
2022-11-28 05:49:26,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:26,047 INFO:     Epoch: 64
2022-11-28 05:49:26,704 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5322970673441887, 'Total loss': 0.5322970673441887} | train loss {'Reaction outcome loss': 0.4412034073574168, 'Total loss': 0.4412034073574168}
2022-11-28 05:49:26,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:26,704 INFO:     Epoch: 65
2022-11-28 05:49:27,363 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5442047762599859, 'Total loss': 0.5442047762599859} | train loss {'Reaction outcome loss': 0.4505436105593558, 'Total loss': 0.4505436105593558}
2022-11-28 05:49:27,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:27,363 INFO:     Epoch: 66
2022-11-28 05:49:28,021 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48703786527568643, 'Total loss': 0.48703786527568643} | train loss {'Reaction outcome loss': 0.45111340260313404, 'Total loss': 0.45111340260313404}
2022-11-28 05:49:28,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:28,022 INFO:     Epoch: 67
2022-11-28 05:49:28,683 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.515383876521479, 'Total loss': 0.515383876521479} | train loss {'Reaction outcome loss': 0.4518438113192397, 'Total loss': 0.4518438113192397}
2022-11-28 05:49:28,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:28,684 INFO:     Epoch: 68
2022-11-28 05:49:29,343 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5201973843980919, 'Total loss': 0.5201973843980919} | train loss {'Reaction outcome loss': 0.44712679592832444, 'Total loss': 0.44712679592832444}
2022-11-28 05:49:29,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:29,344 INFO:     Epoch: 69
2022-11-28 05:49:30,004 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4762918684970249, 'Total loss': 0.4762918684970249} | train loss {'Reaction outcome loss': 0.4477396684909059, 'Total loss': 0.4477396684909059}
2022-11-28 05:49:30,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:30,004 INFO:     Epoch: 70
2022-11-28 05:49:30,664 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4819169389930638, 'Total loss': 0.4819169389930638} | train loss {'Reaction outcome loss': 0.4461753444986478, 'Total loss': 0.4461753444986478}
2022-11-28 05:49:30,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:30,664 INFO:     Epoch: 71
2022-11-28 05:49:31,321 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49250898374752566, 'Total loss': 0.49250898374752566} | train loss {'Reaction outcome loss': 0.44329872925675684, 'Total loss': 0.44329872925675684}
2022-11-28 05:49:31,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:31,322 INFO:     Epoch: 72
2022-11-28 05:49:31,982 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47555349225347693, 'Total loss': 0.47555349225347693} | train loss {'Reaction outcome loss': 0.45111637619594414, 'Total loss': 0.45111637619594414}
2022-11-28 05:49:31,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:31,982 INFO:     Epoch: 73
2022-11-28 05:49:32,646 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4913298697634177, 'Total loss': 0.4913298697634177} | train loss {'Reaction outcome loss': 0.446772409933469, 'Total loss': 0.446772409933469}
2022-11-28 05:49:32,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:32,647 INFO:     Epoch: 74
2022-11-28 05:49:33,309 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4861021736128764, 'Total loss': 0.4861021736128764} | train loss {'Reaction outcome loss': 0.4437207853601825, 'Total loss': 0.4437207853601825}
2022-11-28 05:49:33,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:33,310 INFO:     Epoch: 75
2022-11-28 05:49:33,969 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5374629057266496, 'Total loss': 0.5374629057266496} | train loss {'Reaction outcome loss': 0.4488865556495805, 'Total loss': 0.4488865556495805}
2022-11-28 05:49:33,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:33,969 INFO:     Epoch: 76
2022-11-28 05:49:34,629 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.504214958711104, 'Total loss': 0.504214958711104} | train loss {'Reaction outcome loss': 0.45218344711728636, 'Total loss': 0.45218344711728636}
2022-11-28 05:49:34,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:34,629 INFO:     Epoch: 77
2022-11-28 05:49:35,287 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5358381637118079, 'Total loss': 0.5358381637118079} | train loss {'Reaction outcome loss': 0.4474899658272343, 'Total loss': 0.4474899658272343}
2022-11-28 05:49:35,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:35,287 INFO:     Epoch: 78
2022-11-28 05:49:35,946 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5408882315863263, 'Total loss': 0.5408882315863263} | train loss {'Reaction outcome loss': 0.45211896071991614, 'Total loss': 0.45211896071991614}
2022-11-28 05:49:35,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:35,946 INFO:     Epoch: 79
2022-11-28 05:49:36,604 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49311099404638464, 'Total loss': 0.49311099404638464} | train loss {'Reaction outcome loss': 0.45029651650017305, 'Total loss': 0.45029651650017305}
2022-11-28 05:49:36,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:36,605 INFO:     Epoch: 80
2022-11-28 05:49:37,266 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46677310087464075, 'Total loss': 0.46677310087464075} | train loss {'Reaction outcome loss': 0.44860436743305576, 'Total loss': 0.44860436743305576}
2022-11-28 05:49:37,266 INFO:     Found new best model at epoch 80
2022-11-28 05:49:37,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:37,267 INFO:     Epoch: 81
2022-11-28 05:49:37,926 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4960825531320138, 'Total loss': 0.4960825531320138} | train loss {'Reaction outcome loss': 0.44932561686202405, 'Total loss': 0.44932561686202405}
2022-11-28 05:49:37,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:37,926 INFO:     Epoch: 82
2022-11-28 05:49:38,588 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4914329553192312, 'Total loss': 0.4914329553192312} | train loss {'Reaction outcome loss': 0.4435854222505323, 'Total loss': 0.4435854222505323}
2022-11-28 05:49:38,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:38,588 INFO:     Epoch: 83
2022-11-28 05:49:39,252 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4750836440785365, 'Total loss': 0.4750836440785365} | train loss {'Reaction outcome loss': 0.4453949464424964, 'Total loss': 0.4453949464424964}
2022-11-28 05:49:39,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:39,252 INFO:     Epoch: 84
2022-11-28 05:49:39,913 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4845333526080305, 'Total loss': 0.4845333526080305} | train loss {'Reaction outcome loss': 0.4555521332508614, 'Total loss': 0.4555521332508614}
2022-11-28 05:49:39,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:39,913 INFO:     Epoch: 85
2022-11-28 05:49:40,569 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4711394150826064, 'Total loss': 0.4711394150826064} | train loss {'Reaction outcome loss': 0.44659240612940443, 'Total loss': 0.44659240612940443}
2022-11-28 05:49:40,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:40,569 INFO:     Epoch: 86
2022-11-28 05:49:41,228 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46949448030103336, 'Total loss': 0.46949448030103336} | train loss {'Reaction outcome loss': 0.44253207544886297, 'Total loss': 0.44253207544886297}
2022-11-28 05:49:41,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:41,229 INFO:     Epoch: 87
2022-11-28 05:49:41,885 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49210561337796127, 'Total loss': 0.49210561337796127} | train loss {'Reaction outcome loss': 0.45069248027979364, 'Total loss': 0.45069248027979364}
2022-11-28 05:49:41,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:41,885 INFO:     Epoch: 88
2022-11-28 05:49:42,546 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47327874550087884, 'Total loss': 0.47327874550087884} | train loss {'Reaction outcome loss': 0.4530285668949927, 'Total loss': 0.4530285668949927}
2022-11-28 05:49:42,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:42,546 INFO:     Epoch: 89
2022-11-28 05:49:43,207 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4695708504454656, 'Total loss': 0.4695708504454656} | train loss {'Reaction outcome loss': 0.450376006263879, 'Total loss': 0.450376006263879}
2022-11-28 05:49:43,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:43,207 INFO:     Epoch: 90
2022-11-28 05:49:43,867 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5015039620074359, 'Total loss': 0.5015039620074359} | train loss {'Reaction outcome loss': 0.4482743312274256, 'Total loss': 0.4482743312274256}
2022-11-28 05:49:43,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:43,868 INFO:     Epoch: 91
2022-11-28 05:49:44,530 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4914796528491107, 'Total loss': 0.4914796528491107} | train loss {'Reaction outcome loss': 0.4497362274766689, 'Total loss': 0.4497362274766689}
2022-11-28 05:49:44,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:44,530 INFO:     Epoch: 92
2022-11-28 05:49:45,193 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4650961682200432, 'Total loss': 0.4650961682200432} | train loss {'Reaction outcome loss': 0.44940094097006705, 'Total loss': 0.44940094097006705}
2022-11-28 05:49:45,194 INFO:     Found new best model at epoch 92
2022-11-28 05:49:45,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:45,194 INFO:     Epoch: 93
2022-11-28 05:49:45,857 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5223015661944043, 'Total loss': 0.5223015661944043} | train loss {'Reaction outcome loss': 0.4493919410292179, 'Total loss': 0.4493919410292179}
2022-11-28 05:49:45,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:45,857 INFO:     Epoch: 94
2022-11-28 05:49:46,521 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5430172658102079, 'Total loss': 0.5430172658102079} | train loss {'Reaction outcome loss': 0.4489760586931821, 'Total loss': 0.4489760586931821}
2022-11-28 05:49:46,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:46,521 INFO:     Epoch: 95
2022-11-28 05:49:47,179 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.51145892793482, 'Total loss': 0.51145892793482} | train loss {'Reaction outcome loss': 0.4486449526682977, 'Total loss': 0.4486449526682977}
2022-11-28 05:49:47,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:47,179 INFO:     Epoch: 96
2022-11-28 05:49:47,844 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5318559150804173, 'Total loss': 0.5318559150804173} | train loss {'Reaction outcome loss': 0.45343188334616924, 'Total loss': 0.45343188334616924}
2022-11-28 05:49:47,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:47,845 INFO:     Epoch: 97
2022-11-28 05:49:48,511 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4905067092993043, 'Total loss': 0.4905067092993043} | train loss {'Reaction outcome loss': 0.45025526335643185, 'Total loss': 0.45025526335643185}
2022-11-28 05:49:48,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:48,511 INFO:     Epoch: 98
2022-11-28 05:49:49,174 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46376113762909715, 'Total loss': 0.46376113762909715} | train loss {'Reaction outcome loss': 0.4445742306509806, 'Total loss': 0.4445742306509806}
2022-11-28 05:49:49,174 INFO:     Found new best model at epoch 98
2022-11-28 05:49:49,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:49,176 INFO:     Epoch: 99
2022-11-28 05:49:49,836 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4972247508439151, 'Total loss': 0.4972247508439151} | train loss {'Reaction outcome loss': 0.445323656162908, 'Total loss': 0.445323656162908}
2022-11-28 05:49:49,837 INFO:     Best model found after epoch 99 of 100.
2022-11-28 05:49:49,837 INFO:   Done with stage: TRAINING
2022-11-28 05:49:49,837 INFO:   Starting stage: EVALUATION
2022-11-28 05:49:49,948 INFO:   Done with stage: EVALUATION
2022-11-28 05:49:49,948 INFO:   Leaving out SEQ value Fold_9
2022-11-28 05:49:49,961 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:49:49,961 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:49:50,596 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:49:50,597 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:49:50,667 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:49:50,667 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:49:50,667 INFO:     No hyperparam tuning for this model
2022-11-28 05:49:50,667 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:49:50,667 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:49:50,668 INFO:     None feature selector for col prot
2022-11-28 05:49:50,668 INFO:     None feature selector for col prot
2022-11-28 05:49:50,668 INFO:     None feature selector for col prot
2022-11-28 05:49:50,668 INFO:     None feature selector for col chem
2022-11-28 05:49:50,669 INFO:     None feature selector for col chem
2022-11-28 05:49:50,669 INFO:     None feature selector for col chem
2022-11-28 05:49:50,669 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:49:50,669 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:49:50,670 INFO:     Number of params in model 169651
2022-11-28 05:49:50,673 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:49:50,673 INFO:   Starting stage: TRAINING
2022-11-28 05:49:50,724 INFO:     Val loss before train {'Reaction outcome loss': 0.895533796061169, 'Total loss': 0.895533796061169}
2022-11-28 05:49:50,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:50,724 INFO:     Epoch: 0
2022-11-28 05:49:51,387 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5463457940654322, 'Total loss': 0.5463457940654322} | train loss {'Reaction outcome loss': 0.6937624910666097, 'Total loss': 0.6937624910666097}
2022-11-28 05:49:51,387 INFO:     Found new best model at epoch 0
2022-11-28 05:49:51,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:51,388 INFO:     Epoch: 1
2022-11-28 05:49:52,051 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5066703974523328, 'Total loss': 0.5066703974523328} | train loss {'Reaction outcome loss': 0.6012238349405027, 'Total loss': 0.6012238349405027}
2022-11-28 05:49:52,051 INFO:     Found new best model at epoch 1
2022-11-28 05:49:52,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:52,052 INFO:     Epoch: 2
2022-11-28 05:49:52,713 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.460389525375583, 'Total loss': 0.460389525375583} | train loss {'Reaction outcome loss': 0.5671358601220192, 'Total loss': 0.5671358601220192}
2022-11-28 05:49:52,713 INFO:     Found new best model at epoch 2
2022-11-28 05:49:52,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:52,714 INFO:     Epoch: 3
2022-11-28 05:49:53,374 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5041897313838656, 'Total loss': 0.5041897313838656} | train loss {'Reaction outcome loss': 0.5415890760599605, 'Total loss': 0.5415890760599605}
2022-11-28 05:49:53,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:53,375 INFO:     Epoch: 4
2022-11-28 05:49:54,038 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.467559373175556, 'Total loss': 0.467559373175556} | train loss {'Reaction outcome loss': 0.537611745898762, 'Total loss': 0.537611745898762}
2022-11-28 05:49:54,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:54,039 INFO:     Epoch: 5
2022-11-28 05:49:54,703 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4671890275044875, 'Total loss': 0.4671890275044875} | train loss {'Reaction outcome loss': 0.5299751458148803, 'Total loss': 0.5299751458148803}
2022-11-28 05:49:54,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:54,703 INFO:     Epoch: 6
2022-11-28 05:49:55,365 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4441256773742763, 'Total loss': 0.4441256773742763} | train loss {'Reaction outcome loss': 0.5135248008394434, 'Total loss': 0.5135248008394434}
2022-11-28 05:49:55,366 INFO:     Found new best model at epoch 6
2022-11-28 05:49:55,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:55,366 INFO:     Epoch: 7
2022-11-28 05:49:56,026 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42997692796317016, 'Total loss': 0.42997692796317016} | train loss {'Reaction outcome loss': 0.508000913226316, 'Total loss': 0.508000913226316}
2022-11-28 05:49:56,026 INFO:     Found new best model at epoch 7
2022-11-28 05:49:56,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:56,027 INFO:     Epoch: 8
2022-11-28 05:49:56,684 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46230514313686977, 'Total loss': 0.46230514313686977} | train loss {'Reaction outcome loss': 0.5047504625193053, 'Total loss': 0.5047504625193053}
2022-11-28 05:49:56,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:56,684 INFO:     Epoch: 9
2022-11-28 05:49:57,343 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.444178390909325, 'Total loss': 0.444178390909325} | train loss {'Reaction outcome loss': 0.4955335721493729, 'Total loss': 0.4955335721493729}
2022-11-28 05:49:57,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:57,344 INFO:     Epoch: 10
2022-11-28 05:49:58,007 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45298423211682926, 'Total loss': 0.45298423211682926} | train loss {'Reaction outcome loss': 0.4974424611897238, 'Total loss': 0.4974424611897238}
2022-11-28 05:49:58,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:58,007 INFO:     Epoch: 11
2022-11-28 05:49:58,674 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4147500888529149, 'Total loss': 0.4147500888529149} | train loss {'Reaction outcome loss': 0.4871129806363775, 'Total loss': 0.4871129806363775}
2022-11-28 05:49:58,674 INFO:     Found new best model at epoch 11
2022-11-28 05:49:58,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:58,675 INFO:     Epoch: 12
2022-11-28 05:49:59,342 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44877648793838243, 'Total loss': 0.44877648793838243} | train loss {'Reaction outcome loss': 0.48552676158085945, 'Total loss': 0.48552676158085945}
2022-11-28 05:49:59,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:49:59,342 INFO:     Epoch: 13
2022-11-28 05:50:00,008 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4326642436737364, 'Total loss': 0.4326642436737364} | train loss {'Reaction outcome loss': 0.48172534689787894, 'Total loss': 0.48172534689787894}
2022-11-28 05:50:00,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:00,009 INFO:     Epoch: 14
2022-11-28 05:50:00,673 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43270173939791595, 'Total loss': 0.43270173939791595} | train loss {'Reaction outcome loss': 0.48290371023599177, 'Total loss': 0.48290371023599177}
2022-11-28 05:50:00,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:00,674 INFO:     Epoch: 15
2022-11-28 05:50:01,340 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41805869340896606, 'Total loss': 0.41805869340896606} | train loss {'Reaction outcome loss': 0.47739851156309726, 'Total loss': 0.47739851156309726}
2022-11-28 05:50:01,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:01,340 INFO:     Epoch: 16
2022-11-28 05:50:02,005 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42613748901269655, 'Total loss': 0.42613748901269655} | train loss {'Reaction outcome loss': 0.476520360838021, 'Total loss': 0.476520360838021}
2022-11-28 05:50:02,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:02,005 INFO:     Epoch: 17
2022-11-28 05:50:02,669 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42562846500765195, 'Total loss': 0.42562846500765195} | train loss {'Reaction outcome loss': 0.4791495423283308, 'Total loss': 0.4791495423283308}
2022-11-28 05:50:02,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:02,670 INFO:     Epoch: 18
2022-11-28 05:50:03,333 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42535924674435094, 'Total loss': 0.42535924674435094} | train loss {'Reaction outcome loss': 0.4741067018720411, 'Total loss': 0.4741067018720411}
2022-11-28 05:50:03,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:03,333 INFO:     Epoch: 19
2022-11-28 05:50:03,993 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42821565202691336, 'Total loss': 0.42821565202691336} | train loss {'Reaction outcome loss': 0.4740772776666187, 'Total loss': 0.4740772776666187}
2022-11-28 05:50:03,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:03,994 INFO:     Epoch: 20
2022-11-28 05:50:04,653 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4056295132772489, 'Total loss': 0.4056295132772489} | train loss {'Reaction outcome loss': 0.4752146035673157, 'Total loss': 0.4752146035673157}
2022-11-28 05:50:04,653 INFO:     Found new best model at epoch 20
2022-11-28 05:50:04,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:04,654 INFO:     Epoch: 21
2022-11-28 05:50:05,315 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45167380876161833, 'Total loss': 0.45167380876161833} | train loss {'Reaction outcome loss': 0.4773955833046667, 'Total loss': 0.4773955833046667}
2022-11-28 05:50:05,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:05,316 INFO:     Epoch: 22
2022-11-28 05:50:05,981 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4215288788757541, 'Total loss': 0.4215288788757541} | train loss {'Reaction outcome loss': 0.4679229284726804, 'Total loss': 0.4679229284726804}
2022-11-28 05:50:05,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:05,982 INFO:     Epoch: 23
2022-11-28 05:50:06,645 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41892876340584323, 'Total loss': 0.41892876340584323} | train loss {'Reaction outcome loss': 0.4682952291181972, 'Total loss': 0.4682952291181972}
2022-11-28 05:50:06,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:06,645 INFO:     Epoch: 24
2022-11-28 05:50:07,306 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4266368570652875, 'Total loss': 0.4266368570652875} | train loss {'Reaction outcome loss': 0.4723806918989266, 'Total loss': 0.4723806918989266}
2022-11-28 05:50:07,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:07,306 INFO:     Epoch: 25
2022-11-28 05:50:07,969 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4250688769600608, 'Total loss': 0.4250688769600608} | train loss {'Reaction outcome loss': 0.4719617675028501, 'Total loss': 0.4719617675028501}
2022-11-28 05:50:07,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:07,969 INFO:     Epoch: 26
2022-11-28 05:50:08,629 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43091250041669066, 'Total loss': 0.43091250041669066} | train loss {'Reaction outcome loss': 0.4724553278196723, 'Total loss': 0.4724553278196723}
2022-11-28 05:50:08,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:08,630 INFO:     Epoch: 27
2022-11-28 05:50:09,294 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4345457140694965, 'Total loss': 0.4345457140694965} | train loss {'Reaction outcome loss': 0.4776917936340455, 'Total loss': 0.4776917936340455}
2022-11-28 05:50:09,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:09,294 INFO:     Epoch: 28
2022-11-28 05:50:09,958 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.399946772239425, 'Total loss': 0.399946772239425} | train loss {'Reaction outcome loss': 0.4706974822066484, 'Total loss': 0.4706974822066484}
2022-11-28 05:50:09,958 INFO:     Found new best model at epoch 28
2022-11-28 05:50:09,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:09,959 INFO:     Epoch: 29
2022-11-28 05:50:10,625 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44050968844782223, 'Total loss': 0.44050968844782223} | train loss {'Reaction outcome loss': 0.4670244831471674, 'Total loss': 0.4670244831471674}
2022-11-28 05:50:10,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:10,625 INFO:     Epoch: 30
2022-11-28 05:50:11,287 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4260014593601227, 'Total loss': 0.4260014593601227} | train loss {'Reaction outcome loss': 0.4699117983541181, 'Total loss': 0.4699117983541181}
2022-11-28 05:50:11,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:11,287 INFO:     Epoch: 31
2022-11-28 05:50:11,951 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4132710207592357, 'Total loss': 0.4132710207592357} | train loss {'Reaction outcome loss': 0.4681538192615394, 'Total loss': 0.4681538192615394}
2022-11-28 05:50:11,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:11,951 INFO:     Epoch: 32
2022-11-28 05:50:12,609 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40798358246684074, 'Total loss': 0.40798358246684074} | train loss {'Reaction outcome loss': 0.46906240218349043, 'Total loss': 0.46906240218349043}
2022-11-28 05:50:12,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:12,610 INFO:     Epoch: 33
2022-11-28 05:50:13,273 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4504603154279969, 'Total loss': 0.4504603154279969} | train loss {'Reaction outcome loss': 0.46461389376030815, 'Total loss': 0.46461389376030815}
2022-11-28 05:50:13,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:13,273 INFO:     Epoch: 34
2022-11-28 05:50:13,934 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43556291508403694, 'Total loss': 0.43556291508403694} | train loss {'Reaction outcome loss': 0.472094667835101, 'Total loss': 0.472094667835101}
2022-11-28 05:50:13,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:13,934 INFO:     Epoch: 35
2022-11-28 05:50:14,596 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4053812257268212, 'Total loss': 0.4053812257268212} | train loss {'Reaction outcome loss': 0.47478542440841276, 'Total loss': 0.47478542440841276}
2022-11-28 05:50:14,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:14,596 INFO:     Epoch: 36
2022-11-28 05:50:15,258 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3972289384427396, 'Total loss': 0.3972289384427396} | train loss {'Reaction outcome loss': 0.4675084255155056, 'Total loss': 0.4675084255155056}
2022-11-28 05:50:15,258 INFO:     Found new best model at epoch 36
2022-11-28 05:50:15,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:15,259 INFO:     Epoch: 37
2022-11-28 05:50:15,923 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4065038944509896, 'Total loss': 0.4065038944509896} | train loss {'Reaction outcome loss': 0.4656217063386594, 'Total loss': 0.4656217063386594}
2022-11-28 05:50:15,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:15,923 INFO:     Epoch: 38
2022-11-28 05:50:16,586 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42335388640111143, 'Total loss': 0.42335388640111143} | train loss {'Reaction outcome loss': 0.4704387711300965, 'Total loss': 0.4704387711300965}
2022-11-28 05:50:16,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:16,587 INFO:     Epoch: 39
2022-11-28 05:50:17,248 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4311807792295109, 'Total loss': 0.4311807792295109} | train loss {'Reaction outcome loss': 0.46675068299256023, 'Total loss': 0.46675068299256023}
2022-11-28 05:50:17,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:17,248 INFO:     Epoch: 40
2022-11-28 05:50:17,913 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42704111202196643, 'Total loss': 0.42704111202196643} | train loss {'Reaction outcome loss': 0.4684729749757436, 'Total loss': 0.4684729749757436}
2022-11-28 05:50:17,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:17,913 INFO:     Epoch: 41
2022-11-28 05:50:18,577 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.414423983882774, 'Total loss': 0.414423983882774} | train loss {'Reaction outcome loss': 0.47653640560325117, 'Total loss': 0.47653640560325117}
2022-11-28 05:50:18,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:18,577 INFO:     Epoch: 42
2022-11-28 05:50:19,237 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41428829763423314, 'Total loss': 0.41428829763423314} | train loss {'Reaction outcome loss': 0.4648059367412521, 'Total loss': 0.4648059367412521}
2022-11-28 05:50:19,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:19,238 INFO:     Epoch: 43
2022-11-28 05:50:19,899 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4318646758117459, 'Total loss': 0.4318646758117459} | train loss {'Reaction outcome loss': 0.47184507362544537, 'Total loss': 0.47184507362544537}
2022-11-28 05:50:19,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:19,900 INFO:     Epoch: 44
2022-11-28 05:50:20,562 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4109625840051608, 'Total loss': 0.4109625840051608} | train loss {'Reaction outcome loss': 0.47200724981244535, 'Total loss': 0.47200724981244535}
2022-11-28 05:50:20,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:20,563 INFO:     Epoch: 45
2022-11-28 05:50:21,222 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4152092097157782, 'Total loss': 0.4152092097157782} | train loss {'Reaction outcome loss': 0.46894251194692427, 'Total loss': 0.46894251194692427}
2022-11-28 05:50:21,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:21,223 INFO:     Epoch: 46
2022-11-28 05:50:21,884 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41430604085326195, 'Total loss': 0.41430604085326195} | train loss {'Reaction outcome loss': 0.4645630856675486, 'Total loss': 0.4645630856675486}
2022-11-28 05:50:21,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:21,884 INFO:     Epoch: 47
2022-11-28 05:50:22,546 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4142688661813736, 'Total loss': 0.4142688661813736} | train loss {'Reaction outcome loss': 0.4722294507007445, 'Total loss': 0.4722294507007445}
2022-11-28 05:50:22,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:22,546 INFO:     Epoch: 48
2022-11-28 05:50:23,211 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46260758692568, 'Total loss': 0.46260758692568} | train loss {'Reaction outcome loss': 0.46320230195358875, 'Total loss': 0.46320230195358875}
2022-11-28 05:50:23,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:23,211 INFO:     Epoch: 49
2022-11-28 05:50:23,880 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4096927239813588, 'Total loss': 0.4096927239813588} | train loss {'Reaction outcome loss': 0.47334658072119756, 'Total loss': 0.47334658072119756}
2022-11-28 05:50:23,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:23,880 INFO:     Epoch: 50
2022-11-28 05:50:24,549 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4027474871413274, 'Total loss': 0.4027474871413274} | train loss {'Reaction outcome loss': 0.4638136184263614, 'Total loss': 0.4638136184263614}
2022-11-28 05:50:24,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:24,549 INFO:     Epoch: 51
2022-11-28 05:50:25,211 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43496924063021486, 'Total loss': 0.43496924063021486} | train loss {'Reaction outcome loss': 0.47007042812483923, 'Total loss': 0.47007042812483923}
2022-11-28 05:50:25,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:25,211 INFO:     Epoch: 52
2022-11-28 05:50:25,870 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44039455327120697, 'Total loss': 0.44039455327120697} | train loss {'Reaction outcome loss': 0.46609309874475, 'Total loss': 0.46609309874475}
2022-11-28 05:50:25,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:25,870 INFO:     Epoch: 53
2022-11-28 05:50:26,531 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4297963712703098, 'Total loss': 0.4297963712703098} | train loss {'Reaction outcome loss': 0.4685198007031314, 'Total loss': 0.4685198007031314}
2022-11-28 05:50:26,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:26,531 INFO:     Epoch: 54
2022-11-28 05:50:27,193 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41858996281569655, 'Total loss': 0.41858996281569655} | train loss {'Reaction outcome loss': 0.47520697537449097, 'Total loss': 0.47520697537449097}
2022-11-28 05:50:27,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:27,194 INFO:     Epoch: 55
2022-11-28 05:50:27,856 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4229564541442828, 'Total loss': 0.4229564541442828} | train loss {'Reaction outcome loss': 0.4659000611112964, 'Total loss': 0.4659000611112964}
2022-11-28 05:50:27,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:27,856 INFO:     Epoch: 56
2022-11-28 05:50:28,519 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43679676441983745, 'Total loss': 0.43679676441983745} | train loss {'Reaction outcome loss': 0.46631471863797597, 'Total loss': 0.46631471863797597}
2022-11-28 05:50:28,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:28,520 INFO:     Epoch: 57
2022-11-28 05:50:29,183 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41885090517726814, 'Total loss': 0.41885090517726814} | train loss {'Reaction outcome loss': 0.47850700942499025, 'Total loss': 0.47850700942499025}
2022-11-28 05:50:29,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:29,183 INFO:     Epoch: 58
2022-11-28 05:50:29,850 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4200864698399197, 'Total loss': 0.4200864698399197} | train loss {'Reaction outcome loss': 0.4655039994226348, 'Total loss': 0.4655039994226348}
2022-11-28 05:50:29,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:29,851 INFO:     Epoch: 59
2022-11-28 05:50:30,517 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4432172416286035, 'Total loss': 0.4432172416286035} | train loss {'Reaction outcome loss': 0.46853916647453464, 'Total loss': 0.46853916647453464}
2022-11-28 05:50:30,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:30,517 INFO:     Epoch: 60
2022-11-28 05:50:31,178 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4678752913393758, 'Total loss': 0.4678752913393758} | train loss {'Reaction outcome loss': 0.4684816011858563, 'Total loss': 0.4684816011858563}
2022-11-28 05:50:31,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:31,178 INFO:     Epoch: 61
2022-11-28 05:50:31,839 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4153560684485869, 'Total loss': 0.4153560684485869} | train loss {'Reaction outcome loss': 0.46167100665550076, 'Total loss': 0.46167100665550076}
2022-11-28 05:50:31,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:31,840 INFO:     Epoch: 62
2022-11-28 05:50:32,501 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42699936049228365, 'Total loss': 0.42699936049228365} | train loss {'Reaction outcome loss': 0.4663385645516457, 'Total loss': 0.4663385645516457}
2022-11-28 05:50:32,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:32,501 INFO:     Epoch: 63
2022-11-28 05:50:33,164 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4248247671533715, 'Total loss': 0.4248247671533715} | train loss {'Reaction outcome loss': 0.4722543543865604, 'Total loss': 0.4722543543865604}
2022-11-28 05:50:33,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:33,164 INFO:     Epoch: 64
2022-11-28 05:50:33,831 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42774320156736806, 'Total loss': 0.42774320156736806} | train loss {'Reaction outcome loss': 0.46783186513329705, 'Total loss': 0.46783186513329705}
2022-11-28 05:50:33,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:33,831 INFO:     Epoch: 65
2022-11-28 05:50:34,494 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4410750462927602, 'Total loss': 0.4410750462927602} | train loss {'Reaction outcome loss': 0.4769986301900879, 'Total loss': 0.4769986301900879}
2022-11-28 05:50:34,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:34,494 INFO:     Epoch: 66
2022-11-28 05:50:35,158 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4087678807025606, 'Total loss': 0.4087678807025606} | train loss {'Reaction outcome loss': 0.4659609844487521, 'Total loss': 0.4659609844487521}
2022-11-28 05:50:35,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:35,158 INFO:     Epoch: 67
2022-11-28 05:50:35,826 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44628186828710814, 'Total loss': 0.44628186828710814} | train loss {'Reaction outcome loss': 0.4759119948552501, 'Total loss': 0.4759119948552501}
2022-11-28 05:50:35,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:35,826 INFO:     Epoch: 68
2022-11-28 05:50:36,488 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42282892238687386, 'Total loss': 0.42282892238687386} | train loss {'Reaction outcome loss': 0.4592436692647396, 'Total loss': 0.4592436692647396}
2022-11-28 05:50:36,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:36,488 INFO:     Epoch: 69
2022-11-28 05:50:37,151 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43459674241867935, 'Total loss': 0.43459674241867935} | train loss {'Reaction outcome loss': 0.47012554211241586, 'Total loss': 0.47012554211241586}
2022-11-28 05:50:37,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:37,152 INFO:     Epoch: 70
2022-11-28 05:50:37,813 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42107815227725287, 'Total loss': 0.42107815227725287} | train loss {'Reaction outcome loss': 0.47006681092804475, 'Total loss': 0.47006681092804475}
2022-11-28 05:50:37,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:37,814 INFO:     Epoch: 71
2022-11-28 05:50:38,477 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40799409320408647, 'Total loss': 0.40799409320408647} | train loss {'Reaction outcome loss': 0.4706477795637423, 'Total loss': 0.4706477795637423}
2022-11-28 05:50:38,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:38,477 INFO:     Epoch: 72
2022-11-28 05:50:39,140 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4351243417371403, 'Total loss': 0.4351243417371403} | train loss {'Reaction outcome loss': 0.4727699203837302, 'Total loss': 0.4727699203837302}
2022-11-28 05:50:39,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:39,140 INFO:     Epoch: 73
2022-11-28 05:50:39,806 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3931361230259592, 'Total loss': 0.3931361230259592} | train loss {'Reaction outcome loss': 0.475131144927394, 'Total loss': 0.475131144927394}
2022-11-28 05:50:39,806 INFO:     Found new best model at epoch 73
2022-11-28 05:50:39,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:39,807 INFO:     Epoch: 74
2022-11-28 05:50:40,472 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.431578371504491, 'Total loss': 0.431578371504491} | train loss {'Reaction outcome loss': 0.4728968835946533, 'Total loss': 0.4728968835946533}
2022-11-28 05:50:40,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:40,472 INFO:     Epoch: 75
2022-11-28 05:50:41,131 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4079020063985478, 'Total loss': 0.4079020063985478} | train loss {'Reaction outcome loss': 0.47181963055364545, 'Total loss': 0.47181963055364545}
2022-11-28 05:50:41,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:41,131 INFO:     Epoch: 76
2022-11-28 05:50:41,791 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3975050374865532, 'Total loss': 0.3975050374865532} | train loss {'Reaction outcome loss': 0.46803005808784115, 'Total loss': 0.46803005808784115}
2022-11-28 05:50:41,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:41,791 INFO:     Epoch: 77
2022-11-28 05:50:42,453 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4199156734076413, 'Total loss': 0.4199156734076413} | train loss {'Reaction outcome loss': 0.471514324928003, 'Total loss': 0.471514324928003}
2022-11-28 05:50:42,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:42,453 INFO:     Epoch: 78
2022-11-28 05:50:43,117 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4031897746026516, 'Total loss': 0.4031897746026516} | train loss {'Reaction outcome loss': 0.4691381336700532, 'Total loss': 0.4691381336700532}
2022-11-28 05:50:43,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:43,117 INFO:     Epoch: 79
2022-11-28 05:50:43,776 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43400363759561017, 'Total loss': 0.43400363759561017} | train loss {'Reaction outcome loss': 0.4688886609529295, 'Total loss': 0.4688886609529295}
2022-11-28 05:50:43,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:43,777 INFO:     Epoch: 80
2022-11-28 05:50:44,437 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42451116239482706, 'Total loss': 0.42451116239482706} | train loss {'Reaction outcome loss': 0.46789527672433084, 'Total loss': 0.46789527672433084}
2022-11-28 05:50:44,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:44,437 INFO:     Epoch: 81
2022-11-28 05:50:45,097 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4093070768497207, 'Total loss': 0.4093070768497207} | train loss {'Reaction outcome loss': 0.46817748185487523, 'Total loss': 0.46817748185487523}
2022-11-28 05:50:45,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:45,097 INFO:     Epoch: 82
2022-11-28 05:50:45,758 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40989371795545926, 'Total loss': 0.40989371795545926} | train loss {'Reaction outcome loss': 0.46570217327004476, 'Total loss': 0.46570217327004476}
2022-11-28 05:50:45,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:45,759 INFO:     Epoch: 83
2022-11-28 05:50:46,424 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39764332737434993, 'Total loss': 0.39764332737434993} | train loss {'Reaction outcome loss': 0.4685562476816197, 'Total loss': 0.4685562476816197}
2022-11-28 05:50:46,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:46,424 INFO:     Epoch: 84
2022-11-28 05:50:47,086 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4338561398061839, 'Total loss': 0.4338561398061839} | train loss {'Reaction outcome loss': 0.4649537656636488, 'Total loss': 0.4649537656636488}
2022-11-28 05:50:47,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:47,087 INFO:     Epoch: 85
2022-11-28 05:50:47,748 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42165280641479924, 'Total loss': 0.42165280641479924} | train loss {'Reaction outcome loss': 0.46799573061927674, 'Total loss': 0.46799573061927674}
2022-11-28 05:50:47,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:47,748 INFO:     Epoch: 86
2022-11-28 05:50:48,411 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3968351283534007, 'Total loss': 0.3968351283534007} | train loss {'Reaction outcome loss': 0.4803433739129574, 'Total loss': 0.4803433739129574}
2022-11-28 05:50:48,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:48,411 INFO:     Epoch: 87
2022-11-28 05:50:49,074 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3962366120381789, 'Total loss': 0.3962366120381789} | train loss {'Reaction outcome loss': 0.46542161618990285, 'Total loss': 0.46542161618990285}
2022-11-28 05:50:49,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:49,074 INFO:     Epoch: 88
2022-11-28 05:50:49,738 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4260280565782027, 'Total loss': 0.4260280565782027} | train loss {'Reaction outcome loss': 0.46899964245817355, 'Total loss': 0.46899964245817355}
2022-11-28 05:50:49,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:49,739 INFO:     Epoch: 89
2022-11-28 05:50:50,403 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4258533147248355, 'Total loss': 0.4258533147248355} | train loss {'Reaction outcome loss': 0.46882449709359675, 'Total loss': 0.46882449709359675}
2022-11-28 05:50:50,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:50,404 INFO:     Epoch: 90
2022-11-28 05:50:51,066 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40665941109711473, 'Total loss': 0.40665941109711473} | train loss {'Reaction outcome loss': 0.468928107511132, 'Total loss': 0.468928107511132}
2022-11-28 05:50:51,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:51,066 INFO:     Epoch: 91
2022-11-28 05:50:51,727 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4298229979520494, 'Total loss': 0.4298229979520494} | train loss {'Reaction outcome loss': 0.47099015459177956, 'Total loss': 0.47099015459177956}
2022-11-28 05:50:51,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:51,727 INFO:     Epoch: 92
2022-11-28 05:50:52,391 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4294708723371679, 'Total loss': 0.4294708723371679} | train loss {'Reaction outcome loss': 0.4675879205667203, 'Total loss': 0.4675879205667203}
2022-11-28 05:50:52,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:52,391 INFO:     Epoch: 93
2022-11-28 05:50:53,054 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41021158038215205, 'Total loss': 0.41021158038215205} | train loss {'Reaction outcome loss': 0.47121276898730186, 'Total loss': 0.47121276898730186}
2022-11-28 05:50:53,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:53,054 INFO:     Epoch: 94
2022-11-28 05:50:53,711 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4486315392635085, 'Total loss': 0.4486315392635085} | train loss {'Reaction outcome loss': 0.4715538520606295, 'Total loss': 0.4715538520606295}
2022-11-28 05:50:53,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:53,711 INFO:     Epoch: 95
2022-11-28 05:50:54,375 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4421274722977118, 'Total loss': 0.4421274722977118} | train loss {'Reaction outcome loss': 0.47218244510792917, 'Total loss': 0.47218244510792917}
2022-11-28 05:50:54,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:54,375 INFO:     Epoch: 96
2022-11-28 05:50:55,038 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4239559935575182, 'Total loss': 0.4239559935575182} | train loss {'Reaction outcome loss': 0.4728176284040655, 'Total loss': 0.4728176284040655}
2022-11-28 05:50:55,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:55,038 INFO:     Epoch: 97
2022-11-28 05:50:55,703 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4408461248332804, 'Total loss': 0.4408461248332804} | train loss {'Reaction outcome loss': 0.46605190899102916, 'Total loss': 0.46605190899102916}
2022-11-28 05:50:55,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:55,703 INFO:     Epoch: 98
2022-11-28 05:50:56,365 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43660719387910585, 'Total loss': 0.43660719387910585} | train loss {'Reaction outcome loss': 0.46979818390982764, 'Total loss': 0.46979818390982764}
2022-11-28 05:50:56,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:56,365 INFO:     Epoch: 99
2022-11-28 05:50:57,027 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4840345091440461, 'Total loss': 0.4840345091440461} | train loss {'Reaction outcome loss': 0.46681810801308, 'Total loss': 0.46681810801308}
2022-11-28 05:50:57,027 INFO:     Best model found after epoch 74 of 100.
2022-11-28 05:50:57,027 INFO:   Done with stage: TRAINING
2022-11-28 05:50:57,027 INFO:   Starting stage: EVALUATION
2022-11-28 05:50:57,140 INFO:   Done with stage: EVALUATION
2022-11-28 05:50:57,148 INFO:   Leaving out SEQ value Fold_0
2022-11-28 05:50:57,161 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:50:57,161 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:50:57,797 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:50:57,797 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:50:57,867 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:50:57,868 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:50:57,868 INFO:     No hyperparam tuning for this model
2022-11-28 05:50:57,868 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:50:57,868 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:50:57,868 INFO:     None feature selector for col prot
2022-11-28 05:50:57,869 INFO:     None feature selector for col prot
2022-11-28 05:50:57,869 INFO:     None feature selector for col prot
2022-11-28 05:50:57,869 INFO:     None feature selector for col chem
2022-11-28 05:50:57,869 INFO:     None feature selector for col chem
2022-11-28 05:50:57,869 INFO:     None feature selector for col chem
2022-11-28 05:50:57,869 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:50:57,869 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:50:57,871 INFO:     Number of params in model 169651
2022-11-28 05:50:57,874 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:50:57,874 INFO:   Starting stage: TRAINING
2022-11-28 05:50:57,925 INFO:     Val loss before train {'Reaction outcome loss': 0.9640329012816603, 'Total loss': 0.9640329012816603}
2022-11-28 05:50:57,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:57,925 INFO:     Epoch: 0
2022-11-28 05:50:58,584 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5503451092676683, 'Total loss': 0.5503451092676683} | train loss {'Reaction outcome loss': 0.682826390923286, 'Total loss': 0.682826390923286}
2022-11-28 05:50:58,584 INFO:     Found new best model at epoch 0
2022-11-28 05:50:58,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:58,585 INFO:     Epoch: 1
2022-11-28 05:50:59,241 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5681870484893973, 'Total loss': 0.5681870484893973} | train loss {'Reaction outcome loss': 0.57163486486795, 'Total loss': 0.57163486486795}
2022-11-28 05:50:59,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:59,241 INFO:     Epoch: 2
2022-11-28 05:50:59,895 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5299220999533479, 'Total loss': 0.5299220999533479} | train loss {'Reaction outcome loss': 0.5504305784191404, 'Total loss': 0.5504305784191404}
2022-11-28 05:50:59,895 INFO:     Found new best model at epoch 2
2022-11-28 05:50:59,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:50:59,895 INFO:     Epoch: 3
2022-11-28 05:51:00,556 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5206384343857114, 'Total loss': 0.5206384343857114} | train loss {'Reaction outcome loss': 0.5253684640843042, 'Total loss': 0.5253684640843042}
2022-11-28 05:51:00,556 INFO:     Found new best model at epoch 3
2022-11-28 05:51:00,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:00,557 INFO:     Epoch: 4
2022-11-28 05:51:01,216 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4594492922452363, 'Total loss': 0.4594492922452363} | train loss {'Reaction outcome loss': 0.5164445838757924, 'Total loss': 0.5164445838757924}
2022-11-28 05:51:01,216 INFO:     Found new best model at epoch 4
2022-11-28 05:51:01,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:01,217 INFO:     Epoch: 5
2022-11-28 05:51:01,872 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5435144738717512, 'Total loss': 0.5435144738717512} | train loss {'Reaction outcome loss': 0.5057949363577122, 'Total loss': 0.5057949363577122}
2022-11-28 05:51:01,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:01,872 INFO:     Epoch: 6
2022-11-28 05:51:02,528 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4866604185239835, 'Total loss': 0.4866604185239835} | train loss {'Reaction outcome loss': 0.4925634690693447, 'Total loss': 0.4925634690693447}
2022-11-28 05:51:02,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:02,528 INFO:     Epoch: 7
2022-11-28 05:51:03,181 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47752665796063165, 'Total loss': 0.47752665796063165} | train loss {'Reaction outcome loss': 0.482722962450008, 'Total loss': 0.482722962450008}
2022-11-28 05:51:03,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:03,181 INFO:     Epoch: 8
2022-11-28 05:51:03,836 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49199700220064685, 'Total loss': 0.49199700220064685} | train loss {'Reaction outcome loss': 0.4849109037798278, 'Total loss': 0.4849109037798278}
2022-11-28 05:51:03,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:03,836 INFO:     Epoch: 9
2022-11-28 05:51:04,493 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4899139573628252, 'Total loss': 0.4899139573628252} | train loss {'Reaction outcome loss': 0.478411407920779, 'Total loss': 0.478411407920779}
2022-11-28 05:51:04,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:04,493 INFO:     Epoch: 10
2022-11-28 05:51:05,144 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44746028259396553, 'Total loss': 0.44746028259396553} | train loss {'Reaction outcome loss': 0.4759921219275922, 'Total loss': 0.4759921219275922}
2022-11-28 05:51:05,144 INFO:     Found new best model at epoch 10
2022-11-28 05:51:05,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:05,145 INFO:     Epoch: 11
2022-11-28 05:51:05,798 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45396126129410486, 'Total loss': 0.45396126129410486} | train loss {'Reaction outcome loss': 0.47317078551467584, 'Total loss': 0.47317078551467584}
2022-11-28 05:51:05,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:05,798 INFO:     Epoch: 12
2022-11-28 05:51:06,454 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48285879397934134, 'Total loss': 0.48285879397934134} | train loss {'Reaction outcome loss': 0.467435044354322, 'Total loss': 0.467435044354322}
2022-11-28 05:51:06,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:06,454 INFO:     Epoch: 13
2022-11-28 05:51:07,109 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4786807948892767, 'Total loss': 0.4786807948892767} | train loss {'Reaction outcome loss': 0.4742557248898915, 'Total loss': 0.4742557248898915}
2022-11-28 05:51:07,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:07,110 INFO:     Epoch: 14
2022-11-28 05:51:07,766 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45311142030087387, 'Total loss': 0.45311142030087387} | train loss {'Reaction outcome loss': 0.4716632091877412, 'Total loss': 0.4716632091877412}
2022-11-28 05:51:07,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:07,766 INFO:     Epoch: 15
2022-11-28 05:51:08,421 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46069651503454556, 'Total loss': 0.46069651503454556} | train loss {'Reaction outcome loss': 0.47219382025757617, 'Total loss': 0.47219382025757617}
2022-11-28 05:51:08,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:08,421 INFO:     Epoch: 16
2022-11-28 05:51:09,080 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4589512073858218, 'Total loss': 0.4589512073858218} | train loss {'Reaction outcome loss': 0.46461584197015177, 'Total loss': 0.46461584197015177}
2022-11-28 05:51:09,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:09,080 INFO:     Epoch: 17
2022-11-28 05:51:09,732 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4703276841477914, 'Total loss': 0.4703276841477914} | train loss {'Reaction outcome loss': 0.47166678698695436, 'Total loss': 0.47166678698695436}
2022-11-28 05:51:09,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:09,732 INFO:     Epoch: 18
2022-11-28 05:51:10,387 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49038874730467796, 'Total loss': 0.49038874730467796} | train loss {'Reaction outcome loss': 0.4725237516724333, 'Total loss': 0.4725237516724333}
2022-11-28 05:51:10,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:10,387 INFO:     Epoch: 19
2022-11-28 05:51:11,047 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44002764917571435, 'Total loss': 0.44002764917571435} | train loss {'Reaction outcome loss': 0.4672529522557648, 'Total loss': 0.4672529522557648}
2022-11-28 05:51:11,047 INFO:     Found new best model at epoch 19
2022-11-28 05:51:11,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:11,048 INFO:     Epoch: 20
2022-11-28 05:51:11,702 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44676221382211556, 'Total loss': 0.44676221382211556} | train loss {'Reaction outcome loss': 0.46697394884362514, 'Total loss': 0.46697394884362514}
2022-11-28 05:51:11,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:11,702 INFO:     Epoch: 21
2022-11-28 05:51:12,358 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47092940218069335, 'Total loss': 0.47092940218069335} | train loss {'Reaction outcome loss': 0.47220788731866953, 'Total loss': 0.47220788731866953}
2022-11-28 05:51:12,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:12,358 INFO:     Epoch: 22
2022-11-28 05:51:13,011 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45611904900182376, 'Total loss': 0.45611904900182376} | train loss {'Reaction outcome loss': 0.4674769214221409, 'Total loss': 0.4674769214221409}
2022-11-28 05:51:13,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:13,012 INFO:     Epoch: 23
2022-11-28 05:51:13,663 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4646474454890598, 'Total loss': 0.4646474454890598} | train loss {'Reaction outcome loss': 0.4671255567244121, 'Total loss': 0.4671255567244121}
2022-11-28 05:51:13,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:13,663 INFO:     Epoch: 24
2022-11-28 05:51:14,316 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5181483751670881, 'Total loss': 0.5181483751670881} | train loss {'Reaction outcome loss': 0.46880489630358557, 'Total loss': 0.46880489630358557}
2022-11-28 05:51:14,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:14,317 INFO:     Epoch: 25
2022-11-28 05:51:14,974 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4621112546460195, 'Total loss': 0.4621112546460195} | train loss {'Reaction outcome loss': 0.465982413109468, 'Total loss': 0.465982413109468}
2022-11-28 05:51:14,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:14,975 INFO:     Epoch: 26
2022-11-28 05:51:15,629 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4734959920698946, 'Total loss': 0.4734959920698946} | train loss {'Reaction outcome loss': 0.46405689278427437, 'Total loss': 0.46405689278427437}
2022-11-28 05:51:15,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:15,629 INFO:     Epoch: 27
2022-11-28 05:51:16,286 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44395358792760153, 'Total loss': 0.44395358792760153} | train loss {'Reaction outcome loss': 0.46426543480887705, 'Total loss': 0.46426543480887705}
2022-11-28 05:51:16,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:16,286 INFO:     Epoch: 28
2022-11-28 05:51:16,941 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4422529265284538, 'Total loss': 0.4422529265284538} | train loss {'Reaction outcome loss': 0.46933173318298493, 'Total loss': 0.46933173318298493}
2022-11-28 05:51:16,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:16,942 INFO:     Epoch: 29
2022-11-28 05:51:17,597 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4703774052587422, 'Total loss': 0.4703774052587422} | train loss {'Reaction outcome loss': 0.4635811648806747, 'Total loss': 0.4635811648806747}
2022-11-28 05:51:17,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:17,598 INFO:     Epoch: 30
2022-11-28 05:51:18,251 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45798832042650744, 'Total loss': 0.45798832042650744} | train loss {'Reaction outcome loss': 0.46583408019980604, 'Total loss': 0.46583408019980604}
2022-11-28 05:51:18,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:18,251 INFO:     Epoch: 31
2022-11-28 05:51:18,905 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4683675034479661, 'Total loss': 0.4683675034479661} | train loss {'Reaction outcome loss': 0.46097156627445807, 'Total loss': 0.46097156627445807}
2022-11-28 05:51:18,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:18,905 INFO:     Epoch: 32
2022-11-28 05:51:19,559 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44815066626126115, 'Total loss': 0.44815066626126115} | train loss {'Reaction outcome loss': 0.4634475309021619, 'Total loss': 0.4634475309021619}
2022-11-28 05:51:19,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:19,560 INFO:     Epoch: 33
2022-11-28 05:51:20,218 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4473055641759526, 'Total loss': 0.4473055641759526} | train loss {'Reaction outcome loss': 0.4743319403760287, 'Total loss': 0.4743319403760287}
2022-11-28 05:51:20,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:20,219 INFO:     Epoch: 34
2022-11-28 05:51:20,875 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4576311470432715, 'Total loss': 0.4576311470432715} | train loss {'Reaction outcome loss': 0.46545713635123503, 'Total loss': 0.46545713635123503}
2022-11-28 05:51:20,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:20,876 INFO:     Epoch: 35
2022-11-28 05:51:21,529 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4555259363895113, 'Total loss': 0.4555259363895113} | train loss {'Reaction outcome loss': 0.4666872798788304, 'Total loss': 0.4666872798788304}
2022-11-28 05:51:21,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:21,530 INFO:     Epoch: 36
2022-11-28 05:51:22,185 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43959735452451487, 'Total loss': 0.43959735452451487} | train loss {'Reaction outcome loss': 0.4660552920735612, 'Total loss': 0.4660552920735612}
2022-11-28 05:51:22,185 INFO:     Found new best model at epoch 36
2022-11-28 05:51:22,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:22,186 INFO:     Epoch: 37
2022-11-28 05:51:22,837 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4464860988611525, 'Total loss': 0.4464860988611525} | train loss {'Reaction outcome loss': 0.47060295939445496, 'Total loss': 0.47060295939445496}
2022-11-28 05:51:22,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:22,837 INFO:     Epoch: 38
2022-11-28 05:51:23,489 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42848198183558206, 'Total loss': 0.42848198183558206} | train loss {'Reaction outcome loss': 0.465045555726606, 'Total loss': 0.465045555726606}
2022-11-28 05:51:23,489 INFO:     Found new best model at epoch 38
2022-11-28 05:51:23,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:23,490 INFO:     Epoch: 39
2022-11-28 05:51:24,144 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4368945529515093, 'Total loss': 0.4368945529515093} | train loss {'Reaction outcome loss': 0.469758272657589, 'Total loss': 0.469758272657589}
2022-11-28 05:51:24,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:24,144 INFO:     Epoch: 40
2022-11-28 05:51:24,796 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45822240581566637, 'Total loss': 0.45822240581566637} | train loss {'Reaction outcome loss': 0.465672153873103, 'Total loss': 0.465672153873103}
2022-11-28 05:51:24,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:24,796 INFO:     Epoch: 41
2022-11-28 05:51:25,451 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4323792301795699, 'Total loss': 0.4323792301795699} | train loss {'Reaction outcome loss': 0.4660466075551753, 'Total loss': 0.4660466075551753}
2022-11-28 05:51:25,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:25,451 INFO:     Epoch: 42
2022-11-28 05:51:26,104 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48966134983030235, 'Total loss': 0.48966134983030235} | train loss {'Reaction outcome loss': 0.4619627983594427, 'Total loss': 0.4619627983594427}
2022-11-28 05:51:26,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:26,104 INFO:     Epoch: 43
2022-11-28 05:51:26,755 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4405270383100618, 'Total loss': 0.4405270383100618} | train loss {'Reaction outcome loss': 0.4703011774895143, 'Total loss': 0.4703011774895143}
2022-11-28 05:51:26,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:26,755 INFO:     Epoch: 44
2022-11-28 05:51:27,406 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.439767640422691, 'Total loss': 0.439767640422691} | train loss {'Reaction outcome loss': 0.4640859781479349, 'Total loss': 0.4640859781479349}
2022-11-28 05:51:27,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:27,406 INFO:     Epoch: 45
2022-11-28 05:51:28,054 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.450952756811272, 'Total loss': 0.450952756811272} | train loss {'Reaction outcome loss': 0.4655220949528169, 'Total loss': 0.4655220949528169}
2022-11-28 05:51:28,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:28,054 INFO:     Epoch: 46
2022-11-28 05:51:28,710 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4604180450127883, 'Total loss': 0.4604180450127883} | train loss {'Reaction outcome loss': 0.46502082238391956, 'Total loss': 0.46502082238391956}
2022-11-28 05:51:28,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:28,710 INFO:     Epoch: 47
2022-11-28 05:51:29,364 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45647102492776787, 'Total loss': 0.45647102492776787} | train loss {'Reaction outcome loss': 0.46495754195719347, 'Total loss': 0.46495754195719347}
2022-11-28 05:51:29,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:29,365 INFO:     Epoch: 48
2022-11-28 05:51:30,019 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4550786797295917, 'Total loss': 0.4550786797295917} | train loss {'Reaction outcome loss': 0.47151407605531265, 'Total loss': 0.47151407605531265}
2022-11-28 05:51:30,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:30,019 INFO:     Epoch: 49
2022-11-28 05:51:30,672 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43525974689559505, 'Total loss': 0.43525974689559505} | train loss {'Reaction outcome loss': 0.46387515238353183, 'Total loss': 0.46387515238353183}
2022-11-28 05:51:30,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:30,673 INFO:     Epoch: 50
2022-11-28 05:51:31,323 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4385162066160278, 'Total loss': 0.4385162066160278} | train loss {'Reaction outcome loss': 0.4654619154881458, 'Total loss': 0.4654619154881458}
2022-11-28 05:51:31,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:31,323 INFO:     Epoch: 51
2022-11-28 05:51:31,975 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4376069066876715, 'Total loss': 0.4376069066876715} | train loss {'Reaction outcome loss': 0.46719655114777237, 'Total loss': 0.46719655114777237}
2022-11-28 05:51:31,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:31,975 INFO:     Epoch: 52
2022-11-28 05:51:32,628 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4680939387868751, 'Total loss': 0.4680939387868751} | train loss {'Reaction outcome loss': 0.46481877541055483, 'Total loss': 0.46481877541055483}
2022-11-28 05:51:32,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:32,628 INFO:     Epoch: 53
2022-11-28 05:51:33,283 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4665540118109096, 'Total loss': 0.4665540118109096} | train loss {'Reaction outcome loss': 0.466697971005829, 'Total loss': 0.466697971005829}
2022-11-28 05:51:33,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:33,283 INFO:     Epoch: 54
2022-11-28 05:51:33,941 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4529693719338287, 'Total loss': 0.4529693719338287} | train loss {'Reaction outcome loss': 0.47222554163665187, 'Total loss': 0.47222554163665187}
2022-11-28 05:51:33,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:33,942 INFO:     Epoch: 55
2022-11-28 05:51:34,600 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4580183726820079, 'Total loss': 0.4580183726820079} | train loss {'Reaction outcome loss': 0.4673709300707798, 'Total loss': 0.4673709300707798}
2022-11-28 05:51:34,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:34,600 INFO:     Epoch: 56
2022-11-28 05:51:35,253 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4592256820337339, 'Total loss': 0.4592256820337339} | train loss {'Reaction outcome loss': 0.4558552757817872, 'Total loss': 0.4558552757817872}
2022-11-28 05:51:35,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:35,253 INFO:     Epoch: 57
2022-11-28 05:51:35,905 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45790626819838176, 'Total loss': 0.45790626819838176} | train loss {'Reaction outcome loss': 0.4645990772514927, 'Total loss': 0.4645990772514927}
2022-11-28 05:51:35,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:35,905 INFO:     Epoch: 58
2022-11-28 05:51:36,565 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4590065668929707, 'Total loss': 0.4590065668929707} | train loss {'Reaction outcome loss': 0.466339032199918, 'Total loss': 0.466339032199918}
2022-11-28 05:51:36,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:36,566 INFO:     Epoch: 59
2022-11-28 05:51:37,223 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4482925310730934, 'Total loss': 0.4482925310730934} | train loss {'Reaction outcome loss': 0.46552870644598593, 'Total loss': 0.46552870644598593}
2022-11-28 05:51:37,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:37,224 INFO:     Epoch: 60
2022-11-28 05:51:37,879 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5096802840178664, 'Total loss': 0.5096802840178664} | train loss {'Reaction outcome loss': 0.46192300684598026, 'Total loss': 0.46192300684598026}
2022-11-28 05:51:37,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:37,880 INFO:     Epoch: 61
2022-11-28 05:51:38,533 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45183833519166167, 'Total loss': 0.45183833519166167} | train loss {'Reaction outcome loss': 0.4605329157746568, 'Total loss': 0.4605329157746568}
2022-11-28 05:51:38,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:38,533 INFO:     Epoch: 62
2022-11-28 05:51:39,189 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4383114190264182, 'Total loss': 0.4383114190264182} | train loss {'Reaction outcome loss': 0.45956106119009915, 'Total loss': 0.45956106119009915}
2022-11-28 05:51:39,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:39,189 INFO:     Epoch: 63
2022-11-28 05:51:39,843 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43899422375993297, 'Total loss': 0.43899422375993297} | train loss {'Reaction outcome loss': 0.46085619391227256, 'Total loss': 0.46085619391227256}
2022-11-28 05:51:39,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:39,843 INFO:     Epoch: 64
2022-11-28 05:51:40,496 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44844929027286445, 'Total loss': 0.44844929027286445} | train loss {'Reaction outcome loss': 0.4653514042192576, 'Total loss': 0.4653514042192576}
2022-11-28 05:51:40,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:40,497 INFO:     Epoch: 65
2022-11-28 05:51:41,149 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45592366429892456, 'Total loss': 0.45592366429892456} | train loss {'Reaction outcome loss': 0.4624994541309318, 'Total loss': 0.4624994541309318}
2022-11-28 05:51:41,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:41,149 INFO:     Epoch: 66
2022-11-28 05:51:41,801 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4613326381553303, 'Total loss': 0.4613326381553303} | train loss {'Reaction outcome loss': 0.46216018735146036, 'Total loss': 0.46216018735146036}
2022-11-28 05:51:41,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:41,801 INFO:     Epoch: 67
2022-11-28 05:51:42,449 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48136527751657093, 'Total loss': 0.48136527751657093} | train loss {'Reaction outcome loss': 0.46747006153573795, 'Total loss': 0.46747006153573795}
2022-11-28 05:51:42,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:42,449 INFO:     Epoch: 68
2022-11-28 05:51:43,100 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4730196524072777, 'Total loss': 0.4730196524072777} | train loss {'Reaction outcome loss': 0.46429442234185275, 'Total loss': 0.46429442234185275}
2022-11-28 05:51:43,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:43,100 INFO:     Epoch: 69
2022-11-28 05:51:43,751 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43349433690309525, 'Total loss': 0.43349433690309525} | train loss {'Reaction outcome loss': 0.4646753365896186, 'Total loss': 0.4646753365896186}
2022-11-28 05:51:43,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:43,751 INFO:     Epoch: 70
2022-11-28 05:51:44,402 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4538774629208175, 'Total loss': 0.4538774629208175} | train loss {'Reaction outcome loss': 0.4651014866877575, 'Total loss': 0.4651014866877575}
2022-11-28 05:51:44,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:44,402 INFO:     Epoch: 71
2022-11-28 05:51:45,056 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43270944109694526, 'Total loss': 0.43270944109694526} | train loss {'Reaction outcome loss': 0.46326309968622364, 'Total loss': 0.46326309968622364}
2022-11-28 05:51:45,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:45,056 INFO:     Epoch: 72
2022-11-28 05:51:45,710 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4710874885997989, 'Total loss': 0.4710874885997989} | train loss {'Reaction outcome loss': 0.4586435156817339, 'Total loss': 0.4586435156817339}
2022-11-28 05:51:45,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:45,710 INFO:     Epoch: 73
2022-11-28 05:51:46,366 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45591021210632543, 'Total loss': 0.45591021210632543} | train loss {'Reaction outcome loss': 0.4589575098485363, 'Total loss': 0.4589575098485363}
2022-11-28 05:51:46,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:46,367 INFO:     Epoch: 74
2022-11-28 05:51:47,023 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4899190857329152, 'Total loss': 0.4899190857329152} | train loss {'Reaction outcome loss': 0.4652782081341257, 'Total loss': 0.4652782081341257}
2022-11-28 05:51:47,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:47,023 INFO:     Epoch: 75
2022-11-28 05:51:47,676 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47245175865563477, 'Total loss': 0.47245175865563477} | train loss {'Reaction outcome loss': 0.4577242458961448, 'Total loss': 0.4577242458961448}
2022-11-28 05:51:47,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:47,676 INFO:     Epoch: 76
2022-11-28 05:51:48,329 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45679440383206715, 'Total loss': 0.45679440383206715} | train loss {'Reaction outcome loss': 0.4611978772951632, 'Total loss': 0.4611978772951632}
2022-11-28 05:51:48,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:48,329 INFO:     Epoch: 77
2022-11-28 05:51:48,985 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4422748244621537, 'Total loss': 0.4422748244621537} | train loss {'Reaction outcome loss': 0.45932309892104595, 'Total loss': 0.45932309892104595}
2022-11-28 05:51:48,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:48,985 INFO:     Epoch: 78
2022-11-28 05:51:49,637 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.476825763894753, 'Total loss': 0.476825763894753} | train loss {'Reaction outcome loss': 0.4549999585565256, 'Total loss': 0.4549999585565256}
2022-11-28 05:51:49,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:49,637 INFO:     Epoch: 79
2022-11-28 05:51:50,289 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4553457142954523, 'Total loss': 0.4553457142954523} | train loss {'Reaction outcome loss': 0.46055887329335116, 'Total loss': 0.46055887329335116}
2022-11-28 05:51:50,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:50,289 INFO:     Epoch: 80
2022-11-28 05:51:50,940 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46045166524973785, 'Total loss': 0.46045166524973785} | train loss {'Reaction outcome loss': 0.461218475200692, 'Total loss': 0.461218475200692}
2022-11-28 05:51:50,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:50,940 INFO:     Epoch: 81
2022-11-28 05:51:51,589 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43069609660993924, 'Total loss': 0.43069609660993924} | train loss {'Reaction outcome loss': 0.4636651924070047, 'Total loss': 0.4636651924070047}
2022-11-28 05:51:51,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:51,589 INFO:     Epoch: 82
2022-11-28 05:51:52,239 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4287119541655887, 'Total loss': 0.4287119541655887} | train loss {'Reaction outcome loss': 0.4582896322011948, 'Total loss': 0.4582896322011948}
2022-11-28 05:51:52,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:52,240 INFO:     Epoch: 83
2022-11-28 05:51:52,895 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4526160819963975, 'Total loss': 0.4526160819963975} | train loss {'Reaction outcome loss': 0.4604634710720607, 'Total loss': 0.4604634710720607}
2022-11-28 05:51:52,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:52,896 INFO:     Epoch: 84
2022-11-28 05:51:53,552 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4741605129092932, 'Total loss': 0.4741605129092932} | train loss {'Reaction outcome loss': 0.4558581063942033, 'Total loss': 0.4558581063942033}
2022-11-28 05:51:53,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:53,552 INFO:     Epoch: 85
2022-11-28 05:51:54,207 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4571392492137172, 'Total loss': 0.4571392492137172} | train loss {'Reaction outcome loss': 0.46429212373130174, 'Total loss': 0.46429212373130174}
2022-11-28 05:51:54,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:54,208 INFO:     Epoch: 86
2022-11-28 05:51:54,866 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4592651403085752, 'Total loss': 0.4592651403085752} | train loss {'Reaction outcome loss': 0.4526025492317822, 'Total loss': 0.4526025492317822}
2022-11-28 05:51:54,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:54,866 INFO:     Epoch: 87
2022-11-28 05:51:55,521 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44119048423387786, 'Total loss': 0.44119048423387786} | train loss {'Reaction outcome loss': 0.4580141470748551, 'Total loss': 0.4580141470748551}
2022-11-28 05:51:55,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:55,522 INFO:     Epoch: 88
2022-11-28 05:51:56,176 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4755144380033016, 'Total loss': 0.4755144380033016} | train loss {'Reaction outcome loss': 0.45950322540438904, 'Total loss': 0.45950322540438904}
2022-11-28 05:51:56,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:56,176 INFO:     Epoch: 89
2022-11-28 05:51:56,830 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4480549374764616, 'Total loss': 0.4480549374764616} | train loss {'Reaction outcome loss': 0.45703851519798744, 'Total loss': 0.45703851519798744}
2022-11-28 05:51:56,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:56,830 INFO:     Epoch: 90
2022-11-28 05:51:57,485 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4523947475986047, 'Total loss': 0.4523947475986047} | train loss {'Reaction outcome loss': 0.46110144738031894, 'Total loss': 0.46110144738031894}
2022-11-28 05:51:57,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:57,485 INFO:     Epoch: 91
2022-11-28 05:51:58,139 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47588599676435644, 'Total loss': 0.47588599676435644} | train loss {'Reaction outcome loss': 0.4553693136998585, 'Total loss': 0.4553693136998585}
2022-11-28 05:51:58,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:58,139 INFO:     Epoch: 92
2022-11-28 05:51:58,793 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4496434225954793, 'Total loss': 0.4496434225954793} | train loss {'Reaction outcome loss': 0.45824238286942853, 'Total loss': 0.45824238286942853}
2022-11-28 05:51:58,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:58,793 INFO:     Epoch: 93
2022-11-28 05:51:59,445 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4642192604528232, 'Total loss': 0.4642192604528232} | train loss {'Reaction outcome loss': 0.4566960386171633, 'Total loss': 0.4566960386171633}
2022-11-28 05:51:59,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:51:59,445 INFO:     Epoch: 94
2022-11-28 05:52:00,099 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.433862596580928, 'Total loss': 0.433862596580928} | train loss {'Reaction outcome loss': 0.46264694016806934, 'Total loss': 0.46264694016806934}
2022-11-28 05:52:00,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:00,099 INFO:     Epoch: 95
2022-11-28 05:52:00,749 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44358916309746826, 'Total loss': 0.44358916309746826} | train loss {'Reaction outcome loss': 0.46414377969138476, 'Total loss': 0.46414377969138476}
2022-11-28 05:52:00,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:00,749 INFO:     Epoch: 96
2022-11-28 05:52:01,403 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4315057479120283, 'Total loss': 0.4315057479120283} | train loss {'Reaction outcome loss': 0.4504618491445269, 'Total loss': 0.4504618491445269}
2022-11-28 05:52:01,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:01,403 INFO:     Epoch: 97
2022-11-28 05:52:02,058 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43247493593530223, 'Total loss': 0.43247493593530223} | train loss {'Reaction outcome loss': 0.45738578481333597, 'Total loss': 0.45738578481333597}
2022-11-28 05:52:02,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:02,058 INFO:     Epoch: 98
2022-11-28 05:52:02,712 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4609965593977408, 'Total loss': 0.4609965593977408} | train loss {'Reaction outcome loss': 0.4585173216097209, 'Total loss': 0.4585173216097209}
2022-11-28 05:52:02,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:02,712 INFO:     Epoch: 99
2022-11-28 05:52:03,365 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4587388086048039, 'Total loss': 0.4587388086048039} | train loss {'Reaction outcome loss': 0.4657688888360043, 'Total loss': 0.4657688888360043}
2022-11-28 05:52:03,365 INFO:     Best model found after epoch 39 of 100.
2022-11-28 05:52:03,365 INFO:   Done with stage: TRAINING
2022-11-28 05:52:03,365 INFO:   Starting stage: EVALUATION
2022-11-28 05:52:03,489 INFO:   Done with stage: EVALUATION
2022-11-28 05:52:03,489 INFO:   Leaving out SEQ value Fold_1
2022-11-28 05:52:03,502 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:52:03,502 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:52:04,131 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:52:04,131 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:52:04,201 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:52:04,201 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:52:04,201 INFO:     No hyperparam tuning for this model
2022-11-28 05:52:04,201 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:52:04,201 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:52:04,202 INFO:     None feature selector for col prot
2022-11-28 05:52:04,202 INFO:     None feature selector for col prot
2022-11-28 05:52:04,202 INFO:     None feature selector for col prot
2022-11-28 05:52:04,203 INFO:     None feature selector for col chem
2022-11-28 05:52:04,203 INFO:     None feature selector for col chem
2022-11-28 05:52:04,203 INFO:     None feature selector for col chem
2022-11-28 05:52:04,203 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:52:04,203 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:52:04,204 INFO:     Number of params in model 169651
2022-11-28 05:52:04,207 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:52:04,208 INFO:   Starting stage: TRAINING
2022-11-28 05:52:04,259 INFO:     Val loss before train {'Reaction outcome loss': 1.0427740101109852, 'Total loss': 1.0427740101109852}
2022-11-28 05:52:04,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:04,259 INFO:     Epoch: 0
2022-11-28 05:52:04,913 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5870032547549768, 'Total loss': 0.5870032547549768} | train loss {'Reaction outcome loss': 0.6825583508428262, 'Total loss': 0.6825583508428262}
2022-11-28 05:52:04,914 INFO:     Found new best model at epoch 0
2022-11-28 05:52:04,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:04,915 INFO:     Epoch: 1
2022-11-28 05:52:05,567 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5788561376658353, 'Total loss': 0.5788561376658353} | train loss {'Reaction outcome loss': 0.5777534596774043, 'Total loss': 0.5777534596774043}
2022-11-28 05:52:05,567 INFO:     Found new best model at epoch 1
2022-11-28 05:52:05,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:05,568 INFO:     Epoch: 2
2022-11-28 05:52:06,221 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5563694475726648, 'Total loss': 0.5563694475726648} | train loss {'Reaction outcome loss': 0.55806000202286, 'Total loss': 0.55806000202286}
2022-11-28 05:52:06,221 INFO:     Found new best model at epoch 2
2022-11-28 05:52:06,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:06,222 INFO:     Epoch: 3
2022-11-28 05:52:06,874 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5183484066616405, 'Total loss': 0.5183484066616405} | train loss {'Reaction outcome loss': 0.5352269613621187, 'Total loss': 0.5352269613621187}
2022-11-28 05:52:06,875 INFO:     Found new best model at epoch 3
2022-11-28 05:52:06,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:06,875 INFO:     Epoch: 4
2022-11-28 05:52:07,526 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5278306596658446, 'Total loss': 0.5278306596658446} | train loss {'Reaction outcome loss': 0.5180564135921245, 'Total loss': 0.5180564135921245}
2022-11-28 05:52:07,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:07,527 INFO:     Epoch: 5
2022-11-28 05:52:08,180 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5256455855613406, 'Total loss': 0.5256455855613406} | train loss {'Reaction outcome loss': 0.5102385589358758, 'Total loss': 0.5102385589358758}
2022-11-28 05:52:08,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:08,181 INFO:     Epoch: 6
2022-11-28 05:52:08,832 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5416038073599339, 'Total loss': 0.5416038073599339} | train loss {'Reaction outcome loss': 0.5024526219586937, 'Total loss': 0.5024526219586937}
2022-11-28 05:52:08,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:08,833 INFO:     Epoch: 7
2022-11-28 05:52:09,484 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5439507907087152, 'Total loss': 0.5439507907087152} | train loss {'Reaction outcome loss': 0.49013860773067086, 'Total loss': 0.49013860773067086}
2022-11-28 05:52:09,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:09,485 INFO:     Epoch: 8
2022-11-28 05:52:10,136 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5029691064899618, 'Total loss': 0.5029691064899618} | train loss {'Reaction outcome loss': 0.49447287965794, 'Total loss': 0.49447287965794}
2022-11-28 05:52:10,136 INFO:     Found new best model at epoch 8
2022-11-28 05:52:10,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:10,137 INFO:     Epoch: 9
2022-11-28 05:52:10,787 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5107419564473358, 'Total loss': 0.5107419564473358} | train loss {'Reaction outcome loss': 0.48917264853205, 'Total loss': 0.48917264853205}
2022-11-28 05:52:10,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:10,788 INFO:     Epoch: 10
2022-11-28 05:52:11,443 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5214977233924649, 'Total loss': 0.5214977233924649} | train loss {'Reaction outcome loss': 0.49088529342291304, 'Total loss': 0.49088529342291304}
2022-11-28 05:52:11,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:11,443 INFO:     Epoch: 11
2022-11-28 05:52:12,098 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5060326724567197, 'Total loss': 0.5060326724567197} | train loss {'Reaction outcome loss': 0.49109816529921124, 'Total loss': 0.49109816529921124}
2022-11-28 05:52:12,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:12,098 INFO:     Epoch: 12
2022-11-28 05:52:12,756 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.526714414358139, 'Total loss': 0.526714414358139} | train loss {'Reaction outcome loss': 0.48251440601081264, 'Total loss': 0.48251440601081264}
2022-11-28 05:52:12,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:12,756 INFO:     Epoch: 13
2022-11-28 05:52:13,411 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5252081196416508, 'Total loss': 0.5252081196416508} | train loss {'Reaction outcome loss': 0.4818098898444857, 'Total loss': 0.4818098898444857}
2022-11-28 05:52:13,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:13,411 INFO:     Epoch: 14
2022-11-28 05:52:14,066 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5248155935921452, 'Total loss': 0.5248155935921452} | train loss {'Reaction outcome loss': 0.48342328351371144, 'Total loss': 0.48342328351371144}
2022-11-28 05:52:14,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:14,066 INFO:     Epoch: 15
2022-11-28 05:52:14,723 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5009527219967409, 'Total loss': 0.5009527219967409} | train loss {'Reaction outcome loss': 0.46746858778048533, 'Total loss': 0.46746858778048533}
2022-11-28 05:52:14,723 INFO:     Found new best model at epoch 15
2022-11-28 05:52:14,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:14,724 INFO:     Epoch: 16
2022-11-28 05:52:15,378 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49053826521743427, 'Total loss': 0.49053826521743427} | train loss {'Reaction outcome loss': 0.47266280839637836, 'Total loss': 0.47266280839637836}
2022-11-28 05:52:15,379 INFO:     Found new best model at epoch 16
2022-11-28 05:52:15,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:15,379 INFO:     Epoch: 17
2022-11-28 05:52:16,035 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48798058757727797, 'Total loss': 0.48798058757727797} | train loss {'Reaction outcome loss': 0.46891706993385235, 'Total loss': 0.46891706993385235}
2022-11-28 05:52:16,035 INFO:     Found new best model at epoch 17
2022-11-28 05:52:16,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:16,036 INFO:     Epoch: 18
2022-11-28 05:52:16,692 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5035232739015059, 'Total loss': 0.5035232739015059} | train loss {'Reaction outcome loss': 0.4653170274228466, 'Total loss': 0.4653170274228466}
2022-11-28 05:52:16,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:16,692 INFO:     Epoch: 19
2022-11-28 05:52:17,348 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.488406068560752, 'Total loss': 0.488406068560752} | train loss {'Reaction outcome loss': 0.46715570353731817, 'Total loss': 0.46715570353731817}
2022-11-28 05:52:17,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:17,348 INFO:     Epoch: 20
2022-11-28 05:52:18,005 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.502907195551829, 'Total loss': 0.502907195551829} | train loss {'Reaction outcome loss': 0.4668490588056798, 'Total loss': 0.4668490588056798}
2022-11-28 05:52:18,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:18,006 INFO:     Epoch: 21
2022-11-28 05:52:18,664 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46473470059308136, 'Total loss': 0.46473470059308136} | train loss {'Reaction outcome loss': 0.4679468039347201, 'Total loss': 0.4679468039347201}
2022-11-28 05:52:18,664 INFO:     Found new best model at epoch 21
2022-11-28 05:52:18,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:18,665 INFO:     Epoch: 22
2022-11-28 05:52:19,321 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48376398059454834, 'Total loss': 0.48376398059454834} | train loss {'Reaction outcome loss': 0.4679372889046766, 'Total loss': 0.4679372889046766}
2022-11-28 05:52:19,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:19,322 INFO:     Epoch: 23
2022-11-28 05:52:19,977 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4765096286481077, 'Total loss': 0.4765096286481077} | train loss {'Reaction outcome loss': 0.46738009093975535, 'Total loss': 0.46738009093975535}
2022-11-28 05:52:19,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:19,977 INFO:     Epoch: 24
2022-11-28 05:52:20,635 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49432681839574466, 'Total loss': 0.49432681839574466} | train loss {'Reaction outcome loss': 0.4683901724158501, 'Total loss': 0.4683901724158501}
2022-11-28 05:52:20,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:20,635 INFO:     Epoch: 25
2022-11-28 05:52:21,298 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48887646570801735, 'Total loss': 0.48887646570801735} | train loss {'Reaction outcome loss': 0.4656541868131988, 'Total loss': 0.4656541868131988}
2022-11-28 05:52:21,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:21,299 INFO:     Epoch: 26
2022-11-28 05:52:21,961 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4880410859530622, 'Total loss': 0.4880410859530622} | train loss {'Reaction outcome loss': 0.4687190632126769, 'Total loss': 0.4687190632126769}
2022-11-28 05:52:21,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:21,961 INFO:     Epoch: 27
2022-11-28 05:52:22,618 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5122854872183367, 'Total loss': 0.5122854872183367} | train loss {'Reaction outcome loss': 0.46890169132728965, 'Total loss': 0.46890169132728965}
2022-11-28 05:52:22,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:22,618 INFO:     Epoch: 28
2022-11-28 05:52:23,273 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48388185555284674, 'Total loss': 0.48388185555284674} | train loss {'Reaction outcome loss': 0.46846612886506683, 'Total loss': 0.46846612886506683}
2022-11-28 05:52:23,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:23,273 INFO:     Epoch: 29
2022-11-28 05:52:23,933 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49008232761513104, 'Total loss': 0.49008232761513104} | train loss {'Reaction outcome loss': 0.4646194035909614, 'Total loss': 0.4646194035909614}
2022-11-28 05:52:23,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:23,933 INFO:     Epoch: 30
2022-11-28 05:52:24,592 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4941758747127923, 'Total loss': 0.4941758747127923} | train loss {'Reaction outcome loss': 0.46953575477308157, 'Total loss': 0.46953575477308157}
2022-11-28 05:52:24,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:24,593 INFO:     Epoch: 31
2022-11-28 05:52:25,254 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47833107310262596, 'Total loss': 0.47833107310262596} | train loss {'Reaction outcome loss': 0.4651574753985113, 'Total loss': 0.4651574753985113}
2022-11-28 05:52:25,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:25,254 INFO:     Epoch: 32
2022-11-28 05:52:25,912 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4895147457718849, 'Total loss': 0.4895147457718849} | train loss {'Reaction outcome loss': 0.468922433257103, 'Total loss': 0.468922433257103}
2022-11-28 05:52:25,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:25,913 INFO:     Epoch: 33
2022-11-28 05:52:26,571 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4664191830564629, 'Total loss': 0.4664191830564629} | train loss {'Reaction outcome loss': 0.46647392116030867, 'Total loss': 0.46647392116030867}
2022-11-28 05:52:26,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:26,571 INFO:     Epoch: 34
2022-11-28 05:52:27,230 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5223095962269739, 'Total loss': 0.5223095962269739} | train loss {'Reaction outcome loss': 0.4624450105793622, 'Total loss': 0.4624450105793622}
2022-11-28 05:52:27,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:27,231 INFO:     Epoch: 35
2022-11-28 05:52:27,886 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4873066652904857, 'Total loss': 0.4873066652904857} | train loss {'Reaction outcome loss': 0.46443990250023043, 'Total loss': 0.46443990250023043}
2022-11-28 05:52:27,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:27,886 INFO:     Epoch: 36
2022-11-28 05:52:28,540 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4660915278575637, 'Total loss': 0.4660915278575637} | train loss {'Reaction outcome loss': 0.4764199228615177, 'Total loss': 0.4764199228615177}
2022-11-28 05:52:28,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:28,541 INFO:     Epoch: 37
2022-11-28 05:52:29,196 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5006704909557645, 'Total loss': 0.5006704909557645} | train loss {'Reaction outcome loss': 0.47057642219017964, 'Total loss': 0.47057642219017964}
2022-11-28 05:52:29,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:29,197 INFO:     Epoch: 38
2022-11-28 05:52:29,851 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48887682062658394, 'Total loss': 0.48887682062658394} | train loss {'Reaction outcome loss': 0.46756874414122834, 'Total loss': 0.46756874414122834}
2022-11-28 05:52:29,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:29,851 INFO:     Epoch: 39
2022-11-28 05:52:30,508 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4832842754708095, 'Total loss': 0.4832842754708095} | train loss {'Reaction outcome loss': 0.46957351647469464, 'Total loss': 0.46957351647469464}
2022-11-28 05:52:30,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:30,508 INFO:     Epoch: 40
2022-11-28 05:52:31,164 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5111938457597386, 'Total loss': 0.5111938457597386} | train loss {'Reaction outcome loss': 0.4702204919591242, 'Total loss': 0.4702204919591242}
2022-11-28 05:52:31,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:31,165 INFO:     Epoch: 41
2022-11-28 05:52:31,823 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4663368014153093, 'Total loss': 0.4663368014153093} | train loss {'Reaction outcome loss': 0.4663925121633374, 'Total loss': 0.4663925121633374}
2022-11-28 05:52:31,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:31,823 INFO:     Epoch: 42
2022-11-28 05:52:32,482 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5014501850713383, 'Total loss': 0.5014501850713383} | train loss {'Reaction outcome loss': 0.46983779924256464, 'Total loss': 0.46983779924256464}
2022-11-28 05:52:32,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:32,482 INFO:     Epoch: 43
2022-11-28 05:52:33,138 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47999766943129624, 'Total loss': 0.47999766943129624} | train loss {'Reaction outcome loss': 0.47165939272666463, 'Total loss': 0.47165939272666463}
2022-11-28 05:52:33,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:33,139 INFO:     Epoch: 44
2022-11-28 05:52:33,797 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45965414900671353, 'Total loss': 0.45965414900671353} | train loss {'Reaction outcome loss': 0.465752333706739, 'Total loss': 0.465752333706739}
2022-11-28 05:52:33,797 INFO:     Found new best model at epoch 44
2022-11-28 05:52:33,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:33,798 INFO:     Epoch: 45
2022-11-28 05:52:34,454 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47236676404083316, 'Total loss': 0.47236676404083316} | train loss {'Reaction outcome loss': 0.4661440256298805, 'Total loss': 0.4661440256298805}
2022-11-28 05:52:34,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:34,455 INFO:     Epoch: 46
2022-11-28 05:52:35,111 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4921198331496932, 'Total loss': 0.4921198331496932} | train loss {'Reaction outcome loss': 0.4686340542472139, 'Total loss': 0.4686340542472139}
2022-11-28 05:52:35,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:35,111 INFO:     Epoch: 47
2022-11-28 05:52:35,766 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5027434216304258, 'Total loss': 0.5027434216304258} | train loss {'Reaction outcome loss': 0.4666966147568761, 'Total loss': 0.4666966147568761}
2022-11-28 05:52:35,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:35,766 INFO:     Epoch: 48
2022-11-28 05:52:36,426 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49436986209316686, 'Total loss': 0.49436986209316686} | train loss {'Reaction outcome loss': 0.46881925189981655, 'Total loss': 0.46881925189981655}
2022-11-28 05:52:36,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:36,426 INFO:     Epoch: 49
2022-11-28 05:52:37,083 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5107163556597449, 'Total loss': 0.5107163556597449} | train loss {'Reaction outcome loss': 0.46726483301240573, 'Total loss': 0.46726483301240573}
2022-11-28 05:52:37,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:37,084 INFO:     Epoch: 50
2022-11-28 05:52:37,741 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5227844053032723, 'Total loss': 0.5227844053032723} | train loss {'Reaction outcome loss': 0.4713902820129784, 'Total loss': 0.4713902820129784}
2022-11-28 05:52:37,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:37,741 INFO:     Epoch: 51
2022-11-28 05:52:38,398 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4827324202792211, 'Total loss': 0.4827324202792211} | train loss {'Reaction outcome loss': 0.4671331280348252, 'Total loss': 0.4671331280348252}
2022-11-28 05:52:38,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:38,399 INFO:     Epoch: 52
2022-11-28 05:52:39,054 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4847595508803021, 'Total loss': 0.4847595508803021} | train loss {'Reaction outcome loss': 0.47092046129460235, 'Total loss': 0.47092046129460235}
2022-11-28 05:52:39,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:39,055 INFO:     Epoch: 53
2022-11-28 05:52:39,714 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4946131374348294, 'Total loss': 0.4946131374348294} | train loss {'Reaction outcome loss': 0.4719117162178974, 'Total loss': 0.4719117162178974}
2022-11-28 05:52:39,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:39,714 INFO:     Epoch: 54
2022-11-28 05:52:40,376 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4737409793517806, 'Total loss': 0.4737409793517806} | train loss {'Reaction outcome loss': 0.47397762050434034, 'Total loss': 0.47397762050434034}
2022-11-28 05:52:40,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:40,376 INFO:     Epoch: 55
2022-11-28 05:52:41,034 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5287580733949487, 'Total loss': 0.5287580733949487} | train loss {'Reaction outcome loss': 0.46385209469162686, 'Total loss': 0.46385209469162686}
2022-11-28 05:52:41,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:41,034 INFO:     Epoch: 56
2022-11-28 05:52:41,694 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5201084464788437, 'Total loss': 0.5201084464788437} | train loss {'Reaction outcome loss': 0.4696137085861089, 'Total loss': 0.4696137085861089}
2022-11-28 05:52:41,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:41,695 INFO:     Epoch: 57
2022-11-28 05:52:42,353 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.477546038614078, 'Total loss': 0.477546038614078} | train loss {'Reaction outcome loss': 0.46748168997618617, 'Total loss': 0.46748168997618617}
2022-11-28 05:52:42,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:42,354 INFO:     Epoch: 58
2022-11-28 05:52:43,012 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4889079657467929, 'Total loss': 0.4889079657467929} | train loss {'Reaction outcome loss': 0.4737941338699691, 'Total loss': 0.4737941338699691}
2022-11-28 05:52:43,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:43,013 INFO:     Epoch: 59
2022-11-28 05:52:43,669 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4912865615703843, 'Total loss': 0.4912865615703843} | train loss {'Reaction outcome loss': 0.4651965455133088, 'Total loss': 0.4651965455133088}
2022-11-28 05:52:43,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:43,669 INFO:     Epoch: 60
2022-11-28 05:52:44,328 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5078332359817895, 'Total loss': 0.5078332359817895} | train loss {'Reaction outcome loss': 0.47216026235599906, 'Total loss': 0.47216026235599906}
2022-11-28 05:52:44,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:44,328 INFO:     Epoch: 61
2022-11-28 05:52:44,985 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4912296357479962, 'Total loss': 0.4912296357479962} | train loss {'Reaction outcome loss': 0.47027516857701906, 'Total loss': 0.47027516857701906}
2022-11-28 05:52:44,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:44,985 INFO:     Epoch: 62
2022-11-28 05:52:45,646 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4765137931839986, 'Total loss': 0.4765137931839986} | train loss {'Reaction outcome loss': 0.47077778012168653, 'Total loss': 0.47077778012168653}
2022-11-28 05:52:45,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:45,646 INFO:     Epoch: 63
2022-11-28 05:52:46,309 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49373666874387045, 'Total loss': 0.49373666874387045} | train loss {'Reaction outcome loss': 0.4747670723163352, 'Total loss': 0.4747670723163352}
2022-11-28 05:52:46,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:46,309 INFO:     Epoch: 64
2022-11-28 05:52:46,970 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.505364101041447, 'Total loss': 0.505364101041447} | train loss {'Reaction outcome loss': 0.46612014174461364, 'Total loss': 0.46612014174461364}
2022-11-28 05:52:46,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:46,971 INFO:     Epoch: 65
2022-11-28 05:52:47,631 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4933659400452267, 'Total loss': 0.4933659400452267} | train loss {'Reaction outcome loss': 0.4662811138192002, 'Total loss': 0.4662811138192002}
2022-11-28 05:52:47,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:47,631 INFO:     Epoch: 66
2022-11-28 05:52:48,290 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5520701984112913, 'Total loss': 0.5520701984112913} | train loss {'Reaction outcome loss': 0.46345738628689126, 'Total loss': 0.46345738628689126}
2022-11-28 05:52:48,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:48,290 INFO:     Epoch: 67
2022-11-28 05:52:48,951 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5300898362289775, 'Total loss': 0.5300898362289775} | train loss {'Reaction outcome loss': 0.47264405525460534, 'Total loss': 0.47264405525460534}
2022-11-28 05:52:48,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:48,952 INFO:     Epoch: 68
2022-11-28 05:52:49,611 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4767554077235135, 'Total loss': 0.4767554077235135} | train loss {'Reaction outcome loss': 0.4698786360876901, 'Total loss': 0.4698786360876901}
2022-11-28 05:52:49,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:49,611 INFO:     Epoch: 69
2022-11-28 05:52:50,272 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5050532899119637, 'Total loss': 0.5050532899119637} | train loss {'Reaction outcome loss': 0.46970079620273747, 'Total loss': 0.46970079620273747}
2022-11-28 05:52:50,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:50,272 INFO:     Epoch: 70
2022-11-28 05:52:50,936 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49470007148655976, 'Total loss': 0.49470007148655976} | train loss {'Reaction outcome loss': 0.4722059130060429, 'Total loss': 0.4722059130060429}
2022-11-28 05:52:50,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:50,937 INFO:     Epoch: 71
2022-11-28 05:52:51,604 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4946212155575102, 'Total loss': 0.4946212155575102} | train loss {'Reaction outcome loss': 0.47826850718381453, 'Total loss': 0.47826850718381453}
2022-11-28 05:52:51,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:51,605 INFO:     Epoch: 72
2022-11-28 05:52:52,264 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4870609248226339, 'Total loss': 0.4870609248226339} | train loss {'Reaction outcome loss': 0.4713534724955656, 'Total loss': 0.4713534724955656}
2022-11-28 05:52:52,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:52,264 INFO:     Epoch: 73
2022-11-28 05:52:52,923 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4786247353662144, 'Total loss': 0.4786247353662144} | train loss {'Reaction outcome loss': 0.46898332542302656, 'Total loss': 0.46898332542302656}
2022-11-28 05:52:52,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:52,923 INFO:     Epoch: 74
2022-11-28 05:52:53,582 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4919550344347954, 'Total loss': 0.4919550344347954} | train loss {'Reaction outcome loss': 0.4702122434973717, 'Total loss': 0.4702122434973717}
2022-11-28 05:52:53,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:53,583 INFO:     Epoch: 75
2022-11-28 05:52:54,240 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49466121433810756, 'Total loss': 0.49466121433810756} | train loss {'Reaction outcome loss': 0.4762500822544098, 'Total loss': 0.4762500822544098}
2022-11-28 05:52:54,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:54,240 INFO:     Epoch: 76
2022-11-28 05:52:54,895 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.477482824946161, 'Total loss': 0.477482824946161} | train loss {'Reaction outcome loss': 0.4676773072505484, 'Total loss': 0.4676773072505484}
2022-11-28 05:52:54,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:54,896 INFO:     Epoch: 77
2022-11-28 05:52:55,553 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49122988703576004, 'Total loss': 0.49122988703576004} | train loss {'Reaction outcome loss': 0.46359751674593713, 'Total loss': 0.46359751674593713}
2022-11-28 05:52:55,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:55,554 INFO:     Epoch: 78
2022-11-28 05:52:56,211 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49005722762508824, 'Total loss': 0.49005722762508824} | train loss {'Reaction outcome loss': 0.4658119721072061, 'Total loss': 0.4658119721072061}
2022-11-28 05:52:56,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:56,212 INFO:     Epoch: 79
2022-11-28 05:52:56,871 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4972109706564383, 'Total loss': 0.4972109706564383} | train loss {'Reaction outcome loss': 0.47190950969044043, 'Total loss': 0.47190950969044043}
2022-11-28 05:52:56,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:56,871 INFO:     Epoch: 80
2022-11-28 05:52:57,534 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5326097025112673, 'Total loss': 0.5326097025112673} | train loss {'Reaction outcome loss': 0.4703032967691519, 'Total loss': 0.4703032967691519}
2022-11-28 05:52:57,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:57,534 INFO:     Epoch: 81
2022-11-28 05:52:58,193 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5145093310963024, 'Total loss': 0.5145093310963024} | train loss {'Reaction outcome loss': 0.467149026600682, 'Total loss': 0.467149026600682}
2022-11-28 05:52:58,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:58,193 INFO:     Epoch: 82
2022-11-28 05:52:58,853 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4976329071955247, 'Total loss': 0.4976329071955247} | train loss {'Reaction outcome loss': 0.46833622631978017, 'Total loss': 0.46833622631978017}
2022-11-28 05:52:58,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:58,853 INFO:     Epoch: 83
2022-11-28 05:52:59,511 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4931468096646396, 'Total loss': 0.4931468096646396} | train loss {'Reaction outcome loss': 0.47340405318810014, 'Total loss': 0.47340405318810014}
2022-11-28 05:52:59,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:52:59,512 INFO:     Epoch: 84
2022-11-28 05:53:00,169 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4806628453291275, 'Total loss': 0.4806628453291275} | train loss {'Reaction outcome loss': 0.46536266298926604, 'Total loss': 0.46536266298926604}
2022-11-28 05:53:00,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:00,169 INFO:     Epoch: 85
2022-11-28 05:53:00,829 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.534726350822232, 'Total loss': 0.534726350822232} | train loss {'Reaction outcome loss': 0.47568797189362194, 'Total loss': 0.47568797189362194}
2022-11-28 05:53:00,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:00,829 INFO:     Epoch: 86
2022-11-28 05:53:01,490 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5119817981665785, 'Total loss': 0.5119817981665785} | train loss {'Reaction outcome loss': 0.4748585771541206, 'Total loss': 0.4748585771541206}
2022-11-28 05:53:01,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:01,490 INFO:     Epoch: 87
2022-11-28 05:53:02,152 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4931605156849731, 'Total loss': 0.4931605156849731} | train loss {'Reaction outcome loss': 0.4686144156723606, 'Total loss': 0.4686144156723606}
2022-11-28 05:53:02,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:02,152 INFO:     Epoch: 88
2022-11-28 05:53:02,810 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4970358183438128, 'Total loss': 0.4970358183438128} | train loss {'Reaction outcome loss': 0.4676462080405683, 'Total loss': 0.4676462080405683}
2022-11-28 05:53:02,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:02,810 INFO:     Epoch: 89
2022-11-28 05:53:03,469 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4853059442883188, 'Total loss': 0.4853059442883188} | train loss {'Reaction outcome loss': 0.47464560878520107, 'Total loss': 0.47464560878520107}
2022-11-28 05:53:03,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:03,469 INFO:     Epoch: 90
2022-11-28 05:53:04,132 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48559513654221187, 'Total loss': 0.48559513654221187} | train loss {'Reaction outcome loss': 0.46748468225099604, 'Total loss': 0.46748468225099604}
2022-11-28 05:53:04,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:04,132 INFO:     Epoch: 91
2022-11-28 05:53:04,796 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.489802881736647, 'Total loss': 0.489802881736647} | train loss {'Reaction outcome loss': 0.4675710515100129, 'Total loss': 0.4675710515100129}
2022-11-28 05:53:04,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:04,796 INFO:     Epoch: 92
2022-11-28 05:53:05,459 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46794184839183633, 'Total loss': 0.46794184839183633} | train loss {'Reaction outcome loss': 0.46437660583427975, 'Total loss': 0.46437660583427975}
2022-11-28 05:53:05,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:05,460 INFO:     Epoch: 93
2022-11-28 05:53:06,119 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4943675314160911, 'Total loss': 0.4943675314160911} | train loss {'Reaction outcome loss': 0.47182577854516555, 'Total loss': 0.47182577854516555}
2022-11-28 05:53:06,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:06,120 INFO:     Epoch: 94
2022-11-28 05:53:06,782 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4941747649149461, 'Total loss': 0.4941747649149461} | train loss {'Reaction outcome loss': 0.4723966058419675, 'Total loss': 0.4723966058419675}
2022-11-28 05:53:06,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:06,783 INFO:     Epoch: 95
2022-11-28 05:53:07,444 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5037446611306884, 'Total loss': 0.5037446611306884} | train loss {'Reaction outcome loss': 0.4683491964729465, 'Total loss': 0.4683491964729465}
2022-11-28 05:53:07,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:07,444 INFO:     Epoch: 96
2022-11-28 05:53:08,102 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48635689981959085, 'Total loss': 0.48635689981959085} | train loss {'Reaction outcome loss': 0.4681384492893608, 'Total loss': 0.4681384492893608}
2022-11-28 05:53:08,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:08,102 INFO:     Epoch: 97
2022-11-28 05:53:08,765 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4843447072939439, 'Total loss': 0.4843447072939439} | train loss {'Reaction outcome loss': 0.46514697847317676, 'Total loss': 0.46514697847317676}
2022-11-28 05:53:08,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:08,766 INFO:     Epoch: 98
2022-11-28 05:53:09,426 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5095441566610878, 'Total loss': 0.5095441566610878} | train loss {'Reaction outcome loss': 0.47319070781980244, 'Total loss': 0.47319070781980244}
2022-11-28 05:53:09,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:09,426 INFO:     Epoch: 99
2022-11-28 05:53:10,085 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5063262895088304, 'Total loss': 0.5063262895088304} | train loss {'Reaction outcome loss': 0.4724073067003367, 'Total loss': 0.4724073067003367}
2022-11-28 05:53:10,085 INFO:     Best model found after epoch 45 of 100.
2022-11-28 05:53:10,085 INFO:   Done with stage: TRAINING
2022-11-28 05:53:10,085 INFO:   Starting stage: EVALUATION
2022-11-28 05:53:10,210 INFO:   Done with stage: EVALUATION
2022-11-28 05:53:10,210 INFO:   Leaving out SEQ value Fold_2
2022-11-28 05:53:10,223 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 05:53:10,223 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:53:10,863 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:53:10,863 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:53:10,932 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:53:10,932 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:53:10,932 INFO:     No hyperparam tuning for this model
2022-11-28 05:53:10,932 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:53:10,932 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:53:10,933 INFO:     None feature selector for col prot
2022-11-28 05:53:10,933 INFO:     None feature selector for col prot
2022-11-28 05:53:10,933 INFO:     None feature selector for col prot
2022-11-28 05:53:10,933 INFO:     None feature selector for col chem
2022-11-28 05:53:10,934 INFO:     None feature selector for col chem
2022-11-28 05:53:10,934 INFO:     None feature selector for col chem
2022-11-28 05:53:10,934 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:53:10,934 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:53:10,935 INFO:     Number of params in model 169651
2022-11-28 05:53:10,938 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:53:10,938 INFO:   Starting stage: TRAINING
2022-11-28 05:53:10,989 INFO:     Val loss before train {'Reaction outcome loss': 0.9678354138551757, 'Total loss': 0.9678354138551757}
2022-11-28 05:53:10,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:10,989 INFO:     Epoch: 0
2022-11-28 05:53:11,645 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5756811173849328, 'Total loss': 0.5756811173849328} | train loss {'Reaction outcome loss': 0.6984069029205158, 'Total loss': 0.6984069029205158}
2022-11-28 05:53:11,645 INFO:     Found new best model at epoch 0
2022-11-28 05:53:11,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:11,646 INFO:     Epoch: 1
2022-11-28 05:53:12,302 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5452779226524885, 'Total loss': 0.5452779226524885} | train loss {'Reaction outcome loss': 0.5815099367841345, 'Total loss': 0.5815099367841345}
2022-11-28 05:53:12,302 INFO:     Found new best model at epoch 1
2022-11-28 05:53:12,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:12,303 INFO:     Epoch: 2
2022-11-28 05:53:12,960 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5572264097457709, 'Total loss': 0.5572264097457709} | train loss {'Reaction outcome loss': 0.5514450916623483, 'Total loss': 0.5514450916623483}
2022-11-28 05:53:12,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:12,960 INFO:     Epoch: 3
2022-11-28 05:53:13,615 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5205081174539965, 'Total loss': 0.5205081174539965} | train loss {'Reaction outcome loss': 0.5412356090716651, 'Total loss': 0.5412356090716651}
2022-11-28 05:53:13,615 INFO:     Found new best model at epoch 3
2022-11-28 05:53:13,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:13,616 INFO:     Epoch: 4
2022-11-28 05:53:14,270 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5270192803338517, 'Total loss': 0.5270192803338517} | train loss {'Reaction outcome loss': 0.5253910781418691, 'Total loss': 0.5253910781418691}
2022-11-28 05:53:14,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:14,270 INFO:     Epoch: 5
2022-11-28 05:53:14,925 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5285343638686246, 'Total loss': 0.5285343638686246} | train loss {'Reaction outcome loss': 0.5220561332878519, 'Total loss': 0.5220561332878519}
2022-11-28 05:53:14,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:14,925 INFO:     Epoch: 6
2022-11-28 05:53:15,580 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5242844438830088, 'Total loss': 0.5242844438830088} | train loss {'Reaction outcome loss': 0.5158238544083033, 'Total loss': 0.5158238544083033}
2022-11-28 05:53:15,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:15,580 INFO:     Epoch: 7
2022-11-28 05:53:16,236 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49514930019545, 'Total loss': 0.49514930019545} | train loss {'Reaction outcome loss': 0.5089735347838675, 'Total loss': 0.5089735347838675}
2022-11-28 05:53:16,237 INFO:     Found new best model at epoch 7
2022-11-28 05:53:16,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:16,237 INFO:     Epoch: 8
2022-11-28 05:53:16,892 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5085885341084281, 'Total loss': 0.5085885341084281} | train loss {'Reaction outcome loss': 0.49962355685038645, 'Total loss': 0.49962355685038645}
2022-11-28 05:53:16,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:16,892 INFO:     Epoch: 9
2022-11-28 05:53:17,546 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5213237786015799, 'Total loss': 0.5213237786015799} | train loss {'Reaction outcome loss': 0.4961411954193819, 'Total loss': 0.4961411954193819}
2022-11-28 05:53:17,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:17,546 INFO:     Epoch: 10
2022-11-28 05:53:18,201 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5326774945092756, 'Total loss': 0.5326774945092756} | train loss {'Reaction outcome loss': 0.486058381981537, 'Total loss': 0.486058381981537}
2022-11-28 05:53:18,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:18,202 INFO:     Epoch: 11
2022-11-28 05:53:18,856 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.501246104406756, 'Total loss': 0.501246104406756} | train loss {'Reaction outcome loss': 0.49120355733349674, 'Total loss': 0.49120355733349674}
2022-11-28 05:53:18,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:18,857 INFO:     Epoch: 12
2022-11-28 05:53:19,516 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5204805354046267, 'Total loss': 0.5204805354046267} | train loss {'Reaction outcome loss': 0.48393947044845487, 'Total loss': 0.48393947044845487}
2022-11-28 05:53:19,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:19,517 INFO:     Epoch: 13
2022-11-28 05:53:20,174 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5087068406648414, 'Total loss': 0.5087068406648414} | train loss {'Reaction outcome loss': 0.48257743893954597, 'Total loss': 0.48257743893954597}
2022-11-28 05:53:20,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:20,174 INFO:     Epoch: 14
2022-11-28 05:53:20,828 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.486851557396179, 'Total loss': 0.486851557396179} | train loss {'Reaction outcome loss': 0.4851224340009885, 'Total loss': 0.4851224340009885}
2022-11-28 05:53:20,828 INFO:     Found new best model at epoch 14
2022-11-28 05:53:20,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:20,829 INFO:     Epoch: 15
2022-11-28 05:53:21,487 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5147067183671996, 'Total loss': 0.5147067183671996} | train loss {'Reaction outcome loss': 0.4809092192864809, 'Total loss': 0.4809092192864809}
2022-11-28 05:53:21,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:21,487 INFO:     Epoch: 16
2022-11-28 05:53:22,147 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5114412536454755, 'Total loss': 0.5114412536454755} | train loss {'Reaction outcome loss': 0.48399121613531815, 'Total loss': 0.48399121613531815}
2022-11-28 05:53:22,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:22,147 INFO:     Epoch: 17
2022-11-28 05:53:22,805 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4834555831066398, 'Total loss': 0.4834555831066398} | train loss {'Reaction outcome loss': 0.48454809277394756, 'Total loss': 0.48454809277394756}
2022-11-28 05:53:22,805 INFO:     Found new best model at epoch 17
2022-11-28 05:53:22,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:22,806 INFO:     Epoch: 18
2022-11-28 05:53:23,463 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4864280979300654, 'Total loss': 0.4864280979300654} | train loss {'Reaction outcome loss': 0.47513667286419475, 'Total loss': 0.47513667286419475}
2022-11-28 05:53:23,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:23,464 INFO:     Epoch: 19
2022-11-28 05:53:24,119 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5053003811559011, 'Total loss': 0.5053003811559011} | train loss {'Reaction outcome loss': 0.4814193231649086, 'Total loss': 0.4814193231649086}
2022-11-28 05:53:24,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:24,119 INFO:     Epoch: 20
2022-11-28 05:53:24,775 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5009898730488711, 'Total loss': 0.5009898730488711} | train loss {'Reaction outcome loss': 0.4798354133352882, 'Total loss': 0.4798354133352882}
2022-11-28 05:53:24,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:24,775 INFO:     Epoch: 21
2022-11-28 05:53:25,434 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49740728735923767, 'Total loss': 0.49740728735923767} | train loss {'Reaction outcome loss': 0.47539955371471704, 'Total loss': 0.47539955371471704}
2022-11-28 05:53:25,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:25,434 INFO:     Epoch: 22
2022-11-28 05:53:26,090 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5353665116221406, 'Total loss': 0.5353665116221406} | train loss {'Reaction outcome loss': 0.4809397258108757, 'Total loss': 0.4809397258108757}
2022-11-28 05:53:26,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:26,091 INFO:     Epoch: 23
2022-11-28 05:53:26,747 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4893252236205478, 'Total loss': 0.4893252236205478} | train loss {'Reaction outcome loss': 0.47360182364211706, 'Total loss': 0.47360182364211706}
2022-11-28 05:53:26,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:26,748 INFO:     Epoch: 24
2022-11-28 05:53:27,404 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5089174467463826, 'Total loss': 0.5089174467463826} | train loss {'Reaction outcome loss': 0.4781912019873252, 'Total loss': 0.4781912019873252}
2022-11-28 05:53:27,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:27,404 INFO:     Epoch: 25
2022-11-28 05:53:28,062 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47525168989979943, 'Total loss': 0.47525168989979943} | train loss {'Reaction outcome loss': 0.48283138895621064, 'Total loss': 0.48283138895621064}
2022-11-28 05:53:28,062 INFO:     Found new best model at epoch 25
2022-11-28 05:53:28,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:28,063 INFO:     Epoch: 26
2022-11-28 05:53:28,723 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5125660258670186, 'Total loss': 0.5125660258670186} | train loss {'Reaction outcome loss': 0.47356191228647704, 'Total loss': 0.47356191228647704}
2022-11-28 05:53:28,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:28,723 INFO:     Epoch: 27
2022-11-28 05:53:29,383 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49493275236251744, 'Total loss': 0.49493275236251744} | train loss {'Reaction outcome loss': 0.4731859641119105, 'Total loss': 0.4731859641119105}
2022-11-28 05:53:29,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:29,383 INFO:     Epoch: 28
2022-11-28 05:53:30,041 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5029761066963506, 'Total loss': 0.5029761066963506} | train loss {'Reaction outcome loss': 0.4765264622744967, 'Total loss': 0.4765264622744967}
2022-11-28 05:53:30,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:30,041 INFO:     Epoch: 29
2022-11-28 05:53:30,699 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5023787305798642, 'Total loss': 0.5023787305798642} | train loss {'Reaction outcome loss': 0.47758583675642485, 'Total loss': 0.47758583675642485}
2022-11-28 05:53:30,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:30,699 INFO:     Epoch: 30
2022-11-28 05:53:31,357 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5454982318157373, 'Total loss': 0.5454982318157373} | train loss {'Reaction outcome loss': 0.4752247888350584, 'Total loss': 0.4752247888350584}
2022-11-28 05:53:31,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:31,357 INFO:     Epoch: 31
2022-11-28 05:53:32,014 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5408985982107561, 'Total loss': 0.5408985982107561} | train loss {'Reaction outcome loss': 0.47761819187979226, 'Total loss': 0.47761819187979226}
2022-11-28 05:53:32,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:32,015 INFO:     Epoch: 32
2022-11-28 05:53:32,675 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49472395521263746, 'Total loss': 0.49472395521263746} | train loss {'Reaction outcome loss': 0.4722008198255398, 'Total loss': 0.4722008198255398}
2022-11-28 05:53:32,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:32,675 INFO:     Epoch: 33
2022-11-28 05:53:33,331 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4935045069040254, 'Total loss': 0.4935045069040254} | train loss {'Reaction outcome loss': 0.4756909947170586, 'Total loss': 0.4756909947170586}
2022-11-28 05:53:33,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:33,332 INFO:     Epoch: 34
2022-11-28 05:53:33,988 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47830205670622894, 'Total loss': 0.47830205670622894} | train loss {'Reaction outcome loss': 0.47190550751373417, 'Total loss': 0.47190550751373417}
2022-11-28 05:53:33,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:33,989 INFO:     Epoch: 35
2022-11-28 05:53:34,647 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4777222636134125, 'Total loss': 0.4777222636134125} | train loss {'Reaction outcome loss': 0.470961934291437, 'Total loss': 0.470961934291437}
2022-11-28 05:53:34,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:34,648 INFO:     Epoch: 36
2022-11-28 05:53:35,308 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47573464623717376, 'Total loss': 0.47573464623717376} | train loss {'Reaction outcome loss': 0.47393621895156923, 'Total loss': 0.47393621895156923}
2022-11-28 05:53:35,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:35,308 INFO:     Epoch: 37
2022-11-28 05:53:35,968 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5235914622628411, 'Total loss': 0.5235914622628411} | train loss {'Reaction outcome loss': 0.4700507768964181, 'Total loss': 0.4700507768964181}
2022-11-28 05:53:35,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:35,969 INFO:     Epoch: 38
2022-11-28 05:53:36,623 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4967460346429847, 'Total loss': 0.4967460346429847} | train loss {'Reaction outcome loss': 0.4743331623736952, 'Total loss': 0.4743331623736952}
2022-11-28 05:53:36,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:36,623 INFO:     Epoch: 39
2022-11-28 05:53:37,278 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4846960139829059, 'Total loss': 0.4846960139829059} | train loss {'Reaction outcome loss': 0.4760489386857533, 'Total loss': 0.4760489386857533}
2022-11-28 05:53:37,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:37,278 INFO:     Epoch: 40
2022-11-28 05:53:37,932 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47324871254521744, 'Total loss': 0.47324871254521744} | train loss {'Reaction outcome loss': 0.4739099527541243, 'Total loss': 0.4739099527541243}
2022-11-28 05:53:37,932 INFO:     Found new best model at epoch 40
2022-11-28 05:53:37,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:37,933 INFO:     Epoch: 41
2022-11-28 05:53:38,590 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4854881777319797, 'Total loss': 0.4854881777319797} | train loss {'Reaction outcome loss': 0.4681946379972286, 'Total loss': 0.4681946379972286}
2022-11-28 05:53:38,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:38,591 INFO:     Epoch: 42
2022-11-28 05:53:39,247 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4793587902257609, 'Total loss': 0.4793587902257609} | train loss {'Reaction outcome loss': 0.47241832896089947, 'Total loss': 0.47241832896089947}
2022-11-28 05:53:39,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:39,247 INFO:     Epoch: 43
2022-11-28 05:53:39,900 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49866011808084887, 'Total loss': 0.49866011808084887} | train loss {'Reaction outcome loss': 0.4690132118517258, 'Total loss': 0.4690132118517258}
2022-11-28 05:53:39,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:39,901 INFO:     Epoch: 44
2022-11-28 05:53:40,556 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.480727881193161, 'Total loss': 0.480727881193161} | train loss {'Reaction outcome loss': 0.4727093629905435, 'Total loss': 0.4727093629905435}
2022-11-28 05:53:40,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:40,556 INFO:     Epoch: 45
2022-11-28 05:53:41,214 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48454380624516064, 'Total loss': 0.48454380624516064} | train loss {'Reaction outcome loss': 0.46658806536407743, 'Total loss': 0.46658806536407743}
2022-11-28 05:53:41,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:41,214 INFO:     Epoch: 46
2022-11-28 05:53:41,870 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4852904140256172, 'Total loss': 0.4852904140256172} | train loss {'Reaction outcome loss': 0.47170923888439037, 'Total loss': 0.47170923888439037}
2022-11-28 05:53:41,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:41,871 INFO:     Epoch: 47
2022-11-28 05:53:42,527 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4863876793966737, 'Total loss': 0.4863876793966737} | train loss {'Reaction outcome loss': 0.4645104185052094, 'Total loss': 0.4645104185052094}
2022-11-28 05:53:42,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:42,527 INFO:     Epoch: 48
2022-11-28 05:53:43,183 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5001813589140426, 'Total loss': 0.5001813589140426} | train loss {'Reaction outcome loss': 0.46714015897424493, 'Total loss': 0.46714015897424493}
2022-11-28 05:53:43,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:43,183 INFO:     Epoch: 49
2022-11-28 05:53:43,839 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5075549632310867, 'Total loss': 0.5075549632310867} | train loss {'Reaction outcome loss': 0.4731730274001106, 'Total loss': 0.4731730274001106}
2022-11-28 05:53:43,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:43,839 INFO:     Epoch: 50
2022-11-28 05:53:44,493 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49282173604466195, 'Total loss': 0.49282173604466195} | train loss {'Reaction outcome loss': 0.46845856421917187, 'Total loss': 0.46845856421917187}
2022-11-28 05:53:44,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:44,493 INFO:     Epoch: 51
2022-11-28 05:53:45,149 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48924028873443604, 'Total loss': 0.48924028873443604} | train loss {'Reaction outcome loss': 0.4684819333621713, 'Total loss': 0.4684819333621713}
2022-11-28 05:53:45,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:45,150 INFO:     Epoch: 52
2022-11-28 05:53:45,808 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4926188182692195, 'Total loss': 0.4926188182692195} | train loss {'Reaction outcome loss': 0.4705394700047423, 'Total loss': 0.4705394700047423}
2022-11-28 05:53:45,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:45,808 INFO:     Epoch: 53
2022-11-28 05:53:46,473 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5128573518852855, 'Total loss': 0.5128573518852855} | train loss {'Reaction outcome loss': 0.4675811442745025, 'Total loss': 0.4675811442745025}
2022-11-28 05:53:46,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:46,474 INFO:     Epoch: 54
2022-11-28 05:53:47,129 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.475627658672111, 'Total loss': 0.475627658672111} | train loss {'Reaction outcome loss': 0.47008150333508114, 'Total loss': 0.47008150333508114}
2022-11-28 05:53:47,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:47,129 INFO:     Epoch: 55
2022-11-28 05:53:47,786 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49188660223816716, 'Total loss': 0.49188660223816716} | train loss {'Reaction outcome loss': 0.46117836536198364, 'Total loss': 0.46117836536198364}
2022-11-28 05:53:47,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:47,787 INFO:     Epoch: 56
2022-11-28 05:53:48,446 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48783581201420273, 'Total loss': 0.48783581201420273} | train loss {'Reaction outcome loss': 0.47032823291469794, 'Total loss': 0.47032823291469794}
2022-11-28 05:53:48,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:48,446 INFO:     Epoch: 57
2022-11-28 05:53:49,105 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.485445324071618, 'Total loss': 0.485445324071618} | train loss {'Reaction outcome loss': 0.4727678364295451, 'Total loss': 0.4727678364295451}
2022-11-28 05:53:49,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:49,105 INFO:     Epoch: 58
2022-11-28 05:53:49,765 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4720286678436191, 'Total loss': 0.4720286678436191} | train loss {'Reaction outcome loss': 0.47092287187449267, 'Total loss': 0.47092287187449267}
2022-11-28 05:53:49,766 INFO:     Found new best model at epoch 58
2022-11-28 05:53:49,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:49,766 INFO:     Epoch: 59
2022-11-28 05:53:50,423 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48820066313410915, 'Total loss': 0.48820066313410915} | train loss {'Reaction outcome loss': 0.46719786414846043, 'Total loss': 0.46719786414846043}
2022-11-28 05:53:50,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:50,424 INFO:     Epoch: 60
2022-11-28 05:53:51,081 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49059694104416424, 'Total loss': 0.49059694104416424} | train loss {'Reaction outcome loss': 0.47384757908885594, 'Total loss': 0.47384757908885594}
2022-11-28 05:53:51,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:51,082 INFO:     Epoch: 61
2022-11-28 05:53:51,737 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5060993277056273, 'Total loss': 0.5060993277056273} | train loss {'Reaction outcome loss': 0.46742673224357306, 'Total loss': 0.46742673224357306}
2022-11-28 05:53:51,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:51,737 INFO:     Epoch: 62
2022-11-28 05:53:52,392 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4952982040338738, 'Total loss': 0.4952982040338738} | train loss {'Reaction outcome loss': 0.46859405763813705, 'Total loss': 0.46859405763813705}
2022-11-28 05:53:52,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:52,393 INFO:     Epoch: 63
2022-11-28 05:53:53,048 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4904325801965802, 'Total loss': 0.4904325801965802} | train loss {'Reaction outcome loss': 0.47033716671046666, 'Total loss': 0.47033716671046666}
2022-11-28 05:53:53,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:53,048 INFO:     Epoch: 64
2022-11-28 05:53:53,706 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48048185227915297, 'Total loss': 0.48048185227915297} | train loss {'Reaction outcome loss': 0.47167793728533336, 'Total loss': 0.47167793728533336}
2022-11-28 05:53:53,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:53,707 INFO:     Epoch: 65
2022-11-28 05:53:54,364 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4793522070313609, 'Total loss': 0.4793522070313609} | train loss {'Reaction outcome loss': 0.47211464292934685, 'Total loss': 0.47211464292934685}
2022-11-28 05:53:54,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:54,365 INFO:     Epoch: 66
2022-11-28 05:53:55,023 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4865596495395483, 'Total loss': 0.4865596495395483} | train loss {'Reaction outcome loss': 0.46270441441018073, 'Total loss': 0.46270441441018073}
2022-11-28 05:53:55,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:55,023 INFO:     Epoch: 67
2022-11-28 05:53:55,681 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5133470879044644, 'Total loss': 0.5133470879044644} | train loss {'Reaction outcome loss': 0.46962752504671207, 'Total loss': 0.46962752504671207}
2022-11-28 05:53:55,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:55,681 INFO:     Epoch: 68
2022-11-28 05:53:56,337 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4998147647048152, 'Total loss': 0.4998147647048152} | train loss {'Reaction outcome loss': 0.47144033784260514, 'Total loss': 0.47144033784260514}
2022-11-28 05:53:56,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:56,337 INFO:     Epoch: 69
2022-11-28 05:53:56,994 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4688594486824302, 'Total loss': 0.4688594486824302} | train loss {'Reaction outcome loss': 0.46856583700683274, 'Total loss': 0.46856583700683274}
2022-11-28 05:53:56,995 INFO:     Found new best model at epoch 69
2022-11-28 05:53:56,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:56,995 INFO:     Epoch: 70
2022-11-28 05:53:57,657 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4650841812754786, 'Total loss': 0.4650841812754786} | train loss {'Reaction outcome loss': 0.4698717889727139, 'Total loss': 0.4698717889727139}
2022-11-28 05:53:57,658 INFO:     Found new best model at epoch 70
2022-11-28 05:53:57,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:57,659 INFO:     Epoch: 71
2022-11-28 05:53:58,314 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48840066651965297, 'Total loss': 0.48840066651965297} | train loss {'Reaction outcome loss': 0.46648598908156647, 'Total loss': 0.46648598908156647}
2022-11-28 05:53:58,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:58,314 INFO:     Epoch: 72
2022-11-28 05:53:58,970 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5063606171413909, 'Total loss': 0.5063606171413909} | train loss {'Reaction outcome loss': 0.4712879371936204, 'Total loss': 0.4712879371936204}
2022-11-28 05:53:58,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:58,970 INFO:     Epoch: 73
2022-11-28 05:53:59,624 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4827186369965243, 'Total loss': 0.4827186369965243} | train loss {'Reaction outcome loss': 0.4593205039740586, 'Total loss': 0.4593205039740586}
2022-11-28 05:53:59,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:53:59,625 INFO:     Epoch: 74
2022-11-28 05:54:00,277 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4955207781736241, 'Total loss': 0.4955207781736241} | train loss {'Reaction outcome loss': 0.4709043610902106, 'Total loss': 0.4709043610902106}
2022-11-28 05:54:00,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:00,277 INFO:     Epoch: 75
2022-11-28 05:54:00,934 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48499356972616775, 'Total loss': 0.48499356972616775} | train loss {'Reaction outcome loss': 0.46274100073048324, 'Total loss': 0.46274100073048324}
2022-11-28 05:54:00,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:00,934 INFO:     Epoch: 76
2022-11-28 05:54:01,593 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5085224990927896, 'Total loss': 0.5085224990927896} | train loss {'Reaction outcome loss': 0.4652527402170369, 'Total loss': 0.4652527402170369}
2022-11-28 05:54:01,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:01,593 INFO:     Epoch: 77
2022-11-28 05:54:02,249 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5188440077526625, 'Total loss': 0.5188440077526625} | train loss {'Reaction outcome loss': 0.47414748840888993, 'Total loss': 0.47414748840888993}
2022-11-28 05:54:02,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:02,250 INFO:     Epoch: 78
2022-11-28 05:54:02,907 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49914542810861456, 'Total loss': 0.49914542810861456} | train loss {'Reaction outcome loss': 0.4684001840040332, 'Total loss': 0.4684001840040332}
2022-11-28 05:54:02,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:02,907 INFO:     Epoch: 79
2022-11-28 05:54:03,563 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49601043483545615, 'Total loss': 0.49601043483545615} | train loss {'Reaction outcome loss': 0.4691190044166612, 'Total loss': 0.4691190044166612}
2022-11-28 05:54:03,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:03,563 INFO:     Epoch: 80
2022-11-28 05:54:04,216 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5020151526428932, 'Total loss': 0.5020151526428932} | train loss {'Reaction outcome loss': 0.4691178883257948, 'Total loss': 0.4691178883257948}
2022-11-28 05:54:04,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:04,216 INFO:     Epoch: 81
2022-11-28 05:54:04,873 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5007785846327626, 'Total loss': 0.5007785846327626} | train loss {'Reaction outcome loss': 0.47431684529683626, 'Total loss': 0.47431684529683626}
2022-11-28 05:54:04,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:04,874 INFO:     Epoch: 82
2022-11-28 05:54:05,532 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5019849467762681, 'Total loss': 0.5019849467762681} | train loss {'Reaction outcome loss': 0.46125232739771, 'Total loss': 0.46125232739771}
2022-11-28 05:54:05,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:05,533 INFO:     Epoch: 83
2022-11-28 05:54:06,190 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4721146454644758, 'Total loss': 0.4721146454644758} | train loss {'Reaction outcome loss': 0.46621507565017606, 'Total loss': 0.46621507565017606}
2022-11-28 05:54:06,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:06,190 INFO:     Epoch: 84
2022-11-28 05:54:06,847 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47502946645714517, 'Total loss': 0.47502946645714517} | train loss {'Reaction outcome loss': 0.4670522851167155, 'Total loss': 0.4670522851167155}
2022-11-28 05:54:06,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:06,847 INFO:     Epoch: 85
2022-11-28 05:54:07,502 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4755537891110709, 'Total loss': 0.4755537891110709} | train loss {'Reaction outcome loss': 0.4644677770919487, 'Total loss': 0.4644677770919487}
2022-11-28 05:54:07,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:07,503 INFO:     Epoch: 86
2022-11-28 05:54:08,159 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.50131987416467, 'Total loss': 0.50131987416467} | train loss {'Reaction outcome loss': 0.47476920399998057, 'Total loss': 0.47476920399998057}
2022-11-28 05:54:08,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:08,159 INFO:     Epoch: 87
2022-11-28 05:54:08,814 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4999066417993501, 'Total loss': 0.4999066417993501} | train loss {'Reaction outcome loss': 0.4653980606159226, 'Total loss': 0.4653980606159226}
2022-11-28 05:54:08,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:08,815 INFO:     Epoch: 88
2022-11-28 05:54:09,474 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4777873768362888, 'Total loss': 0.4777873768362888} | train loss {'Reaction outcome loss': 0.47360077243847926, 'Total loss': 0.47360077243847926}
2022-11-28 05:54:09,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:09,474 INFO:     Epoch: 89
2022-11-28 05:54:10,130 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49460590509481206, 'Total loss': 0.49460590509481206} | train loss {'Reaction outcome loss': 0.4716918358548743, 'Total loss': 0.4716918358548743}
2022-11-28 05:54:10,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:10,131 INFO:     Epoch: 90
2022-11-28 05:54:10,788 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5183520892331767, 'Total loss': 0.5183520892331767} | train loss {'Reaction outcome loss': 0.4655524037289815, 'Total loss': 0.4655524037289815}
2022-11-28 05:54:10,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:10,788 INFO:     Epoch: 91
2022-11-28 05:54:11,447 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4960387411505677, 'Total loss': 0.4960387411505677} | train loss {'Reaction outcome loss': 0.4683588210676537, 'Total loss': 0.4683588210676537}
2022-11-28 05:54:11,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:11,447 INFO:     Epoch: 92
2022-11-28 05:54:12,105 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48611905269844585, 'Total loss': 0.48611905269844585} | train loss {'Reaction outcome loss': 0.46603476494306423, 'Total loss': 0.46603476494306423}
2022-11-28 05:54:12,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:12,105 INFO:     Epoch: 93
2022-11-28 05:54:12,763 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49036911233913066, 'Total loss': 0.49036911233913066} | train loss {'Reaction outcome loss': 0.4693166499377274, 'Total loss': 0.4693166499377274}
2022-11-28 05:54:12,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:12,763 INFO:     Epoch: 94
2022-11-28 05:54:13,422 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5025419156218685, 'Total loss': 0.5025419156218685} | train loss {'Reaction outcome loss': 0.4689325980353551, 'Total loss': 0.4689325980353551}
2022-11-28 05:54:13,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:13,422 INFO:     Epoch: 95
2022-11-28 05:54:14,084 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49037176301313, 'Total loss': 0.49037176301313} | train loss {'Reaction outcome loss': 0.46627735059525144, 'Total loss': 0.46627735059525144}
2022-11-28 05:54:14,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:14,084 INFO:     Epoch: 96
2022-11-28 05:54:14,740 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5217054160528405, 'Total loss': 0.5217054160528405} | train loss {'Reaction outcome loss': 0.4666939047088877, 'Total loss': 0.4666939047088877}
2022-11-28 05:54:14,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:14,741 INFO:     Epoch: 97
2022-11-28 05:54:15,399 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48742571074602214, 'Total loss': 0.48742571074602214} | train loss {'Reaction outcome loss': 0.47239410492484685, 'Total loss': 0.47239410492484685}
2022-11-28 05:54:15,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:15,399 INFO:     Epoch: 98
2022-11-28 05:54:16,058 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49573268914638563, 'Total loss': 0.49573268914638563} | train loss {'Reaction outcome loss': 0.4654457664392034, 'Total loss': 0.4654457664392034}
2022-11-28 05:54:16,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:16,058 INFO:     Epoch: 99
2022-11-28 05:54:16,716 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49586136881695236, 'Total loss': 0.49586136881695236} | train loss {'Reaction outcome loss': 0.46333590510194417, 'Total loss': 0.46333590510194417}
2022-11-28 05:54:16,716 INFO:     Best model found after epoch 71 of 100.
2022-11-28 05:54:16,716 INFO:   Done with stage: TRAINING
2022-11-28 05:54:16,717 INFO:   Starting stage: EVALUATION
2022-11-28 05:54:16,846 INFO:   Done with stage: EVALUATION
2022-11-28 05:54:16,846 INFO:   Leaving out SEQ value Fold_3
2022-11-28 05:54:16,859 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 05:54:16,859 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:54:17,498 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:54:17,498 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:54:17,567 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:54:17,567 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:54:17,567 INFO:     No hyperparam tuning for this model
2022-11-28 05:54:17,567 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:54:17,567 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:54:17,568 INFO:     None feature selector for col prot
2022-11-28 05:54:17,568 INFO:     None feature selector for col prot
2022-11-28 05:54:17,568 INFO:     None feature selector for col prot
2022-11-28 05:54:17,569 INFO:     None feature selector for col chem
2022-11-28 05:54:17,569 INFO:     None feature selector for col chem
2022-11-28 05:54:17,569 INFO:     None feature selector for col chem
2022-11-28 05:54:17,569 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:54:17,569 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:54:17,570 INFO:     Number of params in model 169651
2022-11-28 05:54:17,574 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:54:17,574 INFO:   Starting stage: TRAINING
2022-11-28 05:54:17,625 INFO:     Val loss before train {'Reaction outcome loss': 1.0092245243316473, 'Total loss': 1.0092245243316473}
2022-11-28 05:54:17,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:17,625 INFO:     Epoch: 0
2022-11-28 05:54:18,286 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5666274456090705, 'Total loss': 0.5666274456090705} | train loss {'Reaction outcome loss': 0.6764912290162728, 'Total loss': 0.6764912290162728}
2022-11-28 05:54:18,286 INFO:     Found new best model at epoch 0
2022-11-28 05:54:18,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:18,287 INFO:     Epoch: 1
2022-11-28 05:54:18,944 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5424154747364133, 'Total loss': 0.5424154747364133} | train loss {'Reaction outcome loss': 0.5618041689034368, 'Total loss': 0.5618041689034368}
2022-11-28 05:54:18,944 INFO:     Found new best model at epoch 1
2022-11-28 05:54:18,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:18,944 INFO:     Epoch: 2
2022-11-28 05:54:19,600 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5337448161701823, 'Total loss': 0.5337448161701823} | train loss {'Reaction outcome loss': 0.5332781692630932, 'Total loss': 0.5332781692630932}
2022-11-28 05:54:19,600 INFO:     Found new best model at epoch 2
2022-11-28 05:54:19,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:19,600 INFO:     Epoch: 3
2022-11-28 05:54:20,256 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5016377568244934, 'Total loss': 0.5016377568244934} | train loss {'Reaction outcome loss': 0.517113127119717, 'Total loss': 0.517113127119717}
2022-11-28 05:54:20,256 INFO:     Found new best model at epoch 3
2022-11-28 05:54:20,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:20,257 INFO:     Epoch: 4
2022-11-28 05:54:20,913 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48209793415180474, 'Total loss': 0.48209793415180474} | train loss {'Reaction outcome loss': 0.5036601451088171, 'Total loss': 0.5036601451088171}
2022-11-28 05:54:20,913 INFO:     Found new best model at epoch 4
2022-11-28 05:54:20,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:20,914 INFO:     Epoch: 5
2022-11-28 05:54:21,569 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49949892333080603, 'Total loss': 0.49949892333080603} | train loss {'Reaction outcome loss': 0.49217778963387987, 'Total loss': 0.49217778963387987}
2022-11-28 05:54:21,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:21,570 INFO:     Epoch: 6
2022-11-28 05:54:22,226 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47206782462985014, 'Total loss': 0.47206782462985014} | train loss {'Reaction outcome loss': 0.48415758308084283, 'Total loss': 0.48415758308084283}
2022-11-28 05:54:22,227 INFO:     Found new best model at epoch 6
2022-11-28 05:54:22,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:22,227 INFO:     Epoch: 7
2022-11-28 05:54:22,884 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5070982055608616, 'Total loss': 0.5070982055608616} | train loss {'Reaction outcome loss': 0.4753057740506579, 'Total loss': 0.4753057740506579}
2022-11-28 05:54:22,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:22,884 INFO:     Epoch: 8
2022-11-28 05:54:23,543 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49837996238885923, 'Total loss': 0.49837996238885923} | train loss {'Reaction outcome loss': 0.47934038082107167, 'Total loss': 0.47934038082107167}
2022-11-28 05:54:23,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:23,543 INFO:     Epoch: 9
2022-11-28 05:54:24,202 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4759329855442047, 'Total loss': 0.4759329855442047} | train loss {'Reaction outcome loss': 0.4680130137283294, 'Total loss': 0.4680130137283294}
2022-11-28 05:54:24,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:24,203 INFO:     Epoch: 10
2022-11-28 05:54:24,861 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4731539799723514, 'Total loss': 0.4731539799723514} | train loss {'Reaction outcome loss': 0.4709175092885729, 'Total loss': 0.4709175092885729}
2022-11-28 05:54:24,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:24,862 INFO:     Epoch: 11
2022-11-28 05:54:25,520 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4519921943198803, 'Total loss': 0.4519921943198803} | train loss {'Reaction outcome loss': 0.46047516432819796, 'Total loss': 0.46047516432819796}
2022-11-28 05:54:25,521 INFO:     Found new best model at epoch 11
2022-11-28 05:54:25,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:25,521 INFO:     Epoch: 12
2022-11-28 05:54:26,175 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49103425304557, 'Total loss': 0.49103425304557} | train loss {'Reaction outcome loss': 0.4570748988294699, 'Total loss': 0.4570748988294699}
2022-11-28 05:54:26,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:26,175 INFO:     Epoch: 13
2022-11-28 05:54:26,828 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.470404825584833, 'Total loss': 0.470404825584833} | train loss {'Reaction outcome loss': 0.4615181583117266, 'Total loss': 0.4615181583117266}
2022-11-28 05:54:26,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:26,829 INFO:     Epoch: 14
2022-11-28 05:54:27,485 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4544876571311507, 'Total loss': 0.4544876571311507} | train loss {'Reaction outcome loss': 0.45694524880315435, 'Total loss': 0.45694524880315435}
2022-11-28 05:54:27,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:27,485 INFO:     Epoch: 15
2022-11-28 05:54:28,138 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48153206220892975, 'Total loss': 0.48153206220892975} | train loss {'Reaction outcome loss': 0.45449320043696734, 'Total loss': 0.45449320043696734}
2022-11-28 05:54:28,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:28,139 INFO:     Epoch: 16
2022-11-28 05:54:28,793 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4421311925316966, 'Total loss': 0.4421311925316966} | train loss {'Reaction outcome loss': 0.4496147404501184, 'Total loss': 0.4496147404501184}
2022-11-28 05:54:28,794 INFO:     Found new best model at epoch 16
2022-11-28 05:54:28,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:28,794 INFO:     Epoch: 17
2022-11-28 05:54:29,452 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48371489449988964, 'Total loss': 0.48371489449988964} | train loss {'Reaction outcome loss': 0.4498202115541599, 'Total loss': 0.4498202115541599}
2022-11-28 05:54:29,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:29,452 INFO:     Epoch: 18
2022-11-28 05:54:30,113 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4370570331811905, 'Total loss': 0.4370570331811905} | train loss {'Reaction outcome loss': 0.4568049761726231, 'Total loss': 0.4568049761726231}
2022-11-28 05:54:30,113 INFO:     Found new best model at epoch 18
2022-11-28 05:54:30,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:30,113 INFO:     Epoch: 19
2022-11-28 05:54:30,774 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4794654104598733, 'Total loss': 0.4794654104598733} | train loss {'Reaction outcome loss': 0.4454704105976175, 'Total loss': 0.4454704105976175}
2022-11-28 05:54:30,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:30,774 INFO:     Epoch: 20
2022-11-28 05:54:31,432 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4683688989905424, 'Total loss': 0.4683688989905424} | train loss {'Reaction outcome loss': 0.45251354562943097, 'Total loss': 0.45251354562943097}
2022-11-28 05:54:31,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:31,432 INFO:     Epoch: 21
2022-11-28 05:54:32,087 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4268671960331673, 'Total loss': 0.4268671960331673} | train loss {'Reaction outcome loss': 0.4507555063264292, 'Total loss': 0.4507555063264292}
2022-11-28 05:54:32,087 INFO:     Found new best model at epoch 21
2022-11-28 05:54:32,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:32,088 INFO:     Epoch: 22
2022-11-28 05:54:32,750 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47522059082984924, 'Total loss': 0.47522059082984924} | train loss {'Reaction outcome loss': 0.44468332103407776, 'Total loss': 0.44468332103407776}
2022-11-28 05:54:32,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:32,751 INFO:     Epoch: 23
2022-11-28 05:54:33,409 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46548733427080996, 'Total loss': 0.46548733427080996} | train loss {'Reaction outcome loss': 0.44375202053638757, 'Total loss': 0.44375202053638757}
2022-11-28 05:54:33,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:33,409 INFO:     Epoch: 24
2022-11-28 05:54:34,067 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43364955692790275, 'Total loss': 0.43364955692790275} | train loss {'Reaction outcome loss': 0.44556133006317694, 'Total loss': 0.44556133006317694}
2022-11-28 05:54:34,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:34,067 INFO:     Epoch: 25
2022-11-28 05:54:34,724 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4540234187314677, 'Total loss': 0.4540234187314677} | train loss {'Reaction outcome loss': 0.44178016569282186, 'Total loss': 0.44178016569282186}
2022-11-28 05:54:34,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:34,724 INFO:     Epoch: 26
2022-11-28 05:54:35,380 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4565743038127589, 'Total loss': 0.4565743038127589} | train loss {'Reaction outcome loss': 0.45344461580036116, 'Total loss': 0.45344461580036116}
2022-11-28 05:54:35,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:35,380 INFO:     Epoch: 27
2022-11-28 05:54:36,034 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4461111603088157, 'Total loss': 0.4461111603088157} | train loss {'Reaction outcome loss': 0.441658973022074, 'Total loss': 0.441658973022074}
2022-11-28 05:54:36,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:36,034 INFO:     Epoch: 28
2022-11-28 05:54:36,694 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4653613856712053, 'Total loss': 0.4653613856712053} | train loss {'Reaction outcome loss': 0.4350840877741575, 'Total loss': 0.4350840877741575}
2022-11-28 05:54:36,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:36,694 INFO:     Epoch: 29
2022-11-28 05:54:37,350 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4507362482159637, 'Total loss': 0.4507362482159637} | train loss {'Reaction outcome loss': 0.44603740604075254, 'Total loss': 0.44603740604075254}
2022-11-28 05:54:37,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:37,351 INFO:     Epoch: 30
2022-11-28 05:54:38,005 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48018473248149074, 'Total loss': 0.48018473248149074} | train loss {'Reaction outcome loss': 0.4465450562048154, 'Total loss': 0.4465450562048154}
2022-11-28 05:54:38,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:38,006 INFO:     Epoch: 31
2022-11-28 05:54:38,662 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4422986129688662, 'Total loss': 0.4422986129688662} | train loss {'Reaction outcome loss': 0.4457743563918305, 'Total loss': 0.4457743563918305}
2022-11-28 05:54:38,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:38,662 INFO:     Epoch: 32
2022-11-28 05:54:39,315 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47053145080111747, 'Total loss': 0.47053145080111747} | train loss {'Reaction outcome loss': 0.45527576850574525, 'Total loss': 0.45527576850574525}
2022-11-28 05:54:39,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:39,315 INFO:     Epoch: 33
2022-11-28 05:54:39,973 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44320099679536595, 'Total loss': 0.44320099679536595} | train loss {'Reaction outcome loss': 0.44401643632865345, 'Total loss': 0.44401643632865345}
2022-11-28 05:54:39,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:39,974 INFO:     Epoch: 34
2022-11-28 05:54:40,628 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4520160029100817, 'Total loss': 0.4520160029100817} | train loss {'Reaction outcome loss': 0.4455670877130794, 'Total loss': 0.4455670877130794}
2022-11-28 05:54:40,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:40,629 INFO:     Epoch: 35
2022-11-28 05:54:41,286 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4593491651291071, 'Total loss': 0.4593491651291071} | train loss {'Reaction outcome loss': 0.44642369180429176, 'Total loss': 0.44642369180429176}
2022-11-28 05:54:41,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:41,286 INFO:     Epoch: 36
2022-11-28 05:54:41,942 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47253710551317346, 'Total loss': 0.47253710551317346} | train loss {'Reaction outcome loss': 0.4418253578612062, 'Total loss': 0.4418253578612062}
2022-11-28 05:54:41,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:41,942 INFO:     Epoch: 37
2022-11-28 05:54:42,600 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44183993582115616, 'Total loss': 0.44183993582115616} | train loss {'Reaction outcome loss': 0.44625795657028916, 'Total loss': 0.44625795657028916}
2022-11-28 05:54:42,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:42,600 INFO:     Epoch: 38
2022-11-28 05:54:43,257 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4128768589607505, 'Total loss': 0.4128768589607505} | train loss {'Reaction outcome loss': 0.44880705561916356, 'Total loss': 0.44880705561916356}
2022-11-28 05:54:43,257 INFO:     Found new best model at epoch 38
2022-11-28 05:54:43,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:43,258 INFO:     Epoch: 39
2022-11-28 05:54:43,915 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4426464684480845, 'Total loss': 0.4426464684480845} | train loss {'Reaction outcome loss': 0.4411027429045224, 'Total loss': 0.4411027429045224}
2022-11-28 05:54:43,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:43,915 INFO:     Epoch: 40
2022-11-28 05:54:44,574 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4334278876005217, 'Total loss': 0.4334278876005217} | train loss {'Reaction outcome loss': 0.44498137409081223, 'Total loss': 0.44498137409081223}
2022-11-28 05:54:44,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:44,574 INFO:     Epoch: 41
2022-11-28 05:54:45,229 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.435603259607803, 'Total loss': 0.435603259607803} | train loss {'Reaction outcome loss': 0.44234466528306243, 'Total loss': 0.44234466528306243}
2022-11-28 05:54:45,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:45,229 INFO:     Epoch: 42
2022-11-28 05:54:45,885 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4578798018222631, 'Total loss': 0.4578798018222631} | train loss {'Reaction outcome loss': 0.4513852035046601, 'Total loss': 0.4513852035046601}
2022-11-28 05:54:45,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:45,885 INFO:     Epoch: 43
2022-11-28 05:54:46,548 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4554704781188521, 'Total loss': 0.4554704781188521} | train loss {'Reaction outcome loss': 0.4437754332836046, 'Total loss': 0.4437754332836046}
2022-11-28 05:54:46,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:46,548 INFO:     Epoch: 44
2022-11-28 05:54:47,205 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4341632484696632, 'Total loss': 0.4341632484696632} | train loss {'Reaction outcome loss': 0.4443909802519884, 'Total loss': 0.4443909802519884}
2022-11-28 05:54:47,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:47,206 INFO:     Epoch: 45
2022-11-28 05:54:47,867 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4413838369208713, 'Total loss': 0.4413838369208713} | train loss {'Reaction outcome loss': 0.4489363368417396, 'Total loss': 0.4489363368417396}
2022-11-28 05:54:47,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:47,867 INFO:     Epoch: 46
2022-11-28 05:54:48,523 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4468739777803421, 'Total loss': 0.4468739777803421} | train loss {'Reaction outcome loss': 0.4432462457506383, 'Total loss': 0.4432462457506383}
2022-11-28 05:54:48,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:48,524 INFO:     Epoch: 47
2022-11-28 05:54:49,178 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4548707697973695, 'Total loss': 0.4548707697973695} | train loss {'Reaction outcome loss': 0.44593261878509993, 'Total loss': 0.44593261878509993}
2022-11-28 05:54:49,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:49,179 INFO:     Epoch: 48
2022-11-28 05:54:49,839 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4372228165698606, 'Total loss': 0.4372228165698606} | train loss {'Reaction outcome loss': 0.44663814064420637, 'Total loss': 0.44663814064420637}
2022-11-28 05:54:49,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:49,839 INFO:     Epoch: 49
2022-11-28 05:54:50,496 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44510525984819543, 'Total loss': 0.44510525984819543} | train loss {'Reaction outcome loss': 0.4456529723877301, 'Total loss': 0.4456529723877301}
2022-11-28 05:54:50,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:50,497 INFO:     Epoch: 50
2022-11-28 05:54:51,154 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4413248633229455, 'Total loss': 0.4413248633229455} | train loss {'Reaction outcome loss': 0.44129760071757385, 'Total loss': 0.44129760071757385}
2022-11-28 05:54:51,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:51,154 INFO:     Epoch: 51
2022-11-28 05:54:51,812 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4456822289976963, 'Total loss': 0.4456822289976963} | train loss {'Reaction outcome loss': 0.44423906618087994, 'Total loss': 0.44423906618087994}
2022-11-28 05:54:51,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:51,812 INFO:     Epoch: 52
2022-11-28 05:54:52,470 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43685385896716006, 'Total loss': 0.43685385896716006} | train loss {'Reaction outcome loss': 0.4411684577887664, 'Total loss': 0.4411684577887664}
2022-11-28 05:54:52,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:52,470 INFO:     Epoch: 53
2022-11-28 05:54:53,125 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43832826995572377, 'Total loss': 0.43832826995572377} | train loss {'Reaction outcome loss': 0.4487121627345437, 'Total loss': 0.4487121627345437}
2022-11-28 05:54:53,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:53,126 INFO:     Epoch: 54
2022-11-28 05:54:53,785 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4554769597774328, 'Total loss': 0.4554769597774328} | train loss {'Reaction outcome loss': 0.4438612581398643, 'Total loss': 0.4438612581398643}
2022-11-28 05:54:53,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:53,786 INFO:     Epoch: 55
2022-11-28 05:54:54,440 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45441555006559503, 'Total loss': 0.45441555006559503} | train loss {'Reaction outcome loss': 0.4389678641054474, 'Total loss': 0.4389678641054474}
2022-11-28 05:54:54,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:54,440 INFO:     Epoch: 56
2022-11-28 05:54:55,097 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4768967372040416, 'Total loss': 0.4768967372040416} | train loss {'Reaction outcome loss': 0.44735638586590526, 'Total loss': 0.44735638586590526}
2022-11-28 05:54:55,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:55,097 INFO:     Epoch: 57
2022-11-28 05:54:55,755 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42278839821039244, 'Total loss': 0.42278839821039244} | train loss {'Reaction outcome loss': 0.44555186119968776, 'Total loss': 0.44555186119968776}
2022-11-28 05:54:55,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:55,755 INFO:     Epoch: 58
2022-11-28 05:54:56,412 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4357897271943647, 'Total loss': 0.4357897271943647} | train loss {'Reaction outcome loss': 0.4470330670353819, 'Total loss': 0.4470330670353819}
2022-11-28 05:54:56,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:56,412 INFO:     Epoch: 59
2022-11-28 05:54:57,071 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4305355895397275, 'Total loss': 0.4305355895397275} | train loss {'Reaction outcome loss': 0.4474882113396144, 'Total loss': 0.4474882113396144}
2022-11-28 05:54:57,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:57,071 INFO:     Epoch: 60
2022-11-28 05:54:57,728 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4397242152413657, 'Total loss': 0.4397242152413657} | train loss {'Reaction outcome loss': 0.4472112297156795, 'Total loss': 0.4472112297156795}
2022-11-28 05:54:57,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:57,729 INFO:     Epoch: 61
2022-11-28 05:54:58,386 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4233217859684035, 'Total loss': 0.4233217859684035} | train loss {'Reaction outcome loss': 0.4418488309764471, 'Total loss': 0.4418488309764471}
2022-11-28 05:54:58,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:58,386 INFO:     Epoch: 62
2022-11-28 05:54:59,042 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43299612298954365, 'Total loss': 0.43299612298954365} | train loss {'Reaction outcome loss': 0.4430979518372504, 'Total loss': 0.4430979518372504}
2022-11-28 05:54:59,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:59,042 INFO:     Epoch: 63
2022-11-28 05:54:59,698 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4464272472054459, 'Total loss': 0.4464272472054459} | train loss {'Reaction outcome loss': 0.44463072668333525, 'Total loss': 0.44463072668333525}
2022-11-28 05:54:59,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:54:59,699 INFO:     Epoch: 64
2022-11-28 05:55:00,356 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4580189939155135, 'Total loss': 0.4580189939155135} | train loss {'Reaction outcome loss': 0.44472681963052907, 'Total loss': 0.44472681963052907}
2022-11-28 05:55:00,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:00,357 INFO:     Epoch: 65
2022-11-28 05:55:01,019 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4423913127461145, 'Total loss': 0.4423913127461145} | train loss {'Reaction outcome loss': 0.4508491209173789, 'Total loss': 0.4508491209173789}
2022-11-28 05:55:01,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:01,019 INFO:     Epoch: 66
2022-11-28 05:55:01,678 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4487464074478593, 'Total loss': 0.4487464074478593} | train loss {'Reaction outcome loss': 0.441416829152674, 'Total loss': 0.441416829152674}
2022-11-28 05:55:01,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:01,678 INFO:     Epoch: 67
2022-11-28 05:55:02,334 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46962254061255343, 'Total loss': 0.46962254061255343} | train loss {'Reaction outcome loss': 0.441405247591558, 'Total loss': 0.441405247591558}
2022-11-28 05:55:02,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:02,335 INFO:     Epoch: 68
2022-11-28 05:55:02,991 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44098456827707067, 'Total loss': 0.44098456827707067} | train loss {'Reaction outcome loss': 0.4433790616019339, 'Total loss': 0.4433790616019339}
2022-11-28 05:55:02,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:02,992 INFO:     Epoch: 69
2022-11-28 05:55:03,645 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4422572068003721, 'Total loss': 0.4422572068003721} | train loss {'Reaction outcome loss': 0.44908896662661285, 'Total loss': 0.44908896662661285}
2022-11-28 05:55:03,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:03,646 INFO:     Epoch: 70
2022-11-28 05:55:04,300 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42517606359581617, 'Total loss': 0.42517606359581617} | train loss {'Reaction outcome loss': 0.4456618406855669, 'Total loss': 0.4456618406855669}
2022-11-28 05:55:04,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:04,301 INFO:     Epoch: 71
2022-11-28 05:55:04,951 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4612900451865307, 'Total loss': 0.4612900451865307} | train loss {'Reaction outcome loss': 0.4469837436421973, 'Total loss': 0.4469837436421973}
2022-11-28 05:55:04,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:04,951 INFO:     Epoch: 72
2022-11-28 05:55:05,606 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4346675976764324, 'Total loss': 0.4346675976764324} | train loss {'Reaction outcome loss': 0.4466190974487633, 'Total loss': 0.4466190974487633}
2022-11-28 05:55:05,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:05,606 INFO:     Epoch: 73
2022-11-28 05:55:06,260 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45005087450493214, 'Total loss': 0.45005087450493214} | train loss {'Reaction outcome loss': 0.4484704224789729, 'Total loss': 0.4484704224789729}
2022-11-28 05:55:06,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:06,260 INFO:     Epoch: 74
2022-11-28 05:55:06,911 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4383031452117964, 'Total loss': 0.4383031452117964} | train loss {'Reaction outcome loss': 0.44610059438425986, 'Total loss': 0.44610059438425986}
2022-11-28 05:55:06,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:06,911 INFO:     Epoch: 75
2022-11-28 05:55:07,564 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.440653053307256, 'Total loss': 0.440653053307256} | train loss {'Reaction outcome loss': 0.44286797836911485, 'Total loss': 0.44286797836911485}
2022-11-28 05:55:07,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:07,564 INFO:     Epoch: 76
2022-11-28 05:55:08,219 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4491925814817118, 'Total loss': 0.4491925814817118} | train loss {'Reaction outcome loss': 0.4433721023626992, 'Total loss': 0.4433721023626992}
2022-11-28 05:55:08,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:08,220 INFO:     Epoch: 77
2022-11-28 05:55:08,874 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4469415947448376, 'Total loss': 0.4469415947448376} | train loss {'Reaction outcome loss': 0.4454157058699209, 'Total loss': 0.4454157058699209}
2022-11-28 05:55:08,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:08,875 INFO:     Epoch: 78
2022-11-28 05:55:09,530 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4317438605912896, 'Total loss': 0.4317438605912896} | train loss {'Reaction outcome loss': 0.44250432072115725, 'Total loss': 0.44250432072115725}
2022-11-28 05:55:09,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:09,530 INFO:     Epoch: 79
2022-11-28 05:55:10,188 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4371067864257236, 'Total loss': 0.4371067864257236} | train loss {'Reaction outcome loss': 0.44404742604152103, 'Total loss': 0.44404742604152103}
2022-11-28 05:55:10,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:10,189 INFO:     Epoch: 80
2022-11-28 05:55:10,845 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4482036323048348, 'Total loss': 0.4482036323048348} | train loss {'Reaction outcome loss': 0.44698843341626104, 'Total loss': 0.44698843341626104}
2022-11-28 05:55:10,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:10,845 INFO:     Epoch: 81
2022-11-28 05:55:11,501 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43023312854212387, 'Total loss': 0.43023312854212387} | train loss {'Reaction outcome loss': 0.4438824611181607, 'Total loss': 0.4438824611181607}
2022-11-28 05:55:11,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:11,501 INFO:     Epoch: 82
2022-11-28 05:55:12,157 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44437280609164126, 'Total loss': 0.44437280609164126} | train loss {'Reaction outcome loss': 0.44574462988826097, 'Total loss': 0.44574462988826097}
2022-11-28 05:55:12,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:12,158 INFO:     Epoch: 83
2022-11-28 05:55:12,811 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42249380225359007, 'Total loss': 0.42249380225359007} | train loss {'Reaction outcome loss': 0.44770132683095387, 'Total loss': 0.44770132683095387}
2022-11-28 05:55:12,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:12,811 INFO:     Epoch: 84
2022-11-28 05:55:13,465 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4432355130827704, 'Total loss': 0.4432355130827704} | train loss {'Reaction outcome loss': 0.4387323866125013, 'Total loss': 0.4387323866125013}
2022-11-28 05:55:13,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:13,465 INFO:     Epoch: 85
2022-11-28 05:55:14,121 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41935703522244167, 'Total loss': 0.41935703522244167} | train loss {'Reaction outcome loss': 0.4527452150207074, 'Total loss': 0.4527452150207074}
2022-11-28 05:55:14,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:14,121 INFO:     Epoch: 86
2022-11-28 05:55:14,781 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43006231930366784, 'Total loss': 0.43006231930366784} | train loss {'Reaction outcome loss': 0.44462702484404454, 'Total loss': 0.44462702484404454}
2022-11-28 05:55:14,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:14,781 INFO:     Epoch: 87
2022-11-28 05:55:15,431 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4675351072882497, 'Total loss': 0.4675351072882497} | train loss {'Reaction outcome loss': 0.4413958941509978, 'Total loss': 0.4413958941509978}
2022-11-28 05:55:15,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:15,431 INFO:     Epoch: 88
2022-11-28 05:55:16,089 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4913994683775791, 'Total loss': 0.4913994683775791} | train loss {'Reaction outcome loss': 0.44156614971942587, 'Total loss': 0.44156614971942587}
2022-11-28 05:55:16,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:16,089 INFO:     Epoch: 89
2022-11-28 05:55:16,743 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45985504586336223, 'Total loss': 0.45985504586336223} | train loss {'Reaction outcome loss': 0.4475824688179571, 'Total loss': 0.4475824688179571}
2022-11-28 05:55:16,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:16,744 INFO:     Epoch: 90
2022-11-28 05:55:17,400 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4522599678399951, 'Total loss': 0.4522599678399951} | train loss {'Reaction outcome loss': 0.44724454199437236, 'Total loss': 0.44724454199437236}
2022-11-28 05:55:17,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:17,400 INFO:     Epoch: 91
2022-11-28 05:55:18,053 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4280203052384909, 'Total loss': 0.4280203052384909} | train loss {'Reaction outcome loss': 0.44224416354640583, 'Total loss': 0.44224416354640583}
2022-11-28 05:55:18,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:18,053 INFO:     Epoch: 92
2022-11-28 05:55:18,707 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43631485537734144, 'Total loss': 0.43631485537734144} | train loss {'Reaction outcome loss': 0.4492586434620326, 'Total loss': 0.4492586434620326}
2022-11-28 05:55:18,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:18,707 INFO:     Epoch: 93
2022-11-28 05:55:19,359 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43675456490627557, 'Total loss': 0.43675456490627557} | train loss {'Reaction outcome loss': 0.44547098478088615, 'Total loss': 0.44547098478088615}
2022-11-28 05:55:19,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:19,359 INFO:     Epoch: 94
2022-11-28 05:55:20,013 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4788605442573858, 'Total loss': 0.4788605442573858} | train loss {'Reaction outcome loss': 0.4445991359315202, 'Total loss': 0.4445991359315202}
2022-11-28 05:55:20,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:20,013 INFO:     Epoch: 95
2022-11-28 05:55:20,664 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46352731384510215, 'Total loss': 0.46352731384510215} | train loss {'Reaction outcome loss': 0.4414282772445776, 'Total loss': 0.4414282772445776}
2022-11-28 05:55:20,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:20,664 INFO:     Epoch: 96
2022-11-28 05:55:21,318 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4356456128663795, 'Total loss': 0.4356456128663795} | train loss {'Reaction outcome loss': 0.4470865039429704, 'Total loss': 0.4470865039429704}
2022-11-28 05:55:21,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:21,318 INFO:     Epoch: 97
2022-11-28 05:55:21,970 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4551804058773573, 'Total loss': 0.4551804058773573} | train loss {'Reaction outcome loss': 0.4443663709842768, 'Total loss': 0.4443663709842768}
2022-11-28 05:55:21,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:21,971 INFO:     Epoch: 98
2022-11-28 05:55:22,623 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42821804156830146, 'Total loss': 0.42821804156830146} | train loss {'Reaction outcome loss': 0.44743829019001274, 'Total loss': 0.44743829019001274}
2022-11-28 05:55:22,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:22,624 INFO:     Epoch: 99
2022-11-28 05:55:23,272 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44557844483575154, 'Total loss': 0.44557844483575154} | train loss {'Reaction outcome loss': 0.4526779585380535, 'Total loss': 0.4526779585380535}
2022-11-28 05:55:23,272 INFO:     Best model found after epoch 39 of 100.
2022-11-28 05:55:23,273 INFO:   Done with stage: TRAINING
2022-11-28 05:55:23,273 INFO:   Starting stage: EVALUATION
2022-11-28 05:55:23,402 INFO:   Done with stage: EVALUATION
2022-11-28 05:55:23,402 INFO:   Leaving out SEQ value Fold_4
2022-11-28 05:55:23,415 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:55:23,415 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:55:24,062 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:55:24,063 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:55:24,132 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:55:24,132 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:55:24,132 INFO:     No hyperparam tuning for this model
2022-11-28 05:55:24,132 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:55:24,133 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:55:24,133 INFO:     None feature selector for col prot
2022-11-28 05:55:24,133 INFO:     None feature selector for col prot
2022-11-28 05:55:24,133 INFO:     None feature selector for col prot
2022-11-28 05:55:24,134 INFO:     None feature selector for col chem
2022-11-28 05:55:24,134 INFO:     None feature selector for col chem
2022-11-28 05:55:24,134 INFO:     None feature selector for col chem
2022-11-28 05:55:24,134 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:55:24,134 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:55:24,136 INFO:     Number of params in model 169651
2022-11-28 05:55:24,139 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:55:24,139 INFO:   Starting stage: TRAINING
2022-11-28 05:55:24,190 INFO:     Val loss before train {'Reaction outcome loss': 1.0062501389871945, 'Total loss': 1.0062501389871945}
2022-11-28 05:55:24,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:24,190 INFO:     Epoch: 0
2022-11-28 05:55:24,854 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5975664407014847, 'Total loss': 0.5975664407014847} | train loss {'Reaction outcome loss': 0.6827714878779191, 'Total loss': 0.6827714878779191}
2022-11-28 05:55:24,854 INFO:     Found new best model at epoch 0
2022-11-28 05:55:24,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:24,855 INFO:     Epoch: 1
2022-11-28 05:55:25,515 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5740799118172039, 'Total loss': 0.5740799118172039} | train loss {'Reaction outcome loss': 0.5778490638582843, 'Total loss': 0.5778490638582843}
2022-11-28 05:55:25,515 INFO:     Found new best model at epoch 1
2022-11-28 05:55:25,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:25,516 INFO:     Epoch: 2
2022-11-28 05:55:26,177 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.556295895441012, 'Total loss': 0.556295895441012} | train loss {'Reaction outcome loss': 0.5474800985713719, 'Total loss': 0.5474800985713719}
2022-11-28 05:55:26,177 INFO:     Found new best model at epoch 2
2022-11-28 05:55:26,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:26,178 INFO:     Epoch: 3
2022-11-28 05:55:26,839 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5358490964228456, 'Total loss': 0.5358490964228456} | train loss {'Reaction outcome loss': 0.5503409171876638, 'Total loss': 0.5503409171876638}
2022-11-28 05:55:26,840 INFO:     Found new best model at epoch 3
2022-11-28 05:55:26,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:26,840 INFO:     Epoch: 4
2022-11-28 05:55:27,501 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5441217239607464, 'Total loss': 0.5441217239607464} | train loss {'Reaction outcome loss': 0.5279086045770027, 'Total loss': 0.5279086045770027}
2022-11-28 05:55:27,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:27,501 INFO:     Epoch: 5
2022-11-28 05:55:28,162 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.53554986349561, 'Total loss': 0.53554986349561} | train loss {'Reaction outcome loss': 0.509777962034078, 'Total loss': 0.509777962034078}
2022-11-28 05:55:28,162 INFO:     Found new best model at epoch 5
2022-11-28 05:55:28,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:28,163 INFO:     Epoch: 6
2022-11-28 05:55:28,828 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5358041629872539, 'Total loss': 0.5358041629872539} | train loss {'Reaction outcome loss': 0.502419837754265, 'Total loss': 0.502419837754265}
2022-11-28 05:55:28,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:28,828 INFO:     Epoch: 7
2022-11-28 05:55:29,490 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5580574463714253, 'Total loss': 0.5580574463714253} | train loss {'Reaction outcome loss': 0.49856188296065157, 'Total loss': 0.49856188296065157}
2022-11-28 05:55:29,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:29,491 INFO:     Epoch: 8
2022-11-28 05:55:30,152 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5385380719195713, 'Total loss': 0.5385380719195713} | train loss {'Reaction outcome loss': 0.49297780564680754, 'Total loss': 0.49297780564680754}
2022-11-28 05:55:30,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:30,153 INFO:     Epoch: 9
2022-11-28 05:55:30,817 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5919976984574036, 'Total loss': 0.5919976984574036} | train loss {'Reaction outcome loss': 0.4884052881707064, 'Total loss': 0.4884052881707064}
2022-11-28 05:55:30,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:30,817 INFO:     Epoch: 10
2022-11-28 05:55:31,479 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5119026936590672, 'Total loss': 0.5119026936590672} | train loss {'Reaction outcome loss': 0.5082720142868367, 'Total loss': 0.5082720142868367}
2022-11-28 05:55:31,479 INFO:     Found new best model at epoch 10
2022-11-28 05:55:31,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:31,480 INFO:     Epoch: 11
2022-11-28 05:55:32,139 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.504311940209432, 'Total loss': 0.504311940209432} | train loss {'Reaction outcome loss': 0.4906417068682219, 'Total loss': 0.4906417068682219}
2022-11-28 05:55:32,140 INFO:     Found new best model at epoch 11
2022-11-28 05:55:32,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:32,140 INFO:     Epoch: 12
2022-11-28 05:55:32,803 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4976343675093217, 'Total loss': 0.4976343675093217} | train loss {'Reaction outcome loss': 0.47900921872511565, 'Total loss': 0.47900921872511565}
2022-11-28 05:55:32,803 INFO:     Found new best model at epoch 12
2022-11-28 05:55:32,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:32,804 INFO:     Epoch: 13
2022-11-28 05:55:33,463 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5619298493997618, 'Total loss': 0.5619298493997618} | train loss {'Reaction outcome loss': 0.47897850139903636, 'Total loss': 0.47897850139903636}
2022-11-28 05:55:33,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:33,463 INFO:     Epoch: 14
2022-11-28 05:55:34,127 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5377334945581176, 'Total loss': 0.5377334945581176} | train loss {'Reaction outcome loss': 0.48067427725203127, 'Total loss': 0.48067427725203127}
2022-11-28 05:55:34,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:34,127 INFO:     Epoch: 15
2022-11-28 05:55:34,789 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5178255933252248, 'Total loss': 0.5178255933252248} | train loss {'Reaction outcome loss': 0.49032327884747856, 'Total loss': 0.49032327884747856}
2022-11-28 05:55:34,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:34,789 INFO:     Epoch: 16
2022-11-28 05:55:35,449 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5235012322664261, 'Total loss': 0.5235012322664261} | train loss {'Reaction outcome loss': 0.4667854339246325, 'Total loss': 0.4667854339246325}
2022-11-28 05:55:35,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:35,449 INFO:     Epoch: 17
2022-11-28 05:55:36,109 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5093488510359417, 'Total loss': 0.5093488510359417} | train loss {'Reaction outcome loss': 0.4669178947127662, 'Total loss': 0.4669178947127662}
2022-11-28 05:55:36,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:36,110 INFO:     Epoch: 18
2022-11-28 05:55:36,770 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4946601153774695, 'Total loss': 0.4946601153774695} | train loss {'Reaction outcome loss': 0.4643919372003571, 'Total loss': 0.4643919372003571}
2022-11-28 05:55:36,770 INFO:     Found new best model at epoch 18
2022-11-28 05:55:36,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:36,771 INFO:     Epoch: 19
2022-11-28 05:55:37,430 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.507033705372702, 'Total loss': 0.507033705372702} | train loss {'Reaction outcome loss': 0.4642303710325474, 'Total loss': 0.4642303710325474}
2022-11-28 05:55:37,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:37,431 INFO:     Epoch: 20
2022-11-28 05:55:38,089 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5483661100945689, 'Total loss': 0.5483661100945689} | train loss {'Reaction outcome loss': 0.4640059080201122, 'Total loss': 0.4640059080201122}
2022-11-28 05:55:38,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:38,089 INFO:     Epoch: 21
2022-11-28 05:55:38,744 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48841527239842847, 'Total loss': 0.48841527239842847} | train loss {'Reaction outcome loss': 0.4686208938659444, 'Total loss': 0.4686208938659444}
2022-11-28 05:55:38,744 INFO:     Found new best model at epoch 21
2022-11-28 05:55:38,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:38,745 INFO:     Epoch: 22
2022-11-28 05:55:39,399 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4920844279906966, 'Total loss': 0.4920844279906966} | train loss {'Reaction outcome loss': 0.46693998498668676, 'Total loss': 0.46693998498668676}
2022-11-28 05:55:39,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:39,400 INFO:     Epoch: 23
2022-11-28 05:55:40,054 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4982581087811427, 'Total loss': 0.4982581087811427} | train loss {'Reaction outcome loss': 0.4603571868859805, 'Total loss': 0.4603571868859805}
2022-11-28 05:55:40,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:40,054 INFO:     Epoch: 24
2022-11-28 05:55:40,706 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5270269696008075, 'Total loss': 0.5270269696008075} | train loss {'Reaction outcome loss': 0.4640665438868905, 'Total loss': 0.4640665438868905}
2022-11-28 05:55:40,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:40,706 INFO:     Epoch: 25
2022-11-28 05:55:41,362 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49558713828975504, 'Total loss': 0.49558713828975504} | train loss {'Reaction outcome loss': 0.45973354695658936, 'Total loss': 0.45973354695658936}
2022-11-28 05:55:41,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:41,362 INFO:     Epoch: 26
2022-11-28 05:55:42,019 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49376747689463873, 'Total loss': 0.49376747689463873} | train loss {'Reaction outcome loss': 0.47322277079227, 'Total loss': 0.47322277079227}
2022-11-28 05:55:42,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:42,019 INFO:     Epoch: 27
2022-11-28 05:55:42,678 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4686587710272182, 'Total loss': 0.4686587710272182} | train loss {'Reaction outcome loss': 0.47241410866440064, 'Total loss': 0.47241410866440064}
2022-11-28 05:55:42,678 INFO:     Found new best model at epoch 27
2022-11-28 05:55:42,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:42,679 INFO:     Epoch: 28
2022-11-28 05:55:43,339 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5046177431941032, 'Total loss': 0.5046177431941032} | train loss {'Reaction outcome loss': 0.4699661997769043, 'Total loss': 0.4699661997769043}
2022-11-28 05:55:43,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:43,340 INFO:     Epoch: 29
2022-11-28 05:55:44,000 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5073395635594021, 'Total loss': 0.5073395635594021} | train loss {'Reaction outcome loss': 0.4717164381674909, 'Total loss': 0.4717164381674909}
2022-11-28 05:55:44,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:44,000 INFO:     Epoch: 30
2022-11-28 05:55:44,663 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.518456912853501, 'Total loss': 0.518456912853501} | train loss {'Reaction outcome loss': 0.48483989921658627, 'Total loss': 0.48483989921658627}
2022-11-28 05:55:44,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:44,663 INFO:     Epoch: 31
2022-11-28 05:55:45,325 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48010554841973563, 'Total loss': 0.48010554841973563} | train loss {'Reaction outcome loss': 0.4648826026964767, 'Total loss': 0.4648826026964767}
2022-11-28 05:55:45,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:45,325 INFO:     Epoch: 32
2022-11-28 05:55:45,995 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5170891095291484, 'Total loss': 0.5170891095291484} | train loss {'Reaction outcome loss': 0.4644646073883844, 'Total loss': 0.4644646073883844}
2022-11-28 05:55:45,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:45,995 INFO:     Epoch: 33
2022-11-28 05:55:46,661 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49706247313456103, 'Total loss': 0.49706247313456103} | train loss {'Reaction outcome loss': 0.4735449084989455, 'Total loss': 0.4735449084989455}
2022-11-28 05:55:46,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:46,661 INFO:     Epoch: 34
2022-11-28 05:55:47,332 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.484991598197005, 'Total loss': 0.484991598197005} | train loss {'Reaction outcome loss': 0.4629706640874869, 'Total loss': 0.4629706640874869}
2022-11-28 05:55:47,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:47,333 INFO:     Epoch: 35
2022-11-28 05:55:47,999 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4868960827589035, 'Total loss': 0.4868960827589035} | train loss {'Reaction outcome loss': 0.4638509548868728, 'Total loss': 0.4638509548868728}
2022-11-28 05:55:47,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:48,000 INFO:     Epoch: 36
2022-11-28 05:55:48,665 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5372131409292872, 'Total loss': 0.5372131409292872} | train loss {'Reaction outcome loss': 0.45870159958538254, 'Total loss': 0.45870159958538254}
2022-11-28 05:55:48,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:48,665 INFO:     Epoch: 37
2022-11-28 05:55:49,330 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5229923901232806, 'Total loss': 0.5229923901232806} | train loss {'Reaction outcome loss': 0.47474475494521834, 'Total loss': 0.47474475494521834}
2022-11-28 05:55:49,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:49,330 INFO:     Epoch: 38
2022-11-28 05:55:49,994 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5184537043625658, 'Total loss': 0.5184537043625658} | train loss {'Reaction outcome loss': 0.467382723529661, 'Total loss': 0.467382723529661}
2022-11-28 05:55:49,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:49,994 INFO:     Epoch: 39
2022-11-28 05:55:50,660 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4896899394013665, 'Total loss': 0.4896899394013665} | train loss {'Reaction outcome loss': 0.46801021532249837, 'Total loss': 0.46801021532249837}
2022-11-28 05:55:50,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:50,660 INFO:     Epoch: 40
2022-11-28 05:55:51,323 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4762339375235818, 'Total loss': 0.4762339375235818} | train loss {'Reaction outcome loss': 0.47453431073229324, 'Total loss': 0.47453431073229324}
2022-11-28 05:55:51,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:51,324 INFO:     Epoch: 41
2022-11-28 05:55:51,983 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5201034356247295, 'Total loss': 0.5201034356247295} | train loss {'Reaction outcome loss': 0.4683094329015929, 'Total loss': 0.4683094329015929}
2022-11-28 05:55:51,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:51,983 INFO:     Epoch: 42
2022-11-28 05:55:52,648 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48363539881326933, 'Total loss': 0.48363539881326933} | train loss {'Reaction outcome loss': 0.47695551897108796, 'Total loss': 0.47695551897108796}
2022-11-28 05:55:52,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:52,648 INFO:     Epoch: 43
2022-11-28 05:55:53,313 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5190625211054628, 'Total loss': 0.5190625211054628} | train loss {'Reaction outcome loss': 0.4736427289211316, 'Total loss': 0.4736427289211316}
2022-11-28 05:55:53,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:53,313 INFO:     Epoch: 44
2022-11-28 05:55:53,978 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5062369660220363, 'Total loss': 0.5062369660220363} | train loss {'Reaction outcome loss': 0.4675354222778367, 'Total loss': 0.4675354222778367}
2022-11-28 05:55:53,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:53,978 INFO:     Epoch: 45
2022-11-28 05:55:54,640 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49928597767244687, 'Total loss': 0.49928597767244687} | train loss {'Reaction outcome loss': 0.4705264214803333, 'Total loss': 0.4705264214803333}
2022-11-28 05:55:54,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:54,641 INFO:     Epoch: 46
2022-11-28 05:55:55,304 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5066606923937798, 'Total loss': 0.5066606923937798} | train loss {'Reaction outcome loss': 0.4631749127316571, 'Total loss': 0.4631749127316571}
2022-11-28 05:55:55,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:55,304 INFO:     Epoch: 47
2022-11-28 05:55:55,968 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5212479975413192, 'Total loss': 0.5212479975413192} | train loss {'Reaction outcome loss': 0.45776939342318756, 'Total loss': 0.45776939342318756}
2022-11-28 05:55:55,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:55,968 INFO:     Epoch: 48
2022-11-28 05:55:56,631 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.505506273697723, 'Total loss': 0.505506273697723} | train loss {'Reaction outcome loss': 0.45763722526641026, 'Total loss': 0.45763722526641026}
2022-11-28 05:55:56,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:56,631 INFO:     Epoch: 49
2022-11-28 05:55:57,293 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49441433494741266, 'Total loss': 0.49441433494741266} | train loss {'Reaction outcome loss': 0.4613957464815634, 'Total loss': 0.4613957464815634}
2022-11-28 05:55:57,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:57,294 INFO:     Epoch: 50
2022-11-28 05:55:57,957 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4958633909171278, 'Total loss': 0.4958633909171278} | train loss {'Reaction outcome loss': 0.4661583970432822, 'Total loss': 0.4661583970432822}
2022-11-28 05:55:57,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:57,957 INFO:     Epoch: 51
2022-11-28 05:55:58,623 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47779936817559326, 'Total loss': 0.47779936817559326} | train loss {'Reaction outcome loss': 0.4564611212030404, 'Total loss': 0.4564611212030404}
2022-11-28 05:55:58,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:58,624 INFO:     Epoch: 52
2022-11-28 05:55:59,290 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47568289190530777, 'Total loss': 0.47568289190530777} | train loss {'Reaction outcome loss': 0.4552508934367041, 'Total loss': 0.4552508934367041}
2022-11-28 05:55:59,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:59,290 INFO:     Epoch: 53
2022-11-28 05:55:59,958 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5104078067974611, 'Total loss': 0.5104078067974611} | train loss {'Reaction outcome loss': 0.4623098149895668, 'Total loss': 0.4623098149895668}
2022-11-28 05:55:59,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:55:59,958 INFO:     Epoch: 54
2022-11-28 05:56:00,622 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5136444301090457, 'Total loss': 0.5136444301090457} | train loss {'Reaction outcome loss': 0.4623629944889169, 'Total loss': 0.4623629944889169}
2022-11-28 05:56:00,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:00,622 INFO:     Epoch: 55
2022-11-28 05:56:01,288 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5697691935029897, 'Total loss': 0.5697691935029897} | train loss {'Reaction outcome loss': 0.46791116290005597, 'Total loss': 0.46791116290005597}
2022-11-28 05:56:01,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:01,289 INFO:     Epoch: 56
2022-11-28 05:56:01,955 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5134021429853006, 'Total loss': 0.5134021429853006} | train loss {'Reaction outcome loss': 0.45974087178224493, 'Total loss': 0.45974087178224493}
2022-11-28 05:56:01,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:01,955 INFO:     Epoch: 57
2022-11-28 05:56:02,624 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5117421224713326, 'Total loss': 0.5117421224713326} | train loss {'Reaction outcome loss': 0.4698869316322118, 'Total loss': 0.4698869316322118}
2022-11-28 05:56:02,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:02,624 INFO:     Epoch: 58
2022-11-28 05:56:03,292 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48108848658475006, 'Total loss': 0.48108848658475006} | train loss {'Reaction outcome loss': 0.45502251333100835, 'Total loss': 0.45502251333100835}
2022-11-28 05:56:03,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:03,292 INFO:     Epoch: 59
2022-11-28 05:56:03,960 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4962606369094415, 'Total loss': 0.4962606369094415} | train loss {'Reaction outcome loss': 0.46097829883639146, 'Total loss': 0.46097829883639146}
2022-11-28 05:56:03,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:03,960 INFO:     Epoch: 60
2022-11-28 05:56:04,625 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5230690288272771, 'Total loss': 0.5230690288272771} | train loss {'Reaction outcome loss': 0.4814590214476412, 'Total loss': 0.4814590214476412}
2022-11-28 05:56:04,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:04,625 INFO:     Epoch: 61
2022-11-28 05:56:05,293 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4958427223292264, 'Total loss': 0.4958427223292264} | train loss {'Reaction outcome loss': 0.46529905630750695, 'Total loss': 0.46529905630750695}
2022-11-28 05:56:05,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:05,293 INFO:     Epoch: 62
2022-11-28 05:56:05,961 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5495719388127327, 'Total loss': 0.5495719388127327} | train loss {'Reaction outcome loss': 0.4625468785584214, 'Total loss': 0.4625468785584214}
2022-11-28 05:56:05,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:05,961 INFO:     Epoch: 63
2022-11-28 05:56:06,631 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49221349270506337, 'Total loss': 0.49221349270506337} | train loss {'Reaction outcome loss': 0.4619956974256859, 'Total loss': 0.4619956974256859}
2022-11-28 05:56:06,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:06,631 INFO:     Epoch: 64
2022-11-28 05:56:07,299 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5473138270052996, 'Total loss': 0.5473138270052996} | train loss {'Reaction outcome loss': 0.4601293092193874, 'Total loss': 0.4601293092193874}
2022-11-28 05:56:07,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:07,299 INFO:     Epoch: 65
2022-11-28 05:56:07,963 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4834683356298642, 'Total loss': 0.4834683356298642} | train loss {'Reaction outcome loss': 0.47285851999091716, 'Total loss': 0.47285851999091716}
2022-11-28 05:56:07,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:07,963 INFO:     Epoch: 66
2022-11-28 05:56:08,628 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5005362101576545, 'Total loss': 0.5005362101576545} | train loss {'Reaction outcome loss': 0.46514807989526735, 'Total loss': 0.46514807989526735}
2022-11-28 05:56:08,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:08,629 INFO:     Epoch: 67
2022-11-28 05:56:09,291 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4957186217335137, 'Total loss': 0.4957186217335137} | train loss {'Reaction outcome loss': 0.4676390637451338, 'Total loss': 0.4676390637451338}
2022-11-28 05:56:09,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:09,291 INFO:     Epoch: 68
2022-11-28 05:56:09,952 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47758380425247277, 'Total loss': 0.47758380425247277} | train loss {'Reaction outcome loss': 0.4696742925446043, 'Total loss': 0.4696742925446043}
2022-11-28 05:56:09,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:09,953 INFO:     Epoch: 69
2022-11-28 05:56:10,620 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4908857010304928, 'Total loss': 0.4908857010304928} | train loss {'Reaction outcome loss': 0.4708602301746245, 'Total loss': 0.4708602301746245}
2022-11-28 05:56:10,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:10,621 INFO:     Epoch: 70
2022-11-28 05:56:11,287 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4633053906939246, 'Total loss': 0.4633053906939246} | train loss {'Reaction outcome loss': 0.4586200982271901, 'Total loss': 0.4586200982271901}
2022-11-28 05:56:11,287 INFO:     Found new best model at epoch 70
2022-11-28 05:56:11,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:11,287 INFO:     Epoch: 71
2022-11-28 05:56:11,954 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48749723962762137, 'Total loss': 0.48749723962762137} | train loss {'Reaction outcome loss': 0.46165459449233315, 'Total loss': 0.46165459449233315}
2022-11-28 05:56:11,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:11,954 INFO:     Epoch: 72
2022-11-28 05:56:12,618 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4745140305974267, 'Total loss': 0.4745140305974267} | train loss {'Reaction outcome loss': 0.45754993815910117, 'Total loss': 0.45754993815910117}
2022-11-28 05:56:12,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:12,618 INFO:     Epoch: 73
2022-11-28 05:56:13,287 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4834124273197217, 'Total loss': 0.4834124273197217} | train loss {'Reaction outcome loss': 0.4618100561352394, 'Total loss': 0.4618100561352394}
2022-11-28 05:56:13,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:13,288 INFO:     Epoch: 74
2022-11-28 05:56:13,967 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4919596940956332, 'Total loss': 0.4919596940956332} | train loss {'Reaction outcome loss': 0.4667523330462124, 'Total loss': 0.4667523330462124}
2022-11-28 05:56:13,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:13,968 INFO:     Epoch: 75
2022-11-28 05:56:14,648 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4905592927878553, 'Total loss': 0.4905592927878553} | train loss {'Reaction outcome loss': 0.46040527015803795, 'Total loss': 0.46040527015803795}
2022-11-28 05:56:14,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:14,648 INFO:     Epoch: 76
2022-11-28 05:56:15,332 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49799955636262894, 'Total loss': 0.49799955636262894} | train loss {'Reaction outcome loss': 0.46088852947540127, 'Total loss': 0.46088852947540127}
2022-11-28 05:56:15,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:15,332 INFO:     Epoch: 77
2022-11-28 05:56:16,012 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49779037792574277, 'Total loss': 0.49779037792574277} | train loss {'Reaction outcome loss': 0.4623023376532412, 'Total loss': 0.4623023376532412}
2022-11-28 05:56:16,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:16,013 INFO:     Epoch: 78
2022-11-28 05:56:16,692 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5541640675880692, 'Total loss': 0.5541640675880692} | train loss {'Reaction outcome loss': 0.4615245131315731, 'Total loss': 0.4615245131315731}
2022-11-28 05:56:16,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:16,693 INFO:     Epoch: 79
2022-11-28 05:56:17,373 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.545834098349918, 'Total loss': 0.545834098349918} | train loss {'Reaction outcome loss': 0.4674605934904593, 'Total loss': 0.4674605934904593}
2022-11-28 05:56:17,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:17,374 INFO:     Epoch: 80
2022-11-28 05:56:18,056 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5555108365687457, 'Total loss': 0.5555108365687457} | train loss {'Reaction outcome loss': 0.45874934212157603, 'Total loss': 0.45874934212157603}
2022-11-28 05:56:18,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:18,057 INFO:     Epoch: 81
2022-11-28 05:56:18,737 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4764588095925071, 'Total loss': 0.4764588095925071} | train loss {'Reaction outcome loss': 0.4681100426656514, 'Total loss': 0.4681100426656514}
2022-11-28 05:56:18,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:18,737 INFO:     Epoch: 82
2022-11-28 05:56:19,401 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5501902841708877, 'Total loss': 0.5501902841708877} | train loss {'Reaction outcome loss': 0.4714174038968105, 'Total loss': 0.4714174038968105}
2022-11-28 05:56:19,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:19,402 INFO:     Epoch: 83
2022-11-28 05:56:20,064 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49511776661331003, 'Total loss': 0.49511776661331003} | train loss {'Reaction outcome loss': 0.47314369189835753, 'Total loss': 0.47314369189835753}
2022-11-28 05:56:20,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:20,065 INFO:     Epoch: 84
2022-11-28 05:56:20,731 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4886432032693516, 'Total loss': 0.4886432032693516} | train loss {'Reaction outcome loss': 0.4554961498691003, 'Total loss': 0.4554961498691003}
2022-11-28 05:56:20,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:20,731 INFO:     Epoch: 85
2022-11-28 05:56:21,398 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49476172029972076, 'Total loss': 0.49476172029972076} | train loss {'Reaction outcome loss': 0.4688116205848663, 'Total loss': 0.4688116205848663}
2022-11-28 05:56:21,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:21,398 INFO:     Epoch: 86
2022-11-28 05:56:22,062 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49109896374019707, 'Total loss': 0.49109896374019707} | train loss {'Reaction outcome loss': 0.4608451213974219, 'Total loss': 0.4608451213974219}
2022-11-28 05:56:22,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:22,062 INFO:     Epoch: 87
2022-11-28 05:56:22,726 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47537908008830115, 'Total loss': 0.47537908008830115} | train loss {'Reaction outcome loss': 0.4632019516333244, 'Total loss': 0.4632019516333244}
2022-11-28 05:56:22,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:22,726 INFO:     Epoch: 88
2022-11-28 05:56:23,391 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5097750994292173, 'Total loss': 0.5097750994292173} | train loss {'Reaction outcome loss': 0.4666472751240016, 'Total loss': 0.4666472751240016}
2022-11-28 05:56:23,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:23,391 INFO:     Epoch: 89
2022-11-28 05:56:24,057 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48311170732433145, 'Total loss': 0.48311170732433145} | train loss {'Reaction outcome loss': 0.4659419098363714, 'Total loss': 0.4659419098363714}
2022-11-28 05:56:24,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:24,057 INFO:     Epoch: 90
2022-11-28 05:56:24,724 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48415099253708666, 'Total loss': 0.48415099253708666} | train loss {'Reaction outcome loss': 0.4663416032607739, 'Total loss': 0.4663416032607739}
2022-11-28 05:56:24,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:24,724 INFO:     Epoch: 91
2022-11-28 05:56:25,393 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.500611824406819, 'Total loss': 0.500611824406819} | train loss {'Reaction outcome loss': 0.47365671664717707, 'Total loss': 0.47365671664717707}
2022-11-28 05:56:25,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:25,393 INFO:     Epoch: 92
2022-11-28 05:56:26,063 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46962169117548247, 'Total loss': 0.46962169117548247} | train loss {'Reaction outcome loss': 0.46135929226875305, 'Total loss': 0.46135929226875305}
2022-11-28 05:56:26,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:26,064 INFO:     Epoch: 93
2022-11-28 05:56:26,729 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4840259094807235, 'Total loss': 0.4840259094807235} | train loss {'Reaction outcome loss': 0.464781460914052, 'Total loss': 0.464781460914052}
2022-11-28 05:56:26,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:26,729 INFO:     Epoch: 94
2022-11-28 05:56:27,395 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5024091377854347, 'Total loss': 0.5024091377854347} | train loss {'Reaction outcome loss': 0.4571966495108508, 'Total loss': 0.4571966495108508}
2022-11-28 05:56:27,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:27,395 INFO:     Epoch: 95
2022-11-28 05:56:28,062 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5025806562467054, 'Total loss': 0.5025806562467054} | train loss {'Reaction outcome loss': 0.4709921170342789, 'Total loss': 0.4709921170342789}
2022-11-28 05:56:28,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:28,062 INFO:     Epoch: 96
2022-11-28 05:56:28,729 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.507682051170956, 'Total loss': 0.507682051170956} | train loss {'Reaction outcome loss': 0.4654404566838191, 'Total loss': 0.4654404566838191}
2022-11-28 05:56:28,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:28,729 INFO:     Epoch: 97
2022-11-28 05:56:29,395 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4911643121052872, 'Total loss': 0.4911643121052872} | train loss {'Reaction outcome loss': 0.4695815266494598, 'Total loss': 0.4695815266494598}
2022-11-28 05:56:29,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:29,396 INFO:     Epoch: 98
2022-11-28 05:56:30,062 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47847715562040155, 'Total loss': 0.47847715562040155} | train loss {'Reaction outcome loss': 0.4641948164353969, 'Total loss': 0.4641948164353969}
2022-11-28 05:56:30,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:30,062 INFO:     Epoch: 99
2022-11-28 05:56:30,727 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5439318496395241, 'Total loss': 0.5439318496395241} | train loss {'Reaction outcome loss': 0.462181243262167, 'Total loss': 0.462181243262167}
2022-11-28 05:56:30,727 INFO:     Best model found after epoch 71 of 100.
2022-11-28 05:56:30,727 INFO:   Done with stage: TRAINING
2022-11-28 05:56:30,727 INFO:   Starting stage: EVALUATION
2022-11-28 05:56:30,846 INFO:   Done with stage: EVALUATION
2022-11-28 05:56:30,846 INFO:   Leaving out SEQ value Fold_5
2022-11-28 05:56:30,858 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:56:30,859 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:56:31,503 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:56:31,503 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:56:31,573 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:56:31,573 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:56:31,573 INFO:     No hyperparam tuning for this model
2022-11-28 05:56:31,574 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:56:31,574 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:56:31,574 INFO:     None feature selector for col prot
2022-11-28 05:56:31,574 INFO:     None feature selector for col prot
2022-11-28 05:56:31,575 INFO:     None feature selector for col prot
2022-11-28 05:56:31,575 INFO:     None feature selector for col chem
2022-11-28 05:56:31,575 INFO:     None feature selector for col chem
2022-11-28 05:56:31,575 INFO:     None feature selector for col chem
2022-11-28 05:56:31,575 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:56:31,575 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:56:31,577 INFO:     Number of params in model 169651
2022-11-28 05:56:31,580 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:56:31,580 INFO:   Starting stage: TRAINING
2022-11-28 05:56:31,631 INFO:     Val loss before train {'Reaction outcome loss': 1.0044350637630983, 'Total loss': 1.0044350637630983}
2022-11-28 05:56:31,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:31,632 INFO:     Epoch: 0
2022-11-28 05:56:32,295 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5629965351386503, 'Total loss': 0.5629965351386503} | train loss {'Reaction outcome loss': 0.6856882873289136, 'Total loss': 0.6856882873289136}
2022-11-28 05:56:32,296 INFO:     Found new best model at epoch 0
2022-11-28 05:56:32,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:32,297 INFO:     Epoch: 1
2022-11-28 05:56:32,965 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6254525448788296, 'Total loss': 0.6254525448788296} | train loss {'Reaction outcome loss': 0.5936694410648423, 'Total loss': 0.5936694410648423}
2022-11-28 05:56:32,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:32,965 INFO:     Epoch: 2
2022-11-28 05:56:33,634 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5444811711257155, 'Total loss': 0.5444811711257155} | train loss {'Reaction outcome loss': 0.5544223577756933, 'Total loss': 0.5544223577756933}
2022-11-28 05:56:33,634 INFO:     Found new best model at epoch 2
2022-11-28 05:56:33,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:33,635 INFO:     Epoch: 3
2022-11-28 05:56:34,300 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49154251915487374, 'Total loss': 0.49154251915487374} | train loss {'Reaction outcome loss': 0.5388854684738013, 'Total loss': 0.5388854684738013}
2022-11-28 05:56:34,300 INFO:     Found new best model at epoch 3
2022-11-28 05:56:34,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:34,301 INFO:     Epoch: 4
2022-11-28 05:56:34,966 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5524340522560206, 'Total loss': 0.5524340522560206} | train loss {'Reaction outcome loss': 0.5282181370927979, 'Total loss': 0.5282181370927979}
2022-11-28 05:56:34,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:34,967 INFO:     Epoch: 5
2022-11-28 05:56:35,631 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6109699938784946, 'Total loss': 0.6109699938784946} | train loss {'Reaction outcome loss': 0.522831018697395, 'Total loss': 0.522831018697395}
2022-11-28 05:56:35,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:35,631 INFO:     Epoch: 6
2022-11-28 05:56:36,295 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5399972911585461, 'Total loss': 0.5399972911585461} | train loss {'Reaction outcome loss': 0.523461658763982, 'Total loss': 0.523461658763982}
2022-11-28 05:56:36,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:36,295 INFO:     Epoch: 7
2022-11-28 05:56:36,959 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5120567249303515, 'Total loss': 0.5120567249303515} | train loss {'Reaction outcome loss': 0.5101714656661879, 'Total loss': 0.5101714656661879}
2022-11-28 05:56:36,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:36,959 INFO:     Epoch: 8
2022-11-28 05:56:37,622 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5001616450873289, 'Total loss': 0.5001616450873289} | train loss {'Reaction outcome loss': 0.5084323484887961, 'Total loss': 0.5084323484887961}
2022-11-28 05:56:37,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:37,622 INFO:     Epoch: 9
2022-11-28 05:56:38,288 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4683507115326144, 'Total loss': 0.4683507115326144} | train loss {'Reaction outcome loss': 0.4970925173567616, 'Total loss': 0.4970925173567616}
2022-11-28 05:56:38,288 INFO:     Found new best model at epoch 9
2022-11-28 05:56:38,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:38,289 INFO:     Epoch: 10
2022-11-28 05:56:38,955 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5030464347113263, 'Total loss': 0.5030464347113263} | train loss {'Reaction outcome loss': 0.49415785700897213, 'Total loss': 0.49415785700897213}
2022-11-28 05:56:38,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:38,955 INFO:     Epoch: 11
2022-11-28 05:56:39,622 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48430658131837845, 'Total loss': 0.48430658131837845} | train loss {'Reaction outcome loss': 0.484469174403652, 'Total loss': 0.484469174403652}
2022-11-28 05:56:39,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:39,622 INFO:     Epoch: 12
2022-11-28 05:56:40,287 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5013069232756441, 'Total loss': 0.5013069232756441} | train loss {'Reaction outcome loss': 0.4870611680784689, 'Total loss': 0.4870611680784689}
2022-11-28 05:56:40,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:40,287 INFO:     Epoch: 13
2022-11-28 05:56:40,947 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5233597169545564, 'Total loss': 0.5233597169545564} | train loss {'Reaction outcome loss': 0.4880581016723926, 'Total loss': 0.4880581016723926}
2022-11-28 05:56:40,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:40,947 INFO:     Epoch: 14
2022-11-28 05:56:41,610 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4800814291970296, 'Total loss': 0.4800814291970296} | train loss {'Reaction outcome loss': 0.48479788322077105, 'Total loss': 0.48479788322077105}
2022-11-28 05:56:41,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:41,611 INFO:     Epoch: 15
2022-11-28 05:56:42,275 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4846735203808004, 'Total loss': 0.4846735203808004} | train loss {'Reaction outcome loss': 0.4878986988835007, 'Total loss': 0.4878986988835007}
2022-11-28 05:56:42,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:42,276 INFO:     Epoch: 16
2022-11-28 05:56:42,941 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5736789087002928, 'Total loss': 0.5736789087002928} | train loss {'Reaction outcome loss': 0.4836911019767344, 'Total loss': 0.4836911019767344}
2022-11-28 05:56:42,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:42,941 INFO:     Epoch: 17
2022-11-28 05:56:43,607 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5460924550213597, 'Total loss': 0.5460924550213597} | train loss {'Reaction outcome loss': 0.4812809068423051, 'Total loss': 0.4812809068423051}
2022-11-28 05:56:43,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:43,607 INFO:     Epoch: 18
2022-11-28 05:56:44,273 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48854917965152045, 'Total loss': 0.48854917965152045} | train loss {'Reaction outcome loss': 0.47801764464752394, 'Total loss': 0.47801764464752394}
2022-11-28 05:56:44,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:44,273 INFO:     Epoch: 19
2022-11-28 05:56:44,941 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48375464806502516, 'Total loss': 0.48375464806502516} | train loss {'Reaction outcome loss': 0.4736217006679006, 'Total loss': 0.4736217006679006}
2022-11-28 05:56:44,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:44,946 INFO:     Epoch: 20
2022-11-28 05:56:45,609 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4651900248771364, 'Total loss': 0.4651900248771364} | train loss {'Reaction outcome loss': 0.47684867378429846, 'Total loss': 0.47684867378429846}
2022-11-28 05:56:45,610 INFO:     Found new best model at epoch 20
2022-11-28 05:56:45,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:45,610 INFO:     Epoch: 21
2022-11-28 05:56:46,278 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4493553919548338, 'Total loss': 0.4493553919548338} | train loss {'Reaction outcome loss': 0.46781498054985093, 'Total loss': 0.46781498054985093}
2022-11-28 05:56:46,278 INFO:     Found new best model at epoch 21
2022-11-28 05:56:46,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:46,279 INFO:     Epoch: 22
2022-11-28 05:56:46,940 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5886311009526253, 'Total loss': 0.5886311009526253} | train loss {'Reaction outcome loss': 0.47088480526619114, 'Total loss': 0.47088480526619114}
2022-11-28 05:56:46,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:46,940 INFO:     Epoch: 23
2022-11-28 05:56:47,603 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.460045726461844, 'Total loss': 0.460045726461844} | train loss {'Reaction outcome loss': 0.4747598227188896, 'Total loss': 0.4747598227188896}
2022-11-28 05:56:47,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:47,603 INFO:     Epoch: 24
2022-11-28 05:56:48,263 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45056088946082373, 'Total loss': 0.45056088946082373} | train loss {'Reaction outcome loss': 0.46114894360877, 'Total loss': 0.46114894360877}
2022-11-28 05:56:48,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:48,264 INFO:     Epoch: 25
2022-11-28 05:56:48,923 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5365591208365831, 'Total loss': 0.5365591208365831} | train loss {'Reaction outcome loss': 0.4670041765157993, 'Total loss': 0.4670041765157993}
2022-11-28 05:56:48,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:48,923 INFO:     Epoch: 26
2022-11-28 05:56:49,585 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45693558386780997, 'Total loss': 0.45693558386780997} | train loss {'Reaction outcome loss': 0.4853935627802181, 'Total loss': 0.4853935627802181}
2022-11-28 05:56:49,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:49,586 INFO:     Epoch: 27
2022-11-28 05:56:50,248 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45278676463799045, 'Total loss': 0.45278676463799045} | train loss {'Reaction outcome loss': 0.49197449619591477, 'Total loss': 0.49197449619591477}
2022-11-28 05:56:50,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:50,248 INFO:     Epoch: 28
2022-11-28 05:56:50,916 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48094915226101875, 'Total loss': 0.48094915226101875} | train loss {'Reaction outcome loss': 0.49518350008045614, 'Total loss': 0.49518350008045614}
2022-11-28 05:56:50,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:50,916 INFO:     Epoch: 29
2022-11-28 05:56:51,583 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46606379679658194, 'Total loss': 0.46606379679658194} | train loss {'Reaction outcome loss': 0.47438114895089434, 'Total loss': 0.47438114895089434}
2022-11-28 05:56:51,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:51,583 INFO:     Epoch: 30
2022-11-28 05:56:52,245 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48336355218833144, 'Total loss': 0.48336355218833144} | train loss {'Reaction outcome loss': 0.4642675096689448, 'Total loss': 0.4642675096689448}
2022-11-28 05:56:52,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:52,246 INFO:     Epoch: 31
2022-11-28 05:56:52,913 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4862333888357336, 'Total loss': 0.4862333888357336} | train loss {'Reaction outcome loss': 0.472956514860756, 'Total loss': 0.472956514860756}
2022-11-28 05:56:52,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:52,913 INFO:     Epoch: 32
2022-11-28 05:56:53,578 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44917621599002316, 'Total loss': 0.44917621599002316} | train loss {'Reaction outcome loss': 0.4639352749475101, 'Total loss': 0.4639352749475101}
2022-11-28 05:56:53,578 INFO:     Found new best model at epoch 32
2022-11-28 05:56:53,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:53,579 INFO:     Epoch: 33
2022-11-28 05:56:54,244 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4747875773093917, 'Total loss': 0.4747875773093917} | train loss {'Reaction outcome loss': 0.4595557465425387, 'Total loss': 0.4595557465425387}
2022-11-28 05:56:54,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:54,244 INFO:     Epoch: 34
2022-11-28 05:56:54,905 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47578938406976784, 'Total loss': 0.47578938406976784} | train loss {'Reaction outcome loss': 0.46456094092203054, 'Total loss': 0.46456094092203054}
2022-11-28 05:56:54,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:54,906 INFO:     Epoch: 35
2022-11-28 05:56:55,566 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5538743531162088, 'Total loss': 0.5538743531162088} | train loss {'Reaction outcome loss': 0.4682592051292238, 'Total loss': 0.4682592051292238}
2022-11-28 05:56:55,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:55,567 INFO:     Epoch: 36
2022-11-28 05:56:56,231 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.504806921902028, 'Total loss': 0.504806921902028} | train loss {'Reaction outcome loss': 0.46535115921304293, 'Total loss': 0.46535115921304293}
2022-11-28 05:56:56,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:56,231 INFO:     Epoch: 37
2022-11-28 05:56:56,897 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4666666351258755, 'Total loss': 0.4666666351258755} | train loss {'Reaction outcome loss': 0.474949139875439, 'Total loss': 0.474949139875439}
2022-11-28 05:56:56,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:56,898 INFO:     Epoch: 38
2022-11-28 05:56:57,564 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4654284600507129, 'Total loss': 0.4654284600507129} | train loss {'Reaction outcome loss': 0.4680604776631483, 'Total loss': 0.4680604776631483}
2022-11-28 05:56:57,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:57,564 INFO:     Epoch: 39
2022-11-28 05:56:58,229 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.478899438272823, 'Total loss': 0.478899438272823} | train loss {'Reaction outcome loss': 0.4675486999665677, 'Total loss': 0.4675486999665677}
2022-11-28 05:56:58,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:58,229 INFO:     Epoch: 40
2022-11-28 05:56:58,894 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45292551104318013, 'Total loss': 0.45292551104318013} | train loss {'Reaction outcome loss': 0.46105510853080134, 'Total loss': 0.46105510853080134}
2022-11-28 05:56:58,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:58,894 INFO:     Epoch: 41
2022-11-28 05:56:59,562 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47952922332015907, 'Total loss': 0.47952922332015907} | train loss {'Reaction outcome loss': 0.4670573610525865, 'Total loss': 0.4670573610525865}
2022-11-28 05:56:59,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:56:59,562 INFO:     Epoch: 42
2022-11-28 05:57:00,230 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45706233314492484, 'Total loss': 0.45706233314492484} | train loss {'Reaction outcome loss': 0.47324466252857855, 'Total loss': 0.47324466252857855}
2022-11-28 05:57:00,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:00,230 INFO:     Epoch: 43
2022-11-28 05:57:00,893 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45240500586276705, 'Total loss': 0.45240500586276705} | train loss {'Reaction outcome loss': 0.4597266035885946, 'Total loss': 0.4597266035885946}
2022-11-28 05:57:00,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:00,893 INFO:     Epoch: 44
2022-11-28 05:57:01,555 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4573365372012962, 'Total loss': 0.4573365372012962} | train loss {'Reaction outcome loss': 0.4637704246681229, 'Total loss': 0.4637704246681229}
2022-11-28 05:57:01,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:01,555 INFO:     Epoch: 45
2022-11-28 05:57:02,217 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47441392866047943, 'Total loss': 0.47441392866047943} | train loss {'Reaction outcome loss': 0.46163470917928073, 'Total loss': 0.46163470917928073}
2022-11-28 05:57:02,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:02,217 INFO:     Epoch: 46
2022-11-28 05:57:02,880 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48521404239264404, 'Total loss': 0.48521404239264404} | train loss {'Reaction outcome loss': 0.4582210302801599, 'Total loss': 0.4582210302801599}
2022-11-28 05:57:02,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:02,881 INFO:     Epoch: 47
2022-11-28 05:57:03,545 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47357052259824495, 'Total loss': 0.47357052259824495} | train loss {'Reaction outcome loss': 0.4590650147905475, 'Total loss': 0.4590650147905475}
2022-11-28 05:57:03,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:03,546 INFO:     Epoch: 48
2022-11-28 05:57:04,211 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47479595921256323, 'Total loss': 0.47479595921256323} | train loss {'Reaction outcome loss': 0.4564676489756416, 'Total loss': 0.4564676489756416}
2022-11-28 05:57:04,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:04,212 INFO:     Epoch: 49
2022-11-28 05:57:04,870 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4981385970657522, 'Total loss': 0.4981385970657522} | train loss {'Reaction outcome loss': 0.4685360701822559, 'Total loss': 0.4685360701822559}
2022-11-28 05:57:04,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:04,870 INFO:     Epoch: 50
2022-11-28 05:57:05,536 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45954113961620763, 'Total loss': 0.45954113961620763} | train loss {'Reaction outcome loss': 0.48422573591292145, 'Total loss': 0.48422573591292145}
2022-11-28 05:57:05,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:05,536 INFO:     Epoch: 51
2022-11-28 05:57:06,199 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4574732387607748, 'Total loss': 0.4574732387607748} | train loss {'Reaction outcome loss': 0.46399272942957037, 'Total loss': 0.46399272942957037}
2022-11-28 05:57:06,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:06,199 INFO:     Epoch: 52
2022-11-28 05:57:06,865 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49029175903309474, 'Total loss': 0.49029175903309474} | train loss {'Reaction outcome loss': 0.46450665774133043, 'Total loss': 0.46450665774133043}
2022-11-28 05:57:06,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:06,865 INFO:     Epoch: 53
2022-11-28 05:57:07,527 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.436057005754926, 'Total loss': 0.436057005754926} | train loss {'Reaction outcome loss': 0.4672296496055387, 'Total loss': 0.4672296496055387}
2022-11-28 05:57:07,527 INFO:     Found new best model at epoch 53
2022-11-28 05:57:07,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:07,528 INFO:     Epoch: 54
2022-11-28 05:57:08,190 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4571714018556205, 'Total loss': 0.4571714018556205} | train loss {'Reaction outcome loss': 0.4664897589307082, 'Total loss': 0.4664897589307082}
2022-11-28 05:57:08,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:08,190 INFO:     Epoch: 55
2022-11-28 05:57:08,855 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5060657391493971, 'Total loss': 0.5060657391493971} | train loss {'Reaction outcome loss': 0.454523630636303, 'Total loss': 0.454523630636303}
2022-11-28 05:57:08,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:08,855 INFO:     Epoch: 56
2022-11-28 05:57:09,519 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45735703578049486, 'Total loss': 0.45735703578049486} | train loss {'Reaction outcome loss': 0.46242359162945496, 'Total loss': 0.46242359162945496}
2022-11-28 05:57:09,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:09,519 INFO:     Epoch: 57
2022-11-28 05:57:10,185 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4401725578037175, 'Total loss': 0.4401725578037175} | train loss {'Reaction outcome loss': 0.4624601598934606, 'Total loss': 0.4624601598934606}
2022-11-28 05:57:10,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:10,185 INFO:     Epoch: 58
2022-11-28 05:57:10,849 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45371764491904865, 'Total loss': 0.45371764491904865} | train loss {'Reaction outcome loss': 0.4634902415239075, 'Total loss': 0.4634902415239075}
2022-11-28 05:57:10,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:10,849 INFO:     Epoch: 59
2022-11-28 05:57:11,516 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4519370530139316, 'Total loss': 0.4519370530139316} | train loss {'Reaction outcome loss': 0.4604154028873212, 'Total loss': 0.4604154028873212}
2022-11-28 05:57:11,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:11,517 INFO:     Epoch: 60
2022-11-28 05:57:12,180 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47587268901142205, 'Total loss': 0.47587268901142205} | train loss {'Reaction outcome loss': 0.46252245646015355, 'Total loss': 0.46252245646015355}
2022-11-28 05:57:12,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:12,181 INFO:     Epoch: 61
2022-11-28 05:57:12,845 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.463614456016909, 'Total loss': 0.463614456016909} | train loss {'Reaction outcome loss': 0.4645709537378765, 'Total loss': 0.4645709537378765}
2022-11-28 05:57:12,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:12,845 INFO:     Epoch: 62
2022-11-28 05:57:13,509 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46162916347384453, 'Total loss': 0.46162916347384453} | train loss {'Reaction outcome loss': 0.46640743984867206, 'Total loss': 0.46640743984867206}
2022-11-28 05:57:13,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:13,509 INFO:     Epoch: 63
2022-11-28 05:57:14,173 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5112146792764013, 'Total loss': 0.5112146792764013} | train loss {'Reaction outcome loss': 0.4592468625741449, 'Total loss': 0.4592468625741449}
2022-11-28 05:57:14,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:14,173 INFO:     Epoch: 64
2022-11-28 05:57:14,835 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4549729952758009, 'Total loss': 0.4549729952758009} | train loss {'Reaction outcome loss': 0.4671799401320924, 'Total loss': 0.4671799401320924}
2022-11-28 05:57:14,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:14,835 INFO:     Epoch: 65
2022-11-28 05:57:15,497 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5081140009517019, 'Total loss': 0.5081140009517019} | train loss {'Reaction outcome loss': 0.4627068588125561, 'Total loss': 0.4627068588125561}
2022-11-28 05:57:15,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:15,497 INFO:     Epoch: 66
2022-11-28 05:57:16,162 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45841599052602594, 'Total loss': 0.45841599052602594} | train loss {'Reaction outcome loss': 0.45798757319387634, 'Total loss': 0.45798757319387634}
2022-11-28 05:57:16,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:16,163 INFO:     Epoch: 67
2022-11-28 05:57:16,831 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45399602062322875, 'Total loss': 0.45399602062322875} | train loss {'Reaction outcome loss': 0.4622273730785258, 'Total loss': 0.4622273730785258}
2022-11-28 05:57:16,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:16,832 INFO:     Epoch: 68
2022-11-28 05:57:17,498 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5728586817329581, 'Total loss': 0.5728586817329581} | train loss {'Reaction outcome loss': 0.46288662933205305, 'Total loss': 0.46288662933205305}
2022-11-28 05:57:17,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:17,498 INFO:     Epoch: 69
2022-11-28 05:57:18,165 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4539592804556543, 'Total loss': 0.4539592804556543} | train loss {'Reaction outcome loss': 0.4542746310563464, 'Total loss': 0.4542746310563464}
2022-11-28 05:57:18,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:18,165 INFO:     Epoch: 70
2022-11-28 05:57:18,835 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45599175024438987, 'Total loss': 0.45599175024438987} | train loss {'Reaction outcome loss': 0.4550436622037096, 'Total loss': 0.4550436622037096}
2022-11-28 05:57:18,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:18,836 INFO:     Epoch: 71
2022-11-28 05:57:19,506 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5281288996338844, 'Total loss': 0.5281288996338844} | train loss {'Reaction outcome loss': 0.4641405178709069, 'Total loss': 0.4641405178709069}
2022-11-28 05:57:19,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:19,506 INFO:     Epoch: 72
2022-11-28 05:57:20,176 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4576472650197419, 'Total loss': 0.4576472650197419} | train loss {'Reaction outcome loss': 0.4739204190279308, 'Total loss': 0.4739204190279308}
2022-11-28 05:57:20,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:20,177 INFO:     Epoch: 73
2022-11-28 05:57:20,845 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4584253481165929, 'Total loss': 0.4584253481165929} | train loss {'Reaction outcome loss': 0.45788000873949847, 'Total loss': 0.45788000873949847}
2022-11-28 05:57:20,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:20,845 INFO:     Epoch: 74
2022-11-28 05:57:21,513 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47399290244687686, 'Total loss': 0.47399290244687686} | train loss {'Reaction outcome loss': 0.4616086733148543, 'Total loss': 0.4616086733148543}
2022-11-28 05:57:21,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:21,513 INFO:     Epoch: 75
2022-11-28 05:57:22,180 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4581333879720081, 'Total loss': 0.4581333879720081} | train loss {'Reaction outcome loss': 0.4550984127198154, 'Total loss': 0.4550984127198154}
2022-11-28 05:57:22,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:22,180 INFO:     Epoch: 76
2022-11-28 05:57:22,849 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4671781902963465, 'Total loss': 0.4671781902963465} | train loss {'Reaction outcome loss': 0.4646118974939049, 'Total loss': 0.4646118974939049}
2022-11-28 05:57:22,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:22,850 INFO:     Epoch: 77
2022-11-28 05:57:23,518 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44717148928479716, 'Total loss': 0.44717148928479716} | train loss {'Reaction outcome loss': 0.4562483695656182, 'Total loss': 0.4562483695656182}
2022-11-28 05:57:23,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:23,518 INFO:     Epoch: 78
2022-11-28 05:57:24,188 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46794506738131697, 'Total loss': 0.46794506738131697} | train loss {'Reaction outcome loss': 0.463213492863574, 'Total loss': 0.463213492863574}
2022-11-28 05:57:24,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:24,188 INFO:     Epoch: 79
2022-11-28 05:57:24,860 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.462242622605779, 'Total loss': 0.462242622605779} | train loss {'Reaction outcome loss': 0.4624118039361861, 'Total loss': 0.4624118039361861}
2022-11-28 05:57:24,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:24,860 INFO:     Epoch: 80
2022-11-28 05:57:25,529 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4839047007262707, 'Total loss': 0.4839047007262707} | train loss {'Reaction outcome loss': 0.46525248631774657, 'Total loss': 0.46525248631774657}
2022-11-28 05:57:25,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:25,530 INFO:     Epoch: 81
2022-11-28 05:57:26,197 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4724051325835965, 'Total loss': 0.4724051325835965} | train loss {'Reaction outcome loss': 0.4628623348428879, 'Total loss': 0.4628623348428879}
2022-11-28 05:57:26,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:26,197 INFO:     Epoch: 82
2022-11-28 05:57:26,864 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45736435368995776, 'Total loss': 0.45736435368995776} | train loss {'Reaction outcome loss': 0.46568717925172104, 'Total loss': 0.46568717925172104}
2022-11-28 05:57:26,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:26,865 INFO:     Epoch: 83
2022-11-28 05:57:27,532 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4431441348384727, 'Total loss': 0.4431441348384727} | train loss {'Reaction outcome loss': 0.4589503898402216, 'Total loss': 0.4589503898402216}
2022-11-28 05:57:27,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:27,534 INFO:     Epoch: 84
2022-11-28 05:57:28,203 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4458671080117876, 'Total loss': 0.4458671080117876} | train loss {'Reaction outcome loss': 0.4617000964851032, 'Total loss': 0.4617000964851032}
2022-11-28 05:57:28,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:28,203 INFO:     Epoch: 85
2022-11-28 05:57:28,872 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46878914772109553, 'Total loss': 0.46878914772109553} | train loss {'Reaction outcome loss': 0.45847783946556603, 'Total loss': 0.45847783946556603}
2022-11-28 05:57:28,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:28,872 INFO:     Epoch: 86
2022-11-28 05:57:29,540 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45235615359111264, 'Total loss': 0.45235615359111264} | train loss {'Reaction outcome loss': 0.4604083858279564, 'Total loss': 0.4604083858279564}
2022-11-28 05:57:29,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:29,540 INFO:     Epoch: 87
2022-11-28 05:57:30,208 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47453014281663025, 'Total loss': 0.47453014281663025} | train loss {'Reaction outcome loss': 0.46211912181333975, 'Total loss': 0.46211912181333975}
2022-11-28 05:57:30,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:30,209 INFO:     Epoch: 88
2022-11-28 05:57:30,883 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45590555159883067, 'Total loss': 0.45590555159883067} | train loss {'Reaction outcome loss': 0.463244519072023, 'Total loss': 0.463244519072023}
2022-11-28 05:57:30,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:30,883 INFO:     Epoch: 89
2022-11-28 05:57:31,557 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5669226429679177, 'Total loss': 0.5669226429679177} | train loss {'Reaction outcome loss': 0.4543423776020888, 'Total loss': 0.4543423776020888}
2022-11-28 05:57:31,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:31,557 INFO:     Epoch: 90
2022-11-28 05:57:32,226 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46764979003505275, 'Total loss': 0.46764979003505275} | train loss {'Reaction outcome loss': 0.47020579877531965, 'Total loss': 0.47020579877531965}
2022-11-28 05:57:32,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:32,226 INFO:     Epoch: 91
2022-11-28 05:57:32,895 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4663892960683866, 'Total loss': 0.4663892960683866} | train loss {'Reaction outcome loss': 0.4669037872118506, 'Total loss': 0.4669037872118506}
2022-11-28 05:57:32,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:32,896 INFO:     Epoch: 92
2022-11-28 05:57:33,568 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49146107922900806, 'Total loss': 0.49146107922900806} | train loss {'Reaction outcome loss': 0.46816505666686453, 'Total loss': 0.46816505666686453}
2022-11-28 05:57:33,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:33,569 INFO:     Epoch: 93
2022-11-28 05:57:34,240 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5506855936890299, 'Total loss': 0.5506855936890299} | train loss {'Reaction outcome loss': 0.4685160188298476, 'Total loss': 0.4685160188298476}
2022-11-28 05:57:34,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:34,240 INFO:     Epoch: 94
2022-11-28 05:57:34,908 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4678857766769149, 'Total loss': 0.4678857766769149} | train loss {'Reaction outcome loss': 0.46629980465902493, 'Total loss': 0.46629980465902493}
2022-11-28 05:57:34,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:34,908 INFO:     Epoch: 95
2022-11-28 05:57:35,578 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44604221054098825, 'Total loss': 0.44604221054098825} | train loss {'Reaction outcome loss': 0.4525624933211427, 'Total loss': 0.4525624933211427}
2022-11-28 05:57:35,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:35,579 INFO:     Epoch: 96
2022-11-28 05:57:36,244 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5372958752242002, 'Total loss': 0.5372958752242002} | train loss {'Reaction outcome loss': 0.4647088345245794, 'Total loss': 0.4647088345245794}
2022-11-28 05:57:36,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:36,244 INFO:     Epoch: 97
2022-11-28 05:57:36,913 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46531976759433746, 'Total loss': 0.46531976759433746} | train loss {'Reaction outcome loss': 0.4766802108254631, 'Total loss': 0.4766802108254631}
2022-11-28 05:57:36,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:36,914 INFO:     Epoch: 98
2022-11-28 05:57:37,580 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4749076928604733, 'Total loss': 0.4749076928604733} | train loss {'Reaction outcome loss': 0.4610079696537693, 'Total loss': 0.4610079696537693}
2022-11-28 05:57:37,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:37,580 INFO:     Epoch: 99
2022-11-28 05:57:38,252 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4771018749610944, 'Total loss': 0.4771018749610944} | train loss {'Reaction outcome loss': 0.46306730050740663, 'Total loss': 0.46306730050740663}
2022-11-28 05:57:38,252 INFO:     Best model found after epoch 54 of 100.
2022-11-28 05:57:38,252 INFO:   Done with stage: TRAINING
2022-11-28 05:57:38,253 INFO:   Starting stage: EVALUATION
2022-11-28 05:57:38,371 INFO:   Done with stage: EVALUATION
2022-11-28 05:57:38,372 INFO:   Leaving out SEQ value Fold_6
2022-11-28 05:57:38,384 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:57:38,384 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:57:39,036 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:57:39,036 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:57:39,106 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:57:39,106 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:57:39,106 INFO:     No hyperparam tuning for this model
2022-11-28 05:57:39,106 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:57:39,106 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:57:39,107 INFO:     None feature selector for col prot
2022-11-28 05:57:39,107 INFO:     None feature selector for col prot
2022-11-28 05:57:39,107 INFO:     None feature selector for col prot
2022-11-28 05:57:39,108 INFO:     None feature selector for col chem
2022-11-28 05:57:39,108 INFO:     None feature selector for col chem
2022-11-28 05:57:39,108 INFO:     None feature selector for col chem
2022-11-28 05:57:39,108 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:57:39,108 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:57:39,109 INFO:     Number of params in model 169651
2022-11-28 05:57:39,112 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:57:39,112 INFO:   Starting stage: TRAINING
2022-11-28 05:57:39,164 INFO:     Val loss before train {'Reaction outcome loss': 1.0296896127137272, 'Total loss': 1.0296896127137272}
2022-11-28 05:57:39,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:39,165 INFO:     Epoch: 0
2022-11-28 05:57:39,835 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7276631620797244, 'Total loss': 0.7276631620797244} | train loss {'Reaction outcome loss': 0.6872543573619858, 'Total loss': 0.6872543573619858}
2022-11-28 05:57:39,835 INFO:     Found new best model at epoch 0
2022-11-28 05:57:39,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:39,836 INFO:     Epoch: 1
2022-11-28 05:57:40,507 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5985585918480699, 'Total loss': 0.5985585918480699} | train loss {'Reaction outcome loss': 0.58473966234634, 'Total loss': 0.58473966234634}
2022-11-28 05:57:40,507 INFO:     Found new best model at epoch 1
2022-11-28 05:57:40,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:40,508 INFO:     Epoch: 2
2022-11-28 05:57:41,177 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6288846263831313, 'Total loss': 0.6288846263831313} | train loss {'Reaction outcome loss': 0.5545236921959347, 'Total loss': 0.5545236921959347}
2022-11-28 05:57:41,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:41,177 INFO:     Epoch: 3
2022-11-28 05:57:41,845 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6145166388966821, 'Total loss': 0.6145166388966821} | train loss {'Reaction outcome loss': 0.5410480830938585, 'Total loss': 0.5410480830938585}
2022-11-28 05:57:41,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:41,845 INFO:     Epoch: 4
2022-11-28 05:57:42,516 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6002430522983725, 'Total loss': 0.6002430522983725} | train loss {'Reaction outcome loss': 0.5325158534030761, 'Total loss': 0.5325158534030761}
2022-11-28 05:57:42,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:42,517 INFO:     Epoch: 5
2022-11-28 05:57:43,187 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.548140786588192, 'Total loss': 0.548140786588192} | train loss {'Reaction outcome loss': 0.5276963737823309, 'Total loss': 0.5276963737823309}
2022-11-28 05:57:43,187 INFO:     Found new best model at epoch 5
2022-11-28 05:57:43,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:43,188 INFO:     Epoch: 6
2022-11-28 05:57:43,858 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5287256359376691, 'Total loss': 0.5287256359376691} | train loss {'Reaction outcome loss': 0.5076423943523438, 'Total loss': 0.5076423943523438}
2022-11-28 05:57:43,858 INFO:     Found new best model at epoch 6
2022-11-28 05:57:43,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:43,859 INFO:     Epoch: 7
2022-11-28 05:57:44,528 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5238176943226294, 'Total loss': 0.5238176943226294} | train loss {'Reaction outcome loss': 0.5132877624503547, 'Total loss': 0.5132877624503547}
2022-11-28 05:57:44,528 INFO:     Found new best model at epoch 7
2022-11-28 05:57:44,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:44,529 INFO:     Epoch: 8
2022-11-28 05:57:45,202 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5126183625649322, 'Total loss': 0.5126183625649322} | train loss {'Reaction outcome loss': 0.5039246585820952, 'Total loss': 0.5039246585820952}
2022-11-28 05:57:45,203 INFO:     Found new best model at epoch 8
2022-11-28 05:57:45,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:45,203 INFO:     Epoch: 9
2022-11-28 05:57:45,875 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5135995898057114, 'Total loss': 0.5135995898057114} | train loss {'Reaction outcome loss': 0.49205447294779364, 'Total loss': 0.49205447294779364}
2022-11-28 05:57:45,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:45,879 INFO:     Epoch: 10
2022-11-28 05:57:46,549 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.507253235714002, 'Total loss': 0.507253235714002} | train loss {'Reaction outcome loss': 0.4890504202414905, 'Total loss': 0.4890504202414905}
2022-11-28 05:57:46,549 INFO:     Found new best model at epoch 10
2022-11-28 05:57:46,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:46,550 INFO:     Epoch: 11
2022-11-28 05:57:47,220 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5084484788504514, 'Total loss': 0.5084484788504514} | train loss {'Reaction outcome loss': 0.48695848954300724, 'Total loss': 0.48695848954300724}
2022-11-28 05:57:47,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:47,220 INFO:     Epoch: 12
2022-11-28 05:57:47,890 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5332700942050327, 'Total loss': 0.5332700942050327} | train loss {'Reaction outcome loss': 0.48919771149033503, 'Total loss': 0.48919771149033503}
2022-11-28 05:57:47,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:47,890 INFO:     Epoch: 13
2022-11-28 05:57:48,561 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4936913905495947, 'Total loss': 0.4936913905495947} | train loss {'Reaction outcome loss': 0.48689570470202354, 'Total loss': 0.48689570470202354}
2022-11-28 05:57:48,561 INFO:     Found new best model at epoch 13
2022-11-28 05:57:48,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:48,562 INFO:     Epoch: 14
2022-11-28 05:57:49,230 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5075534419579939, 'Total loss': 0.5075534419579939} | train loss {'Reaction outcome loss': 0.48222084776047736, 'Total loss': 0.48222084776047736}
2022-11-28 05:57:49,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:49,230 INFO:     Epoch: 15
2022-11-28 05:57:49,900 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5043251514434814, 'Total loss': 0.5043251514434814} | train loss {'Reaction outcome loss': 0.49015291413712886, 'Total loss': 0.49015291413712886}
2022-11-28 05:57:49,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:49,901 INFO:     Epoch: 16
2022-11-28 05:57:50,569 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4799638373607939, 'Total loss': 0.4799638373607939} | train loss {'Reaction outcome loss': 0.47767083509074104, 'Total loss': 0.47767083509074104}
2022-11-28 05:57:50,569 INFO:     Found new best model at epoch 16
2022-11-28 05:57:50,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:50,570 INFO:     Epoch: 17
2022-11-28 05:57:51,242 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5161561833863909, 'Total loss': 0.5161561833863909} | train loss {'Reaction outcome loss': 0.48180349648840004, 'Total loss': 0.48180349648840004}
2022-11-28 05:57:51,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:51,242 INFO:     Epoch: 18
2022-11-28 05:57:51,915 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5361930142072114, 'Total loss': 0.5361930142072114} | train loss {'Reaction outcome loss': 0.4689797658713595, 'Total loss': 0.4689797658713595}
2022-11-28 05:57:51,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:51,915 INFO:     Epoch: 19
2022-11-28 05:57:52,586 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5402902913364497, 'Total loss': 0.5402902913364497} | train loss {'Reaction outcome loss': 0.47255625239303034, 'Total loss': 0.47255625239303034}
2022-11-28 05:57:52,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:52,586 INFO:     Epoch: 20
2022-11-28 05:57:53,257 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5000720498236743, 'Total loss': 0.5000720498236743} | train loss {'Reaction outcome loss': 0.4743779004221001, 'Total loss': 0.4743779004221001}
2022-11-28 05:57:53,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:53,257 INFO:     Epoch: 21
2022-11-28 05:57:53,927 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5143643512644551, 'Total loss': 0.5143643512644551} | train loss {'Reaction outcome loss': 0.47006876946937654, 'Total loss': 0.47006876946937654}
2022-11-28 05:57:53,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:53,927 INFO:     Epoch: 22
2022-11-28 05:57:54,595 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.545490624891086, 'Total loss': 0.545490624891086} | train loss {'Reaction outcome loss': 0.475487289109057, 'Total loss': 0.475487289109057}
2022-11-28 05:57:54,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:54,595 INFO:     Epoch: 23
2022-11-28 05:57:55,263 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5146918208761648, 'Total loss': 0.5146918208761648} | train loss {'Reaction outcome loss': 0.47464081981489736, 'Total loss': 0.47464081981489736}
2022-11-28 05:57:55,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:55,264 INFO:     Epoch: 24
2022-11-28 05:57:55,934 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5227972716093063, 'Total loss': 0.5227972716093063} | train loss {'Reaction outcome loss': 0.4731586576709824, 'Total loss': 0.4731586576709824}
2022-11-28 05:57:55,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:55,934 INFO:     Epoch: 25
2022-11-28 05:57:56,604 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5500550351359628, 'Total loss': 0.5500550351359628} | train loss {'Reaction outcome loss': 0.47586065398589256, 'Total loss': 0.47586065398589256}
2022-11-28 05:57:56,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:56,604 INFO:     Epoch: 26
2022-11-28 05:57:57,272 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5258887416937135, 'Total loss': 0.5258887416937135} | train loss {'Reaction outcome loss': 0.4756220682494102, 'Total loss': 0.4756220682494102}
2022-11-28 05:57:57,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:57,273 INFO:     Epoch: 27
2022-11-28 05:57:57,942 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5059505894102834, 'Total loss': 0.5059505894102834} | train loss {'Reaction outcome loss': 0.4707882885010012, 'Total loss': 0.4707882885010012}
2022-11-28 05:57:57,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:57,943 INFO:     Epoch: 28
2022-11-28 05:57:58,616 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5008427317846905, 'Total loss': 0.5008427317846905} | train loss {'Reaction outcome loss': 0.463716990224296, 'Total loss': 0.463716990224296}
2022-11-28 05:57:58,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:58,617 INFO:     Epoch: 29
2022-11-28 05:57:59,291 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.502669822763313, 'Total loss': 0.502669822763313} | train loss {'Reaction outcome loss': 0.47541186531945584, 'Total loss': 0.47541186531945584}
2022-11-28 05:57:59,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:59,291 INFO:     Epoch: 30
2022-11-28 05:57:59,964 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.501198026266965, 'Total loss': 0.501198026266965} | train loss {'Reaction outcome loss': 0.4681345778367212, 'Total loss': 0.4681345778367212}
2022-11-28 05:57:59,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:57:59,964 INFO:     Epoch: 31
2022-11-28 05:58:00,639 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5390813221985643, 'Total loss': 0.5390813221985643} | train loss {'Reaction outcome loss': 0.47087920850683607, 'Total loss': 0.47087920850683607}
2022-11-28 05:58:00,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:00,639 INFO:     Epoch: 32
2022-11-28 05:58:01,310 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5156855644150213, 'Total loss': 0.5156855644150213} | train loss {'Reaction outcome loss': 0.46618867725614577, 'Total loss': 0.46618867725614577}
2022-11-28 05:58:01,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:01,310 INFO:     Epoch: 33
2022-11-28 05:58:01,980 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5300068780779839, 'Total loss': 0.5300068780779839} | train loss {'Reaction outcome loss': 0.47156344840843833, 'Total loss': 0.47156344840843833}
2022-11-28 05:58:01,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:01,981 INFO:     Epoch: 34
2022-11-28 05:58:02,656 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48717467385259544, 'Total loss': 0.48717467385259544} | train loss {'Reaction outcome loss': 0.46790194289097864, 'Total loss': 0.46790194289097864}
2022-11-28 05:58:02,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:02,656 INFO:     Epoch: 35
2022-11-28 05:58:03,325 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4926737157458609, 'Total loss': 0.4926737157458609} | train loss {'Reaction outcome loss': 0.47729803832067597, 'Total loss': 0.47729803832067597}
2022-11-28 05:58:03,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:03,326 INFO:     Epoch: 36
2022-11-28 05:58:03,998 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4861142113804817, 'Total loss': 0.4861142113804817} | train loss {'Reaction outcome loss': 0.46174348938849663, 'Total loss': 0.46174348938849663}
2022-11-28 05:58:03,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:03,998 INFO:     Epoch: 37
2022-11-28 05:58:04,673 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49425230073657905, 'Total loss': 0.49425230073657905} | train loss {'Reaction outcome loss': 0.4651464018970728, 'Total loss': 0.4651464018970728}
2022-11-28 05:58:04,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:04,674 INFO:     Epoch: 38
2022-11-28 05:58:05,348 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5201280611482534, 'Total loss': 0.5201280611482534} | train loss {'Reaction outcome loss': 0.469130534198015, 'Total loss': 0.469130534198015}
2022-11-28 05:58:05,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:05,348 INFO:     Epoch: 39
2022-11-28 05:58:06,023 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4977152388204228, 'Total loss': 0.4977152388204228} | train loss {'Reaction outcome loss': 0.46442624944592675, 'Total loss': 0.46442624944592675}
2022-11-28 05:58:06,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:06,024 INFO:     Epoch: 40
2022-11-28 05:58:06,698 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4943362721665339, 'Total loss': 0.4943362721665339} | train loss {'Reaction outcome loss': 0.4718710792761657, 'Total loss': 0.4718710792761657}
2022-11-28 05:58:06,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:06,698 INFO:     Epoch: 41
2022-11-28 05:58:07,374 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49962304397062823, 'Total loss': 0.49962304397062823} | train loss {'Reaction outcome loss': 0.457940497826184, 'Total loss': 0.457940497826184}
2022-11-28 05:58:07,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:07,374 INFO:     Epoch: 42
2022-11-28 05:58:08,044 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5013595470650629, 'Total loss': 0.5013595470650629} | train loss {'Reaction outcome loss': 0.46589551169064736, 'Total loss': 0.46589551169064736}
2022-11-28 05:58:08,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:08,044 INFO:     Epoch: 43
2022-11-28 05:58:08,716 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.51169949431311, 'Total loss': 0.51169949431311} | train loss {'Reaction outcome loss': 0.4622666436217485, 'Total loss': 0.4622666436217485}
2022-11-28 05:58:08,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:08,716 INFO:     Epoch: 44
2022-11-28 05:58:09,387 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48871075971560046, 'Total loss': 0.48871075971560046} | train loss {'Reaction outcome loss': 0.4682241419270154, 'Total loss': 0.4682241419270154}
2022-11-28 05:58:09,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:09,387 INFO:     Epoch: 45
2022-11-28 05:58:10,062 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48484431071714923, 'Total loss': 0.48484431071714923} | train loss {'Reaction outcome loss': 0.46458452573466685, 'Total loss': 0.46458452573466685}
2022-11-28 05:58:10,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:10,062 INFO:     Epoch: 46
2022-11-28 05:58:10,734 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49741611358794297, 'Total loss': 0.49741611358794297} | train loss {'Reaction outcome loss': 0.4588200496810098, 'Total loss': 0.4588200496810098}
2022-11-28 05:58:10,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:10,734 INFO:     Epoch: 47
2022-11-28 05:58:11,405 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.514542030678554, 'Total loss': 0.514542030678554} | train loss {'Reaction outcome loss': 0.4599303887976754, 'Total loss': 0.4599303887976754}
2022-11-28 05:58:11,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:11,405 INFO:     Epoch: 48
2022-11-28 05:58:12,076 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4865778610110283, 'Total loss': 0.4865778610110283} | train loss {'Reaction outcome loss': 0.46545314395259463, 'Total loss': 0.46545314395259463}
2022-11-28 05:58:12,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:12,077 INFO:     Epoch: 49
2022-11-28 05:58:12,747 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4979552169415084, 'Total loss': 0.4979552169415084} | train loss {'Reaction outcome loss': 0.46509477048511466, 'Total loss': 0.46509477048511466}
2022-11-28 05:58:12,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:12,747 INFO:     Epoch: 50
2022-11-28 05:58:13,415 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4687725762751969, 'Total loss': 0.4687725762751969} | train loss {'Reaction outcome loss': 0.463700560161904, 'Total loss': 0.463700560161904}
2022-11-28 05:58:13,415 INFO:     Found new best model at epoch 50
2022-11-28 05:58:13,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:13,416 INFO:     Epoch: 51
2022-11-28 05:58:14,079 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49612870202823117, 'Total loss': 0.49612870202823117} | train loss {'Reaction outcome loss': 0.45929650613857853, 'Total loss': 0.45929650613857853}
2022-11-28 05:58:14,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:14,080 INFO:     Epoch: 52
2022-11-28 05:58:14,748 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5175627121193842, 'Total loss': 0.5175627121193842} | train loss {'Reaction outcome loss': 0.46560447542898115, 'Total loss': 0.46560447542898115}
2022-11-28 05:58:14,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:14,748 INFO:     Epoch: 53
2022-11-28 05:58:15,417 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49414924904704094, 'Total loss': 0.49414924904704094} | train loss {'Reaction outcome loss': 0.46649751550848445, 'Total loss': 0.46649751550848445}
2022-11-28 05:58:15,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:15,417 INFO:     Epoch: 54
2022-11-28 05:58:16,085 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5162897861816667, 'Total loss': 0.5162897861816667} | train loss {'Reaction outcome loss': 0.47051763198068064, 'Total loss': 0.47051763198068064}
2022-11-28 05:58:16,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:16,085 INFO:     Epoch: 55
2022-11-28 05:58:16,752 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5086961601945487, 'Total loss': 0.5086961601945487} | train loss {'Reaction outcome loss': 0.46360164484189403, 'Total loss': 0.46360164484189403}
2022-11-28 05:58:16,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:16,753 INFO:     Epoch: 56
2022-11-28 05:58:17,422 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5228500108827244, 'Total loss': 0.5228500108827244} | train loss {'Reaction outcome loss': 0.46070517854945314, 'Total loss': 0.46070517854945314}
2022-11-28 05:58:17,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:17,422 INFO:     Epoch: 57
2022-11-28 05:58:18,090 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48755199733105575, 'Total loss': 0.48755199733105575} | train loss {'Reaction outcome loss': 0.46960936672985554, 'Total loss': 0.46960936672985554}
2022-11-28 05:58:18,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:18,091 INFO:     Epoch: 58
2022-11-28 05:58:18,757 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4992901652374051, 'Total loss': 0.4992901652374051} | train loss {'Reaction outcome loss': 0.4711478330915974, 'Total loss': 0.4711478330915974}
2022-11-28 05:58:18,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:18,758 INFO:     Epoch: 59
2022-11-28 05:58:19,424 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4995968396013433, 'Total loss': 0.4995968396013433} | train loss {'Reaction outcome loss': 0.47506759526027786, 'Total loss': 0.47506759526027786}
2022-11-28 05:58:19,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:19,425 INFO:     Epoch: 60
2022-11-28 05:58:20,092 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4871716153892604, 'Total loss': 0.4871716153892604} | train loss {'Reaction outcome loss': 0.4612010513702708, 'Total loss': 0.4612010513702708}
2022-11-28 05:58:20,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:20,092 INFO:     Epoch: 61
2022-11-28 05:58:20,757 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.493655322288925, 'Total loss': 0.493655322288925} | train loss {'Reaction outcome loss': 0.46869181919722785, 'Total loss': 0.46869181919722785}
2022-11-28 05:58:20,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:20,757 INFO:     Epoch: 62
2022-11-28 05:58:21,426 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4699076210910624, 'Total loss': 0.4699076210910624} | train loss {'Reaction outcome loss': 0.4685316996408566, 'Total loss': 0.4685316996408566}
2022-11-28 05:58:21,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:21,426 INFO:     Epoch: 63
2022-11-28 05:58:22,097 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5215080763128671, 'Total loss': 0.5215080763128671} | train loss {'Reaction outcome loss': 0.46693819719216517, 'Total loss': 0.46693819719216517}
2022-11-28 05:58:22,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:22,097 INFO:     Epoch: 64
2022-11-28 05:58:22,763 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4898746738379652, 'Total loss': 0.4898746738379652} | train loss {'Reaction outcome loss': 0.4621934159508636, 'Total loss': 0.4621934159508636}
2022-11-28 05:58:22,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:22,763 INFO:     Epoch: 65
2022-11-28 05:58:23,436 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48885293304920197, 'Total loss': 0.48885293304920197} | train loss {'Reaction outcome loss': 0.4576548516389824, 'Total loss': 0.4576548516389824}
2022-11-28 05:58:23,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:23,436 INFO:     Epoch: 66
2022-11-28 05:58:24,104 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5061027441512455, 'Total loss': 0.5061027441512455} | train loss {'Reaction outcome loss': 0.4644020246942678, 'Total loss': 0.4644020246942678}
2022-11-28 05:58:24,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:24,105 INFO:     Epoch: 67
2022-11-28 05:58:24,775 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49578486721624027, 'Total loss': 0.49578486721624027} | train loss {'Reaction outcome loss': 0.4671268011893957, 'Total loss': 0.4671268011893957}
2022-11-28 05:58:24,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:24,775 INFO:     Epoch: 68
2022-11-28 05:58:25,440 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5168875388123773, 'Total loss': 0.5168875388123773} | train loss {'Reaction outcome loss': 0.4675890698187774, 'Total loss': 0.4675890698187774}
2022-11-28 05:58:25,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:25,441 INFO:     Epoch: 69
2022-11-28 05:58:26,107 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.569237547841939, 'Total loss': 0.569237547841939} | train loss {'Reaction outcome loss': 0.45625943420154436, 'Total loss': 0.45625943420154436}
2022-11-28 05:58:26,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:26,107 INFO:     Epoch: 70
2022-11-28 05:58:26,774 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49992676147005777, 'Total loss': 0.49992676147005777} | train loss {'Reaction outcome loss': 0.4633296280498466, 'Total loss': 0.4633296280498466}
2022-11-28 05:58:26,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:26,774 INFO:     Epoch: 71
2022-11-28 05:58:27,442 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47999095578085293, 'Total loss': 0.47999095578085293} | train loss {'Reaction outcome loss': 0.46550547998518715, 'Total loss': 0.46550547998518715}
2022-11-28 05:58:27,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:27,443 INFO:     Epoch: 72
2022-11-28 05:58:28,112 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5012860213491049, 'Total loss': 0.5012860213491049} | train loss {'Reaction outcome loss': 0.4637091834578783, 'Total loss': 0.4637091834578783}
2022-11-28 05:58:28,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:28,112 INFO:     Epoch: 73
2022-11-28 05:58:28,780 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49349246241829614, 'Total loss': 0.49349246241829614} | train loss {'Reaction outcome loss': 0.4668053042504095, 'Total loss': 0.4668053042504095}
2022-11-28 05:58:28,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:28,780 INFO:     Epoch: 74
2022-11-28 05:58:29,449 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47966368428685446, 'Total loss': 0.47966368428685446} | train loss {'Reaction outcome loss': 0.46119921828710264, 'Total loss': 0.46119921828710264}
2022-11-28 05:58:29,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:29,449 INFO:     Epoch: 75
2022-11-28 05:58:30,115 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5065171014178883, 'Total loss': 0.5065171014178883} | train loss {'Reaction outcome loss': 0.4662374860096362, 'Total loss': 0.4662374860096362}
2022-11-28 05:58:30,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:30,116 INFO:     Epoch: 76
2022-11-28 05:58:30,783 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49237140132622287, 'Total loss': 0.49237140132622287} | train loss {'Reaction outcome loss': 0.4706127514401751, 'Total loss': 0.4706127514401751}
2022-11-28 05:58:30,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:30,783 INFO:     Epoch: 77
2022-11-28 05:58:31,449 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5306069806895473, 'Total loss': 0.5306069806895473} | train loss {'Reaction outcome loss': 0.46091298269288195, 'Total loss': 0.46091298269288195}
2022-11-28 05:58:31,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:31,450 INFO:     Epoch: 78
2022-11-28 05:58:32,117 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.500835392285477, 'Total loss': 0.500835392285477} | train loss {'Reaction outcome loss': 0.4627859897070354, 'Total loss': 0.4627859897070354}
2022-11-28 05:58:32,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:32,118 INFO:     Epoch: 79
2022-11-28 05:58:32,785 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5007571090351451, 'Total loss': 0.5007571090351451} | train loss {'Reaction outcome loss': 0.4655885749887074, 'Total loss': 0.4655885749887074}
2022-11-28 05:58:32,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:32,785 INFO:     Epoch: 80
2022-11-28 05:58:33,451 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4881840744479136, 'Total loss': 0.4881840744479136} | train loss {'Reaction outcome loss': 0.46418382293514665, 'Total loss': 0.46418382293514665}
2022-11-28 05:58:33,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:33,451 INFO:     Epoch: 81
2022-11-28 05:58:34,116 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5314191837202419, 'Total loss': 0.5314191837202419} | train loss {'Reaction outcome loss': 0.4674190704620654, 'Total loss': 0.4674190704620654}
2022-11-28 05:58:34,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:34,117 INFO:     Epoch: 82
2022-11-28 05:58:34,785 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49029650674624875, 'Total loss': 0.49029650674624875} | train loss {'Reaction outcome loss': 0.46358330259400027, 'Total loss': 0.46358330259400027}
2022-11-28 05:58:34,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:34,785 INFO:     Epoch: 83
2022-11-28 05:58:35,452 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5003983693366701, 'Total loss': 0.5003983693366701} | train loss {'Reaction outcome loss': 0.4646918795882694, 'Total loss': 0.4646918795882694}
2022-11-28 05:58:35,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:35,452 INFO:     Epoch: 84
2022-11-28 05:58:36,119 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5069431439042091, 'Total loss': 0.5069431439042091} | train loss {'Reaction outcome loss': 0.4612366447765981, 'Total loss': 0.4612366447765981}
2022-11-28 05:58:36,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:36,120 INFO:     Epoch: 85
2022-11-28 05:58:36,787 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5177958133545789, 'Total loss': 0.5177958133545789} | train loss {'Reaction outcome loss': 0.4660675527467843, 'Total loss': 0.4660675527467843}
2022-11-28 05:58:36,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:36,788 INFO:     Epoch: 86
2022-11-28 05:58:37,455 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49740253388881683, 'Total loss': 0.49740253388881683} | train loss {'Reaction outcome loss': 0.4646754922765878, 'Total loss': 0.4646754922765878}
2022-11-28 05:58:37,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:37,456 INFO:     Epoch: 87
2022-11-28 05:58:38,124 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49159341847354715, 'Total loss': 0.49159341847354715} | train loss {'Reaction outcome loss': 0.46163620739694566, 'Total loss': 0.46163620739694566}
2022-11-28 05:58:38,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:38,124 INFO:     Epoch: 88
2022-11-28 05:58:38,791 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4991339885375716, 'Total loss': 0.4991339885375716} | train loss {'Reaction outcome loss': 0.4635697982964977, 'Total loss': 0.4635697982964977}
2022-11-28 05:58:38,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:38,791 INFO:     Epoch: 89
2022-11-28 05:58:39,459 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5398805879733779, 'Total loss': 0.5398805879733779} | train loss {'Reaction outcome loss': 0.46996433564251466, 'Total loss': 0.46996433564251466}
2022-11-28 05:58:39,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:39,459 INFO:     Epoch: 90
2022-11-28 05:58:40,127 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5068023353815079, 'Total loss': 0.5068023353815079} | train loss {'Reaction outcome loss': 0.46153010127525174, 'Total loss': 0.46153010127525174}
2022-11-28 05:58:40,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:40,127 INFO:     Epoch: 91
2022-11-28 05:58:40,794 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49117436429316347, 'Total loss': 0.49117436429316347} | train loss {'Reaction outcome loss': 0.4580336635511729, 'Total loss': 0.4580336635511729}
2022-11-28 05:58:40,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:40,795 INFO:     Epoch: 92
2022-11-28 05:58:41,463 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4812591915780848, 'Total loss': 0.4812591915780848} | train loss {'Reaction outcome loss': 0.4663932906583913, 'Total loss': 0.4663932906583913}
2022-11-28 05:58:41,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:41,463 INFO:     Epoch: 93
2022-11-28 05:58:42,129 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5021688497879289, 'Total loss': 0.5021688497879289} | train loss {'Reaction outcome loss': 0.4626437008020378, 'Total loss': 0.4626437008020378}
2022-11-28 05:58:42,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:42,130 INFO:     Epoch: 94
2022-11-28 05:58:42,796 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4727876132184809, 'Total loss': 0.4727876132184809} | train loss {'Reaction outcome loss': 0.46449710608970735, 'Total loss': 0.46449710608970735}
2022-11-28 05:58:42,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:42,796 INFO:     Epoch: 95
2022-11-28 05:58:43,463 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4817725741727786, 'Total loss': 0.4817725741727786} | train loss {'Reaction outcome loss': 0.4623876554711211, 'Total loss': 0.4623876554711211}
2022-11-28 05:58:43,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:43,463 INFO:     Epoch: 96
2022-11-28 05:58:44,128 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4928441010415554, 'Total loss': 0.4928441010415554} | train loss {'Reaction outcome loss': 0.46609761794247934, 'Total loss': 0.46609761794247934}
2022-11-28 05:58:44,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:44,128 INFO:     Epoch: 97
2022-11-28 05:58:44,796 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.499942499128255, 'Total loss': 0.499942499128255} | train loss {'Reaction outcome loss': 0.46334331698956027, 'Total loss': 0.46334331698956027}
2022-11-28 05:58:44,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:44,797 INFO:     Epoch: 98
2022-11-28 05:58:45,465 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5118458833206784, 'Total loss': 0.5118458833206784} | train loss {'Reaction outcome loss': 0.45824107239323275, 'Total loss': 0.45824107239323275}
2022-11-28 05:58:45,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:45,465 INFO:     Epoch: 99
2022-11-28 05:58:46,142 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49407638203014026, 'Total loss': 0.49407638203014026} | train loss {'Reaction outcome loss': 0.4629969169055262, 'Total loss': 0.4629969169055262}
2022-11-28 05:58:46,142 INFO:     Best model found after epoch 51 of 100.
2022-11-28 05:58:46,142 INFO:   Done with stage: TRAINING
2022-11-28 05:58:46,142 INFO:   Starting stage: EVALUATION
2022-11-28 05:58:46,255 INFO:   Done with stage: EVALUATION
2022-11-28 05:58:46,256 INFO:   Leaving out SEQ value Fold_7
2022-11-28 05:58:46,268 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:58:46,269 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:58:46,918 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:58:46,919 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:58:46,990 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:58:46,990 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:58:46,990 INFO:     No hyperparam tuning for this model
2022-11-28 05:58:46,990 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:58:46,990 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:58:46,991 INFO:     None feature selector for col prot
2022-11-28 05:58:46,991 INFO:     None feature selector for col prot
2022-11-28 05:58:46,991 INFO:     None feature selector for col prot
2022-11-28 05:58:46,991 INFO:     None feature selector for col chem
2022-11-28 05:58:46,992 INFO:     None feature selector for col chem
2022-11-28 05:58:46,992 INFO:     None feature selector for col chem
2022-11-28 05:58:46,992 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:58:46,992 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:58:46,993 INFO:     Number of params in model 169651
2022-11-28 05:58:46,996 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:58:46,996 INFO:   Starting stage: TRAINING
2022-11-28 05:58:47,049 INFO:     Val loss before train {'Reaction outcome loss': 1.0449209104884754, 'Total loss': 1.0449209104884754}
2022-11-28 05:58:47,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:47,049 INFO:     Epoch: 0
2022-11-28 05:58:47,719 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6119876253333959, 'Total loss': 0.6119876253333959} | train loss {'Reaction outcome loss': 0.6764066751685834, 'Total loss': 0.6764066751685834}
2022-11-28 05:58:47,719 INFO:     Found new best model at epoch 0
2022-11-28 05:58:47,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:47,720 INFO:     Epoch: 1
2022-11-28 05:58:48,386 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.555219517512755, 'Total loss': 0.555219517512755} | train loss {'Reaction outcome loss': 0.5799973633500838, 'Total loss': 0.5799973633500838}
2022-11-28 05:58:48,387 INFO:     Found new best model at epoch 1
2022-11-28 05:58:48,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:48,388 INFO:     Epoch: 2
2022-11-28 05:58:49,052 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5657826086336916, 'Total loss': 0.5657826086336916} | train loss {'Reaction outcome loss': 0.5508391002733861, 'Total loss': 0.5508391002733861}
2022-11-28 05:58:49,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:49,052 INFO:     Epoch: 3
2022-11-28 05:58:49,725 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5604009780694138, 'Total loss': 0.5604009780694138} | train loss {'Reaction outcome loss': 0.5307867586492531, 'Total loss': 0.5307867586492531}
2022-11-28 05:58:49,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:49,725 INFO:     Epoch: 4
2022-11-28 05:58:50,390 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5661713751879606, 'Total loss': 0.5661713751879606} | train loss {'Reaction outcome loss': 0.5142052749231938, 'Total loss': 0.5142052749231938}
2022-11-28 05:58:50,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:50,390 INFO:     Epoch: 5
2022-11-28 05:58:51,057 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5421268804506822, 'Total loss': 0.5421268804506822} | train loss {'Reaction outcome loss': 0.5125232700619006, 'Total loss': 0.5125232700619006}
2022-11-28 05:58:51,058 INFO:     Found new best model at epoch 5
2022-11-28 05:58:51,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:51,058 INFO:     Epoch: 6
2022-11-28 05:58:51,725 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5601336766373027, 'Total loss': 0.5601336766373027} | train loss {'Reaction outcome loss': 0.5041630734959918, 'Total loss': 0.5041630734959918}
2022-11-28 05:58:51,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:51,726 INFO:     Epoch: 7
2022-11-28 05:58:52,390 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.54276774992997, 'Total loss': 0.54276774992997} | train loss {'Reaction outcome loss': 0.48933190563994067, 'Total loss': 0.48933190563994067}
2022-11-28 05:58:52,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:52,390 INFO:     Epoch: 8
2022-11-28 05:58:53,055 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5312644399025224, 'Total loss': 0.5312644399025224} | train loss {'Reaction outcome loss': 0.49372860597025964, 'Total loss': 0.49372860597025964}
2022-11-28 05:58:53,055 INFO:     Found new best model at epoch 8
2022-11-28 05:58:53,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:53,056 INFO:     Epoch: 9
2022-11-28 05:58:53,722 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5319477296011015, 'Total loss': 0.5319477296011015} | train loss {'Reaction outcome loss': 0.4915425755804585, 'Total loss': 0.4915425755804585}
2022-11-28 05:58:53,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:53,722 INFO:     Epoch: 10
2022-11-28 05:58:54,384 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49523450976068323, 'Total loss': 0.49523450976068323} | train loss {'Reaction outcome loss': 0.4925762837932956, 'Total loss': 0.4925762837932956}
2022-11-28 05:58:54,384 INFO:     Found new best model at epoch 10
2022-11-28 05:58:54,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:54,385 INFO:     Epoch: 11
2022-11-28 05:58:55,051 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.526649878106334, 'Total loss': 0.526649878106334} | train loss {'Reaction outcome loss': 0.48010053774041517, 'Total loss': 0.48010053774041517}
2022-11-28 05:58:55,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:55,051 INFO:     Epoch: 12
2022-11-28 05:58:55,719 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.512008900669488, 'Total loss': 0.512008900669488} | train loss {'Reaction outcome loss': 0.4792439709267309, 'Total loss': 0.4792439709267309}
2022-11-28 05:58:55,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:55,720 INFO:     Epoch: 13
2022-11-28 05:58:56,386 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4980489191683856, 'Total loss': 0.4980489191683856} | train loss {'Reaction outcome loss': 0.4709687204731087, 'Total loss': 0.4709687204731087}
2022-11-28 05:58:56,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:56,387 INFO:     Epoch: 14
2022-11-28 05:58:57,056 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4900185740129514, 'Total loss': 0.4900185740129514} | train loss {'Reaction outcome loss': 0.4689352909523633, 'Total loss': 0.4689352909523633}
2022-11-28 05:58:57,056 INFO:     Found new best model at epoch 14
2022-11-28 05:58:57,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:57,057 INFO:     Epoch: 15
2022-11-28 05:58:57,727 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5157026086341251, 'Total loss': 0.5157026086341251} | train loss {'Reaction outcome loss': 0.4729692783326872, 'Total loss': 0.4729692783326872}
2022-11-28 05:58:57,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:57,727 INFO:     Epoch: 16
2022-11-28 05:58:58,392 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5103525404225696, 'Total loss': 0.5103525404225696} | train loss {'Reaction outcome loss': 0.4644306041863597, 'Total loss': 0.4644306041863597}
2022-11-28 05:58:58,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:58,392 INFO:     Epoch: 17
2022-11-28 05:58:59,058 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49886585704304953, 'Total loss': 0.49886585704304953} | train loss {'Reaction outcome loss': 0.47002048069430935, 'Total loss': 0.47002048069430935}
2022-11-28 05:58:59,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:59,058 INFO:     Epoch: 18
2022-11-28 05:58:59,723 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5343517539176074, 'Total loss': 0.5343517539176074} | train loss {'Reaction outcome loss': 0.46832768420778936, 'Total loss': 0.46832768420778936}
2022-11-28 05:58:59,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:58:59,723 INFO:     Epoch: 19
2022-11-28 05:59:00,387 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5851778692819856, 'Total loss': 0.5851778692819856} | train loss {'Reaction outcome loss': 0.467618043324159, 'Total loss': 0.467618043324159}
2022-11-28 05:59:00,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:00,388 INFO:     Epoch: 20
2022-11-28 05:59:01,052 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5020158974961801, 'Total loss': 0.5020158974961801} | train loss {'Reaction outcome loss': 0.4718716774255999, 'Total loss': 0.4718716774255999}
2022-11-28 05:59:01,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:01,053 INFO:     Epoch: 21
2022-11-28 05:59:01,722 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5037478499791839, 'Total loss': 0.5037478499791839} | train loss {'Reaction outcome loss': 0.46142001981816944, 'Total loss': 0.46142001981816944}
2022-11-28 05:59:01,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:01,723 INFO:     Epoch: 22
2022-11-28 05:59:02,389 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49654802544550464, 'Total loss': 0.49654802544550464} | train loss {'Reaction outcome loss': 0.47283899850181993, 'Total loss': 0.47283899850181993}
2022-11-28 05:59:02,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:02,389 INFO:     Epoch: 23
2022-11-28 05:59:03,058 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4950623285364021, 'Total loss': 0.4950623285364021} | train loss {'Reaction outcome loss': 0.4708954980296473, 'Total loss': 0.4708954980296473}
2022-11-28 05:59:03,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:03,058 INFO:     Epoch: 24
2022-11-28 05:59:03,729 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5092190663245592, 'Total loss': 0.5092190663245592} | train loss {'Reaction outcome loss': 0.4706529689532134, 'Total loss': 0.4706529689532134}
2022-11-28 05:59:03,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:03,729 INFO:     Epoch: 25
2022-11-28 05:59:04,400 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.513153960081664, 'Total loss': 0.513153960081664} | train loss {'Reaction outcome loss': 0.4759247966351048, 'Total loss': 0.4759247966351048}
2022-11-28 05:59:04,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:04,400 INFO:     Epoch: 26
2022-11-28 05:59:05,067 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49073587967590854, 'Total loss': 0.49073587967590854} | train loss {'Reaction outcome loss': 0.47103730090443163, 'Total loss': 0.47103730090443163}
2022-11-28 05:59:05,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:05,067 INFO:     Epoch: 27
2022-11-28 05:59:05,735 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5209150842644952, 'Total loss': 0.5209150842644952} | train loss {'Reaction outcome loss': 0.47186799083025227, 'Total loss': 0.47186799083025227}
2022-11-28 05:59:05,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:05,735 INFO:     Epoch: 28
2022-11-28 05:59:06,399 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4962771457027305, 'Total loss': 0.4962771457027305} | train loss {'Reaction outcome loss': 0.4715557685121894, 'Total loss': 0.4715557685121894}
2022-11-28 05:59:06,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:06,399 INFO:     Epoch: 29
2022-11-28 05:59:07,066 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5279064134440639, 'Total loss': 0.5279064134440639} | train loss {'Reaction outcome loss': 0.4654927825134608, 'Total loss': 0.4654927825134608}
2022-11-28 05:59:07,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:07,067 INFO:     Epoch: 30
2022-11-28 05:59:07,737 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5075236978856, 'Total loss': 0.5075236978856} | train loss {'Reaction outcome loss': 0.4677441662117358, 'Total loss': 0.4677441662117358}
2022-11-28 05:59:07,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:07,738 INFO:     Epoch: 31
2022-11-28 05:59:08,403 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5600291802124544, 'Total loss': 0.5600291802124544} | train loss {'Reaction outcome loss': 0.4575371406371555, 'Total loss': 0.4575371406371555}
2022-11-28 05:59:08,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:08,403 INFO:     Epoch: 32
2022-11-28 05:59:09,071 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5516791756857525, 'Total loss': 0.5516791756857525} | train loss {'Reaction outcome loss': 0.46511742376512094, 'Total loss': 0.46511742376512094}
2022-11-28 05:59:09,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:09,071 INFO:     Epoch: 33
2022-11-28 05:59:09,743 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5084592188623819, 'Total loss': 0.5084592188623819} | train loss {'Reaction outcome loss': 0.467317879440323, 'Total loss': 0.467317879440323}
2022-11-28 05:59:09,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:09,743 INFO:     Epoch: 34
2022-11-28 05:59:10,409 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.545090644874356, 'Total loss': 0.545090644874356} | train loss {'Reaction outcome loss': 0.4657833070283936, 'Total loss': 0.4657833070283936}
2022-11-28 05:59:10,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:10,409 INFO:     Epoch: 35
2022-11-28 05:59:11,079 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49215762452645734, 'Total loss': 0.49215762452645734} | train loss {'Reaction outcome loss': 0.46315425955840656, 'Total loss': 0.46315425955840656}
2022-11-28 05:59:11,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:11,080 INFO:     Epoch: 36
2022-11-28 05:59:11,746 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5988633774898269, 'Total loss': 0.5988633774898269} | train loss {'Reaction outcome loss': 0.46777156409957715, 'Total loss': 0.46777156409957715}
2022-11-28 05:59:11,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:11,746 INFO:     Epoch: 37
2022-11-28 05:59:12,417 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5248522799123417, 'Total loss': 0.5248522799123417} | train loss {'Reaction outcome loss': 0.4680417634306415, 'Total loss': 0.4680417634306415}
2022-11-28 05:59:12,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:12,417 INFO:     Epoch: 38
2022-11-28 05:59:13,086 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5273094414310022, 'Total loss': 0.5273094414310022} | train loss {'Reaction outcome loss': 0.46750326082110405, 'Total loss': 0.46750326082110405}
2022-11-28 05:59:13,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:13,087 INFO:     Epoch: 39
2022-11-28 05:59:13,755 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5005551915277134, 'Total loss': 0.5005551915277134} | train loss {'Reaction outcome loss': 0.4733739497680818, 'Total loss': 0.4733739497680818}
2022-11-28 05:59:13,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:13,756 INFO:     Epoch: 40
2022-11-28 05:59:14,425 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4991854043169455, 'Total loss': 0.4991854043169455} | train loss {'Reaction outcome loss': 0.46730327443970787, 'Total loss': 0.46730327443970787}
2022-11-28 05:59:14,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:14,425 INFO:     Epoch: 41
2022-11-28 05:59:15,092 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5176466656002131, 'Total loss': 0.5176466656002131} | train loss {'Reaction outcome loss': 0.46676503999098656, 'Total loss': 0.46676503999098656}
2022-11-28 05:59:15,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:15,092 INFO:     Epoch: 42
2022-11-28 05:59:15,758 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5260856452990662, 'Total loss': 0.5260856452990662} | train loss {'Reaction outcome loss': 0.47055053614800973, 'Total loss': 0.47055053614800973}
2022-11-28 05:59:15,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:15,758 INFO:     Epoch: 43
2022-11-28 05:59:16,430 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5032939877022397, 'Total loss': 0.5032939877022397} | train loss {'Reaction outcome loss': 0.4712989516556263, 'Total loss': 0.4712989516556263}
2022-11-28 05:59:16,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:16,430 INFO:     Epoch: 44
2022-11-28 05:59:17,101 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5385958799584345, 'Total loss': 0.5385958799584345} | train loss {'Reaction outcome loss': 0.4626322704397382, 'Total loss': 0.4626322704397382}
2022-11-28 05:59:17,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:17,102 INFO:     Epoch: 45
2022-11-28 05:59:17,767 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5290014350956137, 'Total loss': 0.5290014350956137} | train loss {'Reaction outcome loss': 0.4684193667865569, 'Total loss': 0.4684193667865569}
2022-11-28 05:59:17,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:17,767 INFO:     Epoch: 46
2022-11-28 05:59:18,437 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5501422607763247, 'Total loss': 0.5501422607763247} | train loss {'Reaction outcome loss': 0.4702248728323367, 'Total loss': 0.4702248728323367}
2022-11-28 05:59:18,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:18,437 INFO:     Epoch: 47
2022-11-28 05:59:19,107 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5058284764262763, 'Total loss': 0.5058284764262763} | train loss {'Reaction outcome loss': 0.4728806252861696, 'Total loss': 0.4728806252861696}
2022-11-28 05:59:19,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:19,108 INFO:     Epoch: 48
2022-11-28 05:59:19,775 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5337521637027914, 'Total loss': 0.5337521637027914} | train loss {'Reaction outcome loss': 0.4738027536340298, 'Total loss': 0.4738027536340298}
2022-11-28 05:59:19,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:19,775 INFO:     Epoch: 49
2022-11-28 05:59:20,442 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5163892656564713, 'Total loss': 0.5163892656564713} | train loss {'Reaction outcome loss': 0.4672593699107247, 'Total loss': 0.4672593699107247}
2022-11-28 05:59:20,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:20,442 INFO:     Epoch: 50
2022-11-28 05:59:21,108 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.570302967320789, 'Total loss': 0.570302967320789} | train loss {'Reaction outcome loss': 0.46689341788090044, 'Total loss': 0.46689341788090044}
2022-11-28 05:59:21,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:21,108 INFO:     Epoch: 51
2022-11-28 05:59:21,776 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5033961713991382, 'Total loss': 0.5033961713991382} | train loss {'Reaction outcome loss': 0.4721151234642152, 'Total loss': 0.4721151234642152}
2022-11-28 05:59:21,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:21,776 INFO:     Epoch: 52
2022-11-28 05:59:22,444 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5190886502916162, 'Total loss': 0.5190886502916162} | train loss {'Reaction outcome loss': 0.4642907603673877, 'Total loss': 0.4642907603673877}
2022-11-28 05:59:22,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:22,445 INFO:     Epoch: 53
2022-11-28 05:59:23,113 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5010660107840191, 'Total loss': 0.5010660107840191} | train loss {'Reaction outcome loss': 0.47122308377537037, 'Total loss': 0.47122308377537037}
2022-11-28 05:59:23,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:23,113 INFO:     Epoch: 54
2022-11-28 05:59:23,780 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5330914150584828, 'Total loss': 0.5330914150584828} | train loss {'Reaction outcome loss': 0.47315526603450697, 'Total loss': 0.47315526603450697}
2022-11-28 05:59:23,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:23,781 INFO:     Epoch: 55
2022-11-28 05:59:24,451 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5428819354962219, 'Total loss': 0.5428819354962219} | train loss {'Reaction outcome loss': 0.46797066332111437, 'Total loss': 0.46797066332111437}
2022-11-28 05:59:24,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:24,452 INFO:     Epoch: 56
2022-11-28 05:59:25,119 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4951106980443001, 'Total loss': 0.4951106980443001} | train loss {'Reaction outcome loss': 0.47422602466277536, 'Total loss': 0.47422602466277536}
2022-11-28 05:59:25,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:25,119 INFO:     Epoch: 57
2022-11-28 05:59:25,788 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5020305880091407, 'Total loss': 0.5020305880091407} | train loss {'Reaction outcome loss': 0.4689174528804518, 'Total loss': 0.4689174528804518}
2022-11-28 05:59:25,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:25,788 INFO:     Epoch: 58
2022-11-28 05:59:26,456 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49279420484196057, 'Total loss': 0.49279420484196057} | train loss {'Reaction outcome loss': 0.4713970716562002, 'Total loss': 0.4713970716562002}
2022-11-28 05:59:26,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:26,456 INFO:     Epoch: 59
2022-11-28 05:59:27,129 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.54685712876645, 'Total loss': 0.54685712876645} | train loss {'Reaction outcome loss': 0.4688695159650618, 'Total loss': 0.4688695159650618}
2022-11-28 05:59:27,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:27,129 INFO:     Epoch: 60
2022-11-28 05:59:27,798 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.501905890350992, 'Total loss': 0.501905890350992} | train loss {'Reaction outcome loss': 0.46401549503207207, 'Total loss': 0.46401549503207207}
2022-11-28 05:59:27,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:27,799 INFO:     Epoch: 61
2022-11-28 05:59:28,466 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49036593769084325, 'Total loss': 0.49036593769084325} | train loss {'Reaction outcome loss': 0.4707252282288767, 'Total loss': 0.4707252282288767}
2022-11-28 05:59:28,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:28,466 INFO:     Epoch: 62
2022-11-28 05:59:29,134 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4786825528876348, 'Total loss': 0.4786825528876348} | train loss {'Reaction outcome loss': 0.46820722069711457, 'Total loss': 0.46820722069711457}
2022-11-28 05:59:29,134 INFO:     Found new best model at epoch 62
2022-11-28 05:59:29,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:29,135 INFO:     Epoch: 63
2022-11-28 05:59:29,803 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49103303253650665, 'Total loss': 0.49103303253650665} | train loss {'Reaction outcome loss': 0.46489432135656955, 'Total loss': 0.46489432135656955}
2022-11-28 05:59:29,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:29,803 INFO:     Epoch: 64
2022-11-28 05:59:30,473 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5106147426095876, 'Total loss': 0.5106147426095876} | train loss {'Reaction outcome loss': 0.4775043446570635, 'Total loss': 0.4775043446570635}
2022-11-28 05:59:30,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:30,473 INFO:     Epoch: 65
2022-11-28 05:59:31,143 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48911784386092966, 'Total loss': 0.48911784386092966} | train loss {'Reaction outcome loss': 0.46477094617101455, 'Total loss': 0.46477094617101455}
2022-11-28 05:59:31,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:31,143 INFO:     Epoch: 66
2022-11-28 05:59:31,811 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5331911471757022, 'Total loss': 0.5331911471757022} | train loss {'Reaction outcome loss': 0.4638599720483105, 'Total loss': 0.4638599720483105}
2022-11-28 05:59:31,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:31,815 INFO:     Epoch: 67
2022-11-28 05:59:32,486 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5055740722878412, 'Total loss': 0.5055740722878412} | train loss {'Reaction outcome loss': 0.4750728693099753, 'Total loss': 0.4750728693099753}
2022-11-28 05:59:32,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:32,486 INFO:     Epoch: 68
2022-11-28 05:59:33,153 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5071227279576388, 'Total loss': 0.5071227279576388} | train loss {'Reaction outcome loss': 0.46789965201770106, 'Total loss': 0.46789965201770106}
2022-11-28 05:59:33,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:33,153 INFO:     Epoch: 69
2022-11-28 05:59:33,821 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49171427908268844, 'Total loss': 0.49171427908268844} | train loss {'Reaction outcome loss': 0.4681042042230406, 'Total loss': 0.4681042042230406}
2022-11-28 05:59:33,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:33,821 INFO:     Epoch: 70
2022-11-28 05:59:34,487 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5064861070026051, 'Total loss': 0.5064861070026051} | train loss {'Reaction outcome loss': 0.47137649675771115, 'Total loss': 0.47137649675771115}
2022-11-28 05:59:34,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:34,488 INFO:     Epoch: 71
2022-11-28 05:59:35,153 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5011879002506082, 'Total loss': 0.5011879002506082} | train loss {'Reaction outcome loss': 0.47171046272400885, 'Total loss': 0.47171046272400885}
2022-11-28 05:59:35,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:35,153 INFO:     Epoch: 72
2022-11-28 05:59:35,820 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.525784848088568, 'Total loss': 0.525784848088568} | train loss {'Reaction outcome loss': 0.4714751053120821, 'Total loss': 0.4714751053120821}
2022-11-28 05:59:35,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:35,820 INFO:     Epoch: 73
2022-11-28 05:59:36,487 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49634498290040274, 'Total loss': 0.49634498290040274} | train loss {'Reaction outcome loss': 0.46893412715965704, 'Total loss': 0.46893412715965704}
2022-11-28 05:59:36,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:36,487 INFO:     Epoch: 74
2022-11-28 05:59:37,155 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49706814844499936, 'Total loss': 0.49706814844499936} | train loss {'Reaction outcome loss': 0.4683059740571245, 'Total loss': 0.4683059740571245}
2022-11-28 05:59:37,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:37,155 INFO:     Epoch: 75
2022-11-28 05:59:37,820 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5106577886776491, 'Total loss': 0.5106577886776491} | train loss {'Reaction outcome loss': 0.4653246465229219, 'Total loss': 0.4653246465229219}
2022-11-28 05:59:37,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:37,821 INFO:     Epoch: 76
2022-11-28 05:59:38,485 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5132816291668199, 'Total loss': 0.5132816291668199} | train loss {'Reaction outcome loss': 0.4765654537346094, 'Total loss': 0.4765654537346094}
2022-11-28 05:59:38,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:38,485 INFO:     Epoch: 77
2022-11-28 05:59:39,150 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5025287168947133, 'Total loss': 0.5025287168947133} | train loss {'Reaction outcome loss': 0.4739586669470995, 'Total loss': 0.4739586669470995}
2022-11-28 05:59:39,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:39,150 INFO:     Epoch: 78
2022-11-28 05:59:39,816 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5225090492855419, 'Total loss': 0.5225090492855419} | train loss {'Reaction outcome loss': 0.4626537141420187, 'Total loss': 0.4626537141420187}
2022-11-28 05:59:39,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:39,816 INFO:     Epoch: 79
2022-11-28 05:59:40,479 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5086079107766802, 'Total loss': 0.5086079107766802} | train loss {'Reaction outcome loss': 0.46732043054315353, 'Total loss': 0.46732043054315353}
2022-11-28 05:59:40,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:40,479 INFO:     Epoch: 80
2022-11-28 05:59:41,145 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4947408322583545, 'Total loss': 0.4947408322583545} | train loss {'Reaction outcome loss': 0.46717614422161735, 'Total loss': 0.46717614422161735}
2022-11-28 05:59:41,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:41,145 INFO:     Epoch: 81
2022-11-28 05:59:41,812 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5217230255630884, 'Total loss': 0.5217230255630884} | train loss {'Reaction outcome loss': 0.46808954682802, 'Total loss': 0.46808954682802}
2022-11-28 05:59:41,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:41,812 INFO:     Epoch: 82
2022-11-28 05:59:42,478 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5601452700793743, 'Total loss': 0.5601452700793743} | train loss {'Reaction outcome loss': 0.47385694921737714, 'Total loss': 0.47385694921737714}
2022-11-28 05:59:42,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:42,479 INFO:     Epoch: 83
2022-11-28 05:59:43,141 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48985515467145224, 'Total loss': 0.48985515467145224} | train loss {'Reaction outcome loss': 0.4691770795372225, 'Total loss': 0.4691770795372225}
2022-11-28 05:59:43,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:43,141 INFO:     Epoch: 84
2022-11-28 05:59:43,803 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49890250204639003, 'Total loss': 0.49890250204639003} | train loss {'Reaction outcome loss': 0.467553933181109, 'Total loss': 0.467553933181109}
2022-11-28 05:59:43,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:43,803 INFO:     Epoch: 85
2022-11-28 05:59:44,466 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5215663699941202, 'Total loss': 0.5215663699941202} | train loss {'Reaction outcome loss': 0.46420424263323506, 'Total loss': 0.46420424263323506}
2022-11-28 05:59:44,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:44,466 INFO:     Epoch: 86
2022-11-28 05:59:45,126 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4867348901250146, 'Total loss': 0.4867348901250146} | train loss {'Reaction outcome loss': 0.4655397101756065, 'Total loss': 0.4655397101756065}
2022-11-28 05:59:45,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:45,127 INFO:     Epoch: 87
2022-11-28 05:59:45,789 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5288377112962983, 'Total loss': 0.5288377112962983} | train loss {'Reaction outcome loss': 0.4664734233050577, 'Total loss': 0.4664734233050577}
2022-11-28 05:59:45,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:45,789 INFO:     Epoch: 88
2022-11-28 05:59:46,454 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5114857161586935, 'Total loss': 0.5114857161586935} | train loss {'Reaction outcome loss': 0.467067593828805, 'Total loss': 0.467067593828805}
2022-11-28 05:59:46,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:46,454 INFO:     Epoch: 89
2022-11-28 05:59:47,116 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5246670544147491, 'Total loss': 0.5246670544147491} | train loss {'Reaction outcome loss': 0.46711640408442867, 'Total loss': 0.46711640408442867}
2022-11-28 05:59:47,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:47,116 INFO:     Epoch: 90
2022-11-28 05:59:47,779 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5027450255372308, 'Total loss': 0.5027450255372308} | train loss {'Reaction outcome loss': 0.47356240192969, 'Total loss': 0.47356240192969}
2022-11-28 05:59:47,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:47,779 INFO:     Epoch: 91
2022-11-28 05:59:48,442 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5169197202406146, 'Total loss': 0.5169197202406146} | train loss {'Reaction outcome loss': 0.46789198987666636, 'Total loss': 0.46789198987666636}
2022-11-28 05:59:48,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:48,442 INFO:     Epoch: 92
2022-11-28 05:59:49,104 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.526160690933466, 'Total loss': 0.526160690933466} | train loss {'Reaction outcome loss': 0.46641354677417585, 'Total loss': 0.46641354677417585}
2022-11-28 05:59:49,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:49,104 INFO:     Epoch: 93
2022-11-28 05:59:49,765 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5332198766144839, 'Total loss': 0.5332198766144839} | train loss {'Reaction outcome loss': 0.46717354847538856, 'Total loss': 0.46717354847538856}
2022-11-28 05:59:49,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:49,766 INFO:     Epoch: 94
2022-11-28 05:59:50,426 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5229587795382197, 'Total loss': 0.5229587795382197} | train loss {'Reaction outcome loss': 0.4715075849164878, 'Total loss': 0.4715075849164878}
2022-11-28 05:59:50,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:50,427 INFO:     Epoch: 95
2022-11-28 05:59:51,085 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5169346837157552, 'Total loss': 0.5169346837157552} | train loss {'Reaction outcome loss': 0.47673472732065186, 'Total loss': 0.47673472732065186}
2022-11-28 05:59:51,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:51,086 INFO:     Epoch: 96
2022-11-28 05:59:51,746 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5038218450817195, 'Total loss': 0.5038218450817195} | train loss {'Reaction outcome loss': 0.4685222147813728, 'Total loss': 0.4685222147813728}
2022-11-28 05:59:51,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:51,747 INFO:     Epoch: 97
2022-11-28 05:59:52,407 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.501243723387068, 'Total loss': 0.501243723387068} | train loss {'Reaction outcome loss': 0.4660865742593042, 'Total loss': 0.4660865742593042}
2022-11-28 05:59:52,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:52,407 INFO:     Epoch: 98
2022-11-28 05:59:53,068 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5059022270143032, 'Total loss': 0.5059022270143032} | train loss {'Reaction outcome loss': 0.46587116721897354, 'Total loss': 0.46587116721897354}
2022-11-28 05:59:53,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:53,068 INFO:     Epoch: 99
2022-11-28 05:59:53,732 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5676491721109911, 'Total loss': 0.5676491721109911} | train loss {'Reaction outcome loss': 0.47432835231865605, 'Total loss': 0.47432835231865605}
2022-11-28 05:59:53,732 INFO:     Best model found after epoch 63 of 100.
2022-11-28 05:59:53,732 INFO:   Done with stage: TRAINING
2022-11-28 05:59:53,732 INFO:   Starting stage: EVALUATION
2022-11-28 05:59:53,845 INFO:   Done with stage: EVALUATION
2022-11-28 05:59:53,845 INFO:   Leaving out SEQ value Fold_8
2022-11-28 05:59:53,858 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:59:53,858 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:59:54,493 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:59:54,493 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:59:54,563 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:59:54,563 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:59:54,563 INFO:     No hyperparam tuning for this model
2022-11-28 05:59:54,563 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:59:54,563 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:59:54,564 INFO:     None feature selector for col prot
2022-11-28 05:59:54,564 INFO:     None feature selector for col prot
2022-11-28 05:59:54,564 INFO:     None feature selector for col prot
2022-11-28 05:59:54,564 INFO:     None feature selector for col chem
2022-11-28 05:59:54,564 INFO:     None feature selector for col chem
2022-11-28 05:59:54,565 INFO:     None feature selector for col chem
2022-11-28 05:59:54,565 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:59:54,565 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:59:54,566 INFO:     Number of params in model 169651
2022-11-28 05:59:54,569 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:59:54,569 INFO:   Starting stage: TRAINING
2022-11-28 05:59:54,620 INFO:     Val loss before train {'Reaction outcome loss': 0.9597596810622648, 'Total loss': 0.9597596810622648}
2022-11-28 05:59:54,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:54,621 INFO:     Epoch: 0
2022-11-28 05:59:55,279 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5707290727983821, 'Total loss': 0.5707290727983821} | train loss {'Reaction outcome loss': 0.6767222082566636, 'Total loss': 0.6767222082566636}
2022-11-28 05:59:55,279 INFO:     Found new best model at epoch 0
2022-11-28 05:59:55,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:55,280 INFO:     Epoch: 1
2022-11-28 05:59:55,936 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5447966409000483, 'Total loss': 0.5447966409000483} | train loss {'Reaction outcome loss': 0.5784543035212557, 'Total loss': 0.5784543035212557}
2022-11-28 05:59:55,936 INFO:     Found new best model at epoch 1
2022-11-28 05:59:55,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:55,937 INFO:     Epoch: 2
2022-11-28 05:59:56,594 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5217815346338532, 'Total loss': 0.5217815346338532} | train loss {'Reaction outcome loss': 0.5663287010994035, 'Total loss': 0.5663287010994035}
2022-11-28 05:59:56,594 INFO:     Found new best model at epoch 2
2022-11-28 05:59:56,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:56,595 INFO:     Epoch: 3
2022-11-28 05:59:57,253 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5329248261722651, 'Total loss': 0.5329248261722651} | train loss {'Reaction outcome loss': 0.5329244698544866, 'Total loss': 0.5329244698544866}
2022-11-28 05:59:57,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:57,254 INFO:     Epoch: 4
2022-11-28 05:59:57,912 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5042116045951843, 'Total loss': 0.5042116045951843} | train loss {'Reaction outcome loss': 0.5337060768353311, 'Total loss': 0.5337060768353311}
2022-11-28 05:59:57,912 INFO:     Found new best model at epoch 4
2022-11-28 05:59:57,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:57,913 INFO:     Epoch: 5
2022-11-28 05:59:58,573 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47576733712445607, 'Total loss': 0.47576733712445607} | train loss {'Reaction outcome loss': 0.5258090553978677, 'Total loss': 0.5258090553978677}
2022-11-28 05:59:58,573 INFO:     Found new best model at epoch 5
2022-11-28 05:59:58,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:58,574 INFO:     Epoch: 6
2022-11-28 05:59:59,231 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5067674727602438, 'Total loss': 0.5067674727602438} | train loss {'Reaction outcome loss': 0.5357053992357331, 'Total loss': 0.5357053992357331}
2022-11-28 05:59:59,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:59,231 INFO:     Epoch: 7
2022-11-28 05:59:59,886 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4923853315412998, 'Total loss': 0.4923853315412998} | train loss {'Reaction outcome loss': 0.5151658698874959, 'Total loss': 0.5151658698874959}
2022-11-28 05:59:59,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:59:59,887 INFO:     Epoch: 8
2022-11-28 06:00:00,545 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4714496975595301, 'Total loss': 0.4714496975595301} | train loss {'Reaction outcome loss': 0.5118742972491723, 'Total loss': 0.5118742972491723}
2022-11-28 06:00:00,545 INFO:     Found new best model at epoch 8
2022-11-28 06:00:00,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:00,546 INFO:     Epoch: 9
2022-11-28 06:00:01,206 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4919002293185754, 'Total loss': 0.4919002293185754} | train loss {'Reaction outcome loss': 0.5028207653658352, 'Total loss': 0.5028207653658352}
2022-11-28 06:00:01,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:01,206 INFO:     Epoch: 10
2022-11-28 06:00:01,865 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5024095499380068, 'Total loss': 0.5024095499380068} | train loss {'Reaction outcome loss': 0.49867367393785883, 'Total loss': 0.49867367393785883}
2022-11-28 06:00:01,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:01,866 INFO:     Epoch: 11
2022-11-28 06:00:02,522 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48130172152410855, 'Total loss': 0.48130172152410855} | train loss {'Reaction outcome loss': 0.4875165726612454, 'Total loss': 0.4875165726612454}
2022-11-28 06:00:02,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:02,522 INFO:     Epoch: 12
2022-11-28 06:00:03,178 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.505893814292821, 'Total loss': 0.505893814292821} | train loss {'Reaction outcome loss': 0.48496600762311265, 'Total loss': 0.48496600762311265}
2022-11-28 06:00:03,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:03,179 INFO:     Epoch: 13
2022-11-28 06:00:03,837 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49418994987552817, 'Total loss': 0.49418994987552817} | train loss {'Reaction outcome loss': 0.4905835851604639, 'Total loss': 0.4905835851604639}
2022-11-28 06:00:03,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:03,837 INFO:     Epoch: 14
2022-11-28 06:00:04,495 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4677333567630161, 'Total loss': 0.4677333567630161} | train loss {'Reaction outcome loss': 0.48651314560731174, 'Total loss': 0.48651314560731174}
2022-11-28 06:00:04,496 INFO:     Found new best model at epoch 14
2022-11-28 06:00:04,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:04,496 INFO:     Epoch: 15
2022-11-28 06:00:05,156 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4385406104001132, 'Total loss': 0.4385406104001132} | train loss {'Reaction outcome loss': 0.4776185631812343, 'Total loss': 0.4776185631812343}
2022-11-28 06:00:05,156 INFO:     Found new best model at epoch 15
2022-11-28 06:00:05,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:05,157 INFO:     Epoch: 16
2022-11-28 06:00:05,812 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4645824002271349, 'Total loss': 0.4645824002271349} | train loss {'Reaction outcome loss': 0.49556630306880967, 'Total loss': 0.49556630306880967}
2022-11-28 06:00:05,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:05,812 INFO:     Epoch: 17
2022-11-28 06:00:06,471 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48964241790500557, 'Total loss': 0.48964241790500557} | train loss {'Reaction outcome loss': 0.4980937969467418, 'Total loss': 0.4980937969467418}
2022-11-28 06:00:06,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:06,471 INFO:     Epoch: 18
2022-11-28 06:00:07,128 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49339575523679907, 'Total loss': 0.49339575523679907} | train loss {'Reaction outcome loss': 0.48301500057884555, 'Total loss': 0.48301500057884555}
2022-11-28 06:00:07,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:07,128 INFO:     Epoch: 19
2022-11-28 06:00:07,783 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47487233646891336, 'Total loss': 0.47487233646891336} | train loss {'Reaction outcome loss': 0.4863502514145152, 'Total loss': 0.4863502514145152}
2022-11-28 06:00:07,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:07,784 INFO:     Epoch: 20
2022-11-28 06:00:08,441 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47463178566911, 'Total loss': 0.47463178566911} | train loss {'Reaction outcome loss': 0.47380038298787136, 'Total loss': 0.47380038298787136}
2022-11-28 06:00:08,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:08,442 INFO:     Epoch: 21
2022-11-28 06:00:09,098 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48113126815720036, 'Total loss': 0.48113126815720036} | train loss {'Reaction outcome loss': 0.47255802190738166, 'Total loss': 0.47255802190738166}
2022-11-28 06:00:09,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:09,098 INFO:     Epoch: 22
2022-11-28 06:00:09,755 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4563611952418631, 'Total loss': 0.4563611952418631} | train loss {'Reaction outcome loss': 0.4762346087257389, 'Total loss': 0.4762346087257389}
2022-11-28 06:00:09,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:09,756 INFO:     Epoch: 23
2022-11-28 06:00:10,414 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47052469985051587, 'Total loss': 0.47052469985051587} | train loss {'Reaction outcome loss': 0.4896541764499687, 'Total loss': 0.4896541764499687}
2022-11-28 06:00:10,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:10,414 INFO:     Epoch: 24
2022-11-28 06:00:11,072 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4764976596290415, 'Total loss': 0.4764976596290415} | train loss {'Reaction outcome loss': 0.479342158778235, 'Total loss': 0.479342158778235}
2022-11-28 06:00:11,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:11,072 INFO:     Epoch: 25
2022-11-28 06:00:11,729 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4757396721027114, 'Total loss': 0.4757396721027114} | train loss {'Reaction outcome loss': 0.4811123034611405, 'Total loss': 0.4811123034611405}
2022-11-28 06:00:11,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:11,729 INFO:     Epoch: 26
2022-11-28 06:00:12,386 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4531975727189671, 'Total loss': 0.4531975727189671} | train loss {'Reaction outcome loss': 0.46718111855962013, 'Total loss': 0.46718111855962013}
2022-11-28 06:00:12,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:12,387 INFO:     Epoch: 27
2022-11-28 06:00:13,045 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4826109856367111, 'Total loss': 0.4826109856367111} | train loss {'Reaction outcome loss': 0.4673253145174459, 'Total loss': 0.4673253145174459}
2022-11-28 06:00:13,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:13,045 INFO:     Epoch: 28
2022-11-28 06:00:13,704 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47945007343183865, 'Total loss': 0.47945007343183865} | train loss {'Reaction outcome loss': 0.46922310164220904, 'Total loss': 0.46922310164220904}
2022-11-28 06:00:13,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:13,704 INFO:     Epoch: 29
2022-11-28 06:00:14,362 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46613005751913245, 'Total loss': 0.46613005751913245} | train loss {'Reaction outcome loss': 0.47133640625216217, 'Total loss': 0.47133640625216217}
2022-11-28 06:00:14,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:14,362 INFO:     Epoch: 30
2022-11-28 06:00:15,018 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4550360028039325, 'Total loss': 0.4550360028039325} | train loss {'Reaction outcome loss': 0.45494480708591367, 'Total loss': 0.45494480708591367}
2022-11-28 06:00:15,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:15,018 INFO:     Epoch: 31
2022-11-28 06:00:15,669 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44379035755991936, 'Total loss': 0.44379035755991936} | train loss {'Reaction outcome loss': 0.46403136851665705, 'Total loss': 0.46403136851665705}
2022-11-28 06:00:15,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:15,670 INFO:     Epoch: 32
2022-11-28 06:00:16,327 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48283404924652795, 'Total loss': 0.48283404924652795} | train loss {'Reaction outcome loss': 0.46091746849569715, 'Total loss': 0.46091746849569715}
2022-11-28 06:00:16,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:16,328 INFO:     Epoch: 33
2022-11-28 06:00:16,985 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5334284481677142, 'Total loss': 0.5334284481677142} | train loss {'Reaction outcome loss': 0.4703890734959228, 'Total loss': 0.4703890734959228}
2022-11-28 06:00:16,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:16,986 INFO:     Epoch: 34
2022-11-28 06:00:17,639 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44877669316801155, 'Total loss': 0.44877669316801155} | train loss {'Reaction outcome loss': 0.4767429817181367, 'Total loss': 0.4767429817181367}
2022-11-28 06:00:17,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:17,639 INFO:     Epoch: 35
2022-11-28 06:00:18,295 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46307244659824803, 'Total loss': 0.46307244659824803} | train loss {'Reaction outcome loss': 0.4719147867756907, 'Total loss': 0.4719147867756907}
2022-11-28 06:00:18,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:18,295 INFO:     Epoch: 36
2022-11-28 06:00:18,954 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4608860584822568, 'Total loss': 0.4608860584822568} | train loss {'Reaction outcome loss': 0.4562796321537285, 'Total loss': 0.4562796321537285}
2022-11-28 06:00:18,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:18,954 INFO:     Epoch: 37
2022-11-28 06:00:19,614 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48963981155644765, 'Total loss': 0.48963981155644765} | train loss {'Reaction outcome loss': 0.4573017795860526, 'Total loss': 0.4573017795860526}
2022-11-28 06:00:19,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:19,614 INFO:     Epoch: 38
2022-11-28 06:00:20,272 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4884147332473235, 'Total loss': 0.4884147332473235} | train loss {'Reaction outcome loss': 0.46401185280292745, 'Total loss': 0.46401185280292745}
2022-11-28 06:00:20,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:20,272 INFO:     Epoch: 39
2022-11-28 06:00:20,929 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47284233502366324, 'Total loss': 0.47284233502366324} | train loss {'Reaction outcome loss': 0.46319873100108944, 'Total loss': 0.46319873100108944}
2022-11-28 06:00:20,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:20,929 INFO:     Epoch: 40
2022-11-28 06:00:21,586 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5032197504558347, 'Total loss': 0.5032197504558347} | train loss {'Reaction outcome loss': 0.4729623758735565, 'Total loss': 0.4729623758735565}
2022-11-28 06:00:21,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:21,586 INFO:     Epoch: 41
2022-11-28 06:00:22,245 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.446412362835624, 'Total loss': 0.446412362835624} | train loss {'Reaction outcome loss': 0.46236600239689535, 'Total loss': 0.46236600239689535}
2022-11-28 06:00:22,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:22,246 INFO:     Epoch: 42
2022-11-28 06:00:22,905 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4671362785791809, 'Total loss': 0.4671362785791809} | train loss {'Reaction outcome loss': 0.4632946182238428, 'Total loss': 0.4632946182238428}
2022-11-28 06:00:22,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:22,906 INFO:     Epoch: 43
2022-11-28 06:00:23,560 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4683564312078736, 'Total loss': 0.4683564312078736} | train loss {'Reaction outcome loss': 0.46131886771092045, 'Total loss': 0.46131886771092045}
2022-11-28 06:00:23,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:23,560 INFO:     Epoch: 44
2022-11-28 06:00:24,214 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.503673183647069, 'Total loss': 0.503673183647069} | train loss {'Reaction outcome loss': 0.465652692474817, 'Total loss': 0.465652692474817}
2022-11-28 06:00:24,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:24,214 INFO:     Epoch: 45
2022-11-28 06:00:24,871 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5073846090923656, 'Total loss': 0.5073846090923656} | train loss {'Reaction outcome loss': 0.46678996605134987, 'Total loss': 0.46678996605134987}
2022-11-28 06:00:24,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:24,871 INFO:     Epoch: 46
2022-11-28 06:00:25,527 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46568227085200226, 'Total loss': 0.46568227085200226} | train loss {'Reaction outcome loss': 0.4567487462817763, 'Total loss': 0.4567487462817763}
2022-11-28 06:00:25,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:25,527 INFO:     Epoch: 47
2022-11-28 06:00:26,182 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4609657170420343, 'Total loss': 0.4609657170420343} | train loss {'Reaction outcome loss': 0.4577539082963457, 'Total loss': 0.4577539082963457}
2022-11-28 06:00:26,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:26,182 INFO:     Epoch: 48
2022-11-28 06:00:26,850 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43884201923554594, 'Total loss': 0.43884201923554594} | train loss {'Reaction outcome loss': 0.46143723279237747, 'Total loss': 0.46143723279237747}
2022-11-28 06:00:26,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:26,850 INFO:     Epoch: 49
2022-11-28 06:00:27,514 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44636567580428993, 'Total loss': 0.44636567580428993} | train loss {'Reaction outcome loss': 0.4623268724453111, 'Total loss': 0.4623268724453111}
2022-11-28 06:00:27,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:27,515 INFO:     Epoch: 50
2022-11-28 06:00:28,179 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44417967477982695, 'Total loss': 0.44417967477982695} | train loss {'Reaction outcome loss': 0.46335279933169393, 'Total loss': 0.46335279933169393}
2022-11-28 06:00:28,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:28,179 INFO:     Epoch: 51
2022-11-28 06:00:28,842 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45209980180317705, 'Total loss': 0.45209980180317705} | train loss {'Reaction outcome loss': 0.4643770044269832, 'Total loss': 0.4643770044269832}
2022-11-28 06:00:28,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:28,842 INFO:     Epoch: 52
2022-11-28 06:00:29,505 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4531766880642284, 'Total loss': 0.4531766880642284} | train loss {'Reaction outcome loss': 0.45843794763932827, 'Total loss': 0.45843794763932827}
2022-11-28 06:00:29,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:29,505 INFO:     Epoch: 53
2022-11-28 06:00:30,167 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42563677206635475, 'Total loss': 0.42563677206635475} | train loss {'Reaction outcome loss': 0.46435782509414775, 'Total loss': 0.46435782509414775}
2022-11-28 06:00:30,167 INFO:     Found new best model at epoch 53
2022-11-28 06:00:30,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:30,168 INFO:     Epoch: 54
2022-11-28 06:00:30,834 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46979163925756107, 'Total loss': 0.46979163925756107} | train loss {'Reaction outcome loss': 0.45963290647456523, 'Total loss': 0.45963290647456523}
2022-11-28 06:00:30,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:30,834 INFO:     Epoch: 55
2022-11-28 06:00:31,506 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45785679803653195, 'Total loss': 0.45785679803653195} | train loss {'Reaction outcome loss': 0.47004557023888177, 'Total loss': 0.47004557023888177}
2022-11-28 06:00:31,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:31,506 INFO:     Epoch: 56
2022-11-28 06:00:32,174 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44085645574060356, 'Total loss': 0.44085645574060356} | train loss {'Reaction outcome loss': 0.4589422553295066, 'Total loss': 0.4589422553295066}
2022-11-28 06:00:32,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:32,174 INFO:     Epoch: 57
2022-11-28 06:00:32,843 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42936149645935406, 'Total loss': 0.42936149645935406} | train loss {'Reaction outcome loss': 0.46750320216663455, 'Total loss': 0.46750320216663455}
2022-11-28 06:00:32,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:32,843 INFO:     Epoch: 58
2022-11-28 06:00:33,510 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4735211618244648, 'Total loss': 0.4735211618244648} | train loss {'Reaction outcome loss': 0.46085181796116387, 'Total loss': 0.46085181796116387}
2022-11-28 06:00:33,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:33,511 INFO:     Epoch: 59
2022-11-28 06:00:34,177 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44639296287840063, 'Total loss': 0.44639296287840063} | train loss {'Reaction outcome loss': 0.4612687926905358, 'Total loss': 0.4612687926905358}
2022-11-28 06:00:34,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:34,178 INFO:     Epoch: 60
2022-11-28 06:00:34,841 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46148570491509006, 'Total loss': 0.46148570491509006} | train loss {'Reaction outcome loss': 0.4555181280996364, 'Total loss': 0.4555181280996364}
2022-11-28 06:00:34,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:34,841 INFO:     Epoch: 61
2022-11-28 06:00:35,502 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.455522511493076, 'Total loss': 0.455522511493076} | train loss {'Reaction outcome loss': 0.44738398142430463, 'Total loss': 0.44738398142430463}
2022-11-28 06:00:35,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:35,503 INFO:     Epoch: 62
2022-11-28 06:00:36,163 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42585251785137435, 'Total loss': 0.42585251785137435} | train loss {'Reaction outcome loss': 0.4607081401504968, 'Total loss': 0.4607081401504968}
2022-11-28 06:00:36,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:36,163 INFO:     Epoch: 63
2022-11-28 06:00:36,822 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4590727443044836, 'Total loss': 0.4590727443044836} | train loss {'Reaction outcome loss': 0.46402918737426946, 'Total loss': 0.46402918737426946}
2022-11-28 06:00:36,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:36,822 INFO:     Epoch: 64
2022-11-28 06:00:37,484 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4478980800644918, 'Total loss': 0.4478980800644918} | train loss {'Reaction outcome loss': 0.4683715618302224, 'Total loss': 0.4683715618302224}
2022-11-28 06:00:37,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:37,484 INFO:     Epoch: 65
2022-11-28 06:00:38,149 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5058427053419027, 'Total loss': 0.5058427053419027} | train loss {'Reaction outcome loss': 0.4620547216189535, 'Total loss': 0.4620547216189535}
2022-11-28 06:00:38,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:38,150 INFO:     Epoch: 66
2022-11-28 06:00:38,811 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4655364995652979, 'Total loss': 0.4655364995652979} | train loss {'Reaction outcome loss': 0.4709885654313988, 'Total loss': 0.4709885654313988}
2022-11-28 06:00:38,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:38,811 INFO:     Epoch: 67
2022-11-28 06:00:39,473 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5051028220490976, 'Total loss': 0.5051028220490976} | train loss {'Reaction outcome loss': 0.4505266771022125, 'Total loss': 0.4505266771022125}
2022-11-28 06:00:39,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:39,473 INFO:     Epoch: 68
2022-11-28 06:00:40,134 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4549761895429004, 'Total loss': 0.4549761895429004} | train loss {'Reaction outcome loss': 0.4678906684643344, 'Total loss': 0.4678906684643344}
2022-11-28 06:00:40,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:40,135 INFO:     Epoch: 69
2022-11-28 06:00:40,795 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44518623873591423, 'Total loss': 0.44518623873591423} | train loss {'Reaction outcome loss': 0.4596390506706996, 'Total loss': 0.4596390506706996}
2022-11-28 06:00:40,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:40,795 INFO:     Epoch: 70
2022-11-28 06:00:41,455 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5074462694200602, 'Total loss': 0.5074462694200602} | train loss {'Reaction outcome loss': 0.45906412596946305, 'Total loss': 0.45906412596946305}
2022-11-28 06:00:41,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:41,455 INFO:     Epoch: 71
2022-11-28 06:00:42,112 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46299096433953807, 'Total loss': 0.46299096433953807} | train loss {'Reaction outcome loss': 0.45792319323973135, 'Total loss': 0.45792319323973135}
2022-11-28 06:00:42,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:42,112 INFO:     Epoch: 72
2022-11-28 06:00:42,767 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48359908908605576, 'Total loss': 0.48359908908605576} | train loss {'Reaction outcome loss': 0.46188267172589476, 'Total loss': 0.46188267172589476}
2022-11-28 06:00:42,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:42,767 INFO:     Epoch: 73
2022-11-28 06:00:43,423 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4394566294821826, 'Total loss': 0.4394566294821826} | train loss {'Reaction outcome loss': 0.456031996651217, 'Total loss': 0.456031996651217}
2022-11-28 06:00:43,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:43,423 INFO:     Epoch: 74
2022-11-28 06:00:44,082 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4458848551254381, 'Total loss': 0.4458848551254381} | train loss {'Reaction outcome loss': 0.46869449944872604, 'Total loss': 0.46869449944872604}
2022-11-28 06:00:44,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:44,082 INFO:     Epoch: 75
2022-11-28 06:00:44,741 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4592531912706115, 'Total loss': 0.4592531912706115} | train loss {'Reaction outcome loss': 0.4596610422574195, 'Total loss': 0.4596610422574195}
2022-11-28 06:00:44,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:44,741 INFO:     Epoch: 76
2022-11-28 06:00:45,400 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4500685442577709, 'Total loss': 0.4500685442577709} | train loss {'Reaction outcome loss': 0.4571276691003216, 'Total loss': 0.4571276691003216}
2022-11-28 06:00:45,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:45,400 INFO:     Epoch: 77
2022-11-28 06:00:46,064 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42805792357433925, 'Total loss': 0.42805792357433925} | train loss {'Reaction outcome loss': 0.4617831197827451, 'Total loss': 0.4617831197827451}
2022-11-28 06:00:46,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:46,064 INFO:     Epoch: 78
2022-11-28 06:00:46,722 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46877766061912884, 'Total loss': 0.46877766061912884} | train loss {'Reaction outcome loss': 0.45696560512504236, 'Total loss': 0.45696560512504236}
2022-11-28 06:00:46,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:46,722 INFO:     Epoch: 79
2022-11-28 06:00:47,383 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44640296968546783, 'Total loss': 0.44640296968546783} | train loss {'Reaction outcome loss': 0.4648546867269593, 'Total loss': 0.4648546867269593}
2022-11-28 06:00:47,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:47,383 INFO:     Epoch: 80
2022-11-28 06:00:48,048 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.484067805450071, 'Total loss': 0.484067805450071} | train loss {'Reaction outcome loss': 0.46300550118872996, 'Total loss': 0.46300550118872996}
2022-11-28 06:00:48,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:48,048 INFO:     Epoch: 81
2022-11-28 06:00:48,710 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45533915236592293, 'Total loss': 0.45533915236592293} | train loss {'Reaction outcome loss': 0.46566288233527287, 'Total loss': 0.46566288233527287}
2022-11-28 06:00:48,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:48,711 INFO:     Epoch: 82
2022-11-28 06:00:49,370 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4616407323628664, 'Total loss': 0.4616407323628664} | train loss {'Reaction outcome loss': 0.45508129559297056, 'Total loss': 0.45508129559297056}
2022-11-28 06:00:49,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:49,371 INFO:     Epoch: 83
2022-11-28 06:00:50,029 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4780365933071483, 'Total loss': 0.4780365933071483} | train loss {'Reaction outcome loss': 0.46623888123131957, 'Total loss': 0.46623888123131957}
2022-11-28 06:00:50,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:50,029 INFO:     Epoch: 84
2022-11-28 06:00:50,685 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47500317746942694, 'Total loss': 0.47500317746942694} | train loss {'Reaction outcome loss': 0.4609277357294522, 'Total loss': 0.4609277357294522}
2022-11-28 06:00:50,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:50,685 INFO:     Epoch: 85
2022-11-28 06:00:51,341 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4409946138885888, 'Total loss': 0.4409946138885888} | train loss {'Reaction outcome loss': 0.4675221758091498, 'Total loss': 0.4675221758091498}
2022-11-28 06:00:51,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:51,341 INFO:     Epoch: 86
2022-11-28 06:00:52,002 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44437178021127527, 'Total loss': 0.44437178021127527} | train loss {'Reaction outcome loss': 0.4752892707040918, 'Total loss': 0.4752892707040918}
2022-11-28 06:00:52,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:52,002 INFO:     Epoch: 87
2022-11-28 06:00:52,662 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4849247960373759, 'Total loss': 0.4849247960373759} | train loss {'Reaction outcome loss': 0.4680810608723868, 'Total loss': 0.4680810608723868}
2022-11-28 06:00:52,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:52,663 INFO:     Epoch: 88
2022-11-28 06:00:53,327 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4546919461678375, 'Total loss': 0.4546919461678375} | train loss {'Reaction outcome loss': 0.4628989676594252, 'Total loss': 0.4628989676594252}
2022-11-28 06:00:53,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:53,327 INFO:     Epoch: 89
2022-11-28 06:00:53,983 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45835204693404114, 'Total loss': 0.45835204693404114} | train loss {'Reaction outcome loss': 0.4570319745463398, 'Total loss': 0.4570319745463398}
2022-11-28 06:00:53,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:53,984 INFO:     Epoch: 90
2022-11-28 06:00:54,643 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45320443334904587, 'Total loss': 0.45320443334904587} | train loss {'Reaction outcome loss': 0.4600104485084171, 'Total loss': 0.4600104485084171}
2022-11-28 06:00:54,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:54,643 INFO:     Epoch: 91
2022-11-28 06:00:55,299 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49693885682658717, 'Total loss': 0.49693885682658717} | train loss {'Reaction outcome loss': 0.4586482022696661, 'Total loss': 0.4586482022696661}
2022-11-28 06:00:55,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:55,299 INFO:     Epoch: 92
2022-11-28 06:00:55,962 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47771682488647377, 'Total loss': 0.47771682488647377} | train loss {'Reaction outcome loss': 0.4545678133484323, 'Total loss': 0.4545678133484323}
2022-11-28 06:00:55,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:55,962 INFO:     Epoch: 93
2022-11-28 06:00:56,621 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4857888573949987, 'Total loss': 0.4857888573949987} | train loss {'Reaction outcome loss': 0.4620821747461311, 'Total loss': 0.4620821747461311}
2022-11-28 06:00:56,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:56,621 INFO:     Epoch: 94
2022-11-28 06:00:57,278 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4659241465005008, 'Total loss': 0.4659241465005008} | train loss {'Reaction outcome loss': 0.46512831138213157, 'Total loss': 0.46512831138213157}
2022-11-28 06:00:57,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:57,278 INFO:     Epoch: 95
2022-11-28 06:00:57,938 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4406030811369419, 'Total loss': 0.4406030811369419} | train loss {'Reaction outcome loss': 0.4642945381130284, 'Total loss': 0.4642945381130284}
2022-11-28 06:00:57,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:57,938 INFO:     Epoch: 96
2022-11-28 06:00:58,600 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4416520172222094, 'Total loss': 0.4416520172222094} | train loss {'Reaction outcome loss': 0.46053569658323823, 'Total loss': 0.46053569658323823}
2022-11-28 06:00:58,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:58,600 INFO:     Epoch: 97
2022-11-28 06:00:59,265 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4766899584369226, 'Total loss': 0.4766899584369226} | train loss {'Reaction outcome loss': 0.46844245665348494, 'Total loss': 0.46844245665348494}
2022-11-28 06:00:59,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:59,265 INFO:     Epoch: 98
2022-11-28 06:00:59,924 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4876480021260001, 'Total loss': 0.4876480021260001} | train loss {'Reaction outcome loss': 0.4684315788359777, 'Total loss': 0.4684315788359777}
2022-11-28 06:00:59,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:00:59,924 INFO:     Epoch: 99
2022-11-28 06:01:00,583 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45750982957807457, 'Total loss': 0.45750982957807457} | train loss {'Reaction outcome loss': 0.4677342171007805, 'Total loss': 0.4677342171007805}
2022-11-28 06:01:00,583 INFO:     Best model found after epoch 54 of 100.
2022-11-28 06:01:00,583 INFO:   Done with stage: TRAINING
2022-11-28 06:01:00,583 INFO:   Starting stage: EVALUATION
2022-11-28 06:01:00,701 INFO:   Done with stage: EVALUATION
2022-11-28 06:01:00,702 INFO:   Leaving out SEQ value Fold_9
2022-11-28 06:01:00,714 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 06:01:00,714 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:01:01,352 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:01:01,352 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:01:01,422 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:01:01,422 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:01:01,422 INFO:     No hyperparam tuning for this model
2022-11-28 06:01:01,422 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:01:01,423 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:01:01,423 INFO:     None feature selector for col prot
2022-11-28 06:01:01,423 INFO:     None feature selector for col prot
2022-11-28 06:01:01,423 INFO:     None feature selector for col prot
2022-11-28 06:01:01,424 INFO:     None feature selector for col chem
2022-11-28 06:01:01,424 INFO:     None feature selector for col chem
2022-11-28 06:01:01,424 INFO:     None feature selector for col chem
2022-11-28 06:01:01,424 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:01:01,424 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:01:01,426 INFO:     Number of params in model 169651
2022-11-28 06:01:01,429 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:01:01,429 INFO:   Starting stage: TRAINING
2022-11-28 06:01:01,480 INFO:     Val loss before train {'Reaction outcome loss': 1.0109635605053469, 'Total loss': 1.0109635605053469}
2022-11-28 06:01:01,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:01,480 INFO:     Epoch: 0
2022-11-28 06:01:02,141 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6406315063888376, 'Total loss': 0.6406315063888376} | train loss {'Reaction outcome loss': 0.7044317452614064, 'Total loss': 0.7044317452614064}
2022-11-28 06:01:02,141 INFO:     Found new best model at epoch 0
2022-11-28 06:01:02,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:02,142 INFO:     Epoch: 1
2022-11-28 06:01:02,800 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5447466231205247, 'Total loss': 0.5447466231205247} | train loss {'Reaction outcome loss': 0.6076121309146225, 'Total loss': 0.6076121309146225}
2022-11-28 06:01:02,801 INFO:     Found new best model at epoch 1
2022-11-28 06:01:02,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:02,801 INFO:     Epoch: 2
2022-11-28 06:01:03,461 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.542775938118046, 'Total loss': 0.542775938118046} | train loss {'Reaction outcome loss': 0.5786405960437258, 'Total loss': 0.5786405960437258}
2022-11-28 06:01:03,462 INFO:     Found new best model at epoch 2
2022-11-28 06:01:03,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:03,462 INFO:     Epoch: 3
2022-11-28 06:01:04,123 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5230847895145416, 'Total loss': 0.5230847895145416} | train loss {'Reaction outcome loss': 0.5638417836565238, 'Total loss': 0.5638417836565238}
2022-11-28 06:01:04,123 INFO:     Found new best model at epoch 3
2022-11-28 06:01:04,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:04,124 INFO:     Epoch: 4
2022-11-28 06:01:04,786 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5075927908447656, 'Total loss': 0.5075927908447656} | train loss {'Reaction outcome loss': 0.548349672664515, 'Total loss': 0.548349672664515}
2022-11-28 06:01:04,787 INFO:     Found new best model at epoch 4
2022-11-28 06:01:04,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:04,788 INFO:     Epoch: 5
2022-11-28 06:01:05,447 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5157471996816722, 'Total loss': 0.5157471996816722} | train loss {'Reaction outcome loss': 0.535517765533345, 'Total loss': 0.535517765533345}
2022-11-28 06:01:05,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:05,447 INFO:     Epoch: 6
2022-11-28 06:01:06,108 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5270060802047903, 'Total loss': 0.5270060802047903} | train loss {'Reaction outcome loss': 0.5206939780383337, 'Total loss': 0.5206939780383337}
2022-11-28 06:01:06,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:06,108 INFO:     Epoch: 7
2022-11-28 06:01:06,768 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5437422103502534, 'Total loss': 0.5437422103502534} | train loss {'Reaction outcome loss': 0.5246915182603998, 'Total loss': 0.5246915182603998}
2022-11-28 06:01:06,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:06,768 INFO:     Epoch: 8
2022-11-28 06:01:07,425 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49600090323524043, 'Total loss': 0.49600090323524043} | train loss {'Reaction outcome loss': 0.5215182327910474, 'Total loss': 0.5215182327910474}
2022-11-28 06:01:07,425 INFO:     Found new best model at epoch 8
2022-11-28 06:01:07,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:07,426 INFO:     Epoch: 9
2022-11-28 06:01:08,082 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46840561587702145, 'Total loss': 0.46840561587702145} | train loss {'Reaction outcome loss': 0.5218806715026075, 'Total loss': 0.5218806715026075}
2022-11-28 06:01:08,082 INFO:     Found new best model at epoch 9
2022-11-28 06:01:08,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:08,083 INFO:     Epoch: 10
2022-11-28 06:01:08,740 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47535024786537344, 'Total loss': 0.47535024786537344} | train loss {'Reaction outcome loss': 0.5138276452424857, 'Total loss': 0.5138276452424857}
2022-11-28 06:01:08,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:08,740 INFO:     Epoch: 11
2022-11-28 06:01:09,398 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5066956522112543, 'Total loss': 0.5066956522112543} | train loss {'Reaction outcome loss': 0.5037678019237904, 'Total loss': 0.5037678019237904}
2022-11-28 06:01:09,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:09,398 INFO:     Epoch: 12
2022-11-28 06:01:10,059 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4727183637971228, 'Total loss': 0.4727183637971228} | train loss {'Reaction outcome loss': 0.5124093936039851, 'Total loss': 0.5124093936039851}
2022-11-28 06:01:10,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:10,059 INFO:     Epoch: 13
2022-11-28 06:01:10,718 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5015503107146784, 'Total loss': 0.5015503107146784} | train loss {'Reaction outcome loss': 0.5071764363330385, 'Total loss': 0.5071764363330385}
2022-11-28 06:01:10,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:10,719 INFO:     Epoch: 14
2022-11-28 06:01:11,378 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45665250752459874, 'Total loss': 0.45665250752459874} | train loss {'Reaction outcome loss': 0.5001153545944315, 'Total loss': 0.5001153545944315}
2022-11-28 06:01:11,379 INFO:     Found new best model at epoch 14
2022-11-28 06:01:11,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:11,380 INFO:     Epoch: 15
2022-11-28 06:01:12,039 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48533098450438544, 'Total loss': 0.48533098450438544} | train loss {'Reaction outcome loss': 0.5066114589873596, 'Total loss': 0.5066114589873596}
2022-11-28 06:01:12,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:12,039 INFO:     Epoch: 16
2022-11-28 06:01:12,698 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4735859195617112, 'Total loss': 0.4735859195617112} | train loss {'Reaction outcome loss': 0.4921171960198445, 'Total loss': 0.4921171960198445}
2022-11-28 06:01:12,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:12,698 INFO:     Epoch: 17
2022-11-28 06:01:13,358 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4708738618276336, 'Total loss': 0.4708738618276336} | train loss {'Reaction outcome loss': 0.5057242454184212, 'Total loss': 0.5057242454184212}
2022-11-28 06:01:13,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:13,358 INFO:     Epoch: 18
2022-11-28 06:01:14,016 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48778824135661125, 'Total loss': 0.48778824135661125} | train loss {'Reaction outcome loss': 0.49167167126891104, 'Total loss': 0.49167167126891104}
2022-11-28 06:01:14,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:14,017 INFO:     Epoch: 19
2022-11-28 06:01:14,675 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5104315917600285, 'Total loss': 0.5104315917600285} | train loss {'Reaction outcome loss': 0.4967656338263137, 'Total loss': 0.4967656338263137}
2022-11-28 06:01:14,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:14,676 INFO:     Epoch: 20
2022-11-28 06:01:15,333 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.461963758549907, 'Total loss': 0.461963758549907} | train loss {'Reaction outcome loss': 0.5111994640788569, 'Total loss': 0.5111994640788569}
2022-11-28 06:01:15,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:15,333 INFO:     Epoch: 21
2022-11-28 06:01:15,994 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4959083307873119, 'Total loss': 0.4959083307873119} | train loss {'Reaction outcome loss': 0.4952371421794177, 'Total loss': 0.4952371421794177}
2022-11-28 06:01:15,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:15,994 INFO:     Epoch: 22
2022-11-28 06:01:16,651 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4874166297641667, 'Total loss': 0.4874166297641667} | train loss {'Reaction outcome loss': 0.5020057492048634, 'Total loss': 0.5020057492048634}
2022-11-28 06:01:16,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:16,651 INFO:     Epoch: 23
2022-11-28 06:01:17,311 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4947304834019054, 'Total loss': 0.4947304834019054} | train loss {'Reaction outcome loss': 0.498525766889576, 'Total loss': 0.498525766889576}
2022-11-28 06:01:17,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:17,311 INFO:     Epoch: 24
2022-11-28 06:01:17,970 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4687773327935826, 'Total loss': 0.4687773327935826} | train loss {'Reaction outcome loss': 0.4921694815098515, 'Total loss': 0.4921694815098515}
2022-11-28 06:01:17,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:17,970 INFO:     Epoch: 25
2022-11-28 06:01:18,627 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49134566296230664, 'Total loss': 0.49134566296230664} | train loss {'Reaction outcome loss': 0.4979139821611435, 'Total loss': 0.4979139821611435}
2022-11-28 06:01:18,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:18,628 INFO:     Epoch: 26
2022-11-28 06:01:19,285 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4798618599095128, 'Total loss': 0.4798618599095128} | train loss {'Reaction outcome loss': 0.4949460269106544, 'Total loss': 0.4949460269106544}
2022-11-28 06:01:19,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:19,286 INFO:     Epoch: 27
2022-11-28 06:01:19,951 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46034263175996865, 'Total loss': 0.46034263175996865} | train loss {'Reaction outcome loss': 0.4914080699083776, 'Total loss': 0.4914080699083776}
2022-11-28 06:01:19,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:19,951 INFO:     Epoch: 28
2022-11-28 06:01:20,613 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49303533272309735, 'Total loss': 0.49303533272309735} | train loss {'Reaction outcome loss': 0.48675576623845923, 'Total loss': 0.48675576623845923}
2022-11-28 06:01:20,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:20,614 INFO:     Epoch: 29
2022-11-28 06:01:21,274 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49797971004789526, 'Total loss': 0.49797971004789526} | train loss {'Reaction outcome loss': 0.4879197076505978, 'Total loss': 0.4879197076505978}
2022-11-28 06:01:21,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:21,274 INFO:     Epoch: 30
2022-11-28 06:01:21,940 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4731934692033313, 'Total loss': 0.4731934692033313} | train loss {'Reaction outcome loss': 0.49358203232303444, 'Total loss': 0.49358203232303444}
2022-11-28 06:01:21,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:21,940 INFO:     Epoch: 31
2022-11-28 06:01:22,600 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48858091506091034, 'Total loss': 0.48858091506091034} | train loss {'Reaction outcome loss': 0.49005347013714823, 'Total loss': 0.49005347013714823}
2022-11-28 06:01:22,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:22,600 INFO:     Epoch: 32
2022-11-28 06:01:23,261 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47252649238163774, 'Total loss': 0.47252649238163774} | train loss {'Reaction outcome loss': 0.4872967009602288, 'Total loss': 0.4872967009602288}
2022-11-28 06:01:23,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:23,261 INFO:     Epoch: 33
2022-11-28 06:01:23,923 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46283708910711785, 'Total loss': 0.46283708910711785} | train loss {'Reaction outcome loss': 0.4821013773259846, 'Total loss': 0.4821013773259846}
2022-11-28 06:01:23,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:23,924 INFO:     Epoch: 34
2022-11-28 06:01:24,586 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4613731381568042, 'Total loss': 0.4613731381568042} | train loss {'Reaction outcome loss': 0.49272382138711723, 'Total loss': 0.49272382138711723}
2022-11-28 06:01:24,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:24,586 INFO:     Epoch: 35
2022-11-28 06:01:25,242 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4567004550587047, 'Total loss': 0.4567004550587047} | train loss {'Reaction outcome loss': 0.4915062922697801, 'Total loss': 0.4915062922697801}
2022-11-28 06:01:25,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:25,242 INFO:     Epoch: 36
2022-11-28 06:01:25,904 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4843342432921583, 'Total loss': 0.4843342432921583} | train loss {'Reaction outcome loss': 0.4918182495272594, 'Total loss': 0.4918182495272594}
2022-11-28 06:01:25,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:25,904 INFO:     Epoch: 37
2022-11-28 06:01:26,563 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4702730090780692, 'Total loss': 0.4702730090780692} | train loss {'Reaction outcome loss': 0.49929309452352255, 'Total loss': 0.49929309452352255}
2022-11-28 06:01:26,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:26,563 INFO:     Epoch: 38
2022-11-28 06:01:27,223 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4542014720765027, 'Total loss': 0.4542014720765027} | train loss {'Reaction outcome loss': 0.4867458843441326, 'Total loss': 0.4867458843441326}
2022-11-28 06:01:27,223 INFO:     Found new best model at epoch 38
2022-11-28 06:01:27,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:27,224 INFO:     Epoch: 39
2022-11-28 06:01:27,883 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43853600255467673, 'Total loss': 0.43853600255467673} | train loss {'Reaction outcome loss': 0.49013045774056363, 'Total loss': 0.49013045774056363}
2022-11-28 06:01:27,883 INFO:     Found new best model at epoch 39
2022-11-28 06:01:27,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:27,884 INFO:     Epoch: 40
2022-11-28 06:01:28,546 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4674187654798681, 'Total loss': 0.4674187654798681} | train loss {'Reaction outcome loss': 0.48993337721477154, 'Total loss': 0.48993337721477154}
2022-11-28 06:01:28,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:28,546 INFO:     Epoch: 41
2022-11-28 06:01:29,206 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47432856261730194, 'Total loss': 0.47432856261730194} | train loss {'Reaction outcome loss': 0.491642027067752, 'Total loss': 0.491642027067752}
2022-11-28 06:01:29,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:29,206 INFO:     Epoch: 42
2022-11-28 06:01:29,864 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4850133274766532, 'Total loss': 0.4850133274766532} | train loss {'Reaction outcome loss': 0.4964593925517098, 'Total loss': 0.4964593925517098}
2022-11-28 06:01:29,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:29,864 INFO:     Epoch: 43
2022-11-28 06:01:30,524 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4836500016125766, 'Total loss': 0.4836500016125766} | train loss {'Reaction outcome loss': 0.4811105966447336, 'Total loss': 0.4811105966447336}
2022-11-28 06:01:30,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:30,524 INFO:     Epoch: 44
2022-11-28 06:01:31,183 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46696343509988353, 'Total loss': 0.46696343509988353} | train loss {'Reaction outcome loss': 0.48404934607174716, 'Total loss': 0.48404934607174716}
2022-11-28 06:01:31,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:31,183 INFO:     Epoch: 45
2022-11-28 06:01:31,842 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4651774520223791, 'Total loss': 0.4651774520223791} | train loss {'Reaction outcome loss': 0.48468660566246946, 'Total loss': 0.48468660566246946}
2022-11-28 06:01:31,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:31,842 INFO:     Epoch: 46
2022-11-28 06:01:32,499 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4720315012064847, 'Total loss': 0.4720315012064847} | train loss {'Reaction outcome loss': 0.5006066303142169, 'Total loss': 0.5006066303142169}
2022-11-28 06:01:32,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:32,499 INFO:     Epoch: 47
2022-11-28 06:01:33,163 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46472146294333716, 'Total loss': 0.46472146294333716} | train loss {'Reaction outcome loss': 0.4968382051961142, 'Total loss': 0.4968382051961142}
2022-11-28 06:01:33,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:33,163 INFO:     Epoch: 48
2022-11-28 06:01:33,825 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5246956897052851, 'Total loss': 0.5246956897052851} | train loss {'Reaction outcome loss': 0.47945201559829326, 'Total loss': 0.47945201559829326}
2022-11-28 06:01:33,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:33,826 INFO:     Epoch: 49
2022-11-28 06:01:34,487 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4505061713809317, 'Total loss': 0.4505061713809317} | train loss {'Reaction outcome loss': 0.485277163656617, 'Total loss': 0.485277163656617}
2022-11-28 06:01:34,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:34,488 INFO:     Epoch: 50
2022-11-28 06:01:35,150 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4658879901875149, 'Total loss': 0.4658879901875149} | train loss {'Reaction outcome loss': 0.48648032085849385, 'Total loss': 0.48648032085849385}
2022-11-28 06:01:35,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:35,150 INFO:     Epoch: 51
2022-11-28 06:01:35,811 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46331789378415456, 'Total loss': 0.46331789378415456} | train loss {'Reaction outcome loss': 0.48451762945063204, 'Total loss': 0.48451762945063204}
2022-11-28 06:01:35,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:35,812 INFO:     Epoch: 52
2022-11-28 06:01:36,475 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5188069245354696, 'Total loss': 0.5188069245354696} | train loss {'Reaction outcome loss': 0.4937217291067486, 'Total loss': 0.4937217291067486}
2022-11-28 06:01:36,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:36,475 INFO:     Epoch: 53
2022-11-28 06:01:37,137 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4868864386596463, 'Total loss': 0.4868864386596463} | train loss {'Reaction outcome loss': 0.49652708005084684, 'Total loss': 0.49652708005084684}
2022-11-28 06:01:37,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:37,137 INFO:     Epoch: 54
2022-11-28 06:01:37,798 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46988644992763345, 'Total loss': 0.46988644992763345} | train loss {'Reaction outcome loss': 0.48325322218510786, 'Total loss': 0.48325322218510786}
2022-11-28 06:01:37,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:37,799 INFO:     Epoch: 55
2022-11-28 06:01:38,462 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48076501387086784, 'Total loss': 0.48076501387086784} | train loss {'Reaction outcome loss': 0.49067667868697207, 'Total loss': 0.49067667868697207}
2022-11-28 06:01:38,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:38,462 INFO:     Epoch: 56
2022-11-28 06:01:39,121 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43579863892360166, 'Total loss': 0.43579863892360166} | train loss {'Reaction outcome loss': 0.48727497971250944, 'Total loss': 0.48727497971250944}
2022-11-28 06:01:39,121 INFO:     Found new best model at epoch 56
2022-11-28 06:01:39,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:39,122 INFO:     Epoch: 57
2022-11-28 06:01:39,783 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4593796089968898, 'Total loss': 0.4593796089968898} | train loss {'Reaction outcome loss': 0.48337857211046376, 'Total loss': 0.48337857211046376}
2022-11-28 06:01:39,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:39,783 INFO:     Epoch: 58
2022-11-28 06:01:40,445 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45288010517304594, 'Total loss': 0.45288010517304594} | train loss {'Reaction outcome loss': 0.47764927286632086, 'Total loss': 0.47764927286632086}
2022-11-28 06:01:40,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:40,445 INFO:     Epoch: 59
2022-11-28 06:01:41,105 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4755994521758773, 'Total loss': 0.4755994521758773} | train loss {'Reaction outcome loss': 0.4849745064732517, 'Total loss': 0.4849745064732517}
2022-11-28 06:01:41,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:41,105 INFO:     Epoch: 60
2022-11-28 06:01:41,766 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.489252277395942, 'Total loss': 0.489252277395942} | train loss {'Reaction outcome loss': 0.48313198941439267, 'Total loss': 0.48313198941439267}
2022-11-28 06:01:41,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:41,766 INFO:     Epoch: 61
2022-11-28 06:01:42,427 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47665781290693715, 'Total loss': 0.47665781290693715} | train loss {'Reaction outcome loss': 0.4815614812588885, 'Total loss': 0.4815614812588885}
2022-11-28 06:01:42,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:42,427 INFO:     Epoch: 62
2022-11-28 06:01:43,088 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4441007660193877, 'Total loss': 0.4441007660193877} | train loss {'Reaction outcome loss': 0.4861715577150646, 'Total loss': 0.4861715577150646}
2022-11-28 06:01:43,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:43,088 INFO:     Epoch: 63
2022-11-28 06:01:43,749 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47396097603169357, 'Total loss': 0.47396097603169357} | train loss {'Reaction outcome loss': 0.4880871849986706, 'Total loss': 0.4880871849986706}
2022-11-28 06:01:43,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:43,750 INFO:     Epoch: 64
2022-11-28 06:01:44,412 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47494460303675046, 'Total loss': 0.47494460303675046} | train loss {'Reaction outcome loss': 0.4855854157886283, 'Total loss': 0.4855854157886283}
2022-11-28 06:01:44,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:44,412 INFO:     Epoch: 65
2022-11-28 06:01:45,070 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44724819098006596, 'Total loss': 0.44724819098006596} | train loss {'Reaction outcome loss': 0.48183207002728573, 'Total loss': 0.48183207002728573}
2022-11-28 06:01:45,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:45,070 INFO:     Epoch: 66
2022-11-28 06:01:45,729 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4517239389771765, 'Total loss': 0.4517239389771765} | train loss {'Reaction outcome loss': 0.4871255788906866, 'Total loss': 0.4871255788906866}
2022-11-28 06:01:45,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:45,729 INFO:     Epoch: 67
2022-11-28 06:01:46,387 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4359128861264749, 'Total loss': 0.4359128861264749} | train loss {'Reaction outcome loss': 0.4966820522304813, 'Total loss': 0.4966820522304813}
2022-11-28 06:01:46,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:46,387 INFO:     Epoch: 68
2022-11-28 06:01:47,047 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4432963742451234, 'Total loss': 0.4432963742451234} | train loss {'Reaction outcome loss': 0.48409775892924894, 'Total loss': 0.48409775892924894}
2022-11-28 06:01:47,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:47,047 INFO:     Epoch: 69
2022-11-28 06:01:47,708 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48009173572063446, 'Total loss': 0.48009173572063446} | train loss {'Reaction outcome loss': 0.48894926778941983, 'Total loss': 0.48894926778941983}
2022-11-28 06:01:47,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:47,708 INFO:     Epoch: 70
2022-11-28 06:01:48,371 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4498138857836073, 'Total loss': 0.4498138857836073} | train loss {'Reaction outcome loss': 0.48174799971380516, 'Total loss': 0.48174799971380516}
2022-11-28 06:01:48,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:48,371 INFO:     Epoch: 71
2022-11-28 06:01:49,030 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4774483659050681, 'Total loss': 0.4774483659050681} | train loss {'Reaction outcome loss': 0.4897770720575503, 'Total loss': 0.4897770720575503}
2022-11-28 06:01:49,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:49,030 INFO:     Epoch: 72
2022-11-28 06:01:49,692 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44581010802225635, 'Total loss': 0.44581010802225635} | train loss {'Reaction outcome loss': 0.49441103245082657, 'Total loss': 0.49441103245082657}
2022-11-28 06:01:49,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:49,692 INFO:     Epoch: 73
2022-11-28 06:01:50,355 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4667058597234162, 'Total loss': 0.4667058597234162} | train loss {'Reaction outcome loss': 0.484012301453212, 'Total loss': 0.484012301453212}
2022-11-28 06:01:50,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:50,355 INFO:     Epoch: 74
2022-11-28 06:01:51,021 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4593332985585386, 'Total loss': 0.4593332985585386} | train loss {'Reaction outcome loss': 0.500558824191692, 'Total loss': 0.500558824191692}
2022-11-28 06:01:51,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:51,021 INFO:     Epoch: 75
2022-11-28 06:01:51,684 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4792785800316117, 'Total loss': 0.4792785800316117} | train loss {'Reaction outcome loss': 0.4795939389480512, 'Total loss': 0.4795939389480512}
2022-11-28 06:01:51,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:51,684 INFO:     Epoch: 76
2022-11-28 06:01:52,347 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5057210498912768, 'Total loss': 0.5057210498912768} | train loss {'Reaction outcome loss': 0.4768201816352914, 'Total loss': 0.4768201816352914}
2022-11-28 06:01:52,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:52,347 INFO:     Epoch: 77
2022-11-28 06:01:53,010 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4531797417862849, 'Total loss': 0.4531797417862849} | train loss {'Reaction outcome loss': 0.48326864790337287, 'Total loss': 0.48326864790337287}
2022-11-28 06:01:53,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:53,010 INFO:     Epoch: 78
2022-11-28 06:01:53,667 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44835457679900254, 'Total loss': 0.44835457679900254} | train loss {'Reaction outcome loss': 0.4783546703185147, 'Total loss': 0.4783546703185147}
2022-11-28 06:01:53,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:53,667 INFO:     Epoch: 79
2022-11-28 06:01:54,327 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47787811200727115, 'Total loss': 0.47787811200727115} | train loss {'Reaction outcome loss': 0.4772821526054429, 'Total loss': 0.4772821526054429}
2022-11-28 06:01:54,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:54,328 INFO:     Epoch: 80
2022-11-28 06:01:54,989 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4857119426808574, 'Total loss': 0.4857119426808574} | train loss {'Reaction outcome loss': 0.48521035131413925, 'Total loss': 0.48521035131413925}
2022-11-28 06:01:54,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:54,990 INFO:     Epoch: 81
2022-11-28 06:01:55,651 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4557544213127006, 'Total loss': 0.4557544213127006} | train loss {'Reaction outcome loss': 0.4848499195537104, 'Total loss': 0.4848499195537104}
2022-11-28 06:01:55,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:55,651 INFO:     Epoch: 82
2022-11-28 06:01:56,312 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46848598156463017, 'Total loss': 0.46848598156463017} | train loss {'Reaction outcome loss': 0.4747376183011599, 'Total loss': 0.4747376183011599}
2022-11-28 06:01:56,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:56,312 INFO:     Epoch: 83
2022-11-28 06:01:56,971 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4678269018503753, 'Total loss': 0.4678269018503753} | train loss {'Reaction outcome loss': 0.4835970571480488, 'Total loss': 0.4835970571480488}
2022-11-28 06:01:56,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:56,971 INFO:     Epoch: 84
2022-11-28 06:01:57,630 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4635251442139799, 'Total loss': 0.4635251442139799} | train loss {'Reaction outcome loss': 0.4739298504373805, 'Total loss': 0.4739298504373805}
2022-11-28 06:01:57,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:57,631 INFO:     Epoch: 85
2022-11-28 06:01:58,287 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4694064489819787, 'Total loss': 0.4694064489819787} | train loss {'Reaction outcome loss': 0.4877847684358778, 'Total loss': 0.4877847684358778}
2022-11-28 06:01:58,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:58,287 INFO:     Epoch: 86
2022-11-28 06:01:58,944 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4662863395430825, 'Total loss': 0.4662863395430825} | train loss {'Reaction outcome loss': 0.4782579821131007, 'Total loss': 0.4782579821131007}
2022-11-28 06:01:58,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:58,945 INFO:     Epoch: 87
2022-11-28 06:01:59,601 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4382642561739141, 'Total loss': 0.4382642561739141} | train loss {'Reaction outcome loss': 0.48567043226174555, 'Total loss': 0.48567043226174555}
2022-11-28 06:01:59,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:01:59,602 INFO:     Epoch: 88
2022-11-28 06:02:00,257 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4586389288306236, 'Total loss': 0.4586389288306236} | train loss {'Reaction outcome loss': 0.4805046943759146, 'Total loss': 0.4805046943759146}
2022-11-28 06:02:00,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:00,257 INFO:     Epoch: 89
2022-11-28 06:02:00,916 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49749854511835356, 'Total loss': 0.49749854511835356} | train loss {'Reaction outcome loss': 0.4900506781602678, 'Total loss': 0.4900506781602678}
2022-11-28 06:02:00,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:00,916 INFO:     Epoch: 90
2022-11-28 06:02:01,572 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44580199840393936, 'Total loss': 0.44580199840393936} | train loss {'Reaction outcome loss': 0.48129786314963086, 'Total loss': 0.48129786314963086}
2022-11-28 06:02:01,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:01,572 INFO:     Epoch: 91
2022-11-28 06:02:02,231 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46245711601593276, 'Total loss': 0.46245711601593276} | train loss {'Reaction outcome loss': 0.4781506050393166, 'Total loss': 0.4781506050393166}
2022-11-28 06:02:02,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:02,231 INFO:     Epoch: 92
2022-11-28 06:02:02,889 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4951957955279134, 'Total loss': 0.4951957955279134} | train loss {'Reaction outcome loss': 0.47896860352894555, 'Total loss': 0.47896860352894555}
2022-11-28 06:02:02,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:02,890 INFO:     Epoch: 93
2022-11-28 06:02:03,549 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49461200511591, 'Total loss': 0.49461200511591} | train loss {'Reaction outcome loss': 0.4918550398607968, 'Total loss': 0.4918550398607968}
2022-11-28 06:02:03,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:03,549 INFO:     Epoch: 94
2022-11-28 06:02:04,205 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4703734422271902, 'Total loss': 0.4703734422271902} | train loss {'Reaction outcome loss': 0.4863962732587266, 'Total loss': 0.4863962732587266}
2022-11-28 06:02:04,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:04,206 INFO:     Epoch: 95
2022-11-28 06:02:04,865 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.462372347373854, 'Total loss': 0.462372347373854} | train loss {'Reaction outcome loss': 0.4824335499089739, 'Total loss': 0.4824335499089739}
2022-11-28 06:02:04,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:04,865 INFO:     Epoch: 96
2022-11-28 06:02:05,522 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46157489818605507, 'Total loss': 0.46157489818605507} | train loss {'Reaction outcome loss': 0.50264335037605, 'Total loss': 0.50264335037605}
2022-11-28 06:02:05,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:05,522 INFO:     Epoch: 97
2022-11-28 06:02:06,181 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4648527685891498, 'Total loss': 0.4648527685891498} | train loss {'Reaction outcome loss': 0.4903833715222504, 'Total loss': 0.4903833715222504}
2022-11-28 06:02:06,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:06,182 INFO:     Epoch: 98
2022-11-28 06:02:06,836 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4591701684350317, 'Total loss': 0.4591701684350317} | train loss {'Reaction outcome loss': 0.4705039518654369, 'Total loss': 0.4705039518654369}
2022-11-28 06:02:06,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:06,837 INFO:     Epoch: 99
2022-11-28 06:02:07,493 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4914835278283466, 'Total loss': 0.4914835278283466} | train loss {'Reaction outcome loss': 0.47912624243058655, 'Total loss': 0.47912624243058655}
2022-11-28 06:02:07,493 INFO:     Best model found after epoch 57 of 100.
2022-11-28 06:02:07,493 INFO:   Done with stage: TRAINING
2022-11-28 06:02:07,493 INFO:   Starting stage: EVALUATION
2022-11-28 06:02:07,612 INFO:   Done with stage: EVALUATION
2022-11-28 06:02:07,620 INFO:   Leaving out SEQ value Fold_0
2022-11-28 06:02:07,633 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 06:02:07,633 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:02:08,264 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:02:08,264 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:02:08,334 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:02:08,334 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:02:08,334 INFO:     No hyperparam tuning for this model
2022-11-28 06:02:08,334 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:02:08,334 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:02:08,335 INFO:     None feature selector for col prot
2022-11-28 06:02:08,335 INFO:     None feature selector for col prot
2022-11-28 06:02:08,335 INFO:     None feature selector for col prot
2022-11-28 06:02:08,335 INFO:     None feature selector for col chem
2022-11-28 06:02:08,336 INFO:     None feature selector for col chem
2022-11-28 06:02:08,336 INFO:     None feature selector for col chem
2022-11-28 06:02:08,336 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:02:08,336 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:02:08,337 INFO:     Number of params in model 169651
2022-11-28 06:02:08,340 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:02:08,340 INFO:   Starting stage: TRAINING
2022-11-28 06:02:08,391 INFO:     Val loss before train {'Reaction outcome loss': 0.9673710512843999, 'Total loss': 0.9673710512843999}
2022-11-28 06:02:08,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:08,391 INFO:     Epoch: 0
2022-11-28 06:02:09,048 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.567897504703565, 'Total loss': 0.567897504703565} | train loss {'Reaction outcome loss': 0.6941393898457897, 'Total loss': 0.6941393898457897}
2022-11-28 06:02:09,048 INFO:     Found new best model at epoch 0
2022-11-28 06:02:09,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:09,049 INFO:     Epoch: 1
2022-11-28 06:02:09,706 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5553857924585993, 'Total loss': 0.5553857924585993} | train loss {'Reaction outcome loss': 0.5863450227951517, 'Total loss': 0.5863450227951517}
2022-11-28 06:02:09,706 INFO:     Found new best model at epoch 1
2022-11-28 06:02:09,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:09,707 INFO:     Epoch: 2
2022-11-28 06:02:10,361 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5610336566513235, 'Total loss': 0.5610336566513235} | train loss {'Reaction outcome loss': 0.5488499371981134, 'Total loss': 0.5488499371981134}
2022-11-28 06:02:10,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:10,362 INFO:     Epoch: 3
2022-11-28 06:02:11,020 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5309674420859665, 'Total loss': 0.5309674420859665} | train loss {'Reaction outcome loss': 0.5329148759039081, 'Total loss': 0.5329148759039081}
2022-11-28 06:02:11,020 INFO:     Found new best model at epoch 3
2022-11-28 06:02:11,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:11,021 INFO:     Epoch: 4
2022-11-28 06:02:11,672 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4939367308027365, 'Total loss': 0.4939367308027365} | train loss {'Reaction outcome loss': 0.533435447848573, 'Total loss': 0.533435447848573}
2022-11-28 06:02:11,672 INFO:     Found new best model at epoch 4
2022-11-28 06:02:11,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:11,673 INFO:     Epoch: 5
2022-11-28 06:02:12,325 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.494986930354075, 'Total loss': 0.494986930354075} | train loss {'Reaction outcome loss': 0.5087436935731343, 'Total loss': 0.5087436935731343}
2022-11-28 06:02:12,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:12,326 INFO:     Epoch: 6
2022-11-28 06:02:12,981 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5038029304282232, 'Total loss': 0.5038029304282232} | train loss {'Reaction outcome loss': 0.5134377742300228, 'Total loss': 0.5134377742300228}
2022-11-28 06:02:12,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:12,981 INFO:     Epoch: 7
2022-11-28 06:02:13,638 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5169475085356019, 'Total loss': 0.5169475085356019} | train loss {'Reaction outcome loss': 0.505033518647661, 'Total loss': 0.505033518647661}
2022-11-28 06:02:13,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:13,638 INFO:     Epoch: 8
2022-11-28 06:02:14,296 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4910845969888297, 'Total loss': 0.4910845969888297} | train loss {'Reaction outcome loss': 0.5008463245265338, 'Total loss': 0.5008463245265338}
2022-11-28 06:02:14,296 INFO:     Found new best model at epoch 8
2022-11-28 06:02:14,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:14,297 INFO:     Epoch: 9
2022-11-28 06:02:14,951 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5016729476099665, 'Total loss': 0.5016729476099665} | train loss {'Reaction outcome loss': 0.49309761098452976, 'Total loss': 0.49309761098452976}
2022-11-28 06:02:14,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:14,951 INFO:     Epoch: 10
2022-11-28 06:02:15,604 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5008663323453881, 'Total loss': 0.5008663323453881} | train loss {'Reaction outcome loss': 0.49321517542916904, 'Total loss': 0.49321517542916904}
2022-11-28 06:02:15,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:15,604 INFO:     Epoch: 11
2022-11-28 06:02:16,257 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49249172617088666, 'Total loss': 0.49249172617088666} | train loss {'Reaction outcome loss': 0.4895712033218267, 'Total loss': 0.4895712033218267}
2022-11-28 06:02:16,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:16,258 INFO:     Epoch: 12
2022-11-28 06:02:16,915 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5446696037595923, 'Total loss': 0.5446696037595923} | train loss {'Reaction outcome loss': 0.48379130369546464, 'Total loss': 0.48379130369546464}
2022-11-28 06:02:16,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:16,915 INFO:     Epoch: 13
2022-11-28 06:02:17,568 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4738125144080682, 'Total loss': 0.4738125144080682} | train loss {'Reaction outcome loss': 0.48364233149557695, 'Total loss': 0.48364233149557695}
2022-11-28 06:02:17,568 INFO:     Found new best model at epoch 13
2022-11-28 06:02:17,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:17,568 INFO:     Epoch: 14
2022-11-28 06:02:18,220 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48356414112177765, 'Total loss': 0.48356414112177765} | train loss {'Reaction outcome loss': 0.4763126076788318, 'Total loss': 0.4763126076788318}
2022-11-28 06:02:18,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:18,220 INFO:     Epoch: 15
2022-11-28 06:02:18,876 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4832152080806819, 'Total loss': 0.4832152080806819} | train loss {'Reaction outcome loss': 0.47761539701296357, 'Total loss': 0.47761539701296357}
2022-11-28 06:02:18,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:18,876 INFO:     Epoch: 16
2022-11-28 06:02:19,532 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49295190891081636, 'Total loss': 0.49295190891081636} | train loss {'Reaction outcome loss': 0.4755736045083221, 'Total loss': 0.4755736045083221}
2022-11-28 06:02:19,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:19,533 INFO:     Epoch: 17
2022-11-28 06:02:20,185 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47742700238119473, 'Total loss': 0.47742700238119473} | train loss {'Reaction outcome loss': 0.46847129087058864, 'Total loss': 0.46847129087058864}
2022-11-28 06:02:20,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:20,186 INFO:     Epoch: 18
2022-11-28 06:02:20,841 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46610486981543625, 'Total loss': 0.46610486981543625} | train loss {'Reaction outcome loss': 0.47082988942156034, 'Total loss': 0.47082988942156034}
2022-11-28 06:02:20,841 INFO:     Found new best model at epoch 18
2022-11-28 06:02:20,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:20,842 INFO:     Epoch: 19
2022-11-28 06:02:21,496 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5084507895464246, 'Total loss': 0.5084507895464246} | train loss {'Reaction outcome loss': 0.47096505347563294, 'Total loss': 0.47096505347563294}
2022-11-28 06:02:21,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:21,497 INFO:     Epoch: 20
2022-11-28 06:02:22,150 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47491181980479846, 'Total loss': 0.47491181980479846} | train loss {'Reaction outcome loss': 0.46874148669291515, 'Total loss': 0.46874148669291515}
2022-11-28 06:02:22,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:22,150 INFO:     Epoch: 21
2022-11-28 06:02:22,804 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4697138029150665, 'Total loss': 0.4697138029150665} | train loss {'Reaction outcome loss': 0.4701427922869215, 'Total loss': 0.4701427922869215}
2022-11-28 06:02:22,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:22,805 INFO:     Epoch: 22
2022-11-28 06:02:23,458 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5222950679334727, 'Total loss': 0.5222950679334727} | train loss {'Reaction outcome loss': 0.46841759091737317, 'Total loss': 0.46841759091737317}
2022-11-28 06:02:23,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:23,458 INFO:     Epoch: 23
2022-11-28 06:02:24,111 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5031864558431235, 'Total loss': 0.5031864558431235} | train loss {'Reaction outcome loss': 0.46768638528123196, 'Total loss': 0.46768638528123196}
2022-11-28 06:02:24,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:24,111 INFO:     Epoch: 24
2022-11-28 06:02:24,767 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47430099377577956, 'Total loss': 0.47430099377577956} | train loss {'Reaction outcome loss': 0.46381350293451423, 'Total loss': 0.46381350293451423}
2022-11-28 06:02:24,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:24,767 INFO:     Epoch: 25
2022-11-28 06:02:25,421 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4711164442653006, 'Total loss': 0.4711164442653006} | train loss {'Reaction outcome loss': 0.4758275951353871, 'Total loss': 0.4758275951353871}
2022-11-28 06:02:25,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:25,422 INFO:     Epoch: 26
2022-11-28 06:02:26,075 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5050745328718965, 'Total loss': 0.5050745328718965} | train loss {'Reaction outcome loss': 0.46320561438190694, 'Total loss': 0.46320561438190694}
2022-11-28 06:02:26,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:26,076 INFO:     Epoch: 27
2022-11-28 06:02:26,731 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48627613789655943, 'Total loss': 0.48627613789655943} | train loss {'Reaction outcome loss': 0.4692651131931616, 'Total loss': 0.4692651131931616}
2022-11-28 06:02:26,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:26,731 INFO:     Epoch: 28
2022-11-28 06:02:27,388 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4878985052081672, 'Total loss': 0.4878985052081672} | train loss {'Reaction outcome loss': 0.4735852197116735, 'Total loss': 0.4735852197116735}
2022-11-28 06:02:27,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:27,388 INFO:     Epoch: 29
2022-11-28 06:02:28,041 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5096176442774859, 'Total loss': 0.5096176442774859} | train loss {'Reaction outcome loss': 0.4672063817783278, 'Total loss': 0.4672063817783278}
2022-11-28 06:02:28,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:28,041 INFO:     Epoch: 30
2022-11-28 06:02:28,691 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4809795187955553, 'Total loss': 0.4809795187955553} | train loss {'Reaction outcome loss': 0.46626560222737645, 'Total loss': 0.46626560222737645}
2022-11-28 06:02:28,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:28,691 INFO:     Epoch: 31
2022-11-28 06:02:29,345 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48731928488070314, 'Total loss': 0.48731928488070314} | train loss {'Reaction outcome loss': 0.4684111231443833, 'Total loss': 0.4684111231443833}
2022-11-28 06:02:29,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:29,345 INFO:     Epoch: 32
2022-11-28 06:02:29,998 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48583971844478085, 'Total loss': 0.48583971844478085} | train loss {'Reaction outcome loss': 0.46814158850786636, 'Total loss': 0.46814158850786636}
2022-11-28 06:02:29,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:29,998 INFO:     Epoch: 33
2022-11-28 06:02:30,653 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47570935264229774, 'Total loss': 0.47570935264229774} | train loss {'Reaction outcome loss': 0.46968188304073955, 'Total loss': 0.46968188304073955}
2022-11-28 06:02:30,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:30,653 INFO:     Epoch: 34
2022-11-28 06:02:31,307 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46781896156343544, 'Total loss': 0.46781896156343544} | train loss {'Reaction outcome loss': 0.46235482805237477, 'Total loss': 0.46235482805237477}
2022-11-28 06:02:31,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:31,307 INFO:     Epoch: 35
2022-11-28 06:02:31,958 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5141247500750151, 'Total loss': 0.5141247500750151} | train loss {'Reaction outcome loss': 0.4620406542505537, 'Total loss': 0.4620406542505537}
2022-11-28 06:02:31,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:31,958 INFO:     Epoch: 36
2022-11-28 06:02:32,610 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47242981381714344, 'Total loss': 0.47242981381714344} | train loss {'Reaction outcome loss': 0.47555227012050394, 'Total loss': 0.47555227012050394}
2022-11-28 06:02:32,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:32,610 INFO:     Epoch: 37
2022-11-28 06:02:33,265 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4691261550919576, 'Total loss': 0.4691261550919576} | train loss {'Reaction outcome loss': 0.4646374302859209, 'Total loss': 0.4646374302859209}
2022-11-28 06:02:33,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:33,265 INFO:     Epoch: 38
2022-11-28 06:02:33,920 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4711864207955924, 'Total loss': 0.4711864207955924} | train loss {'Reaction outcome loss': 0.4707730466613964, 'Total loss': 0.4707730466613964}
2022-11-28 06:02:33,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:33,920 INFO:     Epoch: 39
2022-11-28 06:02:34,575 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4718361505391923, 'Total loss': 0.4718361505391923} | train loss {'Reaction outcome loss': 0.4676067115092764, 'Total loss': 0.4676067115092764}
2022-11-28 06:02:34,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:34,576 INFO:     Epoch: 40
2022-11-28 06:02:35,229 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49900222332640126, 'Total loss': 0.49900222332640126} | train loss {'Reaction outcome loss': 0.45770270155400644, 'Total loss': 0.45770270155400644}
2022-11-28 06:02:35,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:35,229 INFO:     Epoch: 41
2022-11-28 06:02:35,882 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4720482443543998, 'Total loss': 0.4720482443543998} | train loss {'Reaction outcome loss': 0.46478002594441786, 'Total loss': 0.46478002594441786}
2022-11-28 06:02:35,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:35,883 INFO:     Epoch: 42
2022-11-28 06:02:36,539 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4919065223498778, 'Total loss': 0.4919065223498778} | train loss {'Reaction outcome loss': 0.4688801173652921, 'Total loss': 0.4688801173652921}
2022-11-28 06:02:36,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:36,540 INFO:     Epoch: 43
2022-11-28 06:02:37,193 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4679144925691865, 'Total loss': 0.4679144925691865} | train loss {'Reaction outcome loss': 0.466941752725718, 'Total loss': 0.466941752725718}
2022-11-28 06:02:37,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:37,193 INFO:     Epoch: 44
2022-11-28 06:02:37,848 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4573021534491669, 'Total loss': 0.4573021534491669} | train loss {'Reaction outcome loss': 0.46356223213429354, 'Total loss': 0.46356223213429354}
2022-11-28 06:02:37,849 INFO:     Found new best model at epoch 44
2022-11-28 06:02:37,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:37,850 INFO:     Epoch: 45
2022-11-28 06:02:38,503 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4822406169365753, 'Total loss': 0.4822406169365753} | train loss {'Reaction outcome loss': 0.45936321476284336, 'Total loss': 0.45936321476284336}
2022-11-28 06:02:38,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:38,504 INFO:     Epoch: 46
2022-11-28 06:02:39,157 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48559800670905545, 'Total loss': 0.48559800670905545} | train loss {'Reaction outcome loss': 0.459588526402201, 'Total loss': 0.459588526402201}
2022-11-28 06:02:39,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:39,158 INFO:     Epoch: 47
2022-11-28 06:02:39,811 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49837070974436676, 'Total loss': 0.49837070974436676} | train loss {'Reaction outcome loss': 0.45754693944235236, 'Total loss': 0.45754693944235236}
2022-11-28 06:02:39,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:39,812 INFO:     Epoch: 48
2022-11-28 06:02:40,461 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46261119503866543, 'Total loss': 0.46261119503866543} | train loss {'Reaction outcome loss': 0.4736832042129672, 'Total loss': 0.4736832042129672}
2022-11-28 06:02:40,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:40,461 INFO:     Epoch: 49
2022-11-28 06:02:41,112 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47277859107337217, 'Total loss': 0.47277859107337217} | train loss {'Reaction outcome loss': 0.45908922410132935, 'Total loss': 0.45908922410132935}
2022-11-28 06:02:41,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:41,112 INFO:     Epoch: 50
2022-11-28 06:02:41,762 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46132484349337494, 'Total loss': 0.46132484349337494} | train loss {'Reaction outcome loss': 0.4617463551613749, 'Total loss': 0.4617463551613749}
2022-11-28 06:02:41,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:41,762 INFO:     Epoch: 51
2022-11-28 06:02:42,415 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46140195293860004, 'Total loss': 0.46140195293860004} | train loss {'Reaction outcome loss': 0.4644820574899109, 'Total loss': 0.4644820574899109}
2022-11-28 06:02:42,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:42,415 INFO:     Epoch: 52
2022-11-28 06:02:43,068 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48605405674739316, 'Total loss': 0.48605405674739316} | train loss {'Reaction outcome loss': 0.4620804946033322, 'Total loss': 0.4620804946033322}
2022-11-28 06:02:43,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:43,068 INFO:     Epoch: 53
2022-11-28 06:02:43,717 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5090542259541425, 'Total loss': 0.5090542259541425} | train loss {'Reaction outcome loss': 0.4705338259132541, 'Total loss': 0.4705338259132541}
2022-11-28 06:02:43,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:43,717 INFO:     Epoch: 54
2022-11-28 06:02:44,367 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45943298360163515, 'Total loss': 0.45943298360163515} | train loss {'Reaction outcome loss': 0.46838228453178793, 'Total loss': 0.46838228453178793}
2022-11-28 06:02:44,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:44,368 INFO:     Epoch: 55
2022-11-28 06:02:45,018 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47365091470154846, 'Total loss': 0.47365091470154846} | train loss {'Reaction outcome loss': 0.4598084235982019, 'Total loss': 0.4598084235982019}
2022-11-28 06:02:45,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:45,019 INFO:     Epoch: 56
2022-11-28 06:02:45,674 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4758576937019825, 'Total loss': 0.4758576937019825} | train loss {'Reaction outcome loss': 0.45858893421839697, 'Total loss': 0.45858893421839697}
2022-11-28 06:02:45,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:45,674 INFO:     Epoch: 57
2022-11-28 06:02:46,333 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45301664112643764, 'Total loss': 0.45301664112643764} | train loss {'Reaction outcome loss': 0.4659439491982363, 'Total loss': 0.4659439491982363}
2022-11-28 06:02:46,333 INFO:     Found new best model at epoch 57
2022-11-28 06:02:46,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:46,333 INFO:     Epoch: 58
2022-11-28 06:02:46,988 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5290478200397708, 'Total loss': 0.5290478200397708} | train loss {'Reaction outcome loss': 0.46283389457634516, 'Total loss': 0.46283389457634516}
2022-11-28 06:02:46,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:46,988 INFO:     Epoch: 59
2022-11-28 06:02:47,638 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4681821827861396, 'Total loss': 0.4681821827861396} | train loss {'Reaction outcome loss': 0.46145003066987406, 'Total loss': 0.46145003066987406}
2022-11-28 06:02:47,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:47,639 INFO:     Epoch: 60
2022-11-28 06:02:48,292 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4695787128399719, 'Total loss': 0.4695787128399719} | train loss {'Reaction outcome loss': 0.4590969805206571, 'Total loss': 0.4590969805206571}
2022-11-28 06:02:48,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:48,292 INFO:     Epoch: 61
2022-11-28 06:02:48,949 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4887746796011925, 'Total loss': 0.4887746796011925} | train loss {'Reaction outcome loss': 0.4607033131682143, 'Total loss': 0.4607033131682143}
2022-11-28 06:02:48,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:48,949 INFO:     Epoch: 62
2022-11-28 06:02:49,602 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49065354940566147, 'Total loss': 0.49065354940566147} | train loss {'Reaction outcome loss': 0.4564913688265547, 'Total loss': 0.4564913688265547}
2022-11-28 06:02:49,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:49,602 INFO:     Epoch: 63
2022-11-28 06:02:50,253 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4504239262843674, 'Total loss': 0.4504239262843674} | train loss {'Reaction outcome loss': 0.4622867989600921, 'Total loss': 0.4622867989600921}
2022-11-28 06:02:50,253 INFO:     Found new best model at epoch 63
2022-11-28 06:02:50,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:50,254 INFO:     Epoch: 64
2022-11-28 06:02:50,906 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49159700626676733, 'Total loss': 0.49159700626676733} | train loss {'Reaction outcome loss': 0.4580891514311031, 'Total loss': 0.4580891514311031}
2022-11-28 06:02:50,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:50,906 INFO:     Epoch: 65
2022-11-28 06:02:51,560 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5069391944191672, 'Total loss': 0.5069391944191672} | train loss {'Reaction outcome loss': 0.46324853313212494, 'Total loss': 0.46324853313212494}
2022-11-28 06:02:51,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:51,561 INFO:     Epoch: 66
2022-11-28 06:02:52,217 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49126827107234433, 'Total loss': 0.49126827107234433} | train loss {'Reaction outcome loss': 0.4626239414725985, 'Total loss': 0.4626239414725985}
2022-11-28 06:02:52,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:52,217 INFO:     Epoch: 67
2022-11-28 06:02:52,871 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5021964819593863, 'Total loss': 0.5021964819593863} | train loss {'Reaction outcome loss': 0.4652109960512239, 'Total loss': 0.4652109960512239}
2022-11-28 06:02:52,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:52,872 INFO:     Epoch: 68
2022-11-28 06:02:53,525 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4843371239575473, 'Total loss': 0.4843371239575473} | train loss {'Reaction outcome loss': 0.4643886452426716, 'Total loss': 0.4643886452426716}
2022-11-28 06:02:53,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:53,525 INFO:     Epoch: 69
2022-11-28 06:02:54,182 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4498201222582297, 'Total loss': 0.4498201222582297} | train loss {'Reaction outcome loss': 0.46641260312528027, 'Total loss': 0.46641260312528027}
2022-11-28 06:02:54,182 INFO:     Found new best model at epoch 69
2022-11-28 06:02:54,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:54,183 INFO:     Epoch: 70
2022-11-28 06:02:54,843 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46966834569519217, 'Total loss': 0.46966834569519217} | train loss {'Reaction outcome loss': 0.4661940515345457, 'Total loss': 0.4661940515345457}
2022-11-28 06:02:54,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:54,843 INFO:     Epoch: 71
2022-11-28 06:02:55,496 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47262392413209786, 'Total loss': 0.47262392413209786} | train loss {'Reaction outcome loss': 0.46575467440546775, 'Total loss': 0.46575467440546775}
2022-11-28 06:02:55,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:55,496 INFO:     Epoch: 72
2022-11-28 06:02:56,149 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46978383003310725, 'Total loss': 0.46978383003310725} | train loss {'Reaction outcome loss': 0.46080495946261346, 'Total loss': 0.46080495946261346}
2022-11-28 06:02:56,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:56,149 INFO:     Epoch: 73
2022-11-28 06:02:56,804 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4620925535193898, 'Total loss': 0.4620925535193898} | train loss {'Reaction outcome loss': 0.464990957659118, 'Total loss': 0.464990957659118}
2022-11-28 06:02:56,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:56,805 INFO:     Epoch: 74
2022-11-28 06:02:57,462 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45848576758395543, 'Total loss': 0.45848576758395543} | train loss {'Reaction outcome loss': 0.45587553369755646, 'Total loss': 0.45587553369755646}
2022-11-28 06:02:57,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:57,462 INFO:     Epoch: 75
2022-11-28 06:02:58,116 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4742976769127629, 'Total loss': 0.4742976769127629} | train loss {'Reaction outcome loss': 0.4671542210846531, 'Total loss': 0.4671542210846531}
2022-11-28 06:02:58,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:58,117 INFO:     Epoch: 76
2022-11-28 06:02:58,769 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4442645910788666, 'Total loss': 0.4442645910788666} | train loss {'Reaction outcome loss': 0.4670670674163468, 'Total loss': 0.4670670674163468}
2022-11-28 06:02:58,769 INFO:     Found new best model at epoch 76
2022-11-28 06:02:58,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:58,770 INFO:     Epoch: 77
2022-11-28 06:02:59,422 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.447176877070557, 'Total loss': 0.447176877070557} | train loss {'Reaction outcome loss': 0.46924595346256176, 'Total loss': 0.46924595346256176}
2022-11-28 06:02:59,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:02:59,423 INFO:     Epoch: 78
2022-11-28 06:03:00,074 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4784461556171829, 'Total loss': 0.4784461556171829} | train loss {'Reaction outcome loss': 0.4610485001486175, 'Total loss': 0.4610485001486175}
2022-11-28 06:03:00,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:00,074 INFO:     Epoch: 79
2022-11-28 06:03:00,727 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46145255770534277, 'Total loss': 0.46145255770534277} | train loss {'Reaction outcome loss': 0.4660862383793811, 'Total loss': 0.4660862383793811}
2022-11-28 06:03:00,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:00,727 INFO:     Epoch: 80
2022-11-28 06:03:01,379 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48361922868273477, 'Total loss': 0.48361922868273477} | train loss {'Reaction outcome loss': 0.468042378644554, 'Total loss': 0.468042378644554}
2022-11-28 06:03:01,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:01,379 INFO:     Epoch: 81
2022-11-28 06:03:02,033 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49071289328011597, 'Total loss': 0.49071289328011597} | train loss {'Reaction outcome loss': 0.4642942336140847, 'Total loss': 0.4642942336140847}
2022-11-28 06:03:02,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:02,034 INFO:     Epoch: 82
2022-11-28 06:03:02,688 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4669849246063016, 'Total loss': 0.4669849246063016} | train loss {'Reaction outcome loss': 0.4649733461287557, 'Total loss': 0.4649733461287557}
2022-11-28 06:03:02,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:02,689 INFO:     Epoch: 83
2022-11-28 06:03:03,346 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4619058197872205, 'Total loss': 0.4619058197872205} | train loss {'Reaction outcome loss': 0.4643106740348193, 'Total loss': 0.4643106740348193}
2022-11-28 06:03:03,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:03,346 INFO:     Epoch: 84
2022-11-28 06:03:04,000 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4914099428464066, 'Total loss': 0.4914099428464066} | train loss {'Reaction outcome loss': 0.4621049947276407, 'Total loss': 0.4621049947276407}
2022-11-28 06:03:04,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:04,001 INFO:     Epoch: 85
2022-11-28 06:03:04,654 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47861739044839685, 'Total loss': 0.47861739044839685} | train loss {'Reaction outcome loss': 0.4645005241036415, 'Total loss': 0.4645005241036415}
2022-11-28 06:03:04,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:04,654 INFO:     Epoch: 86
2022-11-28 06:03:05,308 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4708948995579373, 'Total loss': 0.4708948995579373} | train loss {'Reaction outcome loss': 0.46328814844695887, 'Total loss': 0.46328814844695887}
2022-11-28 06:03:05,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:05,309 INFO:     Epoch: 87
2022-11-28 06:03:05,963 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5173526121811434, 'Total loss': 0.5173526121811434} | train loss {'Reaction outcome loss': 0.4575748486178262, 'Total loss': 0.4575748486178262}
2022-11-28 06:03:05,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:05,963 INFO:     Epoch: 88
2022-11-28 06:03:06,619 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5000778551806103, 'Total loss': 0.5000778551806103} | train loss {'Reaction outcome loss': 0.4637311774553085, 'Total loss': 0.4637311774553085}
2022-11-28 06:03:06,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:06,620 INFO:     Epoch: 89
2022-11-28 06:03:07,273 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46599865349178965, 'Total loss': 0.46599865349178965} | train loss {'Reaction outcome loss': 0.46897670133989683, 'Total loss': 0.46897670133989683}
2022-11-28 06:03:07,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:07,274 INFO:     Epoch: 90
2022-11-28 06:03:07,929 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5022034624760802, 'Total loss': 0.5022034624760802} | train loss {'Reaction outcome loss': 0.4627475506797129, 'Total loss': 0.4627475506797129}
2022-11-28 06:03:07,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:07,929 INFO:     Epoch: 91
2022-11-28 06:03:08,586 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4752684711817313, 'Total loss': 0.4752684711817313} | train loss {'Reaction outcome loss': 0.4631800923116353, 'Total loss': 0.4631800923116353}
2022-11-28 06:03:08,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:08,587 INFO:     Epoch: 92
2022-11-28 06:03:09,241 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49218940463933075, 'Total loss': 0.49218940463933075} | train loss {'Reaction outcome loss': 0.4633321417837727, 'Total loss': 0.4633321417837727}
2022-11-28 06:03:09,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:09,241 INFO:     Epoch: 93
2022-11-28 06:03:09,895 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46714048934253777, 'Total loss': 0.46714048934253777} | train loss {'Reaction outcome loss': 0.46375388913616844, 'Total loss': 0.46375388913616844}
2022-11-28 06:03:09,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:09,895 INFO:     Epoch: 94
2022-11-28 06:03:10,551 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4549390765076334, 'Total loss': 0.4549390765076334} | train loss {'Reaction outcome loss': 0.46586014561507166, 'Total loss': 0.46586014561507166}
2022-11-28 06:03:10,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:10,551 INFO:     Epoch: 95
2022-11-28 06:03:11,206 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4642758477817882, 'Total loss': 0.4642758477817882} | train loss {'Reaction outcome loss': 0.4585560368031872, 'Total loss': 0.4585560368031872}
2022-11-28 06:03:11,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:11,207 INFO:     Epoch: 96
2022-11-28 06:03:11,859 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.472697297280485, 'Total loss': 0.472697297280485} | train loss {'Reaction outcome loss': 0.46599076359855884, 'Total loss': 0.46599076359855884}
2022-11-28 06:03:11,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:11,859 INFO:     Epoch: 97
2022-11-28 06:03:12,512 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5222432477907701, 'Total loss': 0.5222432477907701} | train loss {'Reaction outcome loss': 0.45759336267198836, 'Total loss': 0.45759336267198836}
2022-11-28 06:03:12,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:12,513 INFO:     Epoch: 98
2022-11-28 06:03:13,168 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46173566613685, 'Total loss': 0.46173566613685} | train loss {'Reaction outcome loss': 0.4644467299690052, 'Total loss': 0.4644467299690052}
2022-11-28 06:03:13,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:13,168 INFO:     Epoch: 99
2022-11-28 06:03:13,822 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4680914668874307, 'Total loss': 0.4680914668874307} | train loss {'Reaction outcome loss': 0.46622396728822163, 'Total loss': 0.46622396728822163}
2022-11-28 06:03:13,822 INFO:     Best model found after epoch 77 of 100.
2022-11-28 06:03:13,822 INFO:   Done with stage: TRAINING
2022-11-28 06:03:13,822 INFO:   Starting stage: EVALUATION
2022-11-28 06:03:13,946 INFO:   Done with stage: EVALUATION
2022-11-28 06:03:13,946 INFO:   Leaving out SEQ value Fold_1
2022-11-28 06:03:13,959 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 06:03:13,959 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:03:14,593 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:03:14,594 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:03:14,663 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:03:14,664 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:03:14,664 INFO:     No hyperparam tuning for this model
2022-11-28 06:03:14,664 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:03:14,664 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:03:14,665 INFO:     None feature selector for col prot
2022-11-28 06:03:14,665 INFO:     None feature selector for col prot
2022-11-28 06:03:14,665 INFO:     None feature selector for col prot
2022-11-28 06:03:14,665 INFO:     None feature selector for col chem
2022-11-28 06:03:14,665 INFO:     None feature selector for col chem
2022-11-28 06:03:14,665 INFO:     None feature selector for col chem
2022-11-28 06:03:14,666 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:03:14,666 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:03:14,667 INFO:     Number of params in model 169651
2022-11-28 06:03:14,670 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:03:14,670 INFO:   Starting stage: TRAINING
2022-11-28 06:03:14,720 INFO:     Val loss before train {'Reaction outcome loss': 0.9386592618254728, 'Total loss': 0.9386592618254728}
2022-11-28 06:03:14,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:14,720 INFO:     Epoch: 0
2022-11-28 06:03:15,370 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5694866391808487, 'Total loss': 0.5694866391808487} | train loss {'Reaction outcome loss': 0.6929003468668852, 'Total loss': 0.6929003468668852}
2022-11-28 06:03:15,370 INFO:     Found new best model at epoch 0
2022-11-28 06:03:15,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:15,371 INFO:     Epoch: 1
2022-11-28 06:03:16,025 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5043390826430432, 'Total loss': 0.5043390826430432} | train loss {'Reaction outcome loss': 0.5923766847394529, 'Total loss': 0.5923766847394529}
2022-11-28 06:03:16,025 INFO:     Found new best model at epoch 1
2022-11-28 06:03:16,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:16,026 INFO:     Epoch: 2
2022-11-28 06:03:16,679 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49773475874302, 'Total loss': 0.49773475874302} | train loss {'Reaction outcome loss': 0.5580114088341838, 'Total loss': 0.5580114088341838}
2022-11-28 06:03:16,679 INFO:     Found new best model at epoch 2
2022-11-28 06:03:16,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:16,680 INFO:     Epoch: 3
2022-11-28 06:03:17,332 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5329633528410003, 'Total loss': 0.5329633528410003} | train loss {'Reaction outcome loss': 0.5541960871854766, 'Total loss': 0.5541960871854766}
2022-11-28 06:03:17,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:17,332 INFO:     Epoch: 4
2022-11-28 06:03:17,982 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5086302393397619, 'Total loss': 0.5086302393397619} | train loss {'Reaction outcome loss': 0.5312531186786832, 'Total loss': 0.5312531186786832}
2022-11-28 06:03:17,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:17,983 INFO:     Epoch: 5
2022-11-28 06:03:18,635 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5091082938881808, 'Total loss': 0.5091082938881808} | train loss {'Reaction outcome loss': 0.5306976947505944, 'Total loss': 0.5306976947505944}
2022-11-28 06:03:18,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:18,635 INFO:     Epoch: 6
2022-11-28 06:03:19,289 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4863063138584758, 'Total loss': 0.4863063138584758} | train loss {'Reaction outcome loss': 0.5146458917831789, 'Total loss': 0.5146458917831789}
2022-11-28 06:03:19,289 INFO:     Found new best model at epoch 6
2022-11-28 06:03:19,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:19,289 INFO:     Epoch: 7
2022-11-28 06:03:19,941 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48189339422902394, 'Total loss': 0.48189339422902394} | train loss {'Reaction outcome loss': 0.5135674778310979, 'Total loss': 0.5135674778310979}
2022-11-28 06:03:19,942 INFO:     Found new best model at epoch 7
2022-11-28 06:03:19,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:19,942 INFO:     Epoch: 8
2022-11-28 06:03:20,594 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49655196555825165, 'Total loss': 0.49655196555825165} | train loss {'Reaction outcome loss': 0.5083921624988806, 'Total loss': 0.5083921624988806}
2022-11-28 06:03:20,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:20,594 INFO:     Epoch: 9
2022-11-28 06:03:21,244 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47565079411101896, 'Total loss': 0.47565079411101896} | train loss {'Reaction outcome loss': 0.5127776114300626, 'Total loss': 0.5127776114300626}
2022-11-28 06:03:21,244 INFO:     Found new best model at epoch 9
2022-11-28 06:03:21,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:21,245 INFO:     Epoch: 10
2022-11-28 06:03:21,896 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47597277562978657, 'Total loss': 0.47597277562978657} | train loss {'Reaction outcome loss': 0.5054362046791882, 'Total loss': 0.5054362046791882}
2022-11-28 06:03:21,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:21,896 INFO:     Epoch: 11
2022-11-28 06:03:22,545 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5043680272823157, 'Total loss': 0.5043680272823157} | train loss {'Reaction outcome loss': 0.5017117523267621, 'Total loss': 0.5017117523267621}
2022-11-28 06:03:22,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:22,545 INFO:     Epoch: 12
2022-11-28 06:03:23,196 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4931609290976857, 'Total loss': 0.4931609290976857} | train loss {'Reaction outcome loss': 0.4953339701426811, 'Total loss': 0.4953339701426811}
2022-11-28 06:03:23,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:23,197 INFO:     Epoch: 13
2022-11-28 06:03:23,850 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47682643075321995, 'Total loss': 0.47682643075321995} | train loss {'Reaction outcome loss': 0.49306572796624215, 'Total loss': 0.49306572796624215}
2022-11-28 06:03:23,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:23,850 INFO:     Epoch: 14
2022-11-28 06:03:24,500 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4587380449439204, 'Total loss': 0.4587380449439204} | train loss {'Reaction outcome loss': 0.490953297461154, 'Total loss': 0.490953297461154}
2022-11-28 06:03:24,500 INFO:     Found new best model at epoch 14
2022-11-28 06:03:24,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:24,501 INFO:     Epoch: 15
2022-11-28 06:03:25,153 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4520666235408118, 'Total loss': 0.4520666235408118} | train loss {'Reaction outcome loss': 0.49347482664419, 'Total loss': 0.49347482664419}
2022-11-28 06:03:25,153 INFO:     Found new best model at epoch 15
2022-11-28 06:03:25,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:25,154 INFO:     Epoch: 16
2022-11-28 06:03:25,806 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45702576533306477, 'Total loss': 0.45702576533306477} | train loss {'Reaction outcome loss': 0.48449218242627673, 'Total loss': 0.48449218242627673}
2022-11-28 06:03:25,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:25,807 INFO:     Epoch: 17
2022-11-28 06:03:26,458 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47537827075913897, 'Total loss': 0.47537827075913897} | train loss {'Reaction outcome loss': 0.49101396033265554, 'Total loss': 0.49101396033265554}
2022-11-28 06:03:26,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:26,458 INFO:     Epoch: 18
2022-11-28 06:03:27,109 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4391010233829188, 'Total loss': 0.4391010233829188} | train loss {'Reaction outcome loss': 0.4853422283882, 'Total loss': 0.4853422283882}
2022-11-28 06:03:27,110 INFO:     Found new best model at epoch 18
2022-11-28 06:03:27,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:27,111 INFO:     Epoch: 19
2022-11-28 06:03:27,760 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46662129392457563, 'Total loss': 0.46662129392457563} | train loss {'Reaction outcome loss': 0.4875927918025705, 'Total loss': 0.4875927918025705}
2022-11-28 06:03:27,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:27,761 INFO:     Epoch: 20
2022-11-28 06:03:28,409 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43918362675711164, 'Total loss': 0.43918362675711164} | train loss {'Reaction outcome loss': 0.4811973555288354, 'Total loss': 0.4811973555288354}
2022-11-28 06:03:28,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:28,410 INFO:     Epoch: 21
2022-11-28 06:03:29,061 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45022414035575337, 'Total loss': 0.45022414035575337} | train loss {'Reaction outcome loss': 0.4746115402181129, 'Total loss': 0.4746115402181129}
2022-11-28 06:03:29,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:29,061 INFO:     Epoch: 22
2022-11-28 06:03:29,715 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46173167817814403, 'Total loss': 0.46173167817814403} | train loss {'Reaction outcome loss': 0.4839728686531059, 'Total loss': 0.4839728686531059}
2022-11-28 06:03:29,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:29,715 INFO:     Epoch: 23
2022-11-28 06:03:30,368 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46473127950069515, 'Total loss': 0.46473127950069515} | train loss {'Reaction outcome loss': 0.48454343900084496, 'Total loss': 0.48454343900084496}
2022-11-28 06:03:30,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:30,368 INFO:     Epoch: 24
2022-11-28 06:03:31,019 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4660408427548963, 'Total loss': 0.4660408427548963} | train loss {'Reaction outcome loss': 0.47762483315633947, 'Total loss': 0.47762483315633947}
2022-11-28 06:03:31,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:31,019 INFO:     Epoch: 25
2022-11-28 06:03:31,672 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4725135758865711, 'Total loss': 0.4725135758865711} | train loss {'Reaction outcome loss': 0.4722645169459894, 'Total loss': 0.4722645169459894}
2022-11-28 06:03:31,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:31,673 INFO:     Epoch: 26
2022-11-28 06:03:32,321 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44560640842415566, 'Total loss': 0.44560640842415566} | train loss {'Reaction outcome loss': 0.49062684935624484, 'Total loss': 0.49062684935624484}
2022-11-28 06:03:32,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:32,322 INFO:     Epoch: 27
2022-11-28 06:03:32,970 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4559328847153242, 'Total loss': 0.4559328847153242} | train loss {'Reaction outcome loss': 0.48033512377592386, 'Total loss': 0.48033512377592386}
2022-11-28 06:03:32,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:32,970 INFO:     Epoch: 28
2022-11-28 06:03:33,617 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4689424329025801, 'Total loss': 0.4689424329025801} | train loss {'Reaction outcome loss': 0.48244117380532087, 'Total loss': 0.48244117380532087}
2022-11-28 06:03:33,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:33,617 INFO:     Epoch: 29
2022-11-28 06:03:34,268 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44978448679280836, 'Total loss': 0.44978448679280836} | train loss {'Reaction outcome loss': 0.47952956260472046, 'Total loss': 0.47952956260472046}
2022-11-28 06:03:34,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:34,268 INFO:     Epoch: 30
2022-11-28 06:03:34,915 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4395234993723936, 'Total loss': 0.4395234993723936} | train loss {'Reaction outcome loss': 0.4806835000082606, 'Total loss': 0.4806835000082606}
2022-11-28 06:03:34,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:34,915 INFO:     Epoch: 31
2022-11-28 06:03:35,567 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4477316082216973, 'Total loss': 0.4477316082216973} | train loss {'Reaction outcome loss': 0.4729096316045425, 'Total loss': 0.4729096316045425}
2022-11-28 06:03:35,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:35,567 INFO:     Epoch: 32
2022-11-28 06:03:36,222 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45705073517422345, 'Total loss': 0.45705073517422345} | train loss {'Reaction outcome loss': 0.47639572675355146, 'Total loss': 0.47639572675355146}
2022-11-28 06:03:36,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:36,223 INFO:     Epoch: 33
2022-11-28 06:03:36,877 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44266749260037447, 'Total loss': 0.44266749260037447} | train loss {'Reaction outcome loss': 0.4799190700420591, 'Total loss': 0.4799190700420591}
2022-11-28 06:03:36,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:36,878 INFO:     Epoch: 34
2022-11-28 06:03:37,527 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44742767131605815, 'Total loss': 0.44742767131605815} | train loss {'Reaction outcome loss': 0.4706854934452987, 'Total loss': 0.4706854934452987}
2022-11-28 06:03:37,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:37,528 INFO:     Epoch: 35
2022-11-28 06:03:38,181 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44667934712975527, 'Total loss': 0.44667934712975527} | train loss {'Reaction outcome loss': 0.4690817582314132, 'Total loss': 0.4690817582314132}
2022-11-28 06:03:38,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:38,182 INFO:     Epoch: 36
2022-11-28 06:03:38,833 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42978291386781736, 'Total loss': 0.42978291386781736} | train loss {'Reaction outcome loss': 0.48411373403228697, 'Total loss': 0.48411373403228697}
2022-11-28 06:03:38,833 INFO:     Found new best model at epoch 36
2022-11-28 06:03:38,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:38,834 INFO:     Epoch: 37
2022-11-28 06:03:39,483 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4717369738013245, 'Total loss': 0.4717369738013245} | train loss {'Reaction outcome loss': 0.47556767301236996, 'Total loss': 0.47556767301236996}
2022-11-28 06:03:39,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:39,483 INFO:     Epoch: 38
2022-11-28 06:03:40,129 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4533771553704905, 'Total loss': 0.4533771553704905} | train loss {'Reaction outcome loss': 0.47579060189548084, 'Total loss': 0.47579060189548084}
2022-11-28 06:03:40,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:40,130 INFO:     Epoch: 39
2022-11-28 06:03:40,777 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4539041335499564, 'Total loss': 0.4539041335499564} | train loss {'Reaction outcome loss': 0.47389088955814723, 'Total loss': 0.47389088955814723}
2022-11-28 06:03:40,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:40,778 INFO:     Epoch: 40
2022-11-28 06:03:41,427 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.427502139363178, 'Total loss': 0.427502139363178} | train loss {'Reaction outcome loss': 0.4717905580631045, 'Total loss': 0.4717905580631045}
2022-11-28 06:03:41,427 INFO:     Found new best model at epoch 40
2022-11-28 06:03:41,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:41,428 INFO:     Epoch: 41
2022-11-28 06:03:42,078 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47050326993299085, 'Total loss': 0.47050326993299085} | train loss {'Reaction outcome loss': 0.47416962322885875, 'Total loss': 0.47416962322885875}
2022-11-28 06:03:42,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:42,078 INFO:     Epoch: 42
2022-11-28 06:03:42,729 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47833408727202303, 'Total loss': 0.47833408727202303} | train loss {'Reaction outcome loss': 0.47644084343900445, 'Total loss': 0.47644084343900445}
2022-11-28 06:03:42,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:42,729 INFO:     Epoch: 43
2022-11-28 06:03:43,382 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42763066014578177, 'Total loss': 0.42763066014578177} | train loss {'Reaction outcome loss': 0.4647856405401816, 'Total loss': 0.4647856405401816}
2022-11-28 06:03:43,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:43,382 INFO:     Epoch: 44
2022-11-28 06:03:44,033 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48155410449172176, 'Total loss': 0.48155410449172176} | train loss {'Reaction outcome loss': 0.46523684757899064, 'Total loss': 0.46523684757899064}
2022-11-28 06:03:44,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:44,033 INFO:     Epoch: 45
2022-11-28 06:03:44,683 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5056111757145372, 'Total loss': 0.5056111757145372} | train loss {'Reaction outcome loss': 0.46658210951041, 'Total loss': 0.46658210951041}
2022-11-28 06:03:44,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:44,683 INFO:     Epoch: 46
2022-11-28 06:03:45,336 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4703085720539093, 'Total loss': 0.4703085720539093} | train loss {'Reaction outcome loss': 0.4737757330180192, 'Total loss': 0.4737757330180192}
2022-11-28 06:03:45,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:45,336 INFO:     Epoch: 47
2022-11-28 06:03:45,993 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45028015971183777, 'Total loss': 0.45028015971183777} | train loss {'Reaction outcome loss': 0.4778567350423727, 'Total loss': 0.4778567350423727}
2022-11-28 06:03:45,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:45,993 INFO:     Epoch: 48
2022-11-28 06:03:46,651 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46385938691538436, 'Total loss': 0.46385938691538436} | train loss {'Reaction outcome loss': 0.46043196662527613, 'Total loss': 0.46043196662527613}
2022-11-28 06:03:46,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:46,652 INFO:     Epoch: 49
2022-11-28 06:03:47,309 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44922813669193623, 'Total loss': 0.44922813669193623} | train loss {'Reaction outcome loss': 0.47243888285316404, 'Total loss': 0.47243888285316404}
2022-11-28 06:03:47,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:47,309 INFO:     Epoch: 50
2022-11-28 06:03:47,970 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4377562843782957, 'Total loss': 0.4377562843782957} | train loss {'Reaction outcome loss': 0.46640220675312105, 'Total loss': 0.46640220675312105}
2022-11-28 06:03:47,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:47,970 INFO:     Epoch: 51
2022-11-28 06:03:48,632 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41851120147594184, 'Total loss': 0.41851120147594184} | train loss {'Reaction outcome loss': 0.471033657427694, 'Total loss': 0.471033657427694}
2022-11-28 06:03:48,632 INFO:     Found new best model at epoch 51
2022-11-28 06:03:48,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:48,633 INFO:     Epoch: 52
2022-11-28 06:03:49,290 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45051393987134447, 'Total loss': 0.45051393987134447} | train loss {'Reaction outcome loss': 0.45837608425587906, 'Total loss': 0.45837608425587906}
2022-11-28 06:03:49,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:49,290 INFO:     Epoch: 53
2022-11-28 06:03:49,951 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43141429022301075, 'Total loss': 0.43141429022301075} | train loss {'Reaction outcome loss': 0.46675331304307843, 'Total loss': 0.46675331304307843}
2022-11-28 06:03:49,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:49,951 INFO:     Epoch: 54
2022-11-28 06:03:50,612 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4566280651231145, 'Total loss': 0.4566280651231145} | train loss {'Reaction outcome loss': 0.45961116376470346, 'Total loss': 0.45961116376470346}
2022-11-28 06:03:50,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:50,612 INFO:     Epoch: 55
2022-11-28 06:03:51,275 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4404824940964233, 'Total loss': 0.4404824940964233} | train loss {'Reaction outcome loss': 0.4676612543827686, 'Total loss': 0.4676612543827686}
2022-11-28 06:03:51,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:51,275 INFO:     Epoch: 56
2022-11-28 06:03:51,932 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4240827861913415, 'Total loss': 0.4240827861913415} | train loss {'Reaction outcome loss': 0.4689310282529866, 'Total loss': 0.4689310282529866}
2022-11-28 06:03:51,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:51,932 INFO:     Epoch: 57
2022-11-28 06:03:52,592 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42982048316057336, 'Total loss': 0.42982048316057336} | train loss {'Reaction outcome loss': 0.4789068913850628, 'Total loss': 0.4789068913850628}
2022-11-28 06:03:52,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:52,592 INFO:     Epoch: 58
2022-11-28 06:03:53,248 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4582024136948031, 'Total loss': 0.4582024136948031} | train loss {'Reaction outcome loss': 0.4695442664574404, 'Total loss': 0.4695442664574404}
2022-11-28 06:03:53,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:53,249 INFO:     Epoch: 59
2022-11-28 06:03:53,904 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4500998203144517, 'Total loss': 0.4500998203144517} | train loss {'Reaction outcome loss': 0.46844144240327057, 'Total loss': 0.46844144240327057}
2022-11-28 06:03:53,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:53,904 INFO:     Epoch: 60
2022-11-28 06:03:54,560 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4630927599446718, 'Total loss': 0.4630927599446718} | train loss {'Reaction outcome loss': 0.4652992509549759, 'Total loss': 0.4652992509549759}
2022-11-28 06:03:54,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:54,561 INFO:     Epoch: 61
2022-11-28 06:03:55,216 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45159327082855755, 'Total loss': 0.45159327082855755} | train loss {'Reaction outcome loss': 0.46387678726774745, 'Total loss': 0.46387678726774745}
2022-11-28 06:03:55,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:55,216 INFO:     Epoch: 62
2022-11-28 06:03:55,871 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42872445527897324, 'Total loss': 0.42872445527897324} | train loss {'Reaction outcome loss': 0.46735508367419243, 'Total loss': 0.46735508367419243}
2022-11-28 06:03:55,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:55,872 INFO:     Epoch: 63
2022-11-28 06:03:56,528 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42941614777542825, 'Total loss': 0.42941614777542825} | train loss {'Reaction outcome loss': 0.4646750736187716, 'Total loss': 0.4646750736187716}
2022-11-28 06:03:56,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:56,528 INFO:     Epoch: 64
2022-11-28 06:03:57,185 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4380100792230562, 'Total loss': 0.4380100792230562} | train loss {'Reaction outcome loss': 0.46711506395310654, 'Total loss': 0.46711506395310654}
2022-11-28 06:03:57,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:57,185 INFO:     Epoch: 65
2022-11-28 06:03:57,843 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4540549722868343, 'Total loss': 0.4540549722868343} | train loss {'Reaction outcome loss': 0.4716821665890881, 'Total loss': 0.4716821665890881}
2022-11-28 06:03:57,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:57,843 INFO:     Epoch: 66
2022-11-28 06:03:58,499 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45934612945068715, 'Total loss': 0.45934612945068715} | train loss {'Reaction outcome loss': 0.47460013078372987, 'Total loss': 0.47460013078372987}
2022-11-28 06:03:58,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:58,499 INFO:     Epoch: 67
2022-11-28 06:03:59,154 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4677011918189914, 'Total loss': 0.4677011918189914} | train loss {'Reaction outcome loss': 0.47272844472136655, 'Total loss': 0.47272844472136655}
2022-11-28 06:03:59,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:59,155 INFO:     Epoch: 68
2022-11-28 06:03:59,811 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43954495808412863, 'Total loss': 0.43954495808412863} | train loss {'Reaction outcome loss': 0.4734205701922784, 'Total loss': 0.4734205701922784}
2022-11-28 06:03:59,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:03:59,811 INFO:     Epoch: 69
2022-11-28 06:04:00,468 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43381458312966104, 'Total loss': 0.43381458312966104} | train loss {'Reaction outcome loss': 0.47531946925599067, 'Total loss': 0.47531946925599067}
2022-11-28 06:04:00,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:00,468 INFO:     Epoch: 70
2022-11-28 06:04:01,122 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43712962644044745, 'Total loss': 0.43712962644044745} | train loss {'Reaction outcome loss': 0.47062420051117415, 'Total loss': 0.47062420051117415}
2022-11-28 06:04:01,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:01,122 INFO:     Epoch: 71
2022-11-28 06:04:01,777 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4337199961030206, 'Total loss': 0.4337199961030206} | train loss {'Reaction outcome loss': 0.46982500641072383, 'Total loss': 0.46982500641072383}
2022-11-28 06:04:01,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:01,777 INFO:     Epoch: 72
2022-11-28 06:04:02,429 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44705082233562027, 'Total loss': 0.44705082233562027} | train loss {'Reaction outcome loss': 0.4713753365346643, 'Total loss': 0.4713753365346643}
2022-11-28 06:04:02,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:02,430 INFO:     Epoch: 73
2022-11-28 06:04:03,084 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5007010528514552, 'Total loss': 0.5007010528514552} | train loss {'Reaction outcome loss': 0.47294040268561877, 'Total loss': 0.47294040268561877}
2022-11-28 06:04:03,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:03,084 INFO:     Epoch: 74
2022-11-28 06:04:03,740 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4465729434822881, 'Total loss': 0.4465729434822881} | train loss {'Reaction outcome loss': 0.47544204242161064, 'Total loss': 0.47544204242161064}
2022-11-28 06:04:03,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:03,740 INFO:     Epoch: 75
2022-11-28 06:04:04,398 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4338928258349729, 'Total loss': 0.4338928258349729} | train loss {'Reaction outcome loss': 0.46947709220598954, 'Total loss': 0.46947709220598954}
2022-11-28 06:04:04,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:04,398 INFO:     Epoch: 76
2022-11-28 06:04:05,053 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45020171445469526, 'Total loss': 0.45020171445469526} | train loss {'Reaction outcome loss': 0.46686107469875304, 'Total loss': 0.46686107469875304}
2022-11-28 06:04:05,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:05,053 INFO:     Epoch: 77
2022-11-28 06:04:05,709 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4393746520197669, 'Total loss': 0.4393746520197669} | train loss {'Reaction outcome loss': 0.476572220625936, 'Total loss': 0.476572220625936}
2022-11-28 06:04:05,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:05,710 INFO:     Epoch: 78
2022-11-28 06:04:06,368 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48660149754479876, 'Total loss': 0.48660149754479876} | train loss {'Reaction outcome loss': 0.4712134193567956, 'Total loss': 0.4712134193567956}
2022-11-28 06:04:06,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:06,368 INFO:     Epoch: 79
2022-11-28 06:04:07,023 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4576994499494863, 'Total loss': 0.4576994499494863} | train loss {'Reaction outcome loss': 0.47447613822143586, 'Total loss': 0.47447613822143586}
2022-11-28 06:04:07,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:07,023 INFO:     Epoch: 80
2022-11-28 06:04:07,681 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46499348830345066, 'Total loss': 0.46499348830345066} | train loss {'Reaction outcome loss': 0.4760677723488847, 'Total loss': 0.4760677723488847}
2022-11-28 06:04:07,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:07,682 INFO:     Epoch: 81
2022-11-28 06:04:08,338 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4323675168115039, 'Total loss': 0.4323675168115039} | train loss {'Reaction outcome loss': 0.47542381769076725, 'Total loss': 0.47542381769076725}
2022-11-28 06:04:08,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:08,338 INFO:     Epoch: 82
2022-11-28 06:04:08,991 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4600600336873254, 'Total loss': 0.4600600336873254} | train loss {'Reaction outcome loss': 0.47496018076284985, 'Total loss': 0.47496018076284985}
2022-11-28 06:04:08,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:08,991 INFO:     Epoch: 83
2022-11-28 06:04:09,647 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5641330709291059, 'Total loss': 0.5641330709291059} | train loss {'Reaction outcome loss': 0.4716306050598133, 'Total loss': 0.4716306050598133}
2022-11-28 06:04:09,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:09,647 INFO:     Epoch: 84
2022-11-28 06:04:10,303 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4613159998904827, 'Total loss': 0.4613159998904827} | train loss {'Reaction outcome loss': 0.47373881178801175, 'Total loss': 0.47373881178801175}
2022-11-28 06:04:10,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:10,304 INFO:     Epoch: 85
2022-11-28 06:04:10,962 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46576152949832206, 'Total loss': 0.46576152949832206} | train loss {'Reaction outcome loss': 0.4724458796201182, 'Total loss': 0.4724458796201182}
2022-11-28 06:04:10,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:10,963 INFO:     Epoch: 86
2022-11-28 06:04:11,620 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5084060991919318, 'Total loss': 0.5084060991919318} | train loss {'Reaction outcome loss': 0.47047785486354204, 'Total loss': 0.47047785486354204}
2022-11-28 06:04:11,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:11,620 INFO:     Epoch: 87
2022-11-28 06:04:12,271 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.443797089332758, 'Total loss': 0.443797089332758} | train loss {'Reaction outcome loss': 0.47335584107481066, 'Total loss': 0.47335584107481066}
2022-11-28 06:04:12,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:12,271 INFO:     Epoch: 88
2022-11-28 06:04:12,925 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4410806721033052, 'Total loss': 0.4410806721033052} | train loss {'Reaction outcome loss': 0.4713221185031484, 'Total loss': 0.4713221185031484}
2022-11-28 06:04:12,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:12,925 INFO:     Epoch: 89
2022-11-28 06:04:13,581 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4628641771715741, 'Total loss': 0.4628641771715741} | train loss {'Reaction outcome loss': 0.47011055662983753, 'Total loss': 0.47011055662983753}
2022-11-28 06:04:13,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:13,581 INFO:     Epoch: 90
2022-11-28 06:04:14,236 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47825007729752117, 'Total loss': 0.47825007729752117} | train loss {'Reaction outcome loss': 0.4806832917889611, 'Total loss': 0.4806832917889611}
2022-11-28 06:04:14,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:14,236 INFO:     Epoch: 91
2022-11-28 06:04:14,891 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47933892143327134, 'Total loss': 0.47933892143327134} | train loss {'Reaction outcome loss': 0.4764815300825189, 'Total loss': 0.4764815300825189}
2022-11-28 06:04:14,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:14,892 INFO:     Epoch: 92
2022-11-28 06:04:15,546 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4452641332565352, 'Total loss': 0.4452641332565352} | train loss {'Reaction outcome loss': 0.4744303893358981, 'Total loss': 0.4744303893358981}
2022-11-28 06:04:15,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:15,546 INFO:     Epoch: 93
2022-11-28 06:04:16,203 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45852445793706315, 'Total loss': 0.45852445793706315} | train loss {'Reaction outcome loss': 0.4723825044319278, 'Total loss': 0.4723825044319278}
2022-11-28 06:04:16,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:16,203 INFO:     Epoch: 94
2022-11-28 06:04:16,859 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4452884010104246, 'Total loss': 0.4452884010104246} | train loss {'Reaction outcome loss': 0.4690476423282115, 'Total loss': 0.4690476423282115}
2022-11-28 06:04:16,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:16,859 INFO:     Epoch: 95
2022-11-28 06:04:17,515 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5084023205346839, 'Total loss': 0.5084023205346839} | train loss {'Reaction outcome loss': 0.47579921024744626, 'Total loss': 0.47579921024744626}
2022-11-28 06:04:17,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:17,516 INFO:     Epoch: 96
2022-11-28 06:04:18,172 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46732512047124464, 'Total loss': 0.46732512047124464} | train loss {'Reaction outcome loss': 0.4774071107023075, 'Total loss': 0.4774071107023075}
2022-11-28 06:04:18,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:18,172 INFO:     Epoch: 97
2022-11-28 06:04:18,827 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4597689651472624, 'Total loss': 0.4597689651472624} | train loss {'Reaction outcome loss': 0.4722210210366327, 'Total loss': 0.4722210210366327}
2022-11-28 06:04:18,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:18,827 INFO:     Epoch: 98
2022-11-28 06:04:19,483 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46210762615813766, 'Total loss': 0.46210762615813766} | train loss {'Reaction outcome loss': 0.4813153079604028, 'Total loss': 0.4813153079604028}
2022-11-28 06:04:19,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:19,484 INFO:     Epoch: 99
2022-11-28 06:04:20,139 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44382852194614186, 'Total loss': 0.44382852194614186} | train loss {'Reaction outcome loss': 0.4779224138035149, 'Total loss': 0.4779224138035149}
2022-11-28 06:04:20,139 INFO:     Best model found after epoch 52 of 100.
2022-11-28 06:04:20,140 INFO:   Done with stage: TRAINING
2022-11-28 06:04:20,140 INFO:   Starting stage: EVALUATION
2022-11-28 06:04:20,269 INFO:   Done with stage: EVALUATION
2022-11-28 06:04:20,270 INFO:   Leaving out SEQ value Fold_2
2022-11-28 06:04:20,282 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 06:04:20,283 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:04:20,919 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:04:20,919 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:04:20,990 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:04:20,990 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:04:20,990 INFO:     No hyperparam tuning for this model
2022-11-28 06:04:20,990 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:04:20,990 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:04:20,991 INFO:     None feature selector for col prot
2022-11-28 06:04:20,991 INFO:     None feature selector for col prot
2022-11-28 06:04:20,991 INFO:     None feature selector for col prot
2022-11-28 06:04:20,991 INFO:     None feature selector for col chem
2022-11-28 06:04:20,992 INFO:     None feature selector for col chem
2022-11-28 06:04:20,992 INFO:     None feature selector for col chem
2022-11-28 06:04:20,992 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:04:20,992 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:04:20,993 INFO:     Number of params in model 169651
2022-11-28 06:04:20,996 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:04:20,996 INFO:   Starting stage: TRAINING
2022-11-28 06:04:21,047 INFO:     Val loss before train {'Reaction outcome loss': 1.0670788080193276, 'Total loss': 1.0670788080193276}
2022-11-28 06:04:21,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:21,048 INFO:     Epoch: 0
2022-11-28 06:04:21,706 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6352053194545036, 'Total loss': 0.6352053194545036} | train loss {'Reaction outcome loss': 0.6952112025194207, 'Total loss': 0.6952112025194207}
2022-11-28 06:04:21,706 INFO:     Found new best model at epoch 0
2022-11-28 06:04:21,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:21,707 INFO:     Epoch: 1
2022-11-28 06:04:22,365 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6128930865332137, 'Total loss': 0.6128930865332137} | train loss {'Reaction outcome loss': 0.5843557161068229, 'Total loss': 0.5843557161068229}
2022-11-28 06:04:22,365 INFO:     Found new best model at epoch 1
2022-11-28 06:04:22,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:22,366 INFO:     Epoch: 2
2022-11-28 06:04:23,021 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5765043774316477, 'Total loss': 0.5765043774316477} | train loss {'Reaction outcome loss': 0.5553160823053784, 'Total loss': 0.5553160823053784}
2022-11-28 06:04:23,021 INFO:     Found new best model at epoch 2
2022-11-28 06:04:23,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:23,022 INFO:     Epoch: 3
2022-11-28 06:04:23,673 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5426585019327873, 'Total loss': 0.5426585019327873} | train loss {'Reaction outcome loss': 0.5367866599388084, 'Total loss': 0.5367866599388084}
2022-11-28 06:04:23,673 INFO:     Found new best model at epoch 3
2022-11-28 06:04:23,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:23,674 INFO:     Epoch: 4
2022-11-28 06:04:24,330 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5053017423596493, 'Total loss': 0.5053017423596493} | train loss {'Reaction outcome loss': 0.5178064192518775, 'Total loss': 0.5178064192518775}
2022-11-28 06:04:24,330 INFO:     Found new best model at epoch 4
2022-11-28 06:04:24,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:24,331 INFO:     Epoch: 5
2022-11-28 06:04:24,983 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5767489044472228, 'Total loss': 0.5767489044472228} | train loss {'Reaction outcome loss': 0.5141740150044485, 'Total loss': 0.5141740150044485}
2022-11-28 06:04:24,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:24,984 INFO:     Epoch: 6
2022-11-28 06:04:25,638 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4612985929084379, 'Total loss': 0.4612985929084379} | train loss {'Reaction outcome loss': 0.5061461092758571, 'Total loss': 0.5061461092758571}
2022-11-28 06:04:25,639 INFO:     Found new best model at epoch 6
2022-11-28 06:04:25,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:25,639 INFO:     Epoch: 7
2022-11-28 06:04:26,291 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46762844781542934, 'Total loss': 0.46762844781542934} | train loss {'Reaction outcome loss': 0.4869021392530865, 'Total loss': 0.4869021392530865}
2022-11-28 06:04:26,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:26,291 INFO:     Epoch: 8
2022-11-28 06:04:26,944 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4699651203876318, 'Total loss': 0.4699651203876318} | train loss {'Reaction outcome loss': 0.49688150528281805, 'Total loss': 0.49688150528281805}
2022-11-28 06:04:26,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:26,945 INFO:     Epoch: 9
2022-11-28 06:04:27,593 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5191633236962695, 'Total loss': 0.5191633236962695} | train loss {'Reaction outcome loss': 0.4779343947829533, 'Total loss': 0.4779343947829533}
2022-11-28 06:04:27,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:27,593 INFO:     Epoch: 10
2022-11-28 06:04:28,246 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5390900920989902, 'Total loss': 0.5390900920989902} | train loss {'Reaction outcome loss': 0.4848318227831228, 'Total loss': 0.4848318227831228}
2022-11-28 06:04:28,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:28,247 INFO:     Epoch: 11
2022-11-28 06:04:28,900 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48733352887076004, 'Total loss': 0.48733352887076004} | train loss {'Reaction outcome loss': 0.47804967372260465, 'Total loss': 0.47804967372260465}
2022-11-28 06:04:28,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:28,900 INFO:     Epoch: 12
2022-11-28 06:04:29,552 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47558681701504907, 'Total loss': 0.47558681701504907} | train loss {'Reaction outcome loss': 0.4884700453821033, 'Total loss': 0.4884700453821033}
2022-11-28 06:04:29,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:29,553 INFO:     Epoch: 13
2022-11-28 06:04:30,208 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4751939031966897, 'Total loss': 0.4751939031966897} | train loss {'Reaction outcome loss': 0.47936685916818217, 'Total loss': 0.47936685916818217}
2022-11-28 06:04:30,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:30,208 INFO:     Epoch: 14
2022-11-28 06:04:30,859 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46240436060484064, 'Total loss': 0.46240436060484064} | train loss {'Reaction outcome loss': 0.4854655017532071, 'Total loss': 0.4854655017532071}
2022-11-28 06:04:30,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:30,859 INFO:     Epoch: 15
2022-11-28 06:04:31,511 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4828727377015491, 'Total loss': 0.4828727377015491} | train loss {'Reaction outcome loss': 0.471050718040378, 'Total loss': 0.471050718040378}
2022-11-28 06:04:31,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:31,511 INFO:     Epoch: 16
2022-11-28 06:04:32,160 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47728236643380895, 'Total loss': 0.47728236643380895} | train loss {'Reaction outcome loss': 0.47433166089371886, 'Total loss': 0.47433166089371886}
2022-11-28 06:04:32,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:32,160 INFO:     Epoch: 17
2022-11-28 06:04:32,812 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5181036827176116, 'Total loss': 0.5181036827176116} | train loss {'Reaction outcome loss': 0.47583832325022896, 'Total loss': 0.47583832325022896}
2022-11-28 06:04:32,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:32,813 INFO:     Epoch: 18
2022-11-28 06:04:33,469 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4554799881785415, 'Total loss': 0.4554799881785415} | train loss {'Reaction outcome loss': 0.4709415591241401, 'Total loss': 0.4709415591241401}
2022-11-28 06:04:33,469 INFO:     Found new best model at epoch 18
2022-11-28 06:04:33,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:33,470 INFO:     Epoch: 19
2022-11-28 06:04:34,119 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4519801864097285, 'Total loss': 0.4519801864097285} | train loss {'Reaction outcome loss': 0.4621703676848745, 'Total loss': 0.4621703676848745}
2022-11-28 06:04:34,120 INFO:     Found new best model at epoch 19
2022-11-28 06:04:34,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:34,120 INFO:     Epoch: 20
2022-11-28 06:04:34,771 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48588546556095746, 'Total loss': 0.48588546556095746} | train loss {'Reaction outcome loss': 0.46873656301586714, 'Total loss': 0.46873656301586714}
2022-11-28 06:04:34,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:34,771 INFO:     Epoch: 21
2022-11-28 06:04:35,423 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45976717042368515, 'Total loss': 0.45976717042368515} | train loss {'Reaction outcome loss': 0.46775872858218204, 'Total loss': 0.46775872858218204}
2022-11-28 06:04:35,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:35,423 INFO:     Epoch: 22
2022-11-28 06:04:36,076 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.477077841758728, 'Total loss': 0.477077841758728} | train loss {'Reaction outcome loss': 0.4781438367970196, 'Total loss': 0.4781438367970196}
2022-11-28 06:04:36,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:36,076 INFO:     Epoch: 23
2022-11-28 06:04:36,728 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5012235981087352, 'Total loss': 0.5012235981087352} | train loss {'Reaction outcome loss': 0.4651609274094978, 'Total loss': 0.4651609274094978}
2022-11-28 06:04:36,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:36,728 INFO:     Epoch: 24
2022-11-28 06:04:37,381 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4706736816916355, 'Total loss': 0.4706736816916355} | train loss {'Reaction outcome loss': 0.4726295772893929, 'Total loss': 0.4726295772893929}
2022-11-28 06:04:37,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:37,381 INFO:     Epoch: 25
2022-11-28 06:04:38,034 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4508029168774915, 'Total loss': 0.4508029168774915} | train loss {'Reaction outcome loss': 0.4693653736830739, 'Total loss': 0.4693653736830739}
2022-11-28 06:04:38,034 INFO:     Found new best model at epoch 25
2022-11-28 06:04:38,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:38,035 INFO:     Epoch: 26
2022-11-28 06:04:38,688 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4572279889916265, 'Total loss': 0.4572279889916265} | train loss {'Reaction outcome loss': 0.4680705792251438, 'Total loss': 0.4680705792251438}
2022-11-28 06:04:38,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:38,689 INFO:     Epoch: 27
2022-11-28 06:04:39,342 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5015168952387433, 'Total loss': 0.5015168952387433} | train loss {'Reaction outcome loss': 0.4648301105930972, 'Total loss': 0.4648301105930972}
2022-11-28 06:04:39,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:39,342 INFO:     Epoch: 28
2022-11-28 06:04:39,995 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4709123234416163, 'Total loss': 0.4709123234416163} | train loss {'Reaction outcome loss': 0.46717700398998496, 'Total loss': 0.46717700398998496}
2022-11-28 06:04:39,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:39,995 INFO:     Epoch: 29
2022-11-28 06:04:40,648 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4670967577501785, 'Total loss': 0.4670967577501785} | train loss {'Reaction outcome loss': 0.4698449780421002, 'Total loss': 0.4698449780421002}
2022-11-28 06:04:40,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:40,648 INFO:     Epoch: 30
2022-11-28 06:04:41,297 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48287962515686833, 'Total loss': 0.48287962515686833} | train loss {'Reaction outcome loss': 0.4713165826880883, 'Total loss': 0.4713165826880883}
2022-11-28 06:04:41,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:41,297 INFO:     Epoch: 31
2022-11-28 06:04:41,950 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4727786737819051, 'Total loss': 0.4727786737819051} | train loss {'Reaction outcome loss': 0.4715856364602415, 'Total loss': 0.4715856364602415}
2022-11-28 06:04:41,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:41,951 INFO:     Epoch: 32
2022-11-28 06:04:42,604 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43835767410522286, 'Total loss': 0.43835767410522286} | train loss {'Reaction outcome loss': 0.4641530025029869, 'Total loss': 0.4641530025029869}
2022-11-28 06:04:42,604 INFO:     Found new best model at epoch 32
2022-11-28 06:04:42,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:42,605 INFO:     Epoch: 33
2022-11-28 06:04:43,259 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47817627912343935, 'Total loss': 0.47817627912343935} | train loss {'Reaction outcome loss': 0.46914768160738574, 'Total loss': 0.46914768160738574}
2022-11-28 06:04:43,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:43,259 INFO:     Epoch: 34
2022-11-28 06:04:43,914 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44708331345125685, 'Total loss': 0.44708331345125685} | train loss {'Reaction outcome loss': 0.466256501804654, 'Total loss': 0.466256501804654}
2022-11-28 06:04:43,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:43,914 INFO:     Epoch: 35
2022-11-28 06:04:44,568 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49661120633746303, 'Total loss': 0.49661120633746303} | train loss {'Reaction outcome loss': 0.47103251375779204, 'Total loss': 0.47103251375779204}
2022-11-28 06:04:44,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:44,568 INFO:     Epoch: 36
2022-11-28 06:04:45,219 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5177276869152867, 'Total loss': 0.5177276869152867} | train loss {'Reaction outcome loss': 0.4624905209114522, 'Total loss': 0.4624905209114522}
2022-11-28 06:04:45,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:45,219 INFO:     Epoch: 37
2022-11-28 06:04:45,876 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45781192235475365, 'Total loss': 0.45781192235475365} | train loss {'Reaction outcome loss': 0.4694177091980177, 'Total loss': 0.4694177091980177}
2022-11-28 06:04:45,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:45,877 INFO:     Epoch: 38
2022-11-28 06:04:46,538 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46153743842313455, 'Total loss': 0.46153743842313455} | train loss {'Reaction outcome loss': 0.4642539833185604, 'Total loss': 0.4642539833185604}
2022-11-28 06:04:46,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:46,538 INFO:     Epoch: 39
2022-11-28 06:04:47,195 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49762592447358506, 'Total loss': 0.49762592447358506} | train loss {'Reaction outcome loss': 0.46276803584501086, 'Total loss': 0.46276803584501086}
2022-11-28 06:04:47,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:47,196 INFO:     Epoch: 40
2022-11-28 06:04:47,854 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4648444534734238, 'Total loss': 0.4648444534734238} | train loss {'Reaction outcome loss': 0.46832828530313547, 'Total loss': 0.46832828530313547}
2022-11-28 06:04:47,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:47,855 INFO:     Epoch: 41
2022-11-28 06:04:48,512 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4570320470388545, 'Total loss': 0.4570320470388545} | train loss {'Reaction outcome loss': 0.46501512273594187, 'Total loss': 0.46501512273594187}
2022-11-28 06:04:48,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:48,513 INFO:     Epoch: 42
2022-11-28 06:04:49,168 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46303407154804055, 'Total loss': 0.46303407154804055} | train loss {'Reaction outcome loss': 0.4594863920545382, 'Total loss': 0.4594863920545382}
2022-11-28 06:04:49,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:49,169 INFO:     Epoch: 43
2022-11-28 06:04:49,827 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4759133473731751, 'Total loss': 0.4759133473731751} | train loss {'Reaction outcome loss': 0.4602970598656454, 'Total loss': 0.4602970598656454}
2022-11-28 06:04:49,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:49,827 INFO:     Epoch: 44
2022-11-28 06:04:50,487 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44647665009942167, 'Total loss': 0.44647665009942167} | train loss {'Reaction outcome loss': 0.467370695537991, 'Total loss': 0.467370695537991}
2022-11-28 06:04:50,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:50,487 INFO:     Epoch: 45
2022-11-28 06:04:51,143 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.446875631462696, 'Total loss': 0.446875631462696} | train loss {'Reaction outcome loss': 0.46682027644581264, 'Total loss': 0.46682027644581264}
2022-11-28 06:04:51,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:51,143 INFO:     Epoch: 46
2022-11-28 06:04:51,801 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4377036829327428, 'Total loss': 0.4377036829327428} | train loss {'Reaction outcome loss': 0.4696922193706771, 'Total loss': 0.4696922193706771}
2022-11-28 06:04:51,801 INFO:     Found new best model at epoch 46
2022-11-28 06:04:51,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:51,802 INFO:     Epoch: 47
2022-11-28 06:04:52,461 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4874973047611325, 'Total loss': 0.4874973047611325} | train loss {'Reaction outcome loss': 0.46212708700156996, 'Total loss': 0.46212708700156996}
2022-11-28 06:04:52,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:52,461 INFO:     Epoch: 48
2022-11-28 06:04:53,117 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4558015247417051, 'Total loss': 0.4558015247417051} | train loss {'Reaction outcome loss': 0.4594962383187357, 'Total loss': 0.4594962383187357}
2022-11-28 06:04:53,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:53,117 INFO:     Epoch: 49
2022-11-28 06:04:53,771 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4656928347986798, 'Total loss': 0.4656928347986798} | train loss {'Reaction outcome loss': 0.46907153394487167, 'Total loss': 0.46907153394487167}
2022-11-28 06:04:53,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:53,772 INFO:     Epoch: 50
2022-11-28 06:04:54,429 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4494090908488562, 'Total loss': 0.4494090908488562} | train loss {'Reaction outcome loss': 0.46112620352227013, 'Total loss': 0.46112620352227013}
2022-11-28 06:04:54,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:54,429 INFO:     Epoch: 51
2022-11-28 06:04:55,086 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4615948740826097, 'Total loss': 0.4615948740826097} | train loss {'Reaction outcome loss': 0.4645432127110752, 'Total loss': 0.4645432127110752}
2022-11-28 06:04:55,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:55,086 INFO:     Epoch: 52
2022-11-28 06:04:55,744 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4609934386125831, 'Total loss': 0.4609934386125831} | train loss {'Reaction outcome loss': 0.4594644428587254, 'Total loss': 0.4594644428587254}
2022-11-28 06:04:55,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:55,744 INFO:     Epoch: 53
2022-11-28 06:04:56,401 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4772218881651413, 'Total loss': 0.4772218881651413} | train loss {'Reaction outcome loss': 0.46436159889148587, 'Total loss': 0.46436159889148587}
2022-11-28 06:04:56,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:56,402 INFO:     Epoch: 54
2022-11-28 06:04:57,059 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4604805468819862, 'Total loss': 0.4604805468819862} | train loss {'Reaction outcome loss': 0.46681717399952344, 'Total loss': 0.46681717399952344}
2022-11-28 06:04:57,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:57,059 INFO:     Epoch: 55
2022-11-28 06:04:57,717 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46405117352341496, 'Total loss': 0.46405117352341496} | train loss {'Reaction outcome loss': 0.4608146313409256, 'Total loss': 0.4608146313409256}
2022-11-28 06:04:57,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:57,717 INFO:     Epoch: 56
2022-11-28 06:04:58,372 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4639277354229328, 'Total loss': 0.4639277354229328} | train loss {'Reaction outcome loss': 0.4588295564729981, 'Total loss': 0.4588295564729981}
2022-11-28 06:04:58,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:58,372 INFO:     Epoch: 57
2022-11-28 06:04:59,029 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46464965440506156, 'Total loss': 0.46464965440506156} | train loss {'Reaction outcome loss': 0.4648053283370081, 'Total loss': 0.4648053283370081}
2022-11-28 06:04:59,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:59,029 INFO:     Epoch: 58
2022-11-28 06:04:59,685 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4797114757604377, 'Total loss': 0.4797114757604377} | train loss {'Reaction outcome loss': 0.46079813434508604, 'Total loss': 0.46079813434508604}
2022-11-28 06:04:59,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:04:59,685 INFO:     Epoch: 59
2022-11-28 06:05:00,342 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44478595984536545, 'Total loss': 0.44478595984536545} | train loss {'Reaction outcome loss': 0.45895742315323756, 'Total loss': 0.45895742315323756}
2022-11-28 06:05:00,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:00,342 INFO:     Epoch: 60
2022-11-28 06:05:01,000 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4923158339982809, 'Total loss': 0.4923158339982809} | train loss {'Reaction outcome loss': 0.4699455726539157, 'Total loss': 0.4699455726539157}
2022-11-28 06:05:01,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:01,000 INFO:     Epoch: 61
2022-11-28 06:05:01,659 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4450541935687841, 'Total loss': 0.4450541935687841} | train loss {'Reaction outcome loss': 0.45986892890047143, 'Total loss': 0.45986892890047143}
2022-11-28 06:05:01,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:01,659 INFO:     Epoch: 62
2022-11-28 06:05:02,316 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4749128669500351, 'Total loss': 0.4749128669500351} | train loss {'Reaction outcome loss': 0.4574979710480804, 'Total loss': 0.4574979710480804}
2022-11-28 06:05:02,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:02,316 INFO:     Epoch: 63
2022-11-28 06:05:02,971 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4594141802815504, 'Total loss': 0.4594141802815504} | train loss {'Reaction outcome loss': 0.4640473917187977, 'Total loss': 0.4640473917187977}
2022-11-28 06:05:02,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:02,972 INFO:     Epoch: 64
2022-11-28 06:05:03,631 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47399366768293605, 'Total loss': 0.47399366768293605} | train loss {'Reaction outcome loss': 0.4641248967053959, 'Total loss': 0.4641248967053959}
2022-11-28 06:05:03,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:03,631 INFO:     Epoch: 65
2022-11-28 06:05:04,291 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46657506359177964, 'Total loss': 0.46657506359177964} | train loss {'Reaction outcome loss': 0.4595593458708422, 'Total loss': 0.4595593458708422}
2022-11-28 06:05:04,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:04,292 INFO:     Epoch: 66
2022-11-28 06:05:04,951 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4652404081682826, 'Total loss': 0.4652404081682826} | train loss {'Reaction outcome loss': 0.4638083718195864, 'Total loss': 0.4638083718195864}
2022-11-28 06:05:04,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:04,951 INFO:     Epoch: 67
2022-11-28 06:05:05,610 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49285818705725115, 'Total loss': 0.49285818705725115} | train loss {'Reaction outcome loss': 0.46271865131187834, 'Total loss': 0.46271865131187834}
2022-11-28 06:05:05,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:05,610 INFO:     Epoch: 68
2022-11-28 06:05:06,265 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.515779875045599, 'Total loss': 0.515779875045599} | train loss {'Reaction outcome loss': 0.4676654749078515, 'Total loss': 0.4676654749078515}
2022-11-28 06:05:06,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:06,266 INFO:     Epoch: 69
2022-11-28 06:05:06,920 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4431562621233075, 'Total loss': 0.4431562621233075} | train loss {'Reaction outcome loss': 0.46362549373151835, 'Total loss': 0.46362549373151835}
2022-11-28 06:05:06,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:06,920 INFO:     Epoch: 70
2022-11-28 06:05:07,576 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4776683927968491, 'Total loss': 0.4776683927968491} | train loss {'Reaction outcome loss': 0.4621183637360977, 'Total loss': 0.4621183637360977}
2022-11-28 06:05:07,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:07,577 INFO:     Epoch: 71
2022-11-28 06:05:08,234 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47707604183707125, 'Total loss': 0.47707604183707125} | train loss {'Reaction outcome loss': 0.46295642552307115, 'Total loss': 0.46295642552307115}
2022-11-28 06:05:08,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:08,235 INFO:     Epoch: 72
2022-11-28 06:05:08,890 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46591122552405956, 'Total loss': 0.46591122552405956} | train loss {'Reaction outcome loss': 0.46017089222439034, 'Total loss': 0.46017089222439034}
2022-11-28 06:05:08,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:08,890 INFO:     Epoch: 73
2022-11-28 06:05:09,548 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4554008817256883, 'Total loss': 0.4554008817256883} | train loss {'Reaction outcome loss': 0.4573603599282449, 'Total loss': 0.4573603599282449}
2022-11-28 06:05:09,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:09,548 INFO:     Epoch: 74
2022-11-28 06:05:10,206 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45030076663161434, 'Total loss': 0.45030076663161434} | train loss {'Reaction outcome loss': 0.45934867791432904, 'Total loss': 0.45934867791432904}
2022-11-28 06:05:10,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:10,206 INFO:     Epoch: 75
2022-11-28 06:05:10,865 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4790140123561371, 'Total loss': 0.4790140123561371} | train loss {'Reaction outcome loss': 0.45797387746626456, 'Total loss': 0.45797387746626456}
2022-11-28 06:05:10,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:10,865 INFO:     Epoch: 76
2022-11-28 06:05:11,523 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4685753296281016, 'Total loss': 0.4685753296281016} | train loss {'Reaction outcome loss': 0.4588184372326474, 'Total loss': 0.4588184372326474}
2022-11-28 06:05:11,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:11,524 INFO:     Epoch: 77
2022-11-28 06:05:12,182 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45226298307263574, 'Total loss': 0.45226298307263574} | train loss {'Reaction outcome loss': 0.4698068928203465, 'Total loss': 0.4698068928203465}
2022-11-28 06:05:12,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:12,182 INFO:     Epoch: 78
2022-11-28 06:05:12,840 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4919411491516025, 'Total loss': 0.4919411491516025} | train loss {'Reaction outcome loss': 0.466062823778072, 'Total loss': 0.466062823778072}
2022-11-28 06:05:12,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:12,841 INFO:     Epoch: 79
2022-11-28 06:05:13,499 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44615369030209473, 'Total loss': 0.44615369030209473} | train loss {'Reaction outcome loss': 0.4627335235292529, 'Total loss': 0.4627335235292529}
2022-11-28 06:05:13,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:13,499 INFO:     Epoch: 80
2022-11-28 06:05:14,160 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5001428096100341, 'Total loss': 0.5001428096100341} | train loss {'Reaction outcome loss': 0.46773356784886294, 'Total loss': 0.46773356784886294}
2022-11-28 06:05:14,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:14,161 INFO:     Epoch: 81
2022-11-28 06:05:14,821 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4850328231966773, 'Total loss': 0.4850328231966773} | train loss {'Reaction outcome loss': 0.45319099564856463, 'Total loss': 0.45319099564856463}
2022-11-28 06:05:14,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:14,821 INFO:     Epoch: 82
2022-11-28 06:05:15,481 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.498999715197918, 'Total loss': 0.498999715197918} | train loss {'Reaction outcome loss': 0.4597674024448473, 'Total loss': 0.4597674024448473}
2022-11-28 06:05:15,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:15,481 INFO:     Epoch: 83
2022-11-28 06:05:16,139 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4822595050168592, 'Total loss': 0.4822595050168592} | train loss {'Reaction outcome loss': 0.4676580777690734, 'Total loss': 0.4676580777690734}
2022-11-28 06:05:16,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:16,139 INFO:     Epoch: 84
2022-11-28 06:05:16,797 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4642389520656231, 'Total loss': 0.4642389520656231} | train loss {'Reaction outcome loss': 0.45840996469336526, 'Total loss': 0.45840996469336526}
2022-11-28 06:05:16,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:16,797 INFO:     Epoch: 85
2022-11-28 06:05:17,453 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44630514501139174, 'Total loss': 0.44630514501139174} | train loss {'Reaction outcome loss': 0.45787978172302246, 'Total loss': 0.45787978172302246}
2022-11-28 06:05:17,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:17,454 INFO:     Epoch: 86
2022-11-28 06:05:18,109 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4621913686048153, 'Total loss': 0.4621913686048153} | train loss {'Reaction outcome loss': 0.4675149797718711, 'Total loss': 0.4675149797718711}
2022-11-28 06:05:18,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:18,110 INFO:     Epoch: 87
2022-11-28 06:05:18,770 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4518270984638569, 'Total loss': 0.4518270984638569} | train loss {'Reaction outcome loss': 0.4591794706605099, 'Total loss': 0.4591794706605099}
2022-11-28 06:05:18,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:18,770 INFO:     Epoch: 88
2022-11-28 06:05:19,428 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.455433102194653, 'Total loss': 0.455433102194653} | train loss {'Reaction outcome loss': 0.46059297399265775, 'Total loss': 0.46059297399265775}
2022-11-28 06:05:19,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:19,429 INFO:     Epoch: 89
2022-11-28 06:05:20,093 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44926085686960887, 'Total loss': 0.44926085686960887} | train loss {'Reaction outcome loss': 0.46081189808930145, 'Total loss': 0.46081189808930145}
2022-11-28 06:05:20,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:20,093 INFO:     Epoch: 90
2022-11-28 06:05:20,752 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43858845116094103, 'Total loss': 0.43858845116094103} | train loss {'Reaction outcome loss': 0.4623320430455875, 'Total loss': 0.4623320430455875}
2022-11-28 06:05:20,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:20,752 INFO:     Epoch: 91
2022-11-28 06:05:21,412 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4647908515708391, 'Total loss': 0.4647908515708391} | train loss {'Reaction outcome loss': 0.4636343849416623, 'Total loss': 0.4636343849416623}
2022-11-28 06:05:21,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:21,412 INFO:     Epoch: 92
2022-11-28 06:05:22,069 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.458065107811329, 'Total loss': 0.458065107811329} | train loss {'Reaction outcome loss': 0.46365583274099564, 'Total loss': 0.46365583274099564}
2022-11-28 06:05:22,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:22,069 INFO:     Epoch: 93
2022-11-28 06:05:22,726 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4613891472650129, 'Total loss': 0.4613891472650129} | train loss {'Reaction outcome loss': 0.4652797876562111, 'Total loss': 0.4652797876562111}
2022-11-28 06:05:22,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:22,726 INFO:     Epoch: 94
2022-11-28 06:05:23,384 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5069748513227286, 'Total loss': 0.5069748513227286} | train loss {'Reaction outcome loss': 0.46354138759183294, 'Total loss': 0.46354138759183294}
2022-11-28 06:05:23,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:23,384 INFO:     Epoch: 95
2022-11-28 06:05:24,043 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48152203234129176, 'Total loss': 0.48152203234129176} | train loss {'Reaction outcome loss': 0.46072950100702514, 'Total loss': 0.46072950100702514}
2022-11-28 06:05:24,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:24,044 INFO:     Epoch: 96
2022-11-28 06:05:24,706 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4466827802879866, 'Total loss': 0.4466827802879866} | train loss {'Reaction outcome loss': 0.46186253943561034, 'Total loss': 0.46186253943561034}
2022-11-28 06:05:24,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:24,706 INFO:     Epoch: 97
2022-11-28 06:05:25,366 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46116593237533127, 'Total loss': 0.46116593237533127} | train loss {'Reaction outcome loss': 0.45944424841261694, 'Total loss': 0.45944424841261694}
2022-11-28 06:05:25,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:25,366 INFO:     Epoch: 98
2022-11-28 06:05:26,026 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46974091543707736, 'Total loss': 0.46974091543707736} | train loss {'Reaction outcome loss': 0.45941584799515367, 'Total loss': 0.45941584799515367}
2022-11-28 06:05:26,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:26,026 INFO:     Epoch: 99
2022-11-28 06:05:26,692 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4800432391984518, 'Total loss': 0.4800432391984518} | train loss {'Reaction outcome loss': 0.4678260422169917, 'Total loss': 0.4678260422169917}
2022-11-28 06:05:26,692 INFO:     Best model found after epoch 47 of 100.
2022-11-28 06:05:26,692 INFO:   Done with stage: TRAINING
2022-11-28 06:05:26,692 INFO:   Starting stage: EVALUATION
2022-11-28 06:05:26,829 INFO:   Done with stage: EVALUATION
2022-11-28 06:05:26,829 INFO:   Leaving out SEQ value Fold_3
2022-11-28 06:05:26,842 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 06:05:26,842 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:05:27,490 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:05:27,490 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:05:27,561 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:05:27,561 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:05:27,561 INFO:     No hyperparam tuning for this model
2022-11-28 06:05:27,561 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:05:27,561 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:05:27,562 INFO:     None feature selector for col prot
2022-11-28 06:05:27,562 INFO:     None feature selector for col prot
2022-11-28 06:05:27,562 INFO:     None feature selector for col prot
2022-11-28 06:05:27,562 INFO:     None feature selector for col chem
2022-11-28 06:05:27,562 INFO:     None feature selector for col chem
2022-11-28 06:05:27,563 INFO:     None feature selector for col chem
2022-11-28 06:05:27,563 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:05:27,563 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:05:27,564 INFO:     Number of params in model 169651
2022-11-28 06:05:27,567 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:05:27,567 INFO:   Starting stage: TRAINING
2022-11-28 06:05:27,619 INFO:     Val loss before train {'Reaction outcome loss': 1.077617354013703, 'Total loss': 1.077617354013703}
2022-11-28 06:05:27,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:27,619 INFO:     Epoch: 0
2022-11-28 06:05:28,281 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5849019631066106, 'Total loss': 0.5849019631066106} | train loss {'Reaction outcome loss': 0.6837095287381386, 'Total loss': 0.6837095287381386}
2022-11-28 06:05:28,281 INFO:     Found new best model at epoch 0
2022-11-28 06:05:28,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:28,282 INFO:     Epoch: 1
2022-11-28 06:05:28,946 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6074028140441938, 'Total loss': 0.6074028140441938} | train loss {'Reaction outcome loss': 0.5665901527721054, 'Total loss': 0.5665901527721054}
2022-11-28 06:05:28,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:28,946 INFO:     Epoch: 2
2022-11-28 06:05:29,615 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5702686976980079, 'Total loss': 0.5702686976980079} | train loss {'Reaction outcome loss': 0.5515040406158992, 'Total loss': 0.5515040406158992}
2022-11-28 06:05:29,615 INFO:     Found new best model at epoch 2
2022-11-28 06:05:29,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:29,616 INFO:     Epoch: 3
2022-11-28 06:05:30,277 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4961660812524232, 'Total loss': 0.4961660812524232} | train loss {'Reaction outcome loss': 0.5297374271616644, 'Total loss': 0.5297374271616644}
2022-11-28 06:05:30,277 INFO:     Found new best model at epoch 3
2022-11-28 06:05:30,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:30,278 INFO:     Epoch: 4
2022-11-28 06:05:30,941 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5700159248980609, 'Total loss': 0.5700159248980609} | train loss {'Reaction outcome loss': 0.5161191375279913, 'Total loss': 0.5161191375279913}
2022-11-28 06:05:30,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:30,941 INFO:     Epoch: 5
2022-11-28 06:05:31,607 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4987842840227214, 'Total loss': 0.4987842840227214} | train loss {'Reaction outcome loss': 0.5076113690527118, 'Total loss': 0.5076113690527118}
2022-11-28 06:05:31,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:31,608 INFO:     Epoch: 6
2022-11-28 06:05:32,271 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48237312788313086, 'Total loss': 0.48237312788313086} | train loss {'Reaction outcome loss': 0.49961633627512014, 'Total loss': 0.49961633627512014}
2022-11-28 06:05:32,272 INFO:     Found new best model at epoch 6
2022-11-28 06:05:32,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:32,272 INFO:     Epoch: 7
2022-11-28 06:05:32,935 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49624121256849985, 'Total loss': 0.49624121256849985} | train loss {'Reaction outcome loss': 0.4968110194619821, 'Total loss': 0.4968110194619821}
2022-11-28 06:05:32,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:32,935 INFO:     Epoch: 8
2022-11-28 06:05:33,597 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5013547902080145, 'Total loss': 0.5013547902080145} | train loss {'Reaction outcome loss': 0.4863341339388672, 'Total loss': 0.4863341339388672}
2022-11-28 06:05:33,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:33,598 INFO:     Epoch: 9
2022-11-28 06:05:34,265 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4876608635214242, 'Total loss': 0.4876608635214242} | train loss {'Reaction outcome loss': 0.494497658160268, 'Total loss': 0.494497658160268}
2022-11-28 06:05:34,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:34,266 INFO:     Epoch: 10
2022-11-28 06:05:34,928 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5061844831163232, 'Total loss': 0.5061844831163232} | train loss {'Reaction outcome loss': 0.48277185151771623, 'Total loss': 0.48277185151771623}
2022-11-28 06:05:34,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:34,929 INFO:     Epoch: 11
2022-11-28 06:05:35,594 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5134291950274598, 'Total loss': 0.5134291950274598} | train loss {'Reaction outcome loss': 0.4782461222945427, 'Total loss': 0.4782461222945427}
2022-11-28 06:05:35,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:35,594 INFO:     Epoch: 12
2022-11-28 06:05:36,254 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48819882117889146, 'Total loss': 0.48819882117889146} | train loss {'Reaction outcome loss': 0.48320332196902255, 'Total loss': 0.48320332196902255}
2022-11-28 06:05:36,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:36,254 INFO:     Epoch: 13
2022-11-28 06:05:36,919 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5259420770135793, 'Total loss': 0.5259420770135793} | train loss {'Reaction outcome loss': 0.47537102285696536, 'Total loss': 0.47537102285696536}
2022-11-28 06:05:36,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:36,919 INFO:     Epoch: 14
2022-11-28 06:05:37,584 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4938316687264226, 'Total loss': 0.4938316687264226} | train loss {'Reaction outcome loss': 0.4755516909214915, 'Total loss': 0.4755516909214915}
2022-11-28 06:05:37,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:37,585 INFO:     Epoch: 15
2022-11-28 06:05:38,244 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49471535804596817, 'Total loss': 0.49471535804596817} | train loss {'Reaction outcome loss': 0.47328329280931125, 'Total loss': 0.47328329280931125}
2022-11-28 06:05:38,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:38,244 INFO:     Epoch: 16
2022-11-28 06:05:38,903 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47879511592063034, 'Total loss': 0.47879511592063034} | train loss {'Reaction outcome loss': 0.46921114407631814, 'Total loss': 0.46921114407631814}
2022-11-28 06:05:38,903 INFO:     Found new best model at epoch 16
2022-11-28 06:05:38,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:38,904 INFO:     Epoch: 17
2022-11-28 06:05:39,560 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4754982888698578, 'Total loss': 0.4754982888698578} | train loss {'Reaction outcome loss': 0.46013303405168104, 'Total loss': 0.46013303405168104}
2022-11-28 06:05:39,560 INFO:     Found new best model at epoch 17
2022-11-28 06:05:39,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:39,561 INFO:     Epoch: 18
2022-11-28 06:05:40,224 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4806871715594422, 'Total loss': 0.4806871715594422} | train loss {'Reaction outcome loss': 0.4672095215442229, 'Total loss': 0.4672095215442229}
2022-11-28 06:05:40,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:40,224 INFO:     Epoch: 19
2022-11-28 06:05:40,888 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4564977547323162, 'Total loss': 0.4564977547323162} | train loss {'Reaction outcome loss': 0.4730332049788261, 'Total loss': 0.4730332049788261}
2022-11-28 06:05:40,888 INFO:     Found new best model at epoch 19
2022-11-28 06:05:40,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:40,889 INFO:     Epoch: 20
2022-11-28 06:05:41,546 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45283631540157576, 'Total loss': 0.45283631540157576} | train loss {'Reaction outcome loss': 0.46924271489284475, 'Total loss': 0.46924271489284475}
2022-11-28 06:05:41,546 INFO:     Found new best model at epoch 20
2022-11-28 06:05:41,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:41,547 INFO:     Epoch: 21
2022-11-28 06:05:42,202 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5099176625636491, 'Total loss': 0.5099176625636491} | train loss {'Reaction outcome loss': 0.46019257860524315, 'Total loss': 0.46019257860524315}
2022-11-28 06:05:42,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:42,203 INFO:     Epoch: 22
2022-11-28 06:05:42,861 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4701032337139953, 'Total loss': 0.4701032337139953} | train loss {'Reaction outcome loss': 0.47058033772877284, 'Total loss': 0.47058033772877284}
2022-11-28 06:05:42,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:42,862 INFO:     Epoch: 23
2022-11-28 06:05:43,520 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4479875744066455, 'Total loss': 0.4479875744066455} | train loss {'Reaction outcome loss': 0.46038576109068735, 'Total loss': 0.46038576109068735}
2022-11-28 06:05:43,521 INFO:     Found new best model at epoch 23
2022-11-28 06:05:43,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:43,522 INFO:     Epoch: 24
2022-11-28 06:05:44,180 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4841714491221038, 'Total loss': 0.4841714491221038} | train loss {'Reaction outcome loss': 0.45914165590490613, 'Total loss': 0.45914165590490613}
2022-11-28 06:05:44,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:44,181 INFO:     Epoch: 25
2022-11-28 06:05:44,837 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4847205203365196, 'Total loss': 0.4847205203365196} | train loss {'Reaction outcome loss': 0.4623629334021588, 'Total loss': 0.4623629334021588}
2022-11-28 06:05:44,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:44,838 INFO:     Epoch: 26
2022-11-28 06:05:45,496 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.511003927751021, 'Total loss': 0.511003927751021} | train loss {'Reaction outcome loss': 0.46403664645491816, 'Total loss': 0.46403664645491816}
2022-11-28 06:05:45,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:45,496 INFO:     Epoch: 27
2022-11-28 06:05:46,155 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48865949091586197, 'Total loss': 0.48865949091586197} | train loss {'Reaction outcome loss': 0.45793674347960217, 'Total loss': 0.45793674347960217}
2022-11-28 06:05:46,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:46,155 INFO:     Epoch: 28
2022-11-28 06:05:46,811 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4809191369197585, 'Total loss': 0.4809191369197585} | train loss {'Reaction outcome loss': 0.45870345654536265, 'Total loss': 0.45870345654536265}
2022-11-28 06:05:46,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:46,811 INFO:     Epoch: 29
2022-11-28 06:05:47,467 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.518828680908138, 'Total loss': 0.518828680908138} | train loss {'Reaction outcome loss': 0.46346881091594694, 'Total loss': 0.46346881091594694}
2022-11-28 06:05:47,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:47,467 INFO:     Epoch: 30
2022-11-28 06:05:48,124 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5031044527210973, 'Total loss': 0.5031044527210973} | train loss {'Reaction outcome loss': 0.4613771994503177, 'Total loss': 0.4613771994503177}
2022-11-28 06:05:48,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:48,124 INFO:     Epoch: 31
2022-11-28 06:05:48,776 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46274593302620237, 'Total loss': 0.46274593302620237} | train loss {'Reaction outcome loss': 0.4641953220172804, 'Total loss': 0.4641953220172804}
2022-11-28 06:05:48,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:48,776 INFO:     Epoch: 32
2022-11-28 06:05:49,428 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4446548971940171, 'Total loss': 0.4446548971940171} | train loss {'Reaction outcome loss': 0.4606237860054386, 'Total loss': 0.4606237860054386}
2022-11-28 06:05:49,429 INFO:     Found new best model at epoch 32
2022-11-28 06:05:49,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:49,429 INFO:     Epoch: 33
2022-11-28 06:05:50,087 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.454645939509977, 'Total loss': 0.454645939509977} | train loss {'Reaction outcome loss': 0.45337017932716683, 'Total loss': 0.45337017932716683}
2022-11-28 06:05:50,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:50,087 INFO:     Epoch: 34
2022-11-28 06:05:50,749 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5313821096311916, 'Total loss': 0.5313821096311916} | train loss {'Reaction outcome loss': 0.4646744489061589, 'Total loss': 0.4646744489061589}
2022-11-28 06:05:50,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:50,749 INFO:     Epoch: 35
2022-11-28 06:05:51,406 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4935943599451672, 'Total loss': 0.4935943599451672} | train loss {'Reaction outcome loss': 0.4576507886453551, 'Total loss': 0.4576507886453551}
2022-11-28 06:05:51,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:51,406 INFO:     Epoch: 36
2022-11-28 06:05:52,065 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4649996417151256, 'Total loss': 0.4649996417151256} | train loss {'Reaction outcome loss': 0.4679967751612469, 'Total loss': 0.4679967751612469}
2022-11-28 06:05:52,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:52,066 INFO:     Epoch: 37
2022-11-28 06:05:52,726 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46033040569587186, 'Total loss': 0.46033040569587186} | train loss {'Reaction outcome loss': 0.4594068408620601, 'Total loss': 0.4594068408620601}
2022-11-28 06:05:52,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:52,726 INFO:     Epoch: 38
2022-11-28 06:05:53,384 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4632597504691644, 'Total loss': 0.4632597504691644} | train loss {'Reaction outcome loss': 0.46136948746077866, 'Total loss': 0.46136948746077866}
2022-11-28 06:05:53,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:53,384 INFO:     Epoch: 39
2022-11-28 06:05:54,044 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43865681981498544, 'Total loss': 0.43865681981498544} | train loss {'Reaction outcome loss': 0.46750325469338166, 'Total loss': 0.46750325469338166}
2022-11-28 06:05:54,044 INFO:     Found new best model at epoch 39
2022-11-28 06:05:54,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:54,045 INFO:     Epoch: 40
2022-11-28 06:05:54,704 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4623033895411275, 'Total loss': 0.4623033895411275} | train loss {'Reaction outcome loss': 0.46397726584453974, 'Total loss': 0.46397726584453974}
2022-11-28 06:05:54,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:54,705 INFO:     Epoch: 41
2022-11-28 06:05:55,363 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4656186882745136, 'Total loss': 0.4656186882745136} | train loss {'Reaction outcome loss': 0.4570903686844573, 'Total loss': 0.4570903686844573}
2022-11-28 06:05:55,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:55,364 INFO:     Epoch: 42
2022-11-28 06:05:56,035 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4576768460260196, 'Total loss': 0.4576768460260196} | train loss {'Reaction outcome loss': 0.4570883919693986, 'Total loss': 0.4570883919693986}
2022-11-28 06:05:56,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:56,035 INFO:     Epoch: 43
2022-11-28 06:05:56,712 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45979640971530567, 'Total loss': 0.45979640971530567} | train loss {'Reaction outcome loss': 0.45628680425639057, 'Total loss': 0.45628680425639057}
2022-11-28 06:05:56,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:56,712 INFO:     Epoch: 44
2022-11-28 06:05:57,389 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46660505777055566, 'Total loss': 0.46660505777055566} | train loss {'Reaction outcome loss': 0.4602878887434395, 'Total loss': 0.4602878887434395}
2022-11-28 06:05:57,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:57,390 INFO:     Epoch: 45
2022-11-28 06:05:58,056 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44770281355489383, 'Total loss': 0.44770281355489383} | train loss {'Reaction outcome loss': 0.4614377220674437, 'Total loss': 0.4614377220674437}
2022-11-28 06:05:58,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:58,057 INFO:     Epoch: 46
2022-11-28 06:05:58,720 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4976775212721391, 'Total loss': 0.4976775212721391} | train loss {'Reaction outcome loss': 0.46251640319824217, 'Total loss': 0.46251640319824217}
2022-11-28 06:05:58,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:58,721 INFO:     Epoch: 47
2022-11-28 06:05:59,380 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4688982560553334, 'Total loss': 0.4688982560553334} | train loss {'Reaction outcome loss': 0.46384768796210385, 'Total loss': 0.46384768796210385}
2022-11-28 06:05:59,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:05:59,380 INFO:     Epoch: 48
2022-11-28 06:06:00,040 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5061312859708612, 'Total loss': 0.5061312859708612} | train loss {'Reaction outcome loss': 0.45153091799239725, 'Total loss': 0.45153091799239725}
2022-11-28 06:06:00,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:00,040 INFO:     Epoch: 49
2022-11-28 06:06:00,701 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4656670547344468, 'Total loss': 0.4656670547344468} | train loss {'Reaction outcome loss': 0.46599210689262466, 'Total loss': 0.46599210689262466}
2022-11-28 06:06:00,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:00,701 INFO:     Epoch: 50
2022-11-28 06:06:01,360 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4534976052289659, 'Total loss': 0.4534976052289659} | train loss {'Reaction outcome loss': 0.4628475238474048, 'Total loss': 0.4628475238474048}
2022-11-28 06:06:01,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:01,360 INFO:     Epoch: 51
2022-11-28 06:06:02,019 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48246502402153885, 'Total loss': 0.48246502402153885} | train loss {'Reaction outcome loss': 0.45637481443736017, 'Total loss': 0.45637481443736017}
2022-11-28 06:06:02,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:02,019 INFO:     Epoch: 52
2022-11-28 06:06:02,682 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4453215643086217, 'Total loss': 0.4453215643086217} | train loss {'Reaction outcome loss': 0.46581373032258483, 'Total loss': 0.46581373032258483}
2022-11-28 06:06:02,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:02,682 INFO:     Epoch: 53
2022-11-28 06:06:03,341 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45833528719165106, 'Total loss': 0.45833528719165106} | train loss {'Reaction outcome loss': 0.4597667390594677, 'Total loss': 0.4597667390594677}
2022-11-28 06:06:03,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:03,342 INFO:     Epoch: 54
2022-11-28 06:06:04,000 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45219061693007295, 'Total loss': 0.45219061693007295} | train loss {'Reaction outcome loss': 0.4542567650882565, 'Total loss': 0.4542567650882565}
2022-11-28 06:06:04,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:04,000 INFO:     Epoch: 55
2022-11-28 06:06:04,660 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44497410038655455, 'Total loss': 0.44497410038655455} | train loss {'Reaction outcome loss': 0.4582873889378139, 'Total loss': 0.4582873889378139}
2022-11-28 06:06:04,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:04,660 INFO:     Epoch: 56
2022-11-28 06:06:05,324 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4623102200302211, 'Total loss': 0.4623102200302211} | train loss {'Reaction outcome loss': 0.45960010527348033, 'Total loss': 0.45960010527348033}
2022-11-28 06:06:05,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:05,324 INFO:     Epoch: 57
2022-11-28 06:06:05,983 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46479831127957866, 'Total loss': 0.46479831127957866} | train loss {'Reaction outcome loss': 0.46067404674024, 'Total loss': 0.46067404674024}
2022-11-28 06:06:05,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:05,984 INFO:     Epoch: 58
2022-11-28 06:06:06,642 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4906398145989938, 'Total loss': 0.4906398145989938} | train loss {'Reaction outcome loss': 0.46636985509979484, 'Total loss': 0.46636985509979484}
2022-11-28 06:06:06,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:06,642 INFO:     Epoch: 59
2022-11-28 06:06:07,300 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47272185066884215, 'Total loss': 0.47272185066884215} | train loss {'Reaction outcome loss': 0.4606191300615972, 'Total loss': 0.4606191300615972}
2022-11-28 06:06:07,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:07,301 INFO:     Epoch: 60
2022-11-28 06:06:07,955 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.530304263938557, 'Total loss': 0.530304263938557} | train loss {'Reaction outcome loss': 0.46151333585077403, 'Total loss': 0.46151333585077403}
2022-11-28 06:06:07,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:07,956 INFO:     Epoch: 61
2022-11-28 06:06:08,616 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47928663647987624, 'Total loss': 0.47928663647987624} | train loss {'Reaction outcome loss': 0.4600685261037885, 'Total loss': 0.4600685261037885}
2022-11-28 06:06:08,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:08,616 INFO:     Epoch: 62
2022-11-28 06:06:09,276 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46035813811150467, 'Total loss': 0.46035813811150467} | train loss {'Reaction outcome loss': 0.459865716951234, 'Total loss': 0.459865716951234}
2022-11-28 06:06:09,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:09,276 INFO:     Epoch: 63
2022-11-28 06:06:09,935 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4601763630793853, 'Total loss': 0.4601763630793853} | train loss {'Reaction outcome loss': 0.4515061073765463, 'Total loss': 0.4515061073765463}
2022-11-28 06:06:09,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:09,936 INFO:     Epoch: 64
2022-11-28 06:06:10,592 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4932163604958491, 'Total loss': 0.4932163604958491} | train loss {'Reaction outcome loss': 0.449405128493601, 'Total loss': 0.449405128493601}
2022-11-28 06:06:10,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:10,592 INFO:     Epoch: 65
2022-11-28 06:06:11,248 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4501975771378387, 'Total loss': 0.4501975771378387} | train loss {'Reaction outcome loss': 0.4614758317567864, 'Total loss': 0.4614758317567864}
2022-11-28 06:06:11,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:11,248 INFO:     Epoch: 66
2022-11-28 06:06:11,908 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4598006802526387, 'Total loss': 0.4598006802526387} | train loss {'Reaction outcome loss': 0.4592625842410691, 'Total loss': 0.4592625842410691}
2022-11-28 06:06:11,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:11,908 INFO:     Epoch: 67
2022-11-28 06:06:12,567 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47273254597728903, 'Total loss': 0.47273254597728903} | train loss {'Reaction outcome loss': 0.45662559483732496, 'Total loss': 0.45662559483732496}
2022-11-28 06:06:12,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:12,567 INFO:     Epoch: 68
2022-11-28 06:06:13,226 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48051807487552817, 'Total loss': 0.48051807487552817} | train loss {'Reaction outcome loss': 0.45831934298787796, 'Total loss': 0.45831934298787796}
2022-11-28 06:06:13,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:13,226 INFO:     Epoch: 69
2022-11-28 06:06:13,888 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4767453460530801, 'Total loss': 0.4767453460530801} | train loss {'Reaction outcome loss': 0.4574702613511864, 'Total loss': 0.4574702613511864}
2022-11-28 06:06:13,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:13,888 INFO:     Epoch: 70
2022-11-28 06:06:14,545 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.455459091050381, 'Total loss': 0.455459091050381} | train loss {'Reaction outcome loss': 0.4565725831352935, 'Total loss': 0.4565725831352935}
2022-11-28 06:06:14,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:14,546 INFO:     Epoch: 71
2022-11-28 06:06:15,204 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4948953776197, 'Total loss': 0.4948953776197} | train loss {'Reaction outcome loss': 0.4526250845315505, 'Total loss': 0.4526250845315505}
2022-11-28 06:06:15,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:15,205 INFO:     Epoch: 72
2022-11-28 06:06:15,863 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.450567027553916, 'Total loss': 0.450567027553916} | train loss {'Reaction outcome loss': 0.45922221632636323, 'Total loss': 0.45922221632636323}
2022-11-28 06:06:15,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:15,863 INFO:     Epoch: 73
2022-11-28 06:06:16,520 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47457019510594284, 'Total loss': 0.47457019510594284} | train loss {'Reaction outcome loss': 0.45685752271389474, 'Total loss': 0.45685752271389474}
2022-11-28 06:06:16,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:16,520 INFO:     Epoch: 74
2022-11-28 06:06:17,174 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4683404650793157, 'Total loss': 0.4683404650793157} | train loss {'Reaction outcome loss': 0.4582403767473844, 'Total loss': 0.4582403767473844}
2022-11-28 06:06:17,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:17,174 INFO:     Epoch: 75
2022-11-28 06:06:17,829 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47496144846081734, 'Total loss': 0.47496144846081734} | train loss {'Reaction outcome loss': 0.4530680671638372, 'Total loss': 0.4530680671638372}
2022-11-28 06:06:17,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:17,829 INFO:     Epoch: 76
2022-11-28 06:06:18,485 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46816913614218886, 'Total loss': 0.46816913614218886} | train loss {'Reaction outcome loss': 0.45900675703068167, 'Total loss': 0.45900675703068167}
2022-11-28 06:06:18,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:18,485 INFO:     Epoch: 77
2022-11-28 06:06:19,140 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5262003544379364, 'Total loss': 0.5262003544379364} | train loss {'Reaction outcome loss': 0.45798883304304006, 'Total loss': 0.45798883304304006}
2022-11-28 06:06:19,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:19,141 INFO:     Epoch: 78
2022-11-28 06:06:19,793 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.452818980271166, 'Total loss': 0.452818980271166} | train loss {'Reaction outcome loss': 0.4562574696175906, 'Total loss': 0.4562574696175906}
2022-11-28 06:06:19,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:19,794 INFO:     Epoch: 79
2022-11-28 06:06:20,445 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5011365643956445, 'Total loss': 0.5011365643956445} | train loss {'Reaction outcome loss': 0.44951635179470995, 'Total loss': 0.44951635179470995}
2022-11-28 06:06:20,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:20,445 INFO:     Epoch: 80
2022-11-28 06:06:21,098 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4734607200053605, 'Total loss': 0.4734607200053605} | train loss {'Reaction outcome loss': 0.4527755600457289, 'Total loss': 0.4527755600457289}
2022-11-28 06:06:21,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:21,099 INFO:     Epoch: 81
2022-11-28 06:06:21,754 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4604051566936753, 'Total loss': 0.4604051566936753} | train loss {'Reaction outcome loss': 0.4576417048366702, 'Total loss': 0.4576417048366702}
2022-11-28 06:06:21,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:21,755 INFO:     Epoch: 82
2022-11-28 06:06:22,408 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4634122235531157, 'Total loss': 0.4634122235531157} | train loss {'Reaction outcome loss': 0.45066686290867475, 'Total loss': 0.45066686290867475}
2022-11-28 06:06:22,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:22,409 INFO:     Epoch: 83
2022-11-28 06:06:23,061 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47193631902337074, 'Total loss': 0.47193631902337074} | train loss {'Reaction outcome loss': 0.45016512511944284, 'Total loss': 0.45016512511944284}
2022-11-28 06:06:23,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:23,061 INFO:     Epoch: 84
2022-11-28 06:06:23,714 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44485608623786405, 'Total loss': 0.44485608623786405} | train loss {'Reaction outcome loss': 0.4547475454150414, 'Total loss': 0.4547475454150414}
2022-11-28 06:06:23,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:23,714 INFO:     Epoch: 85
2022-11-28 06:06:24,361 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4744840237227353, 'Total loss': 0.4744840237227353} | train loss {'Reaction outcome loss': 0.4493301578626341, 'Total loss': 0.4493301578626341}
2022-11-28 06:06:24,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:24,361 INFO:     Epoch: 86
2022-11-28 06:06:25,015 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5034223337742415, 'Total loss': 0.5034223337742415} | train loss {'Reaction outcome loss': 0.4575985648650296, 'Total loss': 0.4575985648650296}
2022-11-28 06:06:25,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:25,015 INFO:     Epoch: 87
2022-11-28 06:06:25,667 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4576800804246556, 'Total loss': 0.4576800804246556} | train loss {'Reaction outcome loss': 0.4592859705491942, 'Total loss': 0.4592859705491942}
2022-11-28 06:06:25,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:25,667 INFO:     Epoch: 88
2022-11-28 06:06:26,321 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47803557698022237, 'Total loss': 0.47803557698022237} | train loss {'Reaction outcome loss': 0.45932217453207286, 'Total loss': 0.45932217453207286}
2022-11-28 06:06:26,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:26,321 INFO:     Epoch: 89
2022-11-28 06:06:26,975 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4530106892978603, 'Total loss': 0.4530106892978603} | train loss {'Reaction outcome loss': 0.46247660998178985, 'Total loss': 0.46247660998178985}
2022-11-28 06:06:26,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:26,975 INFO:     Epoch: 90
2022-11-28 06:06:27,629 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4592523818666285, 'Total loss': 0.4592523818666285} | train loss {'Reaction outcome loss': 0.45502433241630086, 'Total loss': 0.45502433241630086}
2022-11-28 06:06:27,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:27,630 INFO:     Epoch: 91
2022-11-28 06:06:28,280 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4687096090479331, 'Total loss': 0.4687096090479331} | train loss {'Reaction outcome loss': 0.4536381116935185, 'Total loss': 0.4536381116935185}
2022-11-28 06:06:28,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:28,280 INFO:     Epoch: 92
2022-11-28 06:06:28,929 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47006771713495255, 'Total loss': 0.47006771713495255} | train loss {'Reaction outcome loss': 0.45450915548266196, 'Total loss': 0.45450915548266196}
2022-11-28 06:06:28,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:28,929 INFO:     Epoch: 93
2022-11-28 06:06:29,578 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.452389351346276, 'Total loss': 0.452389351346276} | train loss {'Reaction outcome loss': 0.45949244778983445, 'Total loss': 0.45949244778983445}
2022-11-28 06:06:29,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:29,578 INFO:     Epoch: 94
2022-11-28 06:06:30,230 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.474918297407302, 'Total loss': 0.474918297407302} | train loss {'Reaction outcome loss': 0.4576467770702985, 'Total loss': 0.4576467770702985}
2022-11-28 06:06:30,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:30,230 INFO:     Epoch: 95
2022-11-28 06:06:30,879 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45990761098536576, 'Total loss': 0.45990761098536576} | train loss {'Reaction outcome loss': 0.45296251919804786, 'Total loss': 0.45296251919804786}
2022-11-28 06:06:30,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:30,879 INFO:     Epoch: 96
2022-11-28 06:06:31,530 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4931336624378508, 'Total loss': 0.4931336624378508} | train loss {'Reaction outcome loss': 0.4592354475843663, 'Total loss': 0.4592354475843663}
2022-11-28 06:06:31,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:31,530 INFO:     Epoch: 97
2022-11-28 06:06:32,179 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48091373829679057, 'Total loss': 0.48091373829679057} | train loss {'Reaction outcome loss': 0.4582830566532758, 'Total loss': 0.4582830566532758}
2022-11-28 06:06:32,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:32,180 INFO:     Epoch: 98
2022-11-28 06:06:32,827 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43774854933673685, 'Total loss': 0.43774854933673685} | train loss {'Reaction outcome loss': 0.45682681531322245, 'Total loss': 0.45682681531322245}
2022-11-28 06:06:32,827 INFO:     Found new best model at epoch 98
2022-11-28 06:06:32,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:32,828 INFO:     Epoch: 99
2022-11-28 06:06:33,480 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4588553614237092, 'Total loss': 0.4588553614237092} | train loss {'Reaction outcome loss': 0.45404355872650537, 'Total loss': 0.45404355872650537}
2022-11-28 06:06:33,480 INFO:     Best model found after epoch 99 of 100.
2022-11-28 06:06:33,480 INFO:   Done with stage: TRAINING
2022-11-28 06:06:33,480 INFO:   Starting stage: EVALUATION
2022-11-28 06:06:33,604 INFO:   Done with stage: EVALUATION
2022-11-28 06:06:33,604 INFO:   Leaving out SEQ value Fold_4
2022-11-28 06:06:33,617 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:06:33,617 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:06:34,265 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:06:34,266 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:06:34,335 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:06:34,335 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:06:34,335 INFO:     No hyperparam tuning for this model
2022-11-28 06:06:34,335 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:06:34,335 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:06:34,336 INFO:     None feature selector for col prot
2022-11-28 06:06:34,336 INFO:     None feature selector for col prot
2022-11-28 06:06:34,336 INFO:     None feature selector for col prot
2022-11-28 06:06:34,337 INFO:     None feature selector for col chem
2022-11-28 06:06:34,337 INFO:     None feature selector for col chem
2022-11-28 06:06:34,337 INFO:     None feature selector for col chem
2022-11-28 06:06:34,337 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:06:34,337 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:06:34,338 INFO:     Number of params in model 169651
2022-11-28 06:06:34,341 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:06:34,341 INFO:   Starting stage: TRAINING
2022-11-28 06:06:34,392 INFO:     Val loss before train {'Reaction outcome loss': 1.0287777049974962, 'Total loss': 1.0287777049974962}
2022-11-28 06:06:34,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:34,392 INFO:     Epoch: 0
2022-11-28 06:06:35,053 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.60113605924628, 'Total loss': 0.60113605924628} | train loss {'Reaction outcome loss': 0.6851782695420326, 'Total loss': 0.6851782695420326}
2022-11-28 06:06:35,054 INFO:     Found new best model at epoch 0
2022-11-28 06:06:35,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:35,054 INFO:     Epoch: 1
2022-11-28 06:06:35,712 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5838326588273048, 'Total loss': 0.5838326588273048} | train loss {'Reaction outcome loss': 0.5952890762278149, 'Total loss': 0.5952890762278149}
2022-11-28 06:06:35,712 INFO:     Found new best model at epoch 1
2022-11-28 06:06:35,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:35,712 INFO:     Epoch: 2
2022-11-28 06:06:36,369 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5729536536065015, 'Total loss': 0.5729536536065015} | train loss {'Reaction outcome loss': 0.5544007263116298, 'Total loss': 0.5544007263116298}
2022-11-28 06:06:36,369 INFO:     Found new best model at epoch 2
2022-11-28 06:06:36,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:36,370 INFO:     Epoch: 3
2022-11-28 06:06:37,029 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5813899731094186, 'Total loss': 0.5813899731094186} | train loss {'Reaction outcome loss': 0.531494180461572, 'Total loss': 0.531494180461572}
2022-11-28 06:06:37,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:37,029 INFO:     Epoch: 4
2022-11-28 06:06:37,690 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5228631252592261, 'Total loss': 0.5228631252592261} | train loss {'Reaction outcome loss': 0.5243335148139346, 'Total loss': 0.5243335148139346}
2022-11-28 06:06:37,690 INFO:     Found new best model at epoch 4
2022-11-28 06:06:37,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:37,690 INFO:     Epoch: 5
2022-11-28 06:06:38,347 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5284089520573616, 'Total loss': 0.5284089520573616} | train loss {'Reaction outcome loss': 0.5199414092686868, 'Total loss': 0.5199414092686868}
2022-11-28 06:06:38,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:38,348 INFO:     Epoch: 6
2022-11-28 06:06:39,002 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5361215475608002, 'Total loss': 0.5361215475608002} | train loss {'Reaction outcome loss': 0.52158618315814, 'Total loss': 0.52158618315814}
2022-11-28 06:06:39,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:39,002 INFO:     Epoch: 7
2022-11-28 06:06:39,661 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5269642936235125, 'Total loss': 0.5269642936235125} | train loss {'Reaction outcome loss': 0.5071406524868742, 'Total loss': 0.5071406524868742}
2022-11-28 06:06:39,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:39,661 INFO:     Epoch: 8
2022-11-28 06:06:40,323 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4882397655058991, 'Total loss': 0.4882397655058991} | train loss {'Reaction outcome loss': 0.5092039662263086, 'Total loss': 0.5092039662263086}
2022-11-28 06:06:40,323 INFO:     Found new best model at epoch 8
2022-11-28 06:06:40,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:40,324 INFO:     Epoch: 9
2022-11-28 06:06:40,983 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5166713365099647, 'Total loss': 0.5166713365099647} | train loss {'Reaction outcome loss': 0.51975605252289, 'Total loss': 0.51975605252289}
2022-11-28 06:06:40,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:40,983 INFO:     Epoch: 10
2022-11-28 06:06:41,640 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.499199815094471, 'Total loss': 0.499199815094471} | train loss {'Reaction outcome loss': 0.4948352961049926, 'Total loss': 0.4948352961049926}
2022-11-28 06:06:41,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:41,640 INFO:     Epoch: 11
2022-11-28 06:06:42,298 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47940083051269705, 'Total loss': 0.47940083051269705} | train loss {'Reaction outcome loss': 0.49039237717947654, 'Total loss': 0.49039237717947654}
2022-11-28 06:06:42,299 INFO:     Found new best model at epoch 11
2022-11-28 06:06:42,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:42,299 INFO:     Epoch: 12
2022-11-28 06:06:42,958 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5116867106407881, 'Total loss': 0.5116867106407881} | train loss {'Reaction outcome loss': 0.4922201551436897, 'Total loss': 0.4922201551436897}
2022-11-28 06:06:42,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:42,958 INFO:     Epoch: 13
2022-11-28 06:06:43,613 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48398797688159073, 'Total loss': 0.48398797688159073} | train loss {'Reaction outcome loss': 0.4921820524238771, 'Total loss': 0.4921820524238771}
2022-11-28 06:06:43,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:43,614 INFO:     Epoch: 14
2022-11-28 06:06:44,274 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5050875449722464, 'Total loss': 0.5050875449722464} | train loss {'Reaction outcome loss': 0.4977008359086129, 'Total loss': 0.4977008359086129}
2022-11-28 06:06:44,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:44,274 INFO:     Epoch: 15
2022-11-28 06:06:44,935 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5342863500118256, 'Total loss': 0.5342863500118256} | train loss {'Reaction outcome loss': 0.483930827689267, 'Total loss': 0.483930827689267}
2022-11-28 06:06:44,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:44,935 INFO:     Epoch: 16
2022-11-28 06:06:45,599 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5033943504095078, 'Total loss': 0.5033943504095078} | train loss {'Reaction outcome loss': 0.48345400987853926, 'Total loss': 0.48345400987853926}
2022-11-28 06:06:45,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:45,599 INFO:     Epoch: 17
2022-11-28 06:06:46,255 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5051202354106036, 'Total loss': 0.5051202354106036} | train loss {'Reaction outcome loss': 0.4798800670692036, 'Total loss': 0.4798800670692036}
2022-11-28 06:06:46,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:46,257 INFO:     Epoch: 18
2022-11-28 06:06:46,910 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.6545669483867559, 'Total loss': 0.6545669483867559} | train loss {'Reaction outcome loss': 0.47960160636613447, 'Total loss': 0.47960160636613447}
2022-11-28 06:06:46,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:46,910 INFO:     Epoch: 19
2022-11-28 06:06:47,567 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5038667558269068, 'Total loss': 0.5038667558269068} | train loss {'Reaction outcome loss': 0.48604916510803087, 'Total loss': 0.48604916510803087}
2022-11-28 06:06:47,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:47,567 INFO:     Epoch: 20
2022-11-28 06:06:48,226 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5341140221465718, 'Total loss': 0.5341140221465718} | train loss {'Reaction outcome loss': 0.47031295569914, 'Total loss': 0.47031295569914}
2022-11-28 06:06:48,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:48,226 INFO:     Epoch: 21
2022-11-28 06:06:48,881 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5021826577457514, 'Total loss': 0.5021826577457514} | train loss {'Reaction outcome loss': 0.46677623058278717, 'Total loss': 0.46677623058278717}
2022-11-28 06:06:48,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:48,882 INFO:     Epoch: 22
2022-11-28 06:06:49,537 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.531918382102793, 'Total loss': 0.531918382102793} | train loss {'Reaction outcome loss': 0.4827021310826944, 'Total loss': 0.4827021310826944}
2022-11-28 06:06:49,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:49,537 INFO:     Epoch: 23
2022-11-28 06:06:50,194 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4814010350541635, 'Total loss': 0.4814010350541635} | train loss {'Reaction outcome loss': 0.4664171062289707, 'Total loss': 0.4664171062289707}
2022-11-28 06:06:50,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:50,194 INFO:     Epoch: 24
2022-11-28 06:06:50,856 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5117154561660506, 'Total loss': 0.5117154561660506} | train loss {'Reaction outcome loss': 0.47754382324074546, 'Total loss': 0.47754382324074546}
2022-11-28 06:06:50,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:50,856 INFO:     Epoch: 25
2022-11-28 06:06:51,516 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4867454841732979, 'Total loss': 0.4867454841732979} | train loss {'Reaction outcome loss': 0.47394867851248673, 'Total loss': 0.47394867851248673}
2022-11-28 06:06:51,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:51,517 INFO:     Epoch: 26
2022-11-28 06:06:52,174 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4896294715052301, 'Total loss': 0.4896294715052301} | train loss {'Reaction outcome loss': 0.47006675126331465, 'Total loss': 0.47006675126331465}
2022-11-28 06:06:52,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:52,174 INFO:     Epoch: 27
2022-11-28 06:06:52,834 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5184218016537753, 'Total loss': 0.5184218016537753} | train loss {'Reaction outcome loss': 0.4758110332392877, 'Total loss': 0.4758110332392877}
2022-11-28 06:06:52,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:52,835 INFO:     Epoch: 28
2022-11-28 06:06:53,493 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48493312062187627, 'Total loss': 0.48493312062187627} | train loss {'Reaction outcome loss': 0.46791560112709, 'Total loss': 0.46791560112709}
2022-11-28 06:06:53,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:53,494 INFO:     Epoch: 29
2022-11-28 06:06:54,155 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46463467891920696, 'Total loss': 0.46463467891920696} | train loss {'Reaction outcome loss': 0.46526083560480225, 'Total loss': 0.46526083560480225}
2022-11-28 06:06:54,155 INFO:     Found new best model at epoch 29
2022-11-28 06:06:54,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:54,156 INFO:     Epoch: 30
2022-11-28 06:06:54,813 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5703961869532411, 'Total loss': 0.5703961869532411} | train loss {'Reaction outcome loss': 0.4634129450085663, 'Total loss': 0.4634129450085663}
2022-11-28 06:06:54,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:54,813 INFO:     Epoch: 31
2022-11-28 06:06:55,469 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.505127031694759, 'Total loss': 0.505127031694759} | train loss {'Reaction outcome loss': 0.47019054987017184, 'Total loss': 0.47019054987017184}
2022-11-28 06:06:55,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:55,469 INFO:     Epoch: 32
2022-11-28 06:06:56,127 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49531630697575485, 'Total loss': 0.49531630697575485} | train loss {'Reaction outcome loss': 0.46472636904687653, 'Total loss': 0.46472636904687653}
2022-11-28 06:06:56,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:56,127 INFO:     Epoch: 33
2022-11-28 06:06:56,784 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49743391607295384, 'Total loss': 0.49743391607295384} | train loss {'Reaction outcome loss': 0.46369017384225325, 'Total loss': 0.46369017384225325}
2022-11-28 06:06:56,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:56,784 INFO:     Epoch: 34
2022-11-28 06:06:57,440 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5085950697010214, 'Total loss': 0.5085950697010214} | train loss {'Reaction outcome loss': 0.4643298574993687, 'Total loss': 0.4643298574993687}
2022-11-28 06:06:57,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:57,441 INFO:     Epoch: 35
2022-11-28 06:06:58,099 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4750327749008482, 'Total loss': 0.4750327749008482} | train loss {'Reaction outcome loss': 0.4680118599245625, 'Total loss': 0.4680118599245625}
2022-11-28 06:06:58,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:58,100 INFO:     Epoch: 36
2022-11-28 06:06:58,757 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4602382149208676, 'Total loss': 0.4602382149208676} | train loss {'Reaction outcome loss': 0.4751412257732403, 'Total loss': 0.4751412257732403}
2022-11-28 06:06:58,757 INFO:     Found new best model at epoch 36
2022-11-28 06:06:58,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:58,758 INFO:     Epoch: 37
2022-11-28 06:06:59,413 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47126917270096863, 'Total loss': 0.47126917270096863} | train loss {'Reaction outcome loss': 0.4699879008675775, 'Total loss': 0.4699879008675775}
2022-11-28 06:06:59,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:06:59,413 INFO:     Epoch: 38
2022-11-28 06:07:00,068 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4563742053102363, 'Total loss': 0.4563742053102363} | train loss {'Reaction outcome loss': 0.461345961587804, 'Total loss': 0.461345961587804}
2022-11-28 06:07:00,068 INFO:     Found new best model at epoch 38
2022-11-28 06:07:00,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:00,069 INFO:     Epoch: 39
2022-11-28 06:07:00,727 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5220946161584421, 'Total loss': 0.5220946161584421} | train loss {'Reaction outcome loss': 0.4663628759463468, 'Total loss': 0.4663628759463468}
2022-11-28 06:07:00,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:00,727 INFO:     Epoch: 40
2022-11-28 06:07:01,383 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47476010566407983, 'Total loss': 0.47476010566407983} | train loss {'Reaction outcome loss': 0.4638371497632996, 'Total loss': 0.4638371497632996}
2022-11-28 06:07:01,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:01,383 INFO:     Epoch: 41
2022-11-28 06:07:02,041 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4665540341626514, 'Total loss': 0.4665540341626514} | train loss {'Reaction outcome loss': 0.4672418579519276, 'Total loss': 0.4672418579519276}
2022-11-28 06:07:02,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:02,041 INFO:     Epoch: 42
2022-11-28 06:07:02,695 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44253856959668075, 'Total loss': 0.44253856959668075} | train loss {'Reaction outcome loss': 0.4663323472824789, 'Total loss': 0.4663323472824789}
2022-11-28 06:07:02,695 INFO:     Found new best model at epoch 42
2022-11-28 06:07:02,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:02,696 INFO:     Epoch: 43
2022-11-28 06:07:03,353 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4819852642037652, 'Total loss': 0.4819852642037652} | train loss {'Reaction outcome loss': 0.4641726245322535, 'Total loss': 0.4641726245322535}
2022-11-28 06:07:03,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:03,354 INFO:     Epoch: 44
2022-11-28 06:07:04,013 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47091101787307044, 'Total loss': 0.47091101787307044} | train loss {'Reaction outcome loss': 0.4674006734764384, 'Total loss': 0.4674006734764384}
2022-11-28 06:07:04,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:04,013 INFO:     Epoch: 45
2022-11-28 06:07:04,671 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4591068886220455, 'Total loss': 0.4591068886220455} | train loss {'Reaction outcome loss': 0.4587865916771754, 'Total loss': 0.4587865916771754}
2022-11-28 06:07:04,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:04,671 INFO:     Epoch: 46
2022-11-28 06:07:05,330 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5958190777085044, 'Total loss': 0.5958190777085044} | train loss {'Reaction outcome loss': 0.4683717231476499, 'Total loss': 0.4683717231476499}
2022-11-28 06:07:05,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:05,331 INFO:     Epoch: 47
2022-11-28 06:07:05,991 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45136466554620047, 'Total loss': 0.45136466554620047} | train loss {'Reaction outcome loss': 0.46328213017794395, 'Total loss': 0.46328213017794395}
2022-11-28 06:07:05,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:05,991 INFO:     Epoch: 48
2022-11-28 06:07:06,650 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4539255543865941, 'Total loss': 0.4539255543865941} | train loss {'Reaction outcome loss': 0.4694413257943046, 'Total loss': 0.4694413257943046}
2022-11-28 06:07:06,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:06,651 INFO:     Epoch: 49
2022-11-28 06:07:07,312 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4878601391207088, 'Total loss': 0.4878601391207088} | train loss {'Reaction outcome loss': 0.4659290420672586, 'Total loss': 0.4659290420672586}
2022-11-28 06:07:07,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:07,312 INFO:     Epoch: 50
2022-11-28 06:07:07,966 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4545731232924895, 'Total loss': 0.4545731232924895} | train loss {'Reaction outcome loss': 0.45926935174652644, 'Total loss': 0.45926935174652644}
2022-11-28 06:07:07,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:07,967 INFO:     Epoch: 51
2022-11-28 06:07:08,623 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.6141463348811323, 'Total loss': 0.6141463348811323} | train loss {'Reaction outcome loss': 0.47091990132485667, 'Total loss': 0.47091990132485667}
2022-11-28 06:07:08,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:08,623 INFO:     Epoch: 52
2022-11-28 06:07:09,282 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5312860601327636, 'Total loss': 0.5312860601327636} | train loss {'Reaction outcome loss': 0.46743233210497326, 'Total loss': 0.46743233210497326}
2022-11-28 06:07:09,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:09,282 INFO:     Epoch: 53
2022-11-28 06:07:09,943 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4947846890850501, 'Total loss': 0.4947846890850501} | train loss {'Reaction outcome loss': 0.47407308557341177, 'Total loss': 0.47407308557341177}
2022-11-28 06:07:09,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:09,943 INFO:     Epoch: 54
2022-11-28 06:07:10,600 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.471665389158509, 'Total loss': 0.471665389158509} | train loss {'Reaction outcome loss': 0.4616648639221826, 'Total loss': 0.4616648639221826}
2022-11-28 06:07:10,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:10,600 INFO:     Epoch: 55
2022-11-28 06:07:11,262 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5115889591926878, 'Total loss': 0.5115889591926878} | train loss {'Reaction outcome loss': 0.4607316434623734, 'Total loss': 0.4607316434623734}
2022-11-28 06:07:11,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:11,262 INFO:     Epoch: 56
2022-11-28 06:07:11,921 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46871007504788315, 'Total loss': 0.46871007504788315} | train loss {'Reaction outcome loss': 0.4759125519664057, 'Total loss': 0.4759125519664057}
2022-11-28 06:07:11,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:11,921 INFO:     Epoch: 57
2022-11-28 06:07:12,580 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48020724816755816, 'Total loss': 0.48020724816755816} | train loss {'Reaction outcome loss': 0.4742791677014001, 'Total loss': 0.4742791677014001}
2022-11-28 06:07:12,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:12,581 INFO:     Epoch: 58
2022-11-28 06:07:13,242 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44943498278206045, 'Total loss': 0.44943498278206045} | train loss {'Reaction outcome loss': 0.47052673358590374, 'Total loss': 0.47052673358590374}
2022-11-28 06:07:13,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:13,242 INFO:     Epoch: 59
2022-11-28 06:07:13,900 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46306306089867244, 'Total loss': 0.46306306089867244} | train loss {'Reaction outcome loss': 0.46525062584588606, 'Total loss': 0.46525062584588606}
2022-11-28 06:07:13,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:13,901 INFO:     Epoch: 60
2022-11-28 06:07:14,559 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5215261741117998, 'Total loss': 0.5215261741117998} | train loss {'Reaction outcome loss': 0.4658626111284379, 'Total loss': 0.4658626111284379}
2022-11-28 06:07:14,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:14,559 INFO:     Epoch: 61
2022-11-28 06:07:15,217 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46960168839855626, 'Total loss': 0.46960168839855626} | train loss {'Reaction outcome loss': 0.460886278700444, 'Total loss': 0.460886278700444}
2022-11-28 06:07:15,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:15,218 INFO:     Epoch: 62
2022-11-28 06:07:15,874 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4674217975275083, 'Total loss': 0.4674217975275083} | train loss {'Reaction outcome loss': 0.46044810987528295, 'Total loss': 0.46044810987528295}
2022-11-28 06:07:15,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:15,874 INFO:     Epoch: 63
2022-11-28 06:07:16,533 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48014956272461196, 'Total loss': 0.48014956272461196} | train loss {'Reaction outcome loss': 0.4732480768955523, 'Total loss': 0.4732480768955523}
2022-11-28 06:07:16,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:16,534 INFO:     Epoch: 64
2022-11-28 06:07:17,197 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4508931436999278, 'Total loss': 0.4508931436999278} | train loss {'Reaction outcome loss': 0.4646256444975734, 'Total loss': 0.4646256444975734}
2022-11-28 06:07:17,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:17,198 INFO:     Epoch: 65
2022-11-28 06:07:17,858 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5363544129173864, 'Total loss': 0.5363544129173864} | train loss {'Reaction outcome loss': 0.4668854280344902, 'Total loss': 0.4668854280344902}
2022-11-28 06:07:17,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:17,858 INFO:     Epoch: 66
2022-11-28 06:07:18,517 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46617898074063385, 'Total loss': 0.46617898074063385} | train loss {'Reaction outcome loss': 0.4695446256908678, 'Total loss': 0.4695446256908678}
2022-11-28 06:07:18,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:18,518 INFO:     Epoch: 67
2022-11-28 06:07:19,180 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4456835277378559, 'Total loss': 0.4456835277378559} | train loss {'Reaction outcome loss': 0.4682282707804153, 'Total loss': 0.4682282707804153}
2022-11-28 06:07:19,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:19,180 INFO:     Epoch: 68
2022-11-28 06:07:19,841 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47709307667206635, 'Total loss': 0.47709307667206635} | train loss {'Reaction outcome loss': 0.46524077326419855, 'Total loss': 0.46524077326419855}
2022-11-28 06:07:19,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:19,841 INFO:     Epoch: 69
2022-11-28 06:07:20,503 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4834428998557004, 'Total loss': 0.4834428998557004} | train loss {'Reaction outcome loss': 0.468165050410936, 'Total loss': 0.468165050410936}
2022-11-28 06:07:20,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:20,503 INFO:     Epoch: 70
2022-11-28 06:07:21,167 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4644312547011809, 'Total loss': 0.4644312547011809} | train loss {'Reaction outcome loss': 0.46629192890419113, 'Total loss': 0.46629192890419113}
2022-11-28 06:07:21,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:21,168 INFO:     Epoch: 71
2022-11-28 06:07:21,832 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5135661170563914, 'Total loss': 0.5135661170563914} | train loss {'Reaction outcome loss': 0.4626725352699718, 'Total loss': 0.4626725352699718}
2022-11-28 06:07:21,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:21,833 INFO:     Epoch: 72
2022-11-28 06:07:22,496 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4640748846259984, 'Total loss': 0.4640748846259984} | train loss {'Reaction outcome loss': 0.4673641990990408, 'Total loss': 0.4673641990990408}
2022-11-28 06:07:22,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:22,496 INFO:     Epoch: 73
2022-11-28 06:07:23,156 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.464613367210735, 'Total loss': 0.464613367210735} | train loss {'Reaction outcome loss': 0.46761675882003, 'Total loss': 0.46761675882003}
2022-11-28 06:07:23,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:23,156 INFO:     Epoch: 74
2022-11-28 06:07:23,813 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48452733660286124, 'Total loss': 0.48452733660286124} | train loss {'Reaction outcome loss': 0.47180729563678464, 'Total loss': 0.47180729563678464}
2022-11-28 06:07:23,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:23,814 INFO:     Epoch: 75
2022-11-28 06:07:24,472 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45601837506348436, 'Total loss': 0.45601837506348436} | train loss {'Reaction outcome loss': 0.46643380832768255, 'Total loss': 0.46643380832768255}
2022-11-28 06:07:24,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:24,472 INFO:     Epoch: 76
2022-11-28 06:07:25,131 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4585576687346805, 'Total loss': 0.4585576687346805} | train loss {'Reaction outcome loss': 0.46353971423400986, 'Total loss': 0.46353971423400986}
2022-11-28 06:07:25,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:25,132 INFO:     Epoch: 77
2022-11-28 06:07:25,793 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5101459490304644, 'Total loss': 0.5101459490304644} | train loss {'Reaction outcome loss': 0.46309871959590143, 'Total loss': 0.46309871959590143}
2022-11-28 06:07:25,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:25,793 INFO:     Epoch: 78
2022-11-28 06:07:26,452 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4430257623845881, 'Total loss': 0.4430257623845881} | train loss {'Reaction outcome loss': 0.46798088053061115, 'Total loss': 0.46798088053061115}
2022-11-28 06:07:26,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:26,452 INFO:     Epoch: 79
2022-11-28 06:07:27,115 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44835754721002147, 'Total loss': 0.44835754721002147} | train loss {'Reaction outcome loss': 0.46851280701136394, 'Total loss': 0.46851280701136394}
2022-11-28 06:07:27,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:27,115 INFO:     Epoch: 80
2022-11-28 06:07:27,777 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5160694325512106, 'Total loss': 0.5160694325512106} | train loss {'Reaction outcome loss': 0.4647678001032722, 'Total loss': 0.4647678001032722}
2022-11-28 06:07:27,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:27,777 INFO:     Epoch: 81
2022-11-28 06:07:28,439 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46412469717589294, 'Total loss': 0.46412469717589294} | train loss {'Reaction outcome loss': 0.4604926338239062, 'Total loss': 0.4604926338239062}
2022-11-28 06:07:28,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:28,440 INFO:     Epoch: 82
2022-11-28 06:07:29,104 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47821947119452735, 'Total loss': 0.47821947119452735} | train loss {'Reaction outcome loss': 0.4625228040761525, 'Total loss': 0.4625228040761525}
2022-11-28 06:07:29,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:29,105 INFO:     Epoch: 83
2022-11-28 06:07:29,766 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47661498527635227, 'Total loss': 0.47661498527635227} | train loss {'Reaction outcome loss': 0.4612885182422976, 'Total loss': 0.4612885182422976}
2022-11-28 06:07:29,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:29,766 INFO:     Epoch: 84
2022-11-28 06:07:30,428 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45107116109945555, 'Total loss': 0.45107116109945555} | train loss {'Reaction outcome loss': 0.4645287420360311, 'Total loss': 0.4645287420360311}
2022-11-28 06:07:30,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:30,428 INFO:     Epoch: 85
2022-11-28 06:07:31,089 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46889023550532083, 'Total loss': 0.46889023550532083} | train loss {'Reaction outcome loss': 0.4622220319710792, 'Total loss': 0.4622220319710792}
2022-11-28 06:07:31,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:31,089 INFO:     Epoch: 86
2022-11-28 06:07:31,751 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4428463009270755, 'Total loss': 0.4428463009270755} | train loss {'Reaction outcome loss': 0.45961234574356385, 'Total loss': 0.45961234574356385}
2022-11-28 06:07:31,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:31,751 INFO:     Epoch: 87
2022-11-28 06:07:32,412 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46041539616205474, 'Total loss': 0.46041539616205474} | train loss {'Reaction outcome loss': 0.46474333131505596, 'Total loss': 0.46474333131505596}
2022-11-28 06:07:32,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:32,413 INFO:     Epoch: 88
2022-11-28 06:07:33,076 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45218860087069596, 'Total loss': 0.45218860087069596} | train loss {'Reaction outcome loss': 0.4687528883016879, 'Total loss': 0.4687528883016879}
2022-11-28 06:07:33,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:33,077 INFO:     Epoch: 89
2022-11-28 06:07:33,741 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4574670209126039, 'Total loss': 0.4574670209126039} | train loss {'Reaction outcome loss': 0.4646447687860458, 'Total loss': 0.4646447687860458}
2022-11-28 06:07:33,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:33,741 INFO:     Epoch: 90
2022-11-28 06:07:34,405 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4574129669503732, 'Total loss': 0.4574129669503732} | train loss {'Reaction outcome loss': 0.4661539869322892, 'Total loss': 0.4661539869322892}
2022-11-28 06:07:34,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:34,405 INFO:     Epoch: 91
2022-11-28 06:07:35,067 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4632379077374935, 'Total loss': 0.4632379077374935} | train loss {'Reaction outcome loss': 0.4728187215063841, 'Total loss': 0.4728187215063841}
2022-11-28 06:07:35,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:35,067 INFO:     Epoch: 92
2022-11-28 06:07:35,727 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5089500522748991, 'Total loss': 0.5089500522748991} | train loss {'Reaction outcome loss': 0.46490298614146247, 'Total loss': 0.46490298614146247}
2022-11-28 06:07:35,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:35,727 INFO:     Epoch: 93
2022-11-28 06:07:36,388 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49591717462648044, 'Total loss': 0.49591717462648044} | train loss {'Reaction outcome loss': 0.4604811367368506, 'Total loss': 0.4604811367368506}
2022-11-28 06:07:36,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:36,389 INFO:     Epoch: 94
2022-11-28 06:07:37,046 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4838380366563797, 'Total loss': 0.4838380366563797} | train loss {'Reaction outcome loss': 0.4610485430927046, 'Total loss': 0.4610485430927046}
2022-11-28 06:07:37,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:37,047 INFO:     Epoch: 95
2022-11-28 06:07:37,709 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45512067018584773, 'Total loss': 0.45512067018584773} | train loss {'Reaction outcome loss': 0.4636558978668144, 'Total loss': 0.4636558978668144}
2022-11-28 06:07:37,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:37,710 INFO:     Epoch: 96
2022-11-28 06:07:38,368 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47084820101206953, 'Total loss': 0.47084820101206953} | train loss {'Reaction outcome loss': 0.4599440331841188, 'Total loss': 0.4599440331841188}
2022-11-28 06:07:38,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:38,368 INFO:     Epoch: 97
2022-11-28 06:07:39,026 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49530202556740155, 'Total loss': 0.49530202556740155} | train loss {'Reaction outcome loss': 0.4663615628716446, 'Total loss': 0.4663615628716446}
2022-11-28 06:07:39,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:39,027 INFO:     Epoch: 98
2022-11-28 06:07:39,688 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46559312871911307, 'Total loss': 0.46559312871911307} | train loss {'Reaction outcome loss': 0.4638748674262916, 'Total loss': 0.4638748674262916}
2022-11-28 06:07:39,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:39,688 INFO:     Epoch: 99
2022-11-28 06:07:40,347 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4645889106799256, 'Total loss': 0.4645889106799256} | train loss {'Reaction outcome loss': 0.4645071012839194, 'Total loss': 0.4645071012839194}
2022-11-28 06:07:40,347 INFO:     Best model found after epoch 43 of 100.
2022-11-28 06:07:40,347 INFO:   Done with stage: TRAINING
2022-11-28 06:07:40,347 INFO:   Starting stage: EVALUATION
2022-11-28 06:07:40,460 INFO:   Done with stage: EVALUATION
2022-11-28 06:07:40,460 INFO:   Leaving out SEQ value Fold_5
2022-11-28 06:07:40,473 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:07:40,473 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:07:41,115 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:07:41,115 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:07:41,185 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:07:41,185 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:07:41,186 INFO:     No hyperparam tuning for this model
2022-11-28 06:07:41,186 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:07:41,186 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:07:41,186 INFO:     None feature selector for col prot
2022-11-28 06:07:41,186 INFO:     None feature selector for col prot
2022-11-28 06:07:41,187 INFO:     None feature selector for col prot
2022-11-28 06:07:41,187 INFO:     None feature selector for col chem
2022-11-28 06:07:41,187 INFO:     None feature selector for col chem
2022-11-28 06:07:41,187 INFO:     None feature selector for col chem
2022-11-28 06:07:41,187 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:07:41,187 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:07:41,189 INFO:     Number of params in model 169651
2022-11-28 06:07:41,192 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:07:41,192 INFO:   Starting stage: TRAINING
2022-11-28 06:07:41,242 INFO:     Val loss before train {'Reaction outcome loss': 0.9019523398442701, 'Total loss': 0.9019523398442701}
2022-11-28 06:07:41,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:41,242 INFO:     Epoch: 0
2022-11-28 06:07:41,907 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5257306105711244, 'Total loss': 0.5257306105711244} | train loss {'Reaction outcome loss': 0.6994586370645031, 'Total loss': 0.6994586370645031}
2022-11-28 06:07:41,907 INFO:     Found new best model at epoch 0
2022-11-28 06:07:41,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:41,908 INFO:     Epoch: 1
2022-11-28 06:07:42,570 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4887379621240226, 'Total loss': 0.4887379621240226} | train loss {'Reaction outcome loss': 0.5808794308573969, 'Total loss': 0.5808794308573969}
2022-11-28 06:07:42,570 INFO:     Found new best model at epoch 1
2022-11-28 06:07:42,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:42,571 INFO:     Epoch: 2
2022-11-28 06:07:43,229 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48055204071781854, 'Total loss': 0.48055204071781854} | train loss {'Reaction outcome loss': 0.5626915795428138, 'Total loss': 0.5626915795428138}
2022-11-28 06:07:43,229 INFO:     Found new best model at epoch 2
2022-11-28 06:07:43,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:43,230 INFO:     Epoch: 3
2022-11-28 06:07:43,885 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4955247373066165, 'Total loss': 0.4955247373066165} | train loss {'Reaction outcome loss': 0.538475853180693, 'Total loss': 0.538475853180693}
2022-11-28 06:07:43,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:43,885 INFO:     Epoch: 4
2022-11-28 06:07:44,548 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4507952349429781, 'Total loss': 0.4507952349429781} | train loss {'Reaction outcome loss': 0.5330516447823855, 'Total loss': 0.5330516447823855}
2022-11-28 06:07:44,548 INFO:     Found new best model at epoch 4
2022-11-28 06:07:44,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:44,549 INFO:     Epoch: 5
2022-11-28 06:07:45,207 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46236275644464925, 'Total loss': 0.46236275644464925} | train loss {'Reaction outcome loss': 0.5191812410710319, 'Total loss': 0.5191812410710319}
2022-11-28 06:07:45,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:45,207 INFO:     Epoch: 6
2022-11-28 06:07:45,865 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4656542075628584, 'Total loss': 0.4656542075628584} | train loss {'Reaction outcome loss': 0.5224647812184787, 'Total loss': 0.5224647812184787}
2022-11-28 06:07:45,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:45,865 INFO:     Epoch: 7
2022-11-28 06:07:46,525 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5303739028220827, 'Total loss': 0.5303739028220827} | train loss {'Reaction outcome loss': 0.5064114917430186, 'Total loss': 0.5064114917430186}
2022-11-28 06:07:46,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:46,525 INFO:     Epoch: 8
2022-11-28 06:07:47,182 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44676742499524896, 'Total loss': 0.44676742499524896} | train loss {'Reaction outcome loss': 0.5068872474254139, 'Total loss': 0.5068872474254139}
2022-11-28 06:07:47,182 INFO:     Found new best model at epoch 8
2022-11-28 06:07:47,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:47,183 INFO:     Epoch: 9
2022-11-28 06:07:47,840 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45008982345461845, 'Total loss': 0.45008982345461845} | train loss {'Reaction outcome loss': 0.4956912450612553, 'Total loss': 0.4956912450612553}
2022-11-28 06:07:47,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:47,841 INFO:     Epoch: 10
2022-11-28 06:07:48,497 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46689965745264833, 'Total loss': 0.46689965745264833} | train loss {'Reaction outcome loss': 0.49400967852242533, 'Total loss': 0.49400967852242533}
2022-11-28 06:07:48,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:48,497 INFO:     Epoch: 11
2022-11-28 06:07:49,154 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4499820375984365, 'Total loss': 0.4499820375984365} | train loss {'Reaction outcome loss': 0.49499119980440986, 'Total loss': 0.49499119980440986}
2022-11-28 06:07:49,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:49,154 INFO:     Epoch: 12
2022-11-28 06:07:49,811 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4512400102208961, 'Total loss': 0.4512400102208961} | train loss {'Reaction outcome loss': 0.49492717402115943, 'Total loss': 0.49492717402115943}
2022-11-28 06:07:49,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:49,811 INFO:     Epoch: 13
2022-11-28 06:07:50,466 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46007139337333763, 'Total loss': 0.46007139337333763} | train loss {'Reaction outcome loss': 0.4871199328091837, 'Total loss': 0.4871199328091837}
2022-11-28 06:07:50,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:50,466 INFO:     Epoch: 14
2022-11-28 06:07:51,127 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4747649228030985, 'Total loss': 0.4747649228030985} | train loss {'Reaction outcome loss': 0.48821629764091584, 'Total loss': 0.48821629764091584}
2022-11-28 06:07:51,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:51,127 INFO:     Epoch: 15
2022-11-28 06:07:51,787 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48342681100422685, 'Total loss': 0.48342681100422685} | train loss {'Reaction outcome loss': 0.4837911731954063, 'Total loss': 0.4837911731954063}
2022-11-28 06:07:51,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:51,788 INFO:     Epoch: 16
2022-11-28 06:07:52,444 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4396545172414996, 'Total loss': 0.4396545172414996} | train loss {'Reaction outcome loss': 0.4845384611117263, 'Total loss': 0.4845384611117263}
2022-11-28 06:07:52,444 INFO:     Found new best model at epoch 16
2022-11-28 06:07:52,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:52,445 INFO:     Epoch: 17
2022-11-28 06:07:53,099 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4131825962527232, 'Total loss': 0.4131825962527232} | train loss {'Reaction outcome loss': 0.48218136358885993, 'Total loss': 0.48218136358885993}
2022-11-28 06:07:53,099 INFO:     Found new best model at epoch 17
2022-11-28 06:07:53,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:53,100 INFO:     Epoch: 18
2022-11-28 06:07:53,757 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46679428084330127, 'Total loss': 0.46679428084330127} | train loss {'Reaction outcome loss': 0.4795492139434622, 'Total loss': 0.4795492139434622}
2022-11-28 06:07:53,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:53,757 INFO:     Epoch: 19
2022-11-28 06:07:54,417 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45586277781562373, 'Total loss': 0.45586277781562373} | train loss {'Reaction outcome loss': 0.4786042224375471, 'Total loss': 0.4786042224375471}
2022-11-28 06:07:54,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:54,417 INFO:     Epoch: 20
2022-11-28 06:07:55,075 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4237043952400034, 'Total loss': 0.4237043952400034} | train loss {'Reaction outcome loss': 0.48021089610072876, 'Total loss': 0.48021089610072876}
2022-11-28 06:07:55,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:55,075 INFO:     Epoch: 21
2022-11-28 06:07:55,731 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42095328257842496, 'Total loss': 0.42095328257842496} | train loss {'Reaction outcome loss': 0.4688329325628377, 'Total loss': 0.4688329325628377}
2022-11-28 06:07:55,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:55,731 INFO:     Epoch: 22
2022-11-28 06:07:56,388 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4423394352197647, 'Total loss': 0.4423394352197647} | train loss {'Reaction outcome loss': 0.4808830403752865, 'Total loss': 0.4808830403752865}
2022-11-28 06:07:56,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:56,388 INFO:     Epoch: 23
2022-11-28 06:07:57,049 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4275600361553105, 'Total loss': 0.4275600361553105} | train loss {'Reaction outcome loss': 0.47376065653178, 'Total loss': 0.47376065653178}
2022-11-28 06:07:57,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:57,050 INFO:     Epoch: 24
2022-11-28 06:07:57,709 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43339610878716817, 'Total loss': 0.43339610878716817} | train loss {'Reaction outcome loss': 0.4720405722938238, 'Total loss': 0.4720405722938238}
2022-11-28 06:07:57,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:57,709 INFO:     Epoch: 25
2022-11-28 06:07:58,371 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48636417937549675, 'Total loss': 0.48636417937549675} | train loss {'Reaction outcome loss': 0.4732610305711146, 'Total loss': 0.4732610305711146}
2022-11-28 06:07:58,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:58,371 INFO:     Epoch: 26
2022-11-28 06:07:59,027 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43374367735602637, 'Total loss': 0.43374367735602637} | train loss {'Reaction outcome loss': 0.474480782725638, 'Total loss': 0.474480782725638}
2022-11-28 06:07:59,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:59,028 INFO:     Epoch: 27
2022-11-28 06:07:59,685 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4449196701700037, 'Total loss': 0.4449196701700037} | train loss {'Reaction outcome loss': 0.4718397208639691, 'Total loss': 0.4718397208639691}
2022-11-28 06:07:59,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:07:59,685 INFO:     Epoch: 28
2022-11-28 06:08:00,344 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41234167563644325, 'Total loss': 0.41234167563644325} | train loss {'Reaction outcome loss': 0.4808124231715356, 'Total loss': 0.4808124231715356}
2022-11-28 06:08:00,344 INFO:     Found new best model at epoch 28
2022-11-28 06:08:00,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:00,344 INFO:     Epoch: 29
2022-11-28 06:08:01,003 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4071240895851092, 'Total loss': 0.4071240895851092} | train loss {'Reaction outcome loss': 0.48142341127799404, 'Total loss': 0.48142341127799404}
2022-11-28 06:08:01,003 INFO:     Found new best model at epoch 29
2022-11-28 06:08:01,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:01,004 INFO:     Epoch: 30
2022-11-28 06:08:01,665 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4126407395709645, 'Total loss': 0.4126407395709645} | train loss {'Reaction outcome loss': 0.4743024878083698, 'Total loss': 0.4743024878083698}
2022-11-28 06:08:01,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:01,666 INFO:     Epoch: 31
2022-11-28 06:08:02,324 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4278266233476726, 'Total loss': 0.4278266233476726} | train loss {'Reaction outcome loss': 0.4684859724535096, 'Total loss': 0.4684859724535096}
2022-11-28 06:08:02,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:02,324 INFO:     Epoch: 32
2022-11-28 06:08:02,981 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4160581942309033, 'Total loss': 0.4160581942309033} | train loss {'Reaction outcome loss': 0.4737758252529367, 'Total loss': 0.4737758252529367}
2022-11-28 06:08:02,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:02,981 INFO:     Epoch: 33
2022-11-28 06:08:03,639 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43364311466840183, 'Total loss': 0.43364311466840183} | train loss {'Reaction outcome loss': 0.47558124315354133, 'Total loss': 0.47558124315354133}
2022-11-28 06:08:03,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:03,639 INFO:     Epoch: 34
2022-11-28 06:08:04,301 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4175874998962337, 'Total loss': 0.4175874998962337} | train loss {'Reaction outcome loss': 0.4699437963746248, 'Total loss': 0.4699437963746248}
2022-11-28 06:08:04,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:04,301 INFO:     Epoch: 35
2022-11-28 06:08:04,959 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42794889719648793, 'Total loss': 0.42794889719648793} | train loss {'Reaction outcome loss': 0.47460860668891863, 'Total loss': 0.47460860668891863}
2022-11-28 06:08:04,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:04,959 INFO:     Epoch: 36
2022-11-28 06:08:05,620 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41891524534333835, 'Total loss': 0.41891524534333835} | train loss {'Reaction outcome loss': 0.47156178224230966, 'Total loss': 0.47156178224230966}
2022-11-28 06:08:05,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:05,621 INFO:     Epoch: 37
2022-11-28 06:08:06,284 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4265732653439045, 'Total loss': 0.4265732653439045} | train loss {'Reaction outcome loss': 0.4684792685532762, 'Total loss': 0.4684792685532762}
2022-11-28 06:08:06,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:06,284 INFO:     Epoch: 38
2022-11-28 06:08:06,939 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44787307625467127, 'Total loss': 0.44787307625467127} | train loss {'Reaction outcome loss': 0.4805975299508822, 'Total loss': 0.4805975299508822}
2022-11-28 06:08:06,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:06,940 INFO:     Epoch: 39
2022-11-28 06:08:07,598 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4328893821009181, 'Total loss': 0.4328893821009181} | train loss {'Reaction outcome loss': 0.4696038694631669, 'Total loss': 0.4696038694631669}
2022-11-28 06:08:07,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:07,599 INFO:     Epoch: 40
2022-11-28 06:08:08,256 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43954312293366954, 'Total loss': 0.43954312293366954} | train loss {'Reaction outcome loss': 0.47602138524093934, 'Total loss': 0.47602138524093934}
2022-11-28 06:08:08,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:08,257 INFO:     Epoch: 41
2022-11-28 06:08:08,915 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43250946124846285, 'Total loss': 0.43250946124846285} | train loss {'Reaction outcome loss': 0.46680852019738767, 'Total loss': 0.46680852019738767}
2022-11-28 06:08:08,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:08,915 INFO:     Epoch: 42
2022-11-28 06:08:09,573 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43137410046024754, 'Total loss': 0.43137410046024754} | train loss {'Reaction outcome loss': 0.46601072788959547, 'Total loss': 0.46601072788959547}
2022-11-28 06:08:09,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:09,573 INFO:     Epoch: 43
2022-11-28 06:08:10,229 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40956324575976893, 'Total loss': 0.40956324575976893} | train loss {'Reaction outcome loss': 0.4660118939054589, 'Total loss': 0.4660118939054589}
2022-11-28 06:08:10,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:10,229 INFO:     Epoch: 44
2022-11-28 06:08:10,888 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4557886513119394, 'Total loss': 0.4557886513119394} | train loss {'Reaction outcome loss': 0.4734146582383302, 'Total loss': 0.4734146582383302}
2022-11-28 06:08:10,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:10,888 INFO:     Epoch: 45
2022-11-28 06:08:11,548 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41366704959761014, 'Total loss': 0.41366704959761014} | train loss {'Reaction outcome loss': 0.46721729023321984, 'Total loss': 0.46721729023321984}
2022-11-28 06:08:11,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:11,548 INFO:     Epoch: 46
2022-11-28 06:08:12,208 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4563691575418819, 'Total loss': 0.4563691575418819} | train loss {'Reaction outcome loss': 0.47222318247922007, 'Total loss': 0.47222318247922007}
2022-11-28 06:08:12,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:12,208 INFO:     Epoch: 47
2022-11-28 06:08:12,867 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4833447831598195, 'Total loss': 0.4833447831598195} | train loss {'Reaction outcome loss': 0.4700387911570649, 'Total loss': 0.4700387911570649}
2022-11-28 06:08:12,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:12,867 INFO:     Epoch: 48
2022-11-28 06:08:13,526 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3987360081889413, 'Total loss': 0.3987360081889413} | train loss {'Reaction outcome loss': 0.4676386586600734, 'Total loss': 0.4676386586600734}
2022-11-28 06:08:13,526 INFO:     Found new best model at epoch 48
2022-11-28 06:08:13,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:13,527 INFO:     Epoch: 49
2022-11-28 06:08:14,185 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42688262327150867, 'Total loss': 0.42688262327150867} | train loss {'Reaction outcome loss': 0.46157832648004254, 'Total loss': 0.46157832648004254}
2022-11-28 06:08:14,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:14,185 INFO:     Epoch: 50
2022-11-28 06:08:14,844 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42088293622840534, 'Total loss': 0.42088293622840534} | train loss {'Reaction outcome loss': 0.47368572345904764, 'Total loss': 0.47368572345904764}
2022-11-28 06:08:14,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:14,844 INFO:     Epoch: 51
2022-11-28 06:08:15,504 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4728018356995149, 'Total loss': 0.4728018356995149} | train loss {'Reaction outcome loss': 0.4712085562247422, 'Total loss': 0.4712085562247422}
2022-11-28 06:08:15,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:15,504 INFO:     Epoch: 52
2022-11-28 06:08:16,165 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4319164901971817, 'Total loss': 0.4319164901971817} | train loss {'Reaction outcome loss': 0.4750447078577934, 'Total loss': 0.4750447078577934}
2022-11-28 06:08:16,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:16,165 INFO:     Epoch: 53
2022-11-28 06:08:16,828 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4188604717227546, 'Total loss': 0.4188604717227546} | train loss {'Reaction outcome loss': 0.4682723989770297, 'Total loss': 0.4682723989770297}
2022-11-28 06:08:16,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:16,828 INFO:     Epoch: 54
2022-11-28 06:08:17,492 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4110279960388487, 'Total loss': 0.4110279960388487} | train loss {'Reaction outcome loss': 0.4743395956653741, 'Total loss': 0.4743395956653741}
2022-11-28 06:08:17,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:17,492 INFO:     Epoch: 55
2022-11-28 06:08:18,150 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40398327159610664, 'Total loss': 0.40398327159610664} | train loss {'Reaction outcome loss': 0.46484906454720804, 'Total loss': 0.46484906454720804}
2022-11-28 06:08:18,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:18,151 INFO:     Epoch: 56
2022-11-28 06:08:18,811 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42212682691487396, 'Total loss': 0.42212682691487396} | train loss {'Reaction outcome loss': 0.4681779729622987, 'Total loss': 0.4681779729622987}
2022-11-28 06:08:18,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:18,812 INFO:     Epoch: 57
2022-11-28 06:08:19,471 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4079595252194188, 'Total loss': 0.4079595252194188} | train loss {'Reaction outcome loss': 0.46815792543272816, 'Total loss': 0.46815792543272816}
2022-11-28 06:08:19,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:19,472 INFO:     Epoch: 58
2022-11-28 06:08:20,129 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4160056727176363, 'Total loss': 0.4160056727176363} | train loss {'Reaction outcome loss': 0.46713601569494895, 'Total loss': 0.46713601569494895}
2022-11-28 06:08:20,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:20,130 INFO:     Epoch: 59
2022-11-28 06:08:20,789 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41266537694768474, 'Total loss': 0.41266537694768474} | train loss {'Reaction outcome loss': 0.46777484704169536, 'Total loss': 0.46777484704169536}
2022-11-28 06:08:20,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:20,789 INFO:     Epoch: 60
2022-11-28 06:08:21,448 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41927696256475017, 'Total loss': 0.41927696256475017} | train loss {'Reaction outcome loss': 0.46961835657636963, 'Total loss': 0.46961835657636963}
2022-11-28 06:08:21,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:21,448 INFO:     Epoch: 61
2022-11-28 06:08:22,108 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4874046830968423, 'Total loss': 0.4874046830968423} | train loss {'Reaction outcome loss': 0.4686539800417039, 'Total loss': 0.4686539800417039}
2022-11-28 06:08:22,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:22,109 INFO:     Epoch: 62
2022-11-28 06:08:22,771 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4189622937278314, 'Total loss': 0.4189622937278314} | train loss {'Reaction outcome loss': 0.47316091988355885, 'Total loss': 0.47316091988355885}
2022-11-28 06:08:22,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:22,771 INFO:     Epoch: 63
2022-11-28 06:08:23,427 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4091441167349165, 'Total loss': 0.4091441167349165} | train loss {'Reaction outcome loss': 0.4687555523649339, 'Total loss': 0.4687555523649339}
2022-11-28 06:08:23,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:23,427 INFO:     Epoch: 64
2022-11-28 06:08:24,084 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42031465978784993, 'Total loss': 0.42031465978784993} | train loss {'Reaction outcome loss': 0.465605063604251, 'Total loss': 0.465605063604251}
2022-11-28 06:08:24,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:24,084 INFO:     Epoch: 65
2022-11-28 06:08:24,743 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4233963889154521, 'Total loss': 0.4233963889154521} | train loss {'Reaction outcome loss': 0.467506391386832, 'Total loss': 0.467506391386832}
2022-11-28 06:08:24,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:24,743 INFO:     Epoch: 66
2022-11-28 06:08:25,402 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41404835879802704, 'Total loss': 0.41404835879802704} | train loss {'Reaction outcome loss': 0.4659001819428898, 'Total loss': 0.4659001819428898}
2022-11-28 06:08:25,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:25,402 INFO:     Epoch: 67
2022-11-28 06:08:26,061 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4099485151131045, 'Total loss': 0.4099485151131045} | train loss {'Reaction outcome loss': 0.4677629597004383, 'Total loss': 0.4677629597004383}
2022-11-28 06:08:26,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:26,062 INFO:     Epoch: 68
2022-11-28 06:08:26,718 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4301663755693219, 'Total loss': 0.4301663755693219} | train loss {'Reaction outcome loss': 0.4626781129308285, 'Total loss': 0.4626781129308285}
2022-11-28 06:08:26,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:26,718 INFO:     Epoch: 69
2022-11-28 06:08:27,377 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4141449731859294, 'Total loss': 0.4141449731859294} | train loss {'Reaction outcome loss': 0.4696737788617611, 'Total loss': 0.4696737788617611}
2022-11-28 06:08:27,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:27,377 INFO:     Epoch: 70
2022-11-28 06:08:28,037 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.461098974570632, 'Total loss': 0.461098974570632} | train loss {'Reaction outcome loss': 0.46371781618724905, 'Total loss': 0.46371781618724905}
2022-11-28 06:08:28,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:28,037 INFO:     Epoch: 71
2022-11-28 06:08:28,697 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4272681684656577, 'Total loss': 0.4272681684656577} | train loss {'Reaction outcome loss': 0.46680518906683693, 'Total loss': 0.46680518906683693}
2022-11-28 06:08:28,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:28,697 INFO:     Epoch: 72
2022-11-28 06:08:29,355 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.413118757984855, 'Total loss': 0.413118757984855} | train loss {'Reaction outcome loss': 0.46852234666866643, 'Total loss': 0.46852234666866643}
2022-11-28 06:08:29,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:29,355 INFO:     Epoch: 73
2022-11-28 06:08:30,012 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39432651888240466, 'Total loss': 0.39432651888240466} | train loss {'Reaction outcome loss': 0.4642711627267061, 'Total loss': 0.4642711627267061}
2022-11-28 06:08:30,013 INFO:     Found new best model at epoch 73
2022-11-28 06:08:30,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:30,013 INFO:     Epoch: 74
2022-11-28 06:08:30,670 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4282213859260082, 'Total loss': 0.4282213859260082} | train loss {'Reaction outcome loss': 0.46802556520748523, 'Total loss': 0.46802556520748523}
2022-11-28 06:08:30,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:30,671 INFO:     Epoch: 75
2022-11-28 06:08:31,330 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41584927758032625, 'Total loss': 0.41584927758032625} | train loss {'Reaction outcome loss': 0.46218305976400453, 'Total loss': 0.46218305976400453}
2022-11-28 06:08:31,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:31,330 INFO:     Epoch: 76
2022-11-28 06:08:31,992 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.421454708007249, 'Total loss': 0.421454708007249} | train loss {'Reaction outcome loss': 0.46671864132006324, 'Total loss': 0.46671864132006324}
2022-11-28 06:08:31,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:31,992 INFO:     Epoch: 77
2022-11-28 06:08:32,651 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4562823972241445, 'Total loss': 0.4562823972241445} | train loss {'Reaction outcome loss': 0.4680106353255049, 'Total loss': 0.4680106353255049}
2022-11-28 06:08:32,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:32,651 INFO:     Epoch: 78
2022-11-28 06:08:33,310 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40997155891223386, 'Total loss': 0.40997155891223386} | train loss {'Reaction outcome loss': 0.46148987892534465, 'Total loss': 0.46148987892534465}
2022-11-28 06:08:33,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:33,311 INFO:     Epoch: 79
2022-11-28 06:08:33,970 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4430236481130123, 'Total loss': 0.4430236481130123} | train loss {'Reaction outcome loss': 0.4708280902836592, 'Total loss': 0.4708280902836592}
2022-11-28 06:08:33,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:33,970 INFO:     Epoch: 80
2022-11-28 06:08:34,630 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.415886290371418, 'Total loss': 0.415886290371418} | train loss {'Reaction outcome loss': 0.46020862165718307, 'Total loss': 0.46020862165718307}
2022-11-28 06:08:34,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:34,631 INFO:     Epoch: 81
2022-11-28 06:08:35,295 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4258837706663392, 'Total loss': 0.4258837706663392} | train loss {'Reaction outcome loss': 0.46354047641638785, 'Total loss': 0.46354047641638785}
2022-11-28 06:08:35,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:35,295 INFO:     Epoch: 82
2022-11-28 06:08:35,954 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4688648083670573, 'Total loss': 0.4688648083670573} | train loss {'Reaction outcome loss': 0.45823204481313307, 'Total loss': 0.45823204481313307}
2022-11-28 06:08:35,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:35,954 INFO:     Epoch: 83
2022-11-28 06:08:36,612 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4021748412739147, 'Total loss': 0.4021748412739147} | train loss {'Reaction outcome loss': 0.4678500973649563, 'Total loss': 0.4678500973649563}
2022-11-28 06:08:36,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:36,612 INFO:     Epoch: 84
2022-11-28 06:08:37,268 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4432422640648755, 'Total loss': 0.4432422640648755} | train loss {'Reaction outcome loss': 0.4645204566298954, 'Total loss': 0.4645204566298954}
2022-11-28 06:08:37,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:37,268 INFO:     Epoch: 85
2022-11-28 06:08:37,927 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4165599315681241, 'Total loss': 0.4165599315681241} | train loss {'Reaction outcome loss': 0.4645549783543233, 'Total loss': 0.4645549783543233}
2022-11-28 06:08:37,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:37,927 INFO:     Epoch: 86
2022-11-28 06:08:38,586 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46429667046124284, 'Total loss': 0.46429667046124284} | train loss {'Reaction outcome loss': 0.4599706523360745, 'Total loss': 0.4599706523360745}
2022-11-28 06:08:38,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:38,587 INFO:     Epoch: 87
2022-11-28 06:08:39,247 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41384344547986984, 'Total loss': 0.41384344547986984} | train loss {'Reaction outcome loss': 0.46418959112657654, 'Total loss': 0.46418959112657654}
2022-11-28 06:08:39,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:39,248 INFO:     Epoch: 88
2022-11-28 06:08:39,906 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43065843460234726, 'Total loss': 0.43065843460234726} | train loss {'Reaction outcome loss': 0.46139480434958974, 'Total loss': 0.46139480434958974}
2022-11-28 06:08:39,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:39,906 INFO:     Epoch: 89
2022-11-28 06:08:40,564 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41948304122144525, 'Total loss': 0.41948304122144525} | train loss {'Reaction outcome loss': 0.46430685437254365, 'Total loss': 0.46430685437254365}
2022-11-28 06:08:40,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:40,564 INFO:     Epoch: 90
2022-11-28 06:08:41,226 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3923775279386477, 'Total loss': 0.3923775279386477} | train loss {'Reaction outcome loss': 0.4710859142604374, 'Total loss': 0.4710859142604374}
2022-11-28 06:08:41,226 INFO:     Found new best model at epoch 90
2022-11-28 06:08:41,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:41,227 INFO:     Epoch: 91
2022-11-28 06:08:41,889 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4226115115664222, 'Total loss': 0.4226115115664222} | train loss {'Reaction outcome loss': 0.4602629798314264, 'Total loss': 0.4602629798314264}
2022-11-28 06:08:41,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:41,890 INFO:     Epoch: 92
2022-11-28 06:08:42,552 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3987092043865811, 'Total loss': 0.3987092043865811} | train loss {'Reaction outcome loss': 0.46903108598123633, 'Total loss': 0.46903108598123633}
2022-11-28 06:08:42,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:42,552 INFO:     Epoch: 93
2022-11-28 06:08:43,212 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41406318240545015, 'Total loss': 0.41406318240545015} | train loss {'Reaction outcome loss': 0.46644359827041626, 'Total loss': 0.46644359827041626}
2022-11-28 06:08:43,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:43,212 INFO:     Epoch: 94
2022-11-28 06:08:43,868 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48604618283835327, 'Total loss': 0.48604618283835327} | train loss {'Reaction outcome loss': 0.46083987762610756, 'Total loss': 0.46083987762610756}
2022-11-28 06:08:43,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:43,868 INFO:     Epoch: 95
2022-11-28 06:08:44,524 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43197250298478385, 'Total loss': 0.43197250298478385} | train loss {'Reaction outcome loss': 0.4604892495178407, 'Total loss': 0.4604892495178407}
2022-11-28 06:08:44,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:44,524 INFO:     Epoch: 96
2022-11-28 06:08:45,180 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40444074097004806, 'Total loss': 0.40444074097004806} | train loss {'Reaction outcome loss': 0.4669709593177803, 'Total loss': 0.4669709593177803}
2022-11-28 06:08:45,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:45,181 INFO:     Epoch: 97
2022-11-28 06:08:45,839 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4029160192744298, 'Total loss': 0.4029160192744298} | train loss {'Reaction outcome loss': 0.4653306972956465, 'Total loss': 0.4653306972956465}
2022-11-28 06:08:45,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:45,840 INFO:     Epoch: 98
2022-11-28 06:08:46,498 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4104477028277787, 'Total loss': 0.4104477028277787} | train loss {'Reaction outcome loss': 0.4607287917526499, 'Total loss': 0.4607287917526499}
2022-11-28 06:08:46,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:46,498 INFO:     Epoch: 99
2022-11-28 06:08:47,155 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42558797923001374, 'Total loss': 0.42558797923001374} | train loss {'Reaction outcome loss': 0.4664685660071911, 'Total loss': 0.4664685660071911}
2022-11-28 06:08:47,155 INFO:     Best model found after epoch 91 of 100.
2022-11-28 06:08:47,155 INFO:   Done with stage: TRAINING
2022-11-28 06:08:47,155 INFO:   Starting stage: EVALUATION
2022-11-28 06:08:47,268 INFO:   Done with stage: EVALUATION
2022-11-28 06:08:47,268 INFO:   Leaving out SEQ value Fold_6
2022-11-28 06:08:47,281 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:08:47,281 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:08:47,923 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:08:47,923 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:08:47,994 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:08:47,994 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:08:47,994 INFO:     No hyperparam tuning for this model
2022-11-28 06:08:47,994 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:08:47,994 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:08:47,995 INFO:     None feature selector for col prot
2022-11-28 06:08:47,995 INFO:     None feature selector for col prot
2022-11-28 06:08:47,995 INFO:     None feature selector for col prot
2022-11-28 06:08:47,996 INFO:     None feature selector for col chem
2022-11-28 06:08:47,996 INFO:     None feature selector for col chem
2022-11-28 06:08:47,996 INFO:     None feature selector for col chem
2022-11-28 06:08:47,996 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:08:47,996 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:08:47,998 INFO:     Number of params in model 169651
2022-11-28 06:08:48,001 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:08:48,001 INFO:   Starting stage: TRAINING
2022-11-28 06:08:48,052 INFO:     Val loss before train {'Reaction outcome loss': 0.9249908355149355, 'Total loss': 0.9249908355149355}
2022-11-28 06:08:48,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:48,052 INFO:     Epoch: 0
2022-11-28 06:08:48,712 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5243257758292285, 'Total loss': 0.5243257758292285} | train loss {'Reaction outcome loss': 0.6875092465310327, 'Total loss': 0.6875092465310327}
2022-11-28 06:08:48,712 INFO:     Found new best model at epoch 0
2022-11-28 06:08:48,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:48,713 INFO:     Epoch: 1
2022-11-28 06:08:49,373 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49050179801203986, 'Total loss': 0.49050179801203986} | train loss {'Reaction outcome loss': 0.5702006944244907, 'Total loss': 0.5702006944244907}
2022-11-28 06:08:49,373 INFO:     Found new best model at epoch 1
2022-11-28 06:08:49,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:49,374 INFO:     Epoch: 2
2022-11-28 06:08:50,031 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4974291568452662, 'Total loss': 0.4974291568452662} | train loss {'Reaction outcome loss': 0.537749964082914, 'Total loss': 0.537749964082914}
2022-11-28 06:08:50,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:50,032 INFO:     Epoch: 3
2022-11-28 06:08:50,690 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4755585552616553, 'Total loss': 0.4755585552616553} | train loss {'Reaction outcome loss': 0.5338795980618846, 'Total loss': 0.5338795980618846}
2022-11-28 06:08:50,690 INFO:     Found new best model at epoch 3
2022-11-28 06:08:50,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:50,691 INFO:     Epoch: 4
2022-11-28 06:08:51,353 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4726857407526536, 'Total loss': 0.4726857407526536} | train loss {'Reaction outcome loss': 0.5080067343529193, 'Total loss': 0.5080067343529193}
2022-11-28 06:08:51,353 INFO:     Found new best model at epoch 4
2022-11-28 06:08:51,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:51,354 INFO:     Epoch: 5
2022-11-28 06:08:52,013 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44067725065079605, 'Total loss': 0.44067725065079605} | train loss {'Reaction outcome loss': 0.49541082079972953, 'Total loss': 0.49541082079972953}
2022-11-28 06:08:52,013 INFO:     Found new best model at epoch 5
2022-11-28 06:08:52,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:52,014 INFO:     Epoch: 6
2022-11-28 06:08:52,676 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45425103266130795, 'Total loss': 0.45425103266130795} | train loss {'Reaction outcome loss': 0.5031397961560757, 'Total loss': 0.5031397961560757}
2022-11-28 06:08:52,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:52,676 INFO:     Epoch: 7
2022-11-28 06:08:53,336 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49181818487969314, 'Total loss': 0.49181818487969314} | train loss {'Reaction outcome loss': 0.49731503889685674, 'Total loss': 0.49731503889685674}
2022-11-28 06:08:53,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:53,337 INFO:     Epoch: 8
2022-11-28 06:08:53,992 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47064692256125534, 'Total loss': 0.47064692256125534} | train loss {'Reaction outcome loss': 0.4830606028197273, 'Total loss': 0.4830606028197273}
2022-11-28 06:08:53,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:53,993 INFO:     Epoch: 9
2022-11-28 06:08:54,650 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4376242221756415, 'Total loss': 0.4376242221756415} | train loss {'Reaction outcome loss': 0.4832039289176464, 'Total loss': 0.4832039289176464}
2022-11-28 06:08:54,650 INFO:     Found new best model at epoch 9
2022-11-28 06:08:54,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:54,651 INFO:     Epoch: 10
2022-11-28 06:08:55,305 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4238851158456369, 'Total loss': 0.4238851158456369} | train loss {'Reaction outcome loss': 0.4749927131098605, 'Total loss': 0.4749927131098605}
2022-11-28 06:08:55,305 INFO:     Found new best model at epoch 10
2022-11-28 06:08:55,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:55,306 INFO:     Epoch: 11
2022-11-28 06:08:55,963 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45024864273992454, 'Total loss': 0.45024864273992454} | train loss {'Reaction outcome loss': 0.4785594646368296, 'Total loss': 0.4785594646368296}
2022-11-28 06:08:55,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:55,964 INFO:     Epoch: 12
2022-11-28 06:08:56,623 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4689344509758733, 'Total loss': 0.4689344509758733} | train loss {'Reaction outcome loss': 0.46975060275966124, 'Total loss': 0.46975060275966124}
2022-11-28 06:08:56,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:56,624 INFO:     Epoch: 13
2022-11-28 06:08:57,281 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4425178732384335, 'Total loss': 0.4425178732384335} | train loss {'Reaction outcome loss': 0.4867539070546627, 'Total loss': 0.4867539070546627}
2022-11-28 06:08:57,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:57,281 INFO:     Epoch: 14
2022-11-28 06:08:57,935 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4398985549130223, 'Total loss': 0.4398985549130223} | train loss {'Reaction outcome loss': 0.48045478358624444, 'Total loss': 0.48045478358624444}
2022-11-28 06:08:57,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:57,935 INFO:     Epoch: 15
2022-11-28 06:08:58,593 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4701087088747458, 'Total loss': 0.4701087088747458} | train loss {'Reaction outcome loss': 0.4777371167776085, 'Total loss': 0.4777371167776085}
2022-11-28 06:08:58,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:58,593 INFO:     Epoch: 16
2022-11-28 06:08:59,255 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43987255746668036, 'Total loss': 0.43987255746668036} | train loss {'Reaction outcome loss': 0.4651798908748934, 'Total loss': 0.4651798908748934}
2022-11-28 06:08:59,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:59,256 INFO:     Epoch: 17
2022-11-28 06:08:59,918 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45935468578880484, 'Total loss': 0.45935468578880484} | train loss {'Reaction outcome loss': 0.4771585566923022, 'Total loss': 0.4771585566923022}
2022-11-28 06:08:59,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:08:59,919 INFO:     Epoch: 18
2022-11-28 06:09:00,577 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4356579167599028, 'Total loss': 0.4356579167599028} | train loss {'Reaction outcome loss': 0.4697000092316058, 'Total loss': 0.4697000092316058}
2022-11-28 06:09:00,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:00,577 INFO:     Epoch: 19
2022-11-28 06:09:01,238 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4648277363316579, 'Total loss': 0.4648277363316579} | train loss {'Reaction outcome loss': 0.47672157241932805, 'Total loss': 0.47672157241932805}
2022-11-28 06:09:01,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:01,239 INFO:     Epoch: 20
2022-11-28 06:09:01,896 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4377706375989047, 'Total loss': 0.4377706375989047} | train loss {'Reaction outcome loss': 0.46051514611369176, 'Total loss': 0.46051514611369176}
2022-11-28 06:09:01,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:01,896 INFO:     Epoch: 21
2022-11-28 06:09:02,554 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4330171946097504, 'Total loss': 0.4330171946097504} | train loss {'Reaction outcome loss': 0.4746338403032672, 'Total loss': 0.4746338403032672}
2022-11-28 06:09:02,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:02,555 INFO:     Epoch: 22
2022-11-28 06:09:03,213 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43835318765857, 'Total loss': 0.43835318765857} | train loss {'Reaction outcome loss': 0.466905121781653, 'Total loss': 0.466905121781653}
2022-11-28 06:09:03,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:03,213 INFO:     Epoch: 23
2022-11-28 06:09:03,869 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4390667050399564, 'Total loss': 0.4390667050399564} | train loss {'Reaction outcome loss': 0.46619528225593027, 'Total loss': 0.46619528225593027}
2022-11-28 06:09:03,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:03,869 INFO:     Epoch: 24
2022-11-28 06:09:04,525 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4740596013990315, 'Total loss': 0.4740596013990315} | train loss {'Reaction outcome loss': 0.4733991636143577, 'Total loss': 0.4733991636143577}
2022-11-28 06:09:04,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:04,526 INFO:     Epoch: 25
2022-11-28 06:09:05,187 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4307869669388641, 'Total loss': 0.4307869669388641} | train loss {'Reaction outcome loss': 0.4737463516573752, 'Total loss': 0.4737463516573752}
2022-11-28 06:09:05,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:05,187 INFO:     Epoch: 26
2022-11-28 06:09:05,844 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44869863682172517, 'Total loss': 0.44869863682172517} | train loss {'Reaction outcome loss': 0.4674335220047543, 'Total loss': 0.4674335220047543}
2022-11-28 06:09:05,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:05,844 INFO:     Epoch: 27
2022-11-28 06:09:06,511 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4262710874053565, 'Total loss': 0.4262710874053565} | train loss {'Reaction outcome loss': 0.47212148379654656, 'Total loss': 0.47212148379654656}
2022-11-28 06:09:06,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:06,511 INFO:     Epoch: 28
2022-11-28 06:09:07,188 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4278694066134366, 'Total loss': 0.4278694066134366} | train loss {'Reaction outcome loss': 0.4678354501844414, 'Total loss': 0.4678354501844414}
2022-11-28 06:09:07,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:07,189 INFO:     Epoch: 29
2022-11-28 06:09:07,861 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44058032537048514, 'Total loss': 0.44058032537048514} | train loss {'Reaction outcome loss': 0.4659744258970022, 'Total loss': 0.4659744258970022}
2022-11-28 06:09:07,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:07,861 INFO:     Epoch: 30
2022-11-28 06:09:08,534 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.487975764003667, 'Total loss': 0.487975764003667} | train loss {'Reaction outcome loss': 0.4610843543083437, 'Total loss': 0.4610843543083437}
2022-11-28 06:09:08,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:08,535 INFO:     Epoch: 31
2022-11-28 06:09:09,208 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4380993101407181, 'Total loss': 0.4380993101407181} | train loss {'Reaction outcome loss': 0.4675013816524898, 'Total loss': 0.4675013816524898}
2022-11-28 06:09:09,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:09,209 INFO:     Epoch: 32
2022-11-28 06:09:09,886 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4204624616964297, 'Total loss': 0.4204624616964297} | train loss {'Reaction outcome loss': 0.4622257483462172, 'Total loss': 0.4622257483462172}
2022-11-28 06:09:09,886 INFO:     Found new best model at epoch 32
2022-11-28 06:09:09,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:09,887 INFO:     Epoch: 33
2022-11-28 06:09:10,562 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44351031665097584, 'Total loss': 0.44351031665097584} | train loss {'Reaction outcome loss': 0.46178819533557663, 'Total loss': 0.46178819533557663}
2022-11-28 06:09:10,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:10,562 INFO:     Epoch: 34
2022-11-28 06:09:11,235 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4515898898243904, 'Total loss': 0.4515898898243904} | train loss {'Reaction outcome loss': 0.4629719847993505, 'Total loss': 0.4629719847993505}
2022-11-28 06:09:11,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:11,235 INFO:     Epoch: 35
2022-11-28 06:09:11,908 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4369057586247271, 'Total loss': 0.4369057586247271} | train loss {'Reaction outcome loss': 0.4680509514385654, 'Total loss': 0.4680509514385654}
2022-11-28 06:09:11,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:11,909 INFO:     Epoch: 36
2022-11-28 06:09:12,582 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42948765747926454, 'Total loss': 0.42948765747926454} | train loss {'Reaction outcome loss': 0.4624513283131584, 'Total loss': 0.4624513283131584}
2022-11-28 06:09:12,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:12,582 INFO:     Epoch: 37
2022-11-28 06:09:13,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4507655965333635, 'Total loss': 0.4507655965333635} | train loss {'Reaction outcome loss': 0.4670380890489586, 'Total loss': 0.4670380890489586}
2022-11-28 06:09:13,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:13,256 INFO:     Epoch: 38
2022-11-28 06:09:13,932 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42631747675212944, 'Total loss': 0.42631747675212944} | train loss {'Reaction outcome loss': 0.4659650041571548, 'Total loss': 0.4659650041571548}
2022-11-28 06:09:13,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:13,932 INFO:     Epoch: 39
2022-11-28 06:09:14,607 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4270351603627205, 'Total loss': 0.4270351603627205} | train loss {'Reaction outcome loss': 0.4724001513133126, 'Total loss': 0.4724001513133126}
2022-11-28 06:09:14,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:14,607 INFO:     Epoch: 40
2022-11-28 06:09:15,277 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4283467937599529, 'Total loss': 0.4283467937599529} | train loss {'Reaction outcome loss': 0.465962782802601, 'Total loss': 0.465962782802601}
2022-11-28 06:09:15,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:15,278 INFO:     Epoch: 41
2022-11-28 06:09:15,949 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4494546526534991, 'Total loss': 0.4494546526534991} | train loss {'Reaction outcome loss': 0.4669619183987379, 'Total loss': 0.4669619183987379}
2022-11-28 06:09:15,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:15,949 INFO:     Epoch: 42
2022-11-28 06:09:16,621 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44223774563182483, 'Total loss': 0.44223774563182483} | train loss {'Reaction outcome loss': 0.4600923072186209, 'Total loss': 0.4600923072186209}
2022-11-28 06:09:16,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:16,621 INFO:     Epoch: 43
2022-11-28 06:09:17,297 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4441321783445098, 'Total loss': 0.4441321783445098} | train loss {'Reaction outcome loss': 0.47174046573139006, 'Total loss': 0.47174046573139006}
2022-11-28 06:09:17,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:17,298 INFO:     Epoch: 44
2022-11-28 06:09:17,973 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42880488898266444, 'Total loss': 0.42880488898266444} | train loss {'Reaction outcome loss': 0.460363102055365, 'Total loss': 0.460363102055365}
2022-11-28 06:09:17,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:17,973 INFO:     Epoch: 45
2022-11-28 06:09:18,648 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46975006366317923, 'Total loss': 0.46975006366317923} | train loss {'Reaction outcome loss': 0.4604679776295539, 'Total loss': 0.4604679776295539}
2022-11-28 06:09:18,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:18,648 INFO:     Epoch: 46
2022-11-28 06:09:19,321 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42113530161705887, 'Total loss': 0.42113530161705887} | train loss {'Reaction outcome loss': 0.4639994219666527, 'Total loss': 0.4639994219666527}
2022-11-28 06:09:19,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:19,321 INFO:     Epoch: 47
2022-11-28 06:09:19,995 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4216036948968064, 'Total loss': 0.4216036948968064} | train loss {'Reaction outcome loss': 0.4658427978715589, 'Total loss': 0.4658427978715589}
2022-11-28 06:09:19,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:19,995 INFO:     Epoch: 48
2022-11-28 06:09:20,666 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.459832005541433, 'Total loss': 0.459832005541433} | train loss {'Reaction outcome loss': 0.4659541246270941, 'Total loss': 0.4659541246270941}
2022-11-28 06:09:20,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:20,667 INFO:     Epoch: 49
2022-11-28 06:09:21,342 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4388564161278985, 'Total loss': 0.4388564161278985} | train loss {'Reaction outcome loss': 0.4668044845663732, 'Total loss': 0.4668044845663732}
2022-11-28 06:09:21,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:21,343 INFO:     Epoch: 50
2022-11-28 06:09:22,016 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4185128589584069, 'Total loss': 0.4185128589584069} | train loss {'Reaction outcome loss': 0.4627065862258596, 'Total loss': 0.4627065862258596}
2022-11-28 06:09:22,016 INFO:     Found new best model at epoch 50
2022-11-28 06:09:22,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:22,017 INFO:     Epoch: 51
2022-11-28 06:09:22,694 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5131805860014125, 'Total loss': 0.5131805860014125} | train loss {'Reaction outcome loss': 0.46720756193803203, 'Total loss': 0.46720756193803203}
2022-11-28 06:09:22,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:22,695 INFO:     Epoch: 52
2022-11-28 06:09:23,368 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40627517009323294, 'Total loss': 0.40627517009323294} | train loss {'Reaction outcome loss': 0.4666115923994972, 'Total loss': 0.4666115923994972}
2022-11-28 06:09:23,368 INFO:     Found new best model at epoch 52
2022-11-28 06:09:23,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:23,369 INFO:     Epoch: 53
2022-11-28 06:09:24,048 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4230602918700738, 'Total loss': 0.4230602918700738} | train loss {'Reaction outcome loss': 0.4735297542065382, 'Total loss': 0.4735297542065382}
2022-11-28 06:09:24,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:24,048 INFO:     Epoch: 54
2022-11-28 06:09:24,725 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4422489499503916, 'Total loss': 0.4422489499503916} | train loss {'Reaction outcome loss': 0.4613132102475051, 'Total loss': 0.4613132102475051}
2022-11-28 06:09:24,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:24,725 INFO:     Epoch: 55
2022-11-28 06:09:25,400 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4313714152032679, 'Total loss': 0.4313714152032679} | train loss {'Reaction outcome loss': 0.4643229126569725, 'Total loss': 0.4643229126569725}
2022-11-28 06:09:25,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:25,400 INFO:     Epoch: 56
2022-11-28 06:09:26,075 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42989751865917986, 'Total loss': 0.42989751865917986} | train loss {'Reaction outcome loss': 0.4603648234999949, 'Total loss': 0.4603648234999949}
2022-11-28 06:09:26,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:26,075 INFO:     Epoch: 57
2022-11-28 06:09:26,747 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4293483746322719, 'Total loss': 0.4293483746322719} | train loss {'Reaction outcome loss': 0.4711907186335133, 'Total loss': 0.4711907186335133}
2022-11-28 06:09:26,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:26,747 INFO:     Epoch: 58
2022-11-28 06:09:27,417 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42277767712419684, 'Total loss': 0.42277767712419684} | train loss {'Reaction outcome loss': 0.47341968263349227, 'Total loss': 0.47341968263349227}
2022-11-28 06:09:27,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:27,418 INFO:     Epoch: 59
2022-11-28 06:09:28,092 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43993957103653386, 'Total loss': 0.43993957103653386} | train loss {'Reaction outcome loss': 0.4618110553391518, 'Total loss': 0.4618110553391518}
2022-11-28 06:09:28,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:28,093 INFO:     Epoch: 60
2022-11-28 06:09:28,767 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4466369240121408, 'Total loss': 0.4466369240121408} | train loss {'Reaction outcome loss': 0.46440552331266866, 'Total loss': 0.46440552331266866}
2022-11-28 06:09:28,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:28,767 INFO:     Epoch: 61
2022-11-28 06:09:29,439 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44666240499778226, 'Total loss': 0.44666240499778226} | train loss {'Reaction outcome loss': 0.4704159713921047, 'Total loss': 0.4704159713921047}
2022-11-28 06:09:29,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:29,440 INFO:     Epoch: 62
2022-11-28 06:09:30,113 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44085468487306073, 'Total loss': 0.44085468487306073} | train loss {'Reaction outcome loss': 0.469086233286127, 'Total loss': 0.469086233286127}
2022-11-28 06:09:30,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:30,113 INFO:     Epoch: 63
2022-11-28 06:09:30,787 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46898888220841234, 'Total loss': 0.46898888220841234} | train loss {'Reaction outcome loss': 0.4715882789704107, 'Total loss': 0.4715882789704107}
2022-11-28 06:09:30,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:30,788 INFO:     Epoch: 64
2022-11-28 06:09:31,461 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4308658435263417, 'Total loss': 0.4308658435263417} | train loss {'Reaction outcome loss': 0.46943549361200104, 'Total loss': 0.46943549361200104}
2022-11-28 06:09:31,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:31,461 INFO:     Epoch: 65
2022-11-28 06:09:32,134 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44846132363785396, 'Total loss': 0.44846132363785396} | train loss {'Reaction outcome loss': 0.46349135732218144, 'Total loss': 0.46349135732218144}
2022-11-28 06:09:32,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:32,134 INFO:     Epoch: 66
2022-11-28 06:09:32,811 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46593626351519063, 'Total loss': 0.46593626351519063} | train loss {'Reaction outcome loss': 0.4696561751827117, 'Total loss': 0.4696561751827117}
2022-11-28 06:09:32,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:32,811 INFO:     Epoch: 67
2022-11-28 06:09:33,484 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42865996299819514, 'Total loss': 0.42865996299819514} | train loss {'Reaction outcome loss': 0.4667758286119469, 'Total loss': 0.4667758286119469}
2022-11-28 06:09:33,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:33,484 INFO:     Epoch: 68
2022-11-28 06:09:34,159 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4379144568334926, 'Total loss': 0.4379144568334926} | train loss {'Reaction outcome loss': 0.46493367934899943, 'Total loss': 0.46493367934899943}
2022-11-28 06:09:34,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:34,160 INFO:     Epoch: 69
2022-11-28 06:09:34,835 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4487540234218944, 'Total loss': 0.4487540234218944} | train loss {'Reaction outcome loss': 0.46474560055761566, 'Total loss': 0.46474560055761566}
2022-11-28 06:09:34,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:34,835 INFO:     Epoch: 70
2022-11-28 06:09:35,510 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4515689584341916, 'Total loss': 0.4515689584341916} | train loss {'Reaction outcome loss': 0.46866838922423704, 'Total loss': 0.46866838922423704}
2022-11-28 06:09:35,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:35,510 INFO:     Epoch: 71
2022-11-28 06:09:36,184 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44324045221913944, 'Total loss': 0.44324045221913944} | train loss {'Reaction outcome loss': 0.46375158411120215, 'Total loss': 0.46375158411120215}
2022-11-28 06:09:36,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:36,184 INFO:     Epoch: 72
2022-11-28 06:09:36,857 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4451026405123147, 'Total loss': 0.4451026405123147} | train loss {'Reaction outcome loss': 0.464350851793443, 'Total loss': 0.464350851793443}
2022-11-28 06:09:36,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:36,857 INFO:     Epoch: 73
2022-11-28 06:09:37,533 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41453812982548366, 'Total loss': 0.41453812982548366} | train loss {'Reaction outcome loss': 0.46540355063494177, 'Total loss': 0.46540355063494177}
2022-11-28 06:09:37,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:37,533 INFO:     Epoch: 74
2022-11-28 06:09:38,207 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43423117426308716, 'Total loss': 0.43423117426308716} | train loss {'Reaction outcome loss': 0.46745058010903096, 'Total loss': 0.46745058010903096}
2022-11-28 06:09:38,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:38,207 INFO:     Epoch: 75
2022-11-28 06:09:38,881 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4115324839949608, 'Total loss': 0.4115324839949608} | train loss {'Reaction outcome loss': 0.4586063723470415, 'Total loss': 0.4586063723470415}
2022-11-28 06:09:38,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:38,881 INFO:     Epoch: 76
2022-11-28 06:09:39,554 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.426750799133019, 'Total loss': 0.426750799133019} | train loss {'Reaction outcome loss': 0.4680124809064211, 'Total loss': 0.4680124809064211}
2022-11-28 06:09:39,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:39,555 INFO:     Epoch: 77
2022-11-28 06:09:40,230 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4222776327620853, 'Total loss': 0.4222776327620853} | train loss {'Reaction outcome loss': 0.45937033397175614, 'Total loss': 0.45937033397175614}
2022-11-28 06:09:40,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:40,230 INFO:     Epoch: 78
2022-11-28 06:09:40,905 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43175754459066823, 'Total loss': 0.43175754459066823} | train loss {'Reaction outcome loss': 0.4667257637146019, 'Total loss': 0.4667257637146019}
2022-11-28 06:09:40,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:40,905 INFO:     Epoch: 79
2022-11-28 06:09:41,582 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43040643429214304, 'Total loss': 0.43040643429214304} | train loss {'Reaction outcome loss': 0.4606476253679683, 'Total loss': 0.4606476253679683}
2022-11-28 06:09:41,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:41,583 INFO:     Epoch: 80
2022-11-28 06:09:42,258 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.439317640255798, 'Total loss': 0.439317640255798} | train loss {'Reaction outcome loss': 0.4617321245492466, 'Total loss': 0.4617321245492466}
2022-11-28 06:09:42,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:42,258 INFO:     Epoch: 81
2022-11-28 06:09:42,933 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4324990866536444, 'Total loss': 0.4324990866536444} | train loss {'Reaction outcome loss': 0.4612335909999186, 'Total loss': 0.4612335909999186}
2022-11-28 06:09:42,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:42,933 INFO:     Epoch: 82
2022-11-28 06:09:43,609 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.414795324545015, 'Total loss': 0.414795324545015} | train loss {'Reaction outcome loss': 0.4626799586018728, 'Total loss': 0.4626799586018728}
2022-11-28 06:09:43,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:43,609 INFO:     Epoch: 83
2022-11-28 06:09:44,286 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43347327038645744, 'Total loss': 0.43347327038645744} | train loss {'Reaction outcome loss': 0.46693041415945175, 'Total loss': 0.46693041415945175}
2022-11-28 06:09:44,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:44,286 INFO:     Epoch: 84
2022-11-28 06:09:44,957 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4412130872634324, 'Total loss': 0.4412130872634324} | train loss {'Reaction outcome loss': 0.4634466519158694, 'Total loss': 0.4634466519158694}
2022-11-28 06:09:44,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:44,957 INFO:     Epoch: 85
2022-11-28 06:09:45,629 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4451444088058038, 'Total loss': 0.4451444088058038} | train loss {'Reaction outcome loss': 0.4677936293545269, 'Total loss': 0.4677936293545269}
2022-11-28 06:09:45,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:45,629 INFO:     Epoch: 86
2022-11-28 06:09:46,307 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42351118847727776, 'Total loss': 0.42351118847727776} | train loss {'Reaction outcome loss': 0.46095191837558824, 'Total loss': 0.46095191837558824}
2022-11-28 06:09:46,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:46,307 INFO:     Epoch: 87
2022-11-28 06:09:46,978 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45888055488467216, 'Total loss': 0.45888055488467216} | train loss {'Reaction outcome loss': 0.460371068168071, 'Total loss': 0.460371068168071}
2022-11-28 06:09:46,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:46,979 INFO:     Epoch: 88
2022-11-28 06:09:47,653 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4521409571170807, 'Total loss': 0.4521409571170807} | train loss {'Reaction outcome loss': 0.4632809202397062, 'Total loss': 0.4632809202397062}
2022-11-28 06:09:47,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:47,653 INFO:     Epoch: 89
2022-11-28 06:09:48,326 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4202829897403717, 'Total loss': 0.4202829897403717} | train loss {'Reaction outcome loss': 0.4590040144901122, 'Total loss': 0.4590040144901122}
2022-11-28 06:09:48,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:48,326 INFO:     Epoch: 90
2022-11-28 06:09:49,004 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.456241751936349, 'Total loss': 0.456241751936349} | train loss {'Reaction outcome loss': 0.4616191566831643, 'Total loss': 0.4616191566831643}
2022-11-28 06:09:49,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:49,004 INFO:     Epoch: 91
2022-11-28 06:09:49,679 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43494401025501167, 'Total loss': 0.43494401025501167} | train loss {'Reaction outcome loss': 0.46722340127152784, 'Total loss': 0.46722340127152784}
2022-11-28 06:09:49,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:49,679 INFO:     Epoch: 92
2022-11-28 06:09:50,355 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4463463063267144, 'Total loss': 0.4463463063267144} | train loss {'Reaction outcome loss': 0.4675797448163071, 'Total loss': 0.4675797448163071}
2022-11-28 06:09:50,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:50,355 INFO:     Epoch: 93
2022-11-28 06:09:51,026 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.451911848038435, 'Total loss': 0.451911848038435} | train loss {'Reaction outcome loss': 0.4605959274115101, 'Total loss': 0.4605959274115101}
2022-11-28 06:09:51,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:51,027 INFO:     Epoch: 94
2022-11-28 06:09:51,701 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4222754541445862, 'Total loss': 0.4222754541445862} | train loss {'Reaction outcome loss': 0.4620581632780452, 'Total loss': 0.4620581632780452}
2022-11-28 06:09:51,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:51,702 INFO:     Epoch: 95
2022-11-28 06:09:52,376 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43312550403855066, 'Total loss': 0.43312550403855066} | train loss {'Reaction outcome loss': 0.4594196036698357, 'Total loss': 0.4594196036698357}
2022-11-28 06:09:52,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:52,376 INFO:     Epoch: 96
2022-11-28 06:09:53,051 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4307489219036969, 'Total loss': 0.4307489219036969} | train loss {'Reaction outcome loss': 0.45796522954779284, 'Total loss': 0.45796522954779284}
2022-11-28 06:09:53,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:53,052 INFO:     Epoch: 97
2022-11-28 06:09:53,727 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42189818756146863, 'Total loss': 0.42189818756146863} | train loss {'Reaction outcome loss': 0.4650745714503911, 'Total loss': 0.4650745714503911}
2022-11-28 06:09:53,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:53,728 INFO:     Epoch: 98
2022-11-28 06:09:54,401 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4457200498066165, 'Total loss': 0.4457200498066165} | train loss {'Reaction outcome loss': 0.46376954172287255, 'Total loss': 0.46376954172287255}
2022-11-28 06:09:54,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:54,401 INFO:     Epoch: 99
2022-11-28 06:09:55,075 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4347572353753177, 'Total loss': 0.4347572353753177} | train loss {'Reaction outcome loss': 0.46131461402100904, 'Total loss': 0.46131461402100904}
2022-11-28 06:09:55,075 INFO:     Best model found after epoch 53 of 100.
2022-11-28 06:09:55,075 INFO:   Done with stage: TRAINING
2022-11-28 06:09:55,075 INFO:   Starting stage: EVALUATION
2022-11-28 06:09:55,188 INFO:   Done with stage: EVALUATION
2022-11-28 06:09:55,188 INFO:   Leaving out SEQ value Fold_7
2022-11-28 06:09:55,200 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:09:55,200 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:09:55,836 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:09:55,836 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:09:55,907 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:09:55,907 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:09:55,907 INFO:     No hyperparam tuning for this model
2022-11-28 06:09:55,907 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:09:55,907 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:09:55,908 INFO:     None feature selector for col prot
2022-11-28 06:09:55,908 INFO:     None feature selector for col prot
2022-11-28 06:09:55,908 INFO:     None feature selector for col prot
2022-11-28 06:09:55,908 INFO:     None feature selector for col chem
2022-11-28 06:09:55,908 INFO:     None feature selector for col chem
2022-11-28 06:09:55,908 INFO:     None feature selector for col chem
2022-11-28 06:09:55,909 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:09:55,909 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:09:55,910 INFO:     Number of params in model 169651
2022-11-28 06:09:55,913 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:09:55,913 INFO:   Starting stage: TRAINING
2022-11-28 06:09:55,964 INFO:     Val loss before train {'Reaction outcome loss': 1.0141917914152145, 'Total loss': 1.0141917914152145}
2022-11-28 06:09:55,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:55,964 INFO:     Epoch: 0
2022-11-28 06:09:56,639 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6101173555309122, 'Total loss': 0.6101173555309122} | train loss {'Reaction outcome loss': 0.7011561975363763, 'Total loss': 0.7011561975363763}
2022-11-28 06:09:56,639 INFO:     Found new best model at epoch 0
2022-11-28 06:09:56,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:56,639 INFO:     Epoch: 1
2022-11-28 06:09:57,317 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5607817233963446, 'Total loss': 0.5607817233963446} | train loss {'Reaction outcome loss': 0.5767462774510345, 'Total loss': 0.5767462774510345}
2022-11-28 06:09:57,317 INFO:     Found new best model at epoch 1
2022-11-28 06:09:57,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:57,318 INFO:     Epoch: 2
2022-11-28 06:09:57,993 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5723850740627809, 'Total loss': 0.5723850740627809} | train loss {'Reaction outcome loss': 0.54502521377177, 'Total loss': 0.54502521377177}
2022-11-28 06:09:57,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:57,994 INFO:     Epoch: 3
2022-11-28 06:09:58,673 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5192853009158914, 'Total loss': 0.5192853009158914} | train loss {'Reaction outcome loss': 0.5313535568815085, 'Total loss': 0.5313535568815085}
2022-11-28 06:09:58,673 INFO:     Found new best model at epoch 3
2022-11-28 06:09:58,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:58,674 INFO:     Epoch: 4
2022-11-28 06:09:59,352 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5214053643020716, 'Total loss': 0.5214053643020716} | train loss {'Reaction outcome loss': 0.5233521736076763, 'Total loss': 0.5233521736076763}
2022-11-28 06:09:59,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:09:59,353 INFO:     Epoch: 5
2022-11-28 06:10:00,025 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5223587873307142, 'Total loss': 0.5223587873307142} | train loss {'Reaction outcome loss': 0.5112757047698382, 'Total loss': 0.5112757047698382}
2022-11-28 06:10:00,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:00,025 INFO:     Epoch: 6
2022-11-28 06:10:00,702 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4933472526344386, 'Total loss': 0.4933472526344386} | train loss {'Reaction outcome loss': 0.5017252451469821, 'Total loss': 0.5017252451469821}
2022-11-28 06:10:00,702 INFO:     Found new best model at epoch 6
2022-11-28 06:10:00,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:00,703 INFO:     Epoch: 7
2022-11-28 06:10:01,376 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5128306465392763, 'Total loss': 0.5128306465392763} | train loss {'Reaction outcome loss': 0.49432179445941604, 'Total loss': 0.49432179445941604}
2022-11-28 06:10:01,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:01,377 INFO:     Epoch: 8
2022-11-28 06:10:02,051 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49969432773915207, 'Total loss': 0.49969432773915207} | train loss {'Reaction outcome loss': 0.4859348421375598, 'Total loss': 0.4859348421375598}
2022-11-28 06:10:02,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:02,051 INFO:     Epoch: 9
2022-11-28 06:10:02,725 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5239949331364848, 'Total loss': 0.5239949331364848} | train loss {'Reaction outcome loss': 0.48396352324033937, 'Total loss': 0.48396352324033937}
2022-11-28 06:10:02,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:02,725 INFO:     Epoch: 10
2022-11-28 06:10:03,398 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4802216050977057, 'Total loss': 0.4802216050977057} | train loss {'Reaction outcome loss': 0.48816108718634615, 'Total loss': 0.48816108718634615}
2022-11-28 06:10:03,398 INFO:     Found new best model at epoch 10
2022-11-28 06:10:03,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:03,399 INFO:     Epoch: 11
2022-11-28 06:10:04,073 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49594794281504373, 'Total loss': 0.49594794281504373} | train loss {'Reaction outcome loss': 0.48570329293368325, 'Total loss': 0.48570329293368325}
2022-11-28 06:10:04,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:04,073 INFO:     Epoch: 12
2022-11-28 06:10:04,749 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4973996054719795, 'Total loss': 0.4973996054719795} | train loss {'Reaction outcome loss': 0.479066064401019, 'Total loss': 0.479066064401019}
2022-11-28 06:10:04,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:04,749 INFO:     Epoch: 13
2022-11-28 06:10:05,423 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5199929678981955, 'Total loss': 0.5199929678981955} | train loss {'Reaction outcome loss': 0.47635153584903284, 'Total loss': 0.47635153584903284}
2022-11-28 06:10:05,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:05,423 INFO:     Epoch: 14
2022-11-28 06:10:06,101 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5167898027734323, 'Total loss': 0.5167898027734323} | train loss {'Reaction outcome loss': 0.48019763058231724, 'Total loss': 0.48019763058231724}
2022-11-28 06:10:06,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:06,102 INFO:     Epoch: 15
2022-11-28 06:10:06,775 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5078821744431149, 'Total loss': 0.5078821744431149} | train loss {'Reaction outcome loss': 0.47867833041856367, 'Total loss': 0.47867833041856367}
2022-11-28 06:10:06,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:06,775 INFO:     Epoch: 16
2022-11-28 06:10:07,452 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5304089219055392, 'Total loss': 0.5304089219055392} | train loss {'Reaction outcome loss': 0.4797094043704771, 'Total loss': 0.4797094043704771}
2022-11-28 06:10:07,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:07,452 INFO:     Epoch: 17
2022-11-28 06:10:08,130 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5207658752121709, 'Total loss': 0.5207658752121709} | train loss {'Reaction outcome loss': 0.4737796690315008, 'Total loss': 0.4737796690315008}
2022-11-28 06:10:08,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:08,130 INFO:     Epoch: 18
2022-11-28 06:10:08,810 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5237453437664292, 'Total loss': 0.5237453437664292} | train loss {'Reaction outcome loss': 0.48048295651472384, 'Total loss': 0.48048295651472384}
2022-11-28 06:10:08,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:08,810 INFO:     Epoch: 19
2022-11-28 06:10:09,484 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48256848887963727, 'Total loss': 0.48256848887963727} | train loss {'Reaction outcome loss': 0.4793114111788811, 'Total loss': 0.4793114111788811}
2022-11-28 06:10:09,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:09,485 INFO:     Epoch: 20
2022-11-28 06:10:10,160 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48106626607477665, 'Total loss': 0.48106626607477665} | train loss {'Reaction outcome loss': 0.4715641460591747, 'Total loss': 0.4715641460591747}
2022-11-28 06:10:10,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:10,161 INFO:     Epoch: 21
2022-11-28 06:10:10,840 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4948141344568946, 'Total loss': 0.4948141344568946} | train loss {'Reaction outcome loss': 0.469822179225664, 'Total loss': 0.469822179225664}
2022-11-28 06:10:10,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:10,841 INFO:     Epoch: 22
2022-11-28 06:10:11,516 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47591320967132394, 'Total loss': 0.47591320967132394} | train loss {'Reaction outcome loss': 0.4706068295504778, 'Total loss': 0.4706068295504778}
2022-11-28 06:10:11,516 INFO:     Found new best model at epoch 22
2022-11-28 06:10:11,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:11,517 INFO:     Epoch: 23
2022-11-28 06:10:12,193 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4915820885110985, 'Total loss': 0.4915820885110985} | train loss {'Reaction outcome loss': 0.4751414098145981, 'Total loss': 0.4751414098145981}
2022-11-28 06:10:12,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:12,194 INFO:     Epoch: 24
2022-11-28 06:10:12,871 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48261178081685846, 'Total loss': 0.48261178081685846} | train loss {'Reaction outcome loss': 0.47439394452639166, 'Total loss': 0.47439394452639166}
2022-11-28 06:10:12,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:12,871 INFO:     Epoch: 25
2022-11-28 06:10:13,548 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49547053196213464, 'Total loss': 0.49547053196213464} | train loss {'Reaction outcome loss': 0.46914679971673795, 'Total loss': 0.46914679971673795}
2022-11-28 06:10:13,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:13,548 INFO:     Epoch: 26
2022-11-28 06:10:14,222 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48926447467370465, 'Total loss': 0.48926447467370465} | train loss {'Reaction outcome loss': 0.4689887132375471, 'Total loss': 0.4689887132375471}
2022-11-28 06:10:14,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:14,222 INFO:     Epoch: 27
2022-11-28 06:10:14,897 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4558664065870372, 'Total loss': 0.4558664065870372} | train loss {'Reaction outcome loss': 0.4734584480644234, 'Total loss': 0.4734584480644234}
2022-11-28 06:10:14,897 INFO:     Found new best model at epoch 27
2022-11-28 06:10:14,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:14,898 INFO:     Epoch: 28
2022-11-28 06:10:15,574 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48529290509494866, 'Total loss': 0.48529290509494866} | train loss {'Reaction outcome loss': 0.4706209449758453, 'Total loss': 0.4706209449758453}
2022-11-28 06:10:15,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:15,574 INFO:     Epoch: 29
2022-11-28 06:10:16,250 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4797346083955331, 'Total loss': 0.4797346083955331} | train loss {'Reaction outcome loss': 0.4702985402677328, 'Total loss': 0.4702985402677328}
2022-11-28 06:10:16,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:16,250 INFO:     Epoch: 30
2022-11-28 06:10:16,925 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.494525688954375, 'Total loss': 0.494525688954375} | train loss {'Reaction outcome loss': 0.47278585056624106, 'Total loss': 0.47278585056624106}
2022-11-28 06:10:16,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:16,926 INFO:     Epoch: 31
2022-11-28 06:10:17,600 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4770708307623863, 'Total loss': 0.4770708307623863} | train loss {'Reaction outcome loss': 0.4769379685843183, 'Total loss': 0.4769379685843183}
2022-11-28 06:10:17,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:17,600 INFO:     Epoch: 32
2022-11-28 06:10:18,275 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4757323803549463, 'Total loss': 0.4757323803549463} | train loss {'Reaction outcome loss': 0.4741860181093216, 'Total loss': 0.4741860181093216}
2022-11-28 06:10:18,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:18,276 INFO:     Epoch: 33
2022-11-28 06:10:18,953 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4980633942918344, 'Total loss': 0.4980633942918344} | train loss {'Reaction outcome loss': 0.47239073131593967, 'Total loss': 0.47239073131593967}
2022-11-28 06:10:18,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:18,954 INFO:     Epoch: 34
2022-11-28 06:10:19,629 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4678655964407054, 'Total loss': 0.4678655964407054} | train loss {'Reaction outcome loss': 0.4728166921244514, 'Total loss': 0.4728166921244514}
2022-11-28 06:10:19,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:19,630 INFO:     Epoch: 35
2022-11-28 06:10:20,305 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4969209678132426, 'Total loss': 0.4969209678132426} | train loss {'Reaction outcome loss': 0.4706083440612401, 'Total loss': 0.4706083440612401}
2022-11-28 06:10:20,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:20,305 INFO:     Epoch: 36
2022-11-28 06:10:20,981 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47713608565655624, 'Total loss': 0.47713608565655624} | train loss {'Reaction outcome loss': 0.46950848328490413, 'Total loss': 0.46950848328490413}
2022-11-28 06:10:20,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:20,982 INFO:     Epoch: 37
2022-11-28 06:10:21,654 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47566330060362816, 'Total loss': 0.47566330060362816} | train loss {'Reaction outcome loss': 0.4756825629982256, 'Total loss': 0.4756825629982256}
2022-11-28 06:10:21,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:21,654 INFO:     Epoch: 38
2022-11-28 06:10:22,331 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4733911610462449, 'Total loss': 0.4733911610462449} | train loss {'Reaction outcome loss': 0.4712823876329968, 'Total loss': 0.4712823876329968}
2022-11-28 06:10:22,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:22,331 INFO:     Epoch: 39
2022-11-28 06:10:23,010 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49364559894258325, 'Total loss': 0.49364559894258325} | train loss {'Reaction outcome loss': 0.4685833290099136, 'Total loss': 0.4685833290099136}
2022-11-28 06:10:23,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:23,011 INFO:     Epoch: 40
2022-11-28 06:10:23,686 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47553900798613374, 'Total loss': 0.47553900798613374} | train loss {'Reaction outcome loss': 0.4729920840792118, 'Total loss': 0.4729920840792118}
2022-11-28 06:10:23,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:23,686 INFO:     Epoch: 41
2022-11-28 06:10:24,361 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47587134316563606, 'Total loss': 0.47587134316563606} | train loss {'Reaction outcome loss': 0.467292089676184, 'Total loss': 0.467292089676184}
2022-11-28 06:10:24,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:24,361 INFO:     Epoch: 42
2022-11-28 06:10:25,036 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47576727718114853, 'Total loss': 0.47576727718114853} | train loss {'Reaction outcome loss': 0.4641033123217283, 'Total loss': 0.4641033123217283}
2022-11-28 06:10:25,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:25,037 INFO:     Epoch: 43
2022-11-28 06:10:25,712 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48011549934744835, 'Total loss': 0.48011549934744835} | train loss {'Reaction outcome loss': 0.47133984251488603, 'Total loss': 0.47133984251488603}
2022-11-28 06:10:25,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:25,712 INFO:     Epoch: 44
2022-11-28 06:10:26,387 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.509185746989467, 'Total loss': 0.509185746989467} | train loss {'Reaction outcome loss': 0.4688428121829225, 'Total loss': 0.4688428121829225}
2022-11-28 06:10:26,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:26,388 INFO:     Epoch: 45
2022-11-28 06:10:27,064 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48479228805411945, 'Total loss': 0.48479228805411945} | train loss {'Reaction outcome loss': 0.47092283979779287, 'Total loss': 0.47092283979779287}
2022-11-28 06:10:27,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:27,064 INFO:     Epoch: 46
2022-11-28 06:10:27,739 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46206568757241423, 'Total loss': 0.46206568757241423} | train loss {'Reaction outcome loss': 0.4704490486051767, 'Total loss': 0.4704490486051767}
2022-11-28 06:10:27,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:27,739 INFO:     Epoch: 47
2022-11-28 06:10:28,415 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47193038734522735, 'Total loss': 0.47193038734522735} | train loss {'Reaction outcome loss': 0.4738244374673213, 'Total loss': 0.4738244374673213}
2022-11-28 06:10:28,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:28,415 INFO:     Epoch: 48
2022-11-28 06:10:29,090 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48476215824484825, 'Total loss': 0.48476215824484825} | train loss {'Reaction outcome loss': 0.46514225799229836, 'Total loss': 0.46514225799229836}
2022-11-28 06:10:29,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:29,090 INFO:     Epoch: 49
2022-11-28 06:10:29,767 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4733452024784955, 'Total loss': 0.4733452024784955} | train loss {'Reaction outcome loss': 0.46289151143883506, 'Total loss': 0.46289151143883506}
2022-11-28 06:10:29,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:29,767 INFO:     Epoch: 50
2022-11-28 06:10:30,445 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48205877298658545, 'Total loss': 0.48205877298658545} | train loss {'Reaction outcome loss': 0.4709958649811245, 'Total loss': 0.4709958649811245}
2022-11-28 06:10:30,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:30,445 INFO:     Epoch: 51
2022-11-28 06:10:31,125 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4643077379600568, 'Total loss': 0.4643077379600568} | train loss {'Reaction outcome loss': 0.46213881575292154, 'Total loss': 0.46213881575292154}
2022-11-28 06:10:31,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:31,125 INFO:     Epoch: 52
2022-11-28 06:10:31,803 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47503829442641954, 'Total loss': 0.47503829442641954} | train loss {'Reaction outcome loss': 0.4659025374078943, 'Total loss': 0.4659025374078943}
2022-11-28 06:10:31,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:31,803 INFO:     Epoch: 53
2022-11-28 06:10:32,484 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4727217551659454, 'Total loss': 0.4727217551659454} | train loss {'Reaction outcome loss': 0.45961009428626104, 'Total loss': 0.45961009428626104}
2022-11-28 06:10:32,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:32,484 INFO:     Epoch: 54
2022-11-28 06:10:33,163 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47647509385238995, 'Total loss': 0.47647509385238995} | train loss {'Reaction outcome loss': 0.47257145926836996, 'Total loss': 0.47257145926836996}
2022-11-28 06:10:33,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:33,163 INFO:     Epoch: 55
2022-11-28 06:10:33,840 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4957835288210349, 'Total loss': 0.4957835288210349} | train loss {'Reaction outcome loss': 0.4627377896779968, 'Total loss': 0.4627377896779968}
2022-11-28 06:10:33,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:33,841 INFO:     Epoch: 56
2022-11-28 06:10:34,515 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4733376076275652, 'Total loss': 0.4733376076275652} | train loss {'Reaction outcome loss': 0.4615723304450512, 'Total loss': 0.4615723304450512}
2022-11-28 06:10:34,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:34,515 INFO:     Epoch: 57
2022-11-28 06:10:35,196 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5037612274966456, 'Total loss': 0.5037612274966456} | train loss {'Reaction outcome loss': 0.46785362148957865, 'Total loss': 0.46785362148957865}
2022-11-28 06:10:35,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:35,196 INFO:     Epoch: 58
2022-11-28 06:10:35,874 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4589480297131972, 'Total loss': 0.4589480297131972} | train loss {'Reaction outcome loss': 0.4733437632000254, 'Total loss': 0.4733437632000254}
2022-11-28 06:10:35,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:35,874 INFO:     Epoch: 59
2022-11-28 06:10:36,557 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4780241095206954, 'Total loss': 0.4780241095206954} | train loss {'Reaction outcome loss': 0.46492566060154666, 'Total loss': 0.46492566060154666}
2022-11-28 06:10:36,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:36,557 INFO:     Epoch: 60
2022-11-28 06:10:37,234 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47192829982800916, 'Total loss': 0.47192829982800916} | train loss {'Reaction outcome loss': 0.4643036787428202, 'Total loss': 0.4643036787428202}
2022-11-28 06:10:37,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:37,234 INFO:     Epoch: 61
2022-11-28 06:10:37,911 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4864006367596713, 'Total loss': 0.4864006367596713} | train loss {'Reaction outcome loss': 0.4649407233622286, 'Total loss': 0.4649407233622286}
2022-11-28 06:10:37,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:37,911 INFO:     Epoch: 62
2022-11-28 06:10:38,586 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4621452618051659, 'Total loss': 0.4621452618051659} | train loss {'Reaction outcome loss': 0.46169023203753656, 'Total loss': 0.46169023203753656}
2022-11-28 06:10:38,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:38,587 INFO:     Epoch: 63
2022-11-28 06:10:39,261 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.472737923941829, 'Total loss': 0.472737923941829} | train loss {'Reaction outcome loss': 0.4689129839140561, 'Total loss': 0.4689129839140561}
2022-11-28 06:10:39,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:39,261 INFO:     Epoch: 64
2022-11-28 06:10:39,938 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5072008896280419, 'Total loss': 0.5072008896280419} | train loss {'Reaction outcome loss': 0.4625305850058794, 'Total loss': 0.4625305850058794}
2022-11-28 06:10:39,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:39,938 INFO:     Epoch: 65
2022-11-28 06:10:40,613 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5191824768077243, 'Total loss': 0.5191824768077243} | train loss {'Reaction outcome loss': 0.461249117168688, 'Total loss': 0.461249117168688}
2022-11-28 06:10:40,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:40,613 INFO:     Epoch: 66
2022-11-28 06:10:41,287 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4788969802585515, 'Total loss': 0.4788969802585515} | train loss {'Reaction outcome loss': 0.46729987757580893, 'Total loss': 0.46729987757580893}
2022-11-28 06:10:41,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:41,288 INFO:     Epoch: 67
2022-11-28 06:10:41,966 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5182909938422117, 'Total loss': 0.5182909938422117} | train loss {'Reaction outcome loss': 0.4663094283351975, 'Total loss': 0.4663094283351975}
2022-11-28 06:10:41,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:41,966 INFO:     Epoch: 68
2022-11-28 06:10:42,640 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5468069545247338, 'Total loss': 0.5468069545247338} | train loss {'Reaction outcome loss': 0.46695285915367063, 'Total loss': 0.46695285915367063}
2022-11-28 06:10:42,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:42,640 INFO:     Epoch: 69
2022-11-28 06:10:43,317 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47161468321626837, 'Total loss': 0.47161468321626837} | train loss {'Reaction outcome loss': 0.4647279488703897, 'Total loss': 0.4647279488703897}
2022-11-28 06:10:43,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:43,317 INFO:     Epoch: 70
2022-11-28 06:10:43,993 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48067389970475977, 'Total loss': 0.48067389970475977} | train loss {'Reaction outcome loss': 0.456256945166857, 'Total loss': 0.456256945166857}
2022-11-28 06:10:43,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:43,993 INFO:     Epoch: 71
2022-11-28 06:10:44,669 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.513118714094162, 'Total loss': 0.513118714094162} | train loss {'Reaction outcome loss': 0.4683758013791615, 'Total loss': 0.4683758013791615}
2022-11-28 06:10:44,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:44,669 INFO:     Epoch: 72
2022-11-28 06:10:45,345 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46046330949122255, 'Total loss': 0.46046330949122255} | train loss {'Reaction outcome loss': 0.467476723355151, 'Total loss': 0.467476723355151}
2022-11-28 06:10:45,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:45,345 INFO:     Epoch: 73
2022-11-28 06:10:46,022 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49660063230178575, 'Total loss': 0.49660063230178575} | train loss {'Reaction outcome loss': 0.46038778697050387, 'Total loss': 0.46038778697050387}
2022-11-28 06:10:46,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:46,022 INFO:     Epoch: 74
2022-11-28 06:10:46,699 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4991861607202075, 'Total loss': 0.4991861607202075} | train loss {'Reaction outcome loss': 0.4675855965263421, 'Total loss': 0.4675855965263421}
2022-11-28 06:10:46,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:46,699 INFO:     Epoch: 75
2022-11-28 06:10:47,376 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4616740515286272, 'Total loss': 0.4616740515286272} | train loss {'Reaction outcome loss': 0.4677419661574306, 'Total loss': 0.4677419661574306}
2022-11-28 06:10:47,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:47,376 INFO:     Epoch: 76
2022-11-28 06:10:48,055 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4776015085252849, 'Total loss': 0.4776015085252849} | train loss {'Reaction outcome loss': 0.4650337663028509, 'Total loss': 0.4650337663028509}
2022-11-28 06:10:48,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:48,055 INFO:     Epoch: 77
2022-11-28 06:10:48,732 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4731832448054444, 'Total loss': 0.4731832448054444} | train loss {'Reaction outcome loss': 0.4648847573647095, 'Total loss': 0.4648847573647095}
2022-11-28 06:10:48,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:48,732 INFO:     Epoch: 78
2022-11-28 06:10:49,409 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47528771412643517, 'Total loss': 0.47528771412643517} | train loss {'Reaction outcome loss': 0.46076288134340315, 'Total loss': 0.46076288134340315}
2022-11-28 06:10:49,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:49,409 INFO:     Epoch: 79
2022-11-28 06:10:50,086 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4754684120416641, 'Total loss': 0.4754684120416641} | train loss {'Reaction outcome loss': 0.4633747676327344, 'Total loss': 0.4633747676327344}
2022-11-28 06:10:50,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:50,087 INFO:     Epoch: 80
2022-11-28 06:10:50,749 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5107399160889062, 'Total loss': 0.5107399160889062} | train loss {'Reaction outcome loss': 0.465603802413229, 'Total loss': 0.465603802413229}
2022-11-28 06:10:50,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:50,749 INFO:     Epoch: 81
2022-11-28 06:10:51,409 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5216449770060453, 'Total loss': 0.5216449770060453} | train loss {'Reaction outcome loss': 0.46129884238865587, 'Total loss': 0.46129884238865587}
2022-11-28 06:10:51,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:51,409 INFO:     Epoch: 82
2022-11-28 06:10:52,065 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4778765050525015, 'Total loss': 0.4778765050525015} | train loss {'Reaction outcome loss': 0.46015322785223683, 'Total loss': 0.46015322785223683}
2022-11-28 06:10:52,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:52,065 INFO:     Epoch: 83
2022-11-28 06:10:52,723 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47275886650789867, 'Total loss': 0.47275886650789867} | train loss {'Reaction outcome loss': 0.4591699416839307, 'Total loss': 0.4591699416839307}
2022-11-28 06:10:52,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:52,723 INFO:     Epoch: 84
2022-11-28 06:10:53,380 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48328199406916444, 'Total loss': 0.48328199406916444} | train loss {'Reaction outcome loss': 0.46276099439109525, 'Total loss': 0.46276099439109525}
2022-11-28 06:10:53,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:53,380 INFO:     Epoch: 85
2022-11-28 06:10:54,037 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47404631769115274, 'Total loss': 0.47404631769115274} | train loss {'Reaction outcome loss': 0.4656078523445514, 'Total loss': 0.4656078523445514}
2022-11-28 06:10:54,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:54,038 INFO:     Epoch: 86
2022-11-28 06:10:54,695 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49280213327570394, 'Total loss': 0.49280213327570394} | train loss {'Reaction outcome loss': 0.4631115768345133, 'Total loss': 0.4631115768345133}
2022-11-28 06:10:54,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:54,696 INFO:     Epoch: 87
2022-11-28 06:10:55,357 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4647426188669421, 'Total loss': 0.4647426188669421} | train loss {'Reaction outcome loss': 0.4663250906573188, 'Total loss': 0.4663250906573188}
2022-11-28 06:10:55,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:55,357 INFO:     Epoch: 88
2022-11-28 06:10:56,017 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46667340194637125, 'Total loss': 0.46667340194637125} | train loss {'Reaction outcome loss': 0.4647953641871291, 'Total loss': 0.4647953641871291}
2022-11-28 06:10:56,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:56,017 INFO:     Epoch: 89
2022-11-28 06:10:56,675 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4788998223163865, 'Total loss': 0.4788998223163865} | train loss {'Reaction outcome loss': 0.46465829489452226, 'Total loss': 0.46465829489452226}
2022-11-28 06:10:56,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:56,675 INFO:     Epoch: 90
2022-11-28 06:10:57,335 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4658986919305541, 'Total loss': 0.4658986919305541} | train loss {'Reaction outcome loss': 0.46557670555287795, 'Total loss': 0.46557670555287795}
2022-11-28 06:10:57,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:57,335 INFO:     Epoch: 91
2022-11-28 06:10:57,996 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48391908034682274, 'Total loss': 0.48391908034682274} | train loss {'Reaction outcome loss': 0.46323157378262086, 'Total loss': 0.46323157378262086}
2022-11-28 06:10:57,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:57,996 INFO:     Epoch: 92
2022-11-28 06:10:58,656 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5173675431446596, 'Total loss': 0.5173675431446596} | train loss {'Reaction outcome loss': 0.4664834516062852, 'Total loss': 0.4664834516062852}
2022-11-28 06:10:58,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:58,656 INFO:     Epoch: 93
2022-11-28 06:10:59,314 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4924635020169345, 'Total loss': 0.4924635020169345} | train loss {'Reaction outcome loss': 0.4653774931005413, 'Total loss': 0.4653774931005413}
2022-11-28 06:10:59,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:59,314 INFO:     Epoch: 94
2022-11-28 06:10:59,973 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4740485538813201, 'Total loss': 0.4740485538813201} | train loss {'Reaction outcome loss': 0.46081955205168457, 'Total loss': 0.46081955205168457}
2022-11-28 06:10:59,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:10:59,973 INFO:     Epoch: 95
2022-11-28 06:11:00,632 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45707724717530335, 'Total loss': 0.45707724717530335} | train loss {'Reaction outcome loss': 0.46046283510663816, 'Total loss': 0.46046283510663816}
2022-11-28 06:11:00,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:00,633 INFO:     Epoch: 96
2022-11-28 06:11:01,291 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4767550169066949, 'Total loss': 0.4767550169066949} | train loss {'Reaction outcome loss': 0.46316030615520093, 'Total loss': 0.46316030615520093}
2022-11-28 06:11:01,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:01,292 INFO:     Epoch: 97
2022-11-28 06:11:01,949 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47468587078831415, 'Total loss': 0.47468587078831415} | train loss {'Reaction outcome loss': 0.46532243442150856, 'Total loss': 0.46532243442150856}
2022-11-28 06:11:01,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:01,950 INFO:     Epoch: 98
2022-11-28 06:11:02,607 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4820274656469172, 'Total loss': 0.4820274656469172} | train loss {'Reaction outcome loss': 0.46004730024405066, 'Total loss': 0.46004730024405066}
2022-11-28 06:11:02,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:02,607 INFO:     Epoch: 99
2022-11-28 06:11:03,266 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48421446640383115, 'Total loss': 0.48421446640383115} | train loss {'Reaction outcome loss': 0.4696338858695761, 'Total loss': 0.4696338858695761}
2022-11-28 06:11:03,266 INFO:     Best model found after epoch 28 of 100.
2022-11-28 06:11:03,266 INFO:   Done with stage: TRAINING
2022-11-28 06:11:03,266 INFO:   Starting stage: EVALUATION
2022-11-28 06:11:03,379 INFO:   Done with stage: EVALUATION
2022-11-28 06:11:03,379 INFO:   Leaving out SEQ value Fold_8
2022-11-28 06:11:03,392 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 06:11:03,392 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:11:04,024 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:11:04,024 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:11:04,093 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:11:04,093 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:11:04,093 INFO:     No hyperparam tuning for this model
2022-11-28 06:11:04,093 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:11:04,093 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:11:04,094 INFO:     None feature selector for col prot
2022-11-28 06:11:04,094 INFO:     None feature selector for col prot
2022-11-28 06:11:04,094 INFO:     None feature selector for col prot
2022-11-28 06:11:04,095 INFO:     None feature selector for col chem
2022-11-28 06:11:04,095 INFO:     None feature selector for col chem
2022-11-28 06:11:04,095 INFO:     None feature selector for col chem
2022-11-28 06:11:04,095 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:11:04,095 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:11:04,096 INFO:     Number of params in model 169651
2022-11-28 06:11:04,099 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:11:04,099 INFO:   Starting stage: TRAINING
2022-11-28 06:11:04,150 INFO:     Val loss before train {'Reaction outcome loss': 1.0071858899159865, 'Total loss': 1.0071858899159865}
2022-11-28 06:11:04,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:04,150 INFO:     Epoch: 0
2022-11-28 06:11:04,802 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6455318372357975, 'Total loss': 0.6455318372357975} | train loss {'Reaction outcome loss': 0.6897880625968077, 'Total loss': 0.6897880625968077}
2022-11-28 06:11:04,802 INFO:     Found new best model at epoch 0
2022-11-28 06:11:04,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:04,803 INFO:     Epoch: 1
2022-11-28 06:11:05,454 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5675713877108964, 'Total loss': 0.5675713877108964} | train loss {'Reaction outcome loss': 0.57556056556653, 'Total loss': 0.57556056556653}
2022-11-28 06:11:05,454 INFO:     Found new best model at epoch 1
2022-11-28 06:11:05,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:05,455 INFO:     Epoch: 2
2022-11-28 06:11:06,105 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5555515492504294, 'Total loss': 0.5555515492504294} | train loss {'Reaction outcome loss': 0.5468306564554877, 'Total loss': 0.5468306564554877}
2022-11-28 06:11:06,105 INFO:     Found new best model at epoch 2
2022-11-28 06:11:06,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:06,106 INFO:     Epoch: 3
2022-11-28 06:11:06,757 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5313541679219767, 'Total loss': 0.5313541679219767} | train loss {'Reaction outcome loss': 0.5327882668193505, 'Total loss': 0.5327882668193505}
2022-11-28 06:11:06,758 INFO:     Found new best model at epoch 3
2022-11-28 06:11:06,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:06,758 INFO:     Epoch: 4
2022-11-28 06:11:07,406 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5649739612232555, 'Total loss': 0.5649739612232555} | train loss {'Reaction outcome loss': 0.5178869531470902, 'Total loss': 0.5178869531470902}
2022-11-28 06:11:07,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:07,407 INFO:     Epoch: 5
2022-11-28 06:11:08,057 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5044788271188736, 'Total loss': 0.5044788271188736} | train loss {'Reaction outcome loss': 0.505417365626413, 'Total loss': 0.505417365626413}
2022-11-28 06:11:08,057 INFO:     Found new best model at epoch 5
2022-11-28 06:11:08,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:08,058 INFO:     Epoch: 6
2022-11-28 06:11:08,706 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49232485246929253, 'Total loss': 0.49232485246929253} | train loss {'Reaction outcome loss': 0.4968511782738627, 'Total loss': 0.4968511782738627}
2022-11-28 06:11:08,706 INFO:     Found new best model at epoch 6
2022-11-28 06:11:08,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:08,707 INFO:     Epoch: 7
2022-11-28 06:11:09,357 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5142479186708276, 'Total loss': 0.5142479186708276} | train loss {'Reaction outcome loss': 0.49427857271262576, 'Total loss': 0.49427857271262576}
2022-11-28 06:11:09,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:09,357 INFO:     Epoch: 8
2022-11-28 06:11:10,008 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4683684584769336, 'Total loss': 0.4683684584769336} | train loss {'Reaction outcome loss': 0.4938079992727358, 'Total loss': 0.4938079992727358}
2022-11-28 06:11:10,008 INFO:     Found new best model at epoch 8
2022-11-28 06:11:10,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:10,009 INFO:     Epoch: 9
2022-11-28 06:11:10,659 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4993509077890353, 'Total loss': 0.4993509077890353} | train loss {'Reaction outcome loss': 0.4902112238869375, 'Total loss': 0.4902112238869375}
2022-11-28 06:11:10,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:10,659 INFO:     Epoch: 10
2022-11-28 06:11:11,311 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48953012783419003, 'Total loss': 0.48953012783419003} | train loss {'Reaction outcome loss': 0.49347176126071385, 'Total loss': 0.49347176126071385}
2022-11-28 06:11:11,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:11,311 INFO:     Epoch: 11
2022-11-28 06:11:11,964 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47779703682119196, 'Total loss': 0.47779703682119196} | train loss {'Reaction outcome loss': 0.4898698897386084, 'Total loss': 0.4898698897386084}
2022-11-28 06:11:11,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:11,964 INFO:     Epoch: 12
2022-11-28 06:11:12,613 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5166902575980533, 'Total loss': 0.5166902575980533} | train loss {'Reaction outcome loss': 0.4789301275294654, 'Total loss': 0.4789301275294654}
2022-11-28 06:11:12,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:12,613 INFO:     Epoch: 13
2022-11-28 06:11:13,262 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48358473960648884, 'Total loss': 0.48358473960648884} | train loss {'Reaction outcome loss': 0.4856030872281717, 'Total loss': 0.4856030872281717}
2022-11-28 06:11:13,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:13,263 INFO:     Epoch: 14
2022-11-28 06:11:13,911 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5027563361959024, 'Total loss': 0.5027563361959024} | train loss {'Reaction outcome loss': 0.48061783192109087, 'Total loss': 0.48061783192109087}
2022-11-28 06:11:13,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:13,912 INFO:     Epoch: 15
2022-11-28 06:11:14,558 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4765718199990012, 'Total loss': 0.4765718199990012} | train loss {'Reaction outcome loss': 0.48430398355941384, 'Total loss': 0.48430398355941384}
2022-11-28 06:11:14,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:14,559 INFO:     Epoch: 16
2022-11-28 06:11:15,208 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48145315220410173, 'Total loss': 0.48145315220410173} | train loss {'Reaction outcome loss': 0.48049486717399287, 'Total loss': 0.48049486717399287}
2022-11-28 06:11:15,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:15,208 INFO:     Epoch: 17
2022-11-28 06:11:15,857 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4730393381958658, 'Total loss': 0.4730393381958658} | train loss {'Reaction outcome loss': 0.48029859473510667, 'Total loss': 0.48029859473510667}
2022-11-28 06:11:15,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:15,858 INFO:     Epoch: 18
2022-11-28 06:11:16,510 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4632789103144949, 'Total loss': 0.4632789103144949} | train loss {'Reaction outcome loss': 0.4778380999759752, 'Total loss': 0.4778380999759752}
2022-11-28 06:11:16,510 INFO:     Found new best model at epoch 18
2022-11-28 06:11:16,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:16,511 INFO:     Epoch: 19
2022-11-28 06:11:17,160 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4518466862765225, 'Total loss': 0.4518466862765225} | train loss {'Reaction outcome loss': 0.47425031783629434, 'Total loss': 0.47425031783629434}
2022-11-28 06:11:17,160 INFO:     Found new best model at epoch 19
2022-11-28 06:11:17,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:17,161 INFO:     Epoch: 20
2022-11-28 06:11:17,811 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.510926274752075, 'Total loss': 0.510926274752075} | train loss {'Reaction outcome loss': 0.47704327702522276, 'Total loss': 0.47704327702522276}
2022-11-28 06:11:17,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:17,811 INFO:     Epoch: 21
2022-11-28 06:11:18,464 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46001495319333946, 'Total loss': 0.46001495319333946} | train loss {'Reaction outcome loss': 0.47507521120869384, 'Total loss': 0.47507521120869384}
2022-11-28 06:11:18,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:18,464 INFO:     Epoch: 22
2022-11-28 06:11:19,118 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46364495158195496, 'Total loss': 0.46364495158195496} | train loss {'Reaction outcome loss': 0.47255091174524655, 'Total loss': 0.47255091174524655}
2022-11-28 06:11:19,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:19,119 INFO:     Epoch: 23
2022-11-28 06:11:19,770 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5192680264061148, 'Total loss': 0.5192680264061148} | train loss {'Reaction outcome loss': 0.47916024710450855, 'Total loss': 0.47916024710450855}
2022-11-28 06:11:19,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:19,770 INFO:     Epoch: 24
2022-11-28 06:11:20,422 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46941795301708306, 'Total loss': 0.46941795301708306} | train loss {'Reaction outcome loss': 0.47218165732159906, 'Total loss': 0.47218165732159906}
2022-11-28 06:11:20,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:20,422 INFO:     Epoch: 25
2022-11-28 06:11:21,074 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48571775379506027, 'Total loss': 0.48571775379506027} | train loss {'Reaction outcome loss': 0.4772913974158618, 'Total loss': 0.4772913974158618}
2022-11-28 06:11:21,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:21,074 INFO:     Epoch: 26
2022-11-28 06:11:21,721 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4453083009205081, 'Total loss': 0.4453083009205081} | train loss {'Reaction outcome loss': 0.47940884755582225, 'Total loss': 0.47940884755582225}
2022-11-28 06:11:21,721 INFO:     Found new best model at epoch 26
2022-11-28 06:11:21,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:21,722 INFO:     Epoch: 27
2022-11-28 06:11:22,372 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47347903285514226, 'Total loss': 0.47347903285514226} | train loss {'Reaction outcome loss': 0.4714118930758262, 'Total loss': 0.4714118930758262}
2022-11-28 06:11:22,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:22,372 INFO:     Epoch: 28
2022-11-28 06:11:23,028 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5028173510323871, 'Total loss': 0.5028173510323871} | train loss {'Reaction outcome loss': 0.4728315173363199, 'Total loss': 0.4728315173363199}
2022-11-28 06:11:23,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:23,028 INFO:     Epoch: 29
2022-11-28 06:11:23,681 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5030039892299101, 'Total loss': 0.5030039892299101} | train loss {'Reaction outcome loss': 0.4784663031904065, 'Total loss': 0.4784663031904065}
2022-11-28 06:11:23,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:23,681 INFO:     Epoch: 30
2022-11-28 06:11:24,333 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49694925817576324, 'Total loss': 0.49694925817576324} | train loss {'Reaction outcome loss': 0.4743159910245818, 'Total loss': 0.4743159910245818}
2022-11-28 06:11:24,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:24,333 INFO:     Epoch: 31
2022-11-28 06:11:24,986 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49882377006790857, 'Total loss': 0.49882377006790857} | train loss {'Reaction outcome loss': 0.47612217506583854, 'Total loss': 0.47612217506583854}
2022-11-28 06:11:24,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:24,986 INFO:     Epoch: 32
2022-11-28 06:11:25,643 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4810661578720266, 'Total loss': 0.4810661578720266} | train loss {'Reaction outcome loss': 0.47135437127886987, 'Total loss': 0.47135437127886987}
2022-11-28 06:11:25,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:25,644 INFO:     Epoch: 33
2022-11-28 06:11:26,296 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4504476816139438, 'Total loss': 0.4504476816139438} | train loss {'Reaction outcome loss': 0.471014869882136, 'Total loss': 0.471014869882136}
2022-11-28 06:11:26,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:26,297 INFO:     Epoch: 34
2022-11-28 06:11:26,948 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47558754648674617, 'Total loss': 0.47558754648674617} | train loss {'Reaction outcome loss': 0.4701987374802025, 'Total loss': 0.4701987374802025}
2022-11-28 06:11:26,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:26,948 INFO:     Epoch: 35
2022-11-28 06:11:27,597 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4699046889489347, 'Total loss': 0.4699046889489347} | train loss {'Reaction outcome loss': 0.47926876222600745, 'Total loss': 0.47926876222600745}
2022-11-28 06:11:27,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:27,597 INFO:     Epoch: 36
2022-11-28 06:11:28,249 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4682385924864899, 'Total loss': 0.4682385924864899} | train loss {'Reaction outcome loss': 0.4774982671348416, 'Total loss': 0.4774982671348416}
2022-11-28 06:11:28,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:28,249 INFO:     Epoch: 37
2022-11-28 06:11:28,901 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47329464283856476, 'Total loss': 0.47329464283856476} | train loss {'Reaction outcome loss': 0.46679859222198017, 'Total loss': 0.46679859222198017}
2022-11-28 06:11:28,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:28,901 INFO:     Epoch: 38
2022-11-28 06:11:29,554 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.451928434046832, 'Total loss': 0.451928434046832} | train loss {'Reaction outcome loss': 0.47466537429361927, 'Total loss': 0.47466537429361927}
2022-11-28 06:11:29,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:29,555 INFO:     Epoch: 39
2022-11-28 06:11:30,204 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4579286231574687, 'Total loss': 0.4579286231574687} | train loss {'Reaction outcome loss': 0.4716664290853909, 'Total loss': 0.4716664290853909}
2022-11-28 06:11:30,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:30,204 INFO:     Epoch: 40
2022-11-28 06:11:30,852 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5026293783025308, 'Total loss': 0.5026293783025308} | train loss {'Reaction outcome loss': 0.4650458650929587, 'Total loss': 0.4650458650929587}
2022-11-28 06:11:30,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:30,852 INFO:     Epoch: 41
2022-11-28 06:11:31,504 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47941849583929236, 'Total loss': 0.47941849583929236} | train loss {'Reaction outcome loss': 0.47924827373757656, 'Total loss': 0.47924827373757656}
2022-11-28 06:11:31,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:31,504 INFO:     Epoch: 42
2022-11-28 06:11:32,159 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4702948230234059, 'Total loss': 0.4702948230234059} | train loss {'Reaction outcome loss': 0.4706556714310938, 'Total loss': 0.4706556714310938}
2022-11-28 06:11:32,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:32,160 INFO:     Epoch: 43
2022-11-28 06:11:32,818 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4663042476908727, 'Total loss': 0.4663042476908727} | train loss {'Reaction outcome loss': 0.47726693609539345, 'Total loss': 0.47726693609539345}
2022-11-28 06:11:32,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:32,818 INFO:     Epoch: 44
2022-11-28 06:11:33,472 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47299575873396615, 'Total loss': 0.47299575873396615} | train loss {'Reaction outcome loss': 0.47104476088163805, 'Total loss': 0.47104476088163805}
2022-11-28 06:11:33,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:33,472 INFO:     Epoch: 45
2022-11-28 06:11:34,125 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4539315981621092, 'Total loss': 0.4539315981621092} | train loss {'Reaction outcome loss': 0.4732605686601327, 'Total loss': 0.4732605686601327}
2022-11-28 06:11:34,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:34,125 INFO:     Epoch: 46
2022-11-28 06:11:34,777 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5038666074926202, 'Total loss': 0.5038666074926202} | train loss {'Reaction outcome loss': 0.47583594900004716, 'Total loss': 0.47583594900004716}
2022-11-28 06:11:34,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:34,777 INFO:     Epoch: 47
2022-11-28 06:11:35,432 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5035609440370039, 'Total loss': 0.5035609440370039} | train loss {'Reaction outcome loss': 0.46609926768103427, 'Total loss': 0.46609926768103427}
2022-11-28 06:11:35,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:35,432 INFO:     Epoch: 48
2022-11-28 06:11:36,079 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4606398494744843, 'Total loss': 0.4606398494744843} | train loss {'Reaction outcome loss': 0.4809041591323152, 'Total loss': 0.4809041591323152}
2022-11-28 06:11:36,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:36,080 INFO:     Epoch: 49
2022-11-28 06:11:36,728 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48372483388944104, 'Total loss': 0.48372483388944104} | train loss {'Reaction outcome loss': 0.47184141351252185, 'Total loss': 0.47184141351252185}
2022-11-28 06:11:36,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:36,729 INFO:     Epoch: 50
2022-11-28 06:11:37,380 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45698389783501625, 'Total loss': 0.45698389783501625} | train loss {'Reaction outcome loss': 0.4738521781502938, 'Total loss': 0.4738521781502938}
2022-11-28 06:11:37,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:37,380 INFO:     Epoch: 51
2022-11-28 06:11:38,037 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4672072932801463, 'Total loss': 0.4672072932801463} | train loss {'Reaction outcome loss': 0.4711346859834632, 'Total loss': 0.4711346859834632}
2022-11-28 06:11:38,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:38,037 INFO:     Epoch: 52
2022-11-28 06:11:38,689 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.470275281843814, 'Total loss': 0.470275281843814} | train loss {'Reaction outcome loss': 0.4720048800414922, 'Total loss': 0.4720048800414922}
2022-11-28 06:11:38,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:38,689 INFO:     Epoch: 53
2022-11-28 06:11:39,342 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4923009472814473, 'Total loss': 0.4923009472814473} | train loss {'Reaction outcome loss': 0.4743724413672272, 'Total loss': 0.4743724413672272}
2022-11-28 06:11:39,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:39,342 INFO:     Epoch: 54
2022-11-28 06:11:39,995 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48293777284297074, 'Total loss': 0.48293777284297074} | train loss {'Reaction outcome loss': 0.47383417803414013, 'Total loss': 0.47383417803414013}
2022-11-28 06:11:39,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:39,996 INFO:     Epoch: 55
2022-11-28 06:11:40,652 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4846982204101302, 'Total loss': 0.4846982204101302} | train loss {'Reaction outcome loss': 0.4669587892537214, 'Total loss': 0.4669587892537214}
2022-11-28 06:11:40,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:40,652 INFO:     Epoch: 56
2022-11-28 06:11:41,309 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4745868400416591, 'Total loss': 0.4745868400416591} | train loss {'Reaction outcome loss': 0.47650135022645096, 'Total loss': 0.47650135022645096}
2022-11-28 06:11:41,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:41,309 INFO:     Epoch: 57
2022-11-28 06:11:41,964 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.476297122172334, 'Total loss': 0.476297122172334} | train loss {'Reaction outcome loss': 0.4696261894337985, 'Total loss': 0.4696261894337985}
2022-11-28 06:11:41,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:41,964 INFO:     Epoch: 58
2022-11-28 06:11:42,619 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4776918185366826, 'Total loss': 0.4776918185366826} | train loss {'Reaction outcome loss': 0.46824424035695134, 'Total loss': 0.46824424035695134}
2022-11-28 06:11:42,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:42,619 INFO:     Epoch: 59
2022-11-28 06:11:43,277 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.478466082025658, 'Total loss': 0.478466082025658} | train loss {'Reaction outcome loss': 0.4692252078834845, 'Total loss': 0.4692252078834845}
2022-11-28 06:11:43,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:43,277 INFO:     Epoch: 60
2022-11-28 06:11:43,930 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4798093590546738, 'Total loss': 0.4798093590546738} | train loss {'Reaction outcome loss': 0.4756889177828419, 'Total loss': 0.4756889177828419}
2022-11-28 06:11:43,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:43,931 INFO:     Epoch: 61
2022-11-28 06:11:44,582 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4787219505418431, 'Total loss': 0.4787219505418431} | train loss {'Reaction outcome loss': 0.46805468657795263, 'Total loss': 0.46805468657795263}
2022-11-28 06:11:44,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:44,583 INFO:     Epoch: 62
2022-11-28 06:11:45,234 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4726738411594521, 'Total loss': 0.4726738411594521} | train loss {'Reaction outcome loss': 0.4753581289125949, 'Total loss': 0.4753581289125949}
2022-11-28 06:11:45,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:45,234 INFO:     Epoch: 63
2022-11-28 06:11:45,886 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4976861615749923, 'Total loss': 0.4976861615749923} | train loss {'Reaction outcome loss': 0.47264418176242284, 'Total loss': 0.47264418176242284}
2022-11-28 06:11:45,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:45,887 INFO:     Epoch: 64
2022-11-28 06:11:46,540 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5229404836215756, 'Total loss': 0.5229404836215756} | train loss {'Reaction outcome loss': 0.4660685432200529, 'Total loss': 0.4660685432200529}
2022-11-28 06:11:46,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:46,540 INFO:     Epoch: 65
2022-11-28 06:11:47,191 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4678437779234214, 'Total loss': 0.4678437779234214} | train loss {'Reaction outcome loss': 0.47010577296724126, 'Total loss': 0.47010577296724126}
2022-11-28 06:11:47,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:47,192 INFO:     Epoch: 66
2022-11-28 06:11:47,842 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5090269761329348, 'Total loss': 0.5090269761329348} | train loss {'Reaction outcome loss': 0.47163524092460163, 'Total loss': 0.47163524092460163}
2022-11-28 06:11:47,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:47,842 INFO:     Epoch: 67
2022-11-28 06:11:48,499 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4492240903729742, 'Total loss': 0.4492240903729742} | train loss {'Reaction outcome loss': 0.47089070972739433, 'Total loss': 0.47089070972739433}
2022-11-28 06:11:48,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:48,499 INFO:     Epoch: 68
2022-11-28 06:11:49,151 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4729778197678653, 'Total loss': 0.4729778197678653} | train loss {'Reaction outcome loss': 0.4710417967061607, 'Total loss': 0.4710417967061607}
2022-11-28 06:11:49,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:49,152 INFO:     Epoch: 69
2022-11-28 06:11:49,801 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5051885582506657, 'Total loss': 0.5051885582506657} | train loss {'Reaction outcome loss': 0.4762640760869396, 'Total loss': 0.4762640760869396}
2022-11-28 06:11:49,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:49,802 INFO:     Epoch: 70
2022-11-28 06:11:50,455 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48536112873857334, 'Total loss': 0.48536112873857334} | train loss {'Reaction outcome loss': 0.47063084287302837, 'Total loss': 0.47063084287302837}
2022-11-28 06:11:50,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:50,456 INFO:     Epoch: 71
2022-11-28 06:11:51,105 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4726889194412665, 'Total loss': 0.4726889194412665} | train loss {'Reaction outcome loss': 0.46592335542853996, 'Total loss': 0.46592335542853996}
2022-11-28 06:11:51,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:51,106 INFO:     Epoch: 72
2022-11-28 06:11:51,758 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45949570733037864, 'Total loss': 0.45949570733037864} | train loss {'Reaction outcome loss': 0.4723355261038761, 'Total loss': 0.4723355261038761}
2022-11-28 06:11:51,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:51,758 INFO:     Epoch: 73
2022-11-28 06:11:52,408 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45176218382336875, 'Total loss': 0.45176218382336875} | train loss {'Reaction outcome loss': 0.47270574326417886, 'Total loss': 0.47270574326417886}
2022-11-28 06:11:52,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:52,408 INFO:     Epoch: 74
2022-11-28 06:11:53,065 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48256756974892184, 'Total loss': 0.48256756974892184} | train loss {'Reaction outcome loss': 0.4745005800103655, 'Total loss': 0.4745005800103655}
2022-11-28 06:11:53,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:53,065 INFO:     Epoch: 75
2022-11-28 06:11:53,717 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4627929184247147, 'Total loss': 0.4627929184247147} | train loss {'Reaction outcome loss': 0.46573188821880185, 'Total loss': 0.46573188821880185}
2022-11-28 06:11:53,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:53,717 INFO:     Epoch: 76
2022-11-28 06:11:54,364 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46830031025985425, 'Total loss': 0.46830031025985425} | train loss {'Reaction outcome loss': 0.4689488802029162, 'Total loss': 0.4689488802029162}
2022-11-28 06:11:54,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:54,364 INFO:     Epoch: 77
2022-11-28 06:11:55,019 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48237983137369156, 'Total loss': 0.48237983137369156} | train loss {'Reaction outcome loss': 0.47339657289641246, 'Total loss': 0.47339657289641246}
2022-11-28 06:11:55,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:55,019 INFO:     Epoch: 78
2022-11-28 06:11:55,669 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.464930495755239, 'Total loss': 0.464930495755239} | train loss {'Reaction outcome loss': 0.46396824741850096, 'Total loss': 0.46396824741850096}
2022-11-28 06:11:55,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:55,669 INFO:     Epoch: 79
2022-11-28 06:11:56,321 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5123342275619507, 'Total loss': 0.5123342275619507} | train loss {'Reaction outcome loss': 0.4709259897470474, 'Total loss': 0.4709259897470474}
2022-11-28 06:11:56,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:56,322 INFO:     Epoch: 80
2022-11-28 06:11:56,974 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4685256217013706, 'Total loss': 0.4685256217013706} | train loss {'Reaction outcome loss': 0.47038506178223355, 'Total loss': 0.47038506178223355}
2022-11-28 06:11:56,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:56,974 INFO:     Epoch: 81
2022-11-28 06:11:57,628 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46075027605349367, 'Total loss': 0.46075027605349367} | train loss {'Reaction outcome loss': 0.47318491382258276, 'Total loss': 0.47318491382258276}
2022-11-28 06:11:57,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:57,628 INFO:     Epoch: 82
2022-11-28 06:11:58,279 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48431375555016776, 'Total loss': 0.48431375555016776} | train loss {'Reaction outcome loss': 0.47147861579243017, 'Total loss': 0.47147861579243017}
2022-11-28 06:11:58,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:58,279 INFO:     Epoch: 83
2022-11-28 06:11:58,933 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.461589859967882, 'Total loss': 0.461589859967882} | train loss {'Reaction outcome loss': 0.4711162562881197, 'Total loss': 0.4711162562881197}
2022-11-28 06:11:58,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:58,933 INFO:     Epoch: 84
2022-11-28 06:11:59,584 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4767812835899266, 'Total loss': 0.4767812835899266} | train loss {'Reaction outcome loss': 0.4692025015548784, 'Total loss': 0.4692025015548784}
2022-11-28 06:11:59,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:11:59,585 INFO:     Epoch: 85
2022-11-28 06:12:00,239 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4571999998932535, 'Total loss': 0.4571999998932535} | train loss {'Reaction outcome loss': 0.46840296405918747, 'Total loss': 0.46840296405918747}
2022-11-28 06:12:00,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:00,239 INFO:     Epoch: 86
2022-11-28 06:12:00,892 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47016325017268007, 'Total loss': 0.47016325017268007} | train loss {'Reaction outcome loss': 0.47003671563401517, 'Total loss': 0.47003671563401517}
2022-11-28 06:12:00,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:00,893 INFO:     Epoch: 87
2022-11-28 06:12:01,545 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4768414602360942, 'Total loss': 0.4768414602360942} | train loss {'Reaction outcome loss': 0.4679729236327872, 'Total loss': 0.4679729236327872}
2022-11-28 06:12:01,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:01,545 INFO:     Epoch: 88
2022-11-28 06:12:02,199 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4797271798280152, 'Total loss': 0.4797271798280152} | train loss {'Reaction outcome loss': 0.473230258360201, 'Total loss': 0.473230258360201}
2022-11-28 06:12:02,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:02,199 INFO:     Epoch: 89
2022-11-28 06:12:02,850 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4919481592422182, 'Total loss': 0.4919481592422182} | train loss {'Reaction outcome loss': 0.47396235514660273, 'Total loss': 0.47396235514660273}
2022-11-28 06:12:02,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:02,851 INFO:     Epoch: 90
2022-11-28 06:12:03,505 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47285565158182924, 'Total loss': 0.47285565158182924} | train loss {'Reaction outcome loss': 0.4676195603244159, 'Total loss': 0.4676195603244159}
2022-11-28 06:12:03,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:03,505 INFO:     Epoch: 91
2022-11-28 06:12:04,159 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4762364355000583, 'Total loss': 0.4762364355000583} | train loss {'Reaction outcome loss': 0.4691251407472455, 'Total loss': 0.4691251407472455}
2022-11-28 06:12:04,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:04,159 INFO:     Epoch: 92
2022-11-28 06:12:04,811 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45279960469766095, 'Total loss': 0.45279960469766095} | train loss {'Reaction outcome loss': 0.46950957863306514, 'Total loss': 0.46950957863306514}
2022-11-28 06:12:04,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:04,811 INFO:     Epoch: 93
2022-11-28 06:12:05,462 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4487207220359282, 'Total loss': 0.4487207220359282} | train loss {'Reaction outcome loss': 0.47675255214681433, 'Total loss': 0.47675255214681433}
2022-11-28 06:12:05,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:05,463 INFO:     Epoch: 94
2022-11-28 06:12:06,112 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4826318967071446, 'Total loss': 0.4826318967071446} | train loss {'Reaction outcome loss': 0.4753187261673869, 'Total loss': 0.4753187261673869}
2022-11-28 06:12:06,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:06,112 INFO:     Epoch: 95
2022-11-28 06:12:06,766 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48422491177916527, 'Total loss': 0.48422491177916527} | train loss {'Reaction outcome loss': 0.47675743315901076, 'Total loss': 0.47675743315901076}
2022-11-28 06:12:06,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:06,766 INFO:     Epoch: 96
2022-11-28 06:12:07,422 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45461469380693004, 'Total loss': 0.45461469380693004} | train loss {'Reaction outcome loss': 0.4654731808876505, 'Total loss': 0.4654731808876505}
2022-11-28 06:12:07,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:07,422 INFO:     Epoch: 97
2022-11-28 06:12:08,069 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45266924967819994, 'Total loss': 0.45266924967819994} | train loss {'Reaction outcome loss': 0.47153811606825613, 'Total loss': 0.47153811606825613}
2022-11-28 06:12:08,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:08,069 INFO:     Epoch: 98
2022-11-28 06:12:08,719 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4847277494316751, 'Total loss': 0.4847277494316751} | train loss {'Reaction outcome loss': 0.47108220366799103, 'Total loss': 0.47108220366799103}
2022-11-28 06:12:08,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:08,719 INFO:     Epoch: 99
2022-11-28 06:12:09,373 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4702167229896242, 'Total loss': 0.4702167229896242} | train loss {'Reaction outcome loss': 0.4769110142576451, 'Total loss': 0.4769110142576451}
2022-11-28 06:12:09,373 INFO:     Best model found after epoch 27 of 100.
2022-11-28 06:12:09,373 INFO:   Done with stage: TRAINING
2022-11-28 06:12:09,373 INFO:   Starting stage: EVALUATION
2022-11-28 06:12:09,497 INFO:   Done with stage: EVALUATION
2022-11-28 06:12:09,497 INFO:   Leaving out SEQ value Fold_9
2022-11-28 06:12:09,510 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 06:12:09,510 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:12:10,140 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:12:10,141 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:12:10,211 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:12:10,211 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:12:10,211 INFO:     No hyperparam tuning for this model
2022-11-28 06:12:10,211 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:12:10,211 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:12:10,212 INFO:     None feature selector for col prot
2022-11-28 06:12:10,212 INFO:     None feature selector for col prot
2022-11-28 06:12:10,212 INFO:     None feature selector for col prot
2022-11-28 06:12:10,212 INFO:     None feature selector for col chem
2022-11-28 06:12:10,212 INFO:     None feature selector for col chem
2022-11-28 06:12:10,213 INFO:     None feature selector for col chem
2022-11-28 06:12:10,213 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:12:10,213 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:12:10,214 INFO:     Number of params in model 169651
2022-11-28 06:12:10,217 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:12:10,217 INFO:   Starting stage: TRAINING
2022-11-28 06:12:10,268 INFO:     Val loss before train {'Reaction outcome loss': 1.028355365449732, 'Total loss': 1.028355365449732}
2022-11-28 06:12:10,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:10,268 INFO:     Epoch: 0
2022-11-28 06:12:10,922 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.668905452571132, 'Total loss': 0.668905452571132} | train loss {'Reaction outcome loss': 0.6692178870743586, 'Total loss': 0.6692178870743586}
2022-11-28 06:12:10,922 INFO:     Found new best model at epoch 0
2022-11-28 06:12:10,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:10,923 INFO:     Epoch: 1
2022-11-28 06:12:11,580 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6124920499595728, 'Total loss': 0.6124920499595728} | train loss {'Reaction outcome loss': 0.5765502480601492, 'Total loss': 0.5765502480601492}
2022-11-28 06:12:11,580 INFO:     Found new best model at epoch 1
2022-11-28 06:12:11,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:11,581 INFO:     Epoch: 2
2022-11-28 06:12:12,235 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6120951135050167, 'Total loss': 0.6120951135050167} | train loss {'Reaction outcome loss': 0.5498209005063363, 'Total loss': 0.5498209005063363}
2022-11-28 06:12:12,235 INFO:     Found new best model at epoch 2
2022-11-28 06:12:12,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:12,236 INFO:     Epoch: 3
2022-11-28 06:12:12,891 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.573072842576287, 'Total loss': 0.573072842576287} | train loss {'Reaction outcome loss': 0.5217533894335693, 'Total loss': 0.5217533894335693}
2022-11-28 06:12:12,891 INFO:     Found new best model at epoch 3
2022-11-28 06:12:12,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:12,892 INFO:     Epoch: 4
2022-11-28 06:12:13,554 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5715095732699741, 'Total loss': 0.5715095732699741} | train loss {'Reaction outcome loss': 0.521286694204759, 'Total loss': 0.521286694204759}
2022-11-28 06:12:13,554 INFO:     Found new best model at epoch 4
2022-11-28 06:12:13,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:13,555 INFO:     Epoch: 5
2022-11-28 06:12:14,209 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5806000124324452, 'Total loss': 0.5806000124324452} | train loss {'Reaction outcome loss': 0.5188840393595368, 'Total loss': 0.5188840393595368}
2022-11-28 06:12:14,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:14,209 INFO:     Epoch: 6
2022-11-28 06:12:14,861 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5474789305166765, 'Total loss': 0.5474789305166765} | train loss {'Reaction outcome loss': 0.5064220573538198, 'Total loss': 0.5064220573538198}
2022-11-28 06:12:14,862 INFO:     Found new best model at epoch 6
2022-11-28 06:12:14,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:14,863 INFO:     Epoch: 7
2022-11-28 06:12:15,521 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.6974044570868666, 'Total loss': 0.6974044570868666} | train loss {'Reaction outcome loss': 0.5007475209139619, 'Total loss': 0.5007475209139619}
2022-11-28 06:12:15,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:15,521 INFO:     Epoch: 8
2022-11-28 06:12:16,177 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5660928230394017, 'Total loss': 0.5660928230394017} | train loss {'Reaction outcome loss': 0.5156907895919283, 'Total loss': 0.5156907895919283}
2022-11-28 06:12:16,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:16,177 INFO:     Epoch: 9
2022-11-28 06:12:16,835 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5268230526284738, 'Total loss': 0.5268230526284738} | train loss {'Reaction outcome loss': 0.4904377575104053, 'Total loss': 0.4904377575104053}
2022-11-28 06:12:16,835 INFO:     Found new best model at epoch 9
2022-11-28 06:12:16,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:16,836 INFO:     Epoch: 10
2022-11-28 06:12:17,494 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5685700435530056, 'Total loss': 0.5685700435530056} | train loss {'Reaction outcome loss': 0.47465735268194664, 'Total loss': 0.47465735268194664}
2022-11-28 06:12:17,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:17,494 INFO:     Epoch: 11
2022-11-28 06:12:18,148 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5522267432375387, 'Total loss': 0.5522267432375387} | train loss {'Reaction outcome loss': 0.47425196868808644, 'Total loss': 0.47425196868808644}
2022-11-28 06:12:18,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:18,148 INFO:     Epoch: 12
2022-11-28 06:12:18,800 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.561414723707871, 'Total loss': 0.561414723707871} | train loss {'Reaction outcome loss': 0.47517526994349985, 'Total loss': 0.47517526994349985}
2022-11-28 06:12:18,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:18,800 INFO:     Epoch: 13
2022-11-28 06:12:19,457 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5644868619062684, 'Total loss': 0.5644868619062684} | train loss {'Reaction outcome loss': 0.4735290746276195, 'Total loss': 0.4735290746276195}
2022-11-28 06:12:19,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:19,457 INFO:     Epoch: 14
2022-11-28 06:12:20,113 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5174669227139517, 'Total loss': 0.5174669227139517} | train loss {'Reaction outcome loss': 0.48181289030231444, 'Total loss': 0.48181289030231444}
2022-11-28 06:12:20,113 INFO:     Found new best model at epoch 14
2022-11-28 06:12:20,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:20,114 INFO:     Epoch: 15
2022-11-28 06:12:20,767 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5885524682023309, 'Total loss': 0.5885524682023309} | train loss {'Reaction outcome loss': 0.4703805147998246, 'Total loss': 0.4703805147998246}
2022-11-28 06:12:20,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:20,767 INFO:     Epoch: 16
2022-11-28 06:12:21,422 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5128430995074186, 'Total loss': 0.5128430995074186} | train loss {'Reaction outcome loss': 0.4814414135538615, 'Total loss': 0.4814414135538615}
2022-11-28 06:12:21,422 INFO:     Found new best model at epoch 16
2022-11-28 06:12:21,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:21,423 INFO:     Epoch: 17
2022-11-28 06:12:22,078 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.526832848448645, 'Total loss': 0.526832848448645} | train loss {'Reaction outcome loss': 0.46088481160551914, 'Total loss': 0.46088481160551914}
2022-11-28 06:12:22,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:22,079 INFO:     Epoch: 18
2022-11-28 06:12:22,735 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4966224123808471, 'Total loss': 0.4966224123808471} | train loss {'Reaction outcome loss': 0.4625972505462797, 'Total loss': 0.4625972505462797}
2022-11-28 06:12:22,735 INFO:     Found new best model at epoch 18
2022-11-28 06:12:22,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:22,736 INFO:     Epoch: 19
2022-11-28 06:12:23,396 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.6041831800883467, 'Total loss': 0.6041831800883467} | train loss {'Reaction outcome loss': 0.47379835376795004, 'Total loss': 0.47379835376795004}
2022-11-28 06:12:23,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:23,396 INFO:     Epoch: 20
2022-11-28 06:12:24,053 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.514264041049914, 'Total loss': 0.514264041049914} | train loss {'Reaction outcome loss': 0.47514364237968737, 'Total loss': 0.47514364237968737}
2022-11-28 06:12:24,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:24,054 INFO:     Epoch: 21
2022-11-28 06:12:24,716 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5372623672539537, 'Total loss': 0.5372623672539537} | train loss {'Reaction outcome loss': 0.4605748201550742, 'Total loss': 0.4605748201550742}
2022-11-28 06:12:24,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:24,716 INFO:     Epoch: 22
2022-11-28 06:12:25,372 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5271479277448221, 'Total loss': 0.5271479277448221} | train loss {'Reaction outcome loss': 0.46587325511915, 'Total loss': 0.46587325511915}
2022-11-28 06:12:25,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:25,372 INFO:     Epoch: 23
2022-11-28 06:12:26,032 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5457767170261253, 'Total loss': 0.5457767170261253} | train loss {'Reaction outcome loss': 0.4698822563476408, 'Total loss': 0.4698822563476408}
2022-11-28 06:12:26,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:26,032 INFO:     Epoch: 24
2022-11-28 06:12:26,688 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.540339185771617, 'Total loss': 0.540339185771617} | train loss {'Reaction outcome loss': 0.4644083439821174, 'Total loss': 0.4644083439821174}
2022-11-28 06:12:26,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:26,689 INFO:     Epoch: 25
2022-11-28 06:12:27,342 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5837750678712671, 'Total loss': 0.5837750678712671} | train loss {'Reaction outcome loss': 0.46968809391564204, 'Total loss': 0.46968809391564204}
2022-11-28 06:12:27,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:27,343 INFO:     Epoch: 26
2022-11-28 06:12:28,000 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5323186388069933, 'Total loss': 0.5323186388069933} | train loss {'Reaction outcome loss': 0.5115472320071327, 'Total loss': 0.5115472320071327}
2022-11-28 06:12:28,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:28,001 INFO:     Epoch: 27
2022-11-28 06:12:28,666 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.545102174309167, 'Total loss': 0.545102174309167} | train loss {'Reaction outcome loss': 0.4520884274471144, 'Total loss': 0.4520884274471144}
2022-11-28 06:12:28,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:28,667 INFO:     Epoch: 28
2022-11-28 06:12:29,325 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5643190680579706, 'Total loss': 0.5643190680579706} | train loss {'Reaction outcome loss': 0.46289742151312985, 'Total loss': 0.46289742151312985}
2022-11-28 06:12:29,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:29,325 INFO:     Epoch: 29
2022-11-28 06:12:29,986 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.569345431571657, 'Total loss': 0.569345431571657} | train loss {'Reaction outcome loss': 0.453627113490422, 'Total loss': 0.453627113490422}
2022-11-28 06:12:29,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:29,987 INFO:     Epoch: 30
2022-11-28 06:12:30,644 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.516728610816327, 'Total loss': 0.516728610816327} | train loss {'Reaction outcome loss': 0.45476482590181594, 'Total loss': 0.45476482590181594}
2022-11-28 06:12:30,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:30,644 INFO:     Epoch: 31
2022-11-28 06:12:31,303 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4872389798137275, 'Total loss': 0.4872389798137275} | train loss {'Reaction outcome loss': 0.45799545230728533, 'Total loss': 0.45799545230728533}
2022-11-28 06:12:31,303 INFO:     Found new best model at epoch 31
2022-11-28 06:12:31,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:31,304 INFO:     Epoch: 32
2022-11-28 06:12:31,963 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5343920124525373, 'Total loss': 0.5343920124525373} | train loss {'Reaction outcome loss': 0.452494377025256, 'Total loss': 0.452494377025256}
2022-11-28 06:12:31,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:31,963 INFO:     Epoch: 33
2022-11-28 06:12:32,622 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5593009360811927, 'Total loss': 0.5593009360811927} | train loss {'Reaction outcome loss': 0.45122279148352773, 'Total loss': 0.45122279148352773}
2022-11-28 06:12:32,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:32,622 INFO:     Epoch: 34
2022-11-28 06:12:33,280 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5155398943884806, 'Total loss': 0.5155398943884806} | train loss {'Reaction outcome loss': 0.4675965828572208, 'Total loss': 0.4675965828572208}
2022-11-28 06:12:33,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:33,280 INFO:     Epoch: 35
2022-11-28 06:12:33,939 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5239389504898678, 'Total loss': 0.5239389504898678} | train loss {'Reaction outcome loss': 0.45723908614774467, 'Total loss': 0.45723908614774467}
2022-11-28 06:12:33,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:33,939 INFO:     Epoch: 36
2022-11-28 06:12:34,595 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.567714317955754, 'Total loss': 0.567714317955754} | train loss {'Reaction outcome loss': 0.4625944473482819, 'Total loss': 0.4625944473482819}
2022-11-28 06:12:34,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:34,595 INFO:     Epoch: 37
2022-11-28 06:12:35,252 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5289840705015443, 'Total loss': 0.5289840705015443} | train loss {'Reaction outcome loss': 0.49238719643368895, 'Total loss': 0.49238719643368895}
2022-11-28 06:12:35,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:35,252 INFO:     Epoch: 38
2022-11-28 06:12:35,910 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5504937469959259, 'Total loss': 0.5504937469959259} | train loss {'Reaction outcome loss': 0.46799893146343075, 'Total loss': 0.46799893146343075}
2022-11-28 06:12:35,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:35,910 INFO:     Epoch: 39
2022-11-28 06:12:36,569 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5231624922969125, 'Total loss': 0.5231624922969125} | train loss {'Reaction outcome loss': 0.4591562832415345, 'Total loss': 0.4591562832415345}
2022-11-28 06:12:36,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:36,569 INFO:     Epoch: 40
2022-11-28 06:12:37,225 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.524498546665365, 'Total loss': 0.524498546665365} | train loss {'Reaction outcome loss': 0.46090905956531825, 'Total loss': 0.46090905956531825}
2022-11-28 06:12:37,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:37,226 INFO:     Epoch: 41
2022-11-28 06:12:37,884 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5059162046421658, 'Total loss': 0.5059162046421658} | train loss {'Reaction outcome loss': 0.45696279308937776, 'Total loss': 0.45696279308937776}
2022-11-28 06:12:37,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:37,884 INFO:     Epoch: 42
2022-11-28 06:12:38,542 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5129803981293332, 'Total loss': 0.5129803981293332} | train loss {'Reaction outcome loss': 0.45474508682243253, 'Total loss': 0.45474508682243253}
2022-11-28 06:12:38,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:38,542 INFO:     Epoch: 43
2022-11-28 06:12:39,202 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5243733369491317, 'Total loss': 0.5243733369491317} | train loss {'Reaction outcome loss': 0.4650547304737423, 'Total loss': 0.4650547304737423}
2022-11-28 06:12:39,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:39,202 INFO:     Epoch: 44
2022-11-28 06:12:39,858 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5043591437014666, 'Total loss': 0.5043591437014666} | train loss {'Reaction outcome loss': 0.4633266552377809, 'Total loss': 0.4633266552377809}
2022-11-28 06:12:39,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:39,858 INFO:     Epoch: 45
2022-11-28 06:12:40,515 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5479885556481101, 'Total loss': 0.5479885556481101} | train loss {'Reaction outcome loss': 0.46371688724680227, 'Total loss': 0.46371688724680227}
2022-11-28 06:12:40,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:40,516 INFO:     Epoch: 46
2022-11-28 06:12:41,174 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5040267241949384, 'Total loss': 0.5040267241949384} | train loss {'Reaction outcome loss': 0.45886486455013875, 'Total loss': 0.45886486455013875}
2022-11-28 06:12:41,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:41,174 INFO:     Epoch: 47
2022-11-28 06:12:41,832 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5155175179243088, 'Total loss': 0.5155175179243088} | train loss {'Reaction outcome loss': 0.46248851155462534, 'Total loss': 0.46248851155462534}
2022-11-28 06:12:41,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:41,833 INFO:     Epoch: 48
2022-11-28 06:12:42,492 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5112568336454305, 'Total loss': 0.5112568336454305} | train loss {'Reaction outcome loss': 0.44970674598627247, 'Total loss': 0.44970674598627247}
2022-11-28 06:12:42,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:42,492 INFO:     Epoch: 49
2022-11-28 06:12:43,152 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5114541883495721, 'Total loss': 0.5114541883495721} | train loss {'Reaction outcome loss': 0.4536366216566881, 'Total loss': 0.4536366216566881}
2022-11-28 06:12:43,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:43,152 INFO:     Epoch: 50
2022-11-28 06:12:43,809 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.503639651631767, 'Total loss': 0.503639651631767} | train loss {'Reaction outcome loss': 0.4704765010821192, 'Total loss': 0.4704765010821192}
2022-11-28 06:12:43,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:43,810 INFO:     Epoch: 51
2022-11-28 06:12:44,469 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5240268565037034, 'Total loss': 0.5240268565037034} | train loss {'Reaction outcome loss': 0.45662531323037164, 'Total loss': 0.45662531323037164}
2022-11-28 06:12:44,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:44,470 INFO:     Epoch: 52
2022-11-28 06:12:45,123 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5556211336092516, 'Total loss': 0.5556211336092516} | train loss {'Reaction outcome loss': 0.449379480711603, 'Total loss': 0.449379480711603}
2022-11-28 06:12:45,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:45,123 INFO:     Epoch: 53
2022-11-28 06:12:45,780 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5839252370325002, 'Total loss': 0.5839252370325002} | train loss {'Reaction outcome loss': 0.45895828765172225, 'Total loss': 0.45895828765172225}
2022-11-28 06:12:45,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:45,780 INFO:     Epoch: 54
2022-11-28 06:12:46,436 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.534729658880017, 'Total loss': 0.534729658880017} | train loss {'Reaction outcome loss': 0.45974467252852463, 'Total loss': 0.45974467252852463}
2022-11-28 06:12:46,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:46,437 INFO:     Epoch: 55
2022-11-28 06:12:47,092 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5469649346037344, 'Total loss': 0.5469649346037344} | train loss {'Reaction outcome loss': 0.45481674864827865, 'Total loss': 0.45481674864827865}
2022-11-28 06:12:47,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:47,092 INFO:     Epoch: 56
2022-11-28 06:12:47,747 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.50839868391102, 'Total loss': 0.50839868391102} | train loss {'Reaction outcome loss': 0.45618369330761405, 'Total loss': 0.45618369330761405}
2022-11-28 06:12:47,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:47,747 INFO:     Epoch: 57
2022-11-28 06:12:48,404 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5013655681501735, 'Total loss': 0.5013655681501735} | train loss {'Reaction outcome loss': 0.4592310185977804, 'Total loss': 0.4592310185977804}
2022-11-28 06:12:48,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:48,405 INFO:     Epoch: 58
2022-11-28 06:12:49,063 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5256388438018885, 'Total loss': 0.5256388438018885} | train loss {'Reaction outcome loss': 0.45142175193860945, 'Total loss': 0.45142175193860945}
2022-11-28 06:12:49,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:49,063 INFO:     Epoch: 59
2022-11-28 06:12:49,722 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5679494501514868, 'Total loss': 0.5679494501514868} | train loss {'Reaction outcome loss': 0.4483956617080731, 'Total loss': 0.4483956617080731}
2022-11-28 06:12:49,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:49,722 INFO:     Epoch: 60
2022-11-28 06:12:50,379 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5259337062862787, 'Total loss': 0.5259337062862787} | train loss {'Reaction outcome loss': 0.4564543634894406, 'Total loss': 0.4564543634894406}
2022-11-28 06:12:50,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:50,379 INFO:     Epoch: 61
2022-11-28 06:12:51,041 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5093721110712398, 'Total loss': 0.5093721110712398} | train loss {'Reaction outcome loss': 0.4693057276459358, 'Total loss': 0.4693057276459358}
2022-11-28 06:12:51,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:51,041 INFO:     Epoch: 62
2022-11-28 06:12:51,699 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.534568022259257, 'Total loss': 0.534568022259257} | train loss {'Reaction outcome loss': 0.459107481154353, 'Total loss': 0.459107481154353}
2022-11-28 06:12:51,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:51,700 INFO:     Epoch: 63
2022-11-28 06:12:52,363 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5076958398250017, 'Total loss': 0.5076958398250017} | train loss {'Reaction outcome loss': 0.4895390980398124, 'Total loss': 0.4895390980398124}
2022-11-28 06:12:52,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:52,363 INFO:     Epoch: 64
2022-11-28 06:12:53,020 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49521255188367586, 'Total loss': 0.49521255188367586} | train loss {'Reaction outcome loss': 0.45991681612696245, 'Total loss': 0.45991681612696245}
2022-11-28 06:12:53,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:53,020 INFO:     Epoch: 65
2022-11-28 06:12:53,678 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5045509331605651, 'Total loss': 0.5045509331605651} | train loss {'Reaction outcome loss': 0.45005993096597174, 'Total loss': 0.45005993096597174}
2022-11-28 06:12:53,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:53,679 INFO:     Epoch: 66
2022-11-28 06:12:54,337 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5084722929380157, 'Total loss': 0.5084722929380157} | train loss {'Reaction outcome loss': 0.4518765889198674, 'Total loss': 0.4518765889198674}
2022-11-28 06:12:54,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:54,338 INFO:     Epoch: 67
2022-11-28 06:12:54,995 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5034053793007677, 'Total loss': 0.5034053793007677} | train loss {'Reaction outcome loss': 0.4507174514505545, 'Total loss': 0.4507174514505545}
2022-11-28 06:12:54,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:54,995 INFO:     Epoch: 68
2022-11-28 06:12:55,652 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5571292394941504, 'Total loss': 0.5571292394941504} | train loss {'Reaction outcome loss': 0.45105001849201526, 'Total loss': 0.45105001849201526}
2022-11-28 06:12:55,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:55,652 INFO:     Epoch: 69
2022-11-28 06:12:56,310 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5071587897837162, 'Total loss': 0.5071587897837162} | train loss {'Reaction outcome loss': 0.45513282527747423, 'Total loss': 0.45513282527747423}
2022-11-28 06:12:56,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:56,311 INFO:     Epoch: 70
2022-11-28 06:12:56,967 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5271441011943601, 'Total loss': 0.5271441011943601} | train loss {'Reaction outcome loss': 0.44478220159285947, 'Total loss': 0.44478220159285947}
2022-11-28 06:12:56,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:56,967 INFO:     Epoch: 71
2022-11-28 06:12:57,624 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5283240452408791, 'Total loss': 0.5283240452408791} | train loss {'Reaction outcome loss': 0.4476820243002191, 'Total loss': 0.4476820243002191}
2022-11-28 06:12:57,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:57,624 INFO:     Epoch: 72
2022-11-28 06:12:58,284 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4956644997000694, 'Total loss': 0.4956644997000694} | train loss {'Reaction outcome loss': 0.4527150153027855, 'Total loss': 0.4527150153027855}
2022-11-28 06:12:58,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:58,285 INFO:     Epoch: 73
2022-11-28 06:12:58,947 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5093134678900242, 'Total loss': 0.5093134678900242} | train loss {'Reaction outcome loss': 0.45275884939108785, 'Total loss': 0.45275884939108785}
2022-11-28 06:12:58,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:58,947 INFO:     Epoch: 74
2022-11-28 06:12:59,604 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5084478672255169, 'Total loss': 0.5084478672255169} | train loss {'Reaction outcome loss': 0.45319458885073116, 'Total loss': 0.45319458885073116}
2022-11-28 06:12:59,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:12:59,604 INFO:     Epoch: 75
2022-11-28 06:13:00,263 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5129600438204679, 'Total loss': 0.5129600438204679} | train loss {'Reaction outcome loss': 0.44734481976250645, 'Total loss': 0.44734481976250645}
2022-11-28 06:13:00,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:00,263 INFO:     Epoch: 76
2022-11-28 06:13:00,921 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5352778732776642, 'Total loss': 0.5352778732776642} | train loss {'Reaction outcome loss': 0.4532188158086407, 'Total loss': 0.4532188158086407}
2022-11-28 06:13:00,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:00,922 INFO:     Epoch: 77
2022-11-28 06:13:01,580 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4742713651873849, 'Total loss': 0.4742713651873849} | train loss {'Reaction outcome loss': 0.4528227224644379, 'Total loss': 0.4528227224644379}
2022-11-28 06:13:01,580 INFO:     Found new best model at epoch 77
2022-11-28 06:13:01,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:01,581 INFO:     Epoch: 78
2022-11-28 06:13:02,241 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5296359448270365, 'Total loss': 0.5296359448270365} | train loss {'Reaction outcome loss': 0.45759895081944796, 'Total loss': 0.45759895081944796}
2022-11-28 06:13:02,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:02,241 INFO:     Epoch: 79
2022-11-28 06:13:02,899 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5395214605060491, 'Total loss': 0.5395214605060491} | train loss {'Reaction outcome loss': 0.4588176649712358, 'Total loss': 0.4588176649712358}
2022-11-28 06:13:02,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:02,899 INFO:     Epoch: 80
2022-11-28 06:13:03,558 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5357375795190985, 'Total loss': 0.5357375795190985} | train loss {'Reaction outcome loss': 0.4505503590342208, 'Total loss': 0.4505503590342208}
2022-11-28 06:13:03,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:03,559 INFO:     Epoch: 81
2022-11-28 06:13:04,214 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.503041127527302, 'Total loss': 0.503041127527302} | train loss {'Reaction outcome loss': 0.44697196097518527, 'Total loss': 0.44697196097518527}
2022-11-28 06:13:04,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:04,214 INFO:     Epoch: 82
2022-11-28 06:13:04,870 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.496966315433383, 'Total loss': 0.496966315433383} | train loss {'Reaction outcome loss': 0.4469165752834154, 'Total loss': 0.4469165752834154}
2022-11-28 06:13:04,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:04,871 INFO:     Epoch: 83
2022-11-28 06:13:05,527 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5120879696174101, 'Total loss': 0.5120879696174101} | train loss {'Reaction outcome loss': 0.4493160353377763, 'Total loss': 0.4493160353377763}
2022-11-28 06:13:05,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:05,527 INFO:     Epoch: 84
2022-11-28 06:13:06,185 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5206672085279768, 'Total loss': 0.5206672085279768} | train loss {'Reaction outcome loss': 0.44885744008156453, 'Total loss': 0.44885744008156453}
2022-11-28 06:13:06,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:06,186 INFO:     Epoch: 85
2022-11-28 06:13:06,844 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5461539653214541, 'Total loss': 0.5461539653214541} | train loss {'Reaction outcome loss': 0.44871520772877976, 'Total loss': 0.44871520772877976}
2022-11-28 06:13:06,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:06,844 INFO:     Epoch: 86
2022-11-28 06:13:07,505 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5390014567158439, 'Total loss': 0.5390014567158439} | train loss {'Reaction outcome loss': 0.44721564939476527, 'Total loss': 0.44721564939476527}
2022-11-28 06:13:07,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:07,505 INFO:     Epoch: 87
2022-11-28 06:13:08,164 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5414311289787292, 'Total loss': 0.5414311289787292} | train loss {'Reaction outcome loss': 0.4428086757267776, 'Total loss': 0.4428086757267776}
2022-11-28 06:13:08,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:08,164 INFO:     Epoch: 88
2022-11-28 06:13:08,824 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5566795383664694, 'Total loss': 0.5566795383664694} | train loss {'Reaction outcome loss': 0.45298127142282635, 'Total loss': 0.45298127142282635}
2022-11-28 06:13:08,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:08,825 INFO:     Epoch: 89
2022-11-28 06:13:09,480 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5359441861510277, 'Total loss': 0.5359441861510277} | train loss {'Reaction outcome loss': 0.47066860100035723, 'Total loss': 0.47066860100035723}
2022-11-28 06:13:09,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:09,480 INFO:     Epoch: 90
2022-11-28 06:13:10,142 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4966103820638223, 'Total loss': 0.4966103820638223} | train loss {'Reaction outcome loss': 0.45946557415641753, 'Total loss': 0.45946557415641753}
2022-11-28 06:13:10,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:10,142 INFO:     Epoch: 91
2022-11-28 06:13:10,797 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5082114545459097, 'Total loss': 0.5082114545459097} | train loss {'Reaction outcome loss': 0.4480225194682959, 'Total loss': 0.4480225194682959}
2022-11-28 06:13:10,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:10,797 INFO:     Epoch: 92
2022-11-28 06:13:11,453 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5504583767191931, 'Total loss': 0.5504583767191931} | train loss {'Reaction outcome loss': 0.44868242138099335, 'Total loss': 0.44868242138099335}
2022-11-28 06:13:11,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:11,453 INFO:     Epoch: 93
2022-11-28 06:13:12,110 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5215545035898685, 'Total loss': 0.5215545035898685} | train loss {'Reaction outcome loss': 0.4455923500813936, 'Total loss': 0.4455923500813936}
2022-11-28 06:13:12,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:12,110 INFO:     Epoch: 94
2022-11-28 06:13:12,764 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5116999830034646, 'Total loss': 0.5116999830034646} | train loss {'Reaction outcome loss': 0.447382791985867, 'Total loss': 0.447382791985867}
2022-11-28 06:13:12,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:12,765 INFO:     Epoch: 95
2022-11-28 06:13:13,420 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.525370118631558, 'Total loss': 0.525370118631558} | train loss {'Reaction outcome loss': 0.449583572052751, 'Total loss': 0.449583572052751}
2022-11-28 06:13:13,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:13,420 INFO:     Epoch: 96
2022-11-28 06:13:14,077 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5090061832558025, 'Total loss': 0.5090061832558025} | train loss {'Reaction outcome loss': 0.45982777137264064, 'Total loss': 0.45982777137264064}
2022-11-28 06:13:14,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:14,077 INFO:     Epoch: 97
2022-11-28 06:13:14,736 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5459878011183306, 'Total loss': 0.5459878011183306} | train loss {'Reaction outcome loss': 0.4592687989988549, 'Total loss': 0.4592687989988549}
2022-11-28 06:13:14,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:14,737 INFO:     Epoch: 98
2022-11-28 06:13:15,398 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5200611691583287, 'Total loss': 0.5200611691583287} | train loss {'Reaction outcome loss': 0.45321079188211244, 'Total loss': 0.45321079188211244}
2022-11-28 06:13:15,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:15,398 INFO:     Epoch: 99
2022-11-28 06:13:16,055 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4933769872242754, 'Total loss': 0.4933769872242754} | train loss {'Reaction outcome loss': 0.45078662927696095, 'Total loss': 0.45078662927696095}
2022-11-28 06:13:16,055 INFO:     Best model found after epoch 78 of 100.
2022-11-28 06:13:16,055 INFO:   Done with stage: TRAINING
2022-11-28 06:13:16,055 INFO:   Starting stage: EVALUATION
2022-11-28 06:13:16,174 INFO:   Done with stage: EVALUATION
2022-11-28 06:13:16,183 INFO:   Leaving out SEQ value Fold_0
2022-11-28 06:13:16,195 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 06:13:16,195 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:13:16,835 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:13:16,835 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:13:16,904 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:13:16,905 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:13:16,905 INFO:     No hyperparam tuning for this model
2022-11-28 06:13:16,905 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:13:16,905 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:13:16,906 INFO:     None feature selector for col prot
2022-11-28 06:13:16,906 INFO:     None feature selector for col prot
2022-11-28 06:13:16,906 INFO:     None feature selector for col prot
2022-11-28 06:13:16,907 INFO:     None feature selector for col chem
2022-11-28 06:13:16,907 INFO:     None feature selector for col chem
2022-11-28 06:13:16,907 INFO:     None feature selector for col chem
2022-11-28 06:13:16,907 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:13:16,907 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:13:16,908 INFO:     Number of params in model 169651
2022-11-28 06:13:16,911 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:13:16,911 INFO:   Starting stage: TRAINING
2022-11-28 06:13:16,961 INFO:     Val loss before train {'Reaction outcome loss': 0.9956166952155358, 'Total loss': 0.9956166952155358}
2022-11-28 06:13:16,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:16,961 INFO:     Epoch: 0
2022-11-28 06:13:17,606 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6036218664673871, 'Total loss': 0.6036218664673871} | train loss {'Reaction outcome loss': 0.6725273877382278, 'Total loss': 0.6725273877382278}
2022-11-28 06:13:17,606 INFO:     Found new best model at epoch 0
2022-11-28 06:13:17,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:17,607 INFO:     Epoch: 1
2022-11-28 06:13:18,253 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5718443792226703, 'Total loss': 0.5718443792226703} | train loss {'Reaction outcome loss': 0.562167191762983, 'Total loss': 0.562167191762983}
2022-11-28 06:13:18,253 INFO:     Found new best model at epoch 1
2022-11-28 06:13:18,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:18,254 INFO:     Epoch: 2
2022-11-28 06:13:18,903 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5624395303947981, 'Total loss': 0.5624395303947981} | train loss {'Reaction outcome loss': 0.5504559225138322, 'Total loss': 0.5504559225138322}
2022-11-28 06:13:18,903 INFO:     Found new best model at epoch 2
2022-11-28 06:13:18,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:18,904 INFO:     Epoch: 3
2022-11-28 06:13:19,551 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5415155842553737, 'Total loss': 0.5415155842553737} | train loss {'Reaction outcome loss': 0.534221481516528, 'Total loss': 0.534221481516528}
2022-11-28 06:13:19,551 INFO:     Found new best model at epoch 3
2022-11-28 06:13:19,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:19,552 INFO:     Epoch: 4
2022-11-28 06:13:20,202 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5481689738672834, 'Total loss': 0.5481689738672834} | train loss {'Reaction outcome loss': 0.5104192102887503, 'Total loss': 0.5104192102887503}
2022-11-28 06:13:20,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:20,202 INFO:     Epoch: 5
2022-11-28 06:13:20,847 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5227719011694886, 'Total loss': 0.5227719011694886} | train loss {'Reaction outcome loss': 0.5033502148870578, 'Total loss': 0.5033502148870578}
2022-11-28 06:13:20,847 INFO:     Found new best model at epoch 5
2022-11-28 06:13:20,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:20,848 INFO:     Epoch: 6
2022-11-28 06:13:21,496 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5410955347294031, 'Total loss': 0.5410955347294031} | train loss {'Reaction outcome loss': 0.4973090222343005, 'Total loss': 0.4973090222343005}
2022-11-28 06:13:21,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:21,496 INFO:     Epoch: 7
2022-11-28 06:13:22,143 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5514985565529313, 'Total loss': 0.5514985565529313} | train loss {'Reaction outcome loss': 0.48556208368314147, 'Total loss': 0.48556208368314147}
2022-11-28 06:13:22,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:22,143 INFO:     Epoch: 8
2022-11-28 06:13:22,791 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5262075406174327, 'Total loss': 0.5262075406174327} | train loss {'Reaction outcome loss': 0.48447929893010927, 'Total loss': 0.48447929893010927}
2022-11-28 06:13:22,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:22,791 INFO:     Epoch: 9
2022-11-28 06:13:23,439 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5073860564897227, 'Total loss': 0.5073860564897227} | train loss {'Reaction outcome loss': 0.4783800913963789, 'Total loss': 0.4783800913963789}
2022-11-28 06:13:23,439 INFO:     Found new best model at epoch 9
2022-11-28 06:13:23,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:23,440 INFO:     Epoch: 10
2022-11-28 06:13:24,086 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48586482572001083, 'Total loss': 0.48586482572001083} | train loss {'Reaction outcome loss': 0.4815408714391567, 'Total loss': 0.4815408714391567}
2022-11-28 06:13:24,087 INFO:     Found new best model at epoch 10
2022-11-28 06:13:24,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:24,087 INFO:     Epoch: 11
2022-11-28 06:13:24,733 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4861027210257774, 'Total loss': 0.4861027210257774} | train loss {'Reaction outcome loss': 0.47782249718045994, 'Total loss': 0.47782249718045994}
2022-11-28 06:13:24,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:24,734 INFO:     Epoch: 12
2022-11-28 06:13:25,383 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49919062852859497, 'Total loss': 0.49919062852859497} | train loss {'Reaction outcome loss': 0.46964786002420106, 'Total loss': 0.46964786002420106}
2022-11-28 06:13:25,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:25,384 INFO:     Epoch: 13
2022-11-28 06:13:26,032 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49818871256917024, 'Total loss': 0.49818871256917024} | train loss {'Reaction outcome loss': 0.4651519191056613, 'Total loss': 0.4651519191056613}
2022-11-28 06:13:26,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:26,032 INFO:     Epoch: 14
2022-11-28 06:13:26,679 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4843439560296924, 'Total loss': 0.4843439560296924} | train loss {'Reaction outcome loss': 0.4707934454757981, 'Total loss': 0.4707934454757981}
2022-11-28 06:13:26,679 INFO:     Found new best model at epoch 14
2022-11-28 06:13:26,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:26,680 INFO:     Epoch: 15
2022-11-28 06:13:27,331 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5688272707684096, 'Total loss': 0.5688272707684096} | train loss {'Reaction outcome loss': 0.4637635289212313, 'Total loss': 0.4637635289212313}
2022-11-28 06:13:27,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:27,331 INFO:     Epoch: 16
2022-11-28 06:13:27,981 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47577120536981626, 'Total loss': 0.47577120536981626} | train loss {'Reaction outcome loss': 0.4726210527214003, 'Total loss': 0.4726210527214003}
2022-11-28 06:13:27,981 INFO:     Found new best model at epoch 16
2022-11-28 06:13:27,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:27,982 INFO:     Epoch: 17
2022-11-28 06:13:28,630 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5035252508729003, 'Total loss': 0.5035252508729003} | train loss {'Reaction outcome loss': 0.47118837134950936, 'Total loss': 0.47118837134950936}
2022-11-28 06:13:28,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:28,630 INFO:     Epoch: 18
2022-11-28 06:13:29,279 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49557689005552336, 'Total loss': 0.49557689005552336} | train loss {'Reaction outcome loss': 0.45672023652021776, 'Total loss': 0.45672023652021776}
2022-11-28 06:13:29,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:29,281 INFO:     Epoch: 19
2022-11-28 06:13:29,927 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5316907569419506, 'Total loss': 0.5316907569419506} | train loss {'Reaction outcome loss': 0.4645549684395025, 'Total loss': 0.4645549684395025}
2022-11-28 06:13:29,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:29,928 INFO:     Epoch: 20
2022-11-28 06:13:30,576 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48840007393859153, 'Total loss': 0.48840007393859153} | train loss {'Reaction outcome loss': 0.46746558018427325, 'Total loss': 0.46746558018427325}
2022-11-28 06:13:30,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:30,576 INFO:     Epoch: 21
2022-11-28 06:13:31,228 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49674617204555244, 'Total loss': 0.49674617204555244} | train loss {'Reaction outcome loss': 0.46044466193811395, 'Total loss': 0.46044466193811395}
2022-11-28 06:13:31,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:31,228 INFO:     Epoch: 22
2022-11-28 06:13:31,881 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48194092720053916, 'Total loss': 0.48194092720053916} | train loss {'Reaction outcome loss': 0.46424462851673487, 'Total loss': 0.46424462851673487}
2022-11-28 06:13:31,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:31,881 INFO:     Epoch: 23
2022-11-28 06:13:32,530 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5136969838031503, 'Total loss': 0.5136969838031503} | train loss {'Reaction outcome loss': 0.46288962689814744, 'Total loss': 0.46288962689814744}
2022-11-28 06:13:32,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:32,530 INFO:     Epoch: 24
2022-11-28 06:13:33,178 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4904958737450977, 'Total loss': 0.4904958737450977} | train loss {'Reaction outcome loss': 0.4595869978882158, 'Total loss': 0.4595869978882158}
2022-11-28 06:13:33,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:33,178 INFO:     Epoch: 25
2022-11-28 06:13:33,827 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.488031629213067, 'Total loss': 0.488031629213067} | train loss {'Reaction outcome loss': 0.46457690638279225, 'Total loss': 0.46457690638279225}
2022-11-28 06:13:33,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:33,827 INFO:     Epoch: 26
2022-11-28 06:13:34,479 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4881425354369851, 'Total loss': 0.4881425354369851} | train loss {'Reaction outcome loss': 0.4641559856173433, 'Total loss': 0.4641559856173433}
2022-11-28 06:13:34,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:34,480 INFO:     Epoch: 27
2022-11-28 06:13:35,126 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4833304556303246, 'Total loss': 0.4833304556303246} | train loss {'Reaction outcome loss': 0.4589114164619289, 'Total loss': 0.4589114164619289}
2022-11-28 06:13:35,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:35,127 INFO:     Epoch: 28
2022-11-28 06:13:35,775 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47684347560239393, 'Total loss': 0.47684347560239393} | train loss {'Reaction outcome loss': 0.46389880764141006, 'Total loss': 0.46389880764141006}
2022-11-28 06:13:35,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:35,776 INFO:     Epoch: 29
2022-11-28 06:13:36,426 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5263699844133022, 'Total loss': 0.5263699844133022} | train loss {'Reaction outcome loss': 0.4596206033180771, 'Total loss': 0.4596206033180771}
2022-11-28 06:13:36,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:36,426 INFO:     Epoch: 30
2022-11-28 06:13:37,075 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5064609724768373, 'Total loss': 0.5064609724768373} | train loss {'Reaction outcome loss': 0.45789012499920134, 'Total loss': 0.45789012499920134}
2022-11-28 06:13:37,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:37,075 INFO:     Epoch: 31
2022-11-28 06:13:37,724 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5366275352100993, 'Total loss': 0.5366275352100993} | train loss {'Reaction outcome loss': 0.4674566932666449, 'Total loss': 0.4674566932666449}
2022-11-28 06:13:37,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:37,724 INFO:     Epoch: 32
2022-11-28 06:13:38,372 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48835266849329306, 'Total loss': 0.48835266849329306} | train loss {'Reaction outcome loss': 0.4630125640228452, 'Total loss': 0.4630125640228452}
2022-11-28 06:13:38,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:38,372 INFO:     Epoch: 33
2022-11-28 06:13:39,021 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47870455405046775, 'Total loss': 0.47870455405046775} | train loss {'Reaction outcome loss': 0.4558721552047219, 'Total loss': 0.4558721552047219}
2022-11-28 06:13:39,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:39,021 INFO:     Epoch: 34
2022-11-28 06:13:39,671 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5028574581063071, 'Total loss': 0.5028574581063071} | train loss {'Reaction outcome loss': 0.46041021321290804, 'Total loss': 0.46041021321290804}
2022-11-28 06:13:39,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:39,672 INFO:     Epoch: 35
2022-11-28 06:13:40,320 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4904175497764765, 'Total loss': 0.4904175497764765} | train loss {'Reaction outcome loss': 0.4613929203876252, 'Total loss': 0.4613929203876252}
2022-11-28 06:13:40,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:40,320 INFO:     Epoch: 36
2022-11-28 06:13:40,968 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5270576775074005, 'Total loss': 0.5270576775074005} | train loss {'Reaction outcome loss': 0.45658568461490756, 'Total loss': 0.45658568461490756}
2022-11-28 06:13:40,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:40,968 INFO:     Epoch: 37
2022-11-28 06:13:41,615 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4996305447678233, 'Total loss': 0.4996305447678233} | train loss {'Reaction outcome loss': 0.45597016700991877, 'Total loss': 0.45597016700991877}
2022-11-28 06:13:41,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:41,615 INFO:     Epoch: 38
2022-11-28 06:13:42,264 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4972966043061988, 'Total loss': 0.4972966043061988} | train loss {'Reaction outcome loss': 0.4650715000835466, 'Total loss': 0.4650715000835466}
2022-11-28 06:13:42,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:42,264 INFO:     Epoch: 39
2022-11-28 06:13:42,912 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49734610665676204, 'Total loss': 0.49734610665676204} | train loss {'Reaction outcome loss': 0.4600231757870427, 'Total loss': 0.4600231757870427}
2022-11-28 06:13:42,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:42,912 INFO:     Epoch: 40
2022-11-28 06:13:43,562 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4859046520188797, 'Total loss': 0.4859046520188797} | train loss {'Reaction outcome loss': 0.4606233193795867, 'Total loss': 0.4606233193795867}
2022-11-28 06:13:43,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:43,562 INFO:     Epoch: 41
2022-11-28 06:13:44,216 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.478353304225345, 'Total loss': 0.478353304225345} | train loss {'Reaction outcome loss': 0.46287258049097574, 'Total loss': 0.46287258049097574}
2022-11-28 06:13:44,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:44,216 INFO:     Epoch: 42
2022-11-28 06:13:44,868 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49026602957137794, 'Total loss': 0.49026602957137794} | train loss {'Reaction outcome loss': 0.4533251376799595, 'Total loss': 0.4533251376799595}
2022-11-28 06:13:44,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:44,868 INFO:     Epoch: 43
2022-11-28 06:13:45,521 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4637902198835861, 'Total loss': 0.4637902198835861} | train loss {'Reaction outcome loss': 0.4537827945295185, 'Total loss': 0.4537827945295185}
2022-11-28 06:13:45,521 INFO:     Found new best model at epoch 43
2022-11-28 06:13:45,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:45,522 INFO:     Epoch: 44
2022-11-28 06:13:46,174 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4630703617667043, 'Total loss': 0.4630703617667043} | train loss {'Reaction outcome loss': 0.4593805255590643, 'Total loss': 0.4593805255590643}
2022-11-28 06:13:46,174 INFO:     Found new best model at epoch 44
2022-11-28 06:13:46,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:46,175 INFO:     Epoch: 45
2022-11-28 06:13:46,825 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4872075201467026, 'Total loss': 0.4872075201467026} | train loss {'Reaction outcome loss': 0.45409815571435685, 'Total loss': 0.45409815571435685}
2022-11-28 06:13:46,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:46,826 INFO:     Epoch: 46
2022-11-28 06:13:47,473 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.503124094633169, 'Total loss': 0.503124094633169} | train loss {'Reaction outcome loss': 0.46158852167580844, 'Total loss': 0.46158852167580844}
2022-11-28 06:13:47,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:47,473 INFO:     Epoch: 47
2022-11-28 06:13:48,123 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48021916109462115, 'Total loss': 0.48021916109462115} | train loss {'Reaction outcome loss': 0.4575560768077403, 'Total loss': 0.4575560768077403}
2022-11-28 06:13:48,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:48,124 INFO:     Epoch: 48
2022-11-28 06:13:48,773 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4707234020149985, 'Total loss': 0.4707234020149985} | train loss {'Reaction outcome loss': 0.45502894399342714, 'Total loss': 0.45502894399342714}
2022-11-28 06:13:48,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:48,773 INFO:     Epoch: 49
2022-11-28 06:13:49,423 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47822755367256875, 'Total loss': 0.47822755367256875} | train loss {'Reaction outcome loss': 0.4599036080724418, 'Total loss': 0.4599036080724418}
2022-11-28 06:13:49,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:49,423 INFO:     Epoch: 50
2022-11-28 06:13:50,074 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47582260155400563, 'Total loss': 0.47582260155400563} | train loss {'Reaction outcome loss': 0.4572304394019484, 'Total loss': 0.4572304394019484}
2022-11-28 06:13:50,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:50,075 INFO:     Epoch: 51
2022-11-28 06:13:50,728 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4791667617337648, 'Total loss': 0.4791667617337648} | train loss {'Reaction outcome loss': 0.46163250751210827, 'Total loss': 0.46163250751210827}
2022-11-28 06:13:50,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:50,728 INFO:     Epoch: 52
2022-11-28 06:13:51,378 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47461129655671674, 'Total loss': 0.47461129655671674} | train loss {'Reaction outcome loss': 0.4607805501776958, 'Total loss': 0.4607805501776958}
2022-11-28 06:13:51,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:51,378 INFO:     Epoch: 53
2022-11-28 06:13:52,026 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.509024822088175, 'Total loss': 0.509024822088175} | train loss {'Reaction outcome loss': 0.4653479419495343, 'Total loss': 0.4653479419495343}
2022-11-28 06:13:52,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:52,026 INFO:     Epoch: 54
2022-11-28 06:13:52,678 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5033385732839274, 'Total loss': 0.5033385732839274} | train loss {'Reaction outcome loss': 0.45819382639333545, 'Total loss': 0.45819382639333545}
2022-11-28 06:13:52,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:52,678 INFO:     Epoch: 55
2022-11-28 06:13:53,327 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4676378275765929, 'Total loss': 0.4676378275765929} | train loss {'Reaction outcome loss': 0.45902840124726785, 'Total loss': 0.45902840124726785}
2022-11-28 06:13:53,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:53,327 INFO:     Epoch: 56
2022-11-28 06:13:53,974 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48998783702074095, 'Total loss': 0.48998783702074095} | train loss {'Reaction outcome loss': 0.4615138191499828, 'Total loss': 0.4615138191499828}
2022-11-28 06:13:53,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:53,974 INFO:     Epoch: 57
2022-11-28 06:13:54,621 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48724917755570524, 'Total loss': 0.48724917755570524} | train loss {'Reaction outcome loss': 0.453885593041471, 'Total loss': 0.453885593041471}
2022-11-28 06:13:54,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:54,622 INFO:     Epoch: 58
2022-11-28 06:13:55,269 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48534278952798177, 'Total loss': 0.48534278952798177} | train loss {'Reaction outcome loss': 0.4599972988168399, 'Total loss': 0.4599972988168399}
2022-11-28 06:13:55,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:55,269 INFO:     Epoch: 59
2022-11-28 06:13:55,923 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47100246714991195, 'Total loss': 0.47100246714991195} | train loss {'Reaction outcome loss': 0.46007754577040183, 'Total loss': 0.46007754577040183}
2022-11-28 06:13:55,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:55,924 INFO:     Epoch: 60
2022-11-28 06:13:56,577 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4980359320030656, 'Total loss': 0.4980359320030656} | train loss {'Reaction outcome loss': 0.457342377905983, 'Total loss': 0.457342377905983}
2022-11-28 06:13:56,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:56,578 INFO:     Epoch: 61
2022-11-28 06:13:57,230 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.495907302512679, 'Total loss': 0.495907302512679} | train loss {'Reaction outcome loss': 0.4561460571892468, 'Total loss': 0.4561460571892468}
2022-11-28 06:13:57,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:57,230 INFO:     Epoch: 62
2022-11-28 06:13:57,879 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46465174715186275, 'Total loss': 0.46465174715186275} | train loss {'Reaction outcome loss': 0.45244610277406966, 'Total loss': 0.45244610277406966}
2022-11-28 06:13:57,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:57,880 INFO:     Epoch: 63
2022-11-28 06:13:58,530 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4807568161293518, 'Total loss': 0.4807568161293518} | train loss {'Reaction outcome loss': 0.4563769308137305, 'Total loss': 0.4563769308137305}
2022-11-28 06:13:58,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:58,530 INFO:     Epoch: 64
2022-11-28 06:13:59,182 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48587509677853696, 'Total loss': 0.48587509677853696} | train loss {'Reaction outcome loss': 0.4617094250986115, 'Total loss': 0.4617094250986115}
2022-11-28 06:13:59,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:59,182 INFO:     Epoch: 65
2022-11-28 06:13:59,834 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49944032035594765, 'Total loss': 0.49944032035594765} | train loss {'Reaction outcome loss': 0.4579474442473655, 'Total loss': 0.4579474442473655}
2022-11-28 06:13:59,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:13:59,835 INFO:     Epoch: 66
2022-11-28 06:14:00,485 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5141781225453975, 'Total loss': 0.5141781225453975} | train loss {'Reaction outcome loss': 0.4619072953492035, 'Total loss': 0.4619072953492035}
2022-11-28 06:14:00,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:00,485 INFO:     Epoch: 67
2022-11-28 06:14:01,135 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4886528461478477, 'Total loss': 0.4886528461478477} | train loss {'Reaction outcome loss': 0.4628252812005855, 'Total loss': 0.4628252812005855}
2022-11-28 06:14:01,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:01,135 INFO:     Epoch: 68
2022-11-28 06:14:01,784 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4816305658151937, 'Total loss': 0.4816305658151937} | train loss {'Reaction outcome loss': 0.4594705831182837, 'Total loss': 0.4594705831182837}
2022-11-28 06:14:01,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:01,785 INFO:     Epoch: 69
2022-11-28 06:14:02,435 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4626528787058453, 'Total loss': 0.4626528787058453} | train loss {'Reaction outcome loss': 0.4639356647131374, 'Total loss': 0.4639356647131374}
2022-11-28 06:14:02,435 INFO:     Found new best model at epoch 69
2022-11-28 06:14:02,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:02,436 INFO:     Epoch: 70
2022-11-28 06:14:03,085 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4918666197810062, 'Total loss': 0.4918666197810062} | train loss {'Reaction outcome loss': 0.45910568817407504, 'Total loss': 0.45910568817407504}
2022-11-28 06:14:03,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:03,085 INFO:     Epoch: 71
2022-11-28 06:14:03,733 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5008158458526745, 'Total loss': 0.5008158458526745} | train loss {'Reaction outcome loss': 0.46301088239920973, 'Total loss': 0.46301088239920973}
2022-11-28 06:14:03,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:03,733 INFO:     Epoch: 72
2022-11-28 06:14:04,384 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4756432861782784, 'Total loss': 0.4756432861782784} | train loss {'Reaction outcome loss': 0.45513904806027194, 'Total loss': 0.45513904806027194}
2022-11-28 06:14:04,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:04,384 INFO:     Epoch: 73
2022-11-28 06:14:05,035 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4995386655940566, 'Total loss': 0.4995386655940566} | train loss {'Reaction outcome loss': 0.46309293769759896, 'Total loss': 0.46309293769759896}
2022-11-28 06:14:05,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:05,036 INFO:     Epoch: 74
2022-11-28 06:14:05,686 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5322027643059575, 'Total loss': 0.5322027643059575} | train loss {'Reaction outcome loss': 0.46605867116784855, 'Total loss': 0.46605867116784855}
2022-11-28 06:14:05,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:05,687 INFO:     Epoch: 75
2022-11-28 06:14:06,336 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49964578345764515, 'Total loss': 0.49964578345764515} | train loss {'Reaction outcome loss': 0.4627150957599098, 'Total loss': 0.4627150957599098}
2022-11-28 06:14:06,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:06,337 INFO:     Epoch: 76
2022-11-28 06:14:06,988 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47257279310115546, 'Total loss': 0.47257279310115546} | train loss {'Reaction outcome loss': 0.4567851278884911, 'Total loss': 0.4567851278884911}
2022-11-28 06:14:06,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:06,988 INFO:     Epoch: 77
2022-11-28 06:14:07,641 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4829249357761339, 'Total loss': 0.4829249357761339} | train loss {'Reaction outcome loss': 0.45405557193628554, 'Total loss': 0.45405557193628554}
2022-11-28 06:14:07,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:07,642 INFO:     Epoch: 78
2022-11-28 06:14:08,295 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46781960025776265, 'Total loss': 0.46781960025776265} | train loss {'Reaction outcome loss': 0.4583127098196328, 'Total loss': 0.4583127098196328}
2022-11-28 06:14:08,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:08,295 INFO:     Epoch: 79
2022-11-28 06:14:08,945 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48984562622946365, 'Total loss': 0.48984562622946365} | train loss {'Reaction outcome loss': 0.45488243853604354, 'Total loss': 0.45488243853604354}
2022-11-28 06:14:08,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:08,945 INFO:     Epoch: 80
2022-11-28 06:14:09,596 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5361696495566257, 'Total loss': 0.5361696495566257} | train loss {'Reaction outcome loss': 0.4573139163201729, 'Total loss': 0.4573139163201729}
2022-11-28 06:14:09,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:09,596 INFO:     Epoch: 81
2022-11-28 06:14:10,249 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4988594266564347, 'Total loss': 0.4988594266564347} | train loss {'Reaction outcome loss': 0.4594654625457991, 'Total loss': 0.4594654625457991}
2022-11-28 06:14:10,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:10,250 INFO:     Epoch: 82
2022-11-28 06:14:10,903 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5293601051319478, 'Total loss': 0.5293601051319478} | train loss {'Reaction outcome loss': 0.45319255254396196, 'Total loss': 0.45319255254396196}
2022-11-28 06:14:10,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:10,903 INFO:     Epoch: 83
2022-11-28 06:14:11,561 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4805243084597033, 'Total loss': 0.4805243084597033} | train loss {'Reaction outcome loss': 0.467341469945731, 'Total loss': 0.467341469945731}
2022-11-28 06:14:11,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:11,561 INFO:     Epoch: 84
2022-11-28 06:14:12,217 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4755736440420151, 'Total loss': 0.4755736440420151} | train loss {'Reaction outcome loss': 0.4577132045854757, 'Total loss': 0.4577132045854757}
2022-11-28 06:14:12,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:12,218 INFO:     Epoch: 85
2022-11-28 06:14:12,871 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5027028311823689, 'Total loss': 0.5027028311823689} | train loss {'Reaction outcome loss': 0.4521359443403934, 'Total loss': 0.4521359443403934}
2022-11-28 06:14:12,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:12,871 INFO:     Epoch: 86
2022-11-28 06:14:13,527 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.494559342084929, 'Total loss': 0.494559342084929} | train loss {'Reaction outcome loss': 0.4603031513131695, 'Total loss': 0.4603031513131695}
2022-11-28 06:14:13,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:13,527 INFO:     Epoch: 87
2022-11-28 06:14:14,184 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5081495836723683, 'Total loss': 0.5081495836723683} | train loss {'Reaction outcome loss': 0.45718752301524207, 'Total loss': 0.45718752301524207}
2022-11-28 06:14:14,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:14,184 INFO:     Epoch: 88
2022-11-28 06:14:14,840 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4752298420251802, 'Total loss': 0.4752298420251802} | train loss {'Reaction outcome loss': 0.46546859481207137, 'Total loss': 0.46546859481207137}
2022-11-28 06:14:14,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:14,840 INFO:     Epoch: 89
2022-11-28 06:14:15,494 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4903256570877031, 'Total loss': 0.4903256570877031} | train loss {'Reaction outcome loss': 0.4595556506281527, 'Total loss': 0.4595556506281527}
2022-11-28 06:14:15,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:15,494 INFO:     Epoch: 90
2022-11-28 06:14:16,147 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48257244187732073, 'Total loss': 0.48257244187732073} | train loss {'Reaction outcome loss': 0.45992894029175796, 'Total loss': 0.45992894029175796}
2022-11-28 06:14:16,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:16,147 INFO:     Epoch: 91
2022-11-28 06:14:16,797 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4982376105563585, 'Total loss': 0.4982376105563585} | train loss {'Reaction outcome loss': 0.46313630835509595, 'Total loss': 0.46313630835509595}
2022-11-28 06:14:16,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:16,797 INFO:     Epoch: 92
2022-11-28 06:14:17,449 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4732110860735871, 'Total loss': 0.4732110860735871} | train loss {'Reaction outcome loss': 0.45258345182049914, 'Total loss': 0.45258345182049914}
2022-11-28 06:14:17,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:17,449 INFO:     Epoch: 93
2022-11-28 06:14:18,100 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4670853649460992, 'Total loss': 0.4670853649460992} | train loss {'Reaction outcome loss': 0.458119727211234, 'Total loss': 0.458119727211234}
2022-11-28 06:14:18,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:18,100 INFO:     Epoch: 94
2022-11-28 06:14:18,753 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5483730989833211, 'Total loss': 0.5483730989833211} | train loss {'Reaction outcome loss': 0.4517580246851768, 'Total loss': 0.4517580246851768}
2022-11-28 06:14:18,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:18,754 INFO:     Epoch: 95
2022-11-28 06:14:19,407 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45883503972097883, 'Total loss': 0.45883503972097883} | train loss {'Reaction outcome loss': 0.4556688134071758, 'Total loss': 0.4556688134071758}
2022-11-28 06:14:19,407 INFO:     Found new best model at epoch 95
2022-11-28 06:14:19,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:19,408 INFO:     Epoch: 96
2022-11-28 06:14:20,060 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48432541309401045, 'Total loss': 0.48432541309401045} | train loss {'Reaction outcome loss': 0.4550935082106924, 'Total loss': 0.4550935082106924}
2022-11-28 06:14:20,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:20,060 INFO:     Epoch: 97
2022-11-28 06:14:20,711 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5138955209837404, 'Total loss': 0.5138955209837404} | train loss {'Reaction outcome loss': 0.4533351833928269, 'Total loss': 0.4533351833928269}
2022-11-28 06:14:20,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:20,711 INFO:     Epoch: 98
2022-11-28 06:14:21,359 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47981792965600656, 'Total loss': 0.47981792965600656} | train loss {'Reaction outcome loss': 0.4625069346938114, 'Total loss': 0.4625069346938114}
2022-11-28 06:14:21,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:21,359 INFO:     Epoch: 99
2022-11-28 06:14:22,008 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47394539866336555, 'Total loss': 0.47394539866336555} | train loss {'Reaction outcome loss': 0.4573642842686225, 'Total loss': 0.4573642842686225}
2022-11-28 06:14:22,008 INFO:     Best model found after epoch 96 of 100.
2022-11-28 06:14:22,008 INFO:   Done with stage: TRAINING
2022-11-28 06:14:22,008 INFO:   Starting stage: EVALUATION
2022-11-28 06:14:22,143 INFO:   Done with stage: EVALUATION
2022-11-28 06:14:22,143 INFO:   Leaving out SEQ value Fold_1
2022-11-28 06:14:22,156 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 06:14:22,156 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:14:22,799 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:14:22,799 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:14:22,869 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:14:22,869 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:14:22,869 INFO:     No hyperparam tuning for this model
2022-11-28 06:14:22,869 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:14:22,869 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:14:22,870 INFO:     None feature selector for col prot
2022-11-28 06:14:22,870 INFO:     None feature selector for col prot
2022-11-28 06:14:22,870 INFO:     None feature selector for col prot
2022-11-28 06:14:22,871 INFO:     None feature selector for col chem
2022-11-28 06:14:22,871 INFO:     None feature selector for col chem
2022-11-28 06:14:22,871 INFO:     None feature selector for col chem
2022-11-28 06:14:22,871 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:14:22,871 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:14:22,873 INFO:     Number of params in model 169651
2022-11-28 06:14:22,876 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:14:22,876 INFO:   Starting stage: TRAINING
2022-11-28 06:14:22,927 INFO:     Val loss before train {'Reaction outcome loss': 1.0609430562366138, 'Total loss': 1.0609430562366138}
2022-11-28 06:14:22,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:22,927 INFO:     Epoch: 0
2022-11-28 06:14:23,584 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.619628182189031, 'Total loss': 0.619628182189031} | train loss {'Reaction outcome loss': 0.6996864158280042, 'Total loss': 0.6996864158280042}
2022-11-28 06:14:23,584 INFO:     Found new best model at epoch 0
2022-11-28 06:14:23,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:23,585 INFO:     Epoch: 1
2022-11-28 06:14:24,241 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5466380894861438, 'Total loss': 0.5466380894861438} | train loss {'Reaction outcome loss': 0.5991611613911025, 'Total loss': 0.5991611613911025}
2022-11-28 06:14:24,241 INFO:     Found new best model at epoch 1
2022-11-28 06:14:24,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:24,242 INFO:     Epoch: 2
2022-11-28 06:14:24,895 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5150200926106084, 'Total loss': 0.5150200926106084} | train loss {'Reaction outcome loss': 0.5716743563510933, 'Total loss': 0.5716743563510933}
2022-11-28 06:14:24,895 INFO:     Found new best model at epoch 2
2022-11-28 06:14:24,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:24,896 INFO:     Epoch: 3
2022-11-28 06:14:25,552 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5445013303648342, 'Total loss': 0.5445013303648342} | train loss {'Reaction outcome loss': 0.5436589954458937, 'Total loss': 0.5436589954458937}
2022-11-28 06:14:25,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:25,552 INFO:     Epoch: 4
2022-11-28 06:14:26,210 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5469625118103895, 'Total loss': 0.5469625118103895} | train loss {'Reaction outcome loss': 0.5274349064243083, 'Total loss': 0.5274349064243083}
2022-11-28 06:14:26,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:26,210 INFO:     Epoch: 5
2022-11-28 06:14:26,869 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5524300628087737, 'Total loss': 0.5524300628087737} | train loss {'Reaction outcome loss': 0.5189654596606079, 'Total loss': 0.5189654596606079}
2022-11-28 06:14:26,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:26,869 INFO:     Epoch: 6
2022-11-28 06:14:27,531 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5116377411918207, 'Total loss': 0.5116377411918207} | train loss {'Reaction outcome loss': 0.5164248249360494, 'Total loss': 0.5164248249360494}
2022-11-28 06:14:27,531 INFO:     Found new best model at epoch 6
2022-11-28 06:14:27,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:27,532 INFO:     Epoch: 7
2022-11-28 06:14:28,191 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48395394906401634, 'Total loss': 0.48395394906401634} | train loss {'Reaction outcome loss': 0.509565637063007, 'Total loss': 0.509565637063007}
2022-11-28 06:14:28,191 INFO:     Found new best model at epoch 7
2022-11-28 06:14:28,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:28,192 INFO:     Epoch: 8
2022-11-28 06:14:28,851 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49901154840534384, 'Total loss': 0.49901154840534384} | train loss {'Reaction outcome loss': 0.4976728079878554, 'Total loss': 0.4976728079878554}
2022-11-28 06:14:28,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:28,851 INFO:     Epoch: 9
2022-11-28 06:14:29,508 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4815257449041713, 'Total loss': 0.4815257449041713} | train loss {'Reaction outcome loss': 0.49647819092687295, 'Total loss': 0.49647819092687295}
2022-11-28 06:14:29,508 INFO:     Found new best model at epoch 9
2022-11-28 06:14:29,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:29,509 INFO:     Epoch: 10
2022-11-28 06:14:30,165 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48135862804271956, 'Total loss': 0.48135862804271956} | train loss {'Reaction outcome loss': 0.4892605253628322, 'Total loss': 0.4892605253628322}
2022-11-28 06:14:30,166 INFO:     Found new best model at epoch 10
2022-11-28 06:14:30,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:30,166 INFO:     Epoch: 11
2022-11-28 06:14:30,826 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4736581216142936, 'Total loss': 0.4736581216142936} | train loss {'Reaction outcome loss': 0.4896442186771607, 'Total loss': 0.4896442186771607}
2022-11-28 06:14:30,826 INFO:     Found new best model at epoch 11
2022-11-28 06:14:30,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:30,827 INFO:     Epoch: 12
2022-11-28 06:14:31,485 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48787110806866124, 'Total loss': 0.48787110806866124} | train loss {'Reaction outcome loss': 0.48556604865862396, 'Total loss': 0.48556604865862396}
2022-11-28 06:14:31,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:31,486 INFO:     Epoch: 13
2022-11-28 06:14:32,142 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4725907720964063, 'Total loss': 0.4725907720964063} | train loss {'Reaction outcome loss': 0.4879206253557789, 'Total loss': 0.4879206253557789}
2022-11-28 06:14:32,142 INFO:     Found new best model at epoch 13
2022-11-28 06:14:32,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:32,143 INFO:     Epoch: 14
2022-11-28 06:14:32,795 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49635650556195865, 'Total loss': 0.49635650556195865} | train loss {'Reaction outcome loss': 0.488573303210492, 'Total loss': 0.488573303210492}
2022-11-28 06:14:32,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:32,795 INFO:     Epoch: 15
2022-11-28 06:14:33,448 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4954327189109542, 'Total loss': 0.4954327189109542} | train loss {'Reaction outcome loss': 0.4852518419221956, 'Total loss': 0.4852518419221956}
2022-11-28 06:14:33,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:33,448 INFO:     Epoch: 16
2022-11-28 06:14:34,104 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4337062341245738, 'Total loss': 0.4337062341245738} | train loss {'Reaction outcome loss': 0.4787546021597726, 'Total loss': 0.4787546021597726}
2022-11-28 06:14:34,105 INFO:     Found new best model at epoch 16
2022-11-28 06:14:34,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:34,105 INFO:     Epoch: 17
2022-11-28 06:14:34,761 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5065087107094851, 'Total loss': 0.5065087107094851} | train loss {'Reaction outcome loss': 0.47542817096929163, 'Total loss': 0.47542817096929163}
2022-11-28 06:14:34,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:34,762 INFO:     Epoch: 18
2022-11-28 06:14:35,418 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48329006880521774, 'Total loss': 0.48329006880521774} | train loss {'Reaction outcome loss': 0.4861008756014766, 'Total loss': 0.4861008756014766}
2022-11-28 06:14:35,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:35,418 INFO:     Epoch: 19
2022-11-28 06:14:36,073 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45401445437561383, 'Total loss': 0.45401445437561383} | train loss {'Reaction outcome loss': 0.46688917309654004, 'Total loss': 0.46688917309654004}
2022-11-28 06:14:36,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:36,074 INFO:     Epoch: 20
2022-11-28 06:14:36,729 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45554569736123085, 'Total loss': 0.45554569736123085} | train loss {'Reaction outcome loss': 0.4764142801871105, 'Total loss': 0.4764142801871105}
2022-11-28 06:14:36,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:36,730 INFO:     Epoch: 21
2022-11-28 06:14:37,383 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49836519157344644, 'Total loss': 0.49836519157344644} | train loss {'Reaction outcome loss': 0.47196945280444863, 'Total loss': 0.47196945280444863}
2022-11-28 06:14:37,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:37,383 INFO:     Epoch: 22
2022-11-28 06:14:38,035 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4516552304002372, 'Total loss': 0.4516552304002372} | train loss {'Reaction outcome loss': 0.47794031604212156, 'Total loss': 0.47794031604212156}
2022-11-28 06:14:38,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:38,036 INFO:     Epoch: 23
2022-11-28 06:14:38,692 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4813635477965528, 'Total loss': 0.4813635477965528} | train loss {'Reaction outcome loss': 0.4758847749354888, 'Total loss': 0.4758847749354888}
2022-11-28 06:14:38,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:38,692 INFO:     Epoch: 24
2022-11-28 06:14:39,344 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.473630698567087, 'Total loss': 0.473630698567087} | train loss {'Reaction outcome loss': 0.4743830872433526, 'Total loss': 0.4743830872433526}
2022-11-28 06:14:39,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:39,345 INFO:     Epoch: 25
2022-11-28 06:14:40,001 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5040443502366543, 'Total loss': 0.5040443502366543} | train loss {'Reaction outcome loss': 0.4704802567861518, 'Total loss': 0.4704802567861518}
2022-11-28 06:14:40,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:40,002 INFO:     Epoch: 26
2022-11-28 06:14:40,653 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44552573121406813, 'Total loss': 0.44552573121406813} | train loss {'Reaction outcome loss': 0.47135713489688175, 'Total loss': 0.47135713489688175}
2022-11-28 06:14:40,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:40,653 INFO:     Epoch: 27
2022-11-28 06:14:41,302 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4409563663330945, 'Total loss': 0.4409563663330945} | train loss {'Reaction outcome loss': 0.47299614341891544, 'Total loss': 0.47299614341891544}
2022-11-28 06:14:41,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:41,302 INFO:     Epoch: 28
2022-11-28 06:14:41,956 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4874790212647481, 'Total loss': 0.4874790212647481} | train loss {'Reaction outcome loss': 0.47218464962681944, 'Total loss': 0.47218464962681944}
2022-11-28 06:14:41,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:41,956 INFO:     Epoch: 29
2022-11-28 06:14:42,611 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44717677343975415, 'Total loss': 0.44717677343975415} | train loss {'Reaction outcome loss': 0.4730486754860197, 'Total loss': 0.4730486754860197}
2022-11-28 06:14:42,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:42,611 INFO:     Epoch: 30
2022-11-28 06:14:43,266 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46600945768031204, 'Total loss': 0.46600945768031204} | train loss {'Reaction outcome loss': 0.4716331512344127, 'Total loss': 0.4716331512344127}
2022-11-28 06:14:43,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:43,266 INFO:     Epoch: 31
2022-11-28 06:14:43,924 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45773141289299185, 'Total loss': 0.45773141289299185} | train loss {'Reaction outcome loss': 0.4754319453117799, 'Total loss': 0.4754319453117799}
2022-11-28 06:14:43,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:43,924 INFO:     Epoch: 32
2022-11-28 06:14:44,584 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45107208260081033, 'Total loss': 0.45107208260081033} | train loss {'Reaction outcome loss': 0.4689251642446129, 'Total loss': 0.4689251642446129}
2022-11-28 06:14:44,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:44,585 INFO:     Epoch: 33
2022-11-28 06:14:45,242 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4611057124354623, 'Total loss': 0.4611057124354623} | train loss {'Reaction outcome loss': 0.4706428599296784, 'Total loss': 0.4706428599296784}
2022-11-28 06:14:45,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:45,243 INFO:     Epoch: 34
2022-11-28 06:14:45,900 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47122104465961456, 'Total loss': 0.47122104465961456} | train loss {'Reaction outcome loss': 0.47798198102688305, 'Total loss': 0.47798198102688305}
2022-11-28 06:14:45,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:45,900 INFO:     Epoch: 35
2022-11-28 06:14:46,556 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4697460772638971, 'Total loss': 0.4697460772638971} | train loss {'Reaction outcome loss': 0.4704968651642605, 'Total loss': 0.4704968651642605}
2022-11-28 06:14:46,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:46,556 INFO:     Epoch: 36
2022-11-28 06:14:47,208 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4786683534356681, 'Total loss': 0.4786683534356681} | train loss {'Reaction outcome loss': 0.46950251828042827, 'Total loss': 0.46950251828042827}
2022-11-28 06:14:47,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:47,208 INFO:     Epoch: 37
2022-11-28 06:14:47,865 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43971361219882965, 'Total loss': 0.43971361219882965} | train loss {'Reaction outcome loss': 0.46815438136762505, 'Total loss': 0.46815438136762505}
2022-11-28 06:14:47,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:47,865 INFO:     Epoch: 38
2022-11-28 06:14:48,521 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4569338299334049, 'Total loss': 0.4569338299334049} | train loss {'Reaction outcome loss': 0.47269275565536656, 'Total loss': 0.47269275565536656}
2022-11-28 06:14:48,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:48,521 INFO:     Epoch: 39
2022-11-28 06:14:49,178 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4589850933037021, 'Total loss': 0.4589850933037021} | train loss {'Reaction outcome loss': 0.46303378842314896, 'Total loss': 0.46303378842314896}
2022-11-28 06:14:49,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:49,178 INFO:     Epoch: 40
2022-11-28 06:14:49,833 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4589396799829873, 'Total loss': 0.4589396799829873} | train loss {'Reaction outcome loss': 0.4684517977797255, 'Total loss': 0.4684517977797255}
2022-11-28 06:14:49,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:49,834 INFO:     Epoch: 41
2022-11-28 06:14:50,489 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.437416726030113, 'Total loss': 0.437416726030113} | train loss {'Reaction outcome loss': 0.46509493108914823, 'Total loss': 0.46509493108914823}
2022-11-28 06:14:50,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:50,490 INFO:     Epoch: 42
2022-11-28 06:14:51,144 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4537456143986095, 'Total loss': 0.4537456143986095} | train loss {'Reaction outcome loss': 0.4668426298365301, 'Total loss': 0.4668426298365301}
2022-11-28 06:14:51,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:51,145 INFO:     Epoch: 43
2022-11-28 06:14:51,804 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47460624372417276, 'Total loss': 0.47460624372417276} | train loss {'Reaction outcome loss': 0.4773167924613369, 'Total loss': 0.4773167924613369}
2022-11-28 06:14:51,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:51,805 INFO:     Epoch: 44
2022-11-28 06:14:52,465 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4845604517243125, 'Total loss': 0.4845604517243125} | train loss {'Reaction outcome loss': 0.46876123133970765, 'Total loss': 0.46876123133970765}
2022-11-28 06:14:52,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:52,465 INFO:     Epoch: 45
2022-11-28 06:14:53,122 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4589613689617677, 'Total loss': 0.4589613689617677} | train loss {'Reaction outcome loss': 0.474833169640327, 'Total loss': 0.474833169640327}
2022-11-28 06:14:53,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:53,122 INFO:     Epoch: 46
2022-11-28 06:14:53,780 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4898993833498521, 'Total loss': 0.4898993833498521} | train loss {'Reaction outcome loss': 0.4684891412452776, 'Total loss': 0.4684891412452776}
2022-11-28 06:14:53,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:53,780 INFO:     Epoch: 47
2022-11-28 06:14:54,434 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45795025066895917, 'Total loss': 0.45795025066895917} | train loss {'Reaction outcome loss': 0.46858037260113933, 'Total loss': 0.46858037260113933}
2022-11-28 06:14:54,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:54,434 INFO:     Epoch: 48
2022-11-28 06:14:55,089 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46806038746779616, 'Total loss': 0.46806038746779616} | train loss {'Reaction outcome loss': 0.4693716476766431, 'Total loss': 0.4693716476766431}
2022-11-28 06:14:55,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:55,090 INFO:     Epoch: 49
2022-11-28 06:14:55,746 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4630234716460109, 'Total loss': 0.4630234716460109} | train loss {'Reaction outcome loss': 0.46153296244387726, 'Total loss': 0.46153296244387726}
2022-11-28 06:14:55,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:55,746 INFO:     Epoch: 50
2022-11-28 06:14:56,404 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45991435884074733, 'Total loss': 0.45991435884074733} | train loss {'Reaction outcome loss': 0.4675054902933082, 'Total loss': 0.4675054902933082}
2022-11-28 06:14:56,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:56,404 INFO:     Epoch: 51
2022-11-28 06:14:57,063 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47113791141997685, 'Total loss': 0.47113791141997685} | train loss {'Reaction outcome loss': 0.46917465684973464, 'Total loss': 0.46917465684973464}
2022-11-28 06:14:57,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:57,063 INFO:     Epoch: 52
2022-11-28 06:14:57,720 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4566583492877809, 'Total loss': 0.4566583492877809} | train loss {'Reaction outcome loss': 0.4680081883863527, 'Total loss': 0.4680081883863527}
2022-11-28 06:14:57,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:57,720 INFO:     Epoch: 53
2022-11-28 06:14:58,377 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44801890037276526, 'Total loss': 0.44801890037276526} | train loss {'Reaction outcome loss': 0.47262924559870545, 'Total loss': 0.47262924559870545}
2022-11-28 06:14:58,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:58,377 INFO:     Epoch: 54
2022-11-28 06:14:59,033 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41968420520424843, 'Total loss': 0.41968420520424843} | train loss {'Reaction outcome loss': 0.46928511906643305, 'Total loss': 0.46928511906643305}
2022-11-28 06:14:59,033 INFO:     Found new best model at epoch 54
2022-11-28 06:14:59,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:59,034 INFO:     Epoch: 55
2022-11-28 06:14:59,686 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4861815744502978, 'Total loss': 0.4861815744502978} | train loss {'Reaction outcome loss': 0.46821201778188043, 'Total loss': 0.46821201778188043}
2022-11-28 06:14:59,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:14:59,686 INFO:     Epoch: 56
2022-11-28 06:15:00,341 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47109169445254584, 'Total loss': 0.47109169445254584} | train loss {'Reaction outcome loss': 0.47619007023013366, 'Total loss': 0.47619007023013366}
2022-11-28 06:15:00,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:00,341 INFO:     Epoch: 57
2022-11-28 06:15:00,999 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4535830637270754, 'Total loss': 0.4535830637270754} | train loss {'Reaction outcome loss': 0.47504370297704424, 'Total loss': 0.47504370297704424}
2022-11-28 06:15:00,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:00,999 INFO:     Epoch: 58
2022-11-28 06:15:01,655 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.489967750554735, 'Total loss': 0.489967750554735} | train loss {'Reaction outcome loss': 0.4700594351607926, 'Total loss': 0.4700594351607926}
2022-11-28 06:15:01,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:01,655 INFO:     Epoch: 59
2022-11-28 06:15:02,310 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5711100670424375, 'Total loss': 0.5711100670424375} | train loss {'Reaction outcome loss': 0.47248152248105224, 'Total loss': 0.47248152248105224}
2022-11-28 06:15:02,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:02,312 INFO:     Epoch: 60
2022-11-28 06:15:02,967 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4595740085298365, 'Total loss': 0.4595740085298365} | train loss {'Reaction outcome loss': 0.4739968115577892, 'Total loss': 0.4739968115577892}
2022-11-28 06:15:02,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:02,968 INFO:     Epoch: 61
2022-11-28 06:15:03,623 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46753619822927495, 'Total loss': 0.46753619822927495} | train loss {'Reaction outcome loss': 0.4709142691626841, 'Total loss': 0.4709142691626841}
2022-11-28 06:15:03,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:03,624 INFO:     Epoch: 62
2022-11-28 06:15:04,283 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46784691427918995, 'Total loss': 0.46784691427918995} | train loss {'Reaction outcome loss': 0.4700959080336045, 'Total loss': 0.4700959080336045}
2022-11-28 06:15:04,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:04,283 INFO:     Epoch: 63
2022-11-28 06:15:04,941 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4574076584116979, 'Total loss': 0.4574076584116979} | train loss {'Reaction outcome loss': 0.46935176846324184, 'Total loss': 0.46935176846324184}
2022-11-28 06:15:04,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:04,942 INFO:     Epoch: 64
2022-11-28 06:15:05,598 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44702548144215887, 'Total loss': 0.44702548144215887} | train loss {'Reaction outcome loss': 0.4757858364557733, 'Total loss': 0.4757858364557733}
2022-11-28 06:15:05,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:05,598 INFO:     Epoch: 65
2022-11-28 06:15:06,254 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4507670256901871, 'Total loss': 0.4507670256901871} | train loss {'Reaction outcome loss': 0.4714106816418317, 'Total loss': 0.4714106816418317}
2022-11-28 06:15:06,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:06,255 INFO:     Epoch: 66
2022-11-28 06:15:06,908 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43560779602690175, 'Total loss': 0.43560779602690175} | train loss {'Reaction outcome loss': 0.4727578779264372, 'Total loss': 0.4727578779264372}
2022-11-28 06:15:06,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:06,909 INFO:     Epoch: 67
2022-11-28 06:15:07,559 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47836845910007303, 'Total loss': 0.47836845910007303} | train loss {'Reaction outcome loss': 0.4640979465781426, 'Total loss': 0.4640979465781426}
2022-11-28 06:15:07,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:07,559 INFO:     Epoch: 68
2022-11-28 06:15:08,211 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46072663366794586, 'Total loss': 0.46072663366794586} | train loss {'Reaction outcome loss': 0.46574150165733025, 'Total loss': 0.46574150165733025}
2022-11-28 06:15:08,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:08,212 INFO:     Epoch: 69
2022-11-28 06:15:08,866 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47626338797536766, 'Total loss': 0.47626338797536766} | train loss {'Reaction outcome loss': 0.4762806303038889, 'Total loss': 0.4762806303038889}
2022-11-28 06:15:08,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:08,867 INFO:     Epoch: 70
2022-11-28 06:15:09,522 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45433174107562413, 'Total loss': 0.45433174107562413} | train loss {'Reaction outcome loss': 0.47992658241062747, 'Total loss': 0.47992658241062747}
2022-11-28 06:15:09,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:09,523 INFO:     Epoch: 71
2022-11-28 06:15:10,178 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4479797902432355, 'Total loss': 0.4479797902432355} | train loss {'Reaction outcome loss': 0.46887342668309506, 'Total loss': 0.46887342668309506}
2022-11-28 06:15:10,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:10,178 INFO:     Epoch: 72
2022-11-28 06:15:10,831 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4636437398466197, 'Total loss': 0.4636437398466197} | train loss {'Reaction outcome loss': 0.4683298885822296, 'Total loss': 0.4683298885822296}
2022-11-28 06:15:10,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:10,831 INFO:     Epoch: 73
2022-11-28 06:15:11,486 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4692593345587904, 'Total loss': 0.4692593345587904} | train loss {'Reaction outcome loss': 0.47007326267811717, 'Total loss': 0.47007326267811717}
2022-11-28 06:15:11,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:11,486 INFO:     Epoch: 74
2022-11-28 06:15:12,139 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4537749151614579, 'Total loss': 0.4537749151614579} | train loss {'Reaction outcome loss': 0.471029155594962, 'Total loss': 0.471029155594962}
2022-11-28 06:15:12,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:12,139 INFO:     Epoch: 75
2022-11-28 06:15:12,793 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48787073587829416, 'Total loss': 0.48787073587829416} | train loss {'Reaction outcome loss': 0.47545786025572795, 'Total loss': 0.47545786025572795}
2022-11-28 06:15:12,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:12,793 INFO:     Epoch: 76
2022-11-28 06:15:13,451 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4738492078401826, 'Total loss': 0.4738492078401826} | train loss {'Reaction outcome loss': 0.473688882406877, 'Total loss': 0.473688882406877}
2022-11-28 06:15:13,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:13,451 INFO:     Epoch: 77
2022-11-28 06:15:14,107 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5031013170426543, 'Total loss': 0.5031013170426543} | train loss {'Reaction outcome loss': 0.47150796213928536, 'Total loss': 0.47150796213928536}
2022-11-28 06:15:14,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:14,108 INFO:     Epoch: 78
2022-11-28 06:15:14,762 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4643340710211884, 'Total loss': 0.4643340710211884} | train loss {'Reaction outcome loss': 0.46905793973377774, 'Total loss': 0.46905793973377774}
2022-11-28 06:15:14,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:14,762 INFO:     Epoch: 79
2022-11-28 06:15:15,417 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4708052094687115, 'Total loss': 0.4708052094687115} | train loss {'Reaction outcome loss': 0.474233368768984, 'Total loss': 0.474233368768984}
2022-11-28 06:15:15,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:15,417 INFO:     Epoch: 80
2022-11-28 06:15:16,071 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4783208051865751, 'Total loss': 0.4783208051865751} | train loss {'Reaction outcome loss': 0.4764787965283102, 'Total loss': 0.4764787965283102}
2022-11-28 06:15:16,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:16,071 INFO:     Epoch: 81
2022-11-28 06:15:16,727 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4530097269876437, 'Total loss': 0.4530097269876437} | train loss {'Reaction outcome loss': 0.47035248033246213, 'Total loss': 0.47035248033246213}
2022-11-28 06:15:16,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:16,727 INFO:     Epoch: 82
2022-11-28 06:15:17,382 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45947479558261956, 'Total loss': 0.45947479558261956} | train loss {'Reaction outcome loss': 0.4754298721649209, 'Total loss': 0.4754298721649209}
2022-11-28 06:15:17,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:17,383 INFO:     Epoch: 83
2022-11-28 06:15:18,035 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46960659054192627, 'Total loss': 0.46960659054192627} | train loss {'Reaction outcome loss': 0.4624978822104785, 'Total loss': 0.4624978822104785}
2022-11-28 06:15:18,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:18,035 INFO:     Epoch: 84
2022-11-28 06:15:18,689 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4681225205686959, 'Total loss': 0.4681225205686959} | train loss {'Reaction outcome loss': 0.46962146631308965, 'Total loss': 0.46962146631308965}
2022-11-28 06:15:18,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:18,689 INFO:     Epoch: 85
2022-11-28 06:15:19,339 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46170555089007725, 'Total loss': 0.46170555089007725} | train loss {'Reaction outcome loss': 0.46560267404634126, 'Total loss': 0.46560267404634126}
2022-11-28 06:15:19,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:19,339 INFO:     Epoch: 86
2022-11-28 06:15:19,996 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4516115951013159, 'Total loss': 0.4516115951013159} | train loss {'Reaction outcome loss': 0.4644142527361305, 'Total loss': 0.4644142527361305}
2022-11-28 06:15:19,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:19,996 INFO:     Epoch: 87
2022-11-28 06:15:20,649 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4758410717953335, 'Total loss': 0.4758410717953335} | train loss {'Reaction outcome loss': 0.4635295704919465, 'Total loss': 0.4635295704919465}
2022-11-28 06:15:20,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:20,650 INFO:     Epoch: 88
2022-11-28 06:15:21,305 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4552551172462038, 'Total loss': 0.4552551172462038} | train loss {'Reaction outcome loss': 0.4667665890284947, 'Total loss': 0.4667665890284947}
2022-11-28 06:15:21,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:21,306 INFO:     Epoch: 89
2022-11-28 06:15:21,958 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47593682597983966, 'Total loss': 0.47593682597983966} | train loss {'Reaction outcome loss': 0.4696101473910468, 'Total loss': 0.4696101473910468}
2022-11-28 06:15:21,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:21,958 INFO:     Epoch: 90
2022-11-28 06:15:22,615 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5227706185118719, 'Total loss': 0.5227706185118719} | train loss {'Reaction outcome loss': 0.46227879019416107, 'Total loss': 0.46227879019416107}
2022-11-28 06:15:22,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:22,616 INFO:     Epoch: 91
2022-11-28 06:15:23,272 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44874099134044215, 'Total loss': 0.44874099134044215} | train loss {'Reaction outcome loss': 0.4743235392838108, 'Total loss': 0.4743235392838108}
2022-11-28 06:15:23,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:23,273 INFO:     Epoch: 92
2022-11-28 06:15:23,929 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4554774822159247, 'Total loss': 0.4554774822159247} | train loss {'Reaction outcome loss': 0.4677020542475642, 'Total loss': 0.4677020542475642}
2022-11-28 06:15:23,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:23,929 INFO:     Epoch: 93
2022-11-28 06:15:24,583 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5289994772862304, 'Total loss': 0.5289994772862304} | train loss {'Reaction outcome loss': 0.47429655391951, 'Total loss': 0.47429655391951}
2022-11-28 06:15:24,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:24,583 INFO:     Epoch: 94
2022-11-28 06:15:25,236 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.482367260212248, 'Total loss': 0.482367260212248} | train loss {'Reaction outcome loss': 0.4750789446490152, 'Total loss': 0.4750789446490152}
2022-11-28 06:15:25,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:25,236 INFO:     Epoch: 95
2022-11-28 06:15:25,888 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45714347098361363, 'Total loss': 0.45714347098361363} | train loss {'Reaction outcome loss': 0.46425982339649785, 'Total loss': 0.46425982339649785}
2022-11-28 06:15:25,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:25,888 INFO:     Epoch: 96
2022-11-28 06:15:26,547 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46921582824804564, 'Total loss': 0.46921582824804564} | train loss {'Reaction outcome loss': 0.4624352883927676, 'Total loss': 0.4624352883927676}
2022-11-28 06:15:26,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:26,547 INFO:     Epoch: 97
2022-11-28 06:15:27,202 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4615245427597653, 'Total loss': 0.4615245427597653} | train loss {'Reaction outcome loss': 0.46975970912952814, 'Total loss': 0.46975970912952814}
2022-11-28 06:15:27,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:27,202 INFO:     Epoch: 98
2022-11-28 06:15:27,858 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4739247963509776, 'Total loss': 0.4739247963509776} | train loss {'Reaction outcome loss': 0.4715534730833404, 'Total loss': 0.4715534730833404}
2022-11-28 06:15:27,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:27,858 INFO:     Epoch: 99
2022-11-28 06:15:28,512 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4551020799712701, 'Total loss': 0.4551020799712701} | train loss {'Reaction outcome loss': 0.46882555551674904, 'Total loss': 0.46882555551674904}
2022-11-28 06:15:28,512 INFO:     Best model found after epoch 55 of 100.
2022-11-28 06:15:28,512 INFO:   Done with stage: TRAINING
2022-11-28 06:15:28,512 INFO:   Starting stage: EVALUATION
2022-11-28 06:15:28,635 INFO:   Done with stage: EVALUATION
2022-11-28 06:15:28,635 INFO:   Leaving out SEQ value Fold_2
2022-11-28 06:15:28,648 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 06:15:28,648 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:15:29,292 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:15:29,292 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:15:29,361 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:15:29,362 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:15:29,362 INFO:     No hyperparam tuning for this model
2022-11-28 06:15:29,362 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:15:29,362 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:15:29,362 INFO:     None feature selector for col prot
2022-11-28 06:15:29,363 INFO:     None feature selector for col prot
2022-11-28 06:15:29,363 INFO:     None feature selector for col prot
2022-11-28 06:15:29,363 INFO:     None feature selector for col chem
2022-11-28 06:15:29,363 INFO:     None feature selector for col chem
2022-11-28 06:15:29,363 INFO:     None feature selector for col chem
2022-11-28 06:15:29,363 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:15:29,364 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:15:29,365 INFO:     Number of params in model 169651
2022-11-28 06:15:29,368 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:15:29,368 INFO:   Starting stage: TRAINING
2022-11-28 06:15:29,420 INFO:     Val loss before train {'Reaction outcome loss': 1.002147140828046, 'Total loss': 1.002147140828046}
2022-11-28 06:15:29,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:29,420 INFO:     Epoch: 0
2022-11-28 06:15:30,082 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6001381467689167, 'Total loss': 0.6001381467689167} | train loss {'Reaction outcome loss': 0.6919206583246529, 'Total loss': 0.6919206583246529}
2022-11-28 06:15:30,082 INFO:     Found new best model at epoch 0
2022-11-28 06:15:30,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:30,083 INFO:     Epoch: 1
2022-11-28 06:15:30,742 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5700370218943466, 'Total loss': 0.5700370218943466} | train loss {'Reaction outcome loss': 0.5845285121969849, 'Total loss': 0.5845285121969849}
2022-11-28 06:15:30,742 INFO:     Found new best model at epoch 1
2022-11-28 06:15:30,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:30,743 INFO:     Epoch: 2
2022-11-28 06:15:31,404 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.610522756522352, 'Total loss': 0.610522756522352} | train loss {'Reaction outcome loss': 0.5549885813403226, 'Total loss': 0.5549885813403226}
2022-11-28 06:15:31,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:31,404 INFO:     Epoch: 3
2022-11-28 06:15:32,063 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5280265110460195, 'Total loss': 0.5280265110460195} | train loss {'Reaction outcome loss': 0.5332208492977899, 'Total loss': 0.5332208492977899}
2022-11-28 06:15:32,063 INFO:     Found new best model at epoch 3
2022-11-28 06:15:32,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:32,064 INFO:     Epoch: 4
2022-11-28 06:15:32,722 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5181960361925039, 'Total loss': 0.5181960361925039} | train loss {'Reaction outcome loss': 0.5207934699922439, 'Total loss': 0.5207934699922439}
2022-11-28 06:15:32,722 INFO:     Found new best model at epoch 4
2022-11-28 06:15:32,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:32,723 INFO:     Epoch: 5
2022-11-28 06:15:33,381 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5090342346917499, 'Total loss': 0.5090342346917499} | train loss {'Reaction outcome loss': 0.5339932672769917, 'Total loss': 0.5339932672769917}
2022-11-28 06:15:33,382 INFO:     Found new best model at epoch 5
2022-11-28 06:15:33,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:33,382 INFO:     Epoch: 6
2022-11-28 06:15:34,042 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5425558144396002, 'Total loss': 0.5425558144396002} | train loss {'Reaction outcome loss': 0.5221606515016151, 'Total loss': 0.5221606515016151}
2022-11-28 06:15:34,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:34,043 INFO:     Epoch: 7
2022-11-28 06:15:34,704 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.536227145316926, 'Total loss': 0.536227145316926} | train loss {'Reaction outcome loss': 0.5150512878609602, 'Total loss': 0.5150512878609602}
2022-11-28 06:15:34,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:34,704 INFO:     Epoch: 8
2022-11-28 06:15:35,363 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.525370645252141, 'Total loss': 0.525370645252141} | train loss {'Reaction outcome loss': 0.511645265074394, 'Total loss': 0.511645265074394}
2022-11-28 06:15:35,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:35,364 INFO:     Epoch: 9
2022-11-28 06:15:36,018 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5019439262422648, 'Total loss': 0.5019439262422648} | train loss {'Reaction outcome loss': 0.4977582373660103, 'Total loss': 0.4977582373660103}
2022-11-28 06:15:36,018 INFO:     Found new best model at epoch 9
2022-11-28 06:15:36,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:36,019 INFO:     Epoch: 10
2022-11-28 06:15:36,678 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5235939154570753, 'Total loss': 0.5235939154570753} | train loss {'Reaction outcome loss': 0.4972266671568276, 'Total loss': 0.4972266671568276}
2022-11-28 06:15:36,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:36,678 INFO:     Epoch: 11
2022-11-28 06:15:37,340 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48906979540532286, 'Total loss': 0.48906979540532286} | train loss {'Reaction outcome loss': 0.49817236021221406, 'Total loss': 0.49817236021221406}
2022-11-28 06:15:37,340 INFO:     Found new best model at epoch 11
2022-11-28 06:15:37,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:37,341 INFO:     Epoch: 12
2022-11-28 06:15:38,003 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.51950503885746, 'Total loss': 0.51950503885746} | train loss {'Reaction outcome loss': 0.49679987189861446, 'Total loss': 0.49679987189861446}
2022-11-28 06:15:38,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:38,003 INFO:     Epoch: 13
2022-11-28 06:15:38,665 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5088440020653334, 'Total loss': 0.5088440020653334} | train loss {'Reaction outcome loss': 0.48878761477436616, 'Total loss': 0.48878761477436616}
2022-11-28 06:15:38,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:38,666 INFO:     Epoch: 14
2022-11-28 06:15:39,323 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4932551109655337, 'Total loss': 0.4932551109655337} | train loss {'Reaction outcome loss': 0.4903624198938671, 'Total loss': 0.4903624198938671}
2022-11-28 06:15:39,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:39,323 INFO:     Epoch: 15
2022-11-28 06:15:39,982 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4911337271332741, 'Total loss': 0.4911337271332741} | train loss {'Reaction outcome loss': 0.4905198712942571, 'Total loss': 0.4905198712942571}
2022-11-28 06:15:39,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:39,982 INFO:     Epoch: 16
2022-11-28 06:15:40,643 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5180612809278748, 'Total loss': 0.5180612809278748} | train loss {'Reaction outcome loss': 0.491020799859574, 'Total loss': 0.491020799859574}
2022-11-28 06:15:40,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:40,643 INFO:     Epoch: 17
2022-11-28 06:15:41,301 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4768718823113225, 'Total loss': 0.4768718823113225} | train loss {'Reaction outcome loss': 0.4767348075823798, 'Total loss': 0.4767348075823798}
2022-11-28 06:15:41,301 INFO:     Found new best model at epoch 17
2022-11-28 06:15:41,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:41,301 INFO:     Epoch: 18
2022-11-28 06:15:41,961 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4792666486041112, 'Total loss': 0.4792666486041112} | train loss {'Reaction outcome loss': 0.4733150292504654, 'Total loss': 0.4733150292504654}
2022-11-28 06:15:41,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:41,961 INFO:     Epoch: 19
2022-11-28 06:15:42,620 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5566602606665004, 'Total loss': 0.5566602606665004} | train loss {'Reaction outcome loss': 0.4742147164788806, 'Total loss': 0.4742147164788806}
2022-11-28 06:15:42,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:42,620 INFO:     Epoch: 20
2022-11-28 06:15:43,276 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.54861839894544, 'Total loss': 0.54861839894544} | train loss {'Reaction outcome loss': 0.500984144446097, 'Total loss': 0.500984144446097}
2022-11-28 06:15:43,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:43,276 INFO:     Epoch: 21
2022-11-28 06:15:43,937 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5046935779127207, 'Total loss': 0.5046935779127207} | train loss {'Reaction outcome loss': 0.4770322093958797, 'Total loss': 0.4770322093958797}
2022-11-28 06:15:43,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:43,937 INFO:     Epoch: 22
2022-11-28 06:15:44,597 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5435107777064497, 'Total loss': 0.5435107777064497} | train loss {'Reaction outcome loss': 0.4756633495527361, 'Total loss': 0.4756633495527361}
2022-11-28 06:15:44,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:44,597 INFO:     Epoch: 23
2022-11-28 06:15:45,252 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5177947269244627, 'Total loss': 0.5177947269244627} | train loss {'Reaction outcome loss': 0.4666605445778804, 'Total loss': 0.4666605445778804}
2022-11-28 06:15:45,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:45,253 INFO:     Epoch: 24
2022-11-28 06:15:45,909 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4861895320090381, 'Total loss': 0.4861895320090381} | train loss {'Reaction outcome loss': 0.46751547441912084, 'Total loss': 0.46751547441912084}
2022-11-28 06:15:45,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:45,909 INFO:     Epoch: 25
2022-11-28 06:15:46,566 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48928335918621585, 'Total loss': 0.48928335918621585} | train loss {'Reaction outcome loss': 0.477291812509419, 'Total loss': 0.477291812509419}
2022-11-28 06:15:46,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:46,566 INFO:     Epoch: 26
2022-11-28 06:15:47,225 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5027463050051169, 'Total loss': 0.5027463050051169} | train loss {'Reaction outcome loss': 0.4945123405591679, 'Total loss': 0.4945123405591679}
2022-11-28 06:15:47,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:47,225 INFO:     Epoch: 27
2022-11-28 06:15:47,884 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5229224569418214, 'Total loss': 0.5229224569418214} | train loss {'Reaction outcome loss': 0.4791075862371005, 'Total loss': 0.4791075862371005}
2022-11-28 06:15:47,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:47,884 INFO:     Epoch: 28
2022-11-28 06:15:48,543 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5298541018908675, 'Total loss': 0.5298541018908675} | train loss {'Reaction outcome loss': 0.4758843167832023, 'Total loss': 0.4758843167832023}
2022-11-28 06:15:48,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:48,543 INFO:     Epoch: 29
2022-11-28 06:15:49,200 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5267026349902153, 'Total loss': 0.5267026349902153} | train loss {'Reaction outcome loss': 0.4799052523939233, 'Total loss': 0.4799052523939233}
2022-11-28 06:15:49,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:49,200 INFO:     Epoch: 30
2022-11-28 06:15:49,860 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4524222111160105, 'Total loss': 0.4524222111160105} | train loss {'Reaction outcome loss': 0.4683637491423591, 'Total loss': 0.4683637491423591}
2022-11-28 06:15:49,860 INFO:     Found new best model at epoch 30
2022-11-28 06:15:49,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:49,860 INFO:     Epoch: 31
2022-11-28 06:15:50,517 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5039814409207214, 'Total loss': 0.5039814409207214} | train loss {'Reaction outcome loss': 0.47870632224840676, 'Total loss': 0.47870632224840676}
2022-11-28 06:15:50,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:50,517 INFO:     Epoch: 32
2022-11-28 06:15:51,173 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4695045677098361, 'Total loss': 0.4695045677098361} | train loss {'Reaction outcome loss': 0.4639938143100816, 'Total loss': 0.4639938143100816}
2022-11-28 06:15:51,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:51,173 INFO:     Epoch: 33
2022-11-28 06:15:51,830 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5268496085296978, 'Total loss': 0.5268496085296978} | train loss {'Reaction outcome loss': 0.46822779752344257, 'Total loss': 0.46822779752344257}
2022-11-28 06:15:51,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:51,830 INFO:     Epoch: 34
2022-11-28 06:15:52,491 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5004000176082958, 'Total loss': 0.5004000176082958} | train loss {'Reaction outcome loss': 0.46784773517234124, 'Total loss': 0.46784773517234124}
2022-11-28 06:15:52,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:52,492 INFO:     Epoch: 35
2022-11-28 06:15:53,146 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4624538262459365, 'Total loss': 0.4624538262459365} | train loss {'Reaction outcome loss': 0.4657806000004896, 'Total loss': 0.4657806000004896}
2022-11-28 06:15:53,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:53,146 INFO:     Epoch: 36
2022-11-28 06:15:53,801 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4628868881951679, 'Total loss': 0.4628868881951679} | train loss {'Reaction outcome loss': 0.478661395217243, 'Total loss': 0.478661395217243}
2022-11-28 06:15:53,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:53,801 INFO:     Epoch: 37
2022-11-28 06:15:54,460 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45854956351897935, 'Total loss': 0.45854956351897935} | train loss {'Reaction outcome loss': 0.4820896831380207, 'Total loss': 0.4820896831380207}
2022-11-28 06:15:54,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:54,461 INFO:     Epoch: 38
2022-11-28 06:15:55,121 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48426917093721306, 'Total loss': 0.48426917093721306} | train loss {'Reaction outcome loss': 0.46115199479496916, 'Total loss': 0.46115199479496916}
2022-11-28 06:15:55,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:55,121 INFO:     Epoch: 39
2022-11-28 06:15:55,781 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46806299550966785, 'Total loss': 0.46806299550966785} | train loss {'Reaction outcome loss': 0.4588932554852142, 'Total loss': 0.4588932554852142}
2022-11-28 06:15:55,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:55,781 INFO:     Epoch: 40
2022-11-28 06:15:56,441 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47423445907506073, 'Total loss': 0.47423445907506073} | train loss {'Reaction outcome loss': 0.46175171547995403, 'Total loss': 0.46175171547995403}
2022-11-28 06:15:56,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:56,441 INFO:     Epoch: 41
2022-11-28 06:15:57,100 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5281552902676843, 'Total loss': 0.5281552902676843} | train loss {'Reaction outcome loss': 0.4736300981961764, 'Total loss': 0.4736300981961764}
2022-11-28 06:15:57,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:57,100 INFO:     Epoch: 42
2022-11-28 06:15:57,760 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4989935044537891, 'Total loss': 0.4989935044537891} | train loss {'Reaction outcome loss': 0.47090434026621614, 'Total loss': 0.47090434026621614}
2022-11-28 06:15:57,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:57,760 INFO:     Epoch: 43
2022-11-28 06:15:58,421 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4738166606561704, 'Total loss': 0.4738166606561704} | train loss {'Reaction outcome loss': 0.47170993269455097, 'Total loss': 0.47170993269455097}
2022-11-28 06:15:58,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:58,421 INFO:     Epoch: 44
2022-11-28 06:15:59,079 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4799705252728679, 'Total loss': 0.4799705252728679} | train loss {'Reaction outcome loss': 0.4664374593539759, 'Total loss': 0.4664374593539759}
2022-11-28 06:15:59,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:59,079 INFO:     Epoch: 45
2022-11-28 06:15:59,739 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47380290417508647, 'Total loss': 0.47380290417508647} | train loss {'Reaction outcome loss': 0.4623326797355042, 'Total loss': 0.4623326797355042}
2022-11-28 06:15:59,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:15:59,739 INFO:     Epoch: 46
2022-11-28 06:16:00,398 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5229045301675797, 'Total loss': 0.5229045301675797} | train loss {'Reaction outcome loss': 0.4614977591071534, 'Total loss': 0.4614977591071534}
2022-11-28 06:16:00,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:00,399 INFO:     Epoch: 47
2022-11-28 06:16:01,056 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48058798943053593, 'Total loss': 0.48058798943053593} | train loss {'Reaction outcome loss': 0.475740415002653, 'Total loss': 0.475740415002653}
2022-11-28 06:16:01,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:01,056 INFO:     Epoch: 48
2022-11-28 06:16:01,720 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4679726650091735, 'Total loss': 0.4679726650091735} | train loss {'Reaction outcome loss': 0.47041083157165275, 'Total loss': 0.47041083157165275}
2022-11-28 06:16:01,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:01,720 INFO:     Epoch: 49
2022-11-28 06:16:02,381 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4663083898750218, 'Total loss': 0.4663083898750218} | train loss {'Reaction outcome loss': 0.4602756881520816, 'Total loss': 0.4602756881520816}
2022-11-28 06:16:02,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:02,381 INFO:     Epoch: 50
2022-11-28 06:16:03,043 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4967095262625001, 'Total loss': 0.4967095262625001} | train loss {'Reaction outcome loss': 0.4672970280356645, 'Total loss': 0.4672970280356645}
2022-11-28 06:16:03,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:03,043 INFO:     Epoch: 51
2022-11-28 06:16:03,700 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48677627674557944, 'Total loss': 0.48677627674557944} | train loss {'Reaction outcome loss': 0.45811947423074895, 'Total loss': 0.45811947423074895}
2022-11-28 06:16:03,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:03,701 INFO:     Epoch: 52
2022-11-28 06:16:04,363 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4750433144244281, 'Total loss': 0.4750433144244281} | train loss {'Reaction outcome loss': 0.4666528506317602, 'Total loss': 0.4666528506317602}
2022-11-28 06:16:04,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:04,364 INFO:     Epoch: 53
2022-11-28 06:16:05,023 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47524613819339057, 'Total loss': 0.47524613819339057} | train loss {'Reaction outcome loss': 0.4678391902914897, 'Total loss': 0.4678391902914897}
2022-11-28 06:16:05,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:05,023 INFO:     Epoch: 54
2022-11-28 06:16:05,682 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5051210559904575, 'Total loss': 0.5051210559904575} | train loss {'Reaction outcome loss': 0.45902777478279855, 'Total loss': 0.45902777478279855}
2022-11-28 06:16:05,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:05,682 INFO:     Epoch: 55
2022-11-28 06:16:06,343 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48305385864593764, 'Total loss': 0.48305385864593764} | train loss {'Reaction outcome loss': 0.4640859198402557, 'Total loss': 0.4640859198402557}
2022-11-28 06:16:06,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:06,343 INFO:     Epoch: 56
2022-11-28 06:16:07,004 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5294801765544848, 'Total loss': 0.5294801765544848} | train loss {'Reaction outcome loss': 0.4708746736228225, 'Total loss': 0.4708746736228225}
2022-11-28 06:16:07,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:07,004 INFO:     Epoch: 57
2022-11-28 06:16:07,666 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4695303589105606, 'Total loss': 0.4695303589105606} | train loss {'Reaction outcome loss': 0.4770766635489488, 'Total loss': 0.4770766635489488}
2022-11-28 06:16:07,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:07,666 INFO:     Epoch: 58
2022-11-28 06:16:08,326 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5034287226471034, 'Total loss': 0.5034287226471034} | train loss {'Reaction outcome loss': 0.45725834645468294, 'Total loss': 0.45725834645468294}
2022-11-28 06:16:08,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:08,327 INFO:     Epoch: 59
2022-11-28 06:16:08,987 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46056499501520937, 'Total loss': 0.46056499501520937} | train loss {'Reaction outcome loss': 0.4567594776450381, 'Total loss': 0.4567594776450381}
2022-11-28 06:16:08,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:08,987 INFO:     Epoch: 60
2022-11-28 06:16:09,655 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4730255129662427, 'Total loss': 0.4730255129662427} | train loss {'Reaction outcome loss': 0.46062191259853547, 'Total loss': 0.46062191259853547}
2022-11-28 06:16:09,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:09,655 INFO:     Epoch: 61
2022-11-28 06:16:10,320 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4739406224001538, 'Total loss': 0.4739406224001538} | train loss {'Reaction outcome loss': 0.46239973010536783, 'Total loss': 0.46239973010536783}
2022-11-28 06:16:10,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:10,320 INFO:     Epoch: 62
2022-11-28 06:16:10,976 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4982039433988658, 'Total loss': 0.4982039433988658} | train loss {'Reaction outcome loss': 0.45750992856768946, 'Total loss': 0.45750992856768946}
2022-11-28 06:16:10,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:10,977 INFO:     Epoch: 63
2022-11-28 06:16:11,637 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4734990010884675, 'Total loss': 0.4734990010884675} | train loss {'Reaction outcome loss': 0.46683810907698836, 'Total loss': 0.46683810907698836}
2022-11-28 06:16:11,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:11,637 INFO:     Epoch: 64
2022-11-28 06:16:12,300 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4669242995706471, 'Total loss': 0.4669242995706471} | train loss {'Reaction outcome loss': 0.4635076679681477, 'Total loss': 0.4635076679681477}
2022-11-28 06:16:12,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:12,300 INFO:     Epoch: 65
2022-11-28 06:16:12,961 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47734271396290173, 'Total loss': 0.47734271396290173} | train loss {'Reaction outcome loss': 0.4630874627032261, 'Total loss': 0.4630874627032261}
2022-11-28 06:16:12,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:12,961 INFO:     Epoch: 66
2022-11-28 06:16:13,621 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5004728676920588, 'Total loss': 0.5004728676920588} | train loss {'Reaction outcome loss': 0.46658606923784807, 'Total loss': 0.46658606923784807}
2022-11-28 06:16:13,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:13,621 INFO:     Epoch: 67
2022-11-28 06:16:14,277 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4961368245157329, 'Total loss': 0.4961368245157329} | train loss {'Reaction outcome loss': 0.4744284818408943, 'Total loss': 0.4744284818408943}
2022-11-28 06:16:14,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:14,278 INFO:     Epoch: 68
2022-11-28 06:16:14,934 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4629617611115629, 'Total loss': 0.4629617611115629} | train loss {'Reaction outcome loss': 0.4675576601192536, 'Total loss': 0.4675576601192536}
2022-11-28 06:16:14,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:14,934 INFO:     Epoch: 69
2022-11-28 06:16:15,595 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4757359457964247, 'Total loss': 0.4757359457964247} | train loss {'Reaction outcome loss': 0.4547052840034851, 'Total loss': 0.4547052840034851}
2022-11-28 06:16:15,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:15,595 INFO:     Epoch: 70
2022-11-28 06:16:16,250 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4840696779164401, 'Total loss': 0.4840696779164401} | train loss {'Reaction outcome loss': 0.46030901849028555, 'Total loss': 0.46030901849028555}
2022-11-28 06:16:16,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:16,250 INFO:     Epoch: 71
2022-11-28 06:16:16,911 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46527780118313705, 'Total loss': 0.46527780118313705} | train loss {'Reaction outcome loss': 0.47380257919732377, 'Total loss': 0.47380257919732377}
2022-11-28 06:16:16,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:16,911 INFO:     Epoch: 72
2022-11-28 06:16:17,569 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4753029349852692, 'Total loss': 0.4753029349852692} | train loss {'Reaction outcome loss': 0.4607819265380562, 'Total loss': 0.4607819265380562}
2022-11-28 06:16:17,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:17,569 INFO:     Epoch: 73
2022-11-28 06:16:18,228 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47739586301825265, 'Total loss': 0.47739586301825265} | train loss {'Reaction outcome loss': 0.45581396861541035, 'Total loss': 0.45581396861541035}
2022-11-28 06:16:18,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:18,228 INFO:     Epoch: 74
2022-11-28 06:16:18,886 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44652537493543193, 'Total loss': 0.44652537493543193} | train loss {'Reaction outcome loss': 0.46498551162389606, 'Total loss': 0.46498551162389606}
2022-11-28 06:16:18,886 INFO:     Found new best model at epoch 74
2022-11-28 06:16:18,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:18,886 INFO:     Epoch: 75
2022-11-28 06:16:19,546 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48847330395470967, 'Total loss': 0.48847330395470967} | train loss {'Reaction outcome loss': 0.46195571877152813, 'Total loss': 0.46195571877152813}
2022-11-28 06:16:19,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:19,547 INFO:     Epoch: 76
2022-11-28 06:16:20,207 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4819168611006303, 'Total loss': 0.4819168611006303} | train loss {'Reaction outcome loss': 0.46082597234953754, 'Total loss': 0.46082597234953754}
2022-11-28 06:16:20,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:20,207 INFO:     Epoch: 77
2022-11-28 06:16:20,865 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4784739857370203, 'Total loss': 0.4784739857370203} | train loss {'Reaction outcome loss': 0.4594264832826761, 'Total loss': 0.4594264832826761}
2022-11-28 06:16:20,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:20,865 INFO:     Epoch: 78
2022-11-28 06:16:21,528 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4750187908383933, 'Total loss': 0.4750187908383933} | train loss {'Reaction outcome loss': 0.4697309474834064, 'Total loss': 0.4697309474834064}
2022-11-28 06:16:21,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:21,529 INFO:     Epoch: 79
2022-11-28 06:16:22,196 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4570216451856223, 'Total loss': 0.4570216451856223} | train loss {'Reaction outcome loss': 0.46126788281477415, 'Total loss': 0.46126788281477415}
2022-11-28 06:16:22,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:22,197 INFO:     Epoch: 80
2022-11-28 06:16:22,857 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4856313013217666, 'Total loss': 0.4856313013217666} | train loss {'Reaction outcome loss': 0.4661012980860737, 'Total loss': 0.4661012980860737}
2022-11-28 06:16:22,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:22,857 INFO:     Epoch: 81
2022-11-28 06:16:23,516 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4776153042912483, 'Total loss': 0.4776153042912483} | train loss {'Reaction outcome loss': 0.46542600136597145, 'Total loss': 0.46542600136597145}
2022-11-28 06:16:23,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:23,517 INFO:     Epoch: 82
2022-11-28 06:16:24,178 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4672534442083402, 'Total loss': 0.4672534442083402} | train loss {'Reaction outcome loss': 0.4668754461081887, 'Total loss': 0.4668754461081887}
2022-11-28 06:16:24,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:24,178 INFO:     Epoch: 83
2022-11-28 06:16:24,838 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5083819099447944, 'Total loss': 0.5083819099447944} | train loss {'Reaction outcome loss': 0.46143358323707995, 'Total loss': 0.46143358323707995}
2022-11-28 06:16:24,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:24,838 INFO:     Epoch: 84
2022-11-28 06:16:25,499 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5087587139145895, 'Total loss': 0.5087587139145895} | train loss {'Reaction outcome loss': 0.45956920468161705, 'Total loss': 0.45956920468161705}
2022-11-28 06:16:25,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:25,499 INFO:     Epoch: 85
2022-11-28 06:16:26,160 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5257343063977632, 'Total loss': 0.5257343063977632} | train loss {'Reaction outcome loss': 0.4695947889374335, 'Total loss': 0.4695947889374335}
2022-11-28 06:16:26,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:26,161 INFO:     Epoch: 86
2022-11-28 06:16:26,816 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.467832954431122, 'Total loss': 0.467832954431122} | train loss {'Reaction outcome loss': 0.46569971468767174, 'Total loss': 0.46569971468767174}
2022-11-28 06:16:26,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:26,817 INFO:     Epoch: 87
2022-11-28 06:16:27,477 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4973608356985179, 'Total loss': 0.4973608356985179} | train loss {'Reaction outcome loss': 0.45985061859595117, 'Total loss': 0.45985061859595117}
2022-11-28 06:16:27,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:27,477 INFO:     Epoch: 88
2022-11-28 06:16:28,137 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4624092003161257, 'Total loss': 0.4624092003161257} | train loss {'Reaction outcome loss': 0.4604763578367137, 'Total loss': 0.4604763578367137}
2022-11-28 06:16:28,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:28,137 INFO:     Epoch: 89
2022-11-28 06:16:28,797 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5047564042562788, 'Total loss': 0.5047564042562788} | train loss {'Reaction outcome loss': 0.46368507401421966, 'Total loss': 0.46368507401421966}
2022-11-28 06:16:28,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:28,797 INFO:     Epoch: 90
2022-11-28 06:16:29,461 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5258900079537522, 'Total loss': 0.5258900079537522} | train loss {'Reaction outcome loss': 0.46932228953249544, 'Total loss': 0.46932228953249544}
2022-11-28 06:16:29,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:29,461 INFO:     Epoch: 91
2022-11-28 06:16:30,120 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4657634161412716, 'Total loss': 0.4657634161412716} | train loss {'Reaction outcome loss': 0.4626155912363336, 'Total loss': 0.4626155912363336}
2022-11-28 06:16:30,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:30,120 INFO:     Epoch: 92
2022-11-28 06:16:30,786 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47569509934295306, 'Total loss': 0.47569509934295306} | train loss {'Reaction outcome loss': 0.46186728105853925, 'Total loss': 0.46186728105853925}
2022-11-28 06:16:30,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:30,786 INFO:     Epoch: 93
2022-11-28 06:16:31,452 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46682701259851456, 'Total loss': 0.46682701259851456} | train loss {'Reaction outcome loss': 0.4687151906159725, 'Total loss': 0.4687151906159725}
2022-11-28 06:16:31,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:31,452 INFO:     Epoch: 94
2022-11-28 06:16:32,113 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4862199930304831, 'Total loss': 0.4862199930304831} | train loss {'Reaction outcome loss': 0.4616158287533298, 'Total loss': 0.4616158287533298}
2022-11-28 06:16:32,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:32,114 INFO:     Epoch: 95
2022-11-28 06:16:32,776 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4756960245695981, 'Total loss': 0.4756960245695981} | train loss {'Reaction outcome loss': 0.46755418130140075, 'Total loss': 0.46755418130140075}
2022-11-28 06:16:32,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:32,776 INFO:     Epoch: 96
2022-11-28 06:16:33,436 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4706284583292224, 'Total loss': 0.4706284583292224} | train loss {'Reaction outcome loss': 0.45667418158567896, 'Total loss': 0.45667418158567896}
2022-11-28 06:16:33,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:33,436 INFO:     Epoch: 97
2022-11-28 06:16:34,102 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46627990020947024, 'Total loss': 0.46627990020947024} | train loss {'Reaction outcome loss': 0.46461893612073984, 'Total loss': 0.46461893612073984}
2022-11-28 06:16:34,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:34,102 INFO:     Epoch: 98
2022-11-28 06:16:34,765 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4638647030700337, 'Total loss': 0.4638647030700337} | train loss {'Reaction outcome loss': 0.46638528556234926, 'Total loss': 0.46638528556234926}
2022-11-28 06:16:34,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:34,766 INFO:     Epoch: 99
2022-11-28 06:16:35,431 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47808893769979477, 'Total loss': 0.47808893769979477} | train loss {'Reaction outcome loss': 0.47025677760844287, 'Total loss': 0.47025677760844287}
2022-11-28 06:16:35,432 INFO:     Best model found after epoch 75 of 100.
2022-11-28 06:16:35,432 INFO:   Done with stage: TRAINING
2022-11-28 06:16:35,432 INFO:   Starting stage: EVALUATION
2022-11-28 06:16:35,552 INFO:   Done with stage: EVALUATION
2022-11-28 06:16:35,552 INFO:   Leaving out SEQ value Fold_3
2022-11-28 06:16:35,565 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 06:16:35,565 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:16:36,214 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:16:36,214 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:16:36,285 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:16:36,285 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:16:36,285 INFO:     No hyperparam tuning for this model
2022-11-28 06:16:36,285 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:16:36,285 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:16:36,286 INFO:     None feature selector for col prot
2022-11-28 06:16:36,286 INFO:     None feature selector for col prot
2022-11-28 06:16:36,286 INFO:     None feature selector for col prot
2022-11-28 06:16:36,287 INFO:     None feature selector for col chem
2022-11-28 06:16:36,287 INFO:     None feature selector for col chem
2022-11-28 06:16:36,287 INFO:     None feature selector for col chem
2022-11-28 06:16:36,287 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:16:36,287 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:16:36,289 INFO:     Number of params in model 169651
2022-11-28 06:16:36,292 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:16:36,292 INFO:   Starting stage: TRAINING
2022-11-28 06:16:36,344 INFO:     Val loss before train {'Reaction outcome loss': 1.0173682861707427, 'Total loss': 1.0173682861707427}
2022-11-28 06:16:36,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:36,344 INFO:     Epoch: 0
2022-11-28 06:16:37,018 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6030303023078225, 'Total loss': 0.6030303023078225} | train loss {'Reaction outcome loss': 0.6870732364444597, 'Total loss': 0.6870732364444597}
2022-11-28 06:16:37,018 INFO:     Found new best model at epoch 0
2022-11-28 06:16:37,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:37,019 INFO:     Epoch: 1
2022-11-28 06:16:37,689 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5808220559900458, 'Total loss': 0.5808220559900458} | train loss {'Reaction outcome loss': 0.5938360701929702, 'Total loss': 0.5938360701929702}
2022-11-28 06:16:37,689 INFO:     Found new best model at epoch 1
2022-11-28 06:16:37,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:37,690 INFO:     Epoch: 2
2022-11-28 06:16:38,360 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.562448235397989, 'Total loss': 0.562448235397989} | train loss {'Reaction outcome loss': 0.5774467806463782, 'Total loss': 0.5774467806463782}
2022-11-28 06:16:38,360 INFO:     Found new best model at epoch 2
2022-11-28 06:16:38,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:38,361 INFO:     Epoch: 3
2022-11-28 06:16:39,029 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5697998082773252, 'Total loss': 0.5697998082773252} | train loss {'Reaction outcome loss': 0.5417449776656352, 'Total loss': 0.5417449776656352}
2022-11-28 06:16:39,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:39,029 INFO:     Epoch: 4
2022-11-28 06:16:39,698 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5158744904805314, 'Total loss': 0.5158744904805314} | train loss {'Reaction outcome loss': 0.520208398641845, 'Total loss': 0.520208398641845}
2022-11-28 06:16:39,698 INFO:     Found new best model at epoch 4
2022-11-28 06:16:39,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:39,699 INFO:     Epoch: 5
2022-11-28 06:16:40,367 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5685152408074249, 'Total loss': 0.5685152408074249} | train loss {'Reaction outcome loss': 0.5167091963020897, 'Total loss': 0.5167091963020897}
2022-11-28 06:16:40,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:40,367 INFO:     Epoch: 6
2022-11-28 06:16:41,037 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5057494806295092, 'Total loss': 0.5057494806295092} | train loss {'Reaction outcome loss': 0.5067833662636367, 'Total loss': 0.5067833662636367}
2022-11-28 06:16:41,037 INFO:     Found new best model at epoch 6
2022-11-28 06:16:41,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:41,038 INFO:     Epoch: 7
2022-11-28 06:16:41,708 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5149209407920187, 'Total loss': 0.5149209407920187} | train loss {'Reaction outcome loss': 0.49809884723381476, 'Total loss': 0.49809884723381476}
2022-11-28 06:16:41,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:41,709 INFO:     Epoch: 8
2022-11-28 06:16:42,376 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5313793454657901, 'Total loss': 0.5313793454657901} | train loss {'Reaction outcome loss': 0.49477458283727466, 'Total loss': 0.49477458283727466}
2022-11-28 06:16:42,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:42,376 INFO:     Epoch: 9
2022-11-28 06:16:43,043 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.504505914720622, 'Total loss': 0.504505914720622} | train loss {'Reaction outcome loss': 0.49785296522412703, 'Total loss': 0.49785296522412703}
2022-11-28 06:16:43,044 INFO:     Found new best model at epoch 9
2022-11-28 06:16:43,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:43,044 INFO:     Epoch: 10
2022-11-28 06:16:43,708 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47567150538617914, 'Total loss': 0.47567150538617914} | train loss {'Reaction outcome loss': 0.49276284837288414, 'Total loss': 0.49276284837288414}
2022-11-28 06:16:43,709 INFO:     Found new best model at epoch 10
2022-11-28 06:16:43,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:43,709 INFO:     Epoch: 11
2022-11-28 06:16:44,376 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.517029572616924, 'Total loss': 0.517029572616924} | train loss {'Reaction outcome loss': 0.4888473246020344, 'Total loss': 0.4888473246020344}
2022-11-28 06:16:44,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:44,376 INFO:     Epoch: 12
2022-11-28 06:16:45,044 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5058132152665745, 'Total loss': 0.5058132152665745} | train loss {'Reaction outcome loss': 0.4866065430023183, 'Total loss': 0.4866065430023183}
2022-11-28 06:16:45,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:45,044 INFO:     Epoch: 13
2022-11-28 06:16:45,708 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49001259153539484, 'Total loss': 0.49001259153539484} | train loss {'Reaction outcome loss': 0.47466370747104164, 'Total loss': 0.47466370747104164}
2022-11-28 06:16:45,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:45,708 INFO:     Epoch: 14
2022-11-28 06:16:46,376 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49239268323237245, 'Total loss': 0.49239268323237245} | train loss {'Reaction outcome loss': 0.4680714161938381, 'Total loss': 0.4680714161938381}
2022-11-28 06:16:46,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:46,376 INFO:     Epoch: 15
2022-11-28 06:16:47,043 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5004922100766138, 'Total loss': 0.5004922100766138} | train loss {'Reaction outcome loss': 0.4714638596242256, 'Total loss': 0.4714638596242256}
2022-11-28 06:16:47,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:47,043 INFO:     Epoch: 16
2022-11-28 06:16:47,712 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5225000105459582, 'Total loss': 0.5225000105459582} | train loss {'Reaction outcome loss': 0.4815951194237118, 'Total loss': 0.4815951194237118}
2022-11-28 06:16:47,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:47,712 INFO:     Epoch: 17
2022-11-28 06:16:48,379 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4730449596589262, 'Total loss': 0.4730449596589262} | train loss {'Reaction outcome loss': 0.4773462189781868, 'Total loss': 0.4773462189781868}
2022-11-28 06:16:48,379 INFO:     Found new best model at epoch 17
2022-11-28 06:16:48,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:48,380 INFO:     Epoch: 18
2022-11-28 06:16:49,046 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47092566706917505, 'Total loss': 0.47092566706917505} | train loss {'Reaction outcome loss': 0.4719846283014004, 'Total loss': 0.4719846283014004}
2022-11-28 06:16:49,046 INFO:     Found new best model at epoch 18
2022-11-28 06:16:49,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:49,047 INFO:     Epoch: 19
2022-11-28 06:16:49,719 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48283553462136874, 'Total loss': 0.48283553462136874} | train loss {'Reaction outcome loss': 0.4633134230481167, 'Total loss': 0.4633134230481167}
2022-11-28 06:16:49,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:49,719 INFO:     Epoch: 20
2022-11-28 06:16:50,383 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4960296851667491, 'Total loss': 0.4960296851667491} | train loss {'Reaction outcome loss': 0.4712736683215207, 'Total loss': 0.4712736683215207}
2022-11-28 06:16:50,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:50,383 INFO:     Epoch: 21
2022-11-28 06:16:51,046 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5317199910906228, 'Total loss': 0.5317199910906228} | train loss {'Reaction outcome loss': 0.48548635538773016, 'Total loss': 0.48548635538773016}
2022-11-28 06:16:51,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:51,046 INFO:     Epoch: 22
2022-11-28 06:16:51,713 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4975400428203019, 'Total loss': 0.4975400428203019} | train loss {'Reaction outcome loss': 0.4881290818153605, 'Total loss': 0.4881290818153605}
2022-11-28 06:16:51,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:51,713 INFO:     Epoch: 23
2022-11-28 06:16:52,378 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47157893499190157, 'Total loss': 0.47157893499190157} | train loss {'Reaction outcome loss': 0.47338237354403684, 'Total loss': 0.47338237354403684}
2022-11-28 06:16:52,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:52,379 INFO:     Epoch: 24
2022-11-28 06:16:53,040 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4832243404605172, 'Total loss': 0.4832243404605172} | train loss {'Reaction outcome loss': 0.47336518577477227, 'Total loss': 0.47336518577477227}
2022-11-28 06:16:53,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:53,040 INFO:     Epoch: 25
2022-11-28 06:16:53,698 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4926272410560738, 'Total loss': 0.4926272410560738} | train loss {'Reaction outcome loss': 0.4700771131013569, 'Total loss': 0.4700771131013569}
2022-11-28 06:16:53,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:53,699 INFO:     Epoch: 26
2022-11-28 06:16:54,358 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5129456194964322, 'Total loss': 0.5129456194964322} | train loss {'Reaction outcome loss': 0.48503635051520727, 'Total loss': 0.48503635051520727}
2022-11-28 06:16:54,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:54,359 INFO:     Epoch: 27
2022-11-28 06:16:55,022 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4813109737905589, 'Total loss': 0.4813109737905589} | train loss {'Reaction outcome loss': 0.4798171907033666, 'Total loss': 0.4798171907033666}
2022-11-28 06:16:55,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:55,022 INFO:     Epoch: 28
2022-11-28 06:16:55,684 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5284163213588975, 'Total loss': 0.5284163213588975} | train loss {'Reaction outcome loss': 0.46511486536155827, 'Total loss': 0.46511486536155827}
2022-11-28 06:16:55,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:55,684 INFO:     Epoch: 29
2022-11-28 06:16:56,347 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4774467846886678, 'Total loss': 0.4774467846886678} | train loss {'Reaction outcome loss': 0.46461066350280517, 'Total loss': 0.46461066350280517}
2022-11-28 06:16:56,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:56,348 INFO:     Epoch: 30
2022-11-28 06:16:57,011 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46399611641060223, 'Total loss': 0.46399611641060223} | train loss {'Reaction outcome loss': 0.4587573498065172, 'Total loss': 0.4587573498065172}
2022-11-28 06:16:57,011 INFO:     Found new best model at epoch 30
2022-11-28 06:16:57,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:57,012 INFO:     Epoch: 31
2022-11-28 06:16:57,680 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5022081854668531, 'Total loss': 0.5022081854668531} | train loss {'Reaction outcome loss': 0.4631535993655201, 'Total loss': 0.4631535993655201}
2022-11-28 06:16:57,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:57,681 INFO:     Epoch: 32
2022-11-28 06:16:58,344 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49678165499459614, 'Total loss': 0.49678165499459614} | train loss {'Reaction outcome loss': 0.46620208471410185, 'Total loss': 0.46620208471410185}
2022-11-28 06:16:58,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:58,345 INFO:     Epoch: 33
2022-11-28 06:16:59,007 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4684122976931659, 'Total loss': 0.4684122976931659} | train loss {'Reaction outcome loss': 0.4649112180840631, 'Total loss': 0.4649112180840631}
2022-11-28 06:16:59,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:59,007 INFO:     Epoch: 34
2022-11-28 06:16:59,665 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4879861084575003, 'Total loss': 0.4879861084575003} | train loss {'Reaction outcome loss': 0.4723572618203607, 'Total loss': 0.4723572618203607}
2022-11-28 06:16:59,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:16:59,665 INFO:     Epoch: 35
2022-11-28 06:17:00,322 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5883614319291982, 'Total loss': 0.5883614319291982} | train loss {'Reaction outcome loss': 0.47039773378536287, 'Total loss': 0.47039773378536287}
2022-11-28 06:17:00,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:00,322 INFO:     Epoch: 36
2022-11-28 06:17:00,983 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46677577461708675, 'Total loss': 0.46677577461708675} | train loss {'Reaction outcome loss': 0.4796480711715424, 'Total loss': 0.4796480711715424}
2022-11-28 06:17:00,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:00,984 INFO:     Epoch: 37
2022-11-28 06:17:01,644 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47540379586544906, 'Total loss': 0.47540379586544906} | train loss {'Reaction outcome loss': 0.4679630802348558, 'Total loss': 0.4679630802348558}
2022-11-28 06:17:01,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:01,645 INFO:     Epoch: 38
2022-11-28 06:17:02,305 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5954663787375797, 'Total loss': 0.5954663787375797} | train loss {'Reaction outcome loss': 0.4736988730276162, 'Total loss': 0.4736988730276162}
2022-11-28 06:17:02,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:02,306 INFO:     Epoch: 39
2022-11-28 06:17:02,970 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48219984566623514, 'Total loss': 0.48219984566623514} | train loss {'Reaction outcome loss': 0.47275005685173066, 'Total loss': 0.47275005685173066}
2022-11-28 06:17:02,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:02,970 INFO:     Epoch: 40
2022-11-28 06:17:03,634 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5142496194351803, 'Total loss': 0.5142496194351803} | train loss {'Reaction outcome loss': 0.4627606144197557, 'Total loss': 0.4627606144197557}
2022-11-28 06:17:03,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:03,635 INFO:     Epoch: 41
2022-11-28 06:17:04,300 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4750682122328065, 'Total loss': 0.4750682122328065} | train loss {'Reaction outcome loss': 0.47270495360076187, 'Total loss': 0.47270495360076187}
2022-11-28 06:17:04,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:04,301 INFO:     Epoch: 42
2022-11-28 06:17:04,966 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4880854172462767, 'Total loss': 0.4880854172462767} | train loss {'Reaction outcome loss': 0.46848509560229806, 'Total loss': 0.46848509560229806}
2022-11-28 06:17:04,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:04,966 INFO:     Epoch: 43
2022-11-28 06:17:05,631 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47597705640576105, 'Total loss': 0.47597705640576105} | train loss {'Reaction outcome loss': 0.46399014097400887, 'Total loss': 0.46399014097400887}
2022-11-28 06:17:05,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:05,631 INFO:     Epoch: 44
2022-11-28 06:17:06,289 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4860916252840649, 'Total loss': 0.4860916252840649} | train loss {'Reaction outcome loss': 0.4705782173736858, 'Total loss': 0.4705782173736858}
2022-11-28 06:17:06,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:06,290 INFO:     Epoch: 45
2022-11-28 06:17:06,953 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4996154345571995, 'Total loss': 0.4996154345571995} | train loss {'Reaction outcome loss': 0.4719310415539182, 'Total loss': 0.4719310415539182}
2022-11-28 06:17:06,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:06,953 INFO:     Epoch: 46
2022-11-28 06:17:07,617 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5220960344780575, 'Total loss': 0.5220960344780575} | train loss {'Reaction outcome loss': 0.4677254300609774, 'Total loss': 0.4677254300609774}
2022-11-28 06:17:07,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:07,618 INFO:     Epoch: 47
2022-11-28 06:17:08,278 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48218323358080606, 'Total loss': 0.48218323358080606} | train loss {'Reaction outcome loss': 0.4661192555840199, 'Total loss': 0.4661192555840199}
2022-11-28 06:17:08,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:08,278 INFO:     Epoch: 48
2022-11-28 06:17:08,942 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4773553799499165, 'Total loss': 0.4773553799499165} | train loss {'Reaction outcome loss': 0.47301080448907395, 'Total loss': 0.47301080448907395}
2022-11-28 06:17:08,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:08,943 INFO:     Epoch: 49
2022-11-28 06:17:09,609 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49815797433257103, 'Total loss': 0.49815797433257103} | train loss {'Reaction outcome loss': 0.465597635278335, 'Total loss': 0.465597635278335}
2022-11-28 06:17:09,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:09,609 INFO:     Epoch: 50
2022-11-28 06:17:10,276 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4831250147386031, 'Total loss': 0.4831250147386031} | train loss {'Reaction outcome loss': 0.46485011828573125, 'Total loss': 0.46485011828573125}
2022-11-28 06:17:10,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:10,276 INFO:     Epoch: 51
2022-11-28 06:17:10,940 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4693934294310483, 'Total loss': 0.4693934294310483} | train loss {'Reaction outcome loss': 0.4730509636011201, 'Total loss': 0.4730509636011201}
2022-11-28 06:17:10,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:10,941 INFO:     Epoch: 52
2022-11-28 06:17:11,603 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4742594049735503, 'Total loss': 0.4742594049735503} | train loss {'Reaction outcome loss': 0.4700863045236842, 'Total loss': 0.4700863045236842}
2022-11-28 06:17:11,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:11,603 INFO:     Epoch: 53
2022-11-28 06:17:12,266 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4976613978770646, 'Total loss': 0.4976613978770646} | train loss {'Reaction outcome loss': 0.46533088597208866, 'Total loss': 0.46533088597208866}
2022-11-28 06:17:12,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:12,266 INFO:     Epoch: 54
2022-11-28 06:17:12,927 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5032960918139328, 'Total loss': 0.5032960918139328} | train loss {'Reaction outcome loss': 0.4633106949478991, 'Total loss': 0.4633106949478991}
2022-11-28 06:17:12,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:12,928 INFO:     Epoch: 55
2022-11-28 06:17:13,593 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47300418601794675, 'Total loss': 0.47300418601794675} | train loss {'Reaction outcome loss': 0.46372378861855884, 'Total loss': 0.46372378861855884}
2022-11-28 06:17:13,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:13,594 INFO:     Epoch: 56
2022-11-28 06:17:14,256 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5058266879482702, 'Total loss': 0.5058266879482702} | train loss {'Reaction outcome loss': 0.4740826698691256, 'Total loss': 0.4740826698691256}
2022-11-28 06:17:14,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:14,256 INFO:     Epoch: 57
2022-11-28 06:17:14,917 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47808380729772826, 'Total loss': 0.47808380729772826} | train loss {'Reaction outcome loss': 0.46686791643681314, 'Total loss': 0.46686791643681314}
2022-11-28 06:17:14,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:14,918 INFO:     Epoch: 58
2022-11-28 06:17:15,581 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5059060213918035, 'Total loss': 0.5059060213918035} | train loss {'Reaction outcome loss': 0.46654168054883777, 'Total loss': 0.46654168054883777}
2022-11-28 06:17:15,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:15,581 INFO:     Epoch: 59
2022-11-28 06:17:16,246 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4609047574075786, 'Total loss': 0.4609047574075786} | train loss {'Reaction outcome loss': 0.4648020809840577, 'Total loss': 0.4648020809840577}
2022-11-28 06:17:16,246 INFO:     Found new best model at epoch 59
2022-11-28 06:17:16,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:16,247 INFO:     Epoch: 60
2022-11-28 06:17:16,914 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45578817650675774, 'Total loss': 0.45578817650675774} | train loss {'Reaction outcome loss': 0.4692958386139831, 'Total loss': 0.4692958386139831}
2022-11-28 06:17:16,914 INFO:     Found new best model at epoch 60
2022-11-28 06:17:16,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:16,915 INFO:     Epoch: 61
2022-11-28 06:17:17,580 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4827173860235648, 'Total loss': 0.4827173860235648} | train loss {'Reaction outcome loss': 0.4691892332634945, 'Total loss': 0.4691892332634945}
2022-11-28 06:17:17,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:17,580 INFO:     Epoch: 62
2022-11-28 06:17:18,243 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4614939137615941, 'Total loss': 0.4614939137615941} | train loss {'Reaction outcome loss': 0.46263048926798195, 'Total loss': 0.46263048926798195}
2022-11-28 06:17:18,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:18,243 INFO:     Epoch: 63
2022-11-28 06:17:18,905 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5123909325762228, 'Total loss': 0.5123909325762228} | train loss {'Reaction outcome loss': 0.45978707699519905, 'Total loss': 0.45978707699519905}
2022-11-28 06:17:18,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:18,905 INFO:     Epoch: 64
2022-11-28 06:17:19,567 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5105261389504779, 'Total loss': 0.5105261389504779} | train loss {'Reaction outcome loss': 0.4633570460202964, 'Total loss': 0.4633570460202964}
2022-11-28 06:17:19,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:19,567 INFO:     Epoch: 65
2022-11-28 06:17:20,230 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48393678868358786, 'Total loss': 0.48393678868358786} | train loss {'Reaction outcome loss': 0.46303459072885245, 'Total loss': 0.46303459072885245}
2022-11-28 06:17:20,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:20,230 INFO:     Epoch: 66
2022-11-28 06:17:20,892 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4779744514010169, 'Total loss': 0.4779744514010169} | train loss {'Reaction outcome loss': 0.4632903142947221, 'Total loss': 0.4632903142947221}
2022-11-28 06:17:20,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:20,893 INFO:     Epoch: 67
2022-11-28 06:17:21,557 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5036295306953517, 'Total loss': 0.5036295306953517} | train loss {'Reaction outcome loss': 0.4718760129494163, 'Total loss': 0.4718760129494163}
2022-11-28 06:17:21,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:21,558 INFO:     Epoch: 68
2022-11-28 06:17:22,222 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5067499679597941, 'Total loss': 0.5067499679597941} | train loss {'Reaction outcome loss': 0.45737391511197034, 'Total loss': 0.45737391511197034}
2022-11-28 06:17:22,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:22,223 INFO:     Epoch: 69
2022-11-28 06:17:22,885 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4852133823389357, 'Total loss': 0.4852133823389357} | train loss {'Reaction outcome loss': 0.4761359812277049, 'Total loss': 0.4761359812277049}
2022-11-28 06:17:22,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:22,885 INFO:     Epoch: 70
2022-11-28 06:17:23,546 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48850126496770163, 'Total loss': 0.48850126496770163} | train loss {'Reaction outcome loss': 0.4692647377489067, 'Total loss': 0.4692647377489067}
2022-11-28 06:17:23,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:23,546 INFO:     Epoch: 71
2022-11-28 06:17:24,209 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4708408892832019, 'Total loss': 0.4708408892832019} | train loss {'Reaction outcome loss': 0.4687781056411836, 'Total loss': 0.4687781056411836}
2022-11-28 06:17:24,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:24,210 INFO:     Epoch: 72
2022-11-28 06:17:24,869 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45989797095006163, 'Total loss': 0.45989797095006163} | train loss {'Reaction outcome loss': 0.45914950767750684, 'Total loss': 0.45914950767750684}
2022-11-28 06:17:24,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:24,869 INFO:     Epoch: 73
2022-11-28 06:17:25,532 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4763228439471938, 'Total loss': 0.4763228439471938} | train loss {'Reaction outcome loss': 0.4694489656556596, 'Total loss': 0.4694489656556596}
2022-11-28 06:17:25,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:25,533 INFO:     Epoch: 74
2022-11-28 06:17:26,199 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47206695784221997, 'Total loss': 0.47206695784221997} | train loss {'Reaction outcome loss': 0.46984653983280245, 'Total loss': 0.46984653983280245}
2022-11-28 06:17:26,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:26,199 INFO:     Epoch: 75
2022-11-28 06:17:26,864 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49769546396353026, 'Total loss': 0.49769546396353026} | train loss {'Reaction outcome loss': 0.4726654333382966, 'Total loss': 0.4726654333382966}
2022-11-28 06:17:26,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:26,864 INFO:     Epoch: 76
2022-11-28 06:17:27,527 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4812255244363438, 'Total loss': 0.4812255244363438} | train loss {'Reaction outcome loss': 0.46580434310898516, 'Total loss': 0.46580434310898516}
2022-11-28 06:17:27,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:27,527 INFO:     Epoch: 77
2022-11-28 06:17:28,193 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48367611081762746, 'Total loss': 0.48367611081762746} | train loss {'Reaction outcome loss': 0.4631489526766997, 'Total loss': 0.4631489526766997}
2022-11-28 06:17:28,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:28,193 INFO:     Epoch: 78
2022-11-28 06:17:28,857 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.477147867733782, 'Total loss': 0.477147867733782} | train loss {'Reaction outcome loss': 0.4651469541223426, 'Total loss': 0.4651469541223426}
2022-11-28 06:17:28,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:28,857 INFO:     Epoch: 79
2022-11-28 06:17:29,522 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5179666683755138, 'Total loss': 0.5179666683755138} | train loss {'Reaction outcome loss': 0.46689817755811125, 'Total loss': 0.46689817755811125}
2022-11-28 06:17:29,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:29,523 INFO:     Epoch: 80
2022-11-28 06:17:30,188 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4984914951703765, 'Total loss': 0.4984914951703765} | train loss {'Reaction outcome loss': 0.4683531795059018, 'Total loss': 0.4683531795059018}
2022-11-28 06:17:30,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:30,189 INFO:     Epoch: 81
2022-11-28 06:17:30,853 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4982735619626262, 'Total loss': 0.4982735619626262} | train loss {'Reaction outcome loss': 0.4632912234738771, 'Total loss': 0.4632912234738771}
2022-11-28 06:17:30,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:30,853 INFO:     Epoch: 82
2022-11-28 06:17:31,515 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5005098662593148, 'Total loss': 0.5005098662593148} | train loss {'Reaction outcome loss': 0.4654455187236551, 'Total loss': 0.4654455187236551}
2022-11-28 06:17:31,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:31,515 INFO:     Epoch: 83
2022-11-28 06:17:32,178 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.513371542096138, 'Total loss': 0.513371542096138} | train loss {'Reaction outcome loss': 0.46638358321025786, 'Total loss': 0.46638358321025786}
2022-11-28 06:17:32,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:32,179 INFO:     Epoch: 84
2022-11-28 06:17:32,842 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4768167148259553, 'Total loss': 0.4768167148259553} | train loss {'Reaction outcome loss': 0.4649662604397125, 'Total loss': 0.4649662604397125}
2022-11-28 06:17:32,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:32,842 INFO:     Epoch: 85
2022-11-28 06:17:33,511 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5111665319312703, 'Total loss': 0.5111665319312703} | train loss {'Reaction outcome loss': 0.4653302608416058, 'Total loss': 0.4653302608416058}
2022-11-28 06:17:33,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:33,511 INFO:     Epoch: 86
2022-11-28 06:17:34,178 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4838425489989194, 'Total loss': 0.4838425489989194} | train loss {'Reaction outcome loss': 0.4642765842951261, 'Total loss': 0.4642765842951261}
2022-11-28 06:17:34,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:34,178 INFO:     Epoch: 87
2022-11-28 06:17:34,842 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5029332536188039, 'Total loss': 0.5029332536188039} | train loss {'Reaction outcome loss': 0.4620471759303379, 'Total loss': 0.4620471759303379}
2022-11-28 06:17:34,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:34,842 INFO:     Epoch: 88
2022-11-28 06:17:35,506 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4814493016085841, 'Total loss': 0.4814493016085841} | train loss {'Reaction outcome loss': 0.47689278417753306, 'Total loss': 0.47689278417753306}
2022-11-28 06:17:35,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:35,506 INFO:     Epoch: 89
2022-11-28 06:17:36,170 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5426014431498267, 'Total loss': 0.5426014431498267} | train loss {'Reaction outcome loss': 0.470899713304844, 'Total loss': 0.470899713304844}
2022-11-28 06:17:36,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:36,170 INFO:     Epoch: 90
2022-11-28 06:17:36,833 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5308234962550077, 'Total loss': 0.5308234962550077} | train loss {'Reaction outcome loss': 0.4808236571699984, 'Total loss': 0.4808236571699984}
2022-11-28 06:17:36,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:36,835 INFO:     Epoch: 91
2022-11-28 06:17:37,500 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4614040953191844, 'Total loss': 0.4614040953191844} | train loss {'Reaction outcome loss': 0.47695961208478643, 'Total loss': 0.47695961208478643}
2022-11-28 06:17:37,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:37,500 INFO:     Epoch: 92
2022-11-28 06:17:38,167 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5034035715189847, 'Total loss': 0.5034035715189847} | train loss {'Reaction outcome loss': 0.46806288181770184, 'Total loss': 0.46806288181770184}
2022-11-28 06:17:38,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:38,167 INFO:     Epoch: 93
2022-11-28 06:17:38,831 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49373321709307755, 'Total loss': 0.49373321709307755} | train loss {'Reaction outcome loss': 0.4936087283038116, 'Total loss': 0.4936087283038116}
2022-11-28 06:17:38,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:38,832 INFO:     Epoch: 94
2022-11-28 06:17:39,492 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48875856128605927, 'Total loss': 0.48875856128605927} | train loss {'Reaction outcome loss': 0.4633929256485541, 'Total loss': 0.4633929256485541}
2022-11-28 06:17:39,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:39,493 INFO:     Epoch: 95
2022-11-28 06:17:40,150 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47217999771237373, 'Total loss': 0.47217999771237373} | train loss {'Reaction outcome loss': 0.4731861547970398, 'Total loss': 0.4731861547970398}
2022-11-28 06:17:40,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:40,150 INFO:     Epoch: 96
2022-11-28 06:17:40,812 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4803804863582958, 'Total loss': 0.4803804863582958} | train loss {'Reaction outcome loss': 0.4709104958936753, 'Total loss': 0.4709104958936753}
2022-11-28 06:17:40,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:40,813 INFO:     Epoch: 97
2022-11-28 06:17:41,478 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4828805842182853, 'Total loss': 0.4828805842182853} | train loss {'Reaction outcome loss': 0.4691732810576435, 'Total loss': 0.4691732810576435}
2022-11-28 06:17:41,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:41,478 INFO:     Epoch: 98
2022-11-28 06:17:42,140 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4844761788845062, 'Total loss': 0.4844761788845062} | train loss {'Reaction outcome loss': 0.4758815769603861, 'Total loss': 0.4758815769603861}
2022-11-28 06:17:42,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:42,141 INFO:     Epoch: 99
2022-11-28 06:17:42,804 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.484730337831107, 'Total loss': 0.484730337831107} | train loss {'Reaction outcome loss': 0.4738341682714972, 'Total loss': 0.4738341682714972}
2022-11-28 06:17:42,804 INFO:     Best model found after epoch 61 of 100.
2022-11-28 06:17:42,805 INFO:   Done with stage: TRAINING
2022-11-28 06:17:42,805 INFO:   Starting stage: EVALUATION
2022-11-28 06:17:42,924 INFO:   Done with stage: EVALUATION
2022-11-28 06:17:42,925 INFO:   Leaving out SEQ value Fold_4
2022-11-28 06:17:42,937 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:17:42,938 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:17:43,586 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:17:43,586 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:17:43,657 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:17:43,658 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:17:43,658 INFO:     No hyperparam tuning for this model
2022-11-28 06:17:43,658 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:17:43,658 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:17:43,659 INFO:     None feature selector for col prot
2022-11-28 06:17:43,659 INFO:     None feature selector for col prot
2022-11-28 06:17:43,659 INFO:     None feature selector for col prot
2022-11-28 06:17:43,659 INFO:     None feature selector for col chem
2022-11-28 06:17:43,659 INFO:     None feature selector for col chem
2022-11-28 06:17:43,659 INFO:     None feature selector for col chem
2022-11-28 06:17:43,660 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:17:43,660 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:17:43,661 INFO:     Number of params in model 169651
2022-11-28 06:17:43,664 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:17:43,664 INFO:   Starting stage: TRAINING
2022-11-28 06:17:43,716 INFO:     Val loss before train {'Reaction outcome loss': 0.9728479060259733, 'Total loss': 0.9728479060259733}
2022-11-28 06:17:43,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:43,716 INFO:     Epoch: 0
2022-11-28 06:17:44,378 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5807674703272906, 'Total loss': 0.5807674703272906} | train loss {'Reaction outcome loss': 0.6860650637217106, 'Total loss': 0.6860650637217106}
2022-11-28 06:17:44,379 INFO:     Found new best model at epoch 0
2022-11-28 06:17:44,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:44,379 INFO:     Epoch: 1
2022-11-28 06:17:45,042 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.561944701793519, 'Total loss': 0.561944701793519} | train loss {'Reaction outcome loss': 0.5980966644541871, 'Total loss': 0.5980966644541871}
2022-11-28 06:17:45,042 INFO:     Found new best model at epoch 1
2022-11-28 06:17:45,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:45,043 INFO:     Epoch: 2
2022-11-28 06:17:45,707 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5722124850885435, 'Total loss': 0.5722124850885435} | train loss {'Reaction outcome loss': 0.5620484370738268, 'Total loss': 0.5620484370738268}
2022-11-28 06:17:45,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:45,707 INFO:     Epoch: 3
2022-11-28 06:17:46,376 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5396414507519115, 'Total loss': 0.5396414507519115} | train loss {'Reaction outcome loss': 0.5428431782751314, 'Total loss': 0.5428431782751314}
2022-11-28 06:17:46,376 INFO:     Found new best model at epoch 3
2022-11-28 06:17:46,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:46,377 INFO:     Epoch: 4
2022-11-28 06:17:47,040 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5609436143528331, 'Total loss': 0.5609436143528331} | train loss {'Reaction outcome loss': 0.5195677088152978, 'Total loss': 0.5195677088152978}
2022-11-28 06:17:47,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:47,041 INFO:     Epoch: 5
2022-11-28 06:17:47,705 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4843028472228484, 'Total loss': 0.4843028472228484} | train loss {'Reaction outcome loss': 0.5193797208128437, 'Total loss': 0.5193797208128437}
2022-11-28 06:17:47,705 INFO:     Found new best model at epoch 5
2022-11-28 06:17:47,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:47,706 INFO:     Epoch: 6
2022-11-28 06:17:48,369 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47765127874233504, 'Total loss': 0.47765127874233504} | train loss {'Reaction outcome loss': 0.5078451487446024, 'Total loss': 0.5078451487446024}
2022-11-28 06:17:48,370 INFO:     Found new best model at epoch 6
2022-11-28 06:17:48,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:48,370 INFO:     Epoch: 7
2022-11-28 06:17:49,034 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47617231885140593, 'Total loss': 0.47617231885140593} | train loss {'Reaction outcome loss': 0.5036155705850932, 'Total loss': 0.5036155705850932}
2022-11-28 06:17:49,034 INFO:     Found new best model at epoch 7
2022-11-28 06:17:49,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:49,035 INFO:     Epoch: 8
2022-11-28 06:17:49,700 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47265220467339863, 'Total loss': 0.47265220467339863} | train loss {'Reaction outcome loss': 0.49684126098309794, 'Total loss': 0.49684126098309794}
2022-11-28 06:17:49,700 INFO:     Found new best model at epoch 8
2022-11-28 06:17:49,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:49,701 INFO:     Epoch: 9
2022-11-28 06:17:50,363 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4906767539002679, 'Total loss': 0.4906767539002679} | train loss {'Reaction outcome loss': 0.49910755497553655, 'Total loss': 0.49910755497553655}
2022-11-28 06:17:50,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:50,363 INFO:     Epoch: 10
2022-11-28 06:17:51,027 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49596521630883217, 'Total loss': 0.49596521630883217} | train loss {'Reaction outcome loss': 0.4900576433226947, 'Total loss': 0.4900576433226947}
2022-11-28 06:17:51,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:51,027 INFO:     Epoch: 11
2022-11-28 06:17:51,693 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5194140489805829, 'Total loss': 0.5194140489805829} | train loss {'Reaction outcome loss': 0.4883949619627768, 'Total loss': 0.4883949619627768}
2022-11-28 06:17:51,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:51,693 INFO:     Epoch: 12
2022-11-28 06:17:52,360 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46247057210315357, 'Total loss': 0.46247057210315357} | train loss {'Reaction outcome loss': 0.4827282535693338, 'Total loss': 0.4827282535693338}
2022-11-28 06:17:52,360 INFO:     Found new best model at epoch 12
2022-11-28 06:17:52,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:52,361 INFO:     Epoch: 13
2022-11-28 06:17:53,022 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5103617351163517, 'Total loss': 0.5103617351163517} | train loss {'Reaction outcome loss': 0.4816216061552686, 'Total loss': 0.4816216061552686}
2022-11-28 06:17:53,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:53,023 INFO:     Epoch: 14
2022-11-28 06:17:53,687 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4767574312334711, 'Total loss': 0.4767574312334711} | train loss {'Reaction outcome loss': 0.48581217409622285, 'Total loss': 0.48581217409622285}
2022-11-28 06:17:53,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:53,687 INFO:     Epoch: 15
2022-11-28 06:17:54,352 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4977712719277902, 'Total loss': 0.4977712719277902} | train loss {'Reaction outcome loss': 0.4743068588957671, 'Total loss': 0.4743068588957671}
2022-11-28 06:17:54,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:54,352 INFO:     Epoch: 16
2022-11-28 06:17:55,020 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4820678105408495, 'Total loss': 0.4820678105408495} | train loss {'Reaction outcome loss': 0.4787947974137722, 'Total loss': 0.4787947974137722}
2022-11-28 06:17:55,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:55,021 INFO:     Epoch: 17
2022-11-28 06:17:55,687 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4573181820186702, 'Total loss': 0.4573181820186702} | train loss {'Reaction outcome loss': 0.4719666338135158, 'Total loss': 0.4719666338135158}
2022-11-28 06:17:55,687 INFO:     Found new best model at epoch 17
2022-11-28 06:17:55,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:55,688 INFO:     Epoch: 18
2022-11-28 06:17:56,355 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45201442492279137, 'Total loss': 0.45201442492279137} | train loss {'Reaction outcome loss': 0.4765952016797758, 'Total loss': 0.4765952016797758}
2022-11-28 06:17:56,355 INFO:     Found new best model at epoch 18
2022-11-28 06:17:56,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:56,356 INFO:     Epoch: 19
2022-11-28 06:17:57,024 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4889087680388581, 'Total loss': 0.4889087680388581} | train loss {'Reaction outcome loss': 0.47128746268008986, 'Total loss': 0.47128746268008986}
2022-11-28 06:17:57,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:57,024 INFO:     Epoch: 20
2022-11-28 06:17:57,689 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48795611174269155, 'Total loss': 0.48795611174269155} | train loss {'Reaction outcome loss': 0.46334456886735653, 'Total loss': 0.46334456886735653}
2022-11-28 06:17:57,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:57,689 INFO:     Epoch: 21
2022-11-28 06:17:58,354 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5172014317729257, 'Total loss': 0.5172014317729257} | train loss {'Reaction outcome loss': 0.47012172140661745, 'Total loss': 0.47012172140661745}
2022-11-28 06:17:58,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:58,355 INFO:     Epoch: 22
2022-11-28 06:17:59,021 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5076815055852587, 'Total loss': 0.5076815055852587} | train loss {'Reaction outcome loss': 0.46946627027805776, 'Total loss': 0.46946627027805776}
2022-11-28 06:17:59,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:59,022 INFO:     Epoch: 23
2022-11-28 06:17:59,692 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4676871133798903, 'Total loss': 0.4676871133798903} | train loss {'Reaction outcome loss': 0.4652682852841193, 'Total loss': 0.4652682852841193}
2022-11-28 06:17:59,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:17:59,692 INFO:     Epoch: 24
2022-11-28 06:18:00,358 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.476838235150684, 'Total loss': 0.476838235150684} | train loss {'Reaction outcome loss': 0.47127515930802594, 'Total loss': 0.47127515930802594}
2022-11-28 06:18:00,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:00,358 INFO:     Epoch: 25
2022-11-28 06:18:01,025 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4915644309737466, 'Total loss': 0.4915644309737466} | train loss {'Reaction outcome loss': 0.4661157608272568, 'Total loss': 0.4661157608272568}
2022-11-28 06:18:01,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:01,025 INFO:     Epoch: 26
2022-11-28 06:18:01,692 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4729354286735708, 'Total loss': 0.4729354286735708} | train loss {'Reaction outcome loss': 0.47270694170748034, 'Total loss': 0.47270694170748034}
2022-11-28 06:18:01,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:01,693 INFO:     Epoch: 27
2022-11-28 06:18:02,361 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45077419958331366, 'Total loss': 0.45077419958331366} | train loss {'Reaction outcome loss': 0.4764275820925832, 'Total loss': 0.4764275820925832}
2022-11-28 06:18:02,361 INFO:     Found new best model at epoch 27
2022-11-28 06:18:02,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:02,362 INFO:     Epoch: 28
2022-11-28 06:18:03,029 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4489612951874733, 'Total loss': 0.4489612951874733} | train loss {'Reaction outcome loss': 0.45933745392868597, 'Total loss': 0.45933745392868597}
2022-11-28 06:18:03,029 INFO:     Found new best model at epoch 28
2022-11-28 06:18:03,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:03,030 INFO:     Epoch: 29
2022-11-28 06:18:03,694 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46302977813915774, 'Total loss': 0.46302977813915774} | train loss {'Reaction outcome loss': 0.4669072689308274, 'Total loss': 0.4669072689308274}
2022-11-28 06:18:03,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:03,694 INFO:     Epoch: 30
2022-11-28 06:18:04,358 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45738908648490906, 'Total loss': 0.45738908648490906} | train loss {'Reaction outcome loss': 0.46668773886537357, 'Total loss': 0.46668773886537357}
2022-11-28 06:18:04,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:04,358 INFO:     Epoch: 31
2022-11-28 06:18:05,026 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.448315984823487, 'Total loss': 0.448315984823487} | train loss {'Reaction outcome loss': 0.464969115331769, 'Total loss': 0.464969115331769}
2022-11-28 06:18:05,027 INFO:     Found new best model at epoch 31
2022-11-28 06:18:05,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:05,027 INFO:     Epoch: 32
2022-11-28 06:18:05,699 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48381834934380924, 'Total loss': 0.48381834934380924} | train loss {'Reaction outcome loss': 0.4709268340901021, 'Total loss': 0.4709268340901021}
2022-11-28 06:18:05,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:05,700 INFO:     Epoch: 33
2022-11-28 06:18:06,369 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4569806612350724, 'Total loss': 0.4569806612350724} | train loss {'Reaction outcome loss': 0.46554332490890254, 'Total loss': 0.46554332490890254}
2022-11-28 06:18:06,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:06,369 INFO:     Epoch: 34
2022-11-28 06:18:07,040 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44526601887562056, 'Total loss': 0.44526601887562056} | train loss {'Reaction outcome loss': 0.46559127164824354, 'Total loss': 0.46559127164824354}
2022-11-28 06:18:07,040 INFO:     Found new best model at epoch 34
2022-11-28 06:18:07,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:07,041 INFO:     Epoch: 35
2022-11-28 06:18:07,709 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45464232563972473, 'Total loss': 0.45464232563972473} | train loss {'Reaction outcome loss': 0.46657735433789993, 'Total loss': 0.46657735433789993}
2022-11-28 06:18:07,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:07,710 INFO:     Epoch: 36
2022-11-28 06:18:08,376 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46871359612454067, 'Total loss': 0.46871359612454067} | train loss {'Reaction outcome loss': 0.4608168019762924, 'Total loss': 0.4608168019762924}
2022-11-28 06:18:08,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:08,377 INFO:     Epoch: 37
2022-11-28 06:18:09,043 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4859127307480032, 'Total loss': 0.4859127307480032} | train loss {'Reaction outcome loss': 0.46721099533381, 'Total loss': 0.46721099533381}
2022-11-28 06:18:09,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:09,043 INFO:     Epoch: 38
2022-11-28 06:18:09,712 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46217830445278774, 'Total loss': 0.46217830445278774} | train loss {'Reaction outcome loss': 0.4678172805016079, 'Total loss': 0.4678172805016079}
2022-11-28 06:18:09,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:09,712 INFO:     Epoch: 39
2022-11-28 06:18:10,381 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4571688595143231, 'Total loss': 0.4571688595143231} | train loss {'Reaction outcome loss': 0.46252419838621733, 'Total loss': 0.46252419838621733}
2022-11-28 06:18:10,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:10,381 INFO:     Epoch: 40
2022-11-28 06:18:11,043 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4578655158931559, 'Total loss': 0.4578655158931559} | train loss {'Reaction outcome loss': 0.4656697149658876, 'Total loss': 0.4656697149658876}
2022-11-28 06:18:11,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:11,044 INFO:     Epoch: 41
2022-11-28 06:18:11,704 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4636945311318744, 'Total loss': 0.4636945311318744} | train loss {'Reaction outcome loss': 0.46875897831013125, 'Total loss': 0.46875897831013125}
2022-11-28 06:18:11,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:11,704 INFO:     Epoch: 42
2022-11-28 06:18:12,370 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48303610696034, 'Total loss': 0.48303610696034} | train loss {'Reaction outcome loss': 0.46510490919313124, 'Total loss': 0.46510490919313124}
2022-11-28 06:18:12,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:12,371 INFO:     Epoch: 43
2022-11-28 06:18:13,033 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45570279183712875, 'Total loss': 0.45570279183712875} | train loss {'Reaction outcome loss': 0.46903418794634844, 'Total loss': 0.46903418794634844}
2022-11-28 06:18:13,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:13,034 INFO:     Epoch: 44
2022-11-28 06:18:13,699 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45335206389427185, 'Total loss': 0.45335206389427185} | train loss {'Reaction outcome loss': 0.4676397984186488, 'Total loss': 0.4676397984186488}
2022-11-28 06:18:13,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:13,699 INFO:     Epoch: 45
2022-11-28 06:18:14,368 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47740003195675934, 'Total loss': 0.47740003195675934} | train loss {'Reaction outcome loss': 0.46636411649805887, 'Total loss': 0.46636411649805887}
2022-11-28 06:18:14,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:14,368 INFO:     Epoch: 46
2022-11-28 06:18:15,032 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4789815985343673, 'Total loss': 0.4789815985343673} | train loss {'Reaction outcome loss': 0.4725990152407077, 'Total loss': 0.4725990152407077}
2022-11-28 06:18:15,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:15,033 INFO:     Epoch: 47
2022-11-28 06:18:15,701 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.466209411282431, 'Total loss': 0.466209411282431} | train loss {'Reaction outcome loss': 0.4621298879144653, 'Total loss': 0.4621298879144653}
2022-11-28 06:18:15,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:15,701 INFO:     Epoch: 48
2022-11-28 06:18:16,368 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44972591542384843, 'Total loss': 0.44972591542384843} | train loss {'Reaction outcome loss': 0.46424851963116276, 'Total loss': 0.46424851963116276}
2022-11-28 06:18:16,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:16,368 INFO:     Epoch: 49
2022-11-28 06:18:17,031 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4475391774692319, 'Total loss': 0.4475391774692319} | train loss {'Reaction outcome loss': 0.4655283554907768, 'Total loss': 0.4655283554907768}
2022-11-28 06:18:17,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:17,032 INFO:     Epoch: 50
2022-11-28 06:18:17,696 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44739236851984804, 'Total loss': 0.44739236851984804} | train loss {'Reaction outcome loss': 0.4625458820692955, 'Total loss': 0.4625458820692955}
2022-11-28 06:18:17,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:17,696 INFO:     Epoch: 51
2022-11-28 06:18:18,360 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4862388568845662, 'Total loss': 0.4862388568845662} | train loss {'Reaction outcome loss': 0.46729005924275807, 'Total loss': 0.46729005924275807}
2022-11-28 06:18:18,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:18,360 INFO:     Epoch: 52
2022-11-28 06:18:19,020 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46088114414702763, 'Total loss': 0.46088114414702763} | train loss {'Reaction outcome loss': 0.4619021167558047, 'Total loss': 0.4619021167558047}
2022-11-28 06:18:19,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:19,020 INFO:     Epoch: 53
2022-11-28 06:18:19,680 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4568054188381542, 'Total loss': 0.4568054188381542} | train loss {'Reaction outcome loss': 0.4646097149459585, 'Total loss': 0.4646097149459585}
2022-11-28 06:18:19,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:19,680 INFO:     Epoch: 54
2022-11-28 06:18:20,347 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4819334457543763, 'Total loss': 0.4819334457543763} | train loss {'Reaction outcome loss': 0.467650379264547, 'Total loss': 0.467650379264547}
2022-11-28 06:18:20,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:20,347 INFO:     Epoch: 55
2022-11-28 06:18:21,013 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.476170213046399, 'Total loss': 0.476170213046399} | train loss {'Reaction outcome loss': 0.46786865357670093, 'Total loss': 0.46786865357670093}
2022-11-28 06:18:21,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:21,013 INFO:     Epoch: 56
2022-11-28 06:18:21,679 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5003130039708181, 'Total loss': 0.5003130039708181} | train loss {'Reaction outcome loss': 0.47274320734845054, 'Total loss': 0.47274320734845054}
2022-11-28 06:18:21,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:21,679 INFO:     Epoch: 57
2022-11-28 06:18:22,342 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4464163499122316, 'Total loss': 0.4464163499122316} | train loss {'Reaction outcome loss': 0.46308863271147976, 'Total loss': 0.46308863271147976}
2022-11-28 06:18:22,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:22,342 INFO:     Epoch: 58
2022-11-28 06:18:23,007 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4685113633220846, 'Total loss': 0.4685113633220846} | train loss {'Reaction outcome loss': 0.4642507040332402, 'Total loss': 0.4642507040332402}
2022-11-28 06:18:23,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:23,007 INFO:     Epoch: 59
2022-11-28 06:18:23,674 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4814016145061363, 'Total loss': 0.4814016145061363} | train loss {'Reaction outcome loss': 0.4610900896030568, 'Total loss': 0.4610900896030568}
2022-11-28 06:18:23,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:23,674 INFO:     Epoch: 60
2022-11-28 06:18:24,336 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4902346764098514, 'Total loss': 0.4902346764098514} | train loss {'Reaction outcome loss': 0.4541926702123977, 'Total loss': 0.4541926702123977}
2022-11-28 06:18:24,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:24,336 INFO:     Epoch: 61
2022-11-28 06:18:25,000 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.513871821490201, 'Total loss': 0.513871821490201} | train loss {'Reaction outcome loss': 0.46213566349639046, 'Total loss': 0.46213566349639046}
2022-11-28 06:18:25,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:25,000 INFO:     Epoch: 62
2022-11-28 06:18:25,663 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47202429615638475, 'Total loss': 0.47202429615638475} | train loss {'Reaction outcome loss': 0.47938002237389166, 'Total loss': 0.47938002237389166}
2022-11-28 06:18:25,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:25,663 INFO:     Epoch: 63
2022-11-28 06:18:26,324 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4858287220651453, 'Total loss': 0.4858287220651453} | train loss {'Reaction outcome loss': 0.46616609526738045, 'Total loss': 0.46616609526738045}
2022-11-28 06:18:26,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:26,324 INFO:     Epoch: 64
2022-11-28 06:18:26,993 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45188925991004164, 'Total loss': 0.45188925991004164} | train loss {'Reaction outcome loss': 0.4601701315973074, 'Total loss': 0.4601701315973074}
2022-11-28 06:18:26,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:26,993 INFO:     Epoch: 65
2022-11-28 06:18:27,657 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4565841064534404, 'Total loss': 0.4565841064534404} | train loss {'Reaction outcome loss': 0.46434820389315007, 'Total loss': 0.46434820389315007}
2022-11-28 06:18:27,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:27,658 INFO:     Epoch: 66
2022-11-28 06:18:28,322 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46583103693344374, 'Total loss': 0.46583103693344374} | train loss {'Reaction outcome loss': 0.4590273522922108, 'Total loss': 0.4590273522922108}
2022-11-28 06:18:28,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:28,322 INFO:     Epoch: 67
2022-11-28 06:18:28,985 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46790996668013657, 'Total loss': 0.46790996668013657} | train loss {'Reaction outcome loss': 0.4746638496796931, 'Total loss': 0.4746638496796931}
2022-11-28 06:18:28,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:28,985 INFO:     Epoch: 68
2022-11-28 06:18:29,651 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.466105807911266, 'Total loss': 0.466105807911266} | train loss {'Reaction outcome loss': 0.4612334662026936, 'Total loss': 0.4612334662026936}
2022-11-28 06:18:29,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:29,651 INFO:     Epoch: 69
2022-11-28 06:18:30,319 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47067510268904944, 'Total loss': 0.47067510268904944} | train loss {'Reaction outcome loss': 0.47170108178209874, 'Total loss': 0.47170108178209874}
2022-11-28 06:18:30,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:30,319 INFO:     Epoch: 70
2022-11-28 06:18:30,986 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4952528906816786, 'Total loss': 0.4952528906816786} | train loss {'Reaction outcome loss': 0.4633856252917359, 'Total loss': 0.4633856252917359}
2022-11-28 06:18:30,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:30,986 INFO:     Epoch: 71
2022-11-28 06:18:31,648 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4534029466184703, 'Total loss': 0.4534029466184703} | train loss {'Reaction outcome loss': 0.46675988388878686, 'Total loss': 0.46675988388878686}
2022-11-28 06:18:31,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:31,649 INFO:     Epoch: 72
2022-11-28 06:18:32,312 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46851360526951874, 'Total loss': 0.46851360526951874} | train loss {'Reaction outcome loss': 0.46621471967908645, 'Total loss': 0.46621471967908645}
2022-11-28 06:18:32,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:32,312 INFO:     Epoch: 73
2022-11-28 06:18:32,976 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47988685965538025, 'Total loss': 0.47988685965538025} | train loss {'Reaction outcome loss': 0.4669169161709086, 'Total loss': 0.4669169161709086}
2022-11-28 06:18:32,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:32,977 INFO:     Epoch: 74
2022-11-28 06:18:33,643 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49649408188733185, 'Total loss': 0.49649408188733185} | train loss {'Reaction outcome loss': 0.4633181939922994, 'Total loss': 0.4633181939922994}
2022-11-28 06:18:33,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:33,643 INFO:     Epoch: 75
2022-11-28 06:18:34,306 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48870218274268235, 'Total loss': 0.48870218274268235} | train loss {'Reaction outcome loss': 0.46285535016607854, 'Total loss': 0.46285535016607854}
2022-11-28 06:18:34,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:34,306 INFO:     Epoch: 76
2022-11-28 06:18:34,969 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45253473621877754, 'Total loss': 0.45253473621877754} | train loss {'Reaction outcome loss': 0.46936817443178547, 'Total loss': 0.46936817443178547}
2022-11-28 06:18:34,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:34,969 INFO:     Epoch: 77
2022-11-28 06:18:35,638 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4585216445001689, 'Total loss': 0.4585216445001689} | train loss {'Reaction outcome loss': 0.46283104781421924, 'Total loss': 0.46283104781421924}
2022-11-28 06:18:35,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:35,638 INFO:     Epoch: 78
2022-11-28 06:18:36,302 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4970011656934565, 'Total loss': 0.4970011656934565} | train loss {'Reaction outcome loss': 0.46478644157609633, 'Total loss': 0.46478644157609633}
2022-11-28 06:18:36,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:36,302 INFO:     Epoch: 79
2022-11-28 06:18:36,965 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4701027138666673, 'Total loss': 0.4701027138666673} | train loss {'Reaction outcome loss': 0.464850369961031, 'Total loss': 0.464850369961031}
2022-11-28 06:18:36,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:36,965 INFO:     Epoch: 80
2022-11-28 06:18:37,627 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4691275696862828, 'Total loss': 0.4691275696862828} | train loss {'Reaction outcome loss': 0.4666438623061103, 'Total loss': 0.4666438623061103}
2022-11-28 06:18:37,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:37,627 INFO:     Epoch: 81
2022-11-28 06:18:38,289 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46631042049689725, 'Total loss': 0.46631042049689725} | train loss {'Reaction outcome loss': 0.475559311858829, 'Total loss': 0.475559311858829}
2022-11-28 06:18:38,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:38,290 INFO:     Epoch: 82
2022-11-28 06:18:38,952 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47561643543568527, 'Total loss': 0.47561643543568527} | train loss {'Reaction outcome loss': 0.46385037748804014, 'Total loss': 0.46385037748804014}
2022-11-28 06:18:38,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:38,953 INFO:     Epoch: 83
2022-11-28 06:18:39,619 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48805622485550965, 'Total loss': 0.48805622485550965} | train loss {'Reaction outcome loss': 0.46421013628282853, 'Total loss': 0.46421013628282853}
2022-11-28 06:18:39,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:39,619 INFO:     Epoch: 84
2022-11-28 06:18:40,282 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4649123800071803, 'Total loss': 0.4649123800071803} | train loss {'Reaction outcome loss': 0.4645803992546374, 'Total loss': 0.4645803992546374}
2022-11-28 06:18:40,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:40,282 INFO:     Epoch: 85
2022-11-28 06:18:40,945 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45294145156036725, 'Total loss': 0.45294145156036725} | train loss {'Reaction outcome loss': 0.4688665047287941, 'Total loss': 0.4688665047287941}
2022-11-28 06:18:40,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:40,945 INFO:     Epoch: 86
2022-11-28 06:18:41,605 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46557327698577533, 'Total loss': 0.46557327698577533} | train loss {'Reaction outcome loss': 0.4754610616833933, 'Total loss': 0.4754610616833933}
2022-11-28 06:18:41,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:41,605 INFO:     Epoch: 87
2022-11-28 06:18:42,268 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4913091503761031, 'Total loss': 0.4913091503761031} | train loss {'Reaction outcome loss': 0.4596938046837045, 'Total loss': 0.4596938046837045}
2022-11-28 06:18:42,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:42,268 INFO:     Epoch: 88
2022-11-28 06:18:42,936 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5329194035042416, 'Total loss': 0.5329194035042416} | train loss {'Reaction outcome loss': 0.47398893850585144, 'Total loss': 0.47398893850585144}
2022-11-28 06:18:42,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:42,936 INFO:     Epoch: 89
2022-11-28 06:18:43,603 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4826048876751553, 'Total loss': 0.4826048876751553} | train loss {'Reaction outcome loss': 0.4629863265060609, 'Total loss': 0.4629863265060609}
2022-11-28 06:18:43,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:43,603 INFO:     Epoch: 90
2022-11-28 06:18:44,268 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4682798090983521, 'Total loss': 0.4682798090983521} | train loss {'Reaction outcome loss': 0.469707791122698, 'Total loss': 0.469707791122698}
2022-11-28 06:18:44,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:44,268 INFO:     Epoch: 91
2022-11-28 06:18:44,936 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5334436981515451, 'Total loss': 0.5334436981515451} | train loss {'Reaction outcome loss': 0.46517877893582465, 'Total loss': 0.46517877893582465}
2022-11-28 06:18:44,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:44,936 INFO:     Epoch: 92
2022-11-28 06:18:45,604 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45283459194681863, 'Total loss': 0.45283459194681863} | train loss {'Reaction outcome loss': 0.4739106093803721, 'Total loss': 0.4739106093803721}
2022-11-28 06:18:45,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:45,604 INFO:     Epoch: 93
2022-11-28 06:18:46,273 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49938700449737633, 'Total loss': 0.49938700449737633} | train loss {'Reaction outcome loss': 0.4611697531936149, 'Total loss': 0.4611697531936149}
2022-11-28 06:18:46,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:46,273 INFO:     Epoch: 94
2022-11-28 06:18:46,942 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47079172086986626, 'Total loss': 0.47079172086986626} | train loss {'Reaction outcome loss': 0.46542283652290223, 'Total loss': 0.46542283652290223}
2022-11-28 06:18:46,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:46,942 INFO:     Epoch: 95
2022-11-28 06:18:47,611 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48274036530743947, 'Total loss': 0.48274036530743947} | train loss {'Reaction outcome loss': 0.46722228554708345, 'Total loss': 0.46722228554708345}
2022-11-28 06:18:47,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:47,612 INFO:     Epoch: 96
2022-11-28 06:18:48,277 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4900990951467644, 'Total loss': 0.4900990951467644} | train loss {'Reaction outcome loss': 0.46640411539063337, 'Total loss': 0.46640411539063337}
2022-11-28 06:18:48,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:48,277 INFO:     Epoch: 97
2022-11-28 06:18:48,945 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4626318541440097, 'Total loss': 0.4626318541440097} | train loss {'Reaction outcome loss': 0.46141411598411297, 'Total loss': 0.46141411598411297}
2022-11-28 06:18:48,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:48,946 INFO:     Epoch: 98
2022-11-28 06:18:49,613 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44929975643754005, 'Total loss': 0.44929975643754005} | train loss {'Reaction outcome loss': 0.4630197997415258, 'Total loss': 0.4630197997415258}
2022-11-28 06:18:49,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:49,613 INFO:     Epoch: 99
2022-11-28 06:18:50,278 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46049419011582027, 'Total loss': 0.46049419011582027} | train loss {'Reaction outcome loss': 0.4775196705614367, 'Total loss': 0.4775196705614367}
2022-11-28 06:18:50,278 INFO:     Best model found after epoch 35 of 100.
2022-11-28 06:18:50,278 INFO:   Done with stage: TRAINING
2022-11-28 06:18:50,279 INFO:   Starting stage: EVALUATION
2022-11-28 06:18:50,392 INFO:   Done with stage: EVALUATION
2022-11-28 06:18:50,392 INFO:   Leaving out SEQ value Fold_5
2022-11-28 06:18:50,404 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 06:18:50,405 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:18:51,047 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:18:51,047 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:18:51,117 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:18:51,117 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:18:51,117 INFO:     No hyperparam tuning for this model
2022-11-28 06:18:51,117 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:18:51,117 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:18:51,118 INFO:     None feature selector for col prot
2022-11-28 06:18:51,118 INFO:     None feature selector for col prot
2022-11-28 06:18:51,118 INFO:     None feature selector for col prot
2022-11-28 06:18:51,119 INFO:     None feature selector for col chem
2022-11-28 06:18:51,119 INFO:     None feature selector for col chem
2022-11-28 06:18:51,119 INFO:     None feature selector for col chem
2022-11-28 06:18:51,119 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:18:51,119 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:18:51,120 INFO:     Number of params in model 169651
2022-11-28 06:18:51,123 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:18:51,124 INFO:   Starting stage: TRAINING
2022-11-28 06:18:51,175 INFO:     Val loss before train {'Reaction outcome loss': 0.965423812920397, 'Total loss': 0.965423812920397}
2022-11-28 06:18:51,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:51,175 INFO:     Epoch: 0
2022-11-28 06:18:51,836 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5698158378628168, 'Total loss': 0.5698158378628168} | train loss {'Reaction outcome loss': 0.6880434238180823, 'Total loss': 0.6880434238180823}
2022-11-28 06:18:51,836 INFO:     Found new best model at epoch 0
2022-11-28 06:18:51,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:51,837 INFO:     Epoch: 1
2022-11-28 06:18:52,498 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5019533976235173, 'Total loss': 0.5019533976235173} | train loss {'Reaction outcome loss': 0.5830115831019927, 'Total loss': 0.5830115831019927}
2022-11-28 06:18:52,498 INFO:     Found new best model at epoch 1
2022-11-28 06:18:52,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:52,499 INFO:     Epoch: 2
2022-11-28 06:18:53,157 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.513774449005723, 'Total loss': 0.513774449005723} | train loss {'Reaction outcome loss': 0.5459799416211186, 'Total loss': 0.5459799416211186}
2022-11-28 06:18:53,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:53,157 INFO:     Epoch: 3
2022-11-28 06:18:53,810 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.495845513926311, 'Total loss': 0.495845513926311} | train loss {'Reaction outcome loss': 0.529434238587107, 'Total loss': 0.529434238587107}
2022-11-28 06:18:53,810 INFO:     Found new best model at epoch 3
2022-11-28 06:18:53,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:53,811 INFO:     Epoch: 4
2022-11-28 06:18:54,466 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4684844541956078, 'Total loss': 0.4684844541956078} | train loss {'Reaction outcome loss': 0.5150256855755436, 'Total loss': 0.5150256855755436}
2022-11-28 06:18:54,466 INFO:     Found new best model at epoch 4
2022-11-28 06:18:54,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:54,467 INFO:     Epoch: 5
2022-11-28 06:18:55,124 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47722223130139435, 'Total loss': 0.47722223130139435} | train loss {'Reaction outcome loss': 0.5093260021842256, 'Total loss': 0.5093260021842256}
2022-11-28 06:18:55,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:55,124 INFO:     Epoch: 6
2022-11-28 06:18:55,786 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48799479041587224, 'Total loss': 0.48799479041587224} | train loss {'Reaction outcome loss': 0.4990651970006982, 'Total loss': 0.4990651970006982}
2022-11-28 06:18:55,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:55,786 INFO:     Epoch: 7
2022-11-28 06:18:56,440 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5051359635862437, 'Total loss': 0.5051359635862437} | train loss {'Reaction outcome loss': 0.5042853344459923, 'Total loss': 0.5042853344459923}
2022-11-28 06:18:56,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:56,441 INFO:     Epoch: 8
2022-11-28 06:18:57,098 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4936551482162692, 'Total loss': 0.4936551482162692} | train loss {'Reaction outcome loss': 0.48953927001174613, 'Total loss': 0.48953927001174613}
2022-11-28 06:18:57,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:57,098 INFO:     Epoch: 9
2022-11-28 06:18:57,755 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4701345667920329, 'Total loss': 0.4701345667920329} | train loss {'Reaction outcome loss': 0.4858670062556559, 'Total loss': 0.4858670062556559}
2022-11-28 06:18:57,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:57,756 INFO:     Epoch: 10
2022-11-28 06:18:58,414 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4693531859666109, 'Total loss': 0.4693531859666109} | train loss {'Reaction outcome loss': 0.47958900773403595, 'Total loss': 0.47958900773403595}
2022-11-28 06:18:58,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:58,414 INFO:     Epoch: 11
2022-11-28 06:18:59,073 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45085895603353326, 'Total loss': 0.45085895603353326} | train loss {'Reaction outcome loss': 0.48051939332971766, 'Total loss': 0.48051939332971766}
2022-11-28 06:18:59,073 INFO:     Found new best model at epoch 11
2022-11-28 06:18:59,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:59,074 INFO:     Epoch: 12
2022-11-28 06:18:59,732 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4571776149625128, 'Total loss': 0.4571776149625128} | train loss {'Reaction outcome loss': 0.48373983523675373, 'Total loss': 0.48373983523675373}
2022-11-28 06:18:59,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:18:59,733 INFO:     Epoch: 13
2022-11-28 06:19:00,388 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5200811346823518, 'Total loss': 0.5200811346823518} | train loss {'Reaction outcome loss': 0.46746731187616075, 'Total loss': 0.46746731187616075}
2022-11-28 06:19:00,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:00,388 INFO:     Epoch: 14
2022-11-28 06:19:01,042 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45626947012814606, 'Total loss': 0.45626947012814606} | train loss {'Reaction outcome loss': 0.47415598007489224, 'Total loss': 0.47415598007489224}
2022-11-28 06:19:01,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:01,042 INFO:     Epoch: 15
2022-11-28 06:19:01,698 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.448206847702915, 'Total loss': 0.448206847702915} | train loss {'Reaction outcome loss': 0.46838702547306915, 'Total loss': 0.46838702547306915}
2022-11-28 06:19:01,698 INFO:     Found new best model at epoch 15
2022-11-28 06:19:01,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:01,699 INFO:     Epoch: 16
2022-11-28 06:19:02,353 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4573434107005596, 'Total loss': 0.4573434107005596} | train loss {'Reaction outcome loss': 0.4689947446998285, 'Total loss': 0.4689947446998285}
2022-11-28 06:19:02,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:02,353 INFO:     Epoch: 17
2022-11-28 06:19:03,010 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4206399360502308, 'Total loss': 0.4206399360502308} | train loss {'Reaction outcome loss': 0.47373499134365393, 'Total loss': 0.47373499134365393}
2022-11-28 06:19:03,010 INFO:     Found new best model at epoch 17
2022-11-28 06:19:03,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:03,011 INFO:     Epoch: 18
2022-11-28 06:19:03,665 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44746512750333006, 'Total loss': 0.44746512750333006} | train loss {'Reaction outcome loss': 0.4627227141540878, 'Total loss': 0.4627227141540878}
2022-11-28 06:19:03,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:03,666 INFO:     Epoch: 19
2022-11-28 06:19:04,319 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44780130007050256, 'Total loss': 0.44780130007050256} | train loss {'Reaction outcome loss': 0.4635214183403521, 'Total loss': 0.4635214183403521}
2022-11-28 06:19:04,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:04,319 INFO:     Epoch: 20
2022-11-28 06:19:04,974 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4519520869097588, 'Total loss': 0.4519520869097588} | train loss {'Reaction outcome loss': 0.46634827834002823, 'Total loss': 0.46634827834002823}
2022-11-28 06:19:04,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:04,975 INFO:     Epoch: 21
2022-11-28 06:19:05,629 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47258526290004904, 'Total loss': 0.47258526290004904} | train loss {'Reaction outcome loss': 0.4663018495452647, 'Total loss': 0.4663018495452647}
2022-11-28 06:19:05,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:05,629 INFO:     Epoch: 22
2022-11-28 06:19:06,284 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4198708436028524, 'Total loss': 0.4198708436028524} | train loss {'Reaction outcome loss': 0.4668793813306458, 'Total loss': 0.4668793813306458}
2022-11-28 06:19:06,284 INFO:     Found new best model at epoch 22
2022-11-28 06:19:06,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:06,285 INFO:     Epoch: 23
2022-11-28 06:19:06,938 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4627130417661233, 'Total loss': 0.4627130417661233} | train loss {'Reaction outcome loss': 0.460342286253462, 'Total loss': 0.460342286253462}
2022-11-28 06:19:06,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:06,938 INFO:     Epoch: 24
2022-11-28 06:19:07,593 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45680943165313115, 'Total loss': 0.45680943165313115} | train loss {'Reaction outcome loss': 0.46495436314417393, 'Total loss': 0.46495436314417393}
2022-11-28 06:19:07,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:07,594 INFO:     Epoch: 25
2022-11-28 06:19:08,249 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4666588922793215, 'Total loss': 0.4666588922793215} | train loss {'Reaction outcome loss': 0.45942869137744513, 'Total loss': 0.45942869137744513}
2022-11-28 06:19:08,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:08,249 INFO:     Epoch: 26
2022-11-28 06:19:08,906 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4607848403128711, 'Total loss': 0.4607848403128711} | train loss {'Reaction outcome loss': 0.4610266248182375, 'Total loss': 0.4610266248182375}
2022-11-28 06:19:08,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:08,906 INFO:     Epoch: 27
2022-11-28 06:19:09,566 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4650649990547787, 'Total loss': 0.4650649990547787} | train loss {'Reaction outcome loss': 0.4632421935091213, 'Total loss': 0.4632421935091213}
2022-11-28 06:19:09,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:09,567 INFO:     Epoch: 28
2022-11-28 06:19:10,223 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4619294103573669, 'Total loss': 0.4619294103573669} | train loss {'Reaction outcome loss': 0.45366545514184603, 'Total loss': 0.45366545514184603}
2022-11-28 06:19:10,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:10,224 INFO:     Epoch: 29
2022-11-28 06:19:10,881 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47883716970682144, 'Total loss': 0.47883716970682144} | train loss {'Reaction outcome loss': 0.4536984468601188, 'Total loss': 0.4536984468601188}
2022-11-28 06:19:10,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:10,881 INFO:     Epoch: 30
2022-11-28 06:19:11,543 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43223855301568453, 'Total loss': 0.43223855301568453} | train loss {'Reaction outcome loss': 0.4657642937436396, 'Total loss': 0.4657642937436396}
2022-11-28 06:19:11,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:11,544 INFO:     Epoch: 31
2022-11-28 06:19:12,203 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4564794891259887, 'Total loss': 0.4564794891259887} | train loss {'Reaction outcome loss': 0.4468459842460496, 'Total loss': 0.4468459842460496}
2022-11-28 06:19:12,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:12,203 INFO:     Epoch: 32
2022-11-28 06:19:12,862 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4519306489012458, 'Total loss': 0.4519306489012458} | train loss {'Reaction outcome loss': 0.4604781765110639, 'Total loss': 0.4604781765110639}
2022-11-28 06:19:12,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:12,862 INFO:     Epoch: 33
2022-11-28 06:19:13,520 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41847330975261604, 'Total loss': 0.41847330975261604} | train loss {'Reaction outcome loss': 0.4619456572800266, 'Total loss': 0.4619456572800266}
2022-11-28 06:19:13,520 INFO:     Found new best model at epoch 33
2022-11-28 06:19:13,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:13,521 INFO:     Epoch: 34
2022-11-28 06:19:14,185 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4459913372993469, 'Total loss': 0.4459913372993469} | train loss {'Reaction outcome loss': 0.4644632145154233, 'Total loss': 0.4644632145154233}
2022-11-28 06:19:14,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:14,185 INFO:     Epoch: 35
2022-11-28 06:19:14,846 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44585253366015176, 'Total loss': 0.44585253366015176} | train loss {'Reaction outcome loss': 0.453703014309309, 'Total loss': 0.453703014309309}
2022-11-28 06:19:14,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:14,846 INFO:     Epoch: 36
2022-11-28 06:19:15,510 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4559221023863012, 'Total loss': 0.4559221023863012} | train loss {'Reaction outcome loss': 0.45441221327197795, 'Total loss': 0.45441221327197795}
2022-11-28 06:19:15,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:15,511 INFO:     Epoch: 37
2022-11-28 06:19:16,172 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4497527259994637, 'Total loss': 0.4497527259994637} | train loss {'Reaction outcome loss': 0.4612265384927088, 'Total loss': 0.4612265384927088}
2022-11-28 06:19:16,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:16,172 INFO:     Epoch: 38
2022-11-28 06:19:16,831 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4360485557805408, 'Total loss': 0.4360485557805408} | train loss {'Reaction outcome loss': 0.4557858905013727, 'Total loss': 0.4557858905013727}
2022-11-28 06:19:16,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:16,832 INFO:     Epoch: 39
2022-11-28 06:19:17,492 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5024099803783677, 'Total loss': 0.5024099803783677} | train loss {'Reaction outcome loss': 0.45873200437244105, 'Total loss': 0.45873200437244105}
2022-11-28 06:19:17,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:17,492 INFO:     Epoch: 40
2022-11-28 06:19:18,155 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45956363156437874, 'Total loss': 0.45956363156437874} | train loss {'Reaction outcome loss': 0.45792914443478294, 'Total loss': 0.45792914443478294}
2022-11-28 06:19:18,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:18,155 INFO:     Epoch: 41
2022-11-28 06:19:18,812 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44011761383576825, 'Total loss': 0.44011761383576825} | train loss {'Reaction outcome loss': 0.4659665146652533, 'Total loss': 0.4659665146652533}
2022-11-28 06:19:18,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:18,812 INFO:     Epoch: 42
2022-11-28 06:19:19,466 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4304730096323924, 'Total loss': 0.4304730096323924} | train loss {'Reaction outcome loss': 0.4561943791958751, 'Total loss': 0.4561943791958751}
2022-11-28 06:19:19,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:19,466 INFO:     Epoch: 43
2022-11-28 06:19:20,123 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44425126469948073, 'Total loss': 0.44425126469948073} | train loss {'Reaction outcome loss': 0.4494523342166628, 'Total loss': 0.4494523342166628}
2022-11-28 06:19:20,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:20,123 INFO:     Epoch: 44
2022-11-28 06:19:20,779 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42702110213312233, 'Total loss': 0.42702110213312233} | train loss {'Reaction outcome loss': 0.45943825707143665, 'Total loss': 0.45943825707143665}
2022-11-28 06:19:20,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:20,779 INFO:     Epoch: 45
2022-11-28 06:19:21,433 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44628151235255326, 'Total loss': 0.44628151235255326} | train loss {'Reaction outcome loss': 0.4543295570174042, 'Total loss': 0.4543295570174042}
2022-11-28 06:19:21,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:21,433 INFO:     Epoch: 46
2022-11-28 06:19:22,090 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4248226122422652, 'Total loss': 0.4248226122422652} | train loss {'Reaction outcome loss': 0.4573090120541806, 'Total loss': 0.4573090120541806}
2022-11-28 06:19:22,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:22,090 INFO:     Epoch: 47
2022-11-28 06:19:22,745 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4870149405165152, 'Total loss': 0.4870149405165152} | train loss {'Reaction outcome loss': 0.4590816261816998, 'Total loss': 0.4590816261816998}
2022-11-28 06:19:22,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:22,745 INFO:     Epoch: 48
2022-11-28 06:19:23,406 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4480103635313836, 'Total loss': 0.4480103635313836} | train loss {'Reaction outcome loss': 0.4629823866243265, 'Total loss': 0.4629823866243265}
2022-11-28 06:19:23,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:23,407 INFO:     Epoch: 49
2022-11-28 06:19:24,066 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45841693615710194, 'Total loss': 0.45841693615710194} | train loss {'Reaction outcome loss': 0.4549687108823231, 'Total loss': 0.4549687108823231}
2022-11-28 06:19:24,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:24,067 INFO:     Epoch: 50
2022-11-28 06:19:24,733 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4526710503480651, 'Total loss': 0.4526710503480651} | train loss {'Reaction outcome loss': 0.457578349660854, 'Total loss': 0.457578349660854}
2022-11-28 06:19:24,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:24,733 INFO:     Epoch: 51
2022-11-28 06:19:25,397 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42392696033824573, 'Total loss': 0.42392696033824573} | train loss {'Reaction outcome loss': 0.4538561043690662, 'Total loss': 0.4538561043690662}
2022-11-28 06:19:25,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:25,397 INFO:     Epoch: 52
2022-11-28 06:19:26,055 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43507542325691745, 'Total loss': 0.43507542325691745} | train loss {'Reaction outcome loss': 0.4595864815371377, 'Total loss': 0.4595864815371377}
2022-11-28 06:19:26,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:26,056 INFO:     Epoch: 53
2022-11-28 06:19:26,712 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.454695720246739, 'Total loss': 0.454695720246739} | train loss {'Reaction outcome loss': 0.4511739422472156, 'Total loss': 0.4511739422472156}
2022-11-28 06:19:26,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:26,712 INFO:     Epoch: 54
2022-11-28 06:19:27,368 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44021704293448816, 'Total loss': 0.44021704293448816} | train loss {'Reaction outcome loss': 0.4594896787283372, 'Total loss': 0.4594896787283372}
2022-11-28 06:19:27,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:27,368 INFO:     Epoch: 55
2022-11-28 06:19:28,021 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44027915834025905, 'Total loss': 0.44027915834025905} | train loss {'Reaction outcome loss': 0.4536660010717353, 'Total loss': 0.4536660010717353}
2022-11-28 06:19:28,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:28,021 INFO:     Epoch: 56
2022-11-28 06:19:28,678 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4210815998640927, 'Total loss': 0.4210815998640927} | train loss {'Reaction outcome loss': 0.4617533920066697, 'Total loss': 0.4617533920066697}
2022-11-28 06:19:28,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:28,678 INFO:     Epoch: 57
2022-11-28 06:19:29,336 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46663097935644066, 'Total loss': 0.46663097935644066} | train loss {'Reaction outcome loss': 0.44968113406580323, 'Total loss': 0.44968113406580323}
2022-11-28 06:19:29,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:29,337 INFO:     Epoch: 58
2022-11-28 06:19:29,993 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4251125803725286, 'Total loss': 0.4251125803725286} | train loss {'Reaction outcome loss': 0.45516377079243564, 'Total loss': 0.45516377079243564}
2022-11-28 06:19:29,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:29,993 INFO:     Epoch: 59
2022-11-28 06:19:30,647 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44035181538625195, 'Total loss': 0.44035181538625195} | train loss {'Reaction outcome loss': 0.45976855526773297, 'Total loss': 0.45976855526773297}
2022-11-28 06:19:30,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:30,647 INFO:     Epoch: 60
2022-11-28 06:19:31,303 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4885092657059431, 'Total loss': 0.4885092657059431} | train loss {'Reaction outcome loss': 0.4571121840148556, 'Total loss': 0.4571121840148556}
2022-11-28 06:19:31,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:31,303 INFO:     Epoch: 61
2022-11-28 06:19:31,958 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4496386315334927, 'Total loss': 0.4496386315334927} | train loss {'Reaction outcome loss': 0.455318841186105, 'Total loss': 0.455318841186105}
2022-11-28 06:19:31,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:31,958 INFO:     Epoch: 62
2022-11-28 06:19:32,613 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4329044978049668, 'Total loss': 0.4329044978049668} | train loss {'Reaction outcome loss': 0.44869350641965866, 'Total loss': 0.44869350641965866}
2022-11-28 06:19:32,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:32,613 INFO:     Epoch: 63
2022-11-28 06:19:33,268 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4464258402585983, 'Total loss': 0.4464258402585983} | train loss {'Reaction outcome loss': 0.4519379734080665, 'Total loss': 0.4519379734080665}
2022-11-28 06:19:33,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:33,268 INFO:     Epoch: 64
2022-11-28 06:19:33,927 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43632346171547065, 'Total loss': 0.43632346171547065} | train loss {'Reaction outcome loss': 0.44944476600812405, 'Total loss': 0.44944476600812405}
2022-11-28 06:19:33,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:33,928 INFO:     Epoch: 65
2022-11-28 06:19:34,585 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4301606388762593, 'Total loss': 0.4301606388762593} | train loss {'Reaction outcome loss': 0.4589652339110569, 'Total loss': 0.4589652339110569}
2022-11-28 06:19:34,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:34,586 INFO:     Epoch: 66
2022-11-28 06:19:35,244 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46867691623893654, 'Total loss': 0.46867691623893654} | train loss {'Reaction outcome loss': 0.4526763379573822, 'Total loss': 0.4526763379573822}
2022-11-28 06:19:35,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:35,245 INFO:     Epoch: 67
2022-11-28 06:19:35,902 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45060155337507074, 'Total loss': 0.45060155337507074} | train loss {'Reaction outcome loss': 0.4594754435578171, 'Total loss': 0.4594754435578171}
2022-11-28 06:19:35,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:35,902 INFO:     Epoch: 68
2022-11-28 06:19:36,561 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48372287989001383, 'Total loss': 0.48372287989001383} | train loss {'Reaction outcome loss': 0.45824435858093965, 'Total loss': 0.45824435858093965}
2022-11-28 06:19:36,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:36,561 INFO:     Epoch: 69
2022-11-28 06:19:37,221 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46635046787559986, 'Total loss': 0.46635046787559986} | train loss {'Reaction outcome loss': 0.4549545330052473, 'Total loss': 0.4549545330052473}
2022-11-28 06:19:37,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:37,221 INFO:     Epoch: 70
2022-11-28 06:19:37,879 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4489981220527129, 'Total loss': 0.4489981220527129} | train loss {'Reaction outcome loss': 0.46000562146001933, 'Total loss': 0.46000562146001933}
2022-11-28 06:19:37,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:37,880 INFO:     Epoch: 71
2022-11-28 06:19:38,538 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41962157596241345, 'Total loss': 0.41962157596241345} | train loss {'Reaction outcome loss': 0.45738507150387275, 'Total loss': 0.45738507150387275}
2022-11-28 06:19:38,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:38,538 INFO:     Epoch: 72
2022-11-28 06:19:39,201 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4678587920286439, 'Total loss': 0.4678587920286439} | train loss {'Reaction outcome loss': 0.4527995192274755, 'Total loss': 0.4527995192274755}
2022-11-28 06:19:39,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:39,201 INFO:     Epoch: 73
2022-11-28 06:19:39,860 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44599737193096767, 'Total loss': 0.44599737193096767} | train loss {'Reaction outcome loss': 0.45919399684181017, 'Total loss': 0.45919399684181017}
2022-11-28 06:19:39,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:39,860 INFO:     Epoch: 74
2022-11-28 06:19:40,517 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4624791751531037, 'Total loss': 0.4624791751531037} | train loss {'Reaction outcome loss': 0.4506841129794413, 'Total loss': 0.4506841129794413}
2022-11-28 06:19:40,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:40,517 INFO:     Epoch: 75
2022-11-28 06:19:41,178 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4582184072245251, 'Total loss': 0.4582184072245251} | train loss {'Reaction outcome loss': 0.4525036395508416, 'Total loss': 0.4525036395508416}
2022-11-28 06:19:41,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:41,180 INFO:     Epoch: 76
2022-11-28 06:19:41,838 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4804668521339243, 'Total loss': 0.4804668521339243} | train loss {'Reaction outcome loss': 0.45089372220088025, 'Total loss': 0.45089372220088025}
2022-11-28 06:19:41,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:41,839 INFO:     Epoch: 77
2022-11-28 06:19:42,494 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4397209386595271, 'Total loss': 0.4397209386595271} | train loss {'Reaction outcome loss': 0.45588473604649915, 'Total loss': 0.45588473604649915}
2022-11-28 06:19:42,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:42,495 INFO:     Epoch: 78
2022-11-28 06:19:43,156 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4489982097663663, 'Total loss': 0.4489982097663663} | train loss {'Reaction outcome loss': 0.4497799632500629, 'Total loss': 0.4497799632500629}
2022-11-28 06:19:43,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:43,156 INFO:     Epoch: 79
2022-11-28 06:19:43,818 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4259925985878164, 'Total loss': 0.4259925985878164} | train loss {'Reaction outcome loss': 0.4569401980662832, 'Total loss': 0.4569401980662832}
2022-11-28 06:19:43,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:43,819 INFO:     Epoch: 80
2022-11-28 06:19:44,477 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4144682222130624, 'Total loss': 0.4144682222130624} | train loss {'Reaction outcome loss': 0.45849554447495205, 'Total loss': 0.45849554447495205}
2022-11-28 06:19:44,477 INFO:     Found new best model at epoch 80
2022-11-28 06:19:44,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:44,478 INFO:     Epoch: 81
2022-11-28 06:19:45,133 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46711263941092923, 'Total loss': 0.46711263941092923} | train loss {'Reaction outcome loss': 0.44605865791744115, 'Total loss': 0.44605865791744115}
2022-11-28 06:19:45,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:45,134 INFO:     Epoch: 82
2022-11-28 06:19:45,793 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43455079434947536, 'Total loss': 0.43455079434947536} | train loss {'Reaction outcome loss': 0.45954610553323005, 'Total loss': 0.45954610553323005}
2022-11-28 06:19:45,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:45,793 INFO:     Epoch: 83
2022-11-28 06:19:46,452 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4263567084615881, 'Total loss': 0.4263567084615881} | train loss {'Reaction outcome loss': 0.45210749208927153, 'Total loss': 0.45210749208927153}
2022-11-28 06:19:46,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:46,453 INFO:     Epoch: 84
2022-11-28 06:19:47,108 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4268455363132737, 'Total loss': 0.4268455363132737} | train loss {'Reaction outcome loss': 0.4526054081868152, 'Total loss': 0.4526054081868152}
2022-11-28 06:19:47,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:47,109 INFO:     Epoch: 85
2022-11-28 06:19:47,761 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41677656735886226, 'Total loss': 0.41677656735886226} | train loss {'Reaction outcome loss': 0.4600426679211003, 'Total loss': 0.4600426679211003}
2022-11-28 06:19:47,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:47,762 INFO:     Epoch: 86
2022-11-28 06:19:48,417 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42038398269902577, 'Total loss': 0.42038398269902577} | train loss {'Reaction outcome loss': 0.4490853270705865, 'Total loss': 0.4490853270705865}
2022-11-28 06:19:48,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:48,417 INFO:     Epoch: 87
2022-11-28 06:19:49,073 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43604250049049204, 'Total loss': 0.43604250049049204} | train loss {'Reaction outcome loss': 0.4498706803029897, 'Total loss': 0.4498706803029897}
2022-11-28 06:19:49,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:49,073 INFO:     Epoch: 88
2022-11-28 06:19:49,732 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4496379206803712, 'Total loss': 0.4496379206803712} | train loss {'Reaction outcome loss': 0.4488680436294906, 'Total loss': 0.4488680436294906}
2022-11-28 06:19:49,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:49,733 INFO:     Epoch: 89
2022-11-28 06:19:50,388 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4208153635263443, 'Total loss': 0.4208153635263443} | train loss {'Reaction outcome loss': 0.4615664204164427, 'Total loss': 0.4615664204164427}
2022-11-28 06:19:50,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:50,388 INFO:     Epoch: 90
2022-11-28 06:19:51,042 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44668963145125995, 'Total loss': 0.44668963145125995} | train loss {'Reaction outcome loss': 0.45952671635515835, 'Total loss': 0.45952671635515835}
2022-11-28 06:19:51,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:51,042 INFO:     Epoch: 91
2022-11-28 06:19:51,698 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4354582564397292, 'Total loss': 0.4354582564397292} | train loss {'Reaction outcome loss': 0.4596848396014194, 'Total loss': 0.4596848396014194}
2022-11-28 06:19:51,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:51,699 INFO:     Epoch: 92
2022-11-28 06:19:52,353 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4721869277683171, 'Total loss': 0.4721869277683171} | train loss {'Reaction outcome loss': 0.4538035220029403, 'Total loss': 0.4538035220029403}
2022-11-28 06:19:52,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:52,354 INFO:     Epoch: 93
2022-11-28 06:19:53,010 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4437013099139387, 'Total loss': 0.4437013099139387} | train loss {'Reaction outcome loss': 0.4575951248711469, 'Total loss': 0.4575951248711469}
2022-11-28 06:19:53,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:53,010 INFO:     Epoch: 94
2022-11-28 06:19:53,664 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4495091119950468, 'Total loss': 0.4495091119950468} | train loss {'Reaction outcome loss': 0.4506173633799261, 'Total loss': 0.4506173633799261}
2022-11-28 06:19:53,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:53,665 INFO:     Epoch: 95
2022-11-28 06:19:54,318 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4394339624453675, 'Total loss': 0.4394339624453675} | train loss {'Reaction outcome loss': 0.4567641421848414, 'Total loss': 0.4567641421848414}
2022-11-28 06:19:54,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:54,318 INFO:     Epoch: 96
2022-11-28 06:19:54,974 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45578948577696626, 'Total loss': 0.45578948577696626} | train loss {'Reaction outcome loss': 0.45749547472413704, 'Total loss': 0.45749547472413704}
2022-11-28 06:19:54,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:54,974 INFO:     Epoch: 97
2022-11-28 06:19:55,627 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4420507394454696, 'Total loss': 0.4420507394454696} | train loss {'Reaction outcome loss': 0.45664666130834697, 'Total loss': 0.45664666130834697}
2022-11-28 06:19:55,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:55,628 INFO:     Epoch: 98
2022-11-28 06:19:56,281 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43363677473230794, 'Total loss': 0.43363677473230794} | train loss {'Reaction outcome loss': 0.4513322565628558, 'Total loss': 0.4513322565628558}
2022-11-28 06:19:56,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:56,281 INFO:     Epoch: 99
2022-11-28 06:19:56,930 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4513960528102788, 'Total loss': 0.4513960528102788} | train loss {'Reaction outcome loss': 0.4547805263071644, 'Total loss': 0.4547805263071644}
2022-11-28 06:19:56,930 INFO:     Best model found after epoch 81 of 100.
2022-11-28 06:19:56,930 INFO:   Done with stage: TRAINING
2022-11-28 06:19:56,931 INFO:   Starting stage: EVALUATION
2022-11-28 06:19:57,054 INFO:   Done with stage: EVALUATION
2022-11-28 06:19:57,054 INFO:   Leaving out SEQ value Fold_6
2022-11-28 06:19:57,066 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 06:19:57,066 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:19:57,700 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:19:57,700 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:19:57,768 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:19:57,768 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:19:57,769 INFO:     No hyperparam tuning for this model
2022-11-28 06:19:57,769 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:19:57,769 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:19:57,769 INFO:     None feature selector for col prot
2022-11-28 06:19:57,769 INFO:     None feature selector for col prot
2022-11-28 06:19:57,770 INFO:     None feature selector for col prot
2022-11-28 06:19:57,770 INFO:     None feature selector for col chem
2022-11-28 06:19:57,770 INFO:     None feature selector for col chem
2022-11-28 06:19:57,770 INFO:     None feature selector for col chem
2022-11-28 06:19:57,770 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:19:57,770 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:19:57,772 INFO:     Number of params in model 169651
2022-11-28 06:19:57,775 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:19:57,775 INFO:   Starting stage: TRAINING
2022-11-28 06:19:57,825 INFO:     Val loss before train {'Reaction outcome loss': 1.0242105902627456, 'Total loss': 1.0242105902627456}
2022-11-28 06:19:57,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:57,825 INFO:     Epoch: 0
2022-11-28 06:19:58,478 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7245228824227355, 'Total loss': 0.7245228824227355} | train loss {'Reaction outcome loss': 0.6764254198699701, 'Total loss': 0.6764254198699701}
2022-11-28 06:19:58,478 INFO:     Found new best model at epoch 0
2022-11-28 06:19:58,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:58,479 INFO:     Epoch: 1
2022-11-28 06:19:59,131 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5707813161750173, 'Total loss': 0.5707813161750173} | train loss {'Reaction outcome loss': 0.5853465534135943, 'Total loss': 0.5853465534135943}
2022-11-28 06:19:59,131 INFO:     Found new best model at epoch 1
2022-11-28 06:19:59,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:59,132 INFO:     Epoch: 2
2022-11-28 06:19:59,781 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5839199132697527, 'Total loss': 0.5839199132697527} | train loss {'Reaction outcome loss': 0.5578779633172223, 'Total loss': 0.5578779633172223}
2022-11-28 06:19:59,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:19:59,782 INFO:     Epoch: 3
2022-11-28 06:20:00,431 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5699142058228337, 'Total loss': 0.5699142058228337} | train loss {'Reaction outcome loss': 0.5297161608201558, 'Total loss': 0.5297161608201558}
2022-11-28 06:20:00,431 INFO:     Found new best model at epoch 3
2022-11-28 06:20:00,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:00,432 INFO:     Epoch: 4
2022-11-28 06:20:01,082 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5861892575441405, 'Total loss': 0.5861892575441405} | train loss {'Reaction outcome loss': 0.5229046758813937, 'Total loss': 0.5229046758813937}
2022-11-28 06:20:01,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:01,082 INFO:     Epoch: 5
2022-11-28 06:20:01,735 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5543447531933008, 'Total loss': 0.5543447531933008} | train loss {'Reaction outcome loss': 0.5051632667051964, 'Total loss': 0.5051632667051964}
2022-11-28 06:20:01,735 INFO:     Found new best model at epoch 5
2022-11-28 06:20:01,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:01,736 INFO:     Epoch: 6
2022-11-28 06:20:02,390 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5373361235441163, 'Total loss': 0.5373361235441163} | train loss {'Reaction outcome loss': 0.5011146021548842, 'Total loss': 0.5011146021548842}
2022-11-28 06:20:02,390 INFO:     Found new best model at epoch 6
2022-11-28 06:20:02,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:02,391 INFO:     Epoch: 7
2022-11-28 06:20:03,041 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5416584056477214, 'Total loss': 0.5416584056477214} | train loss {'Reaction outcome loss': 0.4918868875161546, 'Total loss': 0.4918868875161546}
2022-11-28 06:20:03,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:03,041 INFO:     Epoch: 8
2022-11-28 06:20:03,689 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5343920179577761, 'Total loss': 0.5343920179577761} | train loss {'Reaction outcome loss': 0.5017921016475216, 'Total loss': 0.5017921016475216}
2022-11-28 06:20:03,690 INFO:     Found new best model at epoch 8
2022-11-28 06:20:03,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:03,690 INFO:     Epoch: 9
2022-11-28 06:20:04,340 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5162664350382117, 'Total loss': 0.5162664350382117} | train loss {'Reaction outcome loss': 0.48838752630304116, 'Total loss': 0.48838752630304116}
2022-11-28 06:20:04,340 INFO:     Found new best model at epoch 9
2022-11-28 06:20:04,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:04,341 INFO:     Epoch: 10
2022-11-28 06:20:04,992 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5211908391048742, 'Total loss': 0.5211908391048742} | train loss {'Reaction outcome loss': 0.4934827864292215, 'Total loss': 0.4934827864292215}
2022-11-28 06:20:04,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:04,993 INFO:     Epoch: 11
2022-11-28 06:20:05,645 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5169380542843841, 'Total loss': 0.5169380542843841} | train loss {'Reaction outcome loss': 0.49101506106433324, 'Total loss': 0.49101506106433324}
2022-11-28 06:20:05,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:05,645 INFO:     Epoch: 12
2022-11-28 06:20:06,297 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.525501967862595, 'Total loss': 0.525501967862595} | train loss {'Reaction outcome loss': 0.4897654619006837, 'Total loss': 0.4897654619006837}
2022-11-28 06:20:06,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:06,297 INFO:     Epoch: 13
2022-11-28 06:20:06,957 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5311754533024722, 'Total loss': 0.5311754533024722} | train loss {'Reaction outcome loss': 0.4836130867727467, 'Total loss': 0.4836130867727467}
2022-11-28 06:20:06,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:06,957 INFO:     Epoch: 14
2022-11-28 06:20:07,610 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5372141578862833, 'Total loss': 0.5372141578862833} | train loss {'Reaction outcome loss': 0.48545557144479673, 'Total loss': 0.48545557144479673}
2022-11-28 06:20:07,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:07,611 INFO:     Epoch: 15
2022-11-28 06:20:08,264 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5500689398410709, 'Total loss': 0.5500689398410709} | train loss {'Reaction outcome loss': 0.48496864974254467, 'Total loss': 0.48496864974254467}
2022-11-28 06:20:08,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:08,265 INFO:     Epoch: 16
2022-11-28 06:20:08,919 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5145412565663804, 'Total loss': 0.5145412565663804} | train loss {'Reaction outcome loss': 0.4753224734277999, 'Total loss': 0.4753224734277999}
2022-11-28 06:20:08,919 INFO:     Found new best model at epoch 16
2022-11-28 06:20:08,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:08,920 INFO:     Epoch: 17
2022-11-28 06:20:09,576 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5281551754058793, 'Total loss': 0.5281551754058793} | train loss {'Reaction outcome loss': 0.4718958941273025, 'Total loss': 0.4718958941273025}
2022-11-28 06:20:09,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:09,577 INFO:     Epoch: 18
2022-11-28 06:20:10,237 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5114795454712802, 'Total loss': 0.5114795454712802} | train loss {'Reaction outcome loss': 0.4670541713960835, 'Total loss': 0.4670541713960835}
2022-11-28 06:20:10,237 INFO:     Found new best model at epoch 18
2022-11-28 06:20:10,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:10,238 INFO:     Epoch: 19
2022-11-28 06:20:10,897 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5357588030571161, 'Total loss': 0.5357588030571161} | train loss {'Reaction outcome loss': 0.47583693986544845, 'Total loss': 0.47583693986544845}
2022-11-28 06:20:10,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:10,897 INFO:     Epoch: 20
2022-11-28 06:20:11,555 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4991109350392985, 'Total loss': 0.4991109350392985} | train loss {'Reaction outcome loss': 0.4703654549771645, 'Total loss': 0.4703654549771645}
2022-11-28 06:20:11,555 INFO:     Found new best model at epoch 20
2022-11-28 06:20:11,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:11,556 INFO:     Epoch: 21
2022-11-28 06:20:12,212 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5099679037582042, 'Total loss': 0.5099679037582042} | train loss {'Reaction outcome loss': 0.4662366886852217, 'Total loss': 0.4662366886852217}
2022-11-28 06:20:12,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:12,213 INFO:     Epoch: 22
2022-11-28 06:20:12,872 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5178975383209627, 'Total loss': 0.5178975383209627} | train loss {'Reaction outcome loss': 0.4676600172505027, 'Total loss': 0.4676600172505027}
2022-11-28 06:20:12,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:12,873 INFO:     Epoch: 23
2022-11-28 06:20:13,529 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5359510990769364, 'Total loss': 0.5359510990769364} | train loss {'Reaction outcome loss': 0.46661273933580666, 'Total loss': 0.46661273933580666}
2022-11-28 06:20:13,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:13,530 INFO:     Epoch: 24
2022-11-28 06:20:14,185 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5311130708040193, 'Total loss': 0.5311130708040193} | train loss {'Reaction outcome loss': 0.4616175816684473, 'Total loss': 0.4616175816684473}
2022-11-28 06:20:14,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:14,186 INFO:     Epoch: 25
2022-11-28 06:20:14,842 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5185284170993539, 'Total loss': 0.5185284170993539} | train loss {'Reaction outcome loss': 0.4707537598785807, 'Total loss': 0.4707537598785807}
2022-11-28 06:20:14,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:14,842 INFO:     Epoch: 26
2022-11-28 06:20:15,497 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.528183052706164, 'Total loss': 0.528183052706164} | train loss {'Reaction outcome loss': 0.4625624300392925, 'Total loss': 0.4625624300392925}
2022-11-28 06:20:15,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:15,498 INFO:     Epoch: 27
2022-11-28 06:20:16,153 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5226026551668034, 'Total loss': 0.5226026551668034} | train loss {'Reaction outcome loss': 0.461530224282722, 'Total loss': 0.461530224282722}
2022-11-28 06:20:16,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:16,154 INFO:     Epoch: 28
2022-11-28 06:20:16,811 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5351134474540866, 'Total loss': 0.5351134474540866} | train loss {'Reaction outcome loss': 0.4615363598969139, 'Total loss': 0.4615363598969139}
2022-11-28 06:20:16,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:16,812 INFO:     Epoch: 29
2022-11-28 06:20:17,469 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5069377242132674, 'Total loss': 0.5069377242132674} | train loss {'Reaction outcome loss': 0.462225900993484, 'Total loss': 0.462225900993484}
2022-11-28 06:20:17,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:17,470 INFO:     Epoch: 30
2022-11-28 06:20:18,126 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5222569998613623, 'Total loss': 0.5222569998613623} | train loss {'Reaction outcome loss': 0.4666743582633675, 'Total loss': 0.4666743582633675}
2022-11-28 06:20:18,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:18,126 INFO:     Epoch: 31
2022-11-28 06:20:18,782 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49987951475520465, 'Total loss': 0.49987951475520465} | train loss {'Reaction outcome loss': 0.45977470455843894, 'Total loss': 0.45977470455843894}
2022-11-28 06:20:18,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:18,783 INFO:     Epoch: 32
2022-11-28 06:20:19,437 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5264441416014073, 'Total loss': 0.5264441416014073} | train loss {'Reaction outcome loss': 0.4630958214096847, 'Total loss': 0.4630958214096847}
2022-11-28 06:20:19,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:19,438 INFO:     Epoch: 33
2022-11-28 06:20:20,092 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5016595766294835, 'Total loss': 0.5016595766294835} | train loss {'Reaction outcome loss': 0.466508184971868, 'Total loss': 0.466508184971868}
2022-11-28 06:20:20,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:20,093 INFO:     Epoch: 34
2022-11-28 06:20:20,751 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5596168325390927, 'Total loss': 0.5596168325390927} | train loss {'Reaction outcome loss': 0.4595612740052528, 'Total loss': 0.4595612740052528}
2022-11-28 06:20:20,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:20,751 INFO:     Epoch: 35
2022-11-28 06:20:21,413 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5060063170832257, 'Total loss': 0.5060063170832257} | train loss {'Reaction outcome loss': 0.46481262770344, 'Total loss': 0.46481262770344}
2022-11-28 06:20:21,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:21,414 INFO:     Epoch: 36
2022-11-28 06:20:22,067 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5447620163823284, 'Total loss': 0.5447620163823284} | train loss {'Reaction outcome loss': 0.4632210332106371, 'Total loss': 0.4632210332106371}
2022-11-28 06:20:22,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:22,067 INFO:     Epoch: 37
2022-11-28 06:20:22,723 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5377367145793382, 'Total loss': 0.5377367145793382} | train loss {'Reaction outcome loss': 0.4639682447934737, 'Total loss': 0.4639682447934737}
2022-11-28 06:20:22,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:22,723 INFO:     Epoch: 38
2022-11-28 06:20:23,382 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5215588482313378, 'Total loss': 0.5215588482313378} | train loss {'Reaction outcome loss': 0.4673328446071656, 'Total loss': 0.4673328446071656}
2022-11-28 06:20:23,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:23,383 INFO:     Epoch: 39
2022-11-28 06:20:24,037 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5176410695841146, 'Total loss': 0.5176410695841146} | train loss {'Reaction outcome loss': 0.4648230061179302, 'Total loss': 0.4648230061179302}
2022-11-28 06:20:24,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:24,037 INFO:     Epoch: 40
2022-11-28 06:20:24,691 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5258870942648067, 'Total loss': 0.5258870942648067} | train loss {'Reaction outcome loss': 0.4653340557926014, 'Total loss': 0.4653340557926014}
2022-11-28 06:20:24,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:24,692 INFO:     Epoch: 41
2022-11-28 06:20:25,349 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5452968097010324, 'Total loss': 0.5452968097010324} | train loss {'Reaction outcome loss': 0.46680078979154105, 'Total loss': 0.46680078979154105}
2022-11-28 06:20:25,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:25,350 INFO:     Epoch: 42
2022-11-28 06:20:26,003 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5752458922391714, 'Total loss': 0.5752458922391714} | train loss {'Reaction outcome loss': 0.4580815348652054, 'Total loss': 0.4580815348652054}
2022-11-28 06:20:26,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:26,004 INFO:     Epoch: 43
2022-11-28 06:20:26,660 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5183899617472361, 'Total loss': 0.5183899617472361} | train loss {'Reaction outcome loss': 0.4644766381529511, 'Total loss': 0.4644766381529511}
2022-11-28 06:20:26,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:26,660 INFO:     Epoch: 44
2022-11-28 06:20:27,318 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5249516142662182, 'Total loss': 0.5249516142662182} | train loss {'Reaction outcome loss': 0.4656857224028619, 'Total loss': 0.4656857224028619}
2022-11-28 06:20:27,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:27,318 INFO:     Epoch: 45
2022-11-28 06:20:27,976 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.535203205291615, 'Total loss': 0.535203205291615} | train loss {'Reaction outcome loss': 0.4702811255806782, 'Total loss': 0.4702811255806782}
2022-11-28 06:20:27,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:27,976 INFO:     Epoch: 46
2022-11-28 06:20:28,636 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5417216884535413, 'Total loss': 0.5417216884535413} | train loss {'Reaction outcome loss': 0.46692334036113786, 'Total loss': 0.46692334036113786}
2022-11-28 06:20:28,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:28,636 INFO:     Epoch: 47
2022-11-28 06:20:29,295 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5050874771766884, 'Total loss': 0.5050874771766884} | train loss {'Reaction outcome loss': 0.4665243895266388, 'Total loss': 0.4665243895266388}
2022-11-28 06:20:29,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:29,295 INFO:     Epoch: 48
2022-11-28 06:20:29,957 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5198560187289881, 'Total loss': 0.5198560187289881} | train loss {'Reaction outcome loss': 0.47437988294929756, 'Total loss': 0.47437988294929756}
2022-11-28 06:20:29,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:29,958 INFO:     Epoch: 49
2022-11-28 06:20:30,616 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5145396274882693, 'Total loss': 0.5145396274882693} | train loss {'Reaction outcome loss': 0.47013437906738187, 'Total loss': 0.47013437906738187}
2022-11-28 06:20:30,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:30,616 INFO:     Epoch: 50
2022-11-28 06:20:31,275 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5140358590802481, 'Total loss': 0.5140358590802481} | train loss {'Reaction outcome loss': 0.46672210860692087, 'Total loss': 0.46672210860692087}
2022-11-28 06:20:31,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:31,276 INFO:     Epoch: 51
2022-11-28 06:20:31,938 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5113400394140288, 'Total loss': 0.5113400394140288} | train loss {'Reaction outcome loss': 0.4645968169340345, 'Total loss': 0.4645968169340345}
2022-11-28 06:20:31,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:31,938 INFO:     Epoch: 52
2022-11-28 06:20:32,600 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5315997843132463, 'Total loss': 0.5315997843132463} | train loss {'Reaction outcome loss': 0.46472587045587477, 'Total loss': 0.46472587045587477}
2022-11-28 06:20:32,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:32,600 INFO:     Epoch: 53
2022-11-28 06:20:33,259 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5302199894605681, 'Total loss': 0.5302199894605681} | train loss {'Reaction outcome loss': 0.4718497322231043, 'Total loss': 0.4718497322231043}
2022-11-28 06:20:33,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:33,259 INFO:     Epoch: 54
2022-11-28 06:20:33,917 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5195334432430045, 'Total loss': 0.5195334432430045} | train loss {'Reaction outcome loss': 0.4700979611790571, 'Total loss': 0.4700979611790571}
2022-11-28 06:20:33,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:33,918 INFO:     Epoch: 55
2022-11-28 06:20:34,576 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.51359934585039, 'Total loss': 0.51359934585039} | train loss {'Reaction outcome loss': 0.4640532251386369, 'Total loss': 0.4640532251386369}
2022-11-28 06:20:34,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:34,576 INFO:     Epoch: 56
2022-11-28 06:20:35,234 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5098466277122498, 'Total loss': 0.5098466277122498} | train loss {'Reaction outcome loss': 0.47322689589174066, 'Total loss': 0.47322689589174066}
2022-11-28 06:20:35,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:35,234 INFO:     Epoch: 57
2022-11-28 06:20:35,894 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5356999379257823, 'Total loss': 0.5356999379257823} | train loss {'Reaction outcome loss': 0.4642936924441916, 'Total loss': 0.4642936924441916}
2022-11-28 06:20:35,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:35,895 INFO:     Epoch: 58
2022-11-28 06:20:36,552 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5208800064269886, 'Total loss': 0.5208800064269886} | train loss {'Reaction outcome loss': 0.469307860817577, 'Total loss': 0.469307860817577}
2022-11-28 06:20:36,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:36,552 INFO:     Epoch: 59
2022-11-28 06:20:37,210 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5502742241288341, 'Total loss': 0.5502742241288341} | train loss {'Reaction outcome loss': 0.4638732303483564, 'Total loss': 0.4638732303483564}
2022-11-28 06:20:37,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:37,210 INFO:     Epoch: 60
2022-11-28 06:20:37,867 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5171526739763659, 'Total loss': 0.5171526739763659} | train loss {'Reaction outcome loss': 0.4737349208444357, 'Total loss': 0.4737349208444357}
2022-11-28 06:20:37,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:37,867 INFO:     Epoch: 61
2022-11-28 06:20:38,524 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5221964349580366, 'Total loss': 0.5221964349580366} | train loss {'Reaction outcome loss': 0.4676092380016554, 'Total loss': 0.4676092380016554}
2022-11-28 06:20:38,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:38,524 INFO:     Epoch: 62
2022-11-28 06:20:39,183 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4957207912622496, 'Total loss': 0.4957207912622496} | train loss {'Reaction outcome loss': 0.4662315118752542, 'Total loss': 0.4662315118752542}
2022-11-28 06:20:39,183 INFO:     Found new best model at epoch 62
2022-11-28 06:20:39,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:39,184 INFO:     Epoch: 63
2022-11-28 06:20:39,847 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5213362394377242, 'Total loss': 0.5213362394377242} | train loss {'Reaction outcome loss': 0.46347788776286314, 'Total loss': 0.46347788776286314}
2022-11-28 06:20:39,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:39,847 INFO:     Epoch: 64
2022-11-28 06:20:40,512 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5352707976518676, 'Total loss': 0.5352707976518676} | train loss {'Reaction outcome loss': 0.46557974900867116, 'Total loss': 0.46557974900867116}
2022-11-28 06:20:40,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:40,512 INFO:     Epoch: 65
2022-11-28 06:20:41,173 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5166673008785692, 'Total loss': 0.5166673008785692} | train loss {'Reaction outcome loss': 0.46948371082544327, 'Total loss': 0.46948371082544327}
2022-11-28 06:20:41,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:41,174 INFO:     Epoch: 66
2022-11-28 06:20:41,833 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5219612246335938, 'Total loss': 0.5219612246335938} | train loss {'Reaction outcome loss': 0.46249107161506275, 'Total loss': 0.46249107161506275}
2022-11-28 06:20:41,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:41,833 INFO:     Epoch: 67
2022-11-28 06:20:42,494 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49770253550174626, 'Total loss': 0.49770253550174626} | train loss {'Reaction outcome loss': 0.4793552324542257, 'Total loss': 0.4793552324542257}
2022-11-28 06:20:42,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:42,494 INFO:     Epoch: 68
2022-11-28 06:20:43,155 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5077886435874673, 'Total loss': 0.5077886435874673} | train loss {'Reaction outcome loss': 0.4656990811717315, 'Total loss': 0.4656990811717315}
2022-11-28 06:20:43,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:43,157 INFO:     Epoch: 69
2022-11-28 06:20:43,816 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5016001442144083, 'Total loss': 0.5016001442144083} | train loss {'Reaction outcome loss': 0.4668890322085287, 'Total loss': 0.4668890322085287}
2022-11-28 06:20:43,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:43,816 INFO:     Epoch: 70
2022-11-28 06:20:44,475 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5097118089365404, 'Total loss': 0.5097118089365404} | train loss {'Reaction outcome loss': 0.47432886662541845, 'Total loss': 0.47432886662541845}
2022-11-28 06:20:44,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:44,475 INFO:     Epoch: 71
2022-11-28 06:20:45,133 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5023032842680465, 'Total loss': 0.5023032842680465} | train loss {'Reaction outcome loss': 0.46311795693196234, 'Total loss': 0.46311795693196234}
2022-11-28 06:20:45,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:45,133 INFO:     Epoch: 72
2022-11-28 06:20:45,791 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5119171352233998, 'Total loss': 0.5119171352233998} | train loss {'Reaction outcome loss': 0.46873129278299264, 'Total loss': 0.46873129278299264}
2022-11-28 06:20:45,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:45,791 INFO:     Epoch: 73
2022-11-28 06:20:46,450 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5249079604481541, 'Total loss': 0.5249079604481541} | train loss {'Reaction outcome loss': 0.4642516577952221, 'Total loss': 0.4642516577952221}
2022-11-28 06:20:46,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:46,451 INFO:     Epoch: 74
2022-11-28 06:20:47,109 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.525073915719986, 'Total loss': 0.525073915719986} | train loss {'Reaction outcome loss': 0.46253191594217646, 'Total loss': 0.46253191594217646}
2022-11-28 06:20:47,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:47,109 INFO:     Epoch: 75
2022-11-28 06:20:47,766 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5274019847775615, 'Total loss': 0.5274019847775615} | train loss {'Reaction outcome loss': 0.472593935114927, 'Total loss': 0.472593935114927}
2022-11-28 06:20:47,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:47,767 INFO:     Epoch: 76
2022-11-28 06:20:48,425 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5073542969171391, 'Total loss': 0.5073542969171391} | train loss {'Reaction outcome loss': 0.4656703227245417, 'Total loss': 0.4656703227245417}
2022-11-28 06:20:48,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:48,425 INFO:     Epoch: 77
2022-11-28 06:20:49,082 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.532641105180563, 'Total loss': 0.532641105180563} | train loss {'Reaction outcome loss': 0.46872718729933754, 'Total loss': 0.46872718729933754}
2022-11-28 06:20:49,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:49,083 INFO:     Epoch: 78
2022-11-28 06:20:49,742 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5276076357031978, 'Total loss': 0.5276076357031978} | train loss {'Reaction outcome loss': 0.46487199979238825, 'Total loss': 0.46487199979238825}
2022-11-28 06:20:49,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:49,743 INFO:     Epoch: 79
2022-11-28 06:20:50,400 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5074924778106601, 'Total loss': 0.5074924778106601} | train loss {'Reaction outcome loss': 0.47210515644706663, 'Total loss': 0.47210515644706663}
2022-11-28 06:20:50,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:50,400 INFO:     Epoch: 80
2022-11-28 06:20:51,057 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5115069393501726, 'Total loss': 0.5115069393501726} | train loss {'Reaction outcome loss': 0.46562384893415404, 'Total loss': 0.46562384893415404}
2022-11-28 06:20:51,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:51,057 INFO:     Epoch: 81
2022-11-28 06:20:51,717 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5086816296327946, 'Total loss': 0.5086816296327946} | train loss {'Reaction outcome loss': 0.4636249465898412, 'Total loss': 0.4636249465898412}
2022-11-28 06:20:51,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:51,718 INFO:     Epoch: 82
2022-11-28 06:20:52,376 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5214659523132236, 'Total loss': 0.5214659523132236} | train loss {'Reaction outcome loss': 0.4699441011934007, 'Total loss': 0.4699441011934007}
2022-11-28 06:20:52,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:52,376 INFO:     Epoch: 83
2022-11-28 06:20:53,035 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5044820655223935, 'Total loss': 0.5044820655223935} | train loss {'Reaction outcome loss': 0.4651024504030337, 'Total loss': 0.4651024504030337}
2022-11-28 06:20:53,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:53,035 INFO:     Epoch: 84
2022-11-28 06:20:53,695 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5216366863527964, 'Total loss': 0.5216366863527964} | train loss {'Reaction outcome loss': 0.4648032143223481, 'Total loss': 0.4648032143223481}
2022-11-28 06:20:53,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:53,695 INFO:     Epoch: 85
2022-11-28 06:20:54,358 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5208206190619358, 'Total loss': 0.5208206190619358} | train loss {'Reaction outcome loss': 0.4678096065877891, 'Total loss': 0.4678096065877891}
2022-11-28 06:20:54,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:54,358 INFO:     Epoch: 86
2022-11-28 06:20:55,018 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5054612076559732, 'Total loss': 0.5054612076559732} | train loss {'Reaction outcome loss': 0.4634268722939687, 'Total loss': 0.4634268722939687}
2022-11-28 06:20:55,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:55,018 INFO:     Epoch: 87
2022-11-28 06:20:55,675 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4911257097887438, 'Total loss': 0.4911257097887438} | train loss {'Reaction outcome loss': 0.4648395423762134, 'Total loss': 0.4648395423762134}
2022-11-28 06:20:55,675 INFO:     Found new best model at epoch 87
2022-11-28 06:20:55,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:55,676 INFO:     Epoch: 88
2022-11-28 06:20:56,339 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5376248380472494, 'Total loss': 0.5376248380472494} | train loss {'Reaction outcome loss': 0.47018102196152095, 'Total loss': 0.47018102196152095}
2022-11-28 06:20:56,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:56,339 INFO:     Epoch: 89
2022-11-28 06:20:57,000 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5115814943646275, 'Total loss': 0.5115814943646275} | train loss {'Reaction outcome loss': 0.46563587972863774, 'Total loss': 0.46563587972863774}
2022-11-28 06:20:57,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:57,001 INFO:     Epoch: 90
2022-11-28 06:20:57,660 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5085591670385626, 'Total loss': 0.5085591670385626} | train loss {'Reaction outcome loss': 0.4698104693508539, 'Total loss': 0.4698104693508539}
2022-11-28 06:20:57,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:57,661 INFO:     Epoch: 91
2022-11-28 06:20:58,320 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49040775867395625, 'Total loss': 0.49040775867395625} | train loss {'Reaction outcome loss': 0.47032944797003856, 'Total loss': 0.47032944797003856}
2022-11-28 06:20:58,321 INFO:     Found new best model at epoch 91
2022-11-28 06:20:58,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:58,321 INFO:     Epoch: 92
2022-11-28 06:20:58,978 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49003238698770835, 'Total loss': 0.49003238698770835} | train loss {'Reaction outcome loss': 0.463459921481668, 'Total loss': 0.463459921481668}
2022-11-28 06:20:58,978 INFO:     Found new best model at epoch 92
2022-11-28 06:20:58,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:58,979 INFO:     Epoch: 93
2022-11-28 06:20:59,636 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5089669350621312, 'Total loss': 0.5089669350621312} | train loss {'Reaction outcome loss': 0.4656476531727392, 'Total loss': 0.4656476531727392}
2022-11-28 06:20:59,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:20:59,636 INFO:     Epoch: 94
2022-11-28 06:21:00,293 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5334633373936941, 'Total loss': 0.5334633373936941} | train loss {'Reaction outcome loss': 0.4679012269880928, 'Total loss': 0.4679012269880928}
2022-11-28 06:21:00,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:00,294 INFO:     Epoch: 95
2022-11-28 06:21:00,952 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.501634327478187, 'Total loss': 0.501634327478187} | train loss {'Reaction outcome loss': 0.4661539488273566, 'Total loss': 0.4661539488273566}
2022-11-28 06:21:00,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:00,952 INFO:     Epoch: 96
2022-11-28 06:21:01,612 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.499562926763712, 'Total loss': 0.499562926763712} | train loss {'Reaction outcome loss': 0.4731445539681638, 'Total loss': 0.4731445539681638}
2022-11-28 06:21:01,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:01,613 INFO:     Epoch: 97
2022-11-28 06:21:02,270 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5165274947188622, 'Total loss': 0.5165274947188622} | train loss {'Reaction outcome loss': 0.46139371437860316, 'Total loss': 0.46139371437860316}
2022-11-28 06:21:02,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:02,271 INFO:     Epoch: 98
2022-11-28 06:21:02,932 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5003231216308682, 'Total loss': 0.5003231216308682} | train loss {'Reaction outcome loss': 0.47133612895353894, 'Total loss': 0.47133612895353894}
2022-11-28 06:21:02,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:02,932 INFO:     Epoch: 99
2022-11-28 06:21:03,591 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5163382808136385, 'Total loss': 0.5163382808136385} | train loss {'Reaction outcome loss': 0.46265349115748877, 'Total loss': 0.46265349115748877}
2022-11-28 06:21:03,591 INFO:     Best model found after epoch 93 of 100.
2022-11-28 06:21:03,591 INFO:   Done with stage: TRAINING
2022-11-28 06:21:03,591 INFO:   Starting stage: EVALUATION
2022-11-28 06:21:03,721 INFO:   Done with stage: EVALUATION
2022-11-28 06:21:03,721 INFO:   Leaving out SEQ value Fold_7
2022-11-28 06:21:03,734 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:21:03,734 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:21:04,388 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:21:04,388 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:21:04,458 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:21:04,458 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:21:04,459 INFO:     No hyperparam tuning for this model
2022-11-28 06:21:04,459 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:21:04,459 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:21:04,459 INFO:     None feature selector for col prot
2022-11-28 06:21:04,460 INFO:     None feature selector for col prot
2022-11-28 06:21:04,460 INFO:     None feature selector for col prot
2022-11-28 06:21:04,460 INFO:     None feature selector for col chem
2022-11-28 06:21:04,460 INFO:     None feature selector for col chem
2022-11-28 06:21:04,460 INFO:     None feature selector for col chem
2022-11-28 06:21:04,460 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:21:04,460 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:21:04,462 INFO:     Number of params in model 169651
2022-11-28 06:21:04,465 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:21:04,465 INFO:   Starting stage: TRAINING
2022-11-28 06:21:04,517 INFO:     Val loss before train {'Reaction outcome loss': 1.0620743117549203, 'Total loss': 1.0620743117549203}
2022-11-28 06:21:04,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:04,517 INFO:     Epoch: 0
2022-11-28 06:21:05,189 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6449847675182603, 'Total loss': 0.6449847675182603} | train loss {'Reaction outcome loss': 0.7017629229493679, 'Total loss': 0.7017629229493679}
2022-11-28 06:21:05,189 INFO:     Found new best model at epoch 0
2022-11-28 06:21:05,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:05,190 INFO:     Epoch: 1
2022-11-28 06:21:05,860 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5717478949915279, 'Total loss': 0.5717478949915279} | train loss {'Reaction outcome loss': 0.5854042706590507, 'Total loss': 0.5854042706590507}
2022-11-28 06:21:05,860 INFO:     Found new best model at epoch 1
2022-11-28 06:21:05,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:05,861 INFO:     Epoch: 2
2022-11-28 06:21:06,532 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5789667334068905, 'Total loss': 0.5789667334068905} | train loss {'Reaction outcome loss': 0.5588399767875671, 'Total loss': 0.5588399767875671}
2022-11-28 06:21:06,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:06,532 INFO:     Epoch: 3
2022-11-28 06:21:07,204 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5976721847599203, 'Total loss': 0.5976721847599203} | train loss {'Reaction outcome loss': 0.5428134777973737, 'Total loss': 0.5428134777973737}
2022-11-28 06:21:07,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:07,205 INFO:     Epoch: 4
2022-11-28 06:21:07,876 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5614838769490068, 'Total loss': 0.5614838769490068} | train loss {'Reaction outcome loss': 0.5180665323090169, 'Total loss': 0.5180665323090169}
2022-11-28 06:21:07,876 INFO:     Found new best model at epoch 4
2022-11-28 06:21:07,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:07,877 INFO:     Epoch: 5
2022-11-28 06:21:08,548 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5236734714020382, 'Total loss': 0.5236734714020382} | train loss {'Reaction outcome loss': 0.5145446044663268, 'Total loss': 0.5145446044663268}
2022-11-28 06:21:08,548 INFO:     Found new best model at epoch 5
2022-11-28 06:21:08,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:08,549 INFO:     Epoch: 6
2022-11-28 06:21:09,217 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5194406963207505, 'Total loss': 0.5194406963207505} | train loss {'Reaction outcome loss': 0.5057788424554371, 'Total loss': 0.5057788424554371}
2022-11-28 06:21:09,218 INFO:     Found new best model at epoch 6
2022-11-28 06:21:09,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:09,218 INFO:     Epoch: 7
2022-11-28 06:21:09,887 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5083132846788927, 'Total loss': 0.5083132846788927} | train loss {'Reaction outcome loss': 0.503724536768371, 'Total loss': 0.503724536768371}
2022-11-28 06:21:09,888 INFO:     Found new best model at epoch 7
2022-11-28 06:21:09,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:09,888 INFO:     Epoch: 8
2022-11-28 06:21:10,559 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5127745419740677, 'Total loss': 0.5127745419740677} | train loss {'Reaction outcome loss': 0.4932407560127397, 'Total loss': 0.4932407560127397}
2022-11-28 06:21:10,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:10,567 INFO:     Epoch: 9
2022-11-28 06:21:11,238 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5081970386884429, 'Total loss': 0.5081970386884429} | train loss {'Reaction outcome loss': 0.48297911368670965, 'Total loss': 0.48297911368670965}
2022-11-28 06:21:11,238 INFO:     Found new best model at epoch 9
2022-11-28 06:21:11,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:11,239 INFO:     Epoch: 10
2022-11-28 06:21:11,912 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5133151655847376, 'Total loss': 0.5133151655847376} | train loss {'Reaction outcome loss': 0.4847952272262304, 'Total loss': 0.4847952272262304}
2022-11-28 06:21:11,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:11,912 INFO:     Epoch: 11
2022-11-28 06:21:12,578 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5020466650074179, 'Total loss': 0.5020466650074179} | train loss {'Reaction outcome loss': 0.48389889618321774, 'Total loss': 0.48389889618321774}
2022-11-28 06:21:12,578 INFO:     Found new best model at epoch 11
2022-11-28 06:21:12,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:12,579 INFO:     Epoch: 12
2022-11-28 06:21:13,248 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5408790538256819, 'Total loss': 0.5408790538256819} | train loss {'Reaction outcome loss': 0.48223110528722885, 'Total loss': 0.48223110528722885}
2022-11-28 06:21:13,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:13,248 INFO:     Epoch: 13
2022-11-28 06:21:13,917 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5114604387093674, 'Total loss': 0.5114604387093674} | train loss {'Reaction outcome loss': 0.4799846843966553, 'Total loss': 0.4799846843966553}
2022-11-28 06:21:13,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:13,918 INFO:     Epoch: 14
2022-11-28 06:21:14,589 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4981529167429967, 'Total loss': 0.4981529167429967} | train loss {'Reaction outcome loss': 0.48211941762917465, 'Total loss': 0.48211941762917465}
2022-11-28 06:21:14,589 INFO:     Found new best model at epoch 14
2022-11-28 06:21:14,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:14,590 INFO:     Epoch: 15
2022-11-28 06:21:15,261 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5125728798183528, 'Total loss': 0.5125728798183528} | train loss {'Reaction outcome loss': 0.46929648386374595, 'Total loss': 0.46929648386374595}
2022-11-28 06:21:15,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:15,261 INFO:     Epoch: 16
2022-11-28 06:21:15,930 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5328405750068751, 'Total loss': 0.5328405750068751} | train loss {'Reaction outcome loss': 0.4752035556180823, 'Total loss': 0.4752035556180823}
2022-11-28 06:21:15,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:15,930 INFO:     Epoch: 17
2022-11-28 06:21:16,600 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48726154186508874, 'Total loss': 0.48726154186508874} | train loss {'Reaction outcome loss': 0.4734352773596202, 'Total loss': 0.4734352773596202}
2022-11-28 06:21:16,600 INFO:     Found new best model at epoch 17
2022-11-28 06:21:16,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:16,601 INFO:     Epoch: 18
2022-11-28 06:21:17,269 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5013037337498232, 'Total loss': 0.5013037337498232} | train loss {'Reaction outcome loss': 0.4745315961059063, 'Total loss': 0.4745315961059063}
2022-11-28 06:21:17,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:17,270 INFO:     Epoch: 19
2022-11-28 06:21:17,940 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5120944184335795, 'Total loss': 0.5120944184335795} | train loss {'Reaction outcome loss': 0.4787369054411688, 'Total loss': 0.4787369054411688}
2022-11-28 06:21:17,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:17,941 INFO:     Epoch: 20
2022-11-28 06:21:18,614 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4881447157399221, 'Total loss': 0.4881447157399221} | train loss {'Reaction outcome loss': 0.4722512617346741, 'Total loss': 0.4722512617346741}
2022-11-28 06:21:18,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:18,614 INFO:     Epoch: 21
2022-11-28 06:21:19,285 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5027881972491741, 'Total loss': 0.5027881972491741} | train loss {'Reaction outcome loss': 0.47063971851621905, 'Total loss': 0.47063971851621905}
2022-11-28 06:21:19,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:19,286 INFO:     Epoch: 22
2022-11-28 06:21:19,953 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49450643733143806, 'Total loss': 0.49450643733143806} | train loss {'Reaction outcome loss': 0.47215974679397, 'Total loss': 0.47215974679397}
2022-11-28 06:21:19,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:19,953 INFO:     Epoch: 23
2022-11-28 06:21:20,625 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5267789428207007, 'Total loss': 0.5267789428207007} | train loss {'Reaction outcome loss': 0.4604167158625299, 'Total loss': 0.4604167158625299}
2022-11-28 06:21:20,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:20,626 INFO:     Epoch: 24
2022-11-28 06:21:21,295 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48590374196117575, 'Total loss': 0.48590374196117575} | train loss {'Reaction outcome loss': 0.46961760064286573, 'Total loss': 0.46961760064286573}
2022-11-28 06:21:21,295 INFO:     Found new best model at epoch 24
2022-11-28 06:21:21,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:21,296 INFO:     Epoch: 25
2022-11-28 06:21:21,966 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5004170523448424, 'Total loss': 0.5004170523448424} | train loss {'Reaction outcome loss': 0.4613586080170447, 'Total loss': 0.4613586080170447}
2022-11-28 06:21:21,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:21,966 INFO:     Epoch: 26
2022-11-28 06:21:22,635 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5176943455907431, 'Total loss': 0.5176943455907431} | train loss {'Reaction outcome loss': 0.46585229297559105, 'Total loss': 0.46585229297559105}
2022-11-28 06:21:22,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:22,636 INFO:     Epoch: 27
2022-11-28 06:21:23,306 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48723015866496344, 'Total loss': 0.48723015866496344} | train loss {'Reaction outcome loss': 0.4599654539938896, 'Total loss': 0.4599654539938896}
2022-11-28 06:21:23,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:23,306 INFO:     Epoch: 28
2022-11-28 06:21:23,977 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4860839572819797, 'Total loss': 0.4860839572819797} | train loss {'Reaction outcome loss': 0.46407550387084484, 'Total loss': 0.46407550387084484}
2022-11-28 06:21:23,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:23,977 INFO:     Epoch: 29
2022-11-28 06:21:24,646 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49677613309838553, 'Total loss': 0.49677613309838553} | train loss {'Reaction outcome loss': 0.47134131054964756, 'Total loss': 0.47134131054964756}
2022-11-28 06:21:24,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:24,646 INFO:     Epoch: 30
2022-11-28 06:21:25,324 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46904199028557, 'Total loss': 0.46904199028557} | train loss {'Reaction outcome loss': 0.4605492411421672, 'Total loss': 0.4605492411421672}
2022-11-28 06:21:25,324 INFO:     Found new best model at epoch 30
2022-11-28 06:21:25,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:25,325 INFO:     Epoch: 31
2022-11-28 06:21:25,993 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4801843295043165, 'Total loss': 0.4801843295043165} | train loss {'Reaction outcome loss': 0.4610594040563991, 'Total loss': 0.4610594040563991}
2022-11-28 06:21:25,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:25,993 INFO:     Epoch: 32
2022-11-28 06:21:26,662 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49162801626053726, 'Total loss': 0.49162801626053726} | train loss {'Reaction outcome loss': 0.4667482856180399, 'Total loss': 0.4667482856180399}
2022-11-28 06:21:26,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:26,662 INFO:     Epoch: 33
2022-11-28 06:21:27,335 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48363764414733107, 'Total loss': 0.48363764414733107} | train loss {'Reaction outcome loss': 0.46558401183856113, 'Total loss': 0.46558401183856113}
2022-11-28 06:21:27,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:27,335 INFO:     Epoch: 34
2022-11-28 06:21:28,009 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48039251125671645, 'Total loss': 0.48039251125671645} | train loss {'Reaction outcome loss': 0.4713237748871888, 'Total loss': 0.4713237748871888}
2022-11-28 06:21:28,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:28,009 INFO:     Epoch: 35
2022-11-28 06:21:28,677 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48954551734707574, 'Total loss': 0.48954551734707574} | train loss {'Reaction outcome loss': 0.4649833423956748, 'Total loss': 0.4649833423956748}
2022-11-28 06:21:28,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:28,678 INFO:     Epoch: 36
2022-11-28 06:21:29,350 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49981330131942575, 'Total loss': 0.49981330131942575} | train loss {'Reaction outcome loss': 0.459000248882559, 'Total loss': 0.459000248882559}
2022-11-28 06:21:29,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:29,350 INFO:     Epoch: 37
2022-11-28 06:21:30,019 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5096133899959651, 'Total loss': 0.5096133899959651} | train loss {'Reaction outcome loss': 0.4610992156930508, 'Total loss': 0.4610992156930508}
2022-11-28 06:21:30,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:30,019 INFO:     Epoch: 38
2022-11-28 06:21:30,688 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.489296092228456, 'Total loss': 0.489296092228456} | train loss {'Reaction outcome loss': 0.4620952386889727, 'Total loss': 0.4620952386889727}
2022-11-28 06:21:30,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:30,688 INFO:     Epoch: 39
2022-11-28 06:21:31,358 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4989189756187526, 'Total loss': 0.4989189756187526} | train loss {'Reaction outcome loss': 0.4646882760308443, 'Total loss': 0.4646882760308443}
2022-11-28 06:21:31,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:31,358 INFO:     Epoch: 40
2022-11-28 06:21:32,028 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47961282255974685, 'Total loss': 0.47961282255974685} | train loss {'Reaction outcome loss': 0.4658119920641184, 'Total loss': 0.4658119920641184}
2022-11-28 06:21:32,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:32,029 INFO:     Epoch: 41
2022-11-28 06:21:32,697 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5143727175891399, 'Total loss': 0.5143727175891399} | train loss {'Reaction outcome loss': 0.4560483478971066, 'Total loss': 0.4560483478971066}
2022-11-28 06:21:32,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:32,698 INFO:     Epoch: 42
2022-11-28 06:21:33,365 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48165963048284705, 'Total loss': 0.48165963048284705} | train loss {'Reaction outcome loss': 0.4665335196881525, 'Total loss': 0.4665335196881525}
2022-11-28 06:21:33,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:33,365 INFO:     Epoch: 43
2022-11-28 06:21:34,035 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49006952006708493, 'Total loss': 0.49006952006708493} | train loss {'Reaction outcome loss': 0.46700327933555646, 'Total loss': 0.46700327933555646}
2022-11-28 06:21:34,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:34,036 INFO:     Epoch: 44
2022-11-28 06:21:34,708 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4879344749179753, 'Total loss': 0.4879344749179753} | train loss {'Reaction outcome loss': 0.4564537877036679, 'Total loss': 0.4564537877036679}
2022-11-28 06:21:34,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:34,709 INFO:     Epoch: 45
2022-11-28 06:21:35,379 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48943770744583825, 'Total loss': 0.48943770744583825} | train loss {'Reaction outcome loss': 0.46256533295156493, 'Total loss': 0.46256533295156493}
2022-11-28 06:21:35,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:35,380 INFO:     Epoch: 46
2022-11-28 06:21:36,048 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48541221699931403, 'Total loss': 0.48541221699931403} | train loss {'Reaction outcome loss': 0.4653742396002335, 'Total loss': 0.4653742396002335}
2022-11-28 06:21:36,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:36,048 INFO:     Epoch: 47
2022-11-28 06:21:36,719 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4983549206094308, 'Total loss': 0.4983549206094308} | train loss {'Reaction outcome loss': 0.4543776148629765, 'Total loss': 0.4543776148629765}
2022-11-28 06:21:36,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:36,719 INFO:     Epoch: 48
2022-11-28 06:21:37,391 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5326707024465908, 'Total loss': 0.5326707024465908} | train loss {'Reaction outcome loss': 0.46007975317057104, 'Total loss': 0.46007975317057104}
2022-11-28 06:21:37,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:37,391 INFO:     Epoch: 49
2022-11-28 06:21:38,062 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5237013951621272, 'Total loss': 0.5237013951621272} | train loss {'Reaction outcome loss': 0.4638111592540818, 'Total loss': 0.4638111592540818}
2022-11-28 06:21:38,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:38,062 INFO:     Epoch: 50
2022-11-28 06:21:38,729 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5262915674935688, 'Total loss': 0.5262915674935688} | train loss {'Reaction outcome loss': 0.461408857796942, 'Total loss': 0.461408857796942}
2022-11-28 06:21:38,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:38,730 INFO:     Epoch: 51
2022-11-28 06:21:39,398 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4830042885785753, 'Total loss': 0.4830042885785753} | train loss {'Reaction outcome loss': 0.4648632856025811, 'Total loss': 0.4648632856025811}
2022-11-28 06:21:39,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:39,399 INFO:     Epoch: 52
2022-11-28 06:21:40,069 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5275231521915306, 'Total loss': 0.5275231521915306} | train loss {'Reaction outcome loss': 0.4627048221807326, 'Total loss': 0.4627048221807326}
2022-11-28 06:21:40,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:40,069 INFO:     Epoch: 53
2022-11-28 06:21:40,736 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5031962045891718, 'Total loss': 0.5031962045891718} | train loss {'Reaction outcome loss': 0.4611903627913806, 'Total loss': 0.4611903627913806}
2022-11-28 06:21:40,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:40,736 INFO:     Epoch: 54
2022-11-28 06:21:41,405 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5789156095548109, 'Total loss': 0.5789156095548109} | train loss {'Reaction outcome loss': 0.4531063077550742, 'Total loss': 0.4531063077550742}
2022-11-28 06:21:41,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:41,405 INFO:     Epoch: 55
2022-11-28 06:21:42,073 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.483656530353156, 'Total loss': 0.483656530353156} | train loss {'Reaction outcome loss': 0.4601434990162811, 'Total loss': 0.4601434990162811}
2022-11-28 06:21:42,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:42,073 INFO:     Epoch: 56
2022-11-28 06:21:42,741 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49126930060711776, 'Total loss': 0.49126930060711776} | train loss {'Reaction outcome loss': 0.46244927393572943, 'Total loss': 0.46244927393572943}
2022-11-28 06:21:42,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:42,741 INFO:     Epoch: 57
2022-11-28 06:21:43,409 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4931484799493443, 'Total loss': 0.4931484799493443} | train loss {'Reaction outcome loss': 0.4630927417667643, 'Total loss': 0.4630927417667643}
2022-11-28 06:21:43,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:43,409 INFO:     Epoch: 58
2022-11-28 06:21:44,076 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4867087697440928, 'Total loss': 0.4867087697440928} | train loss {'Reaction outcome loss': 0.4606676242584663, 'Total loss': 0.4606676242584663}
2022-11-28 06:21:44,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:44,076 INFO:     Epoch: 59
2022-11-28 06:21:44,743 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4680590168996291, 'Total loss': 0.4680590168996291} | train loss {'Reaction outcome loss': 0.4619451880815529, 'Total loss': 0.4619451880815529}
2022-11-28 06:21:44,744 INFO:     Found new best model at epoch 59
2022-11-28 06:21:44,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:44,745 INFO:     Epoch: 60
2022-11-28 06:21:45,412 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49639553238045087, 'Total loss': 0.49639553238045087} | train loss {'Reaction outcome loss': 0.4549134101853856, 'Total loss': 0.4549134101853856}
2022-11-28 06:21:45,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:45,413 INFO:     Epoch: 61
2022-11-28 06:21:46,081 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4850926179100167, 'Total loss': 0.4850926179100167} | train loss {'Reaction outcome loss': 0.4598243592246886, 'Total loss': 0.4598243592246886}
2022-11-28 06:21:46,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:46,082 INFO:     Epoch: 62
2022-11-28 06:21:46,747 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49016281217336655, 'Total loss': 0.49016281217336655} | train loss {'Reaction outcome loss': 0.4579658363495142, 'Total loss': 0.4579658363495142}
2022-11-28 06:21:46,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:46,747 INFO:     Epoch: 63
2022-11-28 06:21:47,415 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5137944566932592, 'Total loss': 0.5137944566932592} | train loss {'Reaction outcome loss': 0.46237400582721155, 'Total loss': 0.46237400582721155}
2022-11-28 06:21:47,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:47,415 INFO:     Epoch: 64
2022-11-28 06:21:48,084 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5095000835982236, 'Total loss': 0.5095000835982236} | train loss {'Reaction outcome loss': 0.45724063937462145, 'Total loss': 0.45724063937462145}
2022-11-28 06:21:48,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:48,085 INFO:     Epoch: 65
2022-11-28 06:21:48,756 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4883629862557758, 'Total loss': 0.4883629862557758} | train loss {'Reaction outcome loss': 0.4544415025701446, 'Total loss': 0.4544415025701446}
2022-11-28 06:21:48,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:48,756 INFO:     Epoch: 66
2022-11-28 06:21:49,423 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48725438761440193, 'Total loss': 0.48725438761440193} | train loss {'Reaction outcome loss': 0.4532574738766397, 'Total loss': 0.4532574738766397}
2022-11-28 06:21:49,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:49,423 INFO:     Epoch: 67
2022-11-28 06:21:50,091 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4868836802515117, 'Total loss': 0.4868836802515117} | train loss {'Reaction outcome loss': 0.46215929217155904, 'Total loss': 0.46215929217155904}
2022-11-28 06:21:50,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:50,091 INFO:     Epoch: 68
2022-11-28 06:21:50,764 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48999728194691916, 'Total loss': 0.48999728194691916} | train loss {'Reaction outcome loss': 0.45681220028669606, 'Total loss': 0.45681220028669606}
2022-11-28 06:21:50,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:50,765 INFO:     Epoch: 69
2022-11-28 06:21:51,434 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.507525616071441, 'Total loss': 0.507525616071441} | train loss {'Reaction outcome loss': 0.4681944028143921, 'Total loss': 0.4681944028143921}
2022-11-28 06:21:51,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:51,435 INFO:     Epoch: 70
2022-11-28 06:21:52,102 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5146454264494505, 'Total loss': 0.5146454264494505} | train loss {'Reaction outcome loss': 0.4625492259154036, 'Total loss': 0.4625492259154036}
2022-11-28 06:21:52,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:52,102 INFO:     Epoch: 71
2022-11-28 06:21:52,771 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49083218520337885, 'Total loss': 0.49083218520337885} | train loss {'Reaction outcome loss': 0.46235837150485287, 'Total loss': 0.46235837150485287}
2022-11-28 06:21:52,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:52,772 INFO:     Epoch: 72
2022-11-28 06:21:53,440 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49649143693121994, 'Total loss': 0.49649143693121994} | train loss {'Reaction outcome loss': 0.4588386012060988, 'Total loss': 0.4588386012060988}
2022-11-28 06:21:53,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:53,440 INFO:     Epoch: 73
2022-11-28 06:21:54,108 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5275530493394895, 'Total loss': 0.5275530493394895} | train loss {'Reaction outcome loss': 0.46696722771852245, 'Total loss': 0.46696722771852245}
2022-11-28 06:21:54,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:54,108 INFO:     Epoch: 74
2022-11-28 06:21:54,773 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5028812953016975, 'Total loss': 0.5028812953016975} | train loss {'Reaction outcome loss': 0.4549963929720463, 'Total loss': 0.4549963929720463}
2022-11-28 06:21:54,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:54,773 INFO:     Epoch: 75
2022-11-28 06:21:55,440 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4890792728825049, 'Total loss': 0.4890792728825049} | train loss {'Reaction outcome loss': 0.4625688261322437, 'Total loss': 0.4625688261322437}
2022-11-28 06:21:55,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:55,440 INFO:     Epoch: 76
2022-11-28 06:21:56,112 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48753194002942607, 'Total loss': 0.48753194002942607} | train loss {'Reaction outcome loss': 0.46135818291335334, 'Total loss': 0.46135818291335334}
2022-11-28 06:21:56,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:56,112 INFO:     Epoch: 77
2022-11-28 06:21:56,781 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5091294395652685, 'Total loss': 0.5091294395652685} | train loss {'Reaction outcome loss': 0.4577283556723306, 'Total loss': 0.4577283556723306}
2022-11-28 06:21:56,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:56,781 INFO:     Epoch: 78
2022-11-28 06:21:57,450 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49115691300142894, 'Total loss': 0.49115691300142894} | train loss {'Reaction outcome loss': 0.46945274422966665, 'Total loss': 0.46945274422966665}
2022-11-28 06:21:57,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:57,451 INFO:     Epoch: 79
2022-11-28 06:21:58,118 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5264351963996887, 'Total loss': 0.5264351963996887} | train loss {'Reaction outcome loss': 0.465373499439128, 'Total loss': 0.465373499439128}
2022-11-28 06:21:58,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:58,119 INFO:     Epoch: 80
2022-11-28 06:21:58,789 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49343565241857007, 'Total loss': 0.49343565241857007} | train loss {'Reaction outcome loss': 0.4647844692151393, 'Total loss': 0.4647844692151393}
2022-11-28 06:21:58,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:58,789 INFO:     Epoch: 81
2022-11-28 06:21:59,461 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48558795282786543, 'Total loss': 0.48558795282786543} | train loss {'Reaction outcome loss': 0.4586639834507819, 'Total loss': 0.4586639834507819}
2022-11-28 06:21:59,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:21:59,461 INFO:     Epoch: 82
2022-11-28 06:22:00,134 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4712964018637484, 'Total loss': 0.4712964018637484} | train loss {'Reaction outcome loss': 0.4604408135337214, 'Total loss': 0.4604408135337214}
2022-11-28 06:22:00,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:00,135 INFO:     Epoch: 83
2022-11-28 06:22:00,806 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4900405285033313, 'Total loss': 0.4900405285033313} | train loss {'Reaction outcome loss': 0.46304246488838424, 'Total loss': 0.46304246488838424}
2022-11-28 06:22:00,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:00,807 INFO:     Epoch: 84
2022-11-28 06:22:01,478 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4858526966788552, 'Total loss': 0.4858526966788552} | train loss {'Reaction outcome loss': 0.4588149981873651, 'Total loss': 0.4588149981873651}
2022-11-28 06:22:01,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:01,478 INFO:     Epoch: 85
2022-11-28 06:22:02,149 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4986767348918048, 'Total loss': 0.4986767348918048} | train loss {'Reaction outcome loss': 0.46791115180859644, 'Total loss': 0.46791115180859644}
2022-11-28 06:22:02,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:02,150 INFO:     Epoch: 86
2022-11-28 06:22:02,817 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.471689239482988, 'Total loss': 0.471689239482988} | train loss {'Reaction outcome loss': 0.4624810740351677, 'Total loss': 0.4624810740351677}
2022-11-28 06:22:02,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:02,818 INFO:     Epoch: 87
2022-11-28 06:22:03,487 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4955787045711821, 'Total loss': 0.4955787045711821} | train loss {'Reaction outcome loss': 0.4564121105978566, 'Total loss': 0.4564121105978566}
2022-11-28 06:22:03,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:03,487 INFO:     Epoch: 88
2022-11-28 06:22:04,156 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5159837258133021, 'Total loss': 0.5159837258133021} | train loss {'Reaction outcome loss': 0.46213261753080354, 'Total loss': 0.46213261753080354}
2022-11-28 06:22:04,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:04,157 INFO:     Epoch: 89
2022-11-28 06:22:04,822 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5207149846987291, 'Total loss': 0.5207149846987291} | train loss {'Reaction outcome loss': 0.46536933889071785, 'Total loss': 0.46536933889071785}
2022-11-28 06:22:04,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:04,823 INFO:     Epoch: 90
2022-11-28 06:22:05,489 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4928558021783829, 'Total loss': 0.4928558021783829} | train loss {'Reaction outcome loss': 0.45541666072583004, 'Total loss': 0.45541666072583004}
2022-11-28 06:22:05,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:05,489 INFO:     Epoch: 91
2022-11-28 06:22:06,161 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.521899664266543, 'Total loss': 0.521899664266543} | train loss {'Reaction outcome loss': 0.4622385033496445, 'Total loss': 0.4622385033496445}
2022-11-28 06:22:06,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:06,161 INFO:     Epoch: 92
2022-11-28 06:22:06,828 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47408979081294755, 'Total loss': 0.47408979081294755} | train loss {'Reaction outcome loss': 0.4676598124206066, 'Total loss': 0.4676598124206066}
2022-11-28 06:22:06,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:06,828 INFO:     Epoch: 93
2022-11-28 06:22:07,498 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48430040648037737, 'Total loss': 0.48430040648037737} | train loss {'Reaction outcome loss': 0.4707848865899347, 'Total loss': 0.4707848865899347}
2022-11-28 06:22:07,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:07,498 INFO:     Epoch: 94
2022-11-28 06:22:08,165 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5033060163259506, 'Total loss': 0.5033060163259506} | train loss {'Reaction outcome loss': 0.4583714386868861, 'Total loss': 0.4583714386868861}
2022-11-28 06:22:08,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:08,165 INFO:     Epoch: 95
2022-11-28 06:22:08,834 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49010570313442836, 'Total loss': 0.49010570313442836} | train loss {'Reaction outcome loss': 0.4610864546510481, 'Total loss': 0.4610864546510481}
2022-11-28 06:22:08,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:08,835 INFO:     Epoch: 96
2022-11-28 06:22:09,505 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48329191553321754, 'Total loss': 0.48329191553321754} | train loss {'Reaction outcome loss': 0.46435952234652733, 'Total loss': 0.46435952234652733}
2022-11-28 06:22:09,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:09,505 INFO:     Epoch: 97
2022-11-28 06:22:10,174 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47612538120963355, 'Total loss': 0.47612538120963355} | train loss {'Reaction outcome loss': 0.459423934019381, 'Total loss': 0.459423934019381}
2022-11-28 06:22:10,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:10,174 INFO:     Epoch: 98
2022-11-28 06:22:10,840 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4989727159792727, 'Total loss': 0.4989727159792727} | train loss {'Reaction outcome loss': 0.4629515676248458, 'Total loss': 0.4629515676248458}
2022-11-28 06:22:10,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:10,841 INFO:     Epoch: 99
2022-11-28 06:22:11,508 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5097686746581034, 'Total loss': 0.5097686746581034} | train loss {'Reaction outcome loss': 0.4591951021744359, 'Total loss': 0.4591951021744359}
2022-11-28 06:22:11,508 INFO:     Best model found after epoch 60 of 100.
2022-11-28 06:22:11,508 INFO:   Done with stage: TRAINING
2022-11-28 06:22:11,508 INFO:   Starting stage: EVALUATION
2022-11-28 06:22:11,622 INFO:   Done with stage: EVALUATION
2022-11-28 06:22:11,622 INFO:   Leaving out SEQ value Fold_8
2022-11-28 06:22:11,635 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 06:22:11,635 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:22:12,280 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:22:12,280 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:22:12,350 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:22:12,351 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:22:12,351 INFO:     No hyperparam tuning for this model
2022-11-28 06:22:12,351 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:22:12,351 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:22:12,351 INFO:     None feature selector for col prot
2022-11-28 06:22:12,352 INFO:     None feature selector for col prot
2022-11-28 06:22:12,352 INFO:     None feature selector for col prot
2022-11-28 06:22:12,352 INFO:     None feature selector for col chem
2022-11-28 06:22:12,352 INFO:     None feature selector for col chem
2022-11-28 06:22:12,352 INFO:     None feature selector for col chem
2022-11-28 06:22:12,352 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:22:12,352 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:22:12,354 INFO:     Number of params in model 169651
2022-11-28 06:22:12,357 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:22:12,357 INFO:   Starting stage: TRAINING
2022-11-28 06:22:12,408 INFO:     Val loss before train {'Reaction outcome loss': 1.0764634704047984, 'Total loss': 1.0764634704047984}
2022-11-28 06:22:12,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:12,409 INFO:     Epoch: 0
2022-11-28 06:22:13,073 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.589262647384947, 'Total loss': 0.589262647384947} | train loss {'Reaction outcome loss': 0.6796841521856756, 'Total loss': 0.6796841521856756}
2022-11-28 06:22:13,073 INFO:     Found new best model at epoch 0
2022-11-28 06:22:13,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:13,074 INFO:     Epoch: 1
2022-11-28 06:22:13,739 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.58630432323976, 'Total loss': 0.58630432323976} | train loss {'Reaction outcome loss': 0.5850076147539895, 'Total loss': 0.5850076147539895}
2022-11-28 06:22:13,740 INFO:     Found new best model at epoch 1
2022-11-28 06:22:13,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:13,740 INFO:     Epoch: 2
2022-11-28 06:22:14,402 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5291240161115472, 'Total loss': 0.5291240161115472} | train loss {'Reaction outcome loss': 0.5587969732429334, 'Total loss': 0.5587969732429334}
2022-11-28 06:22:14,402 INFO:     Found new best model at epoch 2
2022-11-28 06:22:14,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:14,403 INFO:     Epoch: 3
2022-11-28 06:22:15,064 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5187946679917249, 'Total loss': 0.5187946679917249} | train loss {'Reaction outcome loss': 0.5620393540016432, 'Total loss': 0.5620393540016432}
2022-11-28 06:22:15,064 INFO:     Found new best model at epoch 3
2022-11-28 06:22:15,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:15,065 INFO:     Epoch: 4
2022-11-28 06:22:15,731 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5187926502390341, 'Total loss': 0.5187926502390341} | train loss {'Reaction outcome loss': 0.5192320592671271, 'Total loss': 0.5192320592671271}
2022-11-28 06:22:15,732 INFO:     Found new best model at epoch 4
2022-11-28 06:22:15,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:15,733 INFO:     Epoch: 5
2022-11-28 06:22:16,395 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6703267442909154, 'Total loss': 0.6703267442909154} | train loss {'Reaction outcome loss': 0.516952804225659, 'Total loss': 0.516952804225659}
2022-11-28 06:22:16,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:16,395 INFO:     Epoch: 6
2022-11-28 06:22:17,056 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49576995420185005, 'Total loss': 0.49576995420185005} | train loss {'Reaction outcome loss': 0.5090475374991111, 'Total loss': 0.5090475374991111}
2022-11-28 06:22:17,057 INFO:     Found new best model at epoch 6
2022-11-28 06:22:17,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:17,057 INFO:     Epoch: 7
2022-11-28 06:22:17,721 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49580772153355857, 'Total loss': 0.49580772153355857} | train loss {'Reaction outcome loss': 0.49857321231501545, 'Total loss': 0.49857321231501545}
2022-11-28 06:22:17,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:17,722 INFO:     Epoch: 8
2022-11-28 06:22:18,388 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5608308278024197, 'Total loss': 0.5608308278024197} | train loss {'Reaction outcome loss': 0.5011672235889594, 'Total loss': 0.5011672235889594}
2022-11-28 06:22:18,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:18,388 INFO:     Epoch: 9
2022-11-28 06:22:19,052 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5277644399214875, 'Total loss': 0.5277644399214875} | train loss {'Reaction outcome loss': 0.48685814588055437, 'Total loss': 0.48685814588055437}
2022-11-28 06:22:19,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:19,052 INFO:     Epoch: 10
2022-11-28 06:22:19,716 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5037183924154802, 'Total loss': 0.5037183924154802} | train loss {'Reaction outcome loss': 0.487131725921322, 'Total loss': 0.487131725921322}
2022-11-28 06:22:19,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:19,717 INFO:     Epoch: 11
2022-11-28 06:22:20,382 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4958630275319923, 'Total loss': 0.4958630275319923} | train loss {'Reaction outcome loss': 0.480092004559904, 'Total loss': 0.480092004559904}
2022-11-28 06:22:20,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:20,382 INFO:     Epoch: 12
2022-11-28 06:22:21,050 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4948528266765855, 'Total loss': 0.4948528266765855} | train loss {'Reaction outcome loss': 0.479529636259745, 'Total loss': 0.479529636259745}
2022-11-28 06:22:21,050 INFO:     Found new best model at epoch 12
2022-11-28 06:22:21,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:21,051 INFO:     Epoch: 13
2022-11-28 06:22:21,715 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4673121490261771, 'Total loss': 0.4673121490261771} | train loss {'Reaction outcome loss': 0.4759035521311316, 'Total loss': 0.4759035521311316}
2022-11-28 06:22:21,715 INFO:     Found new best model at epoch 13
2022-11-28 06:22:21,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:21,716 INFO:     Epoch: 14
2022-11-28 06:22:22,381 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5113732516765594, 'Total loss': 0.5113732516765594} | train loss {'Reaction outcome loss': 0.4821924365348058, 'Total loss': 0.4821924365348058}
2022-11-28 06:22:22,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:22,382 INFO:     Epoch: 15
2022-11-28 06:22:23,046 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.519906857135621, 'Total loss': 0.519906857135621} | train loss {'Reaction outcome loss': 0.4828551274079543, 'Total loss': 0.4828551274079543}
2022-11-28 06:22:23,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:23,046 INFO:     Epoch: 16
2022-11-28 06:22:23,711 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4833404289727861, 'Total loss': 0.4833404289727861} | train loss {'Reaction outcome loss': 0.4907439902485141, 'Total loss': 0.4907439902485141}
2022-11-28 06:22:23,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:23,711 INFO:     Epoch: 17
2022-11-28 06:22:24,378 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5141552121124484, 'Total loss': 0.5141552121124484} | train loss {'Reaction outcome loss': 0.4801068360868253, 'Total loss': 0.4801068360868253}
2022-11-28 06:22:24,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:24,378 INFO:     Epoch: 18
2022-11-28 06:22:25,040 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4648038518022407, 'Total loss': 0.4648038518022407} | train loss {'Reaction outcome loss': 0.4755505257199409, 'Total loss': 0.4755505257199409}
2022-11-28 06:22:25,041 INFO:     Found new best model at epoch 18
2022-11-28 06:22:25,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:25,041 INFO:     Epoch: 19
2022-11-28 06:22:25,703 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48106109046123247, 'Total loss': 0.48106109046123247} | train loss {'Reaction outcome loss': 0.47369187273959884, 'Total loss': 0.47369187273959884}
2022-11-28 06:22:25,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:25,703 INFO:     Epoch: 20
2022-11-28 06:22:26,368 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4964657981287349, 'Total loss': 0.4964657981287349} | train loss {'Reaction outcome loss': 0.4840779833284467, 'Total loss': 0.4840779833284467}
2022-11-28 06:22:26,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:26,369 INFO:     Epoch: 21
2022-11-28 06:22:27,035 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4661966304887425, 'Total loss': 0.4661966304887425} | train loss {'Reaction outcome loss': 0.4756867586359804, 'Total loss': 0.4756867586359804}
2022-11-28 06:22:27,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:27,036 INFO:     Epoch: 22
2022-11-28 06:22:27,699 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5099307982759043, 'Total loss': 0.5099307982759043} | train loss {'Reaction outcome loss': 0.47126293926677, 'Total loss': 0.47126293926677}
2022-11-28 06:22:27,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:27,699 INFO:     Epoch: 23
2022-11-28 06:22:28,363 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5569159825417128, 'Total loss': 0.5569159825417128} | train loss {'Reaction outcome loss': 0.47330042454395216, 'Total loss': 0.47330042454395216}
2022-11-28 06:22:28,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:28,363 INFO:     Epoch: 24
2022-11-28 06:22:29,027 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4944553534415635, 'Total loss': 0.4944553534415635} | train loss {'Reaction outcome loss': 0.47589758334130894, 'Total loss': 0.47589758334130894}
2022-11-28 06:22:29,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:29,027 INFO:     Epoch: 25
2022-11-28 06:22:29,693 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4819817454977469, 'Total loss': 0.4819817454977469} | train loss {'Reaction outcome loss': 0.4671354337863111, 'Total loss': 0.4671354337863111}
2022-11-28 06:22:29,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:29,693 INFO:     Epoch: 26
2022-11-28 06:22:30,356 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49843984097242355, 'Total loss': 0.49843984097242355} | train loss {'Reaction outcome loss': 0.47706534921640326, 'Total loss': 0.47706534921640326}
2022-11-28 06:22:30,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:30,357 INFO:     Epoch: 27
2022-11-28 06:22:31,019 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5113439654762094, 'Total loss': 0.5113439654762094} | train loss {'Reaction outcome loss': 0.4795487584614078, 'Total loss': 0.4795487584614078}
2022-11-28 06:22:31,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:31,019 INFO:     Epoch: 28
2022-11-28 06:22:31,684 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4937913031740622, 'Total loss': 0.4937913031740622} | train loss {'Reaction outcome loss': 0.4643572547778427, 'Total loss': 0.4643572547778427}
2022-11-28 06:22:31,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:31,684 INFO:     Epoch: 29
2022-11-28 06:22:32,348 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48454958166588435, 'Total loss': 0.48454958166588435} | train loss {'Reaction outcome loss': 0.4794132678735594, 'Total loss': 0.4794132678735594}
2022-11-28 06:22:32,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:32,348 INFO:     Epoch: 30
2022-11-28 06:22:33,012 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4738300710239194, 'Total loss': 0.4738300710239194} | train loss {'Reaction outcome loss': 0.47930678667930454, 'Total loss': 0.47930678667930454}
2022-11-28 06:22:33,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:33,012 INFO:     Epoch: 31
2022-11-28 06:22:33,677 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5238241113044999, 'Total loss': 0.5238241113044999} | train loss {'Reaction outcome loss': 0.46631067294461526, 'Total loss': 0.46631067294461526}
2022-11-28 06:22:33,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:33,677 INFO:     Epoch: 32
2022-11-28 06:22:34,339 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46879164942286233, 'Total loss': 0.46879164942286233} | train loss {'Reaction outcome loss': 0.47296821148048046, 'Total loss': 0.47296821148048046}
2022-11-28 06:22:34,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:34,339 INFO:     Epoch: 33
2022-11-28 06:22:35,002 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5034640123221007, 'Total loss': 0.5034640123221007} | train loss {'Reaction outcome loss': 0.4735163206513594, 'Total loss': 0.4735163206513594}
2022-11-28 06:22:35,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:35,003 INFO:     Epoch: 34
2022-11-28 06:22:35,667 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4766301411119374, 'Total loss': 0.4766301411119374} | train loss {'Reaction outcome loss': 0.4743734408728024, 'Total loss': 0.4743734408728024}
2022-11-28 06:22:35,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:35,667 INFO:     Epoch: 35
2022-11-28 06:22:36,332 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5267385359514843, 'Total loss': 0.5267385359514843} | train loss {'Reaction outcome loss': 0.47424181614086214, 'Total loss': 0.47424181614086214}
2022-11-28 06:22:36,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:36,333 INFO:     Epoch: 36
2022-11-28 06:22:36,999 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.522018893875859, 'Total loss': 0.522018893875859} | train loss {'Reaction outcome loss': 0.46428963059355854, 'Total loss': 0.46428963059355854}
2022-11-28 06:22:36,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:36,999 INFO:     Epoch: 37
2022-11-28 06:22:37,660 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5061267890374769, 'Total loss': 0.5061267890374769} | train loss {'Reaction outcome loss': 0.4781504066751493, 'Total loss': 0.4781504066751493}
2022-11-28 06:22:37,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:37,661 INFO:     Epoch: 38
2022-11-28 06:22:38,324 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49519208615476434, 'Total loss': 0.49519208615476434} | train loss {'Reaction outcome loss': 0.4619967061347566, 'Total loss': 0.4619967061347566}
2022-11-28 06:22:38,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:38,325 INFO:     Epoch: 39
2022-11-28 06:22:38,988 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4938448681072755, 'Total loss': 0.4938448681072755} | train loss {'Reaction outcome loss': 0.46606757718059216, 'Total loss': 0.46606757718059216}
2022-11-28 06:22:38,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:38,989 INFO:     Epoch: 40
2022-11-28 06:22:39,654 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5042118846692822, 'Total loss': 0.5042118846692822} | train loss {'Reaction outcome loss': 0.46852562621024696, 'Total loss': 0.46852562621024696}
2022-11-28 06:22:39,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:39,655 INFO:     Epoch: 41
2022-11-28 06:22:40,320 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5172464192252267, 'Total loss': 0.5172464192252267} | train loss {'Reaction outcome loss': 0.46930790243119846, 'Total loss': 0.46930790243119846}
2022-11-28 06:22:40,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:40,320 INFO:     Epoch: 42
2022-11-28 06:22:40,984 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5314180038192056, 'Total loss': 0.5314180038192056} | train loss {'Reaction outcome loss': 0.4787835777559985, 'Total loss': 0.4787835777559985}
2022-11-28 06:22:40,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:40,984 INFO:     Epoch: 43
2022-11-28 06:22:41,648 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47148430855436757, 'Total loss': 0.47148430855436757} | train loss {'Reaction outcome loss': 0.46434314995400816, 'Total loss': 0.46434314995400816}
2022-11-28 06:22:41,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:41,648 INFO:     Epoch: 44
2022-11-28 06:22:42,312 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4896502379666675, 'Total loss': 0.4896502379666675} | train loss {'Reaction outcome loss': 0.47129149566053863, 'Total loss': 0.47129149566053863}
2022-11-28 06:22:42,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:42,313 INFO:     Epoch: 45
2022-11-28 06:22:42,977 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5072688436643644, 'Total loss': 0.5072688436643644} | train loss {'Reaction outcome loss': 0.47927478643564075, 'Total loss': 0.47927478643564075}
2022-11-28 06:22:42,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:42,983 INFO:     Epoch: 46
2022-11-28 06:22:43,645 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49638052487915213, 'Total loss': 0.49638052487915213} | train loss {'Reaction outcome loss': 0.5009601597904194, 'Total loss': 0.5009601597904194}
2022-11-28 06:22:43,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:43,646 INFO:     Epoch: 47
2022-11-28 06:22:44,307 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4940469813617793, 'Total loss': 0.4940469813617793} | train loss {'Reaction outcome loss': 0.4702625951092494, 'Total loss': 0.4702625951092494}
2022-11-28 06:22:44,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:44,308 INFO:     Epoch: 48
2022-11-28 06:22:44,971 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5267567343332551, 'Total loss': 0.5267567343332551} | train loss {'Reaction outcome loss': 0.47933244609051506, 'Total loss': 0.47933244609051506}
2022-11-28 06:22:44,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:44,971 INFO:     Epoch: 49
2022-11-28 06:22:45,637 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45880247991193424, 'Total loss': 0.45880247991193424} | train loss {'Reaction outcome loss': 0.4708022677041741, 'Total loss': 0.4708022677041741}
2022-11-28 06:22:45,637 INFO:     Found new best model at epoch 49
2022-11-28 06:22:45,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:45,638 INFO:     Epoch: 50
2022-11-28 06:22:46,304 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47286936335942964, 'Total loss': 0.47286936335942964} | train loss {'Reaction outcome loss': 0.47525152334800136, 'Total loss': 0.47525152334800136}
2022-11-28 06:22:46,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:46,305 INFO:     Epoch: 51
2022-11-28 06:22:46,971 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49018179354342545, 'Total loss': 0.49018179354342545} | train loss {'Reaction outcome loss': 0.4702468980480785, 'Total loss': 0.4702468980480785}
2022-11-28 06:22:46,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:46,971 INFO:     Epoch: 52
2022-11-28 06:22:47,633 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4705245979130268, 'Total loss': 0.4705245979130268} | train loss {'Reaction outcome loss': 0.46191285429937157, 'Total loss': 0.46191285429937157}
2022-11-28 06:22:47,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:47,634 INFO:     Epoch: 53
2022-11-28 06:22:48,295 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5594047009944916, 'Total loss': 0.5594047009944916} | train loss {'Reaction outcome loss': 0.46294696767803145, 'Total loss': 0.46294696767803145}
2022-11-28 06:22:48,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:48,296 INFO:     Epoch: 54
2022-11-28 06:22:48,960 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4637338661334731, 'Total loss': 0.4637338661334731} | train loss {'Reaction outcome loss': 0.4674104192305492, 'Total loss': 0.4674104192305492}
2022-11-28 06:22:48,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:48,960 INFO:     Epoch: 55
2022-11-28 06:22:49,627 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5126981355927207, 'Total loss': 0.5126981355927207} | train loss {'Reaction outcome loss': 0.46766369684263764, 'Total loss': 0.46766369684263764}
2022-11-28 06:22:49,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:49,628 INFO:     Epoch: 56
2022-11-28 06:22:50,292 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5542062277143652, 'Total loss': 0.5542062277143652} | train loss {'Reaction outcome loss': 0.4740317539398668, 'Total loss': 0.4740317539398668}
2022-11-28 06:22:50,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:50,292 INFO:     Epoch: 57
2022-11-28 06:22:50,960 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46597847748886456, 'Total loss': 0.46597847748886456} | train loss {'Reaction outcome loss': 0.4676978113318262, 'Total loss': 0.4676978113318262}
2022-11-28 06:22:50,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:50,960 INFO:     Epoch: 58
2022-11-28 06:22:51,625 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.524534443562681, 'Total loss': 0.524534443562681} | train loss {'Reaction outcome loss': 0.4710221944550271, 'Total loss': 0.4710221944550271}
2022-11-28 06:22:51,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:51,625 INFO:     Epoch: 59
2022-11-28 06:22:52,291 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.474363197657195, 'Total loss': 0.474363197657195} | train loss {'Reaction outcome loss': 0.4759885418089295, 'Total loss': 0.4759885418089295}
2022-11-28 06:22:52,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:52,291 INFO:     Epoch: 60
2022-11-28 06:22:52,957 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48135129057548265, 'Total loss': 0.48135129057548265} | train loss {'Reaction outcome loss': 0.46879169732513215, 'Total loss': 0.46879169732513215}
2022-11-28 06:22:52,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:52,958 INFO:     Epoch: 61
2022-11-28 06:22:53,622 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4799070673232729, 'Total loss': 0.4799070673232729} | train loss {'Reaction outcome loss': 0.47560330821193664, 'Total loss': 0.47560330821193664}
2022-11-28 06:22:53,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:53,622 INFO:     Epoch: 62
2022-11-28 06:22:54,290 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5009763112122362, 'Total loss': 0.5009763112122362} | train loss {'Reaction outcome loss': 0.47816599923589453, 'Total loss': 0.47816599923589453}
2022-11-28 06:22:54,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:54,290 INFO:     Epoch: 63
2022-11-28 06:22:54,956 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4872595092112368, 'Total loss': 0.4872595092112368} | train loss {'Reaction outcome loss': 0.4684516238538842, 'Total loss': 0.4684516238538842}
2022-11-28 06:22:54,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:54,956 INFO:     Epoch: 64
2022-11-28 06:22:55,619 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49427824738350784, 'Total loss': 0.49427824738350784} | train loss {'Reaction outcome loss': 0.47010120936492195, 'Total loss': 0.47010120936492195}
2022-11-28 06:22:55,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:55,619 INFO:     Epoch: 65
2022-11-28 06:22:56,284 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4886139583858577, 'Total loss': 0.4886139583858577} | train loss {'Reaction outcome loss': 0.4735157646027654, 'Total loss': 0.4735157646027654}
2022-11-28 06:22:56,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:56,284 INFO:     Epoch: 66
2022-11-28 06:22:56,954 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4755256734788418, 'Total loss': 0.4755256734788418} | train loss {'Reaction outcome loss': 0.4779240431392241, 'Total loss': 0.4779240431392241}
2022-11-28 06:22:56,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:56,954 INFO:     Epoch: 67
2022-11-28 06:22:57,617 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4685468656772917, 'Total loss': 0.4685468656772917} | train loss {'Reaction outcome loss': 0.4691980603765621, 'Total loss': 0.4691980603765621}
2022-11-28 06:22:57,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:57,617 INFO:     Epoch: 68
2022-11-28 06:22:58,280 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4853176779367707, 'Total loss': 0.4853176779367707} | train loss {'Reaction outcome loss': 0.46946675797947024, 'Total loss': 0.46946675797947024}
2022-11-28 06:22:58,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:58,280 INFO:     Epoch: 69
2022-11-28 06:22:58,944 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48994967849417165, 'Total loss': 0.48994967849417165} | train loss {'Reaction outcome loss': 0.47339935358877666, 'Total loss': 0.47339935358877666}
2022-11-28 06:22:58,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:58,945 INFO:     Epoch: 70
2022-11-28 06:22:59,609 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.473217903890393, 'Total loss': 0.473217903890393} | train loss {'Reaction outcome loss': 0.4685956708453445, 'Total loss': 0.4685956708453445}
2022-11-28 06:22:59,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:22:59,610 INFO:     Epoch: 71
2022-11-28 06:23:00,273 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47881786940111354, 'Total loss': 0.47881786940111354} | train loss {'Reaction outcome loss': 0.47121340242263515, 'Total loss': 0.47121340242263515}
2022-11-28 06:23:00,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:00,273 INFO:     Epoch: 72
2022-11-28 06:23:00,938 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5164302573962645, 'Total loss': 0.5164302573962645} | train loss {'Reaction outcome loss': 0.4642041516018964, 'Total loss': 0.4642041516018964}
2022-11-28 06:23:00,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:00,939 INFO:     Epoch: 73
2022-11-28 06:23:01,610 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4676124175841158, 'Total loss': 0.4676124175841158} | train loss {'Reaction outcome loss': 0.4640523253785454, 'Total loss': 0.4640523253785454}
2022-11-28 06:23:01,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:01,610 INFO:     Epoch: 74
2022-11-28 06:23:02,275 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47482759708707983, 'Total loss': 0.47482759708707983} | train loss {'Reaction outcome loss': 0.4693593707026137, 'Total loss': 0.4693593707026137}
2022-11-28 06:23:02,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:02,275 INFO:     Epoch: 75
2022-11-28 06:23:02,942 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4920594695616852, 'Total loss': 0.4920594695616852} | train loss {'Reaction outcome loss': 0.46919354703371613, 'Total loss': 0.46919354703371613}
2022-11-28 06:23:02,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:02,942 INFO:     Epoch: 76
2022-11-28 06:23:03,607 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49783105606382544, 'Total loss': 0.49783105606382544} | train loss {'Reaction outcome loss': 0.4730708197905467, 'Total loss': 0.4730708197905467}
2022-11-28 06:23:03,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:03,607 INFO:     Epoch: 77
2022-11-28 06:23:04,273 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4689341380514882, 'Total loss': 0.4689341380514882} | train loss {'Reaction outcome loss': 0.4787049771320482, 'Total loss': 0.4787049771320482}
2022-11-28 06:23:04,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:04,274 INFO:     Epoch: 78
2022-11-28 06:23:04,940 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48072928190231323, 'Total loss': 0.48072928190231323} | train loss {'Reaction outcome loss': 0.46847834833237806, 'Total loss': 0.46847834833237806}
2022-11-28 06:23:04,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:04,940 INFO:     Epoch: 79
2022-11-28 06:23:05,602 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4714308137243444, 'Total loss': 0.4714308137243444} | train loss {'Reaction outcome loss': 0.47639105188460484, 'Total loss': 0.47639105188460484}
2022-11-28 06:23:05,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:05,603 INFO:     Epoch: 80
2022-11-28 06:23:06,270 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4819600629535588, 'Total loss': 0.4819600629535588} | train loss {'Reaction outcome loss': 0.47100574671015566, 'Total loss': 0.47100574671015566}
2022-11-28 06:23:06,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:06,271 INFO:     Epoch: 81
2022-11-28 06:23:06,934 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4984114288606427, 'Total loss': 0.4984114288606427} | train loss {'Reaction outcome loss': 0.46987797138903303, 'Total loss': 0.46987797138903303}
2022-11-28 06:23:06,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:06,935 INFO:     Epoch: 82
2022-11-28 06:23:07,599 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4636097773909569, 'Total loss': 0.4636097773909569} | train loss {'Reaction outcome loss': 0.4646280205955631, 'Total loss': 0.4646280205955631}
2022-11-28 06:23:07,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:07,599 INFO:     Epoch: 83
2022-11-28 06:23:08,265 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5433795540170236, 'Total loss': 0.5433795540170236} | train loss {'Reaction outcome loss': 0.46700328099824157, 'Total loss': 0.46700328099824157}
2022-11-28 06:23:08,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:08,265 INFO:     Epoch: 84
2022-11-28 06:23:08,930 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4809397303245284, 'Total loss': 0.4809397303245284} | train loss {'Reaction outcome loss': 0.4769172341362969, 'Total loss': 0.4769172341362969}
2022-11-28 06:23:08,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:08,930 INFO:     Epoch: 85
2022-11-28 06:23:09,596 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5047149962999604, 'Total loss': 0.5047149962999604} | train loss {'Reaction outcome loss': 0.46608592358677975, 'Total loss': 0.46608592358677975}
2022-11-28 06:23:09,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:09,596 INFO:     Epoch: 86
2022-11-28 06:23:10,263 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4682911316102201, 'Total loss': 0.4682911316102201} | train loss {'Reaction outcome loss': 0.4758440318558863, 'Total loss': 0.4758440318558863}
2022-11-28 06:23:10,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:10,263 INFO:     Epoch: 87
2022-11-28 06:23:10,931 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47853593629869545, 'Total loss': 0.47853593629869545} | train loss {'Reaction outcome loss': 0.472983736801244, 'Total loss': 0.472983736801244}
2022-11-28 06:23:10,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:10,931 INFO:     Epoch: 88
2022-11-28 06:23:11,599 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4751690355214206, 'Total loss': 0.4751690355214206} | train loss {'Reaction outcome loss': 0.480471286590886, 'Total loss': 0.480471286590886}
2022-11-28 06:23:11,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:11,599 INFO:     Epoch: 89
2022-11-28 06:23:12,267 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46106559850952844, 'Total loss': 0.46106559850952844} | train loss {'Reaction outcome loss': 0.45919694481530654, 'Total loss': 0.45919694481530654}
2022-11-28 06:23:12,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:12,267 INFO:     Epoch: 90
2022-11-28 06:23:12,937 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47805569422515953, 'Total loss': 0.47805569422515953} | train loss {'Reaction outcome loss': 0.480451066846307, 'Total loss': 0.480451066846307}
2022-11-28 06:23:12,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:12,937 INFO:     Epoch: 91
2022-11-28 06:23:13,607 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4871015237136321, 'Total loss': 0.4871015237136321} | train loss {'Reaction outcome loss': 0.4790603084120191, 'Total loss': 0.4790603084120191}
2022-11-28 06:23:13,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:13,607 INFO:     Epoch: 92
2022-11-28 06:23:14,273 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4497752697630362, 'Total loss': 0.4497752697630362} | train loss {'Reaction outcome loss': 0.4644255131814885, 'Total loss': 0.4644255131814885}
2022-11-28 06:23:14,274 INFO:     Found new best model at epoch 92
2022-11-28 06:23:14,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:14,274 INFO:     Epoch: 93
2022-11-28 06:23:14,939 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5211348293179815, 'Total loss': 0.5211348293179815} | train loss {'Reaction outcome loss': 0.4695455942318024, 'Total loss': 0.4695455942318024}
2022-11-28 06:23:14,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:14,939 INFO:     Epoch: 94
2022-11-28 06:23:15,609 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4633139979771592, 'Total loss': 0.4633139979771592} | train loss {'Reaction outcome loss': 0.4638962648848547, 'Total loss': 0.4638962648848547}
2022-11-28 06:23:15,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:15,610 INFO:     Epoch: 95
2022-11-28 06:23:16,275 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5089686604386027, 'Total loss': 0.5089686604386027} | train loss {'Reaction outcome loss': 0.47039938099712497, 'Total loss': 0.47039938099712497}
2022-11-28 06:23:16,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:16,275 INFO:     Epoch: 96
2022-11-28 06:23:16,941 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5053163407878443, 'Total loss': 0.5053163407878443} | train loss {'Reaction outcome loss': 0.46508360735559273, 'Total loss': 0.46508360735559273}
2022-11-28 06:23:16,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:16,942 INFO:     Epoch: 97
2022-11-28 06:23:17,612 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4760237258266319, 'Total loss': 0.4760237258266319} | train loss {'Reaction outcome loss': 0.47911052571737817, 'Total loss': 0.47911052571737817}
2022-11-28 06:23:17,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:17,613 INFO:     Epoch: 98
2022-11-28 06:23:18,285 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48395092446695676, 'Total loss': 0.48395092446695676} | train loss {'Reaction outcome loss': 0.47215519869617123, 'Total loss': 0.47215519869617123}
2022-11-28 06:23:18,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:18,285 INFO:     Epoch: 99
2022-11-28 06:23:18,952 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47645938565785234, 'Total loss': 0.47645938565785234} | train loss {'Reaction outcome loss': 0.4712711857360324, 'Total loss': 0.4712711857360324}
2022-11-28 06:23:18,952 INFO:     Best model found after epoch 93 of 100.
2022-11-28 06:23:18,952 INFO:   Done with stage: TRAINING
2022-11-28 06:23:18,952 INFO:   Starting stage: EVALUATION
2022-11-28 06:23:19,072 INFO:   Done with stage: EVALUATION
2022-11-28 06:23:19,072 INFO:   Leaving out SEQ value Fold_9
2022-11-28 06:23:19,085 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:23:19,085 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:23:19,738 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:23:19,739 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:23:19,809 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:23:19,809 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:23:19,809 INFO:     No hyperparam tuning for this model
2022-11-28 06:23:19,809 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:23:19,809 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:23:19,810 INFO:     None feature selector for col prot
2022-11-28 06:23:19,810 INFO:     None feature selector for col prot
2022-11-28 06:23:19,810 INFO:     None feature selector for col prot
2022-11-28 06:23:19,811 INFO:     None feature selector for col chem
2022-11-28 06:23:19,811 INFO:     None feature selector for col chem
2022-11-28 06:23:19,811 INFO:     None feature selector for col chem
2022-11-28 06:23:19,811 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:23:19,811 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:23:19,813 INFO:     Number of params in model 169651
2022-11-28 06:23:19,816 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:23:19,816 INFO:   Starting stage: TRAINING
2022-11-28 06:23:19,867 INFO:     Val loss before train {'Reaction outcome loss': 0.9895001433112405, 'Total loss': 0.9895001433112405}
2022-11-28 06:23:19,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:19,868 INFO:     Epoch: 0
2022-11-28 06:23:20,538 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5899989991025492, 'Total loss': 0.5899989991025492} | train loss {'Reaction outcome loss': 0.6816784165078594, 'Total loss': 0.6816784165078594}
2022-11-28 06:23:20,538 INFO:     Found new best model at epoch 0
2022-11-28 06:23:20,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:20,539 INFO:     Epoch: 1
2022-11-28 06:23:21,216 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5719342658465559, 'Total loss': 0.5719342658465559} | train loss {'Reaction outcome loss': 0.5900700987587052, 'Total loss': 0.5900700987587052}
2022-11-28 06:23:21,216 INFO:     Found new best model at epoch 1
2022-11-28 06:23:21,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:21,217 INFO:     Epoch: 2
2022-11-28 06:23:21,889 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5931645459072157, 'Total loss': 0.5931645459072157} | train loss {'Reaction outcome loss': 0.5572794143471026, 'Total loss': 0.5572794143471026}
2022-11-28 06:23:21,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:21,889 INFO:     Epoch: 3
2022-11-28 06:23:22,565 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5486521358517084, 'Total loss': 0.5486521358517084} | train loss {'Reaction outcome loss': 0.5491770561183652, 'Total loss': 0.5491770561183652}
2022-11-28 06:23:22,565 INFO:     Found new best model at epoch 3
2022-11-28 06:23:22,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:22,566 INFO:     Epoch: 4
2022-11-28 06:23:23,237 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.52067512341521, 'Total loss': 0.52067512341521} | train loss {'Reaction outcome loss': 0.5256482570041572, 'Total loss': 0.5256482570041572}
2022-11-28 06:23:23,238 INFO:     Found new best model at epoch 4
2022-11-28 06:23:23,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:23,239 INFO:     Epoch: 5
2022-11-28 06:23:23,908 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6054535230452364, 'Total loss': 0.6054535230452364} | train loss {'Reaction outcome loss': 0.5281454518197044, 'Total loss': 0.5281454518197044}
2022-11-28 06:23:23,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:23,909 INFO:     Epoch: 6
2022-11-28 06:23:24,578 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5111540779471397, 'Total loss': 0.5111540779471397} | train loss {'Reaction outcome loss': 0.504460079204892, 'Total loss': 0.504460079204892}
2022-11-28 06:23:24,578 INFO:     Found new best model at epoch 6
2022-11-28 06:23:24,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:24,579 INFO:     Epoch: 7
2022-11-28 06:23:25,258 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49566403471610765, 'Total loss': 0.49566403471610765} | train loss {'Reaction outcome loss': 0.5097408523602832, 'Total loss': 0.5097408523602832}
2022-11-28 06:23:25,258 INFO:     Found new best model at epoch 7
2022-11-28 06:23:25,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:25,259 INFO:     Epoch: 8
2022-11-28 06:23:25,932 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.480333709242669, 'Total loss': 0.480333709242669} | train loss {'Reaction outcome loss': 0.49959235470141133, 'Total loss': 0.49959235470141133}
2022-11-28 06:23:25,932 INFO:     Found new best model at epoch 8
2022-11-28 06:23:25,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:25,933 INFO:     Epoch: 9
2022-11-28 06:23:26,603 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.497703822160309, 'Total loss': 0.497703822160309} | train loss {'Reaction outcome loss': 0.49529659306450236, 'Total loss': 0.49529659306450236}
2022-11-28 06:23:26,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:26,603 INFO:     Epoch: 10
2022-11-28 06:23:27,273 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4916654388335618, 'Total loss': 0.4916654388335618} | train loss {'Reaction outcome loss': 0.4991332856757987, 'Total loss': 0.4991332856757987}
2022-11-28 06:23:27,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:27,273 INFO:     Epoch: 11
2022-11-28 06:23:27,941 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5113879039206288, 'Total loss': 0.5113879039206288} | train loss {'Reaction outcome loss': 0.49635134162681716, 'Total loss': 0.49635134162681716}
2022-11-28 06:23:27,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:27,941 INFO:     Epoch: 12
2022-11-28 06:23:28,610 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48426438021388923, 'Total loss': 0.48426438021388923} | train loss {'Reaction outcome loss': 0.4938701405039718, 'Total loss': 0.4938701405039718}
2022-11-28 06:23:28,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:28,611 INFO:     Epoch: 13
2022-11-28 06:23:29,279 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5052825950763442, 'Total loss': 0.5052825950763442} | train loss {'Reaction outcome loss': 0.485051259969271, 'Total loss': 0.485051259969271}
2022-11-28 06:23:29,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:29,279 INFO:     Epoch: 14
2022-11-28 06:23:29,949 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4923933338035237, 'Total loss': 0.4923933338035237} | train loss {'Reaction outcome loss': 0.488451577302429, 'Total loss': 0.488451577302429}
2022-11-28 06:23:29,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:29,950 INFO:     Epoch: 15
2022-11-28 06:23:30,623 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5649799061092463, 'Total loss': 0.5649799061092463} | train loss {'Reaction outcome loss': 0.48545703141679686, 'Total loss': 0.48545703141679686}
2022-11-28 06:23:30,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:30,623 INFO:     Epoch: 16
2022-11-28 06:23:31,291 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5143039663406935, 'Total loss': 0.5143039663406935} | train loss {'Reaction outcome loss': 0.4807860493479717, 'Total loss': 0.4807860493479717}
2022-11-28 06:23:31,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:31,291 INFO:     Epoch: 17
2022-11-28 06:23:31,966 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5401397625153715, 'Total loss': 0.5401397625153715} | train loss {'Reaction outcome loss': 0.47978154599906936, 'Total loss': 0.47978154599906936}
2022-11-28 06:23:31,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:31,966 INFO:     Epoch: 18
2022-11-28 06:23:32,639 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5210733833638105, 'Total loss': 0.5210733833638105} | train loss {'Reaction outcome loss': 0.4842228053678428, 'Total loss': 0.4842228053678428}
2022-11-28 06:23:32,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:32,639 INFO:     Epoch: 19
2022-11-28 06:23:33,308 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49841688573360443, 'Total loss': 0.49841688573360443} | train loss {'Reaction outcome loss': 0.4821488210751164, 'Total loss': 0.4821488210751164}
2022-11-28 06:23:33,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:33,308 INFO:     Epoch: 20
2022-11-28 06:23:33,974 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5171228369528597, 'Total loss': 0.5171228369528597} | train loss {'Reaction outcome loss': 0.48478551593519026, 'Total loss': 0.48478551593519026}
2022-11-28 06:23:33,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:33,975 INFO:     Epoch: 21
2022-11-28 06:23:34,639 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5049771751192483, 'Total loss': 0.5049771751192483} | train loss {'Reaction outcome loss': 0.4716467984140881, 'Total loss': 0.4716467984140881}
2022-11-28 06:23:34,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:34,640 INFO:     Epoch: 22
2022-11-28 06:23:35,308 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.506867112761194, 'Total loss': 0.506867112761194} | train loss {'Reaction outcome loss': 0.4789320900435409, 'Total loss': 0.4789320900435409}
2022-11-28 06:23:35,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:35,309 INFO:     Epoch: 23
2022-11-28 06:23:35,976 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5087894343517043, 'Total loss': 0.5087894343517043} | train loss {'Reaction outcome loss': 0.4845134147833432, 'Total loss': 0.4845134147833432}
2022-11-28 06:23:35,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:35,976 INFO:     Epoch: 24
2022-11-28 06:23:36,643 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4908404431559823, 'Total loss': 0.4908404431559823} | train loss {'Reaction outcome loss': 0.4729732568225553, 'Total loss': 0.4729732568225553}
2022-11-28 06:23:36,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:36,643 INFO:     Epoch: 25
2022-11-28 06:23:37,316 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4847578118470582, 'Total loss': 0.4847578118470582} | train loss {'Reaction outcome loss': 0.47267228947772133, 'Total loss': 0.47267228947772133}
2022-11-28 06:23:37,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:37,316 INFO:     Epoch: 26
2022-11-28 06:23:37,987 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4951124018566175, 'Total loss': 0.4951124018566175} | train loss {'Reaction outcome loss': 0.4721891398751928, 'Total loss': 0.4721891398751928}
2022-11-28 06:23:37,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:37,988 INFO:     Epoch: 27
2022-11-28 06:23:38,663 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5017289011315866, 'Total loss': 0.5017289011315866} | train loss {'Reaction outcome loss': 0.47353613953436574, 'Total loss': 0.47353613953436574}
2022-11-28 06:23:38,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:38,663 INFO:     Epoch: 28
2022-11-28 06:23:39,339 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4754618893970143, 'Total loss': 0.4754618893970143} | train loss {'Reaction outcome loss': 0.48081470653414726, 'Total loss': 0.48081470653414726}
2022-11-28 06:23:39,339 INFO:     Found new best model at epoch 28
2022-11-28 06:23:39,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:39,340 INFO:     Epoch: 29
2022-11-28 06:23:40,012 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49778213622895157, 'Total loss': 0.49778213622895157} | train loss {'Reaction outcome loss': 0.47456447038078503, 'Total loss': 0.47456447038078503}
2022-11-28 06:23:40,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:40,012 INFO:     Epoch: 30
2022-11-28 06:23:40,684 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4749057184566151, 'Total loss': 0.4749057184566151} | train loss {'Reaction outcome loss': 0.47721307664628954, 'Total loss': 0.47721307664628954}
2022-11-28 06:23:40,684 INFO:     Found new best model at epoch 30
2022-11-28 06:23:40,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:40,685 INFO:     Epoch: 31
2022-11-28 06:23:41,359 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48102290623567323, 'Total loss': 0.48102290623567323} | train loss {'Reaction outcome loss': 0.4827408944406817, 'Total loss': 0.4827408944406817}
2022-11-28 06:23:41,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:41,360 INFO:     Epoch: 32
2022-11-28 06:23:42,031 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47611813044006174, 'Total loss': 0.47611813044006174} | train loss {'Reaction outcome loss': 0.4794806766534044, 'Total loss': 0.4794806766534044}
2022-11-28 06:23:42,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:42,031 INFO:     Epoch: 33
2022-11-28 06:23:42,704 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4938314753499898, 'Total loss': 0.4938314753499898} | train loss {'Reaction outcome loss': 0.4745879081949111, 'Total loss': 0.4745879081949111}
2022-11-28 06:23:42,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:42,704 INFO:     Epoch: 34
2022-11-28 06:23:43,375 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47843260927633807, 'Total loss': 0.47843260927633807} | train loss {'Reaction outcome loss': 0.4794733974962465, 'Total loss': 0.4794733974962465}
2022-11-28 06:23:43,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:43,375 INFO:     Epoch: 35
2022-11-28 06:23:44,045 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48816378888758744, 'Total loss': 0.48816378888758744} | train loss {'Reaction outcome loss': 0.47649965152865453, 'Total loss': 0.47649965152865453}
2022-11-28 06:23:44,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:44,045 INFO:     Epoch: 36
2022-11-28 06:23:44,713 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5053212188861587, 'Total loss': 0.5053212188861587} | train loss {'Reaction outcome loss': 0.4800833386158751, 'Total loss': 0.4800833386158751}
2022-11-28 06:23:44,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:44,713 INFO:     Epoch: 37
2022-11-28 06:23:45,383 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.50221832502972, 'Total loss': 0.50221832502972} | train loss {'Reaction outcome loss': 0.4848399414650856, 'Total loss': 0.4848399414650856}
2022-11-28 06:23:45,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:45,383 INFO:     Epoch: 38
2022-11-28 06:23:46,052 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4806506484746933, 'Total loss': 0.4806506484746933} | train loss {'Reaction outcome loss': 0.48088365913398806, 'Total loss': 0.48088365913398806}
2022-11-28 06:23:46,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:46,052 INFO:     Epoch: 39
2022-11-28 06:23:46,726 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.512597725472667, 'Total loss': 0.512597725472667} | train loss {'Reaction outcome loss': 0.47545268440679195, 'Total loss': 0.47545268440679195}
2022-11-28 06:23:46,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:46,726 INFO:     Epoch: 40
2022-11-28 06:23:47,401 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48883264511823654, 'Total loss': 0.48883264511823654} | train loss {'Reaction outcome loss': 0.4796467709445184, 'Total loss': 0.4796467709445184}
2022-11-28 06:23:47,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:47,402 INFO:     Epoch: 41
2022-11-28 06:23:48,071 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48099570822986687, 'Total loss': 0.48099570822986687} | train loss {'Reaction outcome loss': 0.47643998304321883, 'Total loss': 0.47643998304321883}
2022-11-28 06:23:48,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:48,072 INFO:     Epoch: 42
2022-11-28 06:23:48,743 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46555529602549295, 'Total loss': 0.46555529602549295} | train loss {'Reaction outcome loss': 0.4795377927441751, 'Total loss': 0.4795377927441751}
2022-11-28 06:23:48,743 INFO:     Found new best model at epoch 42
2022-11-28 06:23:48,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:48,744 INFO:     Epoch: 43
2022-11-28 06:23:49,415 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49861719797958026, 'Total loss': 0.49861719797958026} | train loss {'Reaction outcome loss': 0.4854116944536086, 'Total loss': 0.4854116944536086}
2022-11-28 06:23:49,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:49,415 INFO:     Epoch: 44
2022-11-28 06:23:50,084 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48064513673836534, 'Total loss': 0.48064513673836534} | train loss {'Reaction outcome loss': 0.47970741572639636, 'Total loss': 0.47970741572639636}
2022-11-28 06:23:50,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:50,085 INFO:     Epoch: 45
2022-11-28 06:23:50,755 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.527291112664071, 'Total loss': 0.527291112664071} | train loss {'Reaction outcome loss': 0.48081869589945964, 'Total loss': 0.48081869589945964}
2022-11-28 06:23:50,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:50,755 INFO:     Epoch: 46
2022-11-28 06:23:51,423 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49953518266027624, 'Total loss': 0.49953518266027624} | train loss {'Reaction outcome loss': 0.4796563824939151, 'Total loss': 0.4796563824939151}
2022-11-28 06:23:51,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:51,424 INFO:     Epoch: 47
2022-11-28 06:23:52,094 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4871119396253066, 'Total loss': 0.4871119396253066} | train loss {'Reaction outcome loss': 0.48324969176563526, 'Total loss': 0.48324969176563526}
2022-11-28 06:23:52,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:52,094 INFO:     Epoch: 48
2022-11-28 06:23:52,766 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4897399355064739, 'Total loss': 0.4897399355064739} | train loss {'Reaction outcome loss': 0.4807374592750303, 'Total loss': 0.4807374592750303}
2022-11-28 06:23:52,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:52,766 INFO:     Epoch: 49
2022-11-28 06:23:53,438 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47318840670314705, 'Total loss': 0.47318840670314705} | train loss {'Reaction outcome loss': 0.478724877560331, 'Total loss': 0.478724877560331}
2022-11-28 06:23:53,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:53,439 INFO:     Epoch: 50
2022-11-28 06:23:54,108 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48794850131327455, 'Total loss': 0.48794850131327455} | train loss {'Reaction outcome loss': 0.48097106928546585, 'Total loss': 0.48097106928546585}
2022-11-28 06:23:54,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:54,109 INFO:     Epoch: 51
2022-11-28 06:23:54,779 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48495817658576096, 'Total loss': 0.48495817658576096} | train loss {'Reaction outcome loss': 0.4792616449056133, 'Total loss': 0.4792616449056133}
2022-11-28 06:23:54,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:54,780 INFO:     Epoch: 52
2022-11-28 06:23:55,454 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5210807052525607, 'Total loss': 0.5210807052525607} | train loss {'Reaction outcome loss': 0.48389658446033157, 'Total loss': 0.48389658446033157}
2022-11-28 06:23:55,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:55,454 INFO:     Epoch: 53
2022-11-28 06:23:56,133 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.506996826692061, 'Total loss': 0.506996826692061} | train loss {'Reaction outcome loss': 0.4836828803583499, 'Total loss': 0.4836828803583499}
2022-11-28 06:23:56,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:56,133 INFO:     Epoch: 54
2022-11-28 06:23:56,806 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5155540257692337, 'Total loss': 0.5155540257692337} | train loss {'Reaction outcome loss': 0.4837776537864439, 'Total loss': 0.4837776537864439}
2022-11-28 06:23:56,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:56,806 INFO:     Epoch: 55
2022-11-28 06:23:57,481 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48953294483098114, 'Total loss': 0.48953294483098114} | train loss {'Reaction outcome loss': 0.4764631243362542, 'Total loss': 0.4764631243362542}
2022-11-28 06:23:57,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:57,481 INFO:     Epoch: 56
2022-11-28 06:23:58,154 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5067079372026704, 'Total loss': 0.5067079372026704} | train loss {'Reaction outcome loss': 0.4757127862183317, 'Total loss': 0.4757127862183317}
2022-11-28 06:23:58,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:58,155 INFO:     Epoch: 57
2022-11-28 06:23:58,827 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47657352821393445, 'Total loss': 0.47657352821393445} | train loss {'Reaction outcome loss': 0.4794377303051372, 'Total loss': 0.4794377303051372}
2022-11-28 06:23:58,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:58,827 INFO:     Epoch: 58
2022-11-28 06:23:59,500 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4665009281174703, 'Total loss': 0.4665009281174703} | train loss {'Reaction outcome loss': 0.48943337041043466, 'Total loss': 0.48943337041043466}
2022-11-28 06:23:59,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:23:59,501 INFO:     Epoch: 59
2022-11-28 06:24:00,173 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5065469751981172, 'Total loss': 0.5065469751981172} | train loss {'Reaction outcome loss': 0.48027123090240265, 'Total loss': 0.48027123090240265}
2022-11-28 06:24:00,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:00,173 INFO:     Epoch: 60
2022-11-28 06:24:00,846 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4825526269322092, 'Total loss': 0.4825526269322092} | train loss {'Reaction outcome loss': 0.48389342556437176, 'Total loss': 0.48389342556437176}
2022-11-28 06:24:00,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:00,847 INFO:     Epoch: 61
2022-11-28 06:24:01,520 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47954981096766214, 'Total loss': 0.47954981096766214} | train loss {'Reaction outcome loss': 0.48033924112396853, 'Total loss': 0.48033924112396853}
2022-11-28 06:24:01,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:01,520 INFO:     Epoch: 62
2022-11-28 06:24:02,189 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5089974074878476, 'Total loss': 0.5089974074878476} | train loss {'Reaction outcome loss': 0.47964915999722096, 'Total loss': 0.47964915999722096}
2022-11-28 06:24:02,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:02,190 INFO:     Epoch: 63
2022-11-28 06:24:02,861 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4875772368501533, 'Total loss': 0.4875772368501533} | train loss {'Reaction outcome loss': 0.47875244374717435, 'Total loss': 0.47875244374717435}
2022-11-28 06:24:02,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:02,861 INFO:     Epoch: 64
2022-11-28 06:24:03,532 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45796990394592285, 'Total loss': 0.45796990394592285} | train loss {'Reaction outcome loss': 0.4831725169994658, 'Total loss': 0.4831725169994658}
2022-11-28 06:24:03,532 INFO:     Found new best model at epoch 64
2022-11-28 06:24:03,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:03,533 INFO:     Epoch: 65
2022-11-28 06:24:04,204 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4839198406447064, 'Total loss': 0.4839198406447064} | train loss {'Reaction outcome loss': 0.48019472221213, 'Total loss': 0.48019472221213}
2022-11-28 06:24:04,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:04,204 INFO:     Epoch: 66
2022-11-28 06:24:04,873 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4611504457213662, 'Total loss': 0.4611504457213662} | train loss {'Reaction outcome loss': 0.48368966621496984, 'Total loss': 0.48368966621496984}
2022-11-28 06:24:04,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:04,873 INFO:     Epoch: 67
2022-11-28 06:24:05,543 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.481125859035687, 'Total loss': 0.481125859035687} | train loss {'Reaction outcome loss': 0.4779421678113361, 'Total loss': 0.4779421678113361}
2022-11-28 06:24:05,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:05,544 INFO:     Epoch: 68
2022-11-28 06:24:06,212 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5134703225710175, 'Total loss': 0.5134703225710175} | train loss {'Reaction outcome loss': 0.47739643663648634, 'Total loss': 0.47739643663648634}
2022-11-28 06:24:06,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:06,213 INFO:     Epoch: 69
2022-11-28 06:24:06,882 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4960969425737858, 'Total loss': 0.4960969425737858} | train loss {'Reaction outcome loss': 0.4806288307712924, 'Total loss': 0.4806288307712924}
2022-11-28 06:24:06,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:06,882 INFO:     Epoch: 70
2022-11-28 06:24:07,557 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46093753759156575, 'Total loss': 0.46093753759156575} | train loss {'Reaction outcome loss': 0.4777633363320943, 'Total loss': 0.4777633363320943}
2022-11-28 06:24:07,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:07,557 INFO:     Epoch: 71
2022-11-28 06:24:08,230 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4824646802788431, 'Total loss': 0.4824646802788431} | train loss {'Reaction outcome loss': 0.4812172936095345, 'Total loss': 0.4812172936095345}
2022-11-28 06:24:08,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:08,230 INFO:     Epoch: 72
2022-11-28 06:24:08,902 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49731196429241786, 'Total loss': 0.49731196429241786} | train loss {'Reaction outcome loss': 0.4753053415446512, 'Total loss': 0.4753053415446512}
2022-11-28 06:24:08,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:08,902 INFO:     Epoch: 73
2022-11-28 06:24:09,573 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4921741759912534, 'Total loss': 0.4921741759912534} | train loss {'Reaction outcome loss': 0.47277983121814265, 'Total loss': 0.47277983121814265}
2022-11-28 06:24:09,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:09,573 INFO:     Epoch: 74
2022-11-28 06:24:10,246 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5071520737626336, 'Total loss': 0.5071520737626336} | train loss {'Reaction outcome loss': 0.47925758352803605, 'Total loss': 0.47925758352803605}
2022-11-28 06:24:10,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:10,246 INFO:     Epoch: 75
2022-11-28 06:24:10,913 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.477421450343999, 'Total loss': 0.477421450343999} | train loss {'Reaction outcome loss': 0.482918661568434, 'Total loss': 0.482918661568434}
2022-11-28 06:24:10,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:10,913 INFO:     Epoch: 76
2022-11-28 06:24:11,583 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47818038578737865, 'Total loss': 0.47818038578737865} | train loss {'Reaction outcome loss': 0.4795761544017061, 'Total loss': 0.4795761544017061}
2022-11-28 06:24:11,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:11,583 INFO:     Epoch: 77
2022-11-28 06:24:12,254 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4913009831851179, 'Total loss': 0.4913009831851179} | train loss {'Reaction outcome loss': 0.4735099655245581, 'Total loss': 0.4735099655245581}
2022-11-28 06:24:12,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:12,255 INFO:     Epoch: 78
2022-11-28 06:24:12,925 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5196773619814352, 'Total loss': 0.5196773619814352} | train loss {'Reaction outcome loss': 0.47648497003941764, 'Total loss': 0.47648497003941764}
2022-11-28 06:24:12,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:12,925 INFO:     Epoch: 79
2022-11-28 06:24:13,596 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4723352657800371, 'Total loss': 0.4723352657800371} | train loss {'Reaction outcome loss': 0.48361165373916587, 'Total loss': 0.48361165373916587}
2022-11-28 06:24:13,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:13,597 INFO:     Epoch: 80
2022-11-28 06:24:14,272 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5032694861292839, 'Total loss': 0.5032694861292839} | train loss {'Reaction outcome loss': 0.48227883472798333, 'Total loss': 0.48227883472798333}
2022-11-28 06:24:14,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:14,273 INFO:     Epoch: 81
2022-11-28 06:24:14,942 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48821716383099556, 'Total loss': 0.48821716383099556} | train loss {'Reaction outcome loss': 0.47909663827909577, 'Total loss': 0.47909663827909577}
2022-11-28 06:24:14,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:14,943 INFO:     Epoch: 82
2022-11-28 06:24:15,614 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5091340115124529, 'Total loss': 0.5091340115124529} | train loss {'Reaction outcome loss': 0.47924313477931485, 'Total loss': 0.47924313477931485}
2022-11-28 06:24:15,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:15,615 INFO:     Epoch: 83
2022-11-28 06:24:16,287 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5019677945158698, 'Total loss': 0.5019677945158698} | train loss {'Reaction outcome loss': 0.47751241471738587, 'Total loss': 0.47751241471738587}
2022-11-28 06:24:16,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:16,287 INFO:     Epoch: 84
2022-11-28 06:24:16,958 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46921138736334717, 'Total loss': 0.46921138736334717} | train loss {'Reaction outcome loss': 0.47958317579280946, 'Total loss': 0.47958317579280946}
2022-11-28 06:24:16,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:16,958 INFO:     Epoch: 85
2022-11-28 06:24:17,632 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4970197237350724, 'Total loss': 0.4970197237350724} | train loss {'Reaction outcome loss': 0.480289522798792, 'Total loss': 0.480289522798792}
2022-11-28 06:24:17,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:17,632 INFO:     Epoch: 86
2022-11-28 06:24:18,306 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46742943166331813, 'Total loss': 0.46742943166331813} | train loss {'Reaction outcome loss': 0.4751129805921547, 'Total loss': 0.4751129805921547}
2022-11-28 06:24:18,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:18,306 INFO:     Epoch: 87
2022-11-28 06:24:18,982 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4688451195305044, 'Total loss': 0.4688451195305044} | train loss {'Reaction outcome loss': 0.4770785276026976, 'Total loss': 0.4770785276026976}
2022-11-28 06:24:18,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:18,983 INFO:     Epoch: 88
2022-11-28 06:24:19,659 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.506036371669986, 'Total loss': 0.506036371669986} | train loss {'Reaction outcome loss': 0.48385536208027796, 'Total loss': 0.48385536208027796}
2022-11-28 06:24:19,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:19,660 INFO:     Epoch: 89
2022-11-28 06:24:20,339 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4888096038590778, 'Total loss': 0.4888096038590778} | train loss {'Reaction outcome loss': 0.4761684767661556, 'Total loss': 0.4761684767661556}
2022-11-28 06:24:20,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:20,339 INFO:     Epoch: 90
2022-11-28 06:24:21,014 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4874158115549521, 'Total loss': 0.4874158115549521} | train loss {'Reaction outcome loss': 0.4809193243422816, 'Total loss': 0.4809193243422816}
2022-11-28 06:24:21,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:21,014 INFO:     Epoch: 91
2022-11-28 06:24:21,690 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49451685087247327, 'Total loss': 0.49451685087247327} | train loss {'Reaction outcome loss': 0.4709825346306447, 'Total loss': 0.4709825346306447}
2022-11-28 06:24:21,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:21,690 INFO:     Epoch: 92
2022-11-28 06:24:22,365 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47115184502168134, 'Total loss': 0.47115184502168134} | train loss {'Reaction outcome loss': 0.4761169129201481, 'Total loss': 0.4761169129201481}
2022-11-28 06:24:22,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:22,365 INFO:     Epoch: 93
2022-11-28 06:24:23,042 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.498939591713927, 'Total loss': 0.498939591713927} | train loss {'Reaction outcome loss': 0.4841370024387875, 'Total loss': 0.4841370024387875}
2022-11-28 06:24:23,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:23,042 INFO:     Epoch: 94
2022-11-28 06:24:23,712 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49200660159642046, 'Total loss': 0.49200660159642046} | train loss {'Reaction outcome loss': 0.4727650173609295, 'Total loss': 0.4727650173609295}
2022-11-28 06:24:23,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:23,712 INFO:     Epoch: 95
2022-11-28 06:24:24,391 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5094469643451951, 'Total loss': 0.5094469643451951} | train loss {'Reaction outcome loss': 0.4745236997522654, 'Total loss': 0.4745236997522654}
2022-11-28 06:24:24,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:24,391 INFO:     Epoch: 96
2022-11-28 06:24:25,066 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48290356214750896, 'Total loss': 0.48290356214750896} | train loss {'Reaction outcome loss': 0.48058550666657185, 'Total loss': 0.48058550666657185}
2022-11-28 06:24:25,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:25,067 INFO:     Epoch: 97
2022-11-28 06:24:25,739 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46480774913321843, 'Total loss': 0.46480774913321843} | train loss {'Reaction outcome loss': 0.4824204646771954, 'Total loss': 0.4824204646771954}
2022-11-28 06:24:25,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:25,740 INFO:     Epoch: 98
2022-11-28 06:24:26,414 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4745676978067918, 'Total loss': 0.4745676978067918} | train loss {'Reaction outcome loss': 0.4761963254141231, 'Total loss': 0.4761963254141231}
2022-11-28 06:24:26,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:26,415 INFO:     Epoch: 99
2022-11-28 06:24:27,089 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46586303649978206, 'Total loss': 0.46586303649978206} | train loss {'Reaction outcome loss': 0.4779226824701313, 'Total loss': 0.4779226824701313}
2022-11-28 06:24:27,089 INFO:     Best model found after epoch 65 of 100.
2022-11-28 06:24:27,090 INFO:   Done with stage: TRAINING
2022-11-28 06:24:27,090 INFO:   Starting stage: EVALUATION
2022-11-28 06:24:27,203 INFO:   Done with stage: EVALUATION
2022-11-28 06:24:27,212 INFO:   Leaving out SEQ value Fold_0
2022-11-28 06:24:27,225 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 06:24:27,226 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:24:27,881 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:24:27,881 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:24:27,952 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:24:27,952 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:24:27,952 INFO:     No hyperparam tuning for this model
2022-11-28 06:24:27,952 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:24:27,952 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:24:27,953 INFO:     None feature selector for col prot
2022-11-28 06:24:27,953 INFO:     None feature selector for col prot
2022-11-28 06:24:27,953 INFO:     None feature selector for col prot
2022-11-28 06:24:27,954 INFO:     None feature selector for col chem
2022-11-28 06:24:27,954 INFO:     None feature selector for col chem
2022-11-28 06:24:27,954 INFO:     None feature selector for col chem
2022-11-28 06:24:27,954 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:24:27,954 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:24:27,956 INFO:     Number of params in model 169651
2022-11-28 06:24:27,959 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:24:27,959 INFO:   Starting stage: TRAINING
2022-11-28 06:24:28,011 INFO:     Val loss before train {'Reaction outcome loss': 1.0510558729821986, 'Total loss': 1.0510558729821986}
2022-11-28 06:24:28,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:28,011 INFO:     Epoch: 0
2022-11-28 06:24:28,681 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6069127693772316, 'Total loss': 0.6069127693772316} | train loss {'Reaction outcome loss': 0.7057285219551581, 'Total loss': 0.7057285219551581}
2022-11-28 06:24:28,682 INFO:     Found new best model at epoch 0
2022-11-28 06:24:28,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:28,682 INFO:     Epoch: 1
2022-11-28 06:24:29,352 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5788978229869496, 'Total loss': 0.5788978229869496} | train loss {'Reaction outcome loss': 0.5906385292378273, 'Total loss': 0.5906385292378273}
2022-11-28 06:24:29,352 INFO:     Found new best model at epoch 1
2022-11-28 06:24:29,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:29,353 INFO:     Epoch: 2
2022-11-28 06:24:30,023 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5818719498135827, 'Total loss': 0.5818719498135827} | train loss {'Reaction outcome loss': 0.5687015626715263, 'Total loss': 0.5687015626715263}
2022-11-28 06:24:30,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:30,023 INFO:     Epoch: 3
2022-11-28 06:24:30,693 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5331080498343165, 'Total loss': 0.5331080498343165} | train loss {'Reaction outcome loss': 0.5387553344461841, 'Total loss': 0.5387553344461841}
2022-11-28 06:24:30,693 INFO:     Found new best model at epoch 3
2022-11-28 06:24:30,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:30,694 INFO:     Epoch: 4
2022-11-28 06:24:31,366 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.529766631397334, 'Total loss': 0.529766631397334} | train loss {'Reaction outcome loss': 0.5345658273832036, 'Total loss': 0.5345658273832036}
2022-11-28 06:24:31,366 INFO:     Found new best model at epoch 4
2022-11-28 06:24:31,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:31,367 INFO:     Epoch: 5
2022-11-28 06:24:32,038 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5240958217870105, 'Total loss': 0.5240958217870105} | train loss {'Reaction outcome loss': 0.5337225221067305, 'Total loss': 0.5337225221067305}
2022-11-28 06:24:32,038 INFO:     Found new best model at epoch 5
2022-11-28 06:24:32,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:32,039 INFO:     Epoch: 6
2022-11-28 06:24:32,711 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.56870973973789, 'Total loss': 0.56870973973789} | train loss {'Reaction outcome loss': 0.5255986082590061, 'Total loss': 0.5255986082590061}
2022-11-28 06:24:32,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:32,712 INFO:     Epoch: 7
2022-11-28 06:24:33,389 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5241538672284647, 'Total loss': 0.5241538672284647} | train loss {'Reaction outcome loss': 0.524460837094166, 'Total loss': 0.524460837094166}
2022-11-28 06:24:33,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:33,389 INFO:     Epoch: 8
2022-11-28 06:24:34,061 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5701458819887855, 'Total loss': 0.5701458819887855} | train loss {'Reaction outcome loss': 0.5056903394549964, 'Total loss': 0.5056903394549964}
2022-11-28 06:24:34,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:34,061 INFO:     Epoch: 9
2022-11-28 06:24:34,735 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5352991331707347, 'Total loss': 0.5352991331707347} | train loss {'Reaction outcome loss': 0.5065529712472066, 'Total loss': 0.5065529712472066}
2022-11-28 06:24:34,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:34,735 INFO:     Epoch: 10
2022-11-28 06:24:35,405 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.537242264571515, 'Total loss': 0.537242264571515} | train loss {'Reaction outcome loss': 0.5094558754671923, 'Total loss': 0.5094558754671923}
2022-11-28 06:24:35,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:35,405 INFO:     Epoch: 11
2022-11-28 06:24:36,078 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5226279314268719, 'Total loss': 0.5226279314268719} | train loss {'Reaction outcome loss': 0.5136483696549528, 'Total loss': 0.5136483696549528}
2022-11-28 06:24:36,078 INFO:     Found new best model at epoch 11
2022-11-28 06:24:36,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:36,079 INFO:     Epoch: 12
2022-11-28 06:24:36,749 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4876516749235717, 'Total loss': 0.4876516749235717} | train loss {'Reaction outcome loss': 0.49799517394318754, 'Total loss': 0.49799517394318754}
2022-11-28 06:24:36,749 INFO:     Found new best model at epoch 12
2022-11-28 06:24:36,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:36,750 INFO:     Epoch: 13
2022-11-28 06:24:37,422 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48807415806434373, 'Total loss': 0.48807415806434373} | train loss {'Reaction outcome loss': 0.5090744779539494, 'Total loss': 0.5090744779539494}
2022-11-28 06:24:37,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:37,423 INFO:     Epoch: 14
2022-11-28 06:24:38,095 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49918667633425107, 'Total loss': 0.49918667633425107} | train loss {'Reaction outcome loss': 0.4885293907723446, 'Total loss': 0.4885293907723446}
2022-11-28 06:24:38,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:38,096 INFO:     Epoch: 15
2022-11-28 06:24:38,765 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5212300392714414, 'Total loss': 0.5212300392714414} | train loss {'Reaction outcome loss': 0.4863303180346605, 'Total loss': 0.4863303180346605}
2022-11-28 06:24:38,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:38,765 INFO:     Epoch: 16
2022-11-28 06:24:39,432 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5151752727952871, 'Total loss': 0.5151752727952871} | train loss {'Reaction outcome loss': 0.4827723116406545, 'Total loss': 0.4827723116406545}
2022-11-28 06:24:39,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:39,432 INFO:     Epoch: 17
2022-11-28 06:24:40,101 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5212282863530245, 'Total loss': 0.5212282863530245} | train loss {'Reaction outcome loss': 0.4855731913917943, 'Total loss': 0.4855731913917943}
2022-11-28 06:24:40,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:40,102 INFO:     Epoch: 18
2022-11-28 06:24:40,775 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4947604350745678, 'Total loss': 0.4947604350745678} | train loss {'Reaction outcome loss': 0.49116528989664215, 'Total loss': 0.49116528989664215}
2022-11-28 06:24:40,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:40,775 INFO:     Epoch: 19
2022-11-28 06:24:41,444 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48848051171411166, 'Total loss': 0.48848051171411166} | train loss {'Reaction outcome loss': 0.48826028756525836, 'Total loss': 0.48826028756525836}
2022-11-28 06:24:41,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:41,445 INFO:     Epoch: 20
2022-11-28 06:24:42,118 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5734676562926986, 'Total loss': 0.5734676562926986} | train loss {'Reaction outcome loss': 0.5013394126525292, 'Total loss': 0.5013394126525292}
2022-11-28 06:24:42,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:42,118 INFO:     Epoch: 21
2022-11-28 06:24:42,792 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48557636565105483, 'Total loss': 0.48557636565105483} | train loss {'Reaction outcome loss': 0.4986774710267179, 'Total loss': 0.4986774710267179}
2022-11-28 06:24:42,792 INFO:     Found new best model at epoch 21
2022-11-28 06:24:42,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:42,792 INFO:     Epoch: 22
2022-11-28 06:24:43,462 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5153676664287393, 'Total loss': 0.5153676664287393} | train loss {'Reaction outcome loss': 0.4773931455862546, 'Total loss': 0.4773931455862546}
2022-11-28 06:24:43,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:43,462 INFO:     Epoch: 23
2022-11-28 06:24:44,133 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48793779008767824, 'Total loss': 0.48793779008767824} | train loss {'Reaction outcome loss': 0.4751217451534773, 'Total loss': 0.4751217451534773}
2022-11-28 06:24:44,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:44,134 INFO:     Epoch: 24
2022-11-28 06:24:44,805 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5186538540504195, 'Total loss': 0.5186538540504195} | train loss {'Reaction outcome loss': 0.4796018295804499, 'Total loss': 0.4796018295804499}
2022-11-28 06:24:44,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:44,806 INFO:     Epoch: 25
2022-11-28 06:24:45,478 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4679390632293441, 'Total loss': 0.4679390632293441} | train loss {'Reaction outcome loss': 0.4857646311041315, 'Total loss': 0.4857646311041315}
2022-11-28 06:24:45,478 INFO:     Found new best model at epoch 25
2022-11-28 06:24:45,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:45,479 INFO:     Epoch: 26
2022-11-28 06:24:46,152 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49103530699556525, 'Total loss': 0.49103530699556525} | train loss {'Reaction outcome loss': 0.46874717740636124, 'Total loss': 0.46874717740636124}
2022-11-28 06:24:46,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:46,152 INFO:     Epoch: 27
2022-11-28 06:24:46,827 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4779674475165931, 'Total loss': 0.4779674475165931} | train loss {'Reaction outcome loss': 0.4741211373506016, 'Total loss': 0.4741211373506016}
2022-11-28 06:24:46,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:46,828 INFO:     Epoch: 28
2022-11-28 06:24:47,497 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5406937585635618, 'Total loss': 0.5406937585635618} | train loss {'Reaction outcome loss': 0.4776045374180141, 'Total loss': 0.4776045374180141}
2022-11-28 06:24:47,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:47,498 INFO:     Epoch: 29
2022-11-28 06:24:48,167 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5970987172966654, 'Total loss': 0.5970987172966654} | train loss {'Reaction outcome loss': 0.48163237778643364, 'Total loss': 0.48163237778643364}
2022-11-28 06:24:48,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:48,167 INFO:     Epoch: 30
2022-11-28 06:24:48,836 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5422178911553188, 'Total loss': 0.5422178911553188} | train loss {'Reaction outcome loss': 0.48262228777534083, 'Total loss': 0.48262228777534083}
2022-11-28 06:24:48,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:48,836 INFO:     Epoch: 31
2022-11-28 06:24:49,508 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49881152707067405, 'Total loss': 0.49881152707067405} | train loss {'Reaction outcome loss': 0.49271621503810653, 'Total loss': 0.49271621503810653}
2022-11-28 06:24:49,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:49,509 INFO:     Epoch: 32
2022-11-28 06:24:50,184 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5119463449174707, 'Total loss': 0.5119463449174707} | train loss {'Reaction outcome loss': 0.4782984952398987, 'Total loss': 0.4782984952398987}
2022-11-28 06:24:50,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:50,185 INFO:     Epoch: 33
2022-11-28 06:24:50,856 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5249005932022225, 'Total loss': 0.5249005932022225} | train loss {'Reaction outcome loss': 0.4825526564287753, 'Total loss': 0.4825526564287753}
2022-11-28 06:24:50,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:50,856 INFO:     Epoch: 34
2022-11-28 06:24:51,528 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.487190786071799, 'Total loss': 0.487190786071799} | train loss {'Reaction outcome loss': 0.4791358849297651, 'Total loss': 0.4791358849297651}
2022-11-28 06:24:51,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:51,529 INFO:     Epoch: 35
2022-11-28 06:24:52,200 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5408386625349522, 'Total loss': 0.5408386625349522} | train loss {'Reaction outcome loss': 0.47875471603170583, 'Total loss': 0.47875471603170583}
2022-11-28 06:24:52,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:52,201 INFO:     Epoch: 36
2022-11-28 06:24:52,868 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4697908420454372, 'Total loss': 0.4697908420454372} | train loss {'Reaction outcome loss': 0.4873350538343553, 'Total loss': 0.4873350538343553}
2022-11-28 06:24:52,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:52,868 INFO:     Epoch: 37
2022-11-28 06:24:53,535 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.469785155559128, 'Total loss': 0.469785155559128} | train loss {'Reaction outcome loss': 0.4708464661469826, 'Total loss': 0.4708464661469826}
2022-11-28 06:24:53,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:53,535 INFO:     Epoch: 38
2022-11-28 06:24:54,202 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48579649932005187, 'Total loss': 0.48579649932005187} | train loss {'Reaction outcome loss': 0.47505329739347646, 'Total loss': 0.47505329739347646}
2022-11-28 06:24:54,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:54,202 INFO:     Epoch: 39
2022-11-28 06:24:54,869 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4511311193081466, 'Total loss': 0.4511311193081466} | train loss {'Reaction outcome loss': 0.46416979796452984, 'Total loss': 0.46416979796452984}
2022-11-28 06:24:54,869 INFO:     Found new best model at epoch 39
2022-11-28 06:24:54,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:54,869 INFO:     Epoch: 40
2022-11-28 06:24:55,536 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4691846804185347, 'Total loss': 0.4691846804185347} | train loss {'Reaction outcome loss': 0.4690412795015607, 'Total loss': 0.4690412795015607}
2022-11-28 06:24:55,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:55,536 INFO:     Epoch: 41
2022-11-28 06:24:56,199 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49289053678512573, 'Total loss': 0.49289053678512573} | train loss {'Reaction outcome loss': 0.48475118714426213, 'Total loss': 0.48475118714426213}
2022-11-28 06:24:56,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:56,200 INFO:     Epoch: 42
2022-11-28 06:24:56,868 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49933569421145046, 'Total loss': 0.49933569421145046} | train loss {'Reaction outcome loss': 0.47989910719199824, 'Total loss': 0.47989910719199824}
2022-11-28 06:24:56,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:56,868 INFO:     Epoch: 43
2022-11-28 06:24:57,536 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49736195599490945, 'Total loss': 0.49736195599490945} | train loss {'Reaction outcome loss': 0.4620171364864357, 'Total loss': 0.4620171364864357}
2022-11-28 06:24:57,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:57,537 INFO:     Epoch: 44
2022-11-28 06:24:58,203 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4954183579168536, 'Total loss': 0.4954183579168536} | train loss {'Reaction outcome loss': 0.46908035629281875, 'Total loss': 0.46908035629281875}
2022-11-28 06:24:58,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:58,204 INFO:     Epoch: 45
2022-11-28 06:24:58,871 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4753111783753742, 'Total loss': 0.4753111783753742} | train loss {'Reaction outcome loss': 0.4680676362533801, 'Total loss': 0.4680676362533801}
2022-11-28 06:24:58,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:58,871 INFO:     Epoch: 46
2022-11-28 06:24:59,537 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4769104082476009, 'Total loss': 0.4769104082476009} | train loss {'Reaction outcome loss': 0.46727479159500196, 'Total loss': 0.46727479159500196}
2022-11-28 06:24:59,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:24:59,537 INFO:     Epoch: 47
2022-11-28 06:25:00,202 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49484253877943213, 'Total loss': 0.49484253877943213} | train loss {'Reaction outcome loss': 0.4664879137808495, 'Total loss': 0.4664879137808495}
2022-11-28 06:25:00,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:00,202 INFO:     Epoch: 48
2022-11-28 06:25:00,868 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4730977073989131, 'Total loss': 0.4730977073989131} | train loss {'Reaction outcome loss': 0.4713286942074656, 'Total loss': 0.4713286942074656}
2022-11-28 06:25:00,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:00,868 INFO:     Epoch: 49
2022-11-28 06:25:01,534 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4878652993250977, 'Total loss': 0.4878652993250977} | train loss {'Reaction outcome loss': 0.47366350816811625, 'Total loss': 0.47366350816811625}
2022-11-28 06:25:01,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:01,534 INFO:     Epoch: 50
2022-11-28 06:25:02,199 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5210090276192535, 'Total loss': 0.5210090276192535} | train loss {'Reaction outcome loss': 0.4707765578620347, 'Total loss': 0.4707765578620347}
2022-11-28 06:25:02,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:02,199 INFO:     Epoch: 51
2022-11-28 06:25:02,866 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5024188198149204, 'Total loss': 0.5024188198149204} | train loss {'Reaction outcome loss': 0.4752514241678029, 'Total loss': 0.4752514241678029}
2022-11-28 06:25:02,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:02,866 INFO:     Epoch: 52
2022-11-28 06:25:03,534 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5892557047984817, 'Total loss': 0.5892557047984817} | train loss {'Reaction outcome loss': 0.4769133533905392, 'Total loss': 0.4769133533905392}
2022-11-28 06:25:03,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:03,535 INFO:     Epoch: 53
2022-11-28 06:25:04,201 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45548479936339636, 'Total loss': 0.45548479936339636} | train loss {'Reaction outcome loss': 0.48837296706214284, 'Total loss': 0.48837296706214284}
2022-11-28 06:25:04,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:04,201 INFO:     Epoch: 54
2022-11-28 06:25:04,867 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4661738933487372, 'Total loss': 0.4661738933487372} | train loss {'Reaction outcome loss': 0.46667594610438173, 'Total loss': 0.46667594610438173}
2022-11-28 06:25:04,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:04,867 INFO:     Epoch: 55
2022-11-28 06:25:05,532 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47662748260931537, 'Total loss': 0.47662748260931537} | train loss {'Reaction outcome loss': 0.4764792717359809, 'Total loss': 0.4764792717359809}
2022-11-28 06:25:05,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:05,532 INFO:     Epoch: 56
2022-11-28 06:25:06,197 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49713065881620755, 'Total loss': 0.49713065881620755} | train loss {'Reaction outcome loss': 0.4725447454252224, 'Total loss': 0.4725447454252224}
2022-11-28 06:25:06,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:06,197 INFO:     Epoch: 57
2022-11-28 06:25:06,870 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4930529079654, 'Total loss': 0.4930529079654} | train loss {'Reaction outcome loss': 0.4702610835915635, 'Total loss': 0.4702610835915635}
2022-11-28 06:25:06,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:06,870 INFO:     Epoch: 58
2022-11-28 06:25:07,539 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.51730746708133, 'Total loss': 0.51730746708133} | train loss {'Reaction outcome loss': 0.4610214965184208, 'Total loss': 0.4610214965184208}
2022-11-28 06:25:07,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:07,539 INFO:     Epoch: 59
2022-11-28 06:25:08,205 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4732112403620373, 'Total loss': 0.4732112403620373} | train loss {'Reaction outcome loss': 0.4636392813733956, 'Total loss': 0.4636392813733956}
2022-11-28 06:25:08,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:08,206 INFO:     Epoch: 60
2022-11-28 06:25:08,873 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48993680185892363, 'Total loss': 0.48993680185892363} | train loss {'Reaction outcome loss': 0.46685282825699703, 'Total loss': 0.46685282825699703}
2022-11-28 06:25:08,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:08,873 INFO:     Epoch: 61
2022-11-28 06:25:09,538 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.495264163071459, 'Total loss': 0.495264163071459} | train loss {'Reaction outcome loss': 0.46826543167293794, 'Total loss': 0.46826543167293794}
2022-11-28 06:25:09,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:09,538 INFO:     Epoch: 62
2022-11-28 06:25:10,206 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4938818615945903, 'Total loss': 0.4938818615945903} | train loss {'Reaction outcome loss': 0.4670925776545818, 'Total loss': 0.4670925776545818}
2022-11-28 06:25:10,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:10,207 INFO:     Epoch: 63
2022-11-28 06:25:10,874 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4806162935088981, 'Total loss': 0.4806162935088981} | train loss {'Reaction outcome loss': 0.47541609104828314, 'Total loss': 0.47541609104828314}
2022-11-28 06:25:10,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:10,874 INFO:     Epoch: 64
2022-11-28 06:25:11,539 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4853266260840676, 'Total loss': 0.4853266260840676} | train loss {'Reaction outcome loss': 0.47511390436757434, 'Total loss': 0.47511390436757434}
2022-11-28 06:25:11,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:11,539 INFO:     Epoch: 65
2022-11-28 06:25:12,206 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4657136063006791, 'Total loss': 0.4657136063006791} | train loss {'Reaction outcome loss': 0.48319232490984537, 'Total loss': 0.48319232490984537}
2022-11-28 06:25:12,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:12,206 INFO:     Epoch: 66
2022-11-28 06:25:12,874 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45847187970172276, 'Total loss': 0.45847187970172276} | train loss {'Reaction outcome loss': 0.4783137154120665, 'Total loss': 0.4783137154120665}
2022-11-28 06:25:12,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:12,874 INFO:     Epoch: 67
2022-11-28 06:25:13,543 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.452030286192894, 'Total loss': 0.452030286192894} | train loss {'Reaction outcome loss': 0.46962680055303613, 'Total loss': 0.46962680055303613}
2022-11-28 06:25:13,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:13,543 INFO:     Epoch: 68
2022-11-28 06:25:14,210 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4970993785695596, 'Total loss': 0.4970993785695596} | train loss {'Reaction outcome loss': 0.4707389831965269, 'Total loss': 0.4707389831965269}
2022-11-28 06:25:14,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:14,211 INFO:     Epoch: 69
2022-11-28 06:25:14,879 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4758944701064717, 'Total loss': 0.4758944701064717} | train loss {'Reaction outcome loss': 0.4734834596695688, 'Total loss': 0.4734834596695688}
2022-11-28 06:25:14,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:14,879 INFO:     Epoch: 70
2022-11-28 06:25:15,547 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4819203879345547, 'Total loss': 0.4819203879345547} | train loss {'Reaction outcome loss': 0.4683061809192302, 'Total loss': 0.4683061809192302}
2022-11-28 06:25:15,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:15,548 INFO:     Epoch: 71
2022-11-28 06:25:16,214 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5577896765687249, 'Total loss': 0.5577896765687249} | train loss {'Reaction outcome loss': 0.4747343708870382, 'Total loss': 0.4747343708870382}
2022-11-28 06:25:16,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:16,214 INFO:     Epoch: 72
2022-11-28 06:25:16,882 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4820253700017929, 'Total loss': 0.4820253700017929} | train loss {'Reaction outcome loss': 0.47450571371476175, 'Total loss': 0.47450571371476175}
2022-11-28 06:25:16,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:16,882 INFO:     Epoch: 73
2022-11-28 06:25:17,545 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.507120012559674, 'Total loss': 0.507120012559674} | train loss {'Reaction outcome loss': 0.4763111939223913, 'Total loss': 0.4763111939223913}
2022-11-28 06:25:17,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:17,546 INFO:     Epoch: 74
2022-11-28 06:25:18,212 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47909109192815696, 'Total loss': 0.47909109192815696} | train loss {'Reaction outcome loss': 0.4640293773640747, 'Total loss': 0.4640293773640747}
2022-11-28 06:25:18,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:18,212 INFO:     Epoch: 75
2022-11-28 06:25:18,879 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4481543756344102, 'Total loss': 0.4481543756344102} | train loss {'Reaction outcome loss': 0.4634649133694317, 'Total loss': 0.4634649133694317}
2022-11-28 06:25:18,879 INFO:     Found new best model at epoch 75
2022-11-28 06:25:18,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:18,880 INFO:     Epoch: 76
2022-11-28 06:25:19,545 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4454766136001457, 'Total loss': 0.4454766136001457} | train loss {'Reaction outcome loss': 0.47312095797496284, 'Total loss': 0.47312095797496284}
2022-11-28 06:25:19,545 INFO:     Found new best model at epoch 76
2022-11-28 06:25:19,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:19,546 INFO:     Epoch: 77
2022-11-28 06:25:20,213 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4892926009541208, 'Total loss': 0.4892926009541208} | train loss {'Reaction outcome loss': 0.46496858309034395, 'Total loss': 0.46496858309034395}
2022-11-28 06:25:20,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:20,214 INFO:     Epoch: 78
2022-11-28 06:25:20,881 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4575285501778126, 'Total loss': 0.4575285501778126} | train loss {'Reaction outcome loss': 0.46683395270876554, 'Total loss': 0.46683395270876554}
2022-11-28 06:25:20,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:20,881 INFO:     Epoch: 79
2022-11-28 06:25:21,550 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48841633038087323, 'Total loss': 0.48841633038087323} | train loss {'Reaction outcome loss': 0.4648184473909106, 'Total loss': 0.4648184473909106}
2022-11-28 06:25:21,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:21,551 INFO:     Epoch: 80
2022-11-28 06:25:22,215 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47566312771629204, 'Total loss': 0.47566312771629204} | train loss {'Reaction outcome loss': 0.46632227749443095, 'Total loss': 0.46632227749443095}
2022-11-28 06:25:22,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:22,215 INFO:     Epoch: 81
2022-11-28 06:25:22,881 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4930160147222606, 'Total loss': 0.4930160147222606} | train loss {'Reaction outcome loss': 0.46998198191646623, 'Total loss': 0.46998198191646623}
2022-11-28 06:25:22,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:22,881 INFO:     Epoch: 82
2022-11-28 06:25:23,553 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4592588520185514, 'Total loss': 0.4592588520185514} | train loss {'Reaction outcome loss': 0.47686512557118527, 'Total loss': 0.47686512557118527}
2022-11-28 06:25:23,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:23,553 INFO:     Epoch: 83
2022-11-28 06:25:24,220 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4806236829608679, 'Total loss': 0.4806236829608679} | train loss {'Reaction outcome loss': 0.4782134742751295, 'Total loss': 0.4782134742751295}
2022-11-28 06:25:24,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:24,220 INFO:     Epoch: 84
2022-11-28 06:25:24,890 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4706441421400417, 'Total loss': 0.4706441421400417} | train loss {'Reaction outcome loss': 0.46745310373875776, 'Total loss': 0.46745310373875776}
2022-11-28 06:25:24,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:24,890 INFO:     Epoch: 85
2022-11-28 06:25:25,555 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4802832945503972, 'Total loss': 0.4802832945503972} | train loss {'Reaction outcome loss': 0.46782298386096954, 'Total loss': 0.46782298386096954}
2022-11-28 06:25:25,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:25,555 INFO:     Epoch: 86
2022-11-28 06:25:26,220 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4700951643965461, 'Total loss': 0.4700951643965461} | train loss {'Reaction outcome loss': 0.4749958170087714, 'Total loss': 0.4749958170087714}
2022-11-28 06:25:26,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:26,220 INFO:     Epoch: 87
2022-11-28 06:25:26,887 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5178439437665723, 'Total loss': 0.5178439437665723} | train loss {'Reaction outcome loss': 0.4691367914621164, 'Total loss': 0.4691367914621164}
2022-11-28 06:25:26,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:26,888 INFO:     Epoch: 88
2022-11-28 06:25:27,553 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4543675279075449, 'Total loss': 0.4543675279075449} | train loss {'Reaction outcome loss': 0.4753026615994179, 'Total loss': 0.4753026615994179}
2022-11-28 06:25:27,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:27,554 INFO:     Epoch: 89
2022-11-28 06:25:28,219 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5165119916200638, 'Total loss': 0.5165119916200638} | train loss {'Reaction outcome loss': 0.46374364060760753, 'Total loss': 0.46374364060760753}
2022-11-28 06:25:28,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:28,220 INFO:     Epoch: 90
2022-11-28 06:25:28,888 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49043370004404674, 'Total loss': 0.49043370004404674} | train loss {'Reaction outcome loss': 0.47657954333885477, 'Total loss': 0.47657954333885477}
2022-11-28 06:25:28,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:28,888 INFO:     Epoch: 91
2022-11-28 06:25:29,551 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5017573095180772, 'Total loss': 0.5017573095180772} | train loss {'Reaction outcome loss': 0.4659917265900716, 'Total loss': 0.4659917265900716}
2022-11-28 06:25:29,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:29,552 INFO:     Epoch: 92
2022-11-28 06:25:30,218 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4755624331195246, 'Total loss': 0.4755624331195246} | train loss {'Reaction outcome loss': 0.47816577517551934, 'Total loss': 0.47816577517551934}
2022-11-28 06:25:30,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:30,218 INFO:     Epoch: 93
2022-11-28 06:25:30,884 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4661119119687514, 'Total loss': 0.4661119119687514} | train loss {'Reaction outcome loss': 0.477233757615572, 'Total loss': 0.477233757615572}
2022-11-28 06:25:30,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:30,884 INFO:     Epoch: 94
2022-11-28 06:25:31,550 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5011446750299497, 'Total loss': 0.5011446750299497} | train loss {'Reaction outcome loss': 0.46911950548450926, 'Total loss': 0.46911950548450926}
2022-11-28 06:25:31,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:31,550 INFO:     Epoch: 95
2022-11-28 06:25:32,214 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47239497710358014, 'Total loss': 0.47239497710358014} | train loss {'Reaction outcome loss': 0.47127038614469985, 'Total loss': 0.47127038614469985}
2022-11-28 06:25:32,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:32,214 INFO:     Epoch: 96
2022-11-28 06:25:32,880 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4619826264679432, 'Total loss': 0.4619826264679432} | train loss {'Reaction outcome loss': 0.48085128298398816, 'Total loss': 0.48085128298398816}
2022-11-28 06:25:32,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:32,881 INFO:     Epoch: 97
2022-11-28 06:25:33,547 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45453810319304466, 'Total loss': 0.45453810319304466} | train loss {'Reaction outcome loss': 0.4731555946900883, 'Total loss': 0.4731555946900883}
2022-11-28 06:25:33,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:33,547 INFO:     Epoch: 98
2022-11-28 06:25:34,215 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.520936132832007, 'Total loss': 0.520936132832007} | train loss {'Reaction outcome loss': 0.461911252816679, 'Total loss': 0.461911252816679}
2022-11-28 06:25:34,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:34,216 INFO:     Epoch: 99
2022-11-28 06:25:34,886 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.449879547750408, 'Total loss': 0.449879547750408} | train loss {'Reaction outcome loss': 0.4802236665899937, 'Total loss': 0.4802236665899937}
2022-11-28 06:25:34,887 INFO:     Best model found after epoch 77 of 100.
2022-11-28 06:25:34,887 INFO:   Done with stage: TRAINING
2022-11-28 06:25:34,887 INFO:   Starting stage: EVALUATION
2022-11-28 06:25:35,006 INFO:   Done with stage: EVALUATION
2022-11-28 06:25:35,007 INFO:   Leaving out SEQ value Fold_1
2022-11-28 06:25:35,019 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 06:25:35,020 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:25:35,675 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:25:35,676 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:25:35,747 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:25:35,747 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:25:35,747 INFO:     No hyperparam tuning for this model
2022-11-28 06:25:35,747 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:25:35,747 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:25:35,748 INFO:     None feature selector for col prot
2022-11-28 06:25:35,748 INFO:     None feature selector for col prot
2022-11-28 06:25:35,748 INFO:     None feature selector for col prot
2022-11-28 06:25:35,749 INFO:     None feature selector for col chem
2022-11-28 06:25:35,749 INFO:     None feature selector for col chem
2022-11-28 06:25:35,749 INFO:     None feature selector for col chem
2022-11-28 06:25:35,749 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:25:35,749 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:25:35,750 INFO:     Number of params in model 169651
2022-11-28 06:25:35,754 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:25:35,754 INFO:   Starting stage: TRAINING
2022-11-28 06:25:35,806 INFO:     Val loss before train {'Reaction outcome loss': 1.0414004678075963, 'Total loss': 1.0414004678075963}
2022-11-28 06:25:35,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:35,806 INFO:     Epoch: 0
2022-11-28 06:25:36,473 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5558364262635057, 'Total loss': 0.5558364262635057} | train loss {'Reaction outcome loss': 0.6926356111219537, 'Total loss': 0.6926356111219537}
2022-11-28 06:25:36,474 INFO:     Found new best model at epoch 0
2022-11-28 06:25:36,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:36,474 INFO:     Epoch: 1
2022-11-28 06:25:37,139 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5797077752649784, 'Total loss': 0.5797077752649784} | train loss {'Reaction outcome loss': 0.5971447204650655, 'Total loss': 0.5971447204650655}
2022-11-28 06:25:37,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:37,140 INFO:     Epoch: 2
2022-11-28 06:25:37,804 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5324220582842827, 'Total loss': 0.5324220582842827} | train loss {'Reaction outcome loss': 0.5616766447842363, 'Total loss': 0.5616766447842363}
2022-11-28 06:25:37,804 INFO:     Found new best model at epoch 2
2022-11-28 06:25:37,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:37,804 INFO:     Epoch: 3
2022-11-28 06:25:38,470 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5869146219708703, 'Total loss': 0.5869146219708703} | train loss {'Reaction outcome loss': 0.5649347640121514, 'Total loss': 0.5649347640121514}
2022-11-28 06:25:38,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:38,471 INFO:     Epoch: 4
2022-11-28 06:25:39,134 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49007992581887677, 'Total loss': 0.49007992581887677} | train loss {'Reaction outcome loss': 0.524971339776207, 'Total loss': 0.524971339776207}
2022-11-28 06:25:39,134 INFO:     Found new best model at epoch 4
2022-11-28 06:25:39,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:39,135 INFO:     Epoch: 5
2022-11-28 06:25:39,799 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5022900344973261, 'Total loss': 0.5022900344973261} | train loss {'Reaction outcome loss': 0.5129958957071729, 'Total loss': 0.5129958957071729}
2022-11-28 06:25:39,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:39,800 INFO:     Epoch: 6
2022-11-28 06:25:40,465 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5011513033373789, 'Total loss': 0.5011513033373789} | train loss {'Reaction outcome loss': 0.5006706280339706, 'Total loss': 0.5006706280339706}
2022-11-28 06:25:40,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:40,465 INFO:     Epoch: 7
2022-11-28 06:25:41,130 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4734221673147245, 'Total loss': 0.4734221673147245} | train loss {'Reaction outcome loss': 0.4889251564437079, 'Total loss': 0.4889251564437079}
2022-11-28 06:25:41,130 INFO:     Found new best model at epoch 7
2022-11-28 06:25:41,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:41,131 INFO:     Epoch: 8
2022-11-28 06:25:41,796 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4751549342816526, 'Total loss': 0.4751549342816526} | train loss {'Reaction outcome loss': 0.48500964510431777, 'Total loss': 0.48500964510431777}
2022-11-28 06:25:41,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:41,796 INFO:     Epoch: 9
2022-11-28 06:25:42,460 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4568631229075519, 'Total loss': 0.4568631229075519} | train loss {'Reaction outcome loss': 0.4843139925345718, 'Total loss': 0.4843139925345718}
2022-11-28 06:25:42,460 INFO:     Found new best model at epoch 9
2022-11-28 06:25:42,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:42,461 INFO:     Epoch: 10
2022-11-28 06:25:43,127 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49575950374657457, 'Total loss': 0.49575950374657457} | train loss {'Reaction outcome loss': 0.4873800048536738, 'Total loss': 0.4873800048536738}
2022-11-28 06:25:43,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:43,127 INFO:     Epoch: 11
2022-11-28 06:25:43,792 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5124930146742951, 'Total loss': 0.5124930146742951} | train loss {'Reaction outcome loss': 0.474626526530636, 'Total loss': 0.474626526530636}
2022-11-28 06:25:43,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:43,793 INFO:     Epoch: 12
2022-11-28 06:25:44,457 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47940179163759405, 'Total loss': 0.47940179163759405} | train loss {'Reaction outcome loss': 0.4782299580361679, 'Total loss': 0.4782299580361679}
2022-11-28 06:25:44,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:44,457 INFO:     Epoch: 13
2022-11-28 06:25:45,121 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4814491685141217, 'Total loss': 0.4814491685141217} | train loss {'Reaction outcome loss': 0.49384677759843015, 'Total loss': 0.49384677759843015}
2022-11-28 06:25:45,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:45,121 INFO:     Epoch: 14
2022-11-28 06:25:45,789 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4637239592319185, 'Total loss': 0.4637239592319185} | train loss {'Reaction outcome loss': 0.4676050225250151, 'Total loss': 0.4676050225250151}
2022-11-28 06:25:45,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:45,789 INFO:     Epoch: 15
2022-11-28 06:25:46,460 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.470605817200108, 'Total loss': 0.470605817200108} | train loss {'Reaction outcome loss': 0.4804335859140404, 'Total loss': 0.4804335859140404}
2022-11-28 06:25:46,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:46,460 INFO:     Epoch: 16
2022-11-28 06:25:47,126 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4693439829755913, 'Total loss': 0.4693439829755913} | train loss {'Reaction outcome loss': 0.47682219900582967, 'Total loss': 0.47682219900582967}
2022-11-28 06:25:47,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:47,126 INFO:     Epoch: 17
2022-11-28 06:25:47,792 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44214465536854486, 'Total loss': 0.44214465536854486} | train loss {'Reaction outcome loss': 0.46979533741250634, 'Total loss': 0.46979533741250634}
2022-11-28 06:25:47,792 INFO:     Found new best model at epoch 17
2022-11-28 06:25:47,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:47,793 INFO:     Epoch: 18
2022-11-28 06:25:48,464 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45962401919744234, 'Total loss': 0.45962401919744234} | train loss {'Reaction outcome loss': 0.47062273640261004, 'Total loss': 0.47062273640261004}
2022-11-28 06:25:48,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:48,464 INFO:     Epoch: 19
2022-11-28 06:25:49,133 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46161211214282294, 'Total loss': 0.46161211214282294} | train loss {'Reaction outcome loss': 0.47402508062148385, 'Total loss': 0.47402508062148385}
2022-11-28 06:25:49,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:49,133 INFO:     Epoch: 20
2022-11-28 06:25:49,800 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4530432576482946, 'Total loss': 0.4530432576482946} | train loss {'Reaction outcome loss': 0.4701585350369635, 'Total loss': 0.4701585350369635}
2022-11-28 06:25:49,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:49,800 INFO:     Epoch: 21
2022-11-28 06:25:50,470 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4995664432644844, 'Total loss': 0.4995664432644844} | train loss {'Reaction outcome loss': 0.47209892901573103, 'Total loss': 0.47209892901573103}
2022-11-28 06:25:50,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:50,470 INFO:     Epoch: 22
2022-11-28 06:25:51,135 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4828633520413529, 'Total loss': 0.4828633520413529} | train loss {'Reaction outcome loss': 0.46873943580065663, 'Total loss': 0.46873943580065663}
2022-11-28 06:25:51,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:51,135 INFO:     Epoch: 23
2022-11-28 06:25:51,802 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47252945601940155, 'Total loss': 0.47252945601940155} | train loss {'Reaction outcome loss': 0.4701199669405999, 'Total loss': 0.4701199669405999}
2022-11-28 06:25:51,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:51,803 INFO:     Epoch: 24
2022-11-28 06:25:52,469 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46658770028840413, 'Total loss': 0.46658770028840413} | train loss {'Reaction outcome loss': 0.47386659767765266, 'Total loss': 0.47386659767765266}
2022-11-28 06:25:52,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:52,471 INFO:     Epoch: 25
2022-11-28 06:25:53,136 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47201902520927513, 'Total loss': 0.47201902520927513} | train loss {'Reaction outcome loss': 0.46703253801052386, 'Total loss': 0.46703253801052386}
2022-11-28 06:25:53,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:53,136 INFO:     Epoch: 26
2022-11-28 06:25:53,800 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4592943516644565, 'Total loss': 0.4592943516644565} | train loss {'Reaction outcome loss': 0.46495970952426374, 'Total loss': 0.46495970952426374}
2022-11-28 06:25:53,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:53,800 INFO:     Epoch: 27
2022-11-28 06:25:54,467 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4784306619655002, 'Total loss': 0.4784306619655002} | train loss {'Reaction outcome loss': 0.4732511445336979, 'Total loss': 0.4732511445336979}
2022-11-28 06:25:54,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:54,467 INFO:     Epoch: 28
2022-11-28 06:25:55,133 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4659850536422296, 'Total loss': 0.4659850536422296} | train loss {'Reaction outcome loss': 0.4650216584908305, 'Total loss': 0.4650216584908305}
2022-11-28 06:25:55,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:55,133 INFO:     Epoch: 29
2022-11-28 06:25:55,798 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5007135014642369, 'Total loss': 0.5007135014642369} | train loss {'Reaction outcome loss': 0.47441769768351966, 'Total loss': 0.47441769768351966}
2022-11-28 06:25:55,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:55,798 INFO:     Epoch: 30
2022-11-28 06:25:56,462 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46150339530272916, 'Total loss': 0.46150339530272916} | train loss {'Reaction outcome loss': 0.48528007345522944, 'Total loss': 0.48528007345522944}
2022-11-28 06:25:56,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:56,462 INFO:     Epoch: 31
2022-11-28 06:25:57,128 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46267362717877736, 'Total loss': 0.46267362717877736} | train loss {'Reaction outcome loss': 0.4703626901755931, 'Total loss': 0.4703626901755931}
2022-11-28 06:25:57,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:57,129 INFO:     Epoch: 32
2022-11-28 06:25:57,797 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.445069166069681, 'Total loss': 0.445069166069681} | train loss {'Reaction outcome loss': 0.4709545388998773, 'Total loss': 0.4709545388998773}
2022-11-28 06:25:57,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:57,797 INFO:     Epoch: 33
2022-11-28 06:25:58,465 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4715835872021588, 'Total loss': 0.4715835872021588} | train loss {'Reaction outcome loss': 0.46558384941174435, 'Total loss': 0.46558384941174435}
2022-11-28 06:25:58,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:58,465 INFO:     Epoch: 34
2022-11-28 06:25:59,133 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4756222309714014, 'Total loss': 0.4756222309714014} | train loss {'Reaction outcome loss': 0.46523638552258373, 'Total loss': 0.46523638552258373}
2022-11-28 06:25:59,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:59,134 INFO:     Epoch: 35
2022-11-28 06:25:59,808 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4549251381646503, 'Total loss': 0.4549251381646503} | train loss {'Reaction outcome loss': 0.459035952288944, 'Total loss': 0.459035952288944}
2022-11-28 06:25:59,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:25:59,808 INFO:     Epoch: 36
2022-11-28 06:26:00,480 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4785575903952122, 'Total loss': 0.4785575903952122} | train loss {'Reaction outcome loss': 0.46167176313366487, 'Total loss': 0.46167176313366487}
2022-11-28 06:26:00,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:00,480 INFO:     Epoch: 37
2022-11-28 06:26:01,145 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.465021782300689, 'Total loss': 0.465021782300689} | train loss {'Reaction outcome loss': 0.46644292313318986, 'Total loss': 0.46644292313318986}
2022-11-28 06:26:01,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:01,145 INFO:     Epoch: 38
2022-11-28 06:26:01,811 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5611120462417603, 'Total loss': 0.5611120462417603} | train loss {'Reaction outcome loss': 0.4642294695985462, 'Total loss': 0.4642294695985462}
2022-11-28 06:26:01,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:01,812 INFO:     Epoch: 39
2022-11-28 06:26:02,481 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46118372746489267, 'Total loss': 0.46118372746489267} | train loss {'Reaction outcome loss': 0.4873692559206534, 'Total loss': 0.4873692559206534}
2022-11-28 06:26:02,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:02,482 INFO:     Epoch: 40
2022-11-28 06:26:03,151 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47360230711373413, 'Total loss': 0.47360230711373413} | train loss {'Reaction outcome loss': 0.46668906181651026, 'Total loss': 0.46668906181651026}
2022-11-28 06:26:03,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:03,152 INFO:     Epoch: 41
2022-11-28 06:26:03,821 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4959280009974133, 'Total loss': 0.4959280009974133} | train loss {'Reaction outcome loss': 0.4751454997762495, 'Total loss': 0.4751454997762495}
2022-11-28 06:26:03,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:03,821 INFO:     Epoch: 42
2022-11-28 06:26:04,487 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4952181228859858, 'Total loss': 0.4952181228859858} | train loss {'Reaction outcome loss': 0.487726767536117, 'Total loss': 0.487726767536117}
2022-11-28 06:26:04,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:04,488 INFO:     Epoch: 43
2022-11-28 06:26:05,156 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4707630103961988, 'Total loss': 0.4707630103961988} | train loss {'Reaction outcome loss': 0.482546423456296, 'Total loss': 0.482546423456296}
2022-11-28 06:26:05,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:05,156 INFO:     Epoch: 44
2022-11-28 06:26:05,822 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4794384610246528, 'Total loss': 0.4794384610246528} | train loss {'Reaction outcome loss': 0.47086812022636054, 'Total loss': 0.47086812022636054}
2022-11-28 06:26:05,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:05,822 INFO:     Epoch: 45
2022-11-28 06:26:06,488 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46463797038251703, 'Total loss': 0.46463797038251703} | train loss {'Reaction outcome loss': 0.466981394881918, 'Total loss': 0.466981394881918}
2022-11-28 06:26:06,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:06,489 INFO:     Epoch: 46
2022-11-28 06:26:07,157 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47509186968884687, 'Total loss': 0.47509186968884687} | train loss {'Reaction outcome loss': 0.47178332142622365, 'Total loss': 0.47178332142622365}
2022-11-28 06:26:07,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:07,157 INFO:     Epoch: 47
2022-11-28 06:26:07,826 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4444136040454561, 'Total loss': 0.4444136040454561} | train loss {'Reaction outcome loss': 0.4723072608231533, 'Total loss': 0.4723072608231533}
2022-11-28 06:26:07,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:07,826 INFO:     Epoch: 48
2022-11-28 06:26:08,494 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4658762826160951, 'Total loss': 0.4658762826160951} | train loss {'Reaction outcome loss': 0.47115298663077476, 'Total loss': 0.47115298663077476}
2022-11-28 06:26:08,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:08,494 INFO:     Epoch: 49
2022-11-28 06:26:09,163 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4537424106489528, 'Total loss': 0.4537424106489528} | train loss {'Reaction outcome loss': 0.471323730371259, 'Total loss': 0.471323730371259}
2022-11-28 06:26:09,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:09,163 INFO:     Epoch: 50
2022-11-28 06:26:09,835 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4915351711890914, 'Total loss': 0.4915351711890914} | train loss {'Reaction outcome loss': 0.46800662215180727, 'Total loss': 0.46800662215180727}
2022-11-28 06:26:09,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:09,836 INFO:     Epoch: 51
2022-11-28 06:26:10,504 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47944026508114557, 'Total loss': 0.47944026508114557} | train loss {'Reaction outcome loss': 0.46590622715078867, 'Total loss': 0.46590622715078867}
2022-11-28 06:26:10,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:10,504 INFO:     Epoch: 52
2022-11-28 06:26:11,171 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4531759690832008, 'Total loss': 0.4531759690832008} | train loss {'Reaction outcome loss': 0.4679735369286556, 'Total loss': 0.4679735369286556}
2022-11-28 06:26:11,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:11,172 INFO:     Epoch: 53
2022-11-28 06:26:11,838 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4764629900455475, 'Total loss': 0.4764629900455475} | train loss {'Reaction outcome loss': 0.4619269712040058, 'Total loss': 0.4619269712040058}
2022-11-28 06:26:11,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:11,838 INFO:     Epoch: 54
2022-11-28 06:26:12,504 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4859642931683497, 'Total loss': 0.4859642931683497} | train loss {'Reaction outcome loss': 0.4687656865489145, 'Total loss': 0.4687656865489145}
2022-11-28 06:26:12,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:12,505 INFO:     Epoch: 55
2022-11-28 06:26:13,169 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5407333272424611, 'Total loss': 0.5407333272424611} | train loss {'Reaction outcome loss': 0.4704510911032256, 'Total loss': 0.4704510911032256}
2022-11-28 06:26:13,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:13,170 INFO:     Epoch: 56
2022-11-28 06:26:13,835 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4668667333369905, 'Total loss': 0.4668667333369905} | train loss {'Reaction outcome loss': 0.48436529457810434, 'Total loss': 0.48436529457810434}
2022-11-28 06:26:13,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:13,835 INFO:     Epoch: 57
2022-11-28 06:26:14,501 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4508962878449397, 'Total loss': 0.4508962878449397} | train loss {'Reaction outcome loss': 0.4640017605880615, 'Total loss': 0.4640017605880615}
2022-11-28 06:26:14,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:14,502 INFO:     Epoch: 58
2022-11-28 06:26:15,170 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5140835795212876, 'Total loss': 0.5140835795212876} | train loss {'Reaction outcome loss': 0.466898006956406, 'Total loss': 0.466898006956406}
2022-11-28 06:26:15,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:15,170 INFO:     Epoch: 59
2022-11-28 06:26:15,835 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48759806698018854, 'Total loss': 0.48759806698018854} | train loss {'Reaction outcome loss': 0.46691721653648716, 'Total loss': 0.46691721653648716}
2022-11-28 06:26:15,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:15,835 INFO:     Epoch: 60
2022-11-28 06:26:16,501 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4577566239644181, 'Total loss': 0.4577566239644181} | train loss {'Reaction outcome loss': 0.4758822429276671, 'Total loss': 0.4758822429276671}
2022-11-28 06:26:16,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:16,501 INFO:     Epoch: 61
2022-11-28 06:26:17,166 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45031875710595737, 'Total loss': 0.45031875710595737} | train loss {'Reaction outcome loss': 0.4692909028296272, 'Total loss': 0.4692909028296272}
2022-11-28 06:26:17,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:17,166 INFO:     Epoch: 62
2022-11-28 06:26:17,834 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4754758375612172, 'Total loss': 0.4754758375612172} | train loss {'Reaction outcome loss': 0.4772945694353899, 'Total loss': 0.4772945694353899}
2022-11-28 06:26:17,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:17,834 INFO:     Epoch: 63
2022-11-28 06:26:18,504 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44481647421013226, 'Total loss': 0.44481647421013226} | train loss {'Reaction outcome loss': 0.46963728819540157, 'Total loss': 0.46963728819540157}
2022-11-28 06:26:18,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:18,504 INFO:     Epoch: 64
2022-11-28 06:26:19,168 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4452692788432945, 'Total loss': 0.4452692788432945} | train loss {'Reaction outcome loss': 0.46760885719104334, 'Total loss': 0.46760885719104334}
2022-11-28 06:26:19,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:19,168 INFO:     Epoch: 65
2022-11-28 06:26:19,834 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4525217186998237, 'Total loss': 0.4525217186998237} | train loss {'Reaction outcome loss': 0.46364879405865, 'Total loss': 0.46364879405865}
2022-11-28 06:26:19,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:19,834 INFO:     Epoch: 66
2022-11-28 06:26:20,497 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44471691718155687, 'Total loss': 0.44471691718155687} | train loss {'Reaction outcome loss': 0.4652053246251967, 'Total loss': 0.4652053246251967}
2022-11-28 06:26:20,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:20,498 INFO:     Epoch: 67
2022-11-28 06:26:21,167 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4697892049496824, 'Total loss': 0.4697892049496824} | train loss {'Reaction outcome loss': 0.46726528724074845, 'Total loss': 0.46726528724074845}
2022-11-28 06:26:21,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:21,167 INFO:     Epoch: 68
2022-11-28 06:26:21,834 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46860341693867336, 'Total loss': 0.46860341693867336} | train loss {'Reaction outcome loss': 0.4703145838278508, 'Total loss': 0.4703145838278508}
2022-11-28 06:26:21,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:21,834 INFO:     Epoch: 69
2022-11-28 06:26:22,499 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46454517204653134, 'Total loss': 0.46454517204653134} | train loss {'Reaction outcome loss': 0.4695470237176911, 'Total loss': 0.4695470237176911}
2022-11-28 06:26:22,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:22,499 INFO:     Epoch: 70
2022-11-28 06:26:23,167 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4581616801971739, 'Total loss': 0.4581616801971739} | train loss {'Reaction outcome loss': 0.4680033720094665, 'Total loss': 0.4680033720094665}
2022-11-28 06:26:23,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:23,168 INFO:     Epoch: 71
2022-11-28 06:26:23,838 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4517435340041464, 'Total loss': 0.4517435340041464} | train loss {'Reaction outcome loss': 0.46807081979295984, 'Total loss': 0.46807081979295984}
2022-11-28 06:26:23,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:23,838 INFO:     Epoch: 72
2022-11-28 06:26:24,506 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4773941751230847, 'Total loss': 0.4773941751230847} | train loss {'Reaction outcome loss': 0.4713894499216968, 'Total loss': 0.4713894499216968}
2022-11-28 06:26:24,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:24,506 INFO:     Epoch: 73
2022-11-28 06:26:25,176 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4576098353347995, 'Total loss': 0.4576098353347995} | train loss {'Reaction outcome loss': 0.47197554915057505, 'Total loss': 0.47197554915057505}
2022-11-28 06:26:25,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:25,177 INFO:     Epoch: 74
2022-11-28 06:26:25,844 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4809504537419839, 'Total loss': 0.4809504537419839} | train loss {'Reaction outcome loss': 0.47010826102273184, 'Total loss': 0.47010826102273184}
2022-11-28 06:26:25,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:25,844 INFO:     Epoch: 75
2022-11-28 06:26:26,512 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5002378530123017, 'Total loss': 0.5002378530123017} | train loss {'Reaction outcome loss': 0.47447806168423007, 'Total loss': 0.47447806168423007}
2022-11-28 06:26:26,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:26,512 INFO:     Epoch: 76
2022-11-28 06:26:27,179 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4900753023949536, 'Total loss': 0.4900753023949536} | train loss {'Reaction outcome loss': 0.4720462538332109, 'Total loss': 0.4720462538332109}
2022-11-28 06:26:27,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:27,179 INFO:     Epoch: 77
2022-11-28 06:26:27,847 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5175368650393053, 'Total loss': 0.5175368650393053} | train loss {'Reaction outcome loss': 0.4679175397524467, 'Total loss': 0.4679175397524467}
2022-11-28 06:26:27,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:27,847 INFO:     Epoch: 78
2022-11-28 06:26:28,514 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4933804442936724, 'Total loss': 0.4933804442936724} | train loss {'Reaction outcome loss': 0.4722733426964484, 'Total loss': 0.4722733426964484}
2022-11-28 06:26:28,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:28,514 INFO:     Epoch: 79
2022-11-28 06:26:29,181 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45776564797217195, 'Total loss': 0.45776564797217195} | train loss {'Reaction outcome loss': 0.4685134964915905, 'Total loss': 0.4685134964915905}
2022-11-28 06:26:29,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:29,182 INFO:     Epoch: 80
2022-11-28 06:26:29,849 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4420329508456317, 'Total loss': 0.4420329508456317} | train loss {'Reaction outcome loss': 0.4647632154979204, 'Total loss': 0.4647632154979204}
2022-11-28 06:26:29,849 INFO:     Found new best model at epoch 80
2022-11-28 06:26:29,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:29,850 INFO:     Epoch: 81
2022-11-28 06:26:30,523 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4772285297513008, 'Total loss': 0.4772285297513008} | train loss {'Reaction outcome loss': 0.46656606119382477, 'Total loss': 0.46656606119382477}
2022-11-28 06:26:30,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:30,523 INFO:     Epoch: 82
2022-11-28 06:26:31,189 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4497101110490886, 'Total loss': 0.4497101110490886} | train loss {'Reaction outcome loss': 0.46128142784964216, 'Total loss': 0.46128142784964216}
2022-11-28 06:26:31,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:31,189 INFO:     Epoch: 83
2022-11-28 06:26:31,854 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45356654714454303, 'Total loss': 0.45356654714454303} | train loss {'Reaction outcome loss': 0.4663178041645209, 'Total loss': 0.4663178041645209}
2022-11-28 06:26:31,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:31,854 INFO:     Epoch: 84
2022-11-28 06:26:32,522 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4537025060166012, 'Total loss': 0.4537025060166012} | train loss {'Reaction outcome loss': 0.4731076546164177, 'Total loss': 0.4731076546164177}
2022-11-28 06:26:32,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:32,522 INFO:     Epoch: 85
2022-11-28 06:26:33,187 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47563925656405365, 'Total loss': 0.47563925656405365} | train loss {'Reaction outcome loss': 0.46838978276802945, 'Total loss': 0.46838978276802945}
2022-11-28 06:26:33,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:33,188 INFO:     Epoch: 86
2022-11-28 06:26:33,854 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4486250498078086, 'Total loss': 0.4486250498078086} | train loss {'Reaction outcome loss': 0.46941571323736475, 'Total loss': 0.46941571323736475}
2022-11-28 06:26:33,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:33,855 INFO:     Epoch: 87
2022-11-28 06:26:34,519 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47494214671579277, 'Total loss': 0.47494214671579277} | train loss {'Reaction outcome loss': 0.4657125780094973, 'Total loss': 0.4657125780094973}
2022-11-28 06:26:34,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:34,519 INFO:     Epoch: 88
2022-11-28 06:26:35,188 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4581263183870099, 'Total loss': 0.4581263183870099} | train loss {'Reaction outcome loss': 0.46631714424141024, 'Total loss': 0.46631714424141024}
2022-11-28 06:26:35,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:35,188 INFO:     Epoch: 89
2022-11-28 06:26:35,855 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45909977839751676, 'Total loss': 0.45909977839751676} | train loss {'Reaction outcome loss': 0.4728112602644121, 'Total loss': 0.4728112602644121}
2022-11-28 06:26:35,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:35,855 INFO:     Epoch: 90
2022-11-28 06:26:36,523 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49063697694377467, 'Total loss': 0.49063697694377467} | train loss {'Reaction outcome loss': 0.47123332200986656, 'Total loss': 0.47123332200986656}
2022-11-28 06:26:36,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:36,523 INFO:     Epoch: 91
2022-11-28 06:26:37,189 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4540926759893244, 'Total loss': 0.4540926759893244} | train loss {'Reaction outcome loss': 0.472725129279078, 'Total loss': 0.472725129279078}
2022-11-28 06:26:37,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:37,190 INFO:     Epoch: 92
2022-11-28 06:26:37,856 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4632098251445727, 'Total loss': 0.4632098251445727} | train loss {'Reaction outcome loss': 0.46606412192105284, 'Total loss': 0.46606412192105284}
2022-11-28 06:26:37,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:37,857 INFO:     Epoch: 93
2022-11-28 06:26:38,525 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47214233299547975, 'Total loss': 0.47214233299547975} | train loss {'Reaction outcome loss': 0.4743947819297613, 'Total loss': 0.4743947819297613}
2022-11-28 06:26:38,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:38,525 INFO:     Epoch: 94
2022-11-28 06:26:39,192 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4998560859398408, 'Total loss': 0.4998560859398408} | train loss {'Reaction outcome loss': 0.47365122466434834, 'Total loss': 0.47365122466434834}
2022-11-28 06:26:39,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:39,193 INFO:     Epoch: 95
2022-11-28 06:26:39,859 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4415893063626506, 'Total loss': 0.4415893063626506} | train loss {'Reaction outcome loss': 0.46768352968490073, 'Total loss': 0.46768352968490073}
2022-11-28 06:26:39,859 INFO:     Found new best model at epoch 95
2022-11-28 06:26:39,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:39,860 INFO:     Epoch: 96
2022-11-28 06:26:40,527 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47098473188551987, 'Total loss': 0.47098473188551987} | train loss {'Reaction outcome loss': 0.4656218929057903, 'Total loss': 0.4656218929057903}
2022-11-28 06:26:40,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:40,527 INFO:     Epoch: 97
2022-11-28 06:26:41,198 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4400930264118043, 'Total loss': 0.4400930264118043} | train loss {'Reaction outcome loss': 0.46801459728947536, 'Total loss': 0.46801459728947536}
2022-11-28 06:26:41,199 INFO:     Found new best model at epoch 97
2022-11-28 06:26:41,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:41,200 INFO:     Epoch: 98
2022-11-28 06:26:41,870 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.480272170833566, 'Total loss': 0.480272170833566} | train loss {'Reaction outcome loss': 0.46320633415268503, 'Total loss': 0.46320633415268503}
2022-11-28 06:26:41,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:41,870 INFO:     Epoch: 99
2022-11-28 06:26:42,539 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4809452677992257, 'Total loss': 0.4809452677992257} | train loss {'Reaction outcome loss': 0.47012626780913425, 'Total loss': 0.47012626780913425}
2022-11-28 06:26:42,540 INFO:     Best model found after epoch 98 of 100.
2022-11-28 06:26:42,540 INFO:   Done with stage: TRAINING
2022-11-28 06:26:42,540 INFO:   Starting stage: EVALUATION
2022-11-28 06:26:42,660 INFO:   Done with stage: EVALUATION
2022-11-28 06:26:42,660 INFO:   Leaving out SEQ value Fold_2
2022-11-28 06:26:42,673 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 06:26:42,673 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:26:43,317 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:26:43,317 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:26:43,386 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:26:43,386 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:26:43,387 INFO:     No hyperparam tuning for this model
2022-11-28 06:26:43,387 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:26:43,387 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:26:43,387 INFO:     None feature selector for col prot
2022-11-28 06:26:43,387 INFO:     None feature selector for col prot
2022-11-28 06:26:43,388 INFO:     None feature selector for col prot
2022-11-28 06:26:43,388 INFO:     None feature selector for col chem
2022-11-28 06:26:43,388 INFO:     None feature selector for col chem
2022-11-28 06:26:43,388 INFO:     None feature selector for col chem
2022-11-28 06:26:43,388 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:26:43,388 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:26:43,390 INFO:     Number of params in model 169651
2022-11-28 06:26:43,393 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:26:43,393 INFO:   Starting stage: TRAINING
2022-11-28 06:26:43,444 INFO:     Val loss before train {'Reaction outcome loss': 1.0114945866340814, 'Total loss': 1.0114945866340814}
2022-11-28 06:26:43,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:43,444 INFO:     Epoch: 0
2022-11-28 06:26:44,098 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5783537487651027, 'Total loss': 0.5783537487651027} | train loss {'Reaction outcome loss': 0.6958693216857597, 'Total loss': 0.6958693216857597}
2022-11-28 06:26:44,098 INFO:     Found new best model at epoch 0
2022-11-28 06:26:44,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:44,099 INFO:     Epoch: 1
2022-11-28 06:26:44,753 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5655120347821435, 'Total loss': 0.5655120347821435} | train loss {'Reaction outcome loss': 0.6079243928071403, 'Total loss': 0.6079243928071403}
2022-11-28 06:26:44,753 INFO:     Found new best model at epoch 1
2022-11-28 06:26:44,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:44,754 INFO:     Epoch: 2
2022-11-28 06:26:45,407 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.519006094267202, 'Total loss': 0.519006094267202} | train loss {'Reaction outcome loss': 0.5613829053846406, 'Total loss': 0.5613829053846406}
2022-11-28 06:26:45,407 INFO:     Found new best model at epoch 2
2022-11-28 06:26:45,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:45,408 INFO:     Epoch: 3
2022-11-28 06:26:46,062 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5521842906641405, 'Total loss': 0.5521842906641405} | train loss {'Reaction outcome loss': 0.5516156673799326, 'Total loss': 0.5516156673799326}
2022-11-28 06:26:46,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:46,063 INFO:     Epoch: 4
2022-11-28 06:26:46,719 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.492216101912565, 'Total loss': 0.492216101912565} | train loss {'Reaction outcome loss': 0.5306473046295928, 'Total loss': 0.5306473046295928}
2022-11-28 06:26:46,719 INFO:     Found new best model at epoch 4
2022-11-28 06:26:46,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:46,720 INFO:     Epoch: 5
2022-11-28 06:26:47,376 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47338076455648553, 'Total loss': 0.47338076455648553} | train loss {'Reaction outcome loss': 0.509056462181939, 'Total loss': 0.509056462181939}
2022-11-28 06:26:47,376 INFO:     Found new best model at epoch 5
2022-11-28 06:26:47,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:47,377 INFO:     Epoch: 6
2022-11-28 06:26:48,031 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4957014925258104, 'Total loss': 0.4957014925258104} | train loss {'Reaction outcome loss': 0.5114471345158761, 'Total loss': 0.5114471345158761}
2022-11-28 06:26:48,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:48,031 INFO:     Epoch: 7
2022-11-28 06:26:48,688 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5166419148445129, 'Total loss': 0.5166419148445129} | train loss {'Reaction outcome loss': 0.5057118901132066, 'Total loss': 0.5057118901132066}
2022-11-28 06:26:48,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:48,688 INFO:     Epoch: 8
2022-11-28 06:26:49,344 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4681367059779722, 'Total loss': 0.4681367059779722} | train loss {'Reaction outcome loss': 0.5043390436795513, 'Total loss': 0.5043390436795513}
2022-11-28 06:26:49,345 INFO:     Found new best model at epoch 8
2022-11-28 06:26:49,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:49,345 INFO:     Epoch: 9
2022-11-28 06:26:50,001 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5233624847822411, 'Total loss': 0.5233624847822411} | train loss {'Reaction outcome loss': 0.49736278577719206, 'Total loss': 0.49736278577719206}
2022-11-28 06:26:50,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:50,001 INFO:     Epoch: 10
2022-11-28 06:26:50,658 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4749395875043647, 'Total loss': 0.4749395875043647} | train loss {'Reaction outcome loss': 0.48908361853886045, 'Total loss': 0.48908361853886045}
2022-11-28 06:26:50,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:50,659 INFO:     Epoch: 11
2022-11-28 06:26:51,318 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5165113931478456, 'Total loss': 0.5165113931478456} | train loss {'Reaction outcome loss': 0.4925715204619576, 'Total loss': 0.4925715204619576}
2022-11-28 06:26:51,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:51,318 INFO:     Epoch: 12
2022-11-28 06:26:51,974 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4775719961454702, 'Total loss': 0.4775719961454702} | train loss {'Reaction outcome loss': 0.4949012967784709, 'Total loss': 0.4949012967784709}
2022-11-28 06:26:51,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:51,974 INFO:     Epoch: 13
2022-11-28 06:26:52,627 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4517248862011488, 'Total loss': 0.4517248862011488} | train loss {'Reaction outcome loss': 0.47730898599565763, 'Total loss': 0.47730898599565763}
2022-11-28 06:26:52,627 INFO:     Found new best model at epoch 13
2022-11-28 06:26:52,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:52,628 INFO:     Epoch: 14
2022-11-28 06:26:53,279 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4789393973904987, 'Total loss': 0.4789393973904987} | train loss {'Reaction outcome loss': 0.4869377281317495, 'Total loss': 0.4869377281317495}
2022-11-28 06:26:53,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:53,280 INFO:     Epoch: 15
2022-11-28 06:26:53,933 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46953685269799345, 'Total loss': 0.46953685269799345} | train loss {'Reaction outcome loss': 0.47902789693555714, 'Total loss': 0.47902789693555714}
2022-11-28 06:26:53,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:53,934 INFO:     Epoch: 16
2022-11-28 06:26:54,584 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4788532683322596, 'Total loss': 0.4788532683322596} | train loss {'Reaction outcome loss': 0.483517312034658, 'Total loss': 0.483517312034658}
2022-11-28 06:26:54,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:54,584 INFO:     Epoch: 17
2022-11-28 06:26:55,238 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46878135620161543, 'Total loss': 0.46878135620161543} | train loss {'Reaction outcome loss': 0.4778949046515143, 'Total loss': 0.4778949046515143}
2022-11-28 06:26:55,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:55,239 INFO:     Epoch: 18
2022-11-28 06:26:55,892 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4491239398024803, 'Total loss': 0.4491239398024803} | train loss {'Reaction outcome loss': 0.4759119606189767, 'Total loss': 0.4759119606189767}
2022-11-28 06:26:55,892 INFO:     Found new best model at epoch 18
2022-11-28 06:26:55,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:55,892 INFO:     Epoch: 19
2022-11-28 06:26:56,544 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4755362986132156, 'Total loss': 0.4755362986132156} | train loss {'Reaction outcome loss': 0.4766660681599943, 'Total loss': 0.4766660681599943}
2022-11-28 06:26:56,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:56,544 INFO:     Epoch: 20
2022-11-28 06:26:57,191 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45204948824505475, 'Total loss': 0.45204948824505475} | train loss {'Reaction outcome loss': 0.48088752389444733, 'Total loss': 0.48088752389444733}
2022-11-28 06:26:57,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:57,192 INFO:     Epoch: 21
2022-11-28 06:26:57,845 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4984085494002631, 'Total loss': 0.4984085494002631} | train loss {'Reaction outcome loss': 0.4775115513997804, 'Total loss': 0.4775115513997804}
2022-11-28 06:26:57,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:57,845 INFO:     Epoch: 22
2022-11-28 06:26:58,496 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44583000034786935, 'Total loss': 0.44583000034786935} | train loss {'Reaction outcome loss': 0.4758887991861061, 'Total loss': 0.4758887991861061}
2022-11-28 06:26:58,496 INFO:     Found new best model at epoch 22
2022-11-28 06:26:58,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:58,497 INFO:     Epoch: 23
2022-11-28 06:26:59,145 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44293468012366183, 'Total loss': 0.44293468012366183} | train loss {'Reaction outcome loss': 0.4719835253041468, 'Total loss': 0.4719835253041468}
2022-11-28 06:26:59,145 INFO:     Found new best model at epoch 23
2022-11-28 06:26:59,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:59,146 INFO:     Epoch: 24
2022-11-28 06:26:59,798 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45575488861217056, 'Total loss': 0.45575488861217056} | train loss {'Reaction outcome loss': 0.4710234999656677, 'Total loss': 0.4710234999656677}
2022-11-28 06:26:59,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:26:59,799 INFO:     Epoch: 25
2022-11-28 06:27:00,453 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48840598034304245, 'Total loss': 0.48840598034304245} | train loss {'Reaction outcome loss': 0.46912864111210584, 'Total loss': 0.46912864111210584}
2022-11-28 06:27:00,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:00,454 INFO:     Epoch: 26
2022-11-28 06:27:01,105 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4698091135468594, 'Total loss': 0.4698091135468594} | train loss {'Reaction outcome loss': 0.47278529816448933, 'Total loss': 0.47278529816448933}
2022-11-28 06:27:01,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:01,105 INFO:     Epoch: 27
2022-11-28 06:27:01,753 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49290146418782166, 'Total loss': 0.49290146418782166} | train loss {'Reaction outcome loss': 0.47708295218247937, 'Total loss': 0.47708295218247937}
2022-11-28 06:27:01,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:01,754 INFO:     Epoch: 28
2022-11-28 06:27:02,404 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4471010969475258, 'Total loss': 0.4471010969475258} | train loss {'Reaction outcome loss': 0.4782107323408127, 'Total loss': 0.4782107323408127}
2022-11-28 06:27:02,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:02,404 INFO:     Epoch: 29
2022-11-28 06:27:03,053 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44767568832220034, 'Total loss': 0.44767568832220034} | train loss {'Reaction outcome loss': 0.4641405235470077, 'Total loss': 0.4641405235470077}
2022-11-28 06:27:03,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:03,054 INFO:     Epoch: 30
2022-11-28 06:27:03,705 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4326384043277696, 'Total loss': 0.4326384043277696} | train loss {'Reaction outcome loss': 0.4719994158288579, 'Total loss': 0.4719994158288579}
2022-11-28 06:27:03,705 INFO:     Found new best model at epoch 30
2022-11-28 06:27:03,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:03,706 INFO:     Epoch: 31
2022-11-28 06:27:04,356 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4677211725434592, 'Total loss': 0.4677211725434592} | train loss {'Reaction outcome loss': 0.475337732905223, 'Total loss': 0.475337732905223}
2022-11-28 06:27:04,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:04,356 INFO:     Epoch: 32
2022-11-28 06:27:05,007 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46498542746832205, 'Total loss': 0.46498542746832205} | train loss {'Reaction outcome loss': 0.47110026559711976, 'Total loss': 0.47110026559711976}
2022-11-28 06:27:05,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:05,007 INFO:     Epoch: 33
2022-11-28 06:27:05,659 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.482067009044248, 'Total loss': 0.482067009044248} | train loss {'Reaction outcome loss': 0.4727433949341009, 'Total loss': 0.4727433949341009}
2022-11-28 06:27:05,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:05,659 INFO:     Epoch: 34
2022-11-28 06:27:06,308 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4972855039807253, 'Total loss': 0.4972855039807253} | train loss {'Reaction outcome loss': 0.4686129836388576, 'Total loss': 0.4686129836388576}
2022-11-28 06:27:06,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:06,308 INFO:     Epoch: 35
2022-11-28 06:27:06,957 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46907123368839887, 'Total loss': 0.46907123368839887} | train loss {'Reaction outcome loss': 0.47311646629262855, 'Total loss': 0.47311646629262855}
2022-11-28 06:27:06,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:06,958 INFO:     Epoch: 36
2022-11-28 06:27:07,609 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47064110463441805, 'Total loss': 0.47064110463441805} | train loss {'Reaction outcome loss': 0.4786880693931148, 'Total loss': 0.4786880693931148}
2022-11-28 06:27:07,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:07,610 INFO:     Epoch: 37
2022-11-28 06:27:08,265 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4746474038029826, 'Total loss': 0.4746474038029826} | train loss {'Reaction outcome loss': 0.47255982329815993, 'Total loss': 0.47255982329815993}
2022-11-28 06:27:08,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:08,266 INFO:     Epoch: 38
2022-11-28 06:27:08,917 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4645871845788734, 'Total loss': 0.4645871845788734} | train loss {'Reaction outcome loss': 0.4761343774972139, 'Total loss': 0.4761343774972139}
2022-11-28 06:27:08,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:08,917 INFO:     Epoch: 39
2022-11-28 06:27:09,569 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44495580847873245, 'Total loss': 0.44495580847873245} | train loss {'Reaction outcome loss': 0.4745903861988719, 'Total loss': 0.4745903861988719}
2022-11-28 06:27:09,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:09,569 INFO:     Epoch: 40
2022-11-28 06:27:10,222 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4491805607496306, 'Total loss': 0.4491805607496306} | train loss {'Reaction outcome loss': 0.47064417717142853, 'Total loss': 0.47064417717142853}
2022-11-28 06:27:10,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:10,222 INFO:     Epoch: 41
2022-11-28 06:27:10,873 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4371053122503813, 'Total loss': 0.4371053122503813} | train loss {'Reaction outcome loss': 0.4728042408823967, 'Total loss': 0.4728042408823967}
2022-11-28 06:27:10,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:10,873 INFO:     Epoch: 42
2022-11-28 06:27:11,528 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4787333375492761, 'Total loss': 0.4787333375492761} | train loss {'Reaction outcome loss': 0.4762470145774967, 'Total loss': 0.4762470145774967}
2022-11-28 06:27:11,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:11,528 INFO:     Epoch: 43
2022-11-28 06:27:12,182 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4469429869637933, 'Total loss': 0.4469429869637933} | train loss {'Reaction outcome loss': 0.47098165033040224, 'Total loss': 0.47098165033040224}
2022-11-28 06:27:12,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:12,182 INFO:     Epoch: 44
2022-11-28 06:27:12,833 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44692814454089763, 'Total loss': 0.44692814454089763} | train loss {'Reaction outcome loss': 0.4733205206477593, 'Total loss': 0.4733205206477593}
2022-11-28 06:27:12,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:12,834 INFO:     Epoch: 45
2022-11-28 06:27:13,482 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43531791761864064, 'Total loss': 0.43531791761864064} | train loss {'Reaction outcome loss': 0.4767546057701111, 'Total loss': 0.4767546057701111}
2022-11-28 06:27:13,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:13,483 INFO:     Epoch: 46
2022-11-28 06:27:14,130 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44702721508436427, 'Total loss': 0.44702721508436427} | train loss {'Reaction outcome loss': 0.4716587218728085, 'Total loss': 0.4716587218728085}
2022-11-28 06:27:14,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:14,130 INFO:     Epoch: 47
2022-11-28 06:27:14,780 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4767090744057367, 'Total loss': 0.4767090744057367} | train loss {'Reaction outcome loss': 0.4775827451620573, 'Total loss': 0.4775827451620573}
2022-11-28 06:27:14,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:14,780 INFO:     Epoch: 48
2022-11-28 06:27:15,430 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4532802510400151, 'Total loss': 0.4532802510400151} | train loss {'Reaction outcome loss': 0.4700258954623599, 'Total loss': 0.4700258954623599}
2022-11-28 06:27:15,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:15,430 INFO:     Epoch: 49
2022-11-28 06:27:16,081 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44117774901001955, 'Total loss': 0.44117774901001955} | train loss {'Reaction outcome loss': 0.4634290035860038, 'Total loss': 0.4634290035860038}
2022-11-28 06:27:16,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:16,082 INFO:     Epoch: 50
2022-11-28 06:27:16,733 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4534397651982862, 'Total loss': 0.4534397651982862} | train loss {'Reaction outcome loss': 0.47262168065510657, 'Total loss': 0.47262168065510657}
2022-11-28 06:27:16,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:16,733 INFO:     Epoch: 51
2022-11-28 06:27:17,381 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47858313211174897, 'Total loss': 0.47858313211174897} | train loss {'Reaction outcome loss': 0.4687440773096595, 'Total loss': 0.4687440773096595}
2022-11-28 06:27:17,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:17,382 INFO:     Epoch: 52
2022-11-28 06:27:18,030 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4583598895128383, 'Total loss': 0.4583598895128383} | train loss {'Reaction outcome loss': 0.4718195099398923, 'Total loss': 0.4718195099398923}
2022-11-28 06:27:18,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:18,031 INFO:     Epoch: 53
2022-11-28 06:27:18,680 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4561604770810105, 'Total loss': 0.4561604770810105} | train loss {'Reaction outcome loss': 0.47951363474743847, 'Total loss': 0.47951363474743847}
2022-11-28 06:27:18,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:18,680 INFO:     Epoch: 54
2022-11-28 06:27:19,328 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4482831466336583, 'Total loss': 0.4482831466336583} | train loss {'Reaction outcome loss': 0.4764591690321518, 'Total loss': 0.4764591690321518}
2022-11-28 06:27:19,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:19,329 INFO:     Epoch: 55
2022-11-28 06:27:19,978 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48033244873202124, 'Total loss': 0.48033244873202124} | train loss {'Reaction outcome loss': 0.4663744500144519, 'Total loss': 0.4663744500144519}
2022-11-28 06:27:19,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:19,979 INFO:     Epoch: 56
2022-11-28 06:27:20,629 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4561518444571384, 'Total loss': 0.4561518444571384} | train loss {'Reaction outcome loss': 0.47526317344280916, 'Total loss': 0.47526317344280916}
2022-11-28 06:27:20,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:20,629 INFO:     Epoch: 57
2022-11-28 06:27:21,278 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46215538576591847, 'Total loss': 0.46215538576591847} | train loss {'Reaction outcome loss': 0.46944397988388076, 'Total loss': 0.46944397988388076}
2022-11-28 06:27:21,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:21,278 INFO:     Epoch: 58
2022-11-28 06:27:21,925 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44954061993332795, 'Total loss': 0.44954061993332795} | train loss {'Reaction outcome loss': 0.46962711993804196, 'Total loss': 0.46962711993804196}
2022-11-28 06:27:21,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:21,925 INFO:     Epoch: 59
2022-11-28 06:27:22,577 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4402062210232712, 'Total loss': 0.4402062210232712} | train loss {'Reaction outcome loss': 0.4736919166374599, 'Total loss': 0.4736919166374599}
2022-11-28 06:27:22,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:22,578 INFO:     Epoch: 60
2022-11-28 06:27:23,229 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45600238962228906, 'Total loss': 0.45600238962228906} | train loss {'Reaction outcome loss': 0.46989034741749, 'Total loss': 0.46989034741749}
2022-11-28 06:27:23,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:23,229 INFO:     Epoch: 61
2022-11-28 06:27:23,876 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4611238948134489, 'Total loss': 0.4611238948134489} | train loss {'Reaction outcome loss': 0.47603859657368053, 'Total loss': 0.47603859657368053}
2022-11-28 06:27:23,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:23,877 INFO:     Epoch: 62
2022-11-28 06:27:24,527 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46012420779050783, 'Total loss': 0.46012420779050783} | train loss {'Reaction outcome loss': 0.47110864654980567, 'Total loss': 0.47110864654980567}
2022-11-28 06:27:24,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:24,529 INFO:     Epoch: 63
2022-11-28 06:27:25,177 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4520629335974538, 'Total loss': 0.4520629335974538} | train loss {'Reaction outcome loss': 0.4712054770547176, 'Total loss': 0.4712054770547176}
2022-11-28 06:27:25,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:25,178 INFO:     Epoch: 64
2022-11-28 06:27:25,828 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48085459581641266, 'Total loss': 0.48085459581641266} | train loss {'Reaction outcome loss': 0.4711814585904526, 'Total loss': 0.4711814585904526}
2022-11-28 06:27:25,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:25,828 INFO:     Epoch: 65
2022-11-28 06:27:26,479 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4803148698668147, 'Total loss': 0.4803148698668147} | train loss {'Reaction outcome loss': 0.48011356457270715, 'Total loss': 0.48011356457270715}
2022-11-28 06:27:26,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:26,479 INFO:     Epoch: 66
2022-11-28 06:27:27,127 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4370388121798981, 'Total loss': 0.4370388121798981} | train loss {'Reaction outcome loss': 0.4666347151062616, 'Total loss': 0.4666347151062616}
2022-11-28 06:27:27,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:27,127 INFO:     Epoch: 67
2022-11-28 06:27:27,774 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4663036448317905, 'Total loss': 0.4663036448317905} | train loss {'Reaction outcome loss': 0.46909255666252025, 'Total loss': 0.46909255666252025}
2022-11-28 06:27:27,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:27,775 INFO:     Epoch: 68
2022-11-28 06:27:28,423 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4601546983386195, 'Total loss': 0.4601546983386195} | train loss {'Reaction outcome loss': 0.4765275589845799, 'Total loss': 0.4765275589845799}
2022-11-28 06:27:28,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:28,423 INFO:     Epoch: 69
2022-11-28 06:27:29,071 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45692978314189026, 'Total loss': 0.45692978314189026} | train loss {'Reaction outcome loss': 0.4732347799181448, 'Total loss': 0.4732347799181448}
2022-11-28 06:27:29,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:29,071 INFO:     Epoch: 70
2022-11-28 06:27:29,719 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4701404013606005, 'Total loss': 0.4701404013606005} | train loss {'Reaction outcome loss': 0.47356282401477356, 'Total loss': 0.47356282401477356}
2022-11-28 06:27:29,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:29,719 INFO:     Epoch: 71
2022-11-28 06:27:30,368 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.444969340119251, 'Total loss': 0.444969340119251} | train loss {'Reaction outcome loss': 0.47955198782216374, 'Total loss': 0.47955198782216374}
2022-11-28 06:27:30,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:30,368 INFO:     Epoch: 72
2022-11-28 06:27:31,020 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44481380214524824, 'Total loss': 0.44481380214524824} | train loss {'Reaction outcome loss': 0.4700139034922721, 'Total loss': 0.4700139034922721}
2022-11-28 06:27:31,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:31,021 INFO:     Epoch: 73
2022-11-28 06:27:31,670 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4933860936137133, 'Total loss': 0.4933860936137133} | train loss {'Reaction outcome loss': 0.4752110754266197, 'Total loss': 0.4752110754266197}
2022-11-28 06:27:31,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:31,671 INFO:     Epoch: 74
2022-11-28 06:27:32,320 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4500353859607564, 'Total loss': 0.4500353859607564} | train loss {'Reaction outcome loss': 0.4737363063994749, 'Total loss': 0.4737363063994749}
2022-11-28 06:27:32,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:32,321 INFO:     Epoch: 75
2022-11-28 06:27:32,972 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4730471753796866, 'Total loss': 0.4730471753796866} | train loss {'Reaction outcome loss': 0.4660848238095335, 'Total loss': 0.4660848238095335}
2022-11-28 06:27:32,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:32,973 INFO:     Epoch: 76
2022-11-28 06:27:33,624 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45526006540586783, 'Total loss': 0.45526006540586783} | train loss {'Reaction outcome loss': 0.47458734801767294, 'Total loss': 0.47458734801767294}
2022-11-28 06:27:33,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:33,624 INFO:     Epoch: 77
2022-11-28 06:27:34,275 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45883718098318854, 'Total loss': 0.45883718098318854} | train loss {'Reaction outcome loss': 0.47345091218565716, 'Total loss': 0.47345091218565716}
2022-11-28 06:27:34,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:34,275 INFO:     Epoch: 78
2022-11-28 06:27:34,922 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46722758128199465, 'Total loss': 0.46722758128199465} | train loss {'Reaction outcome loss': 0.4764154801766078, 'Total loss': 0.4764154801766078}
2022-11-28 06:27:34,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:34,922 INFO:     Epoch: 79
2022-11-28 06:27:35,568 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45994183143904044, 'Total loss': 0.45994183143904044} | train loss {'Reaction outcome loss': 0.47367424787685214, 'Total loss': 0.47367424787685214}
2022-11-28 06:27:35,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:35,569 INFO:     Epoch: 80
2022-11-28 06:27:36,221 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47085663606954176, 'Total loss': 0.47085663606954176} | train loss {'Reaction outcome loss': 0.46640462235168173, 'Total loss': 0.46640462235168173}
2022-11-28 06:27:36,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:36,221 INFO:     Epoch: 81
2022-11-28 06:27:36,875 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46642185643661854, 'Total loss': 0.46642185643661854} | train loss {'Reaction outcome loss': 0.47312616602874097, 'Total loss': 0.47312616602874097}
2022-11-28 06:27:36,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:36,876 INFO:     Epoch: 82
2022-11-28 06:27:37,526 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4838500542696132, 'Total loss': 0.4838500542696132} | train loss {'Reaction outcome loss': 0.47492673956317666, 'Total loss': 0.47492673956317666}
2022-11-28 06:27:37,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:37,526 INFO:     Epoch: 83
2022-11-28 06:27:38,174 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4618699723897978, 'Total loss': 0.4618699723897978} | train loss {'Reaction outcome loss': 0.470970743968163, 'Total loss': 0.470970743968163}
2022-11-28 06:27:38,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:38,174 INFO:     Epoch: 84
2022-11-28 06:27:38,825 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4906741158906804, 'Total loss': 0.4906741158906804} | train loss {'Reaction outcome loss': 0.4714594224598182, 'Total loss': 0.4714594224598182}
2022-11-28 06:27:38,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:38,825 INFO:     Epoch: 85
2022-11-28 06:27:39,476 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47666543791460436, 'Total loss': 0.47666543791460436} | train loss {'Reaction outcome loss': 0.4754354751404421, 'Total loss': 0.4754354751404421}
2022-11-28 06:27:39,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:39,476 INFO:     Epoch: 86
2022-11-28 06:27:40,127 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4462824779194455, 'Total loss': 0.4462824779194455} | train loss {'Reaction outcome loss': 0.4733211452087748, 'Total loss': 0.4733211452087748}
2022-11-28 06:27:40,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:40,128 INFO:     Epoch: 87
2022-11-28 06:27:40,776 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45908390574677044, 'Total loss': 0.45908390574677044} | train loss {'Reaction outcome loss': 0.46989112853268045, 'Total loss': 0.46989112853268045}
2022-11-28 06:27:40,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:40,776 INFO:     Epoch: 88
2022-11-28 06:27:41,425 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46689476038134375, 'Total loss': 0.46689476038134375} | train loss {'Reaction outcome loss': 0.4720174602152389, 'Total loss': 0.4720174602152389}
2022-11-28 06:27:41,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:41,425 INFO:     Epoch: 89
2022-11-28 06:27:42,073 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4556878306144892, 'Total loss': 0.4556878306144892} | train loss {'Reaction outcome loss': 0.46431066727442016, 'Total loss': 0.46431066727442016}
2022-11-28 06:27:42,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:42,074 INFO:     Epoch: 90
2022-11-28 06:27:42,723 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4716420222160428, 'Total loss': 0.4716420222160428} | train loss {'Reaction outcome loss': 0.47058753049913254, 'Total loss': 0.47058753049913254}
2022-11-28 06:27:42,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:42,724 INFO:     Epoch: 91
2022-11-28 06:27:43,371 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49167773196863573, 'Total loss': 0.49167773196863573} | train loss {'Reaction outcome loss': 0.4774216677794241, 'Total loss': 0.4774216677794241}
2022-11-28 06:27:43,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:43,372 INFO:     Epoch: 92
2022-11-28 06:27:44,019 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45545257697271746, 'Total loss': 0.45545257697271746} | train loss {'Reaction outcome loss': 0.47289763127334816, 'Total loss': 0.47289763127334816}
2022-11-28 06:27:44,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:44,019 INFO:     Epoch: 93
2022-11-28 06:27:44,668 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4908423361390136, 'Total loss': 0.4908423361390136} | train loss {'Reaction outcome loss': 0.4677103916681353, 'Total loss': 0.4677103916681353}
2022-11-28 06:27:44,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:44,669 INFO:     Epoch: 94
2022-11-28 06:27:45,318 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45165287547333294, 'Total loss': 0.45165287547333294} | train loss {'Reaction outcome loss': 0.4693389775331128, 'Total loss': 0.4693389775331128}
2022-11-28 06:27:45,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:45,318 INFO:     Epoch: 95
2022-11-28 06:27:45,970 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45839831648870955, 'Total loss': 0.45839831648870955} | train loss {'Reaction outcome loss': 0.4638492081145691, 'Total loss': 0.4638492081145691}
2022-11-28 06:27:45,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:45,970 INFO:     Epoch: 96
2022-11-28 06:27:46,624 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44638466661752657, 'Total loss': 0.44638466661752657} | train loss {'Reaction outcome loss': 0.47627776251040366, 'Total loss': 0.47627776251040366}
2022-11-28 06:27:46,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:46,624 INFO:     Epoch: 97
2022-11-28 06:27:47,275 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49407144791858143, 'Total loss': 0.49407144791858143} | train loss {'Reaction outcome loss': 0.466340009199739, 'Total loss': 0.466340009199739}
2022-11-28 06:27:47,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:47,276 INFO:     Epoch: 98
2022-11-28 06:27:47,923 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.445798713800519, 'Total loss': 0.445798713800519} | train loss {'Reaction outcome loss': 0.4657917448890553, 'Total loss': 0.4657917448890553}
2022-11-28 06:27:47,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:47,923 INFO:     Epoch: 99
2022-11-28 06:27:48,571 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.514714494694111, 'Total loss': 0.514714494694111} | train loss {'Reaction outcome loss': 0.46708669136335823, 'Total loss': 0.46708669136335823}
2022-11-28 06:27:48,571 INFO:     Best model found after epoch 31 of 100.
2022-11-28 06:27:48,571 INFO:   Done with stage: TRAINING
2022-11-28 06:27:48,571 INFO:   Starting stage: EVALUATION
2022-11-28 06:27:48,706 INFO:   Done with stage: EVALUATION
2022-11-28 06:27:48,706 INFO:   Leaving out SEQ value Fold_3
2022-11-28 06:27:48,719 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 06:27:48,719 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:27:49,351 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:27:49,351 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:27:49,420 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:27:49,420 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:27:49,420 INFO:     No hyperparam tuning for this model
2022-11-28 06:27:49,420 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:27:49,420 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:27:49,421 INFO:     None feature selector for col prot
2022-11-28 06:27:49,421 INFO:     None feature selector for col prot
2022-11-28 06:27:49,421 INFO:     None feature selector for col prot
2022-11-28 06:27:49,422 INFO:     None feature selector for col chem
2022-11-28 06:27:49,422 INFO:     None feature selector for col chem
2022-11-28 06:27:49,422 INFO:     None feature selector for col chem
2022-11-28 06:27:49,422 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:27:49,422 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:27:49,424 INFO:     Number of params in model 169651
2022-11-28 06:27:49,427 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:27:49,427 INFO:   Starting stage: TRAINING
2022-11-28 06:27:49,477 INFO:     Val loss before train {'Reaction outcome loss': 1.07070217021676, 'Total loss': 1.07070217021676}
2022-11-28 06:27:49,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:49,477 INFO:     Epoch: 0
2022-11-28 06:27:50,131 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6634116054967393, 'Total loss': 0.6634116054967393} | train loss {'Reaction outcome loss': 0.6671469602810502, 'Total loss': 0.6671469602810502}
2022-11-28 06:27:50,131 INFO:     Found new best model at epoch 0
2022-11-28 06:27:50,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:50,132 INFO:     Epoch: 1
2022-11-28 06:27:50,785 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5228682853454767, 'Total loss': 0.5228682853454767} | train loss {'Reaction outcome loss': 0.5721777846170552, 'Total loss': 0.5721777846170552}
2022-11-28 06:27:50,785 INFO:     Found new best model at epoch 1
2022-11-28 06:27:50,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:50,786 INFO:     Epoch: 2
2022-11-28 06:27:51,437 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5287286763967469, 'Total loss': 0.5287286763967469} | train loss {'Reaction outcome loss': 0.5399078682003688, 'Total loss': 0.5399078682003688}
2022-11-28 06:27:51,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:51,437 INFO:     Epoch: 3
2022-11-28 06:27:52,088 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5450611565002176, 'Total loss': 0.5450611565002176} | train loss {'Reaction outcome loss': 0.5193772750749509, 'Total loss': 0.5193772750749509}
2022-11-28 06:27:52,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:52,088 INFO:     Epoch: 4
2022-11-28 06:27:52,737 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5418361331834349, 'Total loss': 0.5418361331834349} | train loss {'Reaction outcome loss': 0.5112731937824944, 'Total loss': 0.5112731937824944}
2022-11-28 06:27:52,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:52,744 INFO:     Epoch: 5
2022-11-28 06:27:53,393 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5017574249311935, 'Total loss': 0.5017574249311935} | train loss {'Reaction outcome loss': 0.5067125583995026, 'Total loss': 0.5067125583995026}
2022-11-28 06:27:53,393 INFO:     Found new best model at epoch 5
2022-11-28 06:27:53,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:53,394 INFO:     Epoch: 6
2022-11-28 06:27:54,042 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5134826749563217, 'Total loss': 0.5134826749563217} | train loss {'Reaction outcome loss': 0.5002354722577358, 'Total loss': 0.5002354722577358}
2022-11-28 06:27:54,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:54,042 INFO:     Epoch: 7
2022-11-28 06:27:54,688 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5051302788562553, 'Total loss': 0.5051302788562553} | train loss {'Reaction outcome loss': 0.4851553251223309, 'Total loss': 0.4851553251223309}
2022-11-28 06:27:54,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:54,688 INFO:     Epoch: 8
2022-11-28 06:27:55,337 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.558506719594778, 'Total loss': 0.558506719594778} | train loss {'Reaction outcome loss': 0.48993458473142776, 'Total loss': 0.48993458473142776}
2022-11-28 06:27:55,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:55,338 INFO:     Epoch: 9
2022-11-28 06:27:55,985 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5027094673971797, 'Total loss': 0.5027094673971797} | train loss {'Reaction outcome loss': 0.4703814318641223, 'Total loss': 0.4703814318641223}
2022-11-28 06:27:55,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:55,987 INFO:     Epoch: 10
2022-11-28 06:27:56,636 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.505438718165076, 'Total loss': 0.505438718165076} | train loss {'Reaction outcome loss': 0.4811215431969843, 'Total loss': 0.4811215431969843}
2022-11-28 06:27:56,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:56,636 INFO:     Epoch: 11
2022-11-28 06:27:57,288 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46529993622802024, 'Total loss': 0.46529993622802024} | train loss {'Reaction outcome loss': 0.47218474009890615, 'Total loss': 0.47218474009890615}
2022-11-28 06:27:57,288 INFO:     Found new best model at epoch 11
2022-11-28 06:27:57,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:57,288 INFO:     Epoch: 12
2022-11-28 06:27:57,941 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49433082411455553, 'Total loss': 0.49433082411455553} | train loss {'Reaction outcome loss': 0.46752074060371385, 'Total loss': 0.46752074060371385}
2022-11-28 06:27:57,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:57,942 INFO:     Epoch: 13
2022-11-28 06:27:58,593 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48967382103897805, 'Total loss': 0.48967382103897805} | train loss {'Reaction outcome loss': 0.46401379593176606, 'Total loss': 0.46401379593176606}
2022-11-28 06:27:58,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:58,593 INFO:     Epoch: 14
2022-11-28 06:27:59,244 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4815631737542707, 'Total loss': 0.4815631737542707} | train loss {'Reaction outcome loss': 0.4722257675947966, 'Total loss': 0.4722257675947966}
2022-11-28 06:27:59,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:59,244 INFO:     Epoch: 15
2022-11-28 06:27:59,895 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4856951694155848, 'Total loss': 0.4856951694155848} | train loss {'Reaction outcome loss': 0.46717740724116197, 'Total loss': 0.46717740724116197}
2022-11-28 06:27:59,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:27:59,895 INFO:     Epoch: 16
2022-11-28 06:28:00,544 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47985444339208827, 'Total loss': 0.47985444339208827} | train loss {'Reaction outcome loss': 0.46735027211683766, 'Total loss': 0.46735027211683766}
2022-11-28 06:28:00,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:00,544 INFO:     Epoch: 17
2022-11-28 06:28:01,194 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48025666281234386, 'Total loss': 0.48025666281234386} | train loss {'Reaction outcome loss': 0.4679174578054942, 'Total loss': 0.4679174578054942}
2022-11-28 06:28:01,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:01,194 INFO:     Epoch: 18
2022-11-28 06:28:01,849 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.472869984285776, 'Total loss': 0.472869984285776} | train loss {'Reaction outcome loss': 0.45980900434064276, 'Total loss': 0.45980900434064276}
2022-11-28 06:28:01,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:01,850 INFO:     Epoch: 19
2022-11-28 06:28:02,499 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5045873966327933, 'Total loss': 0.5045873966327933} | train loss {'Reaction outcome loss': 0.45296141554298713, 'Total loss': 0.45296141554298713}
2022-11-28 06:28:02,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:02,500 INFO:     Epoch: 20
2022-11-28 06:28:03,148 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48440969198249106, 'Total loss': 0.48440969198249106} | train loss {'Reaction outcome loss': 0.46677476891274317, 'Total loss': 0.46677476891274317}
2022-11-28 06:28:03,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:03,149 INFO:     Epoch: 21
2022-11-28 06:28:03,797 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5093429598004319, 'Total loss': 0.5093429598004319} | train loss {'Reaction outcome loss': 0.4621044596036275, 'Total loss': 0.4621044596036275}
2022-11-28 06:28:03,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:03,797 INFO:     Epoch: 22
2022-11-28 06:28:04,444 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4963444277297619, 'Total loss': 0.4963444277297619} | train loss {'Reaction outcome loss': 0.46212478613657226, 'Total loss': 0.46212478613657226}
2022-11-28 06:28:04,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:04,444 INFO:     Epoch: 23
2022-11-28 06:28:05,093 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48824195806370224, 'Total loss': 0.48824195806370224} | train loss {'Reaction outcome loss': 0.4574018050859004, 'Total loss': 0.4574018050859004}
2022-11-28 06:28:05,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:05,093 INFO:     Epoch: 24
2022-11-28 06:28:05,742 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5244511691636817, 'Total loss': 0.5244511691636817} | train loss {'Reaction outcome loss': 0.4574329854284294, 'Total loss': 0.4574329854284294}
2022-11-28 06:28:05,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:05,742 INFO:     Epoch: 25
2022-11-28 06:28:06,393 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48343944757483726, 'Total loss': 0.48343944757483726} | train loss {'Reaction outcome loss': 0.45587940115496944, 'Total loss': 0.45587940115496944}
2022-11-28 06:28:06,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:06,393 INFO:     Epoch: 26
2022-11-28 06:28:07,044 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4954695493675942, 'Total loss': 0.4954695493675942} | train loss {'Reaction outcome loss': 0.4521343703439206, 'Total loss': 0.4521343703439206}
2022-11-28 06:28:07,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:07,044 INFO:     Epoch: 27
2022-11-28 06:28:07,694 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5024953068688859, 'Total loss': 0.5024953068688859} | train loss {'Reaction outcome loss': 0.45636837656605883, 'Total loss': 0.45636837656605883}
2022-11-28 06:28:07,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:07,694 INFO:     Epoch: 28
2022-11-28 06:28:08,346 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4861412741417109, 'Total loss': 0.4861412741417109} | train loss {'Reaction outcome loss': 0.45808151045453893, 'Total loss': 0.45808151045453893}
2022-11-28 06:28:08,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:08,346 INFO:     Epoch: 29
2022-11-28 06:28:08,997 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49858593732811685, 'Total loss': 0.49858593732811685} | train loss {'Reaction outcome loss': 0.45608473492502677, 'Total loss': 0.45608473492502677}
2022-11-28 06:28:08,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:08,997 INFO:     Epoch: 30
2022-11-28 06:28:09,658 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4801222917645477, 'Total loss': 0.4801222917645477} | train loss {'Reaction outcome loss': 0.46167227135273653, 'Total loss': 0.46167227135273653}
2022-11-28 06:28:09,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:09,658 INFO:     Epoch: 31
2022-11-28 06:28:10,313 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5422589550184649, 'Total loss': 0.5422589550184649} | train loss {'Reaction outcome loss': 0.4523298212714156, 'Total loss': 0.4523298212714156}
2022-11-28 06:28:10,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:10,313 INFO:     Epoch: 32
2022-11-28 06:28:10,969 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47664960387141203, 'Total loss': 0.47664960387141203} | train loss {'Reaction outcome loss': 0.454191822022077, 'Total loss': 0.454191822022077}
2022-11-28 06:28:10,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:10,969 INFO:     Epoch: 33
2022-11-28 06:28:11,619 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5126636049082113, 'Total loss': 0.5126636049082113} | train loss {'Reaction outcome loss': 0.4502952869659589, 'Total loss': 0.4502952869659589}
2022-11-28 06:28:11,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:11,620 INFO:     Epoch: 34
2022-11-28 06:28:12,268 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.477592900741932, 'Total loss': 0.477592900741932} | train loss {'Reaction outcome loss': 0.45477362798810494, 'Total loss': 0.45477362798810494}
2022-11-28 06:28:12,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:12,268 INFO:     Epoch: 35
2022-11-28 06:28:12,920 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46995613117550694, 'Total loss': 0.46995613117550694} | train loss {'Reaction outcome loss': 0.44936125697912993, 'Total loss': 0.44936125697912993}
2022-11-28 06:28:12,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:12,920 INFO:     Epoch: 36
2022-11-28 06:28:13,568 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47755629933157634, 'Total loss': 0.47755629933157634} | train loss {'Reaction outcome loss': 0.45323810410597687, 'Total loss': 0.45323810410597687}
2022-11-28 06:28:13,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:13,568 INFO:     Epoch: 37
2022-11-28 06:28:14,219 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4953308992607649, 'Total loss': 0.4953308992607649} | train loss {'Reaction outcome loss': 0.46123732528323497, 'Total loss': 0.46123732528323497}
2022-11-28 06:28:14,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:14,220 INFO:     Epoch: 38
2022-11-28 06:28:14,873 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4916263745967732, 'Total loss': 0.4916263745967732} | train loss {'Reaction outcome loss': 0.4549156938805992, 'Total loss': 0.4549156938805992}
2022-11-28 06:28:14,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:14,874 INFO:     Epoch: 39
2022-11-28 06:28:15,525 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48884973241839297, 'Total loss': 0.48884973241839297} | train loss {'Reaction outcome loss': 0.45621193957672196, 'Total loss': 0.45621193957672196}
2022-11-28 06:28:15,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:15,525 INFO:     Epoch: 40
2022-11-28 06:28:16,175 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48173610762108204, 'Total loss': 0.48173610762108204} | train loss {'Reaction outcome loss': 0.4544251420738275, 'Total loss': 0.4544251420738275}
2022-11-28 06:28:16,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:16,175 INFO:     Epoch: 41
2022-11-28 06:28:16,819 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47193974256515503, 'Total loss': 0.47193974256515503} | train loss {'Reaction outcome loss': 0.45641736076079276, 'Total loss': 0.45641736076079276}
2022-11-28 06:28:16,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:16,819 INFO:     Epoch: 42
2022-11-28 06:28:17,467 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4968993192495302, 'Total loss': 0.4968993192495302} | train loss {'Reaction outcome loss': 0.4607181390862406, 'Total loss': 0.4607181390862406}
2022-11-28 06:28:17,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:17,467 INFO:     Epoch: 43
2022-11-28 06:28:18,117 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4600109461435052, 'Total loss': 0.4600109461435052} | train loss {'Reaction outcome loss': 0.45251974316290866, 'Total loss': 0.45251974316290866}
2022-11-28 06:28:18,117 INFO:     Found new best model at epoch 43
2022-11-28 06:28:18,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:18,118 INFO:     Epoch: 44
2022-11-28 06:28:18,766 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.527332195708918, 'Total loss': 0.527332195708918} | train loss {'Reaction outcome loss': 0.4531471068844383, 'Total loss': 0.4531471068844383}
2022-11-28 06:28:18,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:18,766 INFO:     Epoch: 45
2022-11-28 06:28:19,414 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4773312252621318, 'Total loss': 0.4773312252621318} | train loss {'Reaction outcome loss': 0.4493097164993914, 'Total loss': 0.4493097164993914}
2022-11-28 06:28:19,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:19,414 INFO:     Epoch: 46
2022-11-28 06:28:20,058 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46777870003567185, 'Total loss': 0.46777870003567185} | train loss {'Reaction outcome loss': 0.45277508633372227, 'Total loss': 0.45277508633372227}
2022-11-28 06:28:20,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:20,058 INFO:     Epoch: 47
2022-11-28 06:28:20,706 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5333254510580108, 'Total loss': 0.5333254510580108} | train loss {'Reaction outcome loss': 0.4560684604654587, 'Total loss': 0.4560684604654587}
2022-11-28 06:28:20,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:20,706 INFO:     Epoch: 48
2022-11-28 06:28:21,354 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4947201328915219, 'Total loss': 0.4947201328915219} | train loss {'Reaction outcome loss': 0.45558080451233396, 'Total loss': 0.45558080451233396}
2022-11-28 06:28:21,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:21,355 INFO:     Epoch: 49
2022-11-28 06:28:22,002 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48121762414311253, 'Total loss': 0.48121762414311253} | train loss {'Reaction outcome loss': 0.4585150245101854, 'Total loss': 0.4585150245101854}
2022-11-28 06:28:22,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:22,002 INFO:     Epoch: 50
2022-11-28 06:28:22,646 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47014862506888633, 'Total loss': 0.47014862506888633} | train loss {'Reaction outcome loss': 0.44908623176592366, 'Total loss': 0.44908623176592366}
2022-11-28 06:28:22,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:22,646 INFO:     Epoch: 51
2022-11-28 06:28:23,290 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49113079974817675, 'Total loss': 0.49113079974817675} | train loss {'Reaction outcome loss': 0.4514311213552216, 'Total loss': 0.4514311213552216}
2022-11-28 06:28:23,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:23,290 INFO:     Epoch: 52
2022-11-28 06:28:23,938 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4888818915500197, 'Total loss': 0.4888818915500197} | train loss {'Reaction outcome loss': 0.45244417318100794, 'Total loss': 0.45244417318100794}
2022-11-28 06:28:23,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:23,938 INFO:     Epoch: 53
2022-11-28 06:28:24,584 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48355256540830743, 'Total loss': 0.48355256540830743} | train loss {'Reaction outcome loss': 0.4637948757827037, 'Total loss': 0.4637948757827037}
2022-11-28 06:28:24,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:24,584 INFO:     Epoch: 54
2022-11-28 06:28:25,230 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4814355643682702, 'Total loss': 0.4814355643682702} | train loss {'Reaction outcome loss': 0.4532628435902144, 'Total loss': 0.4532628435902144}
2022-11-28 06:28:25,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:25,230 INFO:     Epoch: 55
2022-11-28 06:28:25,875 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4846619364134101, 'Total loss': 0.4846619364134101} | train loss {'Reaction outcome loss': 0.4534941350604281, 'Total loss': 0.4534941350604281}
2022-11-28 06:28:25,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:25,875 INFO:     Epoch: 56
2022-11-28 06:28:26,521 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.473759573905967, 'Total loss': 0.473759573905967} | train loss {'Reaction outcome loss': 0.4550414208031486, 'Total loss': 0.4550414208031486}
2022-11-28 06:28:26,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:26,522 INFO:     Epoch: 57
2022-11-28 06:28:27,167 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48429245484429734, 'Total loss': 0.48429245484429734} | train loss {'Reaction outcome loss': 0.45403222151008654, 'Total loss': 0.45403222151008654}
2022-11-28 06:28:27,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:27,168 INFO:     Epoch: 58
2022-11-28 06:28:27,812 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4933234487855157, 'Total loss': 0.4933234487855157} | train loss {'Reaction outcome loss': 0.45271510664572934, 'Total loss': 0.45271510664572934}
2022-11-28 06:28:27,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:27,812 INFO:     Epoch: 59
2022-11-28 06:28:28,457 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4814476100511329, 'Total loss': 0.4814476100511329} | train loss {'Reaction outcome loss': 0.4566540912468247, 'Total loss': 0.4566540912468247}
2022-11-28 06:28:28,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:28,457 INFO:     Epoch: 60
2022-11-28 06:28:29,103 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4979923769485119, 'Total loss': 0.4979923769485119} | train loss {'Reaction outcome loss': 0.4542489124178396, 'Total loss': 0.4542489124178396}
2022-11-28 06:28:29,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:29,104 INFO:     Epoch: 61
2022-11-28 06:28:29,749 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48340359399485033, 'Total loss': 0.48340359399485033} | train loss {'Reaction outcome loss': 0.4520056122001797, 'Total loss': 0.4520056122001797}
2022-11-28 06:28:29,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:29,750 INFO:     Epoch: 62
2022-11-28 06:28:30,396 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47803950725599775, 'Total loss': 0.47803950725599775} | train loss {'Reaction outcome loss': 0.46623577888855716, 'Total loss': 0.46623577888855716}
2022-11-28 06:28:30,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:30,396 INFO:     Epoch: 63
2022-11-28 06:28:31,042 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5268231252598208, 'Total loss': 0.5268231252598208} | train loss {'Reaction outcome loss': 0.45469117379237595, 'Total loss': 0.45469117379237595}
2022-11-28 06:28:31,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:31,043 INFO:     Epoch: 64
2022-11-28 06:28:31,689 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4898526613102403, 'Total loss': 0.4898526613102403} | train loss {'Reaction outcome loss': 0.44709023238454826, 'Total loss': 0.44709023238454826}
2022-11-28 06:28:31,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:31,690 INFO:     Epoch: 65
2022-11-28 06:28:32,336 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.506824872521467, 'Total loss': 0.506824872521467} | train loss {'Reaction outcome loss': 0.45361081703945444, 'Total loss': 0.45361081703945444}
2022-11-28 06:28:32,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:32,337 INFO:     Epoch: 66
2022-11-28 06:28:32,981 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49178533498630966, 'Total loss': 0.49178533498630966} | train loss {'Reaction outcome loss': 0.45411843674663654, 'Total loss': 0.45411843674663654}
2022-11-28 06:28:32,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:32,982 INFO:     Epoch: 67
2022-11-28 06:28:33,626 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49664261348025746, 'Total loss': 0.49664261348025746} | train loss {'Reaction outcome loss': 0.4497395194607017, 'Total loss': 0.4497395194607017}
2022-11-28 06:28:33,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:33,626 INFO:     Epoch: 68
2022-11-28 06:28:34,277 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5027746845816456, 'Total loss': 0.5027746845816456} | train loss {'Reaction outcome loss': 0.45508441187962584, 'Total loss': 0.45508441187962584}
2022-11-28 06:28:34,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:34,277 INFO:     Epoch: 69
2022-11-28 06:28:34,922 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5206406171931777, 'Total loss': 0.5206406171931777} | train loss {'Reaction outcome loss': 0.45951369570361245, 'Total loss': 0.45951369570361245}
2022-11-28 06:28:34,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:34,922 INFO:     Epoch: 70
2022-11-28 06:28:35,568 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47625821863496026, 'Total loss': 0.47625821863496026} | train loss {'Reaction outcome loss': 0.45348783560986383, 'Total loss': 0.45348783560986383}
2022-11-28 06:28:35,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:35,568 INFO:     Epoch: 71
2022-11-28 06:28:36,214 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4876335464244665, 'Total loss': 0.4876335464244665} | train loss {'Reaction outcome loss': 0.4541981424446459, 'Total loss': 0.4541981424446459}
2022-11-28 06:28:36,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:36,214 INFO:     Epoch: 72
2022-11-28 06:28:36,860 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.506755821233572, 'Total loss': 0.506755821233572} | train loss {'Reaction outcome loss': 0.4493833856020935, 'Total loss': 0.4493833856020935}
2022-11-28 06:28:36,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:36,860 INFO:     Epoch: 73
2022-11-28 06:28:37,506 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4778635370176892, 'Total loss': 0.4778635370176892} | train loss {'Reaction outcome loss': 0.453579807906975, 'Total loss': 0.453579807906975}
2022-11-28 06:28:37,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:37,507 INFO:     Epoch: 74
2022-11-28 06:28:38,153 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5064855585264605, 'Total loss': 0.5064855585264605} | train loss {'Reaction outcome loss': 0.4574043369035662, 'Total loss': 0.4574043369035662}
2022-11-28 06:28:38,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:38,153 INFO:     Epoch: 75
2022-11-28 06:28:38,799 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4894680807063746, 'Total loss': 0.4894680807063746} | train loss {'Reaction outcome loss': 0.45017014633971475, 'Total loss': 0.45017014633971475}
2022-11-28 06:28:38,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:38,799 INFO:     Epoch: 76
2022-11-28 06:28:39,446 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.507513832907344, 'Total loss': 0.507513832907344} | train loss {'Reaction outcome loss': 0.4633963633589293, 'Total loss': 0.4633963633589293}
2022-11-28 06:28:39,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:39,446 INFO:     Epoch: 77
2022-11-28 06:28:40,093 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5200453376354173, 'Total loss': 0.5200453376354173} | train loss {'Reaction outcome loss': 0.45238128396463984, 'Total loss': 0.45238128396463984}
2022-11-28 06:28:40,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:40,094 INFO:     Epoch: 78
2022-11-28 06:28:40,741 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4710825303959292, 'Total loss': 0.4710825303959292} | train loss {'Reaction outcome loss': 0.45862367822800154, 'Total loss': 0.45862367822800154}
2022-11-28 06:28:40,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:40,741 INFO:     Epoch: 79
2022-11-28 06:28:41,389 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4842986208061839, 'Total loss': 0.4842986208061839} | train loss {'Reaction outcome loss': 0.4575026219273791, 'Total loss': 0.4575026219273791}
2022-11-28 06:28:41,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:41,389 INFO:     Epoch: 80
2022-11-28 06:28:42,038 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.510322050646294, 'Total loss': 0.510322050646294} | train loss {'Reaction outcome loss': 0.4561720944235845, 'Total loss': 0.4561720944235845}
2022-11-28 06:28:42,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:42,038 INFO:     Epoch: 81
2022-11-28 06:28:42,686 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4956452863854031, 'Total loss': 0.4956452863854031} | train loss {'Reaction outcome loss': 0.4545742053799178, 'Total loss': 0.4545742053799178}
2022-11-28 06:28:42,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:42,686 INFO:     Epoch: 82
2022-11-28 06:28:43,337 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49074367451113327, 'Total loss': 0.49074367451113327} | train loss {'Reaction outcome loss': 0.4586780347205974, 'Total loss': 0.4586780347205974}
2022-11-28 06:28:43,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:43,337 INFO:     Epoch: 83
2022-11-28 06:28:43,987 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5083918692760689, 'Total loss': 0.5083918692760689} | train loss {'Reaction outcome loss': 0.4600134193590639, 'Total loss': 0.4600134193590639}
2022-11-28 06:28:43,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:43,987 INFO:     Epoch: 84
2022-11-28 06:28:44,636 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5072106533618861, 'Total loss': 0.5072106533618861} | train loss {'Reaction outcome loss': 0.45569851031764547, 'Total loss': 0.45569851031764547}
2022-11-28 06:28:44,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:44,636 INFO:     Epoch: 85
2022-11-28 06:28:45,282 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4817805602106937, 'Total loss': 0.4817805602106937} | train loss {'Reaction outcome loss': 0.45628654006332037, 'Total loss': 0.45628654006332037}
2022-11-28 06:28:45,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:45,283 INFO:     Epoch: 86
2022-11-28 06:28:45,929 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48674674886603686, 'Total loss': 0.48674674886603686} | train loss {'Reaction outcome loss': 0.4610512936679424, 'Total loss': 0.4610512936679424}
2022-11-28 06:28:45,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:45,929 INFO:     Epoch: 87
2022-11-28 06:28:46,577 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4829157060661981, 'Total loss': 0.4829157060661981} | train loss {'Reaction outcome loss': 0.45670146081182694, 'Total loss': 0.45670146081182694}
2022-11-28 06:28:46,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:46,577 INFO:     Epoch: 88
2022-11-28 06:28:47,222 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4771253463140754, 'Total loss': 0.4771253463140754} | train loss {'Reaction outcome loss': 0.45813403250994506, 'Total loss': 0.45813403250994506}
2022-11-28 06:28:47,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:47,222 INFO:     Epoch: 89
2022-11-28 06:28:47,871 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.531382546175358, 'Total loss': 0.531382546175358} | train loss {'Reaction outcome loss': 0.45211675698742454, 'Total loss': 0.45211675698742454}
2022-11-28 06:28:47,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:47,871 INFO:     Epoch: 90
2022-11-28 06:28:48,523 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47373153407906377, 'Total loss': 0.47373153407906377} | train loss {'Reaction outcome loss': 0.4523947513068225, 'Total loss': 0.4523947513068225}
2022-11-28 06:28:48,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:48,524 INFO:     Epoch: 91
2022-11-28 06:28:49,175 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47979258797889535, 'Total loss': 0.47979258797889535} | train loss {'Reaction outcome loss': 0.4568996237506592, 'Total loss': 0.4568996237506592}
2022-11-28 06:28:49,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:49,175 INFO:     Epoch: 92
2022-11-28 06:28:49,823 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5128587699213694, 'Total loss': 0.5128587699213694} | train loss {'Reaction outcome loss': 0.45841573479244246, 'Total loss': 0.45841573479244246}
2022-11-28 06:28:49,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:49,824 INFO:     Epoch: 93
2022-11-28 06:28:50,469 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4808128968227741, 'Total loss': 0.4808128968227741} | train loss {'Reaction outcome loss': 0.45645725003485815, 'Total loss': 0.45645725003485815}
2022-11-28 06:28:50,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:50,469 INFO:     Epoch: 94
2022-11-28 06:28:51,115 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4699366501597471, 'Total loss': 0.4699366501597471} | train loss {'Reaction outcome loss': 0.45499414910750136, 'Total loss': 0.45499414910750136}
2022-11-28 06:28:51,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:51,115 INFO:     Epoch: 95
2022-11-28 06:28:51,760 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49240232033785, 'Total loss': 0.49240232033785} | train loss {'Reaction outcome loss': 0.45158971660605673, 'Total loss': 0.45158971660605673}
2022-11-28 06:28:51,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:51,760 INFO:     Epoch: 96
2022-11-28 06:28:52,408 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.490160675935967, 'Total loss': 0.490160675935967} | train loss {'Reaction outcome loss': 0.45313185680305024, 'Total loss': 0.45313185680305024}
2022-11-28 06:28:52,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:52,408 INFO:     Epoch: 97
2022-11-28 06:28:53,056 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5084025246459384, 'Total loss': 0.5084025246459384} | train loss {'Reaction outcome loss': 0.4558473922956137, 'Total loss': 0.4558473922956137}
2022-11-28 06:28:53,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:53,056 INFO:     Epoch: 98
2022-11-28 06:28:53,704 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5070078282855278, 'Total loss': 0.5070078282855278} | train loss {'Reaction outcome loss': 0.4577768844832118, 'Total loss': 0.4577768844832118}
2022-11-28 06:28:53,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:53,704 INFO:     Epoch: 99
2022-11-28 06:28:54,350 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.506879645031552, 'Total loss': 0.506879645031552} | train loss {'Reaction outcome loss': 0.4646410051687264, 'Total loss': 0.4646410051687264}
2022-11-28 06:28:54,350 INFO:     Best model found after epoch 44 of 100.
2022-11-28 06:28:54,350 INFO:   Done with stage: TRAINING
2022-11-28 06:28:54,350 INFO:   Starting stage: EVALUATION
2022-11-28 06:28:54,486 INFO:   Done with stage: EVALUATION
2022-11-28 06:28:54,486 INFO:   Leaving out SEQ value Fold_4
2022-11-28 06:28:54,498 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:28:54,499 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:28:55,142 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:28:55,142 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:28:55,212 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:28:55,212 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:28:55,212 INFO:     No hyperparam tuning for this model
2022-11-28 06:28:55,212 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:28:55,212 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:28:55,213 INFO:     None feature selector for col prot
2022-11-28 06:28:55,213 INFO:     None feature selector for col prot
2022-11-28 06:28:55,213 INFO:     None feature selector for col prot
2022-11-28 06:28:55,214 INFO:     None feature selector for col chem
2022-11-28 06:28:55,214 INFO:     None feature selector for col chem
2022-11-28 06:28:55,214 INFO:     None feature selector for col chem
2022-11-28 06:28:55,214 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:28:55,214 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:28:55,215 INFO:     Number of params in model 169651
2022-11-28 06:28:55,219 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:28:55,219 INFO:   Starting stage: TRAINING
2022-11-28 06:28:55,270 INFO:     Val loss before train {'Reaction outcome loss': 0.9566030231389132, 'Total loss': 0.9566030231389132}
2022-11-28 06:28:55,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:55,270 INFO:     Epoch: 0
2022-11-28 06:28:55,931 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5742883753370155, 'Total loss': 0.5742883753370155} | train loss {'Reaction outcome loss': 0.6924409248655842, 'Total loss': 0.6924409248655842}
2022-11-28 06:28:55,931 INFO:     Found new best model at epoch 0
2022-11-28 06:28:55,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:55,932 INFO:     Epoch: 1
2022-11-28 06:28:56,595 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5631214041601528, 'Total loss': 0.5631214041601528} | train loss {'Reaction outcome loss': 0.5874163039148815, 'Total loss': 0.5874163039148815}
2022-11-28 06:28:56,595 INFO:     Found new best model at epoch 1
2022-11-28 06:28:56,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:56,596 INFO:     Epoch: 2
2022-11-28 06:28:57,259 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5058930614455179, 'Total loss': 0.5058930614455179} | train loss {'Reaction outcome loss': 0.5537292147956548, 'Total loss': 0.5537292147956548}
2022-11-28 06:28:57,259 INFO:     Found new best model at epoch 2
2022-11-28 06:28:57,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:57,260 INFO:     Epoch: 3
2022-11-28 06:28:57,921 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48950584503737365, 'Total loss': 0.48950584503737365} | train loss {'Reaction outcome loss': 0.53487001362467, 'Total loss': 0.53487001362467}
2022-11-28 06:28:57,922 INFO:     Found new best model at epoch 3
2022-11-28 06:28:57,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:57,923 INFO:     Epoch: 4
2022-11-28 06:28:58,582 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5474083836783062, 'Total loss': 0.5474083836783062} | train loss {'Reaction outcome loss': 0.5195475135359072, 'Total loss': 0.5195475135359072}
2022-11-28 06:28:58,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:58,582 INFO:     Epoch: 5
2022-11-28 06:28:59,244 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4851964668116786, 'Total loss': 0.4851964668116786} | train loss {'Reaction outcome loss': 0.5155115486873735, 'Total loss': 0.5155115486873735}
2022-11-28 06:28:59,244 INFO:     Found new best model at epoch 5
2022-11-28 06:28:59,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:59,245 INFO:     Epoch: 6
2022-11-28 06:28:59,911 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48945555971427396, 'Total loss': 0.48945555971427396} | train loss {'Reaction outcome loss': 0.5168108681757604, 'Total loss': 0.5168108681757604}
2022-11-28 06:28:59,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:28:59,911 INFO:     Epoch: 7
2022-11-28 06:29:00,572 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4964774637059732, 'Total loss': 0.4964774637059732} | train loss {'Reaction outcome loss': 0.5023363876126467, 'Total loss': 0.5023363876126467}
2022-11-28 06:29:00,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:00,572 INFO:     Epoch: 8
2022-11-28 06:29:01,234 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47653155706145545, 'Total loss': 0.47653155706145545} | train loss {'Reaction outcome loss': 0.5007590255549839, 'Total loss': 0.5007590255549839}
2022-11-28 06:29:01,234 INFO:     Found new best model at epoch 8
2022-11-28 06:29:01,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:01,235 INFO:     Epoch: 9
2022-11-28 06:29:01,896 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49345448342236603, 'Total loss': 0.49345448342236603} | train loss {'Reaction outcome loss': 0.4970040287702314, 'Total loss': 0.4970040287702314}
2022-11-28 06:29:01,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:01,896 INFO:     Epoch: 10
2022-11-28 06:29:02,557 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49831306663426483, 'Total loss': 0.49831306663426483} | train loss {'Reaction outcome loss': 0.49101971792838267, 'Total loss': 0.49101971792838267}
2022-11-28 06:29:02,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:02,557 INFO:     Epoch: 11
2022-11-28 06:29:03,217 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4952525079927661, 'Total loss': 0.4952525079927661} | train loss {'Reaction outcome loss': 0.49005786792164846, 'Total loss': 0.49005786792164846}
2022-11-28 06:29:03,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:03,217 INFO:     Epoch: 12
2022-11-28 06:29:03,882 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4880921095609665, 'Total loss': 0.4880921095609665} | train loss {'Reaction outcome loss': 0.4830404878143341, 'Total loss': 0.4830404878143341}
2022-11-28 06:29:03,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:03,882 INFO:     Epoch: 13
2022-11-28 06:29:04,546 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47512619298967446, 'Total loss': 0.47512619298967446} | train loss {'Reaction outcome loss': 0.4830226483003747, 'Total loss': 0.4830226483003747}
2022-11-28 06:29:04,547 INFO:     Found new best model at epoch 13
2022-11-28 06:29:04,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:04,548 INFO:     Epoch: 14
2022-11-28 06:29:05,210 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49846772239966824, 'Total loss': 0.49846772239966824} | train loss {'Reaction outcome loss': 0.4803167665677686, 'Total loss': 0.4803167665677686}
2022-11-28 06:29:05,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:05,211 INFO:     Epoch: 15
2022-11-28 06:29:05,871 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4576819765974175, 'Total loss': 0.4576819765974175} | train loss {'Reaction outcome loss': 0.48226049344145483, 'Total loss': 0.48226049344145483}
2022-11-28 06:29:05,871 INFO:     Found new best model at epoch 15
2022-11-28 06:29:05,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:05,872 INFO:     Epoch: 16
2022-11-28 06:29:06,537 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4736885784024542, 'Total loss': 0.4736885784024542} | train loss {'Reaction outcome loss': 0.4799853717728007, 'Total loss': 0.4799853717728007}
2022-11-28 06:29:06,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:06,537 INFO:     Epoch: 17
2022-11-28 06:29:07,196 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4588717296719551, 'Total loss': 0.4588717296719551} | train loss {'Reaction outcome loss': 0.4841954113555051, 'Total loss': 0.4841954113555051}
2022-11-28 06:29:07,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:07,197 INFO:     Epoch: 18
2022-11-28 06:29:07,861 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4868001578883691, 'Total loss': 0.4868001578883691} | train loss {'Reaction outcome loss': 0.4843340098497368, 'Total loss': 0.4843340098497368}
2022-11-28 06:29:07,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:07,861 INFO:     Epoch: 19
2022-11-28 06:29:08,522 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4893729727376591, 'Total loss': 0.4893729727376591} | train loss {'Reaction outcome loss': 0.4769700707026547, 'Total loss': 0.4769700707026547}
2022-11-28 06:29:08,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:08,522 INFO:     Epoch: 20
2022-11-28 06:29:09,187 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48023526912385767, 'Total loss': 0.48023526912385767} | train loss {'Reaction outcome loss': 0.48404851477713357, 'Total loss': 0.48404851477713357}
2022-11-28 06:29:09,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:09,187 INFO:     Epoch: 21
2022-11-28 06:29:09,849 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47323842922394926, 'Total loss': 0.47323842922394926} | train loss {'Reaction outcome loss': 0.4751174230609209, 'Total loss': 0.4751174230609209}
2022-11-28 06:29:09,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:09,849 INFO:     Epoch: 22
2022-11-28 06:29:10,512 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4864018586548892, 'Total loss': 0.4864018586548892} | train loss {'Reaction outcome loss': 0.4887554791545676, 'Total loss': 0.4887554791545676}
2022-11-28 06:29:10,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:10,512 INFO:     Epoch: 23
2022-11-28 06:29:11,178 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4958511177789081, 'Total loss': 0.4958511177789081} | train loss {'Reaction outcome loss': 0.48197122906605083, 'Total loss': 0.48197122906605083}
2022-11-28 06:29:11,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:11,179 INFO:     Epoch: 24
2022-11-28 06:29:11,842 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5562636053020303, 'Total loss': 0.5562636053020303} | train loss {'Reaction outcome loss': 0.47942660487587413, 'Total loss': 0.47942660487587413}
2022-11-28 06:29:11,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:11,842 INFO:     Epoch: 25
2022-11-28 06:29:12,507 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4741079800508239, 'Total loss': 0.4741079800508239} | train loss {'Reaction outcome loss': 0.48250622254225517, 'Total loss': 0.48250622254225517}
2022-11-28 06:29:12,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:12,507 INFO:     Epoch: 26
2022-11-28 06:29:13,171 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47765440426089545, 'Total loss': 0.47765440426089545} | train loss {'Reaction outcome loss': 0.4829423041833985, 'Total loss': 0.4829423041833985}
2022-11-28 06:29:13,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:13,171 INFO:     Epoch: 27
2022-11-28 06:29:13,833 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48810734295032243, 'Total loss': 0.48810734295032243} | train loss {'Reaction outcome loss': 0.4783128812428444, 'Total loss': 0.4783128812428444}
2022-11-28 06:29:13,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:13,833 INFO:     Epoch: 28
2022-11-28 06:29:14,504 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45942556925795297, 'Total loss': 0.45942556925795297} | train loss {'Reaction outcome loss': 0.47834846365355677, 'Total loss': 0.47834846365355677}
2022-11-28 06:29:14,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:14,504 INFO:     Epoch: 29
2022-11-28 06:29:15,171 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47638340158896014, 'Total loss': 0.47638340158896014} | train loss {'Reaction outcome loss': 0.4763345889626972, 'Total loss': 0.4763345889626972}
2022-11-28 06:29:15,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:15,171 INFO:     Epoch: 30
2022-11-28 06:29:15,837 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4845344878055833, 'Total loss': 0.4845344878055833} | train loss {'Reaction outcome loss': 0.48373527103854763, 'Total loss': 0.48373527103854763}
2022-11-28 06:29:15,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:15,838 INFO:     Epoch: 31
2022-11-28 06:29:16,502 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47201652960343793, 'Total loss': 0.47201652960343793} | train loss {'Reaction outcome loss': 0.4873404459607217, 'Total loss': 0.4873404459607217}
2022-11-28 06:29:16,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:16,502 INFO:     Epoch: 32
2022-11-28 06:29:17,167 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4869266656989401, 'Total loss': 0.4869266656989401} | train loss {'Reaction outcome loss': 0.47771753286642415, 'Total loss': 0.47771753286642415}
2022-11-28 06:29:17,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:17,168 INFO:     Epoch: 33
2022-11-28 06:29:17,834 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4669054258953441, 'Total loss': 0.4669054258953441} | train loss {'Reaction outcome loss': 0.48399527809552606, 'Total loss': 0.48399527809552606}
2022-11-28 06:29:17,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:17,834 INFO:     Epoch: 34
2022-11-28 06:29:18,497 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4733096601610834, 'Total loss': 0.4733096601610834} | train loss {'Reaction outcome loss': 0.47809710431723823, 'Total loss': 0.47809710431723823}
2022-11-28 06:29:18,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:18,497 INFO:     Epoch: 35
2022-11-28 06:29:19,159 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4693688597868789, 'Total loss': 0.4693688597868789} | train loss {'Reaction outcome loss': 0.4792574151389061, 'Total loss': 0.4792574151389061}
2022-11-28 06:29:19,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:19,159 INFO:     Epoch: 36
2022-11-28 06:29:19,830 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49253988841717894, 'Total loss': 0.49253988841717894} | train loss {'Reaction outcome loss': 0.4790027604228066, 'Total loss': 0.4790027604228066}
2022-11-28 06:29:19,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:19,830 INFO:     Epoch: 37
2022-11-28 06:29:20,495 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48495509069074283, 'Total loss': 0.48495509069074283} | train loss {'Reaction outcome loss': 0.4784549300468737, 'Total loss': 0.4784549300468737}
2022-11-28 06:29:20,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:20,495 INFO:     Epoch: 38
2022-11-28 06:29:21,156 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46936955709349026, 'Total loss': 0.46936955709349026} | train loss {'Reaction outcome loss': 0.47905925360898816, 'Total loss': 0.47905925360898816}
2022-11-28 06:29:21,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:21,156 INFO:     Epoch: 39
2022-11-28 06:29:21,818 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47176249528473074, 'Total loss': 0.47176249528473074} | train loss {'Reaction outcome loss': 0.4711341911986951, 'Total loss': 0.4711341911986951}
2022-11-28 06:29:21,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:21,818 INFO:     Epoch: 40
2022-11-28 06:29:22,483 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45453947342254897, 'Total loss': 0.45453947342254897} | train loss {'Reaction outcome loss': 0.4809022644354451, 'Total loss': 0.4809022644354451}
2022-11-28 06:29:22,484 INFO:     Found new best model at epoch 40
2022-11-28 06:29:22,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:22,484 INFO:     Epoch: 41
2022-11-28 06:29:23,148 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5018513429571282, 'Total loss': 0.5018513429571282} | train loss {'Reaction outcome loss': 0.4857561025287836, 'Total loss': 0.4857561025287836}
2022-11-28 06:29:23,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:23,148 INFO:     Epoch: 42
2022-11-28 06:29:23,813 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4820456189865416, 'Total loss': 0.4820456189865416} | train loss {'Reaction outcome loss': 0.4851461725249406, 'Total loss': 0.4851461725249406}
2022-11-28 06:29:23,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:23,813 INFO:     Epoch: 43
2022-11-28 06:29:24,476 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4884916042739695, 'Total loss': 0.4884916042739695} | train loss {'Reaction outcome loss': 0.48203300384263836, 'Total loss': 0.48203300384263836}
2022-11-28 06:29:24,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:24,476 INFO:     Epoch: 44
2022-11-28 06:29:25,142 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48264170573516324, 'Total loss': 0.48264170573516324} | train loss {'Reaction outcome loss': 0.4817471716012205, 'Total loss': 0.4817471716012205}
2022-11-28 06:29:25,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:25,142 INFO:     Epoch: 45
2022-11-28 06:29:25,809 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4771420197053389, 'Total loss': 0.4771420197053389} | train loss {'Reaction outcome loss': 0.47887397052780273, 'Total loss': 0.47887397052780273}
2022-11-28 06:29:25,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:25,809 INFO:     Epoch: 46
2022-11-28 06:29:26,486 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4708908657458695, 'Total loss': 0.4708908657458695} | train loss {'Reaction outcome loss': 0.4803221910711258, 'Total loss': 0.4803221910711258}
2022-11-28 06:29:26,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:26,487 INFO:     Epoch: 47
2022-11-28 06:29:27,174 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48779190399430017, 'Total loss': 0.48779190399430017} | train loss {'Reaction outcome loss': 0.47463332945781367, 'Total loss': 0.47463332945781367}
2022-11-28 06:29:27,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:27,174 INFO:     Epoch: 48
2022-11-28 06:29:27,854 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.509693006561561, 'Total loss': 0.509693006561561} | train loss {'Reaction outcome loss': 0.47550005393643535, 'Total loss': 0.47550005393643535}
2022-11-28 06:29:27,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:27,854 INFO:     Epoch: 49
2022-11-28 06:29:28,535 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4744137027724223, 'Total loss': 0.4744137027724223} | train loss {'Reaction outcome loss': 0.4814507286514967, 'Total loss': 0.4814507286514967}
2022-11-28 06:29:28,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:28,535 INFO:     Epoch: 50
2022-11-28 06:29:29,219 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4902508235113187, 'Total loss': 0.4902508235113187} | train loss {'Reaction outcome loss': 0.47225062699327547, 'Total loss': 0.47225062699327547}
2022-11-28 06:29:29,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:29,220 INFO:     Epoch: 51
2022-11-28 06:29:29,902 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4651862694458528, 'Total loss': 0.4651862694458528} | train loss {'Reaction outcome loss': 0.47922595374045834, 'Total loss': 0.47922595374045834}
2022-11-28 06:29:29,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:29,902 INFO:     Epoch: 52
2022-11-28 06:29:30,582 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46629123931581323, 'Total loss': 0.46629123931581323} | train loss {'Reaction outcome loss': 0.4827799952679103, 'Total loss': 0.4827799952679103}
2022-11-28 06:29:30,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:30,582 INFO:     Epoch: 53
2022-11-28 06:29:31,267 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4852006597952409, 'Total loss': 0.4852006597952409} | train loss {'Reaction outcome loss': 0.48076771944761276, 'Total loss': 0.48076771944761276}
2022-11-28 06:29:31,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:31,267 INFO:     Epoch: 54
2022-11-28 06:29:31,948 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46983500671657646, 'Total loss': 0.46983500671657646} | train loss {'Reaction outcome loss': 0.4753774501863987, 'Total loss': 0.4753774501863987}
2022-11-28 06:29:31,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:31,948 INFO:     Epoch: 55
2022-11-28 06:29:32,629 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4623429717665369, 'Total loss': 0.4623429717665369} | train loss {'Reaction outcome loss': 0.4732639294478201, 'Total loss': 0.4732639294478201}
2022-11-28 06:29:32,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:32,630 INFO:     Epoch: 56
2022-11-28 06:29:33,311 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47778923538598145, 'Total loss': 0.47778923538598145} | train loss {'Reaction outcome loss': 0.476851444030481, 'Total loss': 0.476851444030481}
2022-11-28 06:29:33,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:33,311 INFO:     Epoch: 57
2022-11-28 06:29:33,991 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4783152792264115, 'Total loss': 0.4783152792264115} | train loss {'Reaction outcome loss': 0.47827902280034557, 'Total loss': 0.47827902280034557}
2022-11-28 06:29:33,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:33,992 INFO:     Epoch: 58
2022-11-28 06:29:34,676 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4672784107652577, 'Total loss': 0.4672784107652577} | train loss {'Reaction outcome loss': 0.4789832070950539, 'Total loss': 0.4789832070950539}
2022-11-28 06:29:34,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:34,677 INFO:     Epoch: 59
2022-11-28 06:29:35,357 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4666059718213298, 'Total loss': 0.4666059718213298} | train loss {'Reaction outcome loss': 0.47717507796422126, 'Total loss': 0.47717507796422126}
2022-11-28 06:29:35,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:35,358 INFO:     Epoch: 60
2022-11-28 06:29:36,023 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4655029736459255, 'Total loss': 0.4655029736459255} | train loss {'Reaction outcome loss': 0.477045891295758, 'Total loss': 0.477045891295758}
2022-11-28 06:29:36,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:36,024 INFO:     Epoch: 61
2022-11-28 06:29:36,687 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4782459752803499, 'Total loss': 0.4782459752803499} | train loss {'Reaction outcome loss': 0.4782766432411248, 'Total loss': 0.4782766432411248}
2022-11-28 06:29:36,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:36,687 INFO:     Epoch: 62
2022-11-28 06:29:37,348 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4902035648172552, 'Total loss': 0.4902035648172552} | train loss {'Reaction outcome loss': 0.4792740907399885, 'Total loss': 0.4792740907399885}
2022-11-28 06:29:37,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:37,349 INFO:     Epoch: 63
2022-11-28 06:29:38,015 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47515116361054505, 'Total loss': 0.47515116361054505} | train loss {'Reaction outcome loss': 0.47413465242472386, 'Total loss': 0.47413465242472386}
2022-11-28 06:29:38,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:38,015 INFO:     Epoch: 64
2022-11-28 06:29:38,676 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4831398610364307, 'Total loss': 0.4831398610364307} | train loss {'Reaction outcome loss': 0.47748696858123424, 'Total loss': 0.47748696858123424}
2022-11-28 06:29:38,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:38,676 INFO:     Epoch: 65
2022-11-28 06:29:39,338 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4587664282457395, 'Total loss': 0.4587664282457395} | train loss {'Reaction outcome loss': 0.4807563602563835, 'Total loss': 0.4807563602563835}
2022-11-28 06:29:39,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:39,338 INFO:     Epoch: 66
2022-11-28 06:29:39,998 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4563832865519957, 'Total loss': 0.4563832865519957} | train loss {'Reaction outcome loss': 0.4814081526091022, 'Total loss': 0.4814081526091022}
2022-11-28 06:29:39,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:39,998 INFO:     Epoch: 67
2022-11-28 06:29:40,663 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4629686481573365, 'Total loss': 0.4629686481573365} | train loss {'Reaction outcome loss': 0.48071755510905095, 'Total loss': 0.48071755510905095}
2022-11-28 06:29:40,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:40,663 INFO:     Epoch: 68
2022-11-28 06:29:41,327 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46559116312048654, 'Total loss': 0.46559116312048654} | train loss {'Reaction outcome loss': 0.47688731539153284, 'Total loss': 0.47688731539153284}
2022-11-28 06:29:41,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:41,328 INFO:     Epoch: 69
2022-11-28 06:29:41,991 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47951808097687637, 'Total loss': 0.47951808097687637} | train loss {'Reaction outcome loss': 0.4664323368981, 'Total loss': 0.4664323368981}
2022-11-28 06:29:41,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:41,991 INFO:     Epoch: 70
2022-11-28 06:29:42,656 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4720375829122283, 'Total loss': 0.4720375829122283} | train loss {'Reaction outcome loss': 0.4732062566064058, 'Total loss': 0.4732062566064058}
2022-11-28 06:29:42,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:42,656 INFO:     Epoch: 71
2022-11-28 06:29:43,318 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4581745717335831, 'Total loss': 0.4581745717335831} | train loss {'Reaction outcome loss': 0.4797483834047471, 'Total loss': 0.4797483834047471}
2022-11-28 06:29:43,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:43,318 INFO:     Epoch: 72
2022-11-28 06:29:43,980 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5024520030075853, 'Total loss': 0.5024520030075853} | train loss {'Reaction outcome loss': 0.4769149721269646, 'Total loss': 0.4769149721269646}
2022-11-28 06:29:43,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:43,981 INFO:     Epoch: 73
2022-11-28 06:29:44,645 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5082745450464162, 'Total loss': 0.5082745450464162} | train loss {'Reaction outcome loss': 0.4746413569176389, 'Total loss': 0.4746413569176389}
2022-11-28 06:29:44,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:44,646 INFO:     Epoch: 74
2022-11-28 06:29:45,310 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47947073118253186, 'Total loss': 0.47947073118253186} | train loss {'Reaction outcome loss': 0.47433293388495523, 'Total loss': 0.47433293388495523}
2022-11-28 06:29:45,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:45,310 INFO:     Epoch: 75
2022-11-28 06:29:45,971 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45815876160155644, 'Total loss': 0.45815876160155644} | train loss {'Reaction outcome loss': 0.4786348139206248, 'Total loss': 0.4786348139206248}
2022-11-28 06:29:45,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:45,971 INFO:     Epoch: 76
2022-11-28 06:29:46,636 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4704906716942787, 'Total loss': 0.4704906716942787} | train loss {'Reaction outcome loss': 0.4719645315480809, 'Total loss': 0.4719645315480809}
2022-11-28 06:29:46,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:46,636 INFO:     Epoch: 77
2022-11-28 06:29:47,301 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47417313808744604, 'Total loss': 0.47417313808744604} | train loss {'Reaction outcome loss': 0.4743177369236946, 'Total loss': 0.4743177369236946}
2022-11-28 06:29:47,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:47,301 INFO:     Epoch: 78
2022-11-28 06:29:47,964 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46192411705851555, 'Total loss': 0.46192411705851555} | train loss {'Reaction outcome loss': 0.479538630153383, 'Total loss': 0.479538630153383}
2022-11-28 06:29:47,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:47,965 INFO:     Epoch: 79
2022-11-28 06:29:48,627 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4994783475995064, 'Total loss': 0.4994783475995064} | train loss {'Reaction outcome loss': 0.4762234763512688, 'Total loss': 0.4762234763512688}
2022-11-28 06:29:48,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:48,628 INFO:     Epoch: 80
2022-11-28 06:29:49,298 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4843755090101199, 'Total loss': 0.4843755090101199} | train loss {'Reaction outcome loss': 0.4780590545025564, 'Total loss': 0.4780590545025564}
2022-11-28 06:29:49,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:49,298 INFO:     Epoch: 81
2022-11-28 06:29:49,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49918312816457316, 'Total loss': 0.49918312816457316} | train loss {'Reaction outcome loss': 0.47308718298952424, 'Total loss': 0.47308718298952424}
2022-11-28 06:29:49,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:49,961 INFO:     Epoch: 82
2022-11-28 06:29:50,629 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4567067680711096, 'Total loss': 0.4567067680711096} | train loss {'Reaction outcome loss': 0.47564428930561387, 'Total loss': 0.47564428930561387}
2022-11-28 06:29:50,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:50,629 INFO:     Epoch: 83
2022-11-28 06:29:51,293 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46561347049745644, 'Total loss': 0.46561347049745644} | train loss {'Reaction outcome loss': 0.4861441140153235, 'Total loss': 0.4861441140153235}
2022-11-28 06:29:51,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:51,294 INFO:     Epoch: 84
2022-11-28 06:29:51,955 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.494559764184735, 'Total loss': 0.494559764184735} | train loss {'Reaction outcome loss': 0.47038671993199854, 'Total loss': 0.47038671993199854}
2022-11-28 06:29:51,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:51,955 INFO:     Epoch: 85
2022-11-28 06:29:52,614 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5013940588317134, 'Total loss': 0.5013940588317134} | train loss {'Reaction outcome loss': 0.47365968283866683, 'Total loss': 0.47365968283866683}
2022-11-28 06:29:52,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:52,614 INFO:     Epoch: 86
2022-11-28 06:29:53,280 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46576383032582025, 'Total loss': 0.46576383032582025} | train loss {'Reaction outcome loss': 0.476587945294957, 'Total loss': 0.476587945294957}
2022-11-28 06:29:53,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:53,280 INFO:     Epoch: 87
2022-11-28 06:29:53,952 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46942208063873375, 'Total loss': 0.46942208063873375} | train loss {'Reaction outcome loss': 0.47138246088739366, 'Total loss': 0.47138246088739366}
2022-11-28 06:29:53,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:53,952 INFO:     Epoch: 88
2022-11-28 06:29:54,625 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4653705937618559, 'Total loss': 0.4653705937618559} | train loss {'Reaction outcome loss': 0.49139431858014676, 'Total loss': 0.49139431858014676}
2022-11-28 06:29:54,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:54,625 INFO:     Epoch: 89
2022-11-28 06:29:55,295 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5081038488583132, 'Total loss': 0.5081038488583132} | train loss {'Reaction outcome loss': 0.47321784021633284, 'Total loss': 0.47321784021633284}
2022-11-28 06:29:55,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:55,295 INFO:     Epoch: 90
2022-11-28 06:29:55,970 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4688489765606143, 'Total loss': 0.4688489765606143} | train loss {'Reaction outcome loss': 0.47946937520417476, 'Total loss': 0.47946937520417476}
2022-11-28 06:29:55,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:55,970 INFO:     Epoch: 91
2022-11-28 06:29:56,641 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.491078585724939, 'Total loss': 0.491078585724939} | train loss {'Reaction outcome loss': 0.482188698294903, 'Total loss': 0.482188698294903}
2022-11-28 06:29:56,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:56,641 INFO:     Epoch: 92
2022-11-28 06:29:57,310 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48114913634278555, 'Total loss': 0.48114913634278555} | train loss {'Reaction outcome loss': 0.4717529861917419, 'Total loss': 0.4717529861917419}
2022-11-28 06:29:57,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:57,311 INFO:     Epoch: 93
2022-11-28 06:29:57,983 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4605910097333518, 'Total loss': 0.4605910097333518} | train loss {'Reaction outcome loss': 0.4764726608991623, 'Total loss': 0.4764726608991623}
2022-11-28 06:29:57,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:57,983 INFO:     Epoch: 94
2022-11-28 06:29:58,649 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48988577181642706, 'Total loss': 0.48988577181642706} | train loss {'Reaction outcome loss': 0.4703061378771259, 'Total loss': 0.4703061378771259}
2022-11-28 06:29:58,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:58,650 INFO:     Epoch: 95
2022-11-28 06:29:59,318 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47190496731888165, 'Total loss': 0.47190496731888165} | train loss {'Reaction outcome loss': 0.4735653589689924, 'Total loss': 0.4735653589689924}
2022-11-28 06:29:59,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:59,319 INFO:     Epoch: 96
2022-11-28 06:29:59,985 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46997590125961736, 'Total loss': 0.46997590125961736} | train loss {'Reaction outcome loss': 0.4758822252793658, 'Total loss': 0.4758822252793658}
2022-11-28 06:29:59,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:29:59,986 INFO:     Epoch: 97
2022-11-28 06:30:00,656 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4669546986168081, 'Total loss': 0.4669546986168081} | train loss {'Reaction outcome loss': 0.4744818316051556, 'Total loss': 0.4744818316051556}
2022-11-28 06:30:00,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:00,658 INFO:     Epoch: 98
2022-11-28 06:30:01,327 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4905314753678712, 'Total loss': 0.4905314753678712} | train loss {'Reaction outcome loss': 0.4776499253367224, 'Total loss': 0.4776499253367224}
2022-11-28 06:30:01,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:01,327 INFO:     Epoch: 99
2022-11-28 06:30:01,998 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4759583513845097, 'Total loss': 0.4759583513845097} | train loss {'Reaction outcome loss': 0.4792360049942809, 'Total loss': 0.4792360049942809}
2022-11-28 06:30:01,998 INFO:     Best model found after epoch 41 of 100.
2022-11-28 06:30:01,998 INFO:   Done with stage: TRAINING
2022-11-28 06:30:01,998 INFO:   Starting stage: EVALUATION
2022-11-28 06:30:02,112 INFO:   Done with stage: EVALUATION
2022-11-28 06:30:02,112 INFO:   Leaving out SEQ value Fold_5
2022-11-28 06:30:02,125 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 06:30:02,125 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:30:02,770 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:30:02,770 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:30:02,840 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:30:02,841 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:30:02,841 INFO:     No hyperparam tuning for this model
2022-11-28 06:30:02,841 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:30:02,841 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:30:02,841 INFO:     None feature selector for col prot
2022-11-28 06:30:02,842 INFO:     None feature selector for col prot
2022-11-28 06:30:02,842 INFO:     None feature selector for col prot
2022-11-28 06:30:02,842 INFO:     None feature selector for col chem
2022-11-28 06:30:02,842 INFO:     None feature selector for col chem
2022-11-28 06:30:02,842 INFO:     None feature selector for col chem
2022-11-28 06:30:02,842 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:30:02,842 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:30:02,844 INFO:     Number of params in model 169651
2022-11-28 06:30:02,847 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:30:02,847 INFO:   Starting stage: TRAINING
2022-11-28 06:30:02,898 INFO:     Val loss before train {'Reaction outcome loss': 1.070439796556126, 'Total loss': 1.070439796556126}
2022-11-28 06:30:02,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:02,899 INFO:     Epoch: 0
2022-11-28 06:30:03,559 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5757121206684546, 'Total loss': 0.5757121206684546} | train loss {'Reaction outcome loss': 0.6854724124986298, 'Total loss': 0.6854724124986298}
2022-11-28 06:30:03,560 INFO:     Found new best model at epoch 0
2022-11-28 06:30:03,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:03,560 INFO:     Epoch: 1
2022-11-28 06:30:04,223 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5840318975123492, 'Total loss': 0.5840318975123492} | train loss {'Reaction outcome loss': 0.5863121486439997, 'Total loss': 0.5863121486439997}
2022-11-28 06:30:04,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:04,223 INFO:     Epoch: 2
2022-11-28 06:30:04,884 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5424789759245786, 'Total loss': 0.5424789759245786} | train loss {'Reaction outcome loss': 0.5430650537719532, 'Total loss': 0.5430650537719532}
2022-11-28 06:30:04,884 INFO:     Found new best model at epoch 2
2022-11-28 06:30:04,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:04,885 INFO:     Epoch: 3
2022-11-28 06:30:05,542 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5558685199780897, 'Total loss': 0.5558685199780897} | train loss {'Reaction outcome loss': 0.5276095218804417, 'Total loss': 0.5276095218804417}
2022-11-28 06:30:05,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:05,543 INFO:     Epoch: 4
2022-11-28 06:30:06,198 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5553640574216843, 'Total loss': 0.5553640574216843} | train loss {'Reaction outcome loss': 0.5137992709875107, 'Total loss': 0.5137992709875107}
2022-11-28 06:30:06,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:06,199 INFO:     Epoch: 5
2022-11-28 06:30:06,857 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5330526185306635, 'Total loss': 0.5330526185306635} | train loss {'Reaction outcome loss': 0.510475851382528, 'Total loss': 0.510475851382528}
2022-11-28 06:30:06,858 INFO:     Found new best model at epoch 5
2022-11-28 06:30:06,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:06,859 INFO:     Epoch: 6
2022-11-28 06:30:07,517 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5190230756998062, 'Total loss': 0.5190230756998062} | train loss {'Reaction outcome loss': 0.4955963393863367, 'Total loss': 0.4955963393863367}
2022-11-28 06:30:07,517 INFO:     Found new best model at epoch 6
2022-11-28 06:30:07,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:07,518 INFO:     Epoch: 7
2022-11-28 06:30:08,179 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5015094645998694, 'Total loss': 0.5015094645998694} | train loss {'Reaction outcome loss': 0.49130095091401316, 'Total loss': 0.49130095091401316}
2022-11-28 06:30:08,179 INFO:     Found new best model at epoch 7
2022-11-28 06:30:08,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:08,180 INFO:     Epoch: 8
2022-11-28 06:30:08,839 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5153770440004088, 'Total loss': 0.5153770440004088} | train loss {'Reaction outcome loss': 0.4947207385179948, 'Total loss': 0.4947207385179948}
2022-11-28 06:30:08,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:08,839 INFO:     Epoch: 9
2022-11-28 06:30:09,501 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5161263915625486, 'Total loss': 0.5161263915625486} | train loss {'Reaction outcome loss': 0.493458723474522, 'Total loss': 0.493458723474522}
2022-11-28 06:30:09,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:09,501 INFO:     Epoch: 10
2022-11-28 06:30:10,159 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.485400221564553, 'Total loss': 0.485400221564553} | train loss {'Reaction outcome loss': 0.4828231324042593, 'Total loss': 0.4828231324042593}
2022-11-28 06:30:10,159 INFO:     Found new best model at epoch 10
2022-11-28 06:30:10,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:10,160 INFO:     Epoch: 11
2022-11-28 06:30:10,821 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5401395886120471, 'Total loss': 0.5401395886120471} | train loss {'Reaction outcome loss': 0.4772394039192978, 'Total loss': 0.4772394039192978}
2022-11-28 06:30:10,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:10,822 INFO:     Epoch: 12
2022-11-28 06:30:11,481 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5128055181015622, 'Total loss': 0.5128055181015622} | train loss {'Reaction outcome loss': 0.4759263578726321, 'Total loss': 0.4759263578726321}
2022-11-28 06:30:11,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:11,481 INFO:     Epoch: 13
2022-11-28 06:30:12,139 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5023710903796282, 'Total loss': 0.5023710903796282} | train loss {'Reaction outcome loss': 0.48579245638482427, 'Total loss': 0.48579245638482427}
2022-11-28 06:30:12,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:12,139 INFO:     Epoch: 14
2022-11-28 06:30:12,801 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5379119234328921, 'Total loss': 0.5379119234328921} | train loss {'Reaction outcome loss': 0.47849817865965316, 'Total loss': 0.47849817865965316}
2022-11-28 06:30:12,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:12,801 INFO:     Epoch: 15
2022-11-28 06:30:13,460 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4845899499275468, 'Total loss': 0.4845899499275468} | train loss {'Reaction outcome loss': 0.4769266021190857, 'Total loss': 0.4769266021190857}
2022-11-28 06:30:13,460 INFO:     Found new best model at epoch 15
2022-11-28 06:30:13,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:13,461 INFO:     Epoch: 16
2022-11-28 06:30:14,120 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49720762873237784, 'Total loss': 0.49720762873237784} | train loss {'Reaction outcome loss': 0.4730366611359071, 'Total loss': 0.4730366611359071}
2022-11-28 06:30:14,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:14,120 INFO:     Epoch: 17
2022-11-28 06:30:14,781 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5036422021009705, 'Total loss': 0.5036422021009705} | train loss {'Reaction outcome loss': 0.4771707348069366, 'Total loss': 0.4771707348069366}
2022-11-28 06:30:14,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:14,782 INFO:     Epoch: 18
2022-11-28 06:30:15,446 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5147105265747417, 'Total loss': 0.5147105265747417} | train loss {'Reaction outcome loss': 0.4786856560682764, 'Total loss': 0.4786856560682764}
2022-11-28 06:30:15,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:15,446 INFO:     Epoch: 19
2022-11-28 06:30:16,106 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4986642430621115, 'Total loss': 0.4986642430621115} | train loss {'Reaction outcome loss': 0.4691751259322069, 'Total loss': 0.4691751259322069}
2022-11-28 06:30:16,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:16,106 INFO:     Epoch: 20
2022-11-28 06:30:16,777 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5002453059635379, 'Total loss': 0.5002453059635379} | train loss {'Reaction outcome loss': 0.46730281473422536, 'Total loss': 0.46730281473422536}
2022-11-28 06:30:16,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:16,778 INFO:     Epoch: 21
2022-11-28 06:30:17,455 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5324509103189815, 'Total loss': 0.5324509103189815} | train loss {'Reaction outcome loss': 0.46980790714828335, 'Total loss': 0.46980790714828335}
2022-11-28 06:30:17,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:17,455 INFO:     Epoch: 22
2022-11-28 06:30:18,131 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.541073950515552, 'Total loss': 0.541073950515552} | train loss {'Reaction outcome loss': 0.47224211808370087, 'Total loss': 0.47224211808370087}
2022-11-28 06:30:18,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:18,132 INFO:     Epoch: 23
2022-11-28 06:30:18,808 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5079865779050372, 'Total loss': 0.5079865779050372} | train loss {'Reaction outcome loss': 0.47160329484209723, 'Total loss': 0.47160329484209723}
2022-11-28 06:30:18,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:18,808 INFO:     Epoch: 24
2022-11-28 06:30:19,484 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5476947125386108, 'Total loss': 0.5476947125386108} | train loss {'Reaction outcome loss': 0.4663750272320241, 'Total loss': 0.4663750272320241}
2022-11-28 06:30:19,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:19,485 INFO:     Epoch: 25
2022-11-28 06:30:20,165 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5027178671549667, 'Total loss': 0.5027178671549667} | train loss {'Reaction outcome loss': 0.4633450763566153, 'Total loss': 0.4633450763566153}
2022-11-28 06:30:20,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:20,165 INFO:     Epoch: 26
2022-11-28 06:30:20,843 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.505329005420208, 'Total loss': 0.505329005420208} | train loss {'Reaction outcome loss': 0.46184380036227557, 'Total loss': 0.46184380036227557}
2022-11-28 06:30:20,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:20,843 INFO:     Epoch: 27
2022-11-28 06:30:21,520 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5412948991764676, 'Total loss': 0.5412948991764676} | train loss {'Reaction outcome loss': 0.4621434000985963, 'Total loss': 0.4621434000985963}
2022-11-28 06:30:21,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:21,520 INFO:     Epoch: 28
2022-11-28 06:30:22,199 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5213608497923071, 'Total loss': 0.5213608497923071} | train loss {'Reaction outcome loss': 0.4661413451238554, 'Total loss': 0.4661413451238554}
2022-11-28 06:30:22,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:22,199 INFO:     Epoch: 29
2022-11-28 06:30:22,877 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5132956200025298, 'Total loss': 0.5132956200025298} | train loss {'Reaction outcome loss': 0.4745874443224498, 'Total loss': 0.4745874443224498}
2022-11-28 06:30:22,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:22,877 INFO:     Epoch: 30
2022-11-28 06:30:23,554 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5141721394929019, 'Total loss': 0.5141721394929019} | train loss {'Reaction outcome loss': 0.46541899539986437, 'Total loss': 0.46541899539986437}
2022-11-28 06:30:23,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:23,554 INFO:     Epoch: 31
2022-11-28 06:30:24,233 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.505886511369185, 'Total loss': 0.505886511369185} | train loss {'Reaction outcome loss': 0.4661365520893311, 'Total loss': 0.4661365520893311}
2022-11-28 06:30:24,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:24,233 INFO:     Epoch: 32
2022-11-28 06:30:24,911 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.516984723508358, 'Total loss': 0.516984723508358} | train loss {'Reaction outcome loss': 0.46095504985780134, 'Total loss': 0.46095504985780134}
2022-11-28 06:30:24,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:24,911 INFO:     Epoch: 33
2022-11-28 06:30:25,588 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4983172897588123, 'Total loss': 0.4983172897588123} | train loss {'Reaction outcome loss': 0.4638940615313394, 'Total loss': 0.4638940615313394}
2022-11-28 06:30:25,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:25,588 INFO:     Epoch: 34
2022-11-28 06:30:26,266 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4875474111600356, 'Total loss': 0.4875474111600356} | train loss {'Reaction outcome loss': 0.4620121196824677, 'Total loss': 0.4620121196824677}
2022-11-28 06:30:26,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:26,266 INFO:     Epoch: 35
2022-11-28 06:30:26,944 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5063132220371203, 'Total loss': 0.5063132220371203} | train loss {'Reaction outcome loss': 0.462214855515227, 'Total loss': 0.462214855515227}
2022-11-28 06:30:26,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:26,944 INFO:     Epoch: 36
2022-11-28 06:30:27,622 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49333687346767296, 'Total loss': 0.49333687346767296} | train loss {'Reaction outcome loss': 0.46296674968028556, 'Total loss': 0.46296674968028556}
2022-11-28 06:30:27,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:27,622 INFO:     Epoch: 37
2022-11-28 06:30:28,300 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47441403195261955, 'Total loss': 0.47441403195261955} | train loss {'Reaction outcome loss': 0.4690545635563987, 'Total loss': 0.4690545635563987}
2022-11-28 06:30:28,300 INFO:     Found new best model at epoch 37
2022-11-28 06:30:28,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:28,301 INFO:     Epoch: 38
2022-11-28 06:30:28,978 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5128964117982171, 'Total loss': 0.5128964117982171} | train loss {'Reaction outcome loss': 0.4630860993448569, 'Total loss': 0.4630860993448569}
2022-11-28 06:30:28,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:28,978 INFO:     Epoch: 39
2022-11-28 06:30:29,658 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49312576482241804, 'Total loss': 0.49312576482241804} | train loss {'Reaction outcome loss': 0.46232011537162626, 'Total loss': 0.46232011537162626}
2022-11-28 06:30:29,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:29,658 INFO:     Epoch: 40
2022-11-28 06:30:30,337 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47866521936587314, 'Total loss': 0.47866521936587314} | train loss {'Reaction outcome loss': 0.4749919670576952, 'Total loss': 0.4749919670576952}
2022-11-28 06:30:30,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:30,337 INFO:     Epoch: 41
2022-11-28 06:30:31,017 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5280984646894715, 'Total loss': 0.5280984646894715} | train loss {'Reaction outcome loss': 0.4586723084960665, 'Total loss': 0.4586723084960665}
2022-11-28 06:30:31,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:31,017 INFO:     Epoch: 42
2022-11-28 06:30:31,695 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5055643191391771, 'Total loss': 0.5055643191391771} | train loss {'Reaction outcome loss': 0.46261538832771537, 'Total loss': 0.46261538832771537}
2022-11-28 06:30:31,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:31,696 INFO:     Epoch: 43
2022-11-28 06:30:32,372 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4777431860566139, 'Total loss': 0.4777431860566139} | train loss {'Reaction outcome loss': 0.4580946558592271, 'Total loss': 0.4580946558592271}
2022-11-28 06:30:32,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:32,372 INFO:     Epoch: 44
2022-11-28 06:30:33,049 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49512381716208026, 'Total loss': 0.49512381716208026} | train loss {'Reaction outcome loss': 0.46183264202305246, 'Total loss': 0.46183264202305246}
2022-11-28 06:30:33,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:33,050 INFO:     Epoch: 45
2022-11-28 06:30:33,727 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47844292714514514, 'Total loss': 0.47844292714514514} | train loss {'Reaction outcome loss': 0.47253965352262767, 'Total loss': 0.47253965352262767}
2022-11-28 06:30:33,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:33,728 INFO:     Epoch: 46
2022-11-28 06:30:34,404 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4762718053534627, 'Total loss': 0.4762718053534627} | train loss {'Reaction outcome loss': 0.46404895837209664, 'Total loss': 0.46404895837209664}
2022-11-28 06:30:34,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:34,405 INFO:     Epoch: 47
2022-11-28 06:30:35,081 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5122082528065551, 'Total loss': 0.5122082528065551} | train loss {'Reaction outcome loss': 0.46610735849458346, 'Total loss': 0.46610735849458346}
2022-11-28 06:30:35,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:35,082 INFO:     Epoch: 48
2022-11-28 06:30:35,761 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.551473701542074, 'Total loss': 0.551473701542074} | train loss {'Reaction outcome loss': 0.46201944716122684, 'Total loss': 0.46201944716122684}
2022-11-28 06:30:35,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:35,761 INFO:     Epoch: 49
2022-11-28 06:30:36,441 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4990438423966142, 'Total loss': 0.4990438423966142} | train loss {'Reaction outcome loss': 0.4670793176305537, 'Total loss': 0.4670793176305537}
2022-11-28 06:30:36,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:36,441 INFO:     Epoch: 50
2022-11-28 06:30:37,117 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4840934310447086, 'Total loss': 0.4840934310447086} | train loss {'Reaction outcome loss': 0.4670766950261836, 'Total loss': 0.4670766950261836}
2022-11-28 06:30:37,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:37,117 INFO:     Epoch: 51
2022-11-28 06:30:37,795 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5148317146707665, 'Total loss': 0.5148317146707665} | train loss {'Reaction outcome loss': 0.4607027227781257, 'Total loss': 0.4607027227781257}
2022-11-28 06:30:37,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:37,796 INFO:     Epoch: 52
2022-11-28 06:30:38,471 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5007586719637568, 'Total loss': 0.5007586719637568} | train loss {'Reaction outcome loss': 0.4690967387690836, 'Total loss': 0.4690967387690836}
2022-11-28 06:30:38,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:38,472 INFO:     Epoch: 53
2022-11-28 06:30:39,148 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5145717219195582, 'Total loss': 0.5145717219195582} | train loss {'Reaction outcome loss': 0.4688267026628767, 'Total loss': 0.4688267026628767}
2022-11-28 06:30:39,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:39,148 INFO:     Epoch: 54
2022-11-28 06:30:39,826 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48228313435207715, 'Total loss': 0.48228313435207715} | train loss {'Reaction outcome loss': 0.4609275465717121, 'Total loss': 0.4609275465717121}
2022-11-28 06:30:39,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:39,826 INFO:     Epoch: 55
2022-11-28 06:30:40,507 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48676202954216435, 'Total loss': 0.48676202954216435} | train loss {'Reaction outcome loss': 0.4584647713875284, 'Total loss': 0.4584647713875284}
2022-11-28 06:30:40,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:40,508 INFO:     Epoch: 56
2022-11-28 06:30:41,186 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4890939749099992, 'Total loss': 0.4890939749099992} | train loss {'Reaction outcome loss': 0.45713051399406124, 'Total loss': 0.45713051399406124}
2022-11-28 06:30:41,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:41,186 INFO:     Epoch: 57
2022-11-28 06:30:41,865 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48049307987093925, 'Total loss': 0.48049307987093925} | train loss {'Reaction outcome loss': 0.4638918800925722, 'Total loss': 0.4638918800925722}
2022-11-28 06:30:41,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:41,865 INFO:     Epoch: 58
2022-11-28 06:30:42,543 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5121394663371823, 'Total loss': 0.5121394663371823} | train loss {'Reaction outcome loss': 0.45751561127146895, 'Total loss': 0.45751561127146895}
2022-11-28 06:30:42,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:42,543 INFO:     Epoch: 59
2022-11-28 06:30:43,223 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48285925489935005, 'Total loss': 0.48285925489935005} | train loss {'Reaction outcome loss': 0.4599934712964661, 'Total loss': 0.4599934712964661}
2022-11-28 06:30:43,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:43,223 INFO:     Epoch: 60
2022-11-28 06:30:43,902 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47812856936996634, 'Total loss': 0.47812856936996634} | train loss {'Reaction outcome loss': 0.4522470173178887, 'Total loss': 0.4522470173178887}
2022-11-28 06:30:43,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:43,902 INFO:     Epoch: 61
2022-11-28 06:30:44,580 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5144546831196005, 'Total loss': 0.5144546831196005} | train loss {'Reaction outcome loss': 0.46646465945000554, 'Total loss': 0.46646465945000554}
2022-11-28 06:30:44,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:44,581 INFO:     Epoch: 62
2022-11-28 06:30:45,257 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5277121209285476, 'Total loss': 0.5277121209285476} | train loss {'Reaction outcome loss': 0.4641674845802541, 'Total loss': 0.4641674845802541}
2022-11-28 06:30:45,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:45,258 INFO:     Epoch: 63
2022-11-28 06:30:45,935 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47195674749937927, 'Total loss': 0.47195674749937927} | train loss {'Reaction outcome loss': 0.45868766046300224, 'Total loss': 0.45868766046300224}
2022-11-28 06:30:45,935 INFO:     Found new best model at epoch 63
2022-11-28 06:30:45,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:45,936 INFO:     Epoch: 64
2022-11-28 06:30:46,616 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4773339886556972, 'Total loss': 0.4773339886556972} | train loss {'Reaction outcome loss': 0.4593578779575776, 'Total loss': 0.4593578779575776}
2022-11-28 06:30:46,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:46,616 INFO:     Epoch: 65
2022-11-28 06:30:47,292 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5037149482152679, 'Total loss': 0.5037149482152679} | train loss {'Reaction outcome loss': 0.4528824474130358, 'Total loss': 0.4528824474130358}
2022-11-28 06:30:47,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:47,293 INFO:     Epoch: 66
2022-11-28 06:30:47,975 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5102159296247092, 'Total loss': 0.5102159296247092} | train loss {'Reaction outcome loss': 0.4579794549212164, 'Total loss': 0.4579794549212164}
2022-11-28 06:30:47,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:47,976 INFO:     Epoch: 67
2022-11-28 06:30:48,655 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4981337883933024, 'Total loss': 0.4981337883933024} | train loss {'Reaction outcome loss': 0.46658873126214867, 'Total loss': 0.46658873126214867}
2022-11-28 06:30:48,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:48,656 INFO:     Epoch: 68
2022-11-28 06:30:49,334 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48579674485054886, 'Total loss': 0.48579674485054886} | train loss {'Reaction outcome loss': 0.45671829316689044, 'Total loss': 0.45671829316689044}
2022-11-28 06:30:49,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:49,334 INFO:     Epoch: 69
2022-11-28 06:30:50,016 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48053866607899015, 'Total loss': 0.48053866607899015} | train loss {'Reaction outcome loss': 0.4552473892970961, 'Total loss': 0.4552473892970961}
2022-11-28 06:30:50,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:50,017 INFO:     Epoch: 70
2022-11-28 06:30:50,697 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5350312251936306, 'Total loss': 0.5350312251936306} | train loss {'Reaction outcome loss': 0.45679769935656567, 'Total loss': 0.45679769935656567}
2022-11-28 06:30:50,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:50,697 INFO:     Epoch: 71
2022-11-28 06:30:51,375 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48671982234174554, 'Total loss': 0.48671982234174554} | train loss {'Reaction outcome loss': 0.4555218185697283, 'Total loss': 0.4555218185697283}
2022-11-28 06:30:51,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:51,376 INFO:     Epoch: 72
2022-11-28 06:30:52,053 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4761157360943881, 'Total loss': 0.4761157360943881} | train loss {'Reaction outcome loss': 0.45813792092459543, 'Total loss': 0.45813792092459543}
2022-11-28 06:30:52,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:52,053 INFO:     Epoch: 73
2022-11-28 06:30:52,731 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4877588843757456, 'Total loss': 0.4877588843757456} | train loss {'Reaction outcome loss': 0.465769541871791, 'Total loss': 0.465769541871791}
2022-11-28 06:30:52,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:52,731 INFO:     Epoch: 74
2022-11-28 06:30:53,407 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4893301356245171, 'Total loss': 0.4893301356245171} | train loss {'Reaction outcome loss': 0.45266046913302677, 'Total loss': 0.45266046913302677}
2022-11-28 06:30:53,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:53,408 INFO:     Epoch: 75
2022-11-28 06:30:54,085 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49812120266936044, 'Total loss': 0.49812120266936044} | train loss {'Reaction outcome loss': 0.45537679998242125, 'Total loss': 0.45537679998242125}
2022-11-28 06:30:54,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:54,085 INFO:     Epoch: 76
2022-11-28 06:30:54,763 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4898023706945506, 'Total loss': 0.4898023706945506} | train loss {'Reaction outcome loss': 0.4504213497954972, 'Total loss': 0.4504213497954972}
2022-11-28 06:30:54,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:54,763 INFO:     Epoch: 77
2022-11-28 06:30:55,441 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4965921173041517, 'Total loss': 0.4965921173041517} | train loss {'Reaction outcome loss': 0.4524648044486435, 'Total loss': 0.4524648044486435}
2022-11-28 06:30:55,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:55,441 INFO:     Epoch: 78
2022-11-28 06:30:56,121 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48471732606942003, 'Total loss': 0.48471732606942003} | train loss {'Reaction outcome loss': 0.45189465697930786, 'Total loss': 0.45189465697930786}
2022-11-28 06:30:56,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:56,122 INFO:     Epoch: 79
2022-11-28 06:30:56,800 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48324462602084334, 'Total loss': 0.48324462602084334} | train loss {'Reaction outcome loss': 0.4570741706812868, 'Total loss': 0.4570741706812868}
2022-11-28 06:30:56,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:56,801 INFO:     Epoch: 80
2022-11-28 06:30:57,479 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5201071216301485, 'Total loss': 0.5201071216301485} | train loss {'Reaction outcome loss': 0.4582320454169293, 'Total loss': 0.4582320454169293}
2022-11-28 06:30:57,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:57,479 INFO:     Epoch: 81
2022-11-28 06:30:58,155 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4736724079332568, 'Total loss': 0.4736724079332568} | train loss {'Reaction outcome loss': 0.4615605078181442, 'Total loss': 0.4615605078181442}
2022-11-28 06:30:58,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:58,155 INFO:     Epoch: 82
2022-11-28 06:30:58,833 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49495709348808636, 'Total loss': 0.49495709348808636} | train loss {'Reaction outcome loss': 0.45613870572070686, 'Total loss': 0.45613870572070686}
2022-11-28 06:30:58,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:58,833 INFO:     Epoch: 83
2022-11-28 06:30:59,510 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48582798208702693, 'Total loss': 0.48582798208702693} | train loss {'Reaction outcome loss': 0.4541810641483385, 'Total loss': 0.4541810641483385}
2022-11-28 06:30:59,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:30:59,510 INFO:     Epoch: 84
2022-11-28 06:31:00,186 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5015092739327387, 'Total loss': 0.5015092739327387} | train loss {'Reaction outcome loss': 0.46014569672394773, 'Total loss': 0.46014569672394773}
2022-11-28 06:31:00,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:00,187 INFO:     Epoch: 85
2022-11-28 06:31:00,867 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.478758642449975, 'Total loss': 0.478758642449975} | train loss {'Reaction outcome loss': 0.45141963557321196, 'Total loss': 0.45141963557321196}
2022-11-28 06:31:00,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:00,867 INFO:     Epoch: 86
2022-11-28 06:31:01,548 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49764449725096876, 'Total loss': 0.49764449725096876} | train loss {'Reaction outcome loss': 0.45068047441998305, 'Total loss': 0.45068047441998305}
2022-11-28 06:31:01,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:01,548 INFO:     Epoch: 87
2022-11-28 06:31:02,224 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.539167451926253, 'Total loss': 0.539167451926253} | train loss {'Reaction outcome loss': 0.4591994761204233, 'Total loss': 0.4591994761204233}
2022-11-28 06:31:02,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:02,225 INFO:     Epoch: 88
2022-11-28 06:31:02,903 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5149570967663418, 'Total loss': 0.5149570967663418} | train loss {'Reaction outcome loss': 0.45521372641835894, 'Total loss': 0.45521372641835894}
2022-11-28 06:31:02,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:02,903 INFO:     Epoch: 89
2022-11-28 06:31:03,582 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5125484761189331, 'Total loss': 0.5125484761189331} | train loss {'Reaction outcome loss': 0.45435459096820985, 'Total loss': 0.45435459096820985}
2022-11-28 06:31:03,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:03,582 INFO:     Epoch: 90
2022-11-28 06:31:04,257 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4930707283995368, 'Total loss': 0.4930707283995368} | train loss {'Reaction outcome loss': 0.4609670134831448, 'Total loss': 0.4609670134831448}
2022-11-28 06:31:04,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:04,257 INFO:     Epoch: 91
2022-11-28 06:31:04,936 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5136446492238478, 'Total loss': 0.5136446492238478} | train loss {'Reaction outcome loss': 0.4527784520266007, 'Total loss': 0.4527784520266007}
2022-11-28 06:31:04,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:04,936 INFO:     Epoch: 92
2022-11-28 06:31:05,615 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5048771012913097, 'Total loss': 0.5048771012913097} | train loss {'Reaction outcome loss': 0.4555808804473098, 'Total loss': 0.4555808804473098}
2022-11-28 06:31:05,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:05,615 INFO:     Epoch: 93
2022-11-28 06:31:06,294 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5366109885614027, 'Total loss': 0.5366109885614027} | train loss {'Reaction outcome loss': 0.4605492826019015, 'Total loss': 0.4605492826019015}
2022-11-28 06:31:06,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:06,294 INFO:     Epoch: 94
2022-11-28 06:31:06,973 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49874805320392956, 'Total loss': 0.49874805320392956} | train loss {'Reaction outcome loss': 0.45664667116135965, 'Total loss': 0.45664667116135965}
2022-11-28 06:31:06,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:06,974 INFO:     Epoch: 95
2022-11-28 06:31:07,651 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48270029574632645, 'Total loss': 0.48270029574632645} | train loss {'Reaction outcome loss': 0.45456687771544163, 'Total loss': 0.45456687771544163}
2022-11-28 06:31:07,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:07,651 INFO:     Epoch: 96
2022-11-28 06:31:08,327 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4846680144017393, 'Total loss': 0.4846680144017393} | train loss {'Reaction outcome loss': 0.454748173514191, 'Total loss': 0.454748173514191}
2022-11-28 06:31:08,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:08,328 INFO:     Epoch: 97
2022-11-28 06:31:09,008 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4919852086088874, 'Total loss': 0.4919852086088874} | train loss {'Reaction outcome loss': 0.4541025450339123, 'Total loss': 0.4541025450339123}
2022-11-28 06:31:09,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:09,009 INFO:     Epoch: 98
2022-11-28 06:31:09,690 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4959870644591071, 'Total loss': 0.4959870644591071} | train loss {'Reaction outcome loss': 0.4562016042519589, 'Total loss': 0.4562016042519589}
2022-11-28 06:31:09,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:09,690 INFO:     Epoch: 99
2022-11-28 06:31:10,368 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5215278504924341, 'Total loss': 0.5215278504924341} | train loss {'Reaction outcome loss': 0.45298643191250004, 'Total loss': 0.45298643191250004}
2022-11-28 06:31:10,368 INFO:     Best model found after epoch 64 of 100.
2022-11-28 06:31:10,368 INFO:   Done with stage: TRAINING
2022-11-28 06:31:10,368 INFO:   Starting stage: EVALUATION
2022-11-28 06:31:10,492 INFO:   Done with stage: EVALUATION
2022-11-28 06:31:10,492 INFO:   Leaving out SEQ value Fold_6
2022-11-28 06:31:10,505 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:31:10,505 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:31:11,160 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:31:11,160 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:31:11,231 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:31:11,231 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:31:11,231 INFO:     No hyperparam tuning for this model
2022-11-28 06:31:11,231 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:31:11,231 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:31:11,232 INFO:     None feature selector for col prot
2022-11-28 06:31:11,232 INFO:     None feature selector for col prot
2022-11-28 06:31:11,232 INFO:     None feature selector for col prot
2022-11-28 06:31:11,233 INFO:     None feature selector for col chem
2022-11-28 06:31:11,233 INFO:     None feature selector for col chem
2022-11-28 06:31:11,233 INFO:     None feature selector for col chem
2022-11-28 06:31:11,233 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:31:11,233 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:31:11,234 INFO:     Number of params in model 169651
2022-11-28 06:31:11,238 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:31:11,238 INFO:   Starting stage: TRAINING
2022-11-28 06:31:11,290 INFO:     Val loss before train {'Reaction outcome loss': 0.9941208403218876, 'Total loss': 0.9941208403218876}
2022-11-28 06:31:11,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:11,290 INFO:     Epoch: 0
2022-11-28 06:31:11,978 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.575582757930864, 'Total loss': 0.575582757930864} | train loss {'Reaction outcome loss': 0.6925478932117263, 'Total loss': 0.6925478932117263}
2022-11-28 06:31:11,978 INFO:     Found new best model at epoch 0
2022-11-28 06:31:11,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:11,979 INFO:     Epoch: 1
2022-11-28 06:31:12,664 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5984011753038927, 'Total loss': 0.5984011753038927} | train loss {'Reaction outcome loss': 0.5957220583072593, 'Total loss': 0.5957220583072593}
2022-11-28 06:31:12,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:12,664 INFO:     Epoch: 2
2022-11-28 06:31:13,346 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5962551581588659, 'Total loss': 0.5962551581588659} | train loss {'Reaction outcome loss': 0.5641603369506136, 'Total loss': 0.5641603369506136}
2022-11-28 06:31:13,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:13,346 INFO:     Epoch: 3
2022-11-28 06:31:14,029 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.585960866375403, 'Total loss': 0.585960866375403} | train loss {'Reaction outcome loss': 0.5492087472230196, 'Total loss': 0.5492087472230196}
2022-11-28 06:31:14,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:14,030 INFO:     Epoch: 4
2022-11-28 06:31:14,715 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.502425800670277, 'Total loss': 0.502425800670277} | train loss {'Reaction outcome loss': 0.5394195524915573, 'Total loss': 0.5394195524915573}
2022-11-28 06:31:14,715 INFO:     Found new best model at epoch 4
2022-11-28 06:31:14,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:14,716 INFO:     Epoch: 5
2022-11-28 06:31:15,405 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49342892454429105, 'Total loss': 0.49342892454429105} | train loss {'Reaction outcome loss': 0.5253916087470227, 'Total loss': 0.5253916087470227}
2022-11-28 06:31:15,406 INFO:     Found new best model at epoch 5
2022-11-28 06:31:15,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:15,406 INFO:     Epoch: 6
2022-11-28 06:31:16,101 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5126656530932947, 'Total loss': 0.5126656530932947} | train loss {'Reaction outcome loss': 0.5016562380497495, 'Total loss': 0.5016562380497495}
2022-11-28 06:31:16,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:16,101 INFO:     Epoch: 7
2022-11-28 06:31:16,791 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48834845288233325, 'Total loss': 0.48834845288233325} | train loss {'Reaction outcome loss': 0.5044965481445673, 'Total loss': 0.5044965481445673}
2022-11-28 06:31:16,791 INFO:     Found new best model at epoch 7
2022-11-28 06:31:16,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:16,792 INFO:     Epoch: 8
2022-11-28 06:31:17,478 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5079657123847441, 'Total loss': 0.5079657123847441} | train loss {'Reaction outcome loss': 0.4943722576623963, 'Total loss': 0.4943722576623963}
2022-11-28 06:31:17,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:17,478 INFO:     Epoch: 9
2022-11-28 06:31:18,161 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49281812188300217, 'Total loss': 0.49281812188300217} | train loss {'Reaction outcome loss': 0.48932081034346936, 'Total loss': 0.48932081034346936}
2022-11-28 06:31:18,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:18,161 INFO:     Epoch: 10
2022-11-28 06:31:18,849 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5342002836140719, 'Total loss': 0.5342002836140719} | train loss {'Reaction outcome loss': 0.49303928801729796, 'Total loss': 0.49303928801729796}
2022-11-28 06:31:18,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:18,849 INFO:     Epoch: 11
2022-11-28 06:31:19,533 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48743916573849594, 'Total loss': 0.48743916573849594} | train loss {'Reaction outcome loss': 0.48706686935357507, 'Total loss': 0.48706686935357507}
2022-11-28 06:31:19,533 INFO:     Found new best model at epoch 11
2022-11-28 06:31:19,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:19,534 INFO:     Epoch: 12
2022-11-28 06:31:20,220 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47018213299187744, 'Total loss': 0.47018213299187744} | train loss {'Reaction outcome loss': 0.48671685844179124, 'Total loss': 0.48671685844179124}
2022-11-28 06:31:20,220 INFO:     Found new best model at epoch 12
2022-11-28 06:31:20,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:20,221 INFO:     Epoch: 13
2022-11-28 06:31:20,906 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45164590599862015, 'Total loss': 0.45164590599862015} | train loss {'Reaction outcome loss': 0.48410852589914877, 'Total loss': 0.48410852589914877}
2022-11-28 06:31:20,906 INFO:     Found new best model at epoch 13
2022-11-28 06:31:20,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:20,907 INFO:     Epoch: 14
2022-11-28 06:31:21,593 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4886350477622314, 'Total loss': 0.4886350477622314} | train loss {'Reaction outcome loss': 0.48290919109938607, 'Total loss': 0.48290919109938607}
2022-11-28 06:31:21,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:21,593 INFO:     Epoch: 15
2022-11-28 06:31:22,280 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46815475008704444, 'Total loss': 0.46815475008704444} | train loss {'Reaction outcome loss': 0.4784071396195119, 'Total loss': 0.4784071396195119}
2022-11-28 06:31:22,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:22,280 INFO:     Epoch: 16
2022-11-28 06:31:22,966 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46253371374173596, 'Total loss': 0.46253371374173596} | train loss {'Reaction outcome loss': 0.47487996236210867, 'Total loss': 0.47487996236210867}
2022-11-28 06:31:22,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:22,967 INFO:     Epoch: 17
2022-11-28 06:31:23,652 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.481913358989087, 'Total loss': 0.481913358989087} | train loss {'Reaction outcome loss': 0.474683630610666, 'Total loss': 0.474683630610666}
2022-11-28 06:31:23,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:23,653 INFO:     Epoch: 18
2022-11-28 06:31:24,338 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4684035073627125, 'Total loss': 0.4684035073627125} | train loss {'Reaction outcome loss': 0.48475932335901645, 'Total loss': 0.48475932335901645}
2022-11-28 06:31:24,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:24,338 INFO:     Epoch: 19
2022-11-28 06:31:25,028 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.478593360632658, 'Total loss': 0.478593360632658} | train loss {'Reaction outcome loss': 0.4773935689440658, 'Total loss': 0.4773935689440658}
2022-11-28 06:31:25,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:25,028 INFO:     Epoch: 20
2022-11-28 06:31:25,714 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5106525583700701, 'Total loss': 0.5106525583700701} | train loss {'Reaction outcome loss': 0.48025517979817045, 'Total loss': 0.48025517979817045}
2022-11-28 06:31:25,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:25,715 INFO:     Epoch: 21
2022-11-28 06:31:26,400 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49563590301708743, 'Total loss': 0.49563590301708743} | train loss {'Reaction outcome loss': 0.4761432447440682, 'Total loss': 0.4761432447440682}
2022-11-28 06:31:26,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:26,400 INFO:     Epoch: 22
2022-11-28 06:31:27,086 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5440299599008127, 'Total loss': 0.5440299599008127} | train loss {'Reaction outcome loss': 0.47499083261936903, 'Total loss': 0.47499083261936903}
2022-11-28 06:31:27,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:27,086 INFO:     Epoch: 23
2022-11-28 06:31:27,772 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.490882796658711, 'Total loss': 0.490882796658711} | train loss {'Reaction outcome loss': 0.47877786729124283, 'Total loss': 0.47877786729124283}
2022-11-28 06:31:27,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:27,772 INFO:     Epoch: 24
2022-11-28 06:31:28,458 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4781941785053773, 'Total loss': 0.4781941785053773} | train loss {'Reaction outcome loss': 0.4727312452610462, 'Total loss': 0.4727312452610462}
2022-11-28 06:31:28,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:28,458 INFO:     Epoch: 25
2022-11-28 06:31:29,144 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4807753305543553, 'Total loss': 0.4807753305543553} | train loss {'Reaction outcome loss': 0.47066794738413825, 'Total loss': 0.47066794738413825}
2022-11-28 06:31:29,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:29,144 INFO:     Epoch: 26
2022-11-28 06:31:29,830 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46800830215215683, 'Total loss': 0.46800830215215683} | train loss {'Reaction outcome loss': 0.4749846099124801, 'Total loss': 0.4749846099124801}
2022-11-28 06:31:29,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:29,830 INFO:     Epoch: 27
2022-11-28 06:31:30,518 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45995478332042694, 'Total loss': 0.45995478332042694} | train loss {'Reaction outcome loss': 0.4769507410425332, 'Total loss': 0.4769507410425332}
2022-11-28 06:31:30,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:30,519 INFO:     Epoch: 28
2022-11-28 06:31:31,205 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44221716848286713, 'Total loss': 0.44221716848286713} | train loss {'Reaction outcome loss': 0.47037279497711887, 'Total loss': 0.47037279497711887}
2022-11-28 06:31:31,205 INFO:     Found new best model at epoch 28
2022-11-28 06:31:31,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:31,206 INFO:     Epoch: 29
2022-11-28 06:31:31,893 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45136145095933566, 'Total loss': 0.45136145095933566} | train loss {'Reaction outcome loss': 0.47451957807906214, 'Total loss': 0.47451957807906214}
2022-11-28 06:31:31,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:31,893 INFO:     Epoch: 30
2022-11-28 06:31:32,577 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4675552706149491, 'Total loss': 0.4675552706149491} | train loss {'Reaction outcome loss': 0.4662081486275119, 'Total loss': 0.4662081486275119}
2022-11-28 06:31:32,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:32,577 INFO:     Epoch: 31
2022-11-28 06:31:33,263 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47359025038101454, 'Total loss': 0.47359025038101454} | train loss {'Reaction outcome loss': 0.4759894328251962, 'Total loss': 0.4759894328251962}
2022-11-28 06:31:33,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:33,263 INFO:     Epoch: 32
2022-11-28 06:31:33,949 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4635851958935911, 'Total loss': 0.4635851958935911} | train loss {'Reaction outcome loss': 0.4680697524379338, 'Total loss': 0.4680697524379338}
2022-11-28 06:31:33,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:33,950 INFO:     Epoch: 33
2022-11-28 06:31:34,638 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45365192504091695, 'Total loss': 0.45365192504091695} | train loss {'Reaction outcome loss': 0.4694075914880922, 'Total loss': 0.4694075914880922}
2022-11-28 06:31:34,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:34,638 INFO:     Epoch: 34
2022-11-28 06:31:35,322 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4571313803846186, 'Total loss': 0.4571313803846186} | train loss {'Reaction outcome loss': 0.46952492521414835, 'Total loss': 0.46952492521414835}
2022-11-28 06:31:35,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:35,323 INFO:     Epoch: 35
2022-11-28 06:31:36,008 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4997827803546732, 'Total loss': 0.4997827803546732} | train loss {'Reaction outcome loss': 0.47346724659925504, 'Total loss': 0.47346724659925504}
2022-11-28 06:31:36,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:36,008 INFO:     Epoch: 36
2022-11-28 06:31:36,694 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4756208604032343, 'Total loss': 0.4756208604032343} | train loss {'Reaction outcome loss': 0.47665735183944624, 'Total loss': 0.47665735183944624}
2022-11-28 06:31:36,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:36,695 INFO:     Epoch: 37
2022-11-28 06:31:37,383 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47152118520303204, 'Total loss': 0.47152118520303204} | train loss {'Reaction outcome loss': 0.475810649354131, 'Total loss': 0.475810649354131}
2022-11-28 06:31:37,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:37,383 INFO:     Epoch: 38
2022-11-28 06:31:38,073 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49042442644184286, 'Total loss': 0.49042442644184286} | train loss {'Reaction outcome loss': 0.47258718173590397, 'Total loss': 0.47258718173590397}
2022-11-28 06:31:38,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:38,073 INFO:     Epoch: 39
2022-11-28 06:31:38,764 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4536758376793428, 'Total loss': 0.4536758376793428} | train loss {'Reaction outcome loss': 0.4786978422273551, 'Total loss': 0.4786978422273551}
2022-11-28 06:31:38,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:38,764 INFO:     Epoch: 40
2022-11-28 06:31:39,449 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4494662682779811, 'Total loss': 0.4494662682779811} | train loss {'Reaction outcome loss': 0.47201196185403294, 'Total loss': 0.47201196185403294}
2022-11-28 06:31:39,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:39,449 INFO:     Epoch: 41
2022-11-28 06:31:40,136 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45091378553347156, 'Total loss': 0.45091378553347156} | train loss {'Reaction outcome loss': 0.4769563309007114, 'Total loss': 0.4769563309007114}
2022-11-28 06:31:40,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:40,136 INFO:     Epoch: 42
2022-11-28 06:31:40,827 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47079916162924335, 'Total loss': 0.47079916162924335} | train loss {'Reaction outcome loss': 0.4635406369042973, 'Total loss': 0.4635406369042973}
2022-11-28 06:31:40,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:40,827 INFO:     Epoch: 43
2022-11-28 06:31:41,515 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4744235947728157, 'Total loss': 0.4744235947728157} | train loss {'Reaction outcome loss': 0.4713737490556894, 'Total loss': 0.4713737490556894}
2022-11-28 06:31:41,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:41,515 INFO:     Epoch: 44
2022-11-28 06:31:42,205 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44610219821333885, 'Total loss': 0.44610219821333885} | train loss {'Reaction outcome loss': 0.4703518077130279, 'Total loss': 0.4703518077130279}
2022-11-28 06:31:42,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:42,205 INFO:     Epoch: 45
2022-11-28 06:31:42,897 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4608007598329674, 'Total loss': 0.4608007598329674} | train loss {'Reaction outcome loss': 0.4714442618912266, 'Total loss': 0.4714442618912266}
2022-11-28 06:31:42,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:42,897 INFO:     Epoch: 46
2022-11-28 06:31:43,583 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45304824513467873, 'Total loss': 0.45304824513467873} | train loss {'Reaction outcome loss': 0.4611927814661495, 'Total loss': 0.4611927814661495}
2022-11-28 06:31:43,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:43,583 INFO:     Epoch: 47
2022-11-28 06:31:44,276 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4493007527833635, 'Total loss': 0.4493007527833635} | train loss {'Reaction outcome loss': 0.46791693087547054, 'Total loss': 0.46791693087547054}
2022-11-28 06:31:44,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:44,276 INFO:     Epoch: 48
2022-11-28 06:31:44,964 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4604241272265261, 'Total loss': 0.4604241272265261} | train loss {'Reaction outcome loss': 0.46608437465563896, 'Total loss': 0.46608437465563896}
2022-11-28 06:31:44,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:44,965 INFO:     Epoch: 49
2022-11-28 06:31:45,653 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4623746082864024, 'Total loss': 0.4623746082864024} | train loss {'Reaction outcome loss': 0.46862020505772484, 'Total loss': 0.46862020505772484}
2022-11-28 06:31:45,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:45,653 INFO:     Epoch: 50
2022-11-28 06:31:46,340 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45860643921927974, 'Total loss': 0.45860643921927974} | train loss {'Reaction outcome loss': 0.47080902472859426, 'Total loss': 0.47080902472859426}
2022-11-28 06:31:46,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:46,340 INFO:     Epoch: 51
2022-11-28 06:31:47,034 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45599718764424324, 'Total loss': 0.45599718764424324} | train loss {'Reaction outcome loss': 0.46666811902316346, 'Total loss': 0.46666811902316346}
2022-11-28 06:31:47,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:47,034 INFO:     Epoch: 52
2022-11-28 06:31:47,723 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4479737447744066, 'Total loss': 0.4479737447744066} | train loss {'Reaction outcome loss': 0.46672400501706907, 'Total loss': 0.46672400501706907}
2022-11-28 06:31:47,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:47,723 INFO:     Epoch: 53
2022-11-28 06:31:48,413 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44550496204332873, 'Total loss': 0.44550496204332873} | train loss {'Reaction outcome loss': 0.46210185910064366, 'Total loss': 0.46210185910064366}
2022-11-28 06:31:48,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:48,413 INFO:     Epoch: 54
2022-11-28 06:31:49,106 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4926911084489389, 'Total loss': 0.4926911084489389} | train loss {'Reaction outcome loss': 0.4680877466115259, 'Total loss': 0.4680877466115259}
2022-11-28 06:31:49,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:49,106 INFO:     Epoch: 55
2022-11-28 06:31:49,795 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49490774084221234, 'Total loss': 0.49490774084221234} | train loss {'Reaction outcome loss': 0.4690536928152846, 'Total loss': 0.4690536928152846}
2022-11-28 06:31:49,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:49,795 INFO:     Epoch: 56
2022-11-28 06:31:50,485 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47671211849559436, 'Total loss': 0.47671211849559436} | train loss {'Reaction outcome loss': 0.46774330296583716, 'Total loss': 0.46774330296583716}
2022-11-28 06:31:50,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:50,485 INFO:     Epoch: 57
2022-11-28 06:31:51,175 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48761744594032114, 'Total loss': 0.48761744594032114} | train loss {'Reaction outcome loss': 0.4713698120847825, 'Total loss': 0.4713698120847825}
2022-11-28 06:31:51,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:51,176 INFO:     Epoch: 58
2022-11-28 06:31:51,865 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5014000511304899, 'Total loss': 0.5014000511304899} | train loss {'Reaction outcome loss': 0.4692269051147084, 'Total loss': 0.4692269051147084}
2022-11-28 06:31:51,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:51,865 INFO:     Epoch: 59
2022-11-28 06:31:52,554 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49043601378798485, 'Total loss': 0.49043601378798485} | train loss {'Reaction outcome loss': 0.4659539085602568, 'Total loss': 0.4659539085602568}
2022-11-28 06:31:52,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:52,555 INFO:     Epoch: 60
2022-11-28 06:31:53,242 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46320991522886534, 'Total loss': 0.46320991522886534} | train loss {'Reaction outcome loss': 0.4699113850872363, 'Total loss': 0.4699113850872363}
2022-11-28 06:31:53,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:53,242 INFO:     Epoch: 61
2022-11-28 06:31:53,928 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45971283689141273, 'Total loss': 0.45971283689141273} | train loss {'Reaction outcome loss': 0.4739010143544405, 'Total loss': 0.4739010143544405}
2022-11-28 06:31:53,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:53,928 INFO:     Epoch: 62
2022-11-28 06:31:54,616 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4711556702174924, 'Total loss': 0.4711556702174924} | train loss {'Reaction outcome loss': 0.46615101739523873, 'Total loss': 0.46615101739523873}
2022-11-28 06:31:54,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:54,616 INFO:     Epoch: 63
2022-11-28 06:31:55,304 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4478760517456315, 'Total loss': 0.4478760517456315} | train loss {'Reaction outcome loss': 0.4689358631449361, 'Total loss': 0.4689358631449361}
2022-11-28 06:31:55,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:55,304 INFO:     Epoch: 64
2022-11-28 06:31:55,992 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4446693144061349, 'Total loss': 0.4446693144061349} | train loss {'Reaction outcome loss': 0.4666883396285196, 'Total loss': 0.4666883396285196}
2022-11-28 06:31:55,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:55,992 INFO:     Epoch: 65
2022-11-28 06:31:56,684 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.483157486400821, 'Total loss': 0.483157486400821} | train loss {'Reaction outcome loss': 0.4760847209442046, 'Total loss': 0.4760847209442046}
2022-11-28 06:31:56,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:56,684 INFO:     Epoch: 66
2022-11-28 06:31:57,373 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4912253597920591, 'Total loss': 0.4912253597920591} | train loss {'Reaction outcome loss': 0.4675601868619842, 'Total loss': 0.4675601868619842}
2022-11-28 06:31:57,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:57,374 INFO:     Epoch: 67
2022-11-28 06:31:58,062 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4549303644082763, 'Total loss': 0.4549303644082763} | train loss {'Reaction outcome loss': 0.47642242487880493, 'Total loss': 0.47642242487880493}
2022-11-28 06:31:58,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:58,062 INFO:     Epoch: 68
2022-11-28 06:31:58,749 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46121806414289906, 'Total loss': 0.46121806414289906} | train loss {'Reaction outcome loss': 0.4703448571324829, 'Total loss': 0.4703448571324829}
2022-11-28 06:31:58,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:58,749 INFO:     Epoch: 69
2022-11-28 06:31:59,440 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46338026428764517, 'Total loss': 0.46338026428764517} | train loss {'Reaction outcome loss': 0.4664782121657364, 'Total loss': 0.4664782121657364}
2022-11-28 06:31:59,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:31:59,441 INFO:     Epoch: 70
2022-11-28 06:32:00,130 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5012254041026939, 'Total loss': 0.5012254041026939} | train loss {'Reaction outcome loss': 0.4688874867053763, 'Total loss': 0.4688874867053763}
2022-11-28 06:32:00,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:00,130 INFO:     Epoch: 71
2022-11-28 06:32:00,821 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4515889883041382, 'Total loss': 0.4515889883041382} | train loss {'Reaction outcome loss': 0.4686396304037302, 'Total loss': 0.4686396304037302}
2022-11-28 06:32:00,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:00,821 INFO:     Epoch: 72
2022-11-28 06:32:01,510 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45140082050453534, 'Total loss': 0.45140082050453534} | train loss {'Reaction outcome loss': 0.4727921771306184, 'Total loss': 0.4727921771306184}
2022-11-28 06:32:01,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:01,510 INFO:     Epoch: 73
2022-11-28 06:32:02,198 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44968207756226714, 'Total loss': 0.44968207756226714} | train loss {'Reaction outcome loss': 0.46686829836858856, 'Total loss': 0.46686829836858856}
2022-11-28 06:32:02,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:02,198 INFO:     Epoch: 74
2022-11-28 06:32:02,885 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49364499341357837, 'Total loss': 0.49364499341357837} | train loss {'Reaction outcome loss': 0.4638496750304776, 'Total loss': 0.4638496750304776}
2022-11-28 06:32:02,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:02,886 INFO:     Epoch: 75
2022-11-28 06:32:03,573 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44607503136450594, 'Total loss': 0.44607503136450594} | train loss {'Reaction outcome loss': 0.4660753687663424, 'Total loss': 0.4660753687663424}
2022-11-28 06:32:03,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:03,573 INFO:     Epoch: 76
2022-11-28 06:32:04,259 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45279889790849254, 'Total loss': 0.45279889790849254} | train loss {'Reaction outcome loss': 0.46953750900443525, 'Total loss': 0.46953750900443525}
2022-11-28 06:32:04,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:04,260 INFO:     Epoch: 77
2022-11-28 06:32:04,948 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.483202878724445, 'Total loss': 0.483202878724445} | train loss {'Reaction outcome loss': 0.46998222550797847, 'Total loss': 0.46998222550797847}
2022-11-28 06:32:04,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:04,949 INFO:     Epoch: 78
2022-11-28 06:32:05,638 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46224412034181034, 'Total loss': 0.46224412034181034} | train loss {'Reaction outcome loss': 0.47280593156333894, 'Total loss': 0.47280593156333894}
2022-11-28 06:32:05,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:05,638 INFO:     Epoch: 79
2022-11-28 06:32:06,327 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5040406009013002, 'Total loss': 0.5040406009013002} | train loss {'Reaction outcome loss': 0.46720428139932696, 'Total loss': 0.46720428139932696}
2022-11-28 06:32:06,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:06,327 INFO:     Epoch: 80
2022-11-28 06:32:07,012 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44992569156668405, 'Total loss': 0.44992569156668405} | train loss {'Reaction outcome loss': 0.4612558785705797, 'Total loss': 0.4612558785705797}
2022-11-28 06:32:07,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:07,013 INFO:     Epoch: 81
2022-11-28 06:32:07,700 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.502096542919224, 'Total loss': 0.502096542919224} | train loss {'Reaction outcome loss': 0.47087643662047, 'Total loss': 0.47087643662047}
2022-11-28 06:32:07,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:07,700 INFO:     Epoch: 82
2022-11-28 06:32:08,390 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4634879343211651, 'Total loss': 0.4634879343211651} | train loss {'Reaction outcome loss': 0.46966591002720015, 'Total loss': 0.46966591002720015}
2022-11-28 06:32:08,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:08,391 INFO:     Epoch: 83
2022-11-28 06:32:09,078 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.459830258380283, 'Total loss': 0.459830258380283} | train loss {'Reaction outcome loss': 0.4612556503665063, 'Total loss': 0.4612556503665063}
2022-11-28 06:32:09,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:09,078 INFO:     Epoch: 84
2022-11-28 06:32:09,768 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4647819609804587, 'Total loss': 0.4647819609804587} | train loss {'Reaction outcome loss': 0.463534718139037, 'Total loss': 0.463534718139037}
2022-11-28 06:32:09,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:09,768 INFO:     Epoch: 85
2022-11-28 06:32:10,459 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5335232256488367, 'Total loss': 0.5335232256488367} | train loss {'Reaction outcome loss': 0.4731361597415901, 'Total loss': 0.4731361597415901}
2022-11-28 06:32:10,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:10,459 INFO:     Epoch: 86
2022-11-28 06:32:11,147 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46138194135644217, 'Total loss': 0.46138194135644217} | train loss {'Reaction outcome loss': 0.46830902870504126, 'Total loss': 0.46830902870504126}
2022-11-28 06:32:11,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:11,148 INFO:     Epoch: 87
2022-11-28 06:32:11,837 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47517291795123706, 'Total loss': 0.47517291795123706} | train loss {'Reaction outcome loss': 0.4676608888492469, 'Total loss': 0.4676608888492469}
2022-11-28 06:32:11,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:11,838 INFO:     Epoch: 88
2022-11-28 06:32:12,527 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47716475142674014, 'Total loss': 0.47716475142674014} | train loss {'Reaction outcome loss': 0.4802197007041785, 'Total loss': 0.4802197007041785}
2022-11-28 06:32:12,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:12,528 INFO:     Epoch: 89
2022-11-28 06:32:13,216 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45922348919239914, 'Total loss': 0.45922348919239914} | train loss {'Reaction outcome loss': 0.47288002229986653, 'Total loss': 0.47288002229986653}
2022-11-28 06:32:13,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:13,216 INFO:     Epoch: 90
2022-11-28 06:32:13,904 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4859158271415667, 'Total loss': 0.4859158271415667} | train loss {'Reaction outcome loss': 0.46686753907030626, 'Total loss': 0.46686753907030626}
2022-11-28 06:32:13,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:13,905 INFO:     Epoch: 91
2022-11-28 06:32:14,592 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4515798904679038, 'Total loss': 0.4515798904679038} | train loss {'Reaction outcome loss': 0.47296833967970264, 'Total loss': 0.47296833967970264}
2022-11-28 06:32:14,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:14,593 INFO:     Epoch: 92
2022-11-28 06:32:15,280 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49135743149302225, 'Total loss': 0.49135743149302225} | train loss {'Reaction outcome loss': 0.46490107665980057, 'Total loss': 0.46490107665980057}
2022-11-28 06:32:15,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:15,280 INFO:     Epoch: 93
2022-11-28 06:32:15,970 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46418237855488603, 'Total loss': 0.46418237855488603} | train loss {'Reaction outcome loss': 0.46650984276446605, 'Total loss': 0.46650984276446605}
2022-11-28 06:32:15,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:15,970 INFO:     Epoch: 94
2022-11-28 06:32:16,661 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4679874550889839, 'Total loss': 0.4679874550889839} | train loss {'Reaction outcome loss': 0.4736784245338171, 'Total loss': 0.4736784245338171}
2022-11-28 06:32:16,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:16,662 INFO:     Epoch: 95
2022-11-28 06:32:17,349 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4695881672880866, 'Total loss': 0.4695881672880866} | train loss {'Reaction outcome loss': 0.46948503114042744, 'Total loss': 0.46948503114042744}
2022-11-28 06:32:17,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:17,349 INFO:     Epoch: 96
2022-11-28 06:32:18,037 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45178253982554784, 'Total loss': 0.45178253982554784} | train loss {'Reaction outcome loss': 0.48046717660561683, 'Total loss': 0.48046717660561683}
2022-11-28 06:32:18,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:18,037 INFO:     Epoch: 97
2022-11-28 06:32:18,731 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4728228835897012, 'Total loss': 0.4728228835897012} | train loss {'Reaction outcome loss': 0.46883388179083985, 'Total loss': 0.46883388179083985}
2022-11-28 06:32:18,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:18,731 INFO:     Epoch: 98
2022-11-28 06:32:19,425 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.525462749668143, 'Total loss': 0.525462749668143} | train loss {'Reaction outcome loss': 0.47384185902774334, 'Total loss': 0.47384185902774334}
2022-11-28 06:32:19,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:19,425 INFO:     Epoch: 99
2022-11-28 06:32:20,116 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4772763147272847, 'Total loss': 0.4772763147272847} | train loss {'Reaction outcome loss': 0.4678542097850192, 'Total loss': 0.4678542097850192}
2022-11-28 06:32:20,116 INFO:     Best model found after epoch 29 of 100.
2022-11-28 06:32:20,116 INFO:   Done with stage: TRAINING
2022-11-28 06:32:20,116 INFO:   Starting stage: EVALUATION
2022-11-28 06:32:20,230 INFO:   Done with stage: EVALUATION
2022-11-28 06:32:20,230 INFO:   Leaving out SEQ value Fold_7
2022-11-28 06:32:20,243 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:32:20,243 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:32:20,892 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:32:20,892 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:32:20,963 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:32:20,963 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:32:20,963 INFO:     No hyperparam tuning for this model
2022-11-28 06:32:20,963 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:32:20,963 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:32:20,964 INFO:     None feature selector for col prot
2022-11-28 06:32:20,964 INFO:     None feature selector for col prot
2022-11-28 06:32:20,964 INFO:     None feature selector for col prot
2022-11-28 06:32:20,965 INFO:     None feature selector for col chem
2022-11-28 06:32:20,965 INFO:     None feature selector for col chem
2022-11-28 06:32:20,965 INFO:     None feature selector for col chem
2022-11-28 06:32:20,965 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:32:20,965 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:32:20,967 INFO:     Number of params in model 169651
2022-11-28 06:32:20,970 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:32:20,970 INFO:   Starting stage: TRAINING
2022-11-28 06:32:21,022 INFO:     Val loss before train {'Reaction outcome loss': 1.0487369014458223, 'Total loss': 1.0487369014458223}
2022-11-28 06:32:21,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:21,022 INFO:     Epoch: 0
2022-11-28 06:32:21,712 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6148178279399872, 'Total loss': 0.6148178279399872} | train loss {'Reaction outcome loss': 0.6876419260497054, 'Total loss': 0.6876419260497054}
2022-11-28 06:32:21,712 INFO:     Found new best model at epoch 0
2022-11-28 06:32:21,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:21,713 INFO:     Epoch: 1
2022-11-28 06:32:22,399 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5549722625450655, 'Total loss': 0.5549722625450655} | train loss {'Reaction outcome loss': 0.5734831937738964, 'Total loss': 0.5734831937738964}
2022-11-28 06:32:22,399 INFO:     Found new best model at epoch 1
2022-11-28 06:32:22,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:22,400 INFO:     Epoch: 2
2022-11-28 06:32:23,085 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5117632049051198, 'Total loss': 0.5117632049051198} | train loss {'Reaction outcome loss': 0.5536919601501957, 'Total loss': 0.5536919601501957}
2022-11-28 06:32:23,085 INFO:     Found new best model at epoch 2
2022-11-28 06:32:23,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:23,086 INFO:     Epoch: 3
2022-11-28 06:32:23,776 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5194390971552242, 'Total loss': 0.5194390971552242} | train loss {'Reaction outcome loss': 0.5414581662344355, 'Total loss': 0.5414581662344355}
2022-11-28 06:32:23,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:23,777 INFO:     Epoch: 4
2022-11-28 06:32:24,466 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5134002640843391, 'Total loss': 0.5134002640843391} | train loss {'Reaction outcome loss': 0.5199341309527236, 'Total loss': 0.5199341309527236}
2022-11-28 06:32:24,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:24,466 INFO:     Epoch: 5
2022-11-28 06:32:25,153 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5272391032088887, 'Total loss': 0.5272391032088887} | train loss {'Reaction outcome loss': 0.5076424183864747, 'Total loss': 0.5076424183864747}
2022-11-28 06:32:25,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:25,153 INFO:     Epoch: 6
2022-11-28 06:32:25,842 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49863332882523537, 'Total loss': 0.49863332882523537} | train loss {'Reaction outcome loss': 0.5033820294925282, 'Total loss': 0.5033820294925282}
2022-11-28 06:32:25,842 INFO:     Found new best model at epoch 6
2022-11-28 06:32:25,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:25,843 INFO:     Epoch: 7
2022-11-28 06:32:26,530 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5902056768536568, 'Total loss': 0.5902056768536568} | train loss {'Reaction outcome loss': 0.4988645551305625, 'Total loss': 0.4988645551305625}
2022-11-28 06:32:26,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:26,530 INFO:     Epoch: 8
2022-11-28 06:32:27,217 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49508971212939784, 'Total loss': 0.49508971212939784} | train loss {'Reaction outcome loss': 0.49718987076513227, 'Total loss': 0.49718987076513227}
2022-11-28 06:32:27,217 INFO:     Found new best model at epoch 8
2022-11-28 06:32:27,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:27,218 INFO:     Epoch: 9
2022-11-28 06:32:27,906 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4710965427485379, 'Total loss': 0.4710965427485379} | train loss {'Reaction outcome loss': 0.4983834678367261, 'Total loss': 0.4983834678367261}
2022-11-28 06:32:27,906 INFO:     Found new best model at epoch 9
2022-11-28 06:32:27,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:27,907 INFO:     Epoch: 10
2022-11-28 06:32:28,595 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5001615316353061, 'Total loss': 0.5001615316353061} | train loss {'Reaction outcome loss': 0.4960031967249609, 'Total loss': 0.4960031967249609}
2022-11-28 06:32:28,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:28,595 INFO:     Epoch: 11
2022-11-28 06:32:29,283 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4905983362008225, 'Total loss': 0.4905983362008225} | train loss {'Reaction outcome loss': 0.4872374342333886, 'Total loss': 0.4872374342333886}
2022-11-28 06:32:29,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:29,283 INFO:     Epoch: 12
2022-11-28 06:32:29,978 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48408746685494075, 'Total loss': 0.48408746685494075} | train loss {'Reaction outcome loss': 0.48897741458589034, 'Total loss': 0.48897741458589034}
2022-11-28 06:32:29,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:29,978 INFO:     Epoch: 13
2022-11-28 06:32:30,664 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5012142363597046, 'Total loss': 0.5012142363597046} | train loss {'Reaction outcome loss': 0.48423276517179703, 'Total loss': 0.48423276517179703}
2022-11-28 06:32:30,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:30,664 INFO:     Epoch: 14
2022-11-28 06:32:31,349 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5495309921150858, 'Total loss': 0.5495309921150858} | train loss {'Reaction outcome loss': 0.488948222009405, 'Total loss': 0.488948222009405}
2022-11-28 06:32:31,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:31,349 INFO:     Epoch: 15
2022-11-28 06:32:32,015 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.530703907663172, 'Total loss': 0.530703907663172} | train loss {'Reaction outcome loss': 0.47866421301038037, 'Total loss': 0.47866421301038037}
2022-11-28 06:32:32,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:32,015 INFO:     Epoch: 16
2022-11-28 06:32:32,683 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5240260355851867, 'Total loss': 0.5240260355851867} | train loss {'Reaction outcome loss': 0.48183276612431775, 'Total loss': 0.48183276612431775}
2022-11-28 06:32:32,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:32,684 INFO:     Epoch: 17
2022-11-28 06:32:33,356 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5221195153214715, 'Total loss': 0.5221195153214715} | train loss {'Reaction outcome loss': 0.4789780020833977, 'Total loss': 0.4789780020833977}
2022-11-28 06:32:33,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:33,356 INFO:     Epoch: 18
2022-11-28 06:32:34,028 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5454936318776824, 'Total loss': 0.5454936318776824} | train loss {'Reaction outcome loss': 0.4778585417136069, 'Total loss': 0.4778585417136069}
2022-11-28 06:32:34,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:34,028 INFO:     Epoch: 19
2022-11-28 06:32:34,695 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48801683499054477, 'Total loss': 0.48801683499054477} | train loss {'Reaction outcome loss': 0.49328664930597427, 'Total loss': 0.49328664930597427}
2022-11-28 06:32:34,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:34,695 INFO:     Epoch: 20
2022-11-28 06:32:35,358 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4726910929788243, 'Total loss': 0.4726910929788243} | train loss {'Reaction outcome loss': 0.4842171312099503, 'Total loss': 0.4842171312099503}
2022-11-28 06:32:35,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:35,359 INFO:     Epoch: 21
2022-11-28 06:32:36,024 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5034178715537895, 'Total loss': 0.5034178715537895} | train loss {'Reaction outcome loss': 0.47907175634416843, 'Total loss': 0.47907175634416843}
2022-11-28 06:32:36,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:36,025 INFO:     Epoch: 22
2022-11-28 06:32:36,696 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49263971400531853, 'Total loss': 0.49263971400531853} | train loss {'Reaction outcome loss': 0.4835307136057846, 'Total loss': 0.4835307136057846}
2022-11-28 06:32:36,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:36,696 INFO:     Epoch: 23
2022-11-28 06:32:37,369 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48361038077961316, 'Total loss': 0.48361038077961316} | train loss {'Reaction outcome loss': 0.48088976338265405, 'Total loss': 0.48088976338265405}
2022-11-28 06:32:37,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:37,370 INFO:     Epoch: 24
2022-11-28 06:32:38,040 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5202479494566267, 'Total loss': 0.5202479494566267} | train loss {'Reaction outcome loss': 0.4760514635953211, 'Total loss': 0.4760514635953211}
2022-11-28 06:32:38,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:38,040 INFO:     Epoch: 25
2022-11-28 06:32:38,711 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5191532102498141, 'Total loss': 0.5191532102498141} | train loss {'Reaction outcome loss': 0.4817841914632628, 'Total loss': 0.4817841914632628}
2022-11-28 06:32:38,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:38,712 INFO:     Epoch: 26
2022-11-28 06:32:39,380 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5310339148749005, 'Total loss': 0.5310339148749005} | train loss {'Reaction outcome loss': 0.4786316787283267, 'Total loss': 0.4786316787283267}
2022-11-28 06:32:39,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:39,380 INFO:     Epoch: 27
2022-11-28 06:32:40,051 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4778362668373368, 'Total loss': 0.4778362668373368} | train loss {'Reaction outcome loss': 0.48698474611005477, 'Total loss': 0.48698474611005477}
2022-11-28 06:32:40,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:40,051 INFO:     Epoch: 28
2022-11-28 06:32:40,722 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4791406721554019, 'Total loss': 0.4791406721554019} | train loss {'Reaction outcome loss': 0.47270837312023484, 'Total loss': 0.47270837312023484}
2022-11-28 06:32:40,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:40,722 INFO:     Epoch: 29
2022-11-28 06:32:41,393 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4746232743967663, 'Total loss': 0.4746232743967663} | train loss {'Reaction outcome loss': 0.4774575608091489, 'Total loss': 0.4774575608091489}
2022-11-28 06:32:41,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:41,394 INFO:     Epoch: 30
2022-11-28 06:32:42,063 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49700287594036624, 'Total loss': 0.49700287594036624} | train loss {'Reaction outcome loss': 0.47098569079272207, 'Total loss': 0.47098569079272207}
2022-11-28 06:32:42,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:42,063 INFO:     Epoch: 31
2022-11-28 06:32:42,735 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4735086763446981, 'Total loss': 0.4735086763446981} | train loss {'Reaction outcome loss': 0.4754205898892495, 'Total loss': 0.4754205898892495}
2022-11-28 06:32:42,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:42,735 INFO:     Epoch: 32
2022-11-28 06:32:43,408 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48840146376328036, 'Total loss': 0.48840146376328036} | train loss {'Reaction outcome loss': 0.4727482269367864, 'Total loss': 0.4727482269367864}
2022-11-28 06:32:43,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:43,408 INFO:     Epoch: 33
2022-11-28 06:32:44,076 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46249777180227364, 'Total loss': 0.46249777180227364} | train loss {'Reaction outcome loss': 0.47108843282706314, 'Total loss': 0.47108843282706314}
2022-11-28 06:32:44,077 INFO:     Found new best model at epoch 33
2022-11-28 06:32:44,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:44,077 INFO:     Epoch: 34
2022-11-28 06:32:44,746 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46337631717324257, 'Total loss': 0.46337631717324257} | train loss {'Reaction outcome loss': 0.4742324510889669, 'Total loss': 0.4742324510889669}
2022-11-28 06:32:44,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:44,746 INFO:     Epoch: 35
2022-11-28 06:32:45,415 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47857255657965486, 'Total loss': 0.47857255657965486} | train loss {'Reaction outcome loss': 0.4732159225931091, 'Total loss': 0.4732159225931091}
2022-11-28 06:32:45,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:45,415 INFO:     Epoch: 36
2022-11-28 06:32:46,096 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4652947902002118, 'Total loss': 0.4652947902002118} | train loss {'Reaction outcome loss': 0.472206354351534, 'Total loss': 0.472206354351534}
2022-11-28 06:32:46,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:46,097 INFO:     Epoch: 37
2022-11-28 06:32:46,773 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49825150959871034, 'Total loss': 0.49825150959871034} | train loss {'Reaction outcome loss': 0.47181554475138265, 'Total loss': 0.47181554475138265}
2022-11-28 06:32:46,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:46,773 INFO:     Epoch: 38
2022-11-28 06:32:47,444 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4796860089356249, 'Total loss': 0.4796860089356249} | train loss {'Reaction outcome loss': 0.46640564879823115, 'Total loss': 0.46640564879823115}
2022-11-28 06:32:47,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:47,444 INFO:     Epoch: 39
2022-11-28 06:32:48,117 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4806748567657037, 'Total loss': 0.4806748567657037} | train loss {'Reaction outcome loss': 0.4757932858962205, 'Total loss': 0.4757932858962205}
2022-11-28 06:32:48,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:48,117 INFO:     Epoch: 40
2022-11-28 06:32:48,787 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4911865825680169, 'Total loss': 0.4911865825680169} | train loss {'Reaction outcome loss': 0.4719776439690782, 'Total loss': 0.4719776439690782}
2022-11-28 06:32:48,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:48,788 INFO:     Epoch: 41
2022-11-28 06:32:49,459 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5026256072927605, 'Total loss': 0.5026256072927605} | train loss {'Reaction outcome loss': 0.4673762544989586, 'Total loss': 0.4673762544989586}
2022-11-28 06:32:49,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:49,460 INFO:     Epoch: 42
2022-11-28 06:32:50,131 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5326843231239102, 'Total loss': 0.5326843231239102} | train loss {'Reaction outcome loss': 0.4729665594716226, 'Total loss': 0.4729665594716226}
2022-11-28 06:32:50,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:50,131 INFO:     Epoch: 43
2022-11-28 06:32:50,803 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46215330165895546, 'Total loss': 0.46215330165895546} | train loss {'Reaction outcome loss': 0.47446954103126643, 'Total loss': 0.47446954103126643}
2022-11-28 06:32:50,803 INFO:     Found new best model at epoch 43
2022-11-28 06:32:50,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:50,804 INFO:     Epoch: 44
2022-11-28 06:32:51,477 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48483672738075256, 'Total loss': 0.48483672738075256} | train loss {'Reaction outcome loss': 0.47357442506378694, 'Total loss': 0.47357442506378694}
2022-11-28 06:32:51,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:51,478 INFO:     Epoch: 45
2022-11-28 06:32:52,153 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4630922573533925, 'Total loss': 0.4630922573533925} | train loss {'Reaction outcome loss': 0.4698411193826506, 'Total loss': 0.4698411193826506}
2022-11-28 06:32:52,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:52,153 INFO:     Epoch: 46
2022-11-28 06:32:52,827 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49815618246793747, 'Total loss': 0.49815618246793747} | train loss {'Reaction outcome loss': 0.45878643019785803, 'Total loss': 0.45878643019785803}
2022-11-28 06:32:52,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:52,828 INFO:     Epoch: 47
2022-11-28 06:32:53,496 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4913568486544219, 'Total loss': 0.4913568486544219} | train loss {'Reaction outcome loss': 0.46607128578809, 'Total loss': 0.46607128578809}
2022-11-28 06:32:53,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:53,497 INFO:     Epoch: 48
2022-11-28 06:32:54,167 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4553685174746947, 'Total loss': 0.4553685174746947} | train loss {'Reaction outcome loss': 0.4722917248765307, 'Total loss': 0.4722917248765307}
2022-11-28 06:32:54,167 INFO:     Found new best model at epoch 48
2022-11-28 06:32:54,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:54,168 INFO:     Epoch: 49
2022-11-28 06:32:54,836 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.504847315563397, 'Total loss': 0.504847315563397} | train loss {'Reaction outcome loss': 0.46584809601547256, 'Total loss': 0.46584809601547256}
2022-11-28 06:32:54,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:54,836 INFO:     Epoch: 50
2022-11-28 06:32:55,509 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45708411339331756, 'Total loss': 0.45708411339331756} | train loss {'Reaction outcome loss': 0.4754098204355086, 'Total loss': 0.4754098204355086}
2022-11-28 06:32:55,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:55,509 INFO:     Epoch: 51
2022-11-28 06:32:56,180 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4658181542022662, 'Total loss': 0.4658181542022662} | train loss {'Reaction outcome loss': 0.473350600369515, 'Total loss': 0.473350600369515}
2022-11-28 06:32:56,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:56,180 INFO:     Epoch: 52
2022-11-28 06:32:56,849 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48967443812977185, 'Total loss': 0.48967443812977185} | train loss {'Reaction outcome loss': 0.46447998820052994, 'Total loss': 0.46447998820052994}
2022-11-28 06:32:56,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:56,850 INFO:     Epoch: 53
2022-11-28 06:32:57,521 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4764718342233788, 'Total loss': 0.4764718342233788} | train loss {'Reaction outcome loss': 0.4730661707299371, 'Total loss': 0.4730661707299371}
2022-11-28 06:32:57,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:57,521 INFO:     Epoch: 54
2022-11-28 06:32:58,193 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4498864182017066, 'Total loss': 0.4498864182017066} | train loss {'Reaction outcome loss': 0.46790524460976163, 'Total loss': 0.46790524460976163}
2022-11-28 06:32:58,193 INFO:     Found new best model at epoch 54
2022-11-28 06:32:58,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:58,194 INFO:     Epoch: 55
2022-11-28 06:32:58,864 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4750372300093824, 'Total loss': 0.4750372300093824} | train loss {'Reaction outcome loss': 0.4642138138653771, 'Total loss': 0.4642138138653771}
2022-11-28 06:32:58,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:58,864 INFO:     Epoch: 56
2022-11-28 06:32:59,538 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4677278362214565, 'Total loss': 0.4677278362214565} | train loss {'Reaction outcome loss': 0.4634275192454938, 'Total loss': 0.4634275192454938}
2022-11-28 06:32:59,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:32:59,538 INFO:     Epoch: 57
2022-11-28 06:33:00,211 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45315044644204056, 'Total loss': 0.45315044644204056} | train loss {'Reaction outcome loss': 0.4734307073747679, 'Total loss': 0.4734307073747679}
2022-11-28 06:33:00,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:00,211 INFO:     Epoch: 58
2022-11-28 06:33:00,882 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4738889969885349, 'Total loss': 0.4738889969885349} | train loss {'Reaction outcome loss': 0.46999741892420477, 'Total loss': 0.46999741892420477}
2022-11-28 06:33:00,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:00,882 INFO:     Epoch: 59
2022-11-28 06:33:01,555 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.455642756074667, 'Total loss': 0.455642756074667} | train loss {'Reaction outcome loss': 0.4653113643608747, 'Total loss': 0.4653113643608747}
2022-11-28 06:33:01,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:01,555 INFO:     Epoch: 60
2022-11-28 06:33:02,233 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46885636855255475, 'Total loss': 0.46885636855255475} | train loss {'Reaction outcome loss': 0.46472038352681744, 'Total loss': 0.46472038352681744}
2022-11-28 06:33:02,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:02,234 INFO:     Epoch: 61
2022-11-28 06:33:02,906 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4811065031046217, 'Total loss': 0.4811065031046217} | train loss {'Reaction outcome loss': 0.4677346111725896, 'Total loss': 0.4677346111725896}
2022-11-28 06:33:02,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:02,907 INFO:     Epoch: 62
2022-11-28 06:33:03,579 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48544169488278305, 'Total loss': 0.48544169488278305} | train loss {'Reaction outcome loss': 0.4717310386439485, 'Total loss': 0.4717310386439485}
2022-11-28 06:33:03,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:03,579 INFO:     Epoch: 63
2022-11-28 06:33:04,249 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5305037281729958, 'Total loss': 0.5305037281729958} | train loss {'Reaction outcome loss': 0.46499626783113324, 'Total loss': 0.46499626783113324}
2022-11-28 06:33:04,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:04,249 INFO:     Epoch: 64
2022-11-28 06:33:04,918 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5124207538637248, 'Total loss': 0.5124207538637248} | train loss {'Reaction outcome loss': 0.4689124362362969, 'Total loss': 0.4689124362362969}
2022-11-28 06:33:04,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:04,919 INFO:     Epoch: 65
2022-11-28 06:33:05,590 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47969281334768643, 'Total loss': 0.47969281334768643} | train loss {'Reaction outcome loss': 0.4752351178397094, 'Total loss': 0.4752351178397094}
2022-11-28 06:33:05,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:05,590 INFO:     Epoch: 66
2022-11-28 06:33:06,260 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4903914958915927, 'Total loss': 0.4903914958915927} | train loss {'Reaction outcome loss': 0.46991895157242974, 'Total loss': 0.46991895157242974}
2022-11-28 06:33:06,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:06,260 INFO:     Epoch: 67
2022-11-28 06:33:06,933 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4903345473788001, 'Total loss': 0.4903345473788001} | train loss {'Reaction outcome loss': 0.4692620699323954, 'Total loss': 0.4692620699323954}
2022-11-28 06:33:06,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:06,934 INFO:     Epoch: 68
2022-11-28 06:33:07,606 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49759609353813256, 'Total loss': 0.49759609353813256} | train loss {'Reaction outcome loss': 0.4672707934533396, 'Total loss': 0.4672707934533396}
2022-11-28 06:33:07,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:07,606 INFO:     Epoch: 69
2022-11-28 06:33:08,284 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4518978616053408, 'Total loss': 0.4518978616053408} | train loss {'Reaction outcome loss': 0.4676773013366807, 'Total loss': 0.4676773013366807}
2022-11-28 06:33:08,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:08,285 INFO:     Epoch: 70
2022-11-28 06:33:08,963 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4920292669399218, 'Total loss': 0.4920292669399218} | train loss {'Reaction outcome loss': 0.46841340572122603, 'Total loss': 0.46841340572122603}
2022-11-28 06:33:08,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:08,963 INFO:     Epoch: 71
2022-11-28 06:33:09,637 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48871633342721243, 'Total loss': 0.48871633342721243} | train loss {'Reaction outcome loss': 0.47834592150344, 'Total loss': 0.47834592150344}
2022-11-28 06:33:09,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:09,637 INFO:     Epoch: 72
2022-11-28 06:33:10,308 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4809241613203829, 'Total loss': 0.4809241613203829} | train loss {'Reaction outcome loss': 0.46781848878749915, 'Total loss': 0.46781848878749915}
2022-11-28 06:33:10,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:10,308 INFO:     Epoch: 73
2022-11-28 06:33:10,977 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48727990551428363, 'Total loss': 0.48727990551428363} | train loss {'Reaction outcome loss': 0.4756510674713119, 'Total loss': 0.4756510674713119}
2022-11-28 06:33:10,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:10,977 INFO:     Epoch: 74
2022-11-28 06:33:11,648 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48298714276064525, 'Total loss': 0.48298714276064525} | train loss {'Reaction outcome loss': 0.4685779302831619, 'Total loss': 0.4685779302831619}
2022-11-28 06:33:11,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:11,648 INFO:     Epoch: 75
2022-11-28 06:33:12,320 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5193739320066842, 'Total loss': 0.5193739320066842} | train loss {'Reaction outcome loss': 0.46974918744977445, 'Total loss': 0.46974918744977445}
2022-11-28 06:33:12,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:12,320 INFO:     Epoch: 76
2022-11-28 06:33:12,992 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46280939707701857, 'Total loss': 0.46280939707701857} | train loss {'Reaction outcome loss': 0.47124424787057984, 'Total loss': 0.47124424787057984}
2022-11-28 06:33:12,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:12,993 INFO:     Epoch: 77
2022-11-28 06:33:13,666 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4800637648864226, 'Total loss': 0.4800637648864226} | train loss {'Reaction outcome loss': 0.4682106678524325, 'Total loss': 0.4682106678524325}
2022-11-28 06:33:13,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:13,666 INFO:     Epoch: 78
2022-11-28 06:33:14,338 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45754589953205804, 'Total loss': 0.45754589953205804} | train loss {'Reaction outcome loss': 0.47083103152052047, 'Total loss': 0.47083103152052047}
2022-11-28 06:33:14,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:14,338 INFO:     Epoch: 79
2022-11-28 06:33:15,008 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45862022042274475, 'Total loss': 0.45862022042274475} | train loss {'Reaction outcome loss': 0.46525276287068285, 'Total loss': 0.46525276287068285}
2022-11-28 06:33:15,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:15,008 INFO:     Epoch: 80
2022-11-28 06:33:15,679 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4855515157634562, 'Total loss': 0.4855515157634562} | train loss {'Reaction outcome loss': 0.46652805120233565, 'Total loss': 0.46652805120233565}
2022-11-28 06:33:15,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:15,679 INFO:     Epoch: 81
2022-11-28 06:33:16,352 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49016041444106534, 'Total loss': 0.49016041444106534} | train loss {'Reaction outcome loss': 0.4703992750615843, 'Total loss': 0.4703992750615843}
2022-11-28 06:33:16,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:16,353 INFO:     Epoch: 82
2022-11-28 06:33:17,021 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4704602584242821, 'Total loss': 0.4704602584242821} | train loss {'Reaction outcome loss': 0.4720796001173796, 'Total loss': 0.4720796001173796}
2022-11-28 06:33:17,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:17,022 INFO:     Epoch: 83
2022-11-28 06:33:17,694 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4792297983711416, 'Total loss': 0.4792297983711416} | train loss {'Reaction outcome loss': 0.4648546166117153, 'Total loss': 0.4648546166117153}
2022-11-28 06:33:17,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:17,695 INFO:     Epoch: 84
2022-11-28 06:33:18,371 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48149004070596263, 'Total loss': 0.48149004070596263} | train loss {'Reaction outcome loss': 0.4697799158973559, 'Total loss': 0.4697799158973559}
2022-11-28 06:33:18,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:18,371 INFO:     Epoch: 85
2022-11-28 06:33:19,042 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4926725802096454, 'Total loss': 0.4926725802096454} | train loss {'Reaction outcome loss': 0.4653071674608415, 'Total loss': 0.4653071674608415}
2022-11-28 06:33:19,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:19,042 INFO:     Epoch: 86
2022-11-28 06:33:19,715 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4879903657869859, 'Total loss': 0.4879903657869859} | train loss {'Reaction outcome loss': 0.474323449416026, 'Total loss': 0.474323449416026}
2022-11-28 06:33:19,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:19,715 INFO:     Epoch: 87
2022-11-28 06:33:20,388 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47246211259202525, 'Total loss': 0.47246211259202525} | train loss {'Reaction outcome loss': 0.4708513077949324, 'Total loss': 0.4708513077949324}
2022-11-28 06:33:20,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:20,388 INFO:     Epoch: 88
2022-11-28 06:33:21,061 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4673784321004694, 'Total loss': 0.4673784321004694} | train loss {'Reaction outcome loss': 0.47341915475384844, 'Total loss': 0.47341915475384844}
2022-11-28 06:33:21,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:21,061 INFO:     Epoch: 89
2022-11-28 06:33:21,731 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5098189528692852, 'Total loss': 0.5098189528692852} | train loss {'Reaction outcome loss': 0.469043625218253, 'Total loss': 0.469043625218253}
2022-11-28 06:33:21,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:21,731 INFO:     Epoch: 90
2022-11-28 06:33:22,404 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4648521603508429, 'Total loss': 0.4648521603508429} | train loss {'Reaction outcome loss': 0.46889656373570043, 'Total loss': 0.46889656373570043}
2022-11-28 06:33:22,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:22,404 INFO:     Epoch: 91
2022-11-28 06:33:23,074 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45903144573623483, 'Total loss': 0.45903144573623483} | train loss {'Reaction outcome loss': 0.46653046717326485, 'Total loss': 0.46653046717326485}
2022-11-28 06:33:23,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:23,074 INFO:     Epoch: 92
2022-11-28 06:33:23,745 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47905187647451053, 'Total loss': 0.47905187647451053} | train loss {'Reaction outcome loss': 0.4693049378693104, 'Total loss': 0.4693049378693104}
2022-11-28 06:33:23,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:23,745 INFO:     Epoch: 93
2022-11-28 06:33:24,417 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47872882742773404, 'Total loss': 0.47872882742773404} | train loss {'Reaction outcome loss': 0.4707945659155807, 'Total loss': 0.4707945659155807}
2022-11-28 06:33:24,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:24,417 INFO:     Epoch: 94
2022-11-28 06:33:25,088 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45545676350593567, 'Total loss': 0.45545676350593567} | train loss {'Reaction outcome loss': 0.4665081946239356, 'Total loss': 0.4665081946239356}
2022-11-28 06:33:25,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:25,089 INFO:     Epoch: 95
2022-11-28 06:33:25,759 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46039525080810895, 'Total loss': 0.46039525080810895} | train loss {'Reaction outcome loss': 0.4675585587599104, 'Total loss': 0.4675585587599104}
2022-11-28 06:33:25,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:25,759 INFO:     Epoch: 96
2022-11-28 06:33:26,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4426568484103138, 'Total loss': 0.4426568484103138} | train loss {'Reaction outcome loss': 0.4665127894090068, 'Total loss': 0.4665127894090068}
2022-11-28 06:33:26,428 INFO:     Found new best model at epoch 96
2022-11-28 06:33:26,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:26,429 INFO:     Epoch: 97
2022-11-28 06:33:27,098 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4632700126279484, 'Total loss': 0.4632700126279484} | train loss {'Reaction outcome loss': 0.47167160313936973, 'Total loss': 0.47167160313936973}
2022-11-28 06:33:27,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:27,098 INFO:     Epoch: 98
2022-11-28 06:33:27,769 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4833537739786235, 'Total loss': 0.4833537739786235} | train loss {'Reaction outcome loss': 0.4642903360448057, 'Total loss': 0.4642903360448057}
2022-11-28 06:33:27,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:27,769 INFO:     Epoch: 99
2022-11-28 06:33:28,441 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48711602118882263, 'Total loss': 0.48711602118882263} | train loss {'Reaction outcome loss': 0.4687455382438437, 'Total loss': 0.4687455382438437}
2022-11-28 06:33:28,441 INFO:     Best model found after epoch 97 of 100.
2022-11-28 06:33:28,442 INFO:   Done with stage: TRAINING
2022-11-28 06:33:28,442 INFO:   Starting stage: EVALUATION
2022-11-28 06:33:28,555 INFO:   Done with stage: EVALUATION
2022-11-28 06:33:28,555 INFO:   Leaving out SEQ value Fold_8
2022-11-28 06:33:28,568 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 06:33:28,568 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:33:29,213 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:33:29,214 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:33:29,283 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:33:29,283 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:33:29,283 INFO:     No hyperparam tuning for this model
2022-11-28 06:33:29,283 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:33:29,283 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:33:29,284 INFO:     None feature selector for col prot
2022-11-28 06:33:29,284 INFO:     None feature selector for col prot
2022-11-28 06:33:29,284 INFO:     None feature selector for col prot
2022-11-28 06:33:29,285 INFO:     None feature selector for col chem
2022-11-28 06:33:29,285 INFO:     None feature selector for col chem
2022-11-28 06:33:29,285 INFO:     None feature selector for col chem
2022-11-28 06:33:29,285 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:33:29,285 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:33:29,287 INFO:     Number of params in model 169651
2022-11-28 06:33:29,290 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:33:29,290 INFO:   Starting stage: TRAINING
2022-11-28 06:33:29,341 INFO:     Val loss before train {'Reaction outcome loss': 0.9551607505841688, 'Total loss': 0.9551607505841688}
2022-11-28 06:33:29,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:29,342 INFO:     Epoch: 0
2022-11-28 06:33:30,009 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5885939598083496, 'Total loss': 0.5885939598083496} | train loss {'Reaction outcome loss': 0.6866830597726666, 'Total loss': 0.6866830597726666}
2022-11-28 06:33:30,009 INFO:     Found new best model at epoch 0
2022-11-28 06:33:30,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:30,010 INFO:     Epoch: 1
2022-11-28 06:33:30,671 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5471095077016137, 'Total loss': 0.5471095077016137} | train loss {'Reaction outcome loss': 0.5597436332580995, 'Total loss': 0.5597436332580995}
2022-11-28 06:33:30,671 INFO:     Found new best model at epoch 1
2022-11-28 06:33:30,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:30,672 INFO:     Epoch: 2
2022-11-28 06:33:31,334 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5171407060697675, 'Total loss': 0.5171407060697675} | train loss {'Reaction outcome loss': 0.5369999277348421, 'Total loss': 0.5369999277348421}
2022-11-28 06:33:31,335 INFO:     Found new best model at epoch 2
2022-11-28 06:33:31,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:31,335 INFO:     Epoch: 3
2022-11-28 06:33:32,002 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48877186463637784, 'Total loss': 0.48877186463637784} | train loss {'Reaction outcome loss': 0.5202673361617691, 'Total loss': 0.5202673361617691}
2022-11-28 06:33:32,002 INFO:     Found new best model at epoch 3
2022-11-28 06:33:32,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:32,003 INFO:     Epoch: 4
2022-11-28 06:33:32,668 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48117912018840964, 'Total loss': 0.48117912018840964} | train loss {'Reaction outcome loss': 0.4982469182841632, 'Total loss': 0.4982469182841632}
2022-11-28 06:33:32,668 INFO:     Found new best model at epoch 4
2022-11-28 06:33:32,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:32,669 INFO:     Epoch: 5
2022-11-28 06:33:33,335 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4854492934590036, 'Total loss': 0.4854492934590036} | train loss {'Reaction outcome loss': 0.49675688810494484, 'Total loss': 0.49675688810494484}
2022-11-28 06:33:33,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:33,336 INFO:     Epoch: 6
2022-11-28 06:33:33,997 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5155586519024589, 'Total loss': 0.5155586519024589} | train loss {'Reaction outcome loss': 0.4854634243006609, 'Total loss': 0.4854634243006609}
2022-11-28 06:33:33,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:33,998 INFO:     Epoch: 7
2022-11-28 06:33:34,663 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4523123186081648, 'Total loss': 0.4523123186081648} | train loss {'Reaction outcome loss': 0.47657107035724483, 'Total loss': 0.47657107035724483}
2022-11-28 06:33:34,663 INFO:     Found new best model at epoch 7
2022-11-28 06:33:34,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:34,664 INFO:     Epoch: 8
2022-11-28 06:33:35,326 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4559784159064293, 'Total loss': 0.4559784159064293} | train loss {'Reaction outcome loss': 0.4697537838196268, 'Total loss': 0.4697537838196268}
2022-11-28 06:33:35,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:35,326 INFO:     Epoch: 9
2022-11-28 06:33:35,988 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.447264299812642, 'Total loss': 0.447264299812642} | train loss {'Reaction outcome loss': 0.47397368002911006, 'Total loss': 0.47397368002911006}
2022-11-28 06:33:35,988 INFO:     Found new best model at epoch 9
2022-11-28 06:33:35,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:35,989 INFO:     Epoch: 10
2022-11-28 06:33:36,656 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4609410830519416, 'Total loss': 0.4609410830519416} | train loss {'Reaction outcome loss': 0.46756768159720363, 'Total loss': 0.46756768159720363}
2022-11-28 06:33:36,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:36,656 INFO:     Epoch: 11
2022-11-28 06:33:37,322 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4578564935787158, 'Total loss': 0.4578564935787158} | train loss {'Reaction outcome loss': 0.45747786656934386, 'Total loss': 0.45747786656934386}
2022-11-28 06:33:37,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:37,323 INFO:     Epoch: 12
2022-11-28 06:33:37,987 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4498733932321722, 'Total loss': 0.4498733932321722} | train loss {'Reaction outcome loss': 0.4648282079672327, 'Total loss': 0.4648282079672327}
2022-11-28 06:33:37,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:37,987 INFO:     Epoch: 13
2022-11-28 06:33:38,650 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5247287425127897, 'Total loss': 0.5247287425127897} | train loss {'Reaction outcome loss': 0.45934630182324626, 'Total loss': 0.45934630182324626}
2022-11-28 06:33:38,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:38,650 INFO:     Epoch: 14
2022-11-28 06:33:39,312 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46009632233868947, 'Total loss': 0.46009632233868947} | train loss {'Reaction outcome loss': 0.45872687028378856, 'Total loss': 0.45872687028378856}
2022-11-28 06:33:39,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:39,312 INFO:     Epoch: 15
2022-11-28 06:33:39,973 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5109298645772717, 'Total loss': 0.5109298645772717} | train loss {'Reaction outcome loss': 0.46398069618307813, 'Total loss': 0.46398069618307813}
2022-11-28 06:33:39,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:39,974 INFO:     Epoch: 16
2022-11-28 06:33:40,642 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4468121372840621, 'Total loss': 0.4468121372840621} | train loss {'Reaction outcome loss': 0.45950049618069005, 'Total loss': 0.45950049618069005}
2022-11-28 06:33:40,642 INFO:     Found new best model at epoch 16
2022-11-28 06:33:40,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:40,643 INFO:     Epoch: 17
2022-11-28 06:33:41,307 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49293824031271716, 'Total loss': 0.49293824031271716} | train loss {'Reaction outcome loss': 0.4565773885773153, 'Total loss': 0.4565773885773153}
2022-11-28 06:33:41,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:41,307 INFO:     Epoch: 18
2022-11-28 06:33:41,969 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4683352478525855, 'Total loss': 0.4683352478525855} | train loss {'Reaction outcome loss': 0.45311326256820134, 'Total loss': 0.45311326256820134}
2022-11-28 06:33:41,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:41,969 INFO:     Epoch: 19
2022-11-28 06:33:42,632 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4494830813597549, 'Total loss': 0.4494830813597549} | train loss {'Reaction outcome loss': 0.4572596182628554, 'Total loss': 0.4572596182628554}
2022-11-28 06:33:42,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:42,632 INFO:     Epoch: 20
2022-11-28 06:33:43,296 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4835983877154914, 'Total loss': 0.4835983877154914} | train loss {'Reaction outcome loss': 0.4500288502598295, 'Total loss': 0.4500288502598295}
2022-11-28 06:33:43,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:43,296 INFO:     Epoch: 21
2022-11-28 06:33:43,960 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.454788110811602, 'Total loss': 0.454788110811602} | train loss {'Reaction outcome loss': 0.4583260510649, 'Total loss': 0.4583260510649}
2022-11-28 06:33:43,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:43,961 INFO:     Epoch: 22
2022-11-28 06:33:44,624 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44119591649029066, 'Total loss': 0.44119591649029066} | train loss {'Reaction outcome loss': 0.449479739945762, 'Total loss': 0.449479739945762}
2022-11-28 06:33:44,624 INFO:     Found new best model at epoch 22
2022-11-28 06:33:44,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:44,625 INFO:     Epoch: 23
2022-11-28 06:33:45,287 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4361984712833708, 'Total loss': 0.4361984712833708} | train loss {'Reaction outcome loss': 0.4513678677836243, 'Total loss': 0.4513678677836243}
2022-11-28 06:33:45,287 INFO:     Found new best model at epoch 23
2022-11-28 06:33:45,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:45,288 INFO:     Epoch: 24
2022-11-28 06:33:45,954 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4715160774913701, 'Total loss': 0.4715160774913701} | train loss {'Reaction outcome loss': 0.4564647514297038, 'Total loss': 0.4564647514297038}
2022-11-28 06:33:45,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:45,954 INFO:     Epoch: 25
2022-11-28 06:33:46,626 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4390136122026227, 'Total loss': 0.4390136122026227} | train loss {'Reaction outcome loss': 0.44653841387860627, 'Total loss': 0.44653841387860627}
2022-11-28 06:33:46,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:46,627 INFO:     Epoch: 26
2022-11-28 06:33:47,292 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45870609378272836, 'Total loss': 0.45870609378272836} | train loss {'Reaction outcome loss': 0.4508126125043752, 'Total loss': 0.4508126125043752}
2022-11-28 06:33:47,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:47,293 INFO:     Epoch: 27
2022-11-28 06:33:47,960 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44454195350408554, 'Total loss': 0.44454195350408554} | train loss {'Reaction outcome loss': 0.44467483539970554, 'Total loss': 0.44467483539970554}
2022-11-28 06:33:47,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:47,960 INFO:     Epoch: 28
2022-11-28 06:33:48,626 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47723555632612924, 'Total loss': 0.47723555632612924} | train loss {'Reaction outcome loss': 0.44806244616605795, 'Total loss': 0.44806244616605795}
2022-11-28 06:33:48,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:48,626 INFO:     Epoch: 29
2022-11-28 06:33:49,291 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4319432025605982, 'Total loss': 0.4319432025605982} | train loss {'Reaction outcome loss': 0.44712051834378924, 'Total loss': 0.44712051834378924}
2022-11-28 06:33:49,291 INFO:     Found new best model at epoch 29
2022-11-28 06:33:49,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:49,292 INFO:     Epoch: 30
2022-11-28 06:33:49,953 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4355083260346543, 'Total loss': 0.4355083260346543} | train loss {'Reaction outcome loss': 0.4507539690453179, 'Total loss': 0.4507539690453179}
2022-11-28 06:33:49,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:49,953 INFO:     Epoch: 31
2022-11-28 06:33:50,616 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44383320821957156, 'Total loss': 0.44383320821957156} | train loss {'Reaction outcome loss': 0.4488781728306595, 'Total loss': 0.4488781728306595}
2022-11-28 06:33:50,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:50,616 INFO:     Epoch: 32
2022-11-28 06:33:51,282 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46268030256032944, 'Total loss': 0.46268030256032944} | train loss {'Reaction outcome loss': 0.44343157173419484, 'Total loss': 0.44343157173419484}
2022-11-28 06:33:51,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:51,282 INFO:     Epoch: 33
2022-11-28 06:33:51,952 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5019216757606376, 'Total loss': 0.5019216757606376} | train loss {'Reaction outcome loss': 0.4455479506327181, 'Total loss': 0.4455479506327181}
2022-11-28 06:33:51,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:51,952 INFO:     Epoch: 34
2022-11-28 06:33:52,620 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5060016915879466, 'Total loss': 0.5060016915879466} | train loss {'Reaction outcome loss': 0.4447188669017383, 'Total loss': 0.4447188669017383}
2022-11-28 06:33:52,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:52,620 INFO:     Epoch: 35
2022-11-28 06:33:53,284 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4368009819564494, 'Total loss': 0.4368009819564494} | train loss {'Reaction outcome loss': 0.45348487064546467, 'Total loss': 0.45348487064546467}
2022-11-28 06:33:53,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:53,285 INFO:     Epoch: 36
2022-11-28 06:33:53,945 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4154236228628592, 'Total loss': 0.4154236228628592} | train loss {'Reaction outcome loss': 0.4432793283036777, 'Total loss': 0.4432793283036777}
2022-11-28 06:33:53,945 INFO:     Found new best model at epoch 36
2022-11-28 06:33:53,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:53,946 INFO:     Epoch: 37
2022-11-28 06:33:54,610 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43579092689535837, 'Total loss': 0.43579092689535837} | train loss {'Reaction outcome loss': 0.4480951947217085, 'Total loss': 0.4480951947217085}
2022-11-28 06:33:54,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:54,610 INFO:     Epoch: 38
2022-11-28 06:33:55,275 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41374946622685954, 'Total loss': 0.41374946622685954} | train loss {'Reaction outcome loss': 0.44774873363120216, 'Total loss': 0.44774873363120216}
2022-11-28 06:33:55,276 INFO:     Found new best model at epoch 38
2022-11-28 06:33:55,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:55,276 INFO:     Epoch: 39
2022-11-28 06:33:55,945 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4282069587233392, 'Total loss': 0.4282069587233392} | train loss {'Reaction outcome loss': 0.4461362451010821, 'Total loss': 0.4461362451010821}
2022-11-28 06:33:55,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:55,946 INFO:     Epoch: 40
2022-11-28 06:33:56,616 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44628259099342604, 'Total loss': 0.44628259099342604} | train loss {'Reaction outcome loss': 0.4387540938598769, 'Total loss': 0.4387540938598769}
2022-11-28 06:33:56,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:56,617 INFO:     Epoch: 41
2022-11-28 06:33:57,284 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4496582340110432, 'Total loss': 0.4496582340110432} | train loss {'Reaction outcome loss': 0.446638620599192, 'Total loss': 0.446638620599192}
2022-11-28 06:33:57,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:57,284 INFO:     Epoch: 42
2022-11-28 06:33:57,950 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4453572275286371, 'Total loss': 0.4453572275286371} | train loss {'Reaction outcome loss': 0.44757718760140086, 'Total loss': 0.44757718760140086}
2022-11-28 06:33:57,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:57,951 INFO:     Epoch: 43
2022-11-28 06:33:58,619 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4552346549250863, 'Total loss': 0.4552346549250863} | train loss {'Reaction outcome loss': 0.4437948453791287, 'Total loss': 0.4437948453791287}
2022-11-28 06:33:58,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:58,620 INFO:     Epoch: 44
2022-11-28 06:33:59,282 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46166069331494247, 'Total loss': 0.46166069331494247} | train loss {'Reaction outcome loss': 0.4519620925188065, 'Total loss': 0.4519620925188065}
2022-11-28 06:33:59,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:59,282 INFO:     Epoch: 45
2022-11-28 06:33:59,947 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44510670006275177, 'Total loss': 0.44510670006275177} | train loss {'Reaction outcome loss': 0.4384545422938405, 'Total loss': 0.4384545422938405}
2022-11-28 06:33:59,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:33:59,948 INFO:     Epoch: 46
2022-11-28 06:34:00,611 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.449071043594317, 'Total loss': 0.449071043594317} | train loss {'Reaction outcome loss': 0.44263127975317895, 'Total loss': 0.44263127975317895}
2022-11-28 06:34:00,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:00,611 INFO:     Epoch: 47
2022-11-28 06:34:01,275 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4960524585436691, 'Total loss': 0.4960524585436691} | train loss {'Reaction outcome loss': 0.4524555330373803, 'Total loss': 0.4524555330373803}
2022-11-28 06:34:01,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:01,275 INFO:     Epoch: 48
2022-11-28 06:34:01,938 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46525681222027, 'Total loss': 0.46525681222027} | train loss {'Reaction outcome loss': 0.44330958809171406, 'Total loss': 0.44330958809171406}
2022-11-28 06:34:01,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:01,938 INFO:     Epoch: 49
2022-11-28 06:34:02,602 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4530204578556798, 'Total loss': 0.4530204578556798} | train loss {'Reaction outcome loss': 0.44072638622352056, 'Total loss': 0.44072638622352056}
2022-11-28 06:34:02,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:02,602 INFO:     Epoch: 50
2022-11-28 06:34:03,266 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4253189682283185, 'Total loss': 0.4253189682283185} | train loss {'Reaction outcome loss': 0.44207049669051657, 'Total loss': 0.44207049669051657}
2022-11-28 06:34:03,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:03,266 INFO:     Epoch: 51
2022-11-28 06:34:03,929 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4665448877283118, 'Total loss': 0.4665448877283118} | train loss {'Reaction outcome loss': 0.4445086035193229, 'Total loss': 0.4445086035193229}
2022-11-28 06:34:03,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:03,929 INFO:     Epoch: 52
2022-11-28 06:34:04,593 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4449855373664336, 'Total loss': 0.4449855373664336} | train loss {'Reaction outcome loss': 0.4473315014522903, 'Total loss': 0.4473315014522903}
2022-11-28 06:34:04,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:04,593 INFO:     Epoch: 53
2022-11-28 06:34:05,259 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44634082507003436, 'Total loss': 0.44634082507003436} | train loss {'Reaction outcome loss': 0.446948801680487, 'Total loss': 0.446948801680487}
2022-11-28 06:34:05,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:05,259 INFO:     Epoch: 54
2022-11-28 06:34:05,922 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44440755451267416, 'Total loss': 0.44440755451267416} | train loss {'Reaction outcome loss': 0.4416327743505945, 'Total loss': 0.4416327743505945}
2022-11-28 06:34:05,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:05,923 INFO:     Epoch: 55
2022-11-28 06:34:06,588 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44946138916367834, 'Total loss': 0.44946138916367834} | train loss {'Reaction outcome loss': 0.4484080180829885, 'Total loss': 0.4484080180829885}
2022-11-28 06:34:06,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:06,588 INFO:     Epoch: 56
2022-11-28 06:34:07,252 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4583684209395539, 'Total loss': 0.4583684209395539} | train loss {'Reaction outcome loss': 0.44974290059537303, 'Total loss': 0.44974290059537303}
2022-11-28 06:34:07,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:07,252 INFO:     Epoch: 57
2022-11-28 06:34:07,914 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45549893616275355, 'Total loss': 0.45549893616275355} | train loss {'Reaction outcome loss': 0.44001764071230987, 'Total loss': 0.44001764071230987}
2022-11-28 06:34:07,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:07,914 INFO:     Epoch: 58
2022-11-28 06:34:08,580 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44489080839875067, 'Total loss': 0.44489080839875067} | train loss {'Reaction outcome loss': 0.4403725212325855, 'Total loss': 0.4403725212325855}
2022-11-28 06:34:08,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:08,582 INFO:     Epoch: 59
2022-11-28 06:34:09,249 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45422814109108667, 'Total loss': 0.45422814109108667} | train loss {'Reaction outcome loss': 0.4428513924078066, 'Total loss': 0.4428513924078066}
2022-11-28 06:34:09,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:09,249 INFO:     Epoch: 60
2022-11-28 06:34:09,914 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4359903024001555, 'Total loss': 0.4359903024001555} | train loss {'Reaction outcome loss': 0.45019472296140634, 'Total loss': 0.45019472296140634}
2022-11-28 06:34:09,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:09,915 INFO:     Epoch: 61
2022-11-28 06:34:10,582 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43326733803207224, 'Total loss': 0.43326733803207224} | train loss {'Reaction outcome loss': 0.43965858579898365, 'Total loss': 0.43965858579898365}
2022-11-28 06:34:10,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:10,583 INFO:     Epoch: 62
2022-11-28 06:34:11,247 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4463759548962116, 'Total loss': 0.4463759548962116} | train loss {'Reaction outcome loss': 0.4439102489729317, 'Total loss': 0.4439102489729317}
2022-11-28 06:34:11,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:11,248 INFO:     Epoch: 63
2022-11-28 06:34:11,912 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4388518744063648, 'Total loss': 0.4388518744063648} | train loss {'Reaction outcome loss': 0.4479506252979746, 'Total loss': 0.4479506252979746}
2022-11-28 06:34:11,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:11,912 INFO:     Epoch: 64
2022-11-28 06:34:12,578 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45207871801473876, 'Total loss': 0.45207871801473876} | train loss {'Reaction outcome loss': 0.44206864684820174, 'Total loss': 0.44206864684820174}
2022-11-28 06:34:12,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:12,578 INFO:     Epoch: 65
2022-11-28 06:34:13,243 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4340192184529521, 'Total loss': 0.4340192184529521} | train loss {'Reaction outcome loss': 0.4414824562717457, 'Total loss': 0.4414824562717457}
2022-11-28 06:34:13,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:13,243 INFO:     Epoch: 66
2022-11-28 06:34:13,914 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45271430198441853, 'Total loss': 0.45271430198441853} | train loss {'Reaction outcome loss': 0.4437504990368473, 'Total loss': 0.4437504990368473}
2022-11-28 06:34:13,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:13,914 INFO:     Epoch: 67
2022-11-28 06:34:14,580 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4584564759650014, 'Total loss': 0.4584564759650014} | train loss {'Reaction outcome loss': 0.4433331415969498, 'Total loss': 0.4433331415969498}
2022-11-28 06:34:14,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:14,581 INFO:     Epoch: 68
2022-11-28 06:34:15,246 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4275375304912979, 'Total loss': 0.4275375304912979} | train loss {'Reaction outcome loss': 0.4388431235235565, 'Total loss': 0.4388431235235565}
2022-11-28 06:34:15,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:15,246 INFO:     Epoch: 69
2022-11-28 06:34:15,908 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4281273956664584, 'Total loss': 0.4281273956664584} | train loss {'Reaction outcome loss': 0.44237705861427346, 'Total loss': 0.44237705861427346}
2022-11-28 06:34:15,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:15,908 INFO:     Epoch: 70
2022-11-28 06:34:16,572 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45324407890439034, 'Total loss': 0.45324407890439034} | train loss {'Reaction outcome loss': 0.4401567291240303, 'Total loss': 0.4401567291240303}
2022-11-28 06:34:16,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:16,572 INFO:     Epoch: 71
2022-11-28 06:34:17,227 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47486833042719145, 'Total loss': 0.47486833042719145} | train loss {'Reaction outcome loss': 0.44749341041457896, 'Total loss': 0.44749341041457896}
2022-11-28 06:34:17,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:17,227 INFO:     Epoch: 72
2022-11-28 06:34:17,882 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4337263981049711, 'Total loss': 0.4337263981049711} | train loss {'Reaction outcome loss': 0.4404535564841056, 'Total loss': 0.4404535564841056}
2022-11-28 06:34:17,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:17,883 INFO:     Epoch: 73
2022-11-28 06:34:18,541 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45351155373183166, 'Total loss': 0.45351155373183166} | train loss {'Reaction outcome loss': 0.45452440545266987, 'Total loss': 0.45452440545266987}
2022-11-28 06:34:18,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:18,542 INFO:     Epoch: 74
2022-11-28 06:34:19,199 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46632057800889015, 'Total loss': 0.46632057800889015} | train loss {'Reaction outcome loss': 0.43811151099448303, 'Total loss': 0.43811151099448303}
2022-11-28 06:34:19,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:19,200 INFO:     Epoch: 75
2022-11-28 06:34:19,855 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4375166534022851, 'Total loss': 0.4375166534022851} | train loss {'Reaction outcome loss': 0.44285532564533, 'Total loss': 0.44285532564533}
2022-11-28 06:34:19,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:19,856 INFO:     Epoch: 76
2022-11-28 06:34:20,511 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4523292915387587, 'Total loss': 0.4523292915387587} | train loss {'Reaction outcome loss': 0.4379546560803238, 'Total loss': 0.4379546560803238}
2022-11-28 06:34:20,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:20,511 INFO:     Epoch: 77
2022-11-28 06:34:21,166 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4344515184109861, 'Total loss': 0.4344515184109861} | train loss {'Reaction outcome loss': 0.4470192408683349, 'Total loss': 0.4470192408683349}
2022-11-28 06:34:21,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:21,166 INFO:     Epoch: 78
2022-11-28 06:34:21,819 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46152944558046083, 'Total loss': 0.46152944558046083} | train loss {'Reaction outcome loss': 0.4378024144896439, 'Total loss': 0.4378024144896439}
2022-11-28 06:34:21,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:21,819 INFO:     Epoch: 79
2022-11-28 06:34:22,472 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4836825007064776, 'Total loss': 0.4836825007064776} | train loss {'Reaction outcome loss': 0.44140368402004243, 'Total loss': 0.44140368402004243}
2022-11-28 06:34:22,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:22,472 INFO:     Epoch: 80
2022-11-28 06:34:23,127 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44771690548143606, 'Total loss': 0.44771690548143606} | train loss {'Reaction outcome loss': 0.44889933126313347, 'Total loss': 0.44889933126313347}
2022-11-28 06:34:23,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:23,127 INFO:     Epoch: 81
2022-11-28 06:34:23,781 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4582841386171905, 'Total loss': 0.4582841386171905} | train loss {'Reaction outcome loss': 0.44162132143974303, 'Total loss': 0.44162132143974303}
2022-11-28 06:34:23,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:23,781 INFO:     Epoch: 82
2022-11-28 06:34:24,436 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44012703238563106, 'Total loss': 0.44012703238563106} | train loss {'Reaction outcome loss': 0.4478286088729391, 'Total loss': 0.4478286088729391}
2022-11-28 06:34:24,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:24,436 INFO:     Epoch: 83
2022-11-28 06:34:25,094 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45951440049843356, 'Total loss': 0.45951440049843356} | train loss {'Reaction outcome loss': 0.4311976559916321, 'Total loss': 0.4311976559916321}
2022-11-28 06:34:25,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:25,095 INFO:     Epoch: 84
2022-11-28 06:34:25,751 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4981102760542523, 'Total loss': 0.4981102760542523} | train loss {'Reaction outcome loss': 0.4514039975648024, 'Total loss': 0.4514039975648024}
2022-11-28 06:34:25,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:25,751 INFO:     Epoch: 85
2022-11-28 06:34:26,406 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4597243529490449, 'Total loss': 0.4597243529490449} | train loss {'Reaction outcome loss': 0.4466968337492067, 'Total loss': 0.4466968337492067}
2022-11-28 06:34:26,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:26,406 INFO:     Epoch: 86
2022-11-28 06:34:27,059 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45086499743840913, 'Total loss': 0.45086499743840913} | train loss {'Reaction outcome loss': 0.4424794425769728, 'Total loss': 0.4424794425769728}
2022-11-28 06:34:27,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:27,059 INFO:     Epoch: 87
2022-11-28 06:34:27,714 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43116394769061694, 'Total loss': 0.43116394769061694} | train loss {'Reaction outcome loss': 0.44569145696503776, 'Total loss': 0.44569145696503776}
2022-11-28 06:34:27,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:27,714 INFO:     Epoch: 88
2022-11-28 06:34:28,370 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46726655892350455, 'Total loss': 0.46726655892350455} | train loss {'Reaction outcome loss': 0.4402844116699939, 'Total loss': 0.4402844116699939}
2022-11-28 06:34:28,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:28,371 INFO:     Epoch: 89
2022-11-28 06:34:29,027 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43871814994649455, 'Total loss': 0.43871814994649455} | train loss {'Reaction outcome loss': 0.4368553744286907, 'Total loss': 0.4368553744286907}
2022-11-28 06:34:29,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:29,027 INFO:     Epoch: 90
2022-11-28 06:34:29,682 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43168005313385616, 'Total loss': 0.43168005313385616} | train loss {'Reaction outcome loss': 0.4422610867084289, 'Total loss': 0.4422610867084289}
2022-11-28 06:34:29,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:29,682 INFO:     Epoch: 91
2022-11-28 06:34:30,342 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47330769625577057, 'Total loss': 0.47330769625577057} | train loss {'Reaction outcome loss': 0.45319905249135833, 'Total loss': 0.45319905249135833}
2022-11-28 06:34:30,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:30,343 INFO:     Epoch: 92
2022-11-28 06:34:30,996 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46267742054028943, 'Total loss': 0.46267742054028943} | train loss {'Reaction outcome loss': 0.4409850570012112, 'Total loss': 0.4409850570012112}
2022-11-28 06:34:30,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:30,997 INFO:     Epoch: 93
2022-11-28 06:34:31,649 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.437086013907736, 'Total loss': 0.437086013907736} | train loss {'Reaction outcome loss': 0.4411122944890236, 'Total loss': 0.4411122944890236}
2022-11-28 06:34:31,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:31,649 INFO:     Epoch: 94
2022-11-28 06:34:32,304 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45855923504991963, 'Total loss': 0.45855923504991963} | train loss {'Reaction outcome loss': 0.4461298818490943, 'Total loss': 0.4461298818490943}
2022-11-28 06:34:32,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:32,304 INFO:     Epoch: 95
2022-11-28 06:34:32,960 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.441304769536311, 'Total loss': 0.441304769536311} | train loss {'Reaction outcome loss': 0.4382105551812114, 'Total loss': 0.4382105551812114}
2022-11-28 06:34:32,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:32,960 INFO:     Epoch: 96
2022-11-28 06:34:33,613 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44510162791067903, 'Total loss': 0.44510162791067903} | train loss {'Reaction outcome loss': 0.4447859209410998, 'Total loss': 0.4447859209410998}
2022-11-28 06:34:33,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:33,613 INFO:     Epoch: 97
2022-11-28 06:34:34,265 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4300410378385674, 'Total loss': 0.4300410378385674} | train loss {'Reaction outcome loss': 0.44567440988457935, 'Total loss': 0.44567440988457935}
2022-11-28 06:34:34,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:34,265 INFO:     Epoch: 98
2022-11-28 06:34:34,920 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.448824076151306, 'Total loss': 0.448824076151306} | train loss {'Reaction outcome loss': 0.4428810612583647, 'Total loss': 0.4428810612583647}
2022-11-28 06:34:34,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:34,920 INFO:     Epoch: 99
2022-11-28 06:34:35,574 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46398688785054465, 'Total loss': 0.46398688785054465} | train loss {'Reaction outcome loss': 0.448193002355342, 'Total loss': 0.448193002355342}
2022-11-28 06:34:35,574 INFO:     Best model found after epoch 39 of 100.
2022-11-28 06:34:35,574 INFO:   Done with stage: TRAINING
2022-11-28 06:34:35,574 INFO:   Starting stage: EVALUATION
2022-11-28 06:34:35,698 INFO:   Done with stage: EVALUATION
2022-11-28 06:34:35,698 INFO:   Leaving out SEQ value Fold_9
2022-11-28 06:34:35,710 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 06:34:35,710 INFO:   Starting stage: FEATURE SCALING
2022-11-28 06:34:36,353 INFO:   Done with stage: FEATURE SCALING
2022-11-28 06:34:36,353 INFO:   Starting stage: SCALING TARGETS
2022-11-28 06:34:36,425 INFO:   Done with stage: SCALING TARGETS
2022-11-28 06:34:36,425 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:34:36,425 INFO:     No hyperparam tuning for this model
2022-11-28 06:34:36,425 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 06:34:36,425 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 06:34:36,426 INFO:     None feature selector for col prot
2022-11-28 06:34:36,426 INFO:     None feature selector for col prot
2022-11-28 06:34:36,426 INFO:     None feature selector for col prot
2022-11-28 06:34:36,427 INFO:     None feature selector for col chem
2022-11-28 06:34:36,427 INFO:     None feature selector for col chem
2022-11-28 06:34:36,427 INFO:     None feature selector for col chem
2022-11-28 06:34:36,427 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 06:34:36,427 INFO:   Starting stage: BUILD MODEL
2022-11-28 06:34:36,428 INFO:     Number of params in model 169651
2022-11-28 06:34:36,432 INFO:   Done with stage: BUILD MODEL
2022-11-28 06:34:36,432 INFO:   Starting stage: TRAINING
2022-11-28 06:34:36,483 INFO:     Val loss before train {'Reaction outcome loss': 0.9740287051959471, 'Total loss': 0.9740287051959471}
2022-11-28 06:34:36,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:36,484 INFO:     Epoch: 0
2022-11-28 06:34:37,142 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5309644145044413, 'Total loss': 0.5309644145044413} | train loss {'Reaction outcome loss': 0.701019024656665, 'Total loss': 0.701019024656665}
2022-11-28 06:34:37,143 INFO:     Found new best model at epoch 0
2022-11-28 06:34:37,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:37,143 INFO:     Epoch: 1
2022-11-28 06:34:37,805 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5157541923902251, 'Total loss': 0.5157541923902251} | train loss {'Reaction outcome loss': 0.5876047208064026, 'Total loss': 0.5876047208064026}
2022-11-28 06:34:37,805 INFO:     Found new best model at epoch 1
2022-11-28 06:34:37,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:37,806 INFO:     Epoch: 2
2022-11-28 06:34:38,468 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5431161963126876, 'Total loss': 0.5431161963126876} | train loss {'Reaction outcome loss': 0.565486517164015, 'Total loss': 0.565486517164015}
2022-11-28 06:34:38,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:38,468 INFO:     Epoch: 3
2022-11-28 06:34:39,128 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48677083206447685, 'Total loss': 0.48677083206447685} | train loss {'Reaction outcome loss': 0.5405564375462071, 'Total loss': 0.5405564375462071}
2022-11-28 06:34:39,128 INFO:     Found new best model at epoch 3
2022-11-28 06:34:39,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:39,129 INFO:     Epoch: 4
2022-11-28 06:34:39,789 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47748434204946866, 'Total loss': 0.47748434204946866} | train loss {'Reaction outcome loss': 0.5388230304684369, 'Total loss': 0.5388230304684369}
2022-11-28 06:34:39,790 INFO:     Found new best model at epoch 4
2022-11-28 06:34:39,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:39,791 INFO:     Epoch: 5
2022-11-28 06:34:40,450 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4639516797932712, 'Total loss': 0.4639516797932712} | train loss {'Reaction outcome loss': 0.5280612880784658, 'Total loss': 0.5280612880784658}
2022-11-28 06:34:40,450 INFO:     Found new best model at epoch 5
2022-11-28 06:34:40,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:40,451 INFO:     Epoch: 6
2022-11-28 06:34:41,110 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.475286255505952, 'Total loss': 0.475286255505952} | train loss {'Reaction outcome loss': 0.5134692854217945, 'Total loss': 0.5134692854217945}
2022-11-28 06:34:41,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:41,110 INFO:     Epoch: 7
2022-11-28 06:34:41,774 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4755362512713129, 'Total loss': 0.4755362512713129} | train loss {'Reaction outcome loss': 0.512067607093242, 'Total loss': 0.512067607093242}
2022-11-28 06:34:41,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:41,774 INFO:     Epoch: 8
2022-11-28 06:34:42,437 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4770863391458988, 'Total loss': 0.4770863391458988} | train loss {'Reaction outcome loss': 0.5012440034488757, 'Total loss': 0.5012440034488757}
2022-11-28 06:34:42,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:42,437 INFO:     Epoch: 9
2022-11-28 06:34:43,102 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4611106604676355, 'Total loss': 0.4611106604676355} | train loss {'Reaction outcome loss': 0.49637998081743717, 'Total loss': 0.49637998081743717}
2022-11-28 06:34:43,102 INFO:     Found new best model at epoch 9
2022-11-28 06:34:43,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:43,103 INFO:     Epoch: 10
2022-11-28 06:34:43,766 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45448528975248337, 'Total loss': 0.45448528975248337} | train loss {'Reaction outcome loss': 0.4955384615328043, 'Total loss': 0.4955384615328043}
2022-11-28 06:34:43,766 INFO:     Found new best model at epoch 10
2022-11-28 06:34:43,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:43,767 INFO:     Epoch: 11
2022-11-28 06:34:44,427 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4331385276534341, 'Total loss': 0.4331385276534341} | train loss {'Reaction outcome loss': 0.49048586928796384, 'Total loss': 0.49048586928796384}
2022-11-28 06:34:44,427 INFO:     Found new best model at epoch 11
2022-11-28 06:34:44,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:44,428 INFO:     Epoch: 12
2022-11-28 06:34:45,092 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4927647445689548, 'Total loss': 0.4927647445689548} | train loss {'Reaction outcome loss': 0.5001788904229479, 'Total loss': 0.5001788904229479}
2022-11-28 06:34:45,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:45,092 INFO:     Epoch: 13
2022-11-28 06:34:45,756 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4677335406568917, 'Total loss': 0.4677335406568917} | train loss {'Reaction outcome loss': 0.486621689021347, 'Total loss': 0.486621689021347}
2022-11-28 06:34:45,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:45,756 INFO:     Epoch: 14
2022-11-28 06:34:46,416 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4437321045181968, 'Total loss': 0.4437321045181968} | train loss {'Reaction outcome loss': 0.48430014413691336, 'Total loss': 0.48430014413691336}
2022-11-28 06:34:46,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:46,417 INFO:     Epoch: 15
2022-11-28 06:34:47,077 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47410933063788846, 'Total loss': 0.47410933063788846} | train loss {'Reaction outcome loss': 0.4810327198957243, 'Total loss': 0.4810327198957243}
2022-11-28 06:34:47,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:47,077 INFO:     Epoch: 16
2022-11-28 06:34:47,736 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4477623467418281, 'Total loss': 0.4477623467418281} | train loss {'Reaction outcome loss': 0.48599826829928544, 'Total loss': 0.48599826829928544}
2022-11-28 06:34:47,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:47,737 INFO:     Epoch: 17
2022-11-28 06:34:48,399 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44017727876251395, 'Total loss': 0.44017727876251395} | train loss {'Reaction outcome loss': 0.4880845692729758, 'Total loss': 0.4880845692729758}
2022-11-28 06:34:48,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:48,400 INFO:     Epoch: 18
2022-11-28 06:34:49,061 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4794068553230979, 'Total loss': 0.4794068553230979} | train loss {'Reaction outcome loss': 0.4875000492940026, 'Total loss': 0.4875000492940026}
2022-11-28 06:34:49,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:49,062 INFO:     Epoch: 19
2022-11-28 06:34:49,722 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4803126474673098, 'Total loss': 0.4803126474673098} | train loss {'Reaction outcome loss': 0.4812665412262563, 'Total loss': 0.4812665412262563}
2022-11-28 06:34:49,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:49,723 INFO:     Epoch: 20
2022-11-28 06:34:50,385 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48032423718409106, 'Total loss': 0.48032423718409106} | train loss {'Reaction outcome loss': 0.4897711201300544, 'Total loss': 0.4897711201300544}
2022-11-28 06:34:50,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:50,385 INFO:     Epoch: 21
2022-11-28 06:34:51,048 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4761529490351677, 'Total loss': 0.4761529490351677} | train loss {'Reaction outcome loss': 0.4781263626270717, 'Total loss': 0.4781263626270717}
2022-11-28 06:34:51,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:51,048 INFO:     Epoch: 22
2022-11-28 06:34:51,711 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46919364583763207, 'Total loss': 0.46919364583763207} | train loss {'Reaction outcome loss': 0.482237720681775, 'Total loss': 0.482237720681775}
2022-11-28 06:34:51,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:51,712 INFO:     Epoch: 23
2022-11-28 06:34:52,376 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42615771056576207, 'Total loss': 0.42615771056576207} | train loss {'Reaction outcome loss': 0.48896098443337027, 'Total loss': 0.48896098443337027}
2022-11-28 06:34:52,377 INFO:     Found new best model at epoch 23
2022-11-28 06:34:52,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:52,377 INFO:     Epoch: 24
2022-11-28 06:34:53,042 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4485419893806631, 'Total loss': 0.4485419893806631} | train loss {'Reaction outcome loss': 0.47765492425570566, 'Total loss': 0.47765492425570566}
2022-11-28 06:34:53,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:53,043 INFO:     Epoch: 25
2022-11-28 06:34:53,708 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4613392505456101, 'Total loss': 0.4613392505456101} | train loss {'Reaction outcome loss': 0.4816075711841545, 'Total loss': 0.4816075711841545}
2022-11-28 06:34:53,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:53,709 INFO:     Epoch: 26
2022-11-28 06:34:54,371 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4484720951454206, 'Total loss': 0.4484720951454206} | train loss {'Reaction outcome loss': 0.47630347816213486, 'Total loss': 0.47630347816213486}
2022-11-28 06:34:54,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:54,371 INFO:     Epoch: 27
2022-11-28 06:34:55,031 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43034889752214606, 'Total loss': 0.43034889752214606} | train loss {'Reaction outcome loss': 0.4809898676410798, 'Total loss': 0.4809898676410798}
2022-11-28 06:34:55,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:55,032 INFO:     Epoch: 28
2022-11-28 06:34:55,691 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4260819053108042, 'Total loss': 0.4260819053108042} | train loss {'Reaction outcome loss': 0.47798937246684103, 'Total loss': 0.47798937246684103}
2022-11-28 06:34:55,692 INFO:     Found new best model at epoch 28
2022-11-28 06:34:55,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:55,692 INFO:     Epoch: 29
2022-11-28 06:34:56,354 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43549317426302214, 'Total loss': 0.43549317426302214} | train loss {'Reaction outcome loss': 0.479529018543901, 'Total loss': 0.479529018543901}
2022-11-28 06:34:56,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:56,354 INFO:     Epoch: 30
2022-11-28 06:34:57,015 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4442907798696648, 'Total loss': 0.4442907798696648} | train loss {'Reaction outcome loss': 0.4801037738760633, 'Total loss': 0.4801037738760633}
2022-11-28 06:34:57,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:57,016 INFO:     Epoch: 31
2022-11-28 06:34:57,680 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44594667039134284, 'Total loss': 0.44594667039134284} | train loss {'Reaction outcome loss': 0.48543603922570905, 'Total loss': 0.48543603922570905}
2022-11-28 06:34:57,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:57,680 INFO:     Epoch: 32
2022-11-28 06:34:58,340 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44327548518776894, 'Total loss': 0.44327548518776894} | train loss {'Reaction outcome loss': 0.4825360816753199, 'Total loss': 0.4825360816753199}
2022-11-28 06:34:58,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:58,340 INFO:     Epoch: 33
2022-11-28 06:34:59,001 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43770513514226134, 'Total loss': 0.43770513514226134} | train loss {'Reaction outcome loss': 0.4859686433788269, 'Total loss': 0.4859686433788269}
2022-11-28 06:34:59,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:59,002 INFO:     Epoch: 34
2022-11-28 06:34:59,666 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44048338451168756, 'Total loss': 0.44048338451168756} | train loss {'Reaction outcome loss': 0.47639391309912166, 'Total loss': 0.47639391309912166}
2022-11-28 06:34:59,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:34:59,666 INFO:     Epoch: 35
2022-11-28 06:35:00,330 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4404180439358408, 'Total loss': 0.4404180439358408} | train loss {'Reaction outcome loss': 0.48227637032828025, 'Total loss': 0.48227637032828025}
2022-11-28 06:35:00,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:00,331 INFO:     Epoch: 36
2022-11-28 06:35:00,992 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44278180260549893, 'Total loss': 0.44278180260549893} | train loss {'Reaction outcome loss': 0.48301816960015603, 'Total loss': 0.48301816960015603}
2022-11-28 06:35:00,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:00,992 INFO:     Epoch: 37
2022-11-28 06:35:01,653 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4367489984089678, 'Total loss': 0.4367489984089678} | train loss {'Reaction outcome loss': 0.4788097163001376, 'Total loss': 0.4788097163001376}
2022-11-28 06:35:01,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:01,653 INFO:     Epoch: 38
2022-11-28 06:35:02,313 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4426825534213673, 'Total loss': 0.4426825534213673} | train loss {'Reaction outcome loss': 0.47903529482503093, 'Total loss': 0.47903529482503093}
2022-11-28 06:35:02,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:02,313 INFO:     Epoch: 39
2022-11-28 06:35:02,977 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4478495642542839, 'Total loss': 0.4478495642542839} | train loss {'Reaction outcome loss': 0.48132692343525346, 'Total loss': 0.48132692343525346}
2022-11-28 06:35:02,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:02,977 INFO:     Epoch: 40
2022-11-28 06:35:03,638 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45656266571445897, 'Total loss': 0.45656266571445897} | train loss {'Reaction outcome loss': 0.47968646844909074, 'Total loss': 0.47968646844909074}
2022-11-28 06:35:03,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:03,638 INFO:     Epoch: 41
2022-11-28 06:35:04,305 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4390334459868344, 'Total loss': 0.4390334459868344} | train loss {'Reaction outcome loss': 0.4723777232030707, 'Total loss': 0.4723777232030707}
2022-11-28 06:35:04,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:04,305 INFO:     Epoch: 42
2022-11-28 06:35:04,967 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4367840008979494, 'Total loss': 0.4367840008979494} | train loss {'Reaction outcome loss': 0.4794566229346298, 'Total loss': 0.4794566229346298}
2022-11-28 06:35:04,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:04,967 INFO:     Epoch: 43
2022-11-28 06:35:05,633 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4354325800456784, 'Total loss': 0.4354325800456784} | train loss {'Reaction outcome loss': 0.48122036553198294, 'Total loss': 0.48122036553198294}
2022-11-28 06:35:05,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:05,633 INFO:     Epoch: 44
2022-11-28 06:35:06,293 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4373337419872934, 'Total loss': 0.4373337419872934} | train loss {'Reaction outcome loss': 0.4806952685598404, 'Total loss': 0.4806952685598404}
2022-11-28 06:35:06,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:06,294 INFO:     Epoch: 45
2022-11-28 06:35:06,953 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.429245033047416, 'Total loss': 0.429245033047416} | train loss {'Reaction outcome loss': 0.47928313772764897, 'Total loss': 0.47928313772764897}
2022-11-28 06:35:06,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:06,953 INFO:     Epoch: 46
2022-11-28 06:35:07,621 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4415982467207042, 'Total loss': 0.4415982467207042} | train loss {'Reaction outcome loss': 0.4776941118161044, 'Total loss': 0.4776941118161044}
2022-11-28 06:35:07,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:07,621 INFO:     Epoch: 47
2022-11-28 06:35:08,282 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44422488050027326, 'Total loss': 0.44422488050027326} | train loss {'Reaction outcome loss': 0.4770553857688942, 'Total loss': 0.4770553857688942}
2022-11-28 06:35:08,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:08,282 INFO:     Epoch: 48
2022-11-28 06:35:08,944 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46684030104767194, 'Total loss': 0.46684030104767194} | train loss {'Reaction outcome loss': 0.4817899422900331, 'Total loss': 0.4817899422900331}
2022-11-28 06:35:08,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:08,944 INFO:     Epoch: 49
2022-11-28 06:35:09,608 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4460261531851508, 'Total loss': 0.4460261531851508} | train loss {'Reaction outcome loss': 0.4767945620321458, 'Total loss': 0.4767945620321458}
2022-11-28 06:35:09,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:09,608 INFO:     Epoch: 50
2022-11-28 06:35:10,270 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4461980905722488, 'Total loss': 0.4461980905722488} | train loss {'Reaction outcome loss': 0.4777055734828595, 'Total loss': 0.4777055734828595}
2022-11-28 06:35:10,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:10,271 INFO:     Epoch: 51
2022-11-28 06:35:10,936 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42841770906339993, 'Total loss': 0.42841770906339993} | train loss {'Reaction outcome loss': 0.48513695116966, 'Total loss': 0.48513695116966}
2022-11-28 06:35:10,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:10,937 INFO:     Epoch: 52
2022-11-28 06:35:11,598 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45833837342533196, 'Total loss': 0.45833837342533196} | train loss {'Reaction outcome loss': 0.48101687245070934, 'Total loss': 0.48101687245070934}
2022-11-28 06:35:11,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:11,598 INFO:     Epoch: 53
2022-11-28 06:35:12,262 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4732323634353551, 'Total loss': 0.4732323634353551} | train loss {'Reaction outcome loss': 0.4756266078160655, 'Total loss': 0.4756266078160655}
2022-11-28 06:35:12,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:12,263 INFO:     Epoch: 54
2022-11-28 06:35:12,924 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44784009185704315, 'Total loss': 0.44784009185704315} | train loss {'Reaction outcome loss': 0.4725404920717401, 'Total loss': 0.4725404920717401}
2022-11-28 06:35:12,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:12,924 INFO:     Epoch: 55
2022-11-28 06:35:13,587 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45184707980264316, 'Total loss': 0.45184707980264316} | train loss {'Reaction outcome loss': 0.4831978663681976, 'Total loss': 0.4831978663681976}
2022-11-28 06:35:13,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:13,587 INFO:     Epoch: 56
2022-11-28 06:35:14,250 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48275754194368015, 'Total loss': 0.48275754194368015} | train loss {'Reaction outcome loss': 0.4756039344375172, 'Total loss': 0.4756039344375172}
2022-11-28 06:35:14,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:14,251 INFO:     Epoch: 57
2022-11-28 06:35:14,915 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5154065310277722, 'Total loss': 0.5154065310277722} | train loss {'Reaction outcome loss': 0.47746933834447014, 'Total loss': 0.47746933834447014}
2022-11-28 06:35:14,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:14,915 INFO:     Epoch: 58
2022-11-28 06:35:15,578 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46229367262937804, 'Total loss': 0.46229367262937804} | train loss {'Reaction outcome loss': 0.4786461298203757, 'Total loss': 0.4786461298203757}
2022-11-28 06:35:15,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:15,578 INFO:     Epoch: 59
2022-11-28 06:35:16,245 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4704464321786707, 'Total loss': 0.4704464321786707} | train loss {'Reaction outcome loss': 0.47490714607580053, 'Total loss': 0.47490714607580053}
2022-11-28 06:35:16,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:16,245 INFO:     Epoch: 60
2022-11-28 06:35:16,909 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43648077242753724, 'Total loss': 0.43648077242753724} | train loss {'Reaction outcome loss': 0.47853158399342527, 'Total loss': 0.47853158399342527}
2022-11-28 06:35:16,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:16,910 INFO:     Epoch: 61
2022-11-28 06:35:17,575 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43715374544262886, 'Total loss': 0.43715374544262886} | train loss {'Reaction outcome loss': 0.48203404205701045, 'Total loss': 0.48203404205701045}
2022-11-28 06:35:17,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:17,575 INFO:     Epoch: 62
2022-11-28 06:35:18,242 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47190422734076326, 'Total loss': 0.47190422734076326} | train loss {'Reaction outcome loss': 0.47838182795432305, 'Total loss': 0.47838182795432305}
2022-11-28 06:35:18,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:18,243 INFO:     Epoch: 63
2022-11-28 06:35:18,910 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.475753704932603, 'Total loss': 0.475753704932603} | train loss {'Reaction outcome loss': 0.47976762927587957, 'Total loss': 0.47976762927587957}
2022-11-28 06:35:18,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:18,911 INFO:     Epoch: 64
2022-11-28 06:35:19,575 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4324317808178338, 'Total loss': 0.4324317808178338} | train loss {'Reaction outcome loss': 0.4749968768728356, 'Total loss': 0.4749968768728356}
2022-11-28 06:35:19,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:19,576 INFO:     Epoch: 65
2022-11-28 06:35:20,243 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.6017634116790511, 'Total loss': 0.6017634116790511} | train loss {'Reaction outcome loss': 0.47414373342067967, 'Total loss': 0.47414373342067967}
2022-11-28 06:35:20,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:20,243 INFO:     Epoch: 66
2022-11-28 06:35:20,909 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48825750974091614, 'Total loss': 0.48825750974091614} | train loss {'Reaction outcome loss': 0.4777529374245674, 'Total loss': 0.4777529374245674}
2022-11-28 06:35:20,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:20,910 INFO:     Epoch: 67
2022-11-28 06:35:21,578 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4307704838839444, 'Total loss': 0.4307704838839444} | train loss {'Reaction outcome loss': 0.4762376335359389, 'Total loss': 0.4762376335359389}
2022-11-28 06:35:21,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:21,578 INFO:     Epoch: 68
2022-11-28 06:35:22,244 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4582880274815993, 'Total loss': 0.4582880274815993} | train loss {'Reaction outcome loss': 0.48021841620004946, 'Total loss': 0.48021841620004946}
2022-11-28 06:35:22,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:22,244 INFO:     Epoch: 69
2022-11-28 06:35:22,910 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4389779679477215, 'Total loss': 0.4389779679477215} | train loss {'Reaction outcome loss': 0.48296643165691244, 'Total loss': 0.48296643165691244}
2022-11-28 06:35:22,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:22,910 INFO:     Epoch: 70
2022-11-28 06:35:23,574 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4748095731166276, 'Total loss': 0.4748095731166276} | train loss {'Reaction outcome loss': 0.4744702182229488, 'Total loss': 0.4744702182229488}
2022-11-28 06:35:23,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:23,575 INFO:     Epoch: 71
2022-11-28 06:35:24,246 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41775855438953097, 'Total loss': 0.41775855438953097} | train loss {'Reaction outcome loss': 0.47249021687574927, 'Total loss': 0.47249021687574927}
2022-11-28 06:35:24,246 INFO:     Found new best model at epoch 71
2022-11-28 06:35:24,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:24,247 INFO:     Epoch: 72
2022-11-28 06:35:24,919 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46976910666985944, 'Total loss': 0.46976910666985944} | train loss {'Reaction outcome loss': 0.4753696697373544, 'Total loss': 0.4753696697373544}
2022-11-28 06:35:24,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:24,919 INFO:     Epoch: 73
2022-11-28 06:35:25,587 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4518300694498149, 'Total loss': 0.4518300694498149} | train loss {'Reaction outcome loss': 0.4844825734654742, 'Total loss': 0.4844825734654742}
2022-11-28 06:35:25,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:25,588 INFO:     Epoch: 74
2022-11-28 06:35:26,256 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47748206928372383, 'Total loss': 0.47748206928372383} | train loss {'Reaction outcome loss': 0.4774914275133802, 'Total loss': 0.4774914275133802}
2022-11-28 06:35:26,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:26,256 INFO:     Epoch: 75
2022-11-28 06:35:26,921 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47799003090370784, 'Total loss': 0.47799003090370784} | train loss {'Reaction outcome loss': 0.4789998905072289, 'Total loss': 0.4789998905072289}
2022-11-28 06:35:26,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:26,921 INFO:     Epoch: 76
2022-11-28 06:35:27,590 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4211066974834962, 'Total loss': 0.4211066974834962} | train loss {'Reaction outcome loss': 0.4771397395600234, 'Total loss': 0.4771397395600234}
2022-11-28 06:35:27,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:27,590 INFO:     Epoch: 77
2022-11-28 06:35:28,255 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44143654812466016, 'Total loss': 0.44143654812466016} | train loss {'Reaction outcome loss': 0.46927041344104276, 'Total loss': 0.46927041344104276}
2022-11-28 06:35:28,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:28,255 INFO:     Epoch: 78
2022-11-28 06:35:28,923 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41376089372418146, 'Total loss': 0.41376089372418146} | train loss {'Reaction outcome loss': 0.48224991505905507, 'Total loss': 0.48224991505905507}
2022-11-28 06:35:28,923 INFO:     Found new best model at epoch 78
2022-11-28 06:35:28,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:28,924 INFO:     Epoch: 79
2022-11-28 06:35:29,592 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4544855220751329, 'Total loss': 0.4544855220751329} | train loss {'Reaction outcome loss': 0.4693454728732186, 'Total loss': 0.4693454728732186}
2022-11-28 06:35:29,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:29,593 INFO:     Epoch: 80
2022-11-28 06:35:30,261 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.442579638551582, 'Total loss': 0.442579638551582} | train loss {'Reaction outcome loss': 0.4746970979556922, 'Total loss': 0.4746970979556922}
2022-11-28 06:35:30,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:30,262 INFO:     Epoch: 81
2022-11-28 06:35:30,927 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42542414976791904, 'Total loss': 0.42542414976791904} | train loss {'Reaction outcome loss': 0.47596941035120716, 'Total loss': 0.47596941035120716}
2022-11-28 06:35:30,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:30,927 INFO:     Epoch: 82
2022-11-28 06:35:31,591 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42837786657566373, 'Total loss': 0.42837786657566373} | train loss {'Reaction outcome loss': 0.47184984758496284, 'Total loss': 0.47184984758496284}
2022-11-28 06:35:31,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:31,592 INFO:     Epoch: 83
2022-11-28 06:35:32,255 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4694639214060523, 'Total loss': 0.4694639214060523} | train loss {'Reaction outcome loss': 0.4736374342633832, 'Total loss': 0.4736374342633832}
2022-11-28 06:35:32,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:32,255 INFO:     Epoch: 84
2022-11-28 06:35:32,922 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43284523995085195, 'Total loss': 0.43284523995085195} | train loss {'Reaction outcome loss': 0.4666902481788589, 'Total loss': 0.4666902481788589}
2022-11-28 06:35:32,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:32,923 INFO:     Epoch: 85
2022-11-28 06:35:33,588 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4533399824391712, 'Total loss': 0.4533399824391712} | train loss {'Reaction outcome loss': 0.48045384228950544, 'Total loss': 0.48045384228950544}
2022-11-28 06:35:33,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:33,588 INFO:     Epoch: 86
2022-11-28 06:35:34,255 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42396454682404344, 'Total loss': 0.42396454682404344} | train loss {'Reaction outcome loss': 0.4696694409414645, 'Total loss': 0.4696694409414645}
2022-11-28 06:35:34,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:34,255 INFO:     Epoch: 87
2022-11-28 06:35:34,921 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42316368086771533, 'Total loss': 0.42316368086771533} | train loss {'Reaction outcome loss': 0.4717784115383702, 'Total loss': 0.4717784115383702}
2022-11-28 06:35:34,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:34,922 INFO:     Epoch: 88
2022-11-28 06:35:35,587 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41368445483121, 'Total loss': 0.41368445483121} | train loss {'Reaction outcome loss': 0.47471701497993163, 'Total loss': 0.47471701497993163}
2022-11-28 06:35:35,587 INFO:     Found new best model at epoch 88
2022-11-28 06:35:35,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:35,588 INFO:     Epoch: 89
2022-11-28 06:35:36,255 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4371800117871978, 'Total loss': 0.4371800117871978} | train loss {'Reaction outcome loss': 0.47455414468722956, 'Total loss': 0.47455414468722956}
2022-11-28 06:35:36,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:36,256 INFO:     Epoch: 90
2022-11-28 06:35:36,923 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42301237176765094, 'Total loss': 0.42301237176765094} | train loss {'Reaction outcome loss': 0.4754889341251504, 'Total loss': 0.4754889341251504}
2022-11-28 06:35:36,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:36,923 INFO:     Epoch: 91
2022-11-28 06:35:37,587 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4223994548347863, 'Total loss': 0.4223994548347863} | train loss {'Reaction outcome loss': 0.46695041295982176, 'Total loss': 0.46695041295982176}
2022-11-28 06:35:37,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:37,587 INFO:     Epoch: 92
2022-11-28 06:35:38,256 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4494510777294636, 'Total loss': 0.4494510777294636} | train loss {'Reaction outcome loss': 0.4704338415495811, 'Total loss': 0.4704338415495811}
2022-11-28 06:35:38,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:38,257 INFO:     Epoch: 93
2022-11-28 06:35:38,924 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43484886667945166, 'Total loss': 0.43484886667945166} | train loss {'Reaction outcome loss': 0.4763982379508595, 'Total loss': 0.4763982379508595}
2022-11-28 06:35:38,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:38,924 INFO:     Epoch: 94
2022-11-28 06:35:39,588 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43593198907646263, 'Total loss': 0.43593198907646263} | train loss {'Reaction outcome loss': 0.47397195607904463, 'Total loss': 0.47397195607904463}
2022-11-28 06:35:39,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:39,589 INFO:     Epoch: 95
2022-11-28 06:35:40,257 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4589455926960165, 'Total loss': 0.4589455926960165} | train loss {'Reaction outcome loss': 0.4790020458880932, 'Total loss': 0.4790020458880932}
2022-11-28 06:35:40,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:40,257 INFO:     Epoch: 96
2022-11-28 06:35:40,920 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44752233949574555, 'Total loss': 0.44752233949574555} | train loss {'Reaction outcome loss': 0.47590044339097315, 'Total loss': 0.47590044339097315}
2022-11-28 06:35:40,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:40,920 INFO:     Epoch: 97
2022-11-28 06:35:41,585 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4383351416750388, 'Total loss': 0.4383351416750388} | train loss {'Reaction outcome loss': 0.4724686569984882, 'Total loss': 0.4724686569984882}
2022-11-28 06:35:41,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:41,585 INFO:     Epoch: 98
2022-11-28 06:35:42,251 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44511861354112625, 'Total loss': 0.44511861354112625} | train loss {'Reaction outcome loss': 0.4696775712072849, 'Total loss': 0.4696775712072849}
2022-11-28 06:35:42,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 06:35:42,252 INFO:     Epoch: 99
2022-11-28 06:35:42,917 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4315088740126653, 'Total loss': 0.4315088740126653} | train loss {'Reaction outcome loss': 0.4674723694521573, 'Total loss': 0.4674723694521573}
2022-11-28 06:35:42,917 INFO:     Best model found after epoch 89 of 100.
2022-11-28 06:35:42,917 INFO:   Done with stage: TRAINING
2022-11-28 06:35:42,917 INFO:   Starting stage: EVALUATION
2022-11-28 06:35:43,031 INFO:   Done with stage: EVALUATION
2022-11-28 06:35:43,031 INFO: Done with stage: RUNNING SPLITS
2022-11-28 06:35:43,031 INFO: Starting stage: COMPUTE METRICS
2022-11-28 06:35:44,212 INFO: Done with stage: COMPUTE METRICS
2022-11-28 06:35:44,213 INFO: Starting stage: EXPORT RESULTS
2022-11-28 06:35:44,230 INFO:   Final results averaged over 50 folds: 
2022-11-28 06:35:44,234 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.185695           NaN  0.307709       NaN
2022-11-28 06:35:45,876 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-28 06:35:45,881 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-28 06:35:45,882 DEBUG:   interactive is False
2022-11-28 06:35:45,883 DEBUG:   platform is linux
2022-11-28 06:35:45,883 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-28 06:35:46,057 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-28 06:35:46,059 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-28 06:35:46,492 DEBUG:   Loaded backend agg version unknown.
2022-11-28 06:35:46,495 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,496 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,497 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 06:35:46,498 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,498 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 06:35:46,534 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-28 06:35:46,534 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,534 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,534 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,534 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,534 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,534 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 06:35:46,535 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,536 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 06:35:46,537 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,537 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,537 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,537 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 06:35:46,537 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,537 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 06:35:46,545 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 06:35:46,545 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,545 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,545 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,546 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,547 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,548 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,548 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 06:35:46,548 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 06:35:46,548 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,548 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,548 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 06:35:46,548 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 06:35:46,548 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 06:35:46,548 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 06:35:46,976 INFO: Done with stage: EXPORT RESULTS
2022-11-28 06:35:46,976 INFO: Starting stage: SAVE MODEL
2022-11-28 06:35:47,044 INFO: Done with stage: SAVE MODEL
2022-11-28 06:35:47,044 INFO: Wall time for program:  3361.60 seconds
